{
  "category": "education-and-learning",
  "categoryDisplay": "Education and Learning",
  "description": "",
  "totalRepositories": 127,
  "repositories": {
    "1282saa--mcp_style": {
      "owner": "1282saa",
      "name": "mcp_style",
      "url": "https://github.com/1282saa/mcp_style",
      "imageUrl": "https://github.com/1282saa.png",
      "description": "The MCP Style Server is an open-source tool that allows users to integrate external resources and prompts into AI workflows easily. It supports customization and quick testing of ML features for enhanced applications involving large language models.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-03T13:09:51Z",
      "readme_content": "# ì„œìš¸ê²½ì œì‹ ë¬¸ ìŠ¤íƒ€ì¼ë¶ MCP ì„œë²„\n\nì´ í”„ë¡œì íŠ¸ëŠ” ì„œìš¸ê²½ì œì‹ ë¬¸ ìŠ¤íƒ€ì¼ë¶ ë°ì´í„°ë¥¼ MCP(Model Context Protocol) ì„œë²„ë¡œ ì œê³µí•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.\n\n## ì„¤ì¹˜ ë°©ë²•\n\n### í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n\n```bash\npip install -r requirements.txt\n```\n\n## ê¸°ë³¸ ì‚¬ìš©ë²•\n\n### 1. ì§ì ‘ ì‹¤í–‰\n\n```bash\npython stylebook_mcp_fastmcp.py --stdio --data_path \"ê¸°ì‚¬ ì‘ì„± ì¤€ì¹™\"\n```\n\n### 2. ìŠ¤ë¯¸ë”ë¦¬ ì—°ë™\n\n1. ìŠ¤ë¯¸ë”ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n2. `smithery.yaml` íŒŒì¼ì„ ìŠ¤ë¯¸ë”ë¦¬ ë””ë ‰í† ë¦¬ì— ë³µì‚¬í•©ë‹ˆë‹¤.\n3. ìŠ¤ë¯¸ë”ë¦¬ì—ì„œ `@your-username/mcp_style`ì„ ë°°í¬í•©ë‹ˆë‹¤.\n\n### 3. í´ë¡œë“œ ë°ìŠ¤í¬íƒ‘ ì—°ë™\n\n1. `claude_desktop_config.json` íŒŒì¼ì„ í™ˆ ë””ë ‰í† ë¦¬ì˜ ì ì ˆí•œ ìœ„ì¹˜ì— ë³µì‚¬í•©ë‹ˆë‹¤:\n\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n   - Linux: `~/.config/Claude/claude_desktop_config.json`\n\n2. í´ë¡œë“œ ë°ìŠ¤í¬íƒ‘ì„ ì¬ì‹œì‘í•©ë‹ˆë‹¤.\n\n## í…ŒìŠ¤íŠ¸ ë°©ë²•\n\n```bash\n# ê¸°ë³¸ í…ŒìŠ¤íŠ¸\npython test_mcp.py\n\n# íŠ¹ì • ë°ì´í„° ê²½ë¡œì™€ í•¨ê»˜ í…ŒìŠ¤íŠ¸\npython test_mcp.py --data-path \"ê¸°ì‚¬ ì‘ì„± ì¤€ì¹™\"\n\n# íŠ¹ì • ê²€ìƒ‰ì–´ë¡œ í…ŒìŠ¤íŠ¸\npython test_mcp.py --query \"ë¬¸ì¥ë¶€í˜¸\"\n```\n\n## MCP Inspectorë¡œ í…ŒìŠ¤íŠ¸\n\n```bash\nnpx @modelcontextprotocol/inspector python -u stylebook_mcp_fastmcp.py --stdio --data_path \".\"\n```\n\n## ë””ë ‰í† ë¦¬ êµ¬ì¡°\n\nì´ MCP ì„œë²„ëŠ” ë‹¤ìŒê³¼ ê°™ì€ íŒŒì¼ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:\n\n```\n.\nâ”œâ”€â”€ smithery.yaml                # ìŠ¤ë¯¸ë”ë¦¬ ì„¤ì • íŒŒì¼\nâ”œâ”€â”€ stylebook_mcp_fastmcp.py     # MCP ì„œë²„ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸\nâ”œâ”€â”€ claude_desktop_config.json   # í´ë¡œë“œ ë°ìŠ¤í¬íƒ‘ ì„¤ì • íŒŒì¼\nâ”œâ”€â”€ test_mcp.py                  # í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸\nâ”œâ”€â”€ requirements.txt             # í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª©ë¡\nâ””â”€â”€ README.md                    # ì´ ë¬¸ì„œ\n```\n\n## ìŠ¤íƒ€ì¼ë¶ ë°ì´í„° êµ¬ì¡°\n\nìŠ¤íƒ€ì¼ë¶ ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤ (ê¸°ë³¸ì ìœ¼ë¡œ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìë™ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤):\n\n```\n.\nâ”œâ”€â”€ ê¸°ì‚¬ ì‘ì„± ì¤€ì¹™/\nâ”œâ”€â”€ ê¸°ì‚¬ì‘ì„± ìš”ë ¹/\nâ”œâ”€â”€ ìì£¼ í‹€ë¦¬ëŠ” ë§/\nâ”œâ”€â”€ ì œëª©ê³¼ ë ˆì´ì•„ì›ƒ_ì œëª©ë‹¬ê¸°/\nâ”œâ”€â”€ ì œëª©ê³¼ ë ˆì´ì•„ì›ƒ_ë ˆì´ì•„ì›ƒ ìš”ë ¹/\nâ””â”€â”€ ë‰´ìŠ¤ê°€ì¹˜ íŒë‹¨/\n```\n\nê° ë””ë ‰í† ë¦¬ì—ëŠ” `.json` íŒŒì¼ë“¤ì´ ìˆì–´ì•¼ í•˜ë©°, ë©”íƒ€ë°ì´í„°ëŠ” `metadata.json` ë˜ëŠ” `_meta.json` íŒŒì¼ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n\n## ë„êµ¬ ëª©ë¡\n\nMCP ì„œë²„ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤:\n\n1. `get_metadata` - ìŠ¤íƒ€ì¼ë¶ ë©”íƒ€ë°ì´í„° ì¡°íšŒ\n2. `get_categories` - ìŠ¤íƒ€ì¼ë¶ ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì¡°íšŒ\n3. `get_rule` - íŠ¹ì • ê·œì¹™ IDë¡œ ìŠ¤íƒ€ì¼ë¶ ê·œì¹™ ì¡°íšŒ\n4. `search` - í‚¤ì›Œë“œë¡œ ìŠ¤íƒ€ì¼ë¶ ê²€ìƒ‰\n5. `claude_search` - Claude AIë¥¼ ì‚¬ìš©í•œ ìŠ¤íƒ€ì¼ë¶ ê²€ìƒ‰\n6. `download_json` - ìŠ¤íƒ€ì¼ë¶ JSON íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n\n## í™˜ê²½ ë³€ìˆ˜\n\n- `PYTHONUNBUFFERED`: í•­ìƒ 1ë¡œ ì„¤ì •í•˜ì—¬ ë²„í¼ë§ì„ ë¹„í™œì„±í™”\n- `PYTHONIOENCODING`: `utf-8`ë¡œ ì„¤ì •í•˜ì—¬ í•œê¸€ ë“± ìœ ë‹ˆì½”ë“œ ë¬¸ìë¥¼ ì˜¬ë°”ë¥´ê²Œ ì²˜ë¦¬\n\n## ë¬¸ì œ í•´ê²°\n\n1. ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°:\n\n   - `--data_path` ì˜µì…˜ìœ¼ë¡œ ì •í™•í•œ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”.\n   - ìŠ¤í¬ë¦½íŠ¸ê°€ ìë™ìœ¼ë¡œ ì—¬ëŸ¬ ë””ë ‰í† ë¦¬ë¥¼ ê²€ìƒ‰í•˜ì§€ë§Œ, ì§ì ‘ ì§€ì •í•˜ëŠ” ê²ƒì´ ë” í™•ì‹¤í•©ë‹ˆë‹¤.\n\n2. í´ë¡œë“œ ë°ìŠ¤í¬íƒ‘ì— ì—°ê²°ë˜ì§€ ì•ŠëŠ” ê²½ìš°:\n\n   - ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”: `tail -n 20 -F ~/Library/Logs/Claude/mcp*.log`\n   - `claude_desktop_config.json` íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n\n3. ìŠ¤ë¯¸ë”ë¦¬ì— ì—°ê²°ë˜ì§€ ì•ŠëŠ” ê²½ìš°:\n   - ìŠ¤ë¯¸ë”ë¦¬ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n   - `smithery.yaml` íŒŒì¼ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n\n## ë¼ì´ì„ ìŠ¤\n\nì´ í”„ë¡œì íŠ¸ëŠ” ììœ ë¡­ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n@mcp.route(\"resources/list\")\ndef handle_resources_list():\nreturn {\"resources\": []}\n\n@mcp.route(\"prompts/list\")\ndef handle_prompts_list():\nreturn {\"prompts\": []}\n\n@mcp.route(\"debug/status\")\ndef debug_status():\nreturn {\n\"loaded_data\": len(stylebook_data),\n\"server_uptime\": \"...\",\n\"memory_usage\": \"...\"\n}\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "54yyyu--school-mcp": {
      "owner": "54yyyu",
      "name": "school-mcp",
      "url": "https://github.com/54yyyu/school-mcp",
      "imageUrl": "https://github.com/54yyyu.png",
      "description": "School MCP is a server designed to help students manage their academic tasks more efficiently. It connects to platforms like Canvas and Gradescope to fetch assignment deadlines, download course materials, and integrate with your calendar for reminders.",
      "stars": 4,
      "forks": 2,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-04-26T09:54:01Z",
      "readme_content": "# School MCP\n\n[![smithery badge](https://smithery.ai/badge/@54yyyu/school-mcp)](https://smithery.ai/server/@54yyyu/school-mcp)\n\nA Model Context Protocol (MCP) server for academic tools, integrating with Canvas and Gradescope platforms.\n\n## Features\n\n- **Assignment Deadlines**: Fetch and display upcoming deadlines from Canvas and Gradescope\n- **Calendar Integration**: Add deadlines to macOS Calendar or Reminders using AppleScript\n- **File Management**: Download course materials from Canvas\n\n## Quickstart\n\n### Installation\n\n#### Installing via Smithery\n\nTo install School MCP for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@54yyyu/school-mcp):\n\n```bash\nnpx -y @smithery/cli install @54yyyu/school-mcp --client claude\n```\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/yourusername/school-mcp.git\ncd school-mcp\n```\n\n2. Install the package:\n```bash\npip install -e .\n```\n\n3. Set up your environment variables by either:\n   - Using the included setup helper (recommended)\n   - Creating a `.env` file manually\n\n### Using the Setup Helper\n\nRun the setup helper to configure Claude Desktop automatically:\n\n```bash\npython setup_helper.py\n```\n\nThe setup helper will:\n- Find your Claude Desktop configuration file\n- Create a `.env` file if needed\n- Configure the MCP server with proper paths\n- Add your environment variables to the Claude Desktop configuration\n\n### Manual Setup\n\nIf you prefer to set up manually:\n\n1. Copy the environment template:\n```bash\ncp .env.template .env\n# Edit .env with your credentials\n```\n\n2. Configure Claude Desktop by following the [Claude Desktop Integration Guide](docs/claude_desktop.md).\n\n### Running the server\n\nRun directly:\n```bash\npython -m school_mcp\n```\n\nOr use the convenience script:\n```bash\n./run_server.py\n```\n\n## Tools\n\n- `get_deadlines`: Fetch upcoming assignment deadlines from Canvas and Gradescope\n- `add_to_reminders`: Add assignments to macOS Reminders\n- `list_courses`: List all available Canvas courses\n- `download_course_files`: Download files from a Canvas course\n- `set_download_path`: Configure where downloaded files are saved\n- `get_download_path_info`: Check the current download location\n\n## Configuration\n\nThe server tries to find configuration in this order:\n1. Environment variables\n2. `.env` file in the current directory\n3. Existing `config.json` file in the home directory\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "54yyyu--zotero-mcp": {
      "owner": "54yyyu",
      "name": "zotero-mcp",
      "url": "https://github.com/54yyyu/zotero-mcp",
      "imageUrl": "https://github.com/54yyyu.png",
      "description": "Zotero MCP allows you to link your Zotero research library with AI assistants, enabling you to discuss academic papers, receive summaries, and analyze citations for better research productivity.",
      "stars": 564,
      "forks": 42,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-04T09:19:49Z",
      "readme_content": "# Zotero MCP: Chat with your Research Libraryâ€”Local or Webâ€”in Claude, ChatGPT, and more.\n\n<p align=\"center\">\n  <a href=\"https://www.zotero.org/\">\n    <img src=\"https://img.shields.io/badge/Zotero-CC2936?style=for-the-badge&logo=zotero&logoColor=white\" alt=\"Zotero\">\n  </a>\n  <a href=\"https://www.anthropic.com/claude\">\n    <img src=\"https://img.shields.io/badge/Claude-6849C3?style=for-the-badge&logo=anthropic&logoColor=white\" alt=\"Claude\">\n  </a>\n  <a href=\"https://chatgpt.com/\">\n    <img src=\"https://img.shields.io/badge/ChatGPT-74AA9C?style=for-the-badge&logo=openai&logoColor=white\" alt=\"ChatGPT\">\n  </a>\n  <a href=\"https://modelcontextprotocol.io/introduction\">\n    <img src=\"https://img.shields.io/badge/MCP-0175C2?style=for-the-badge&logoColor=white\" alt=\"MCP\">\n  </a>\n</p>\n\n**Zotero MCP** seamlessly connects your [Zotero](https://www.zotero.org/) research library with [ChatGPT](https://openai.com), [Claude](https://www.anthropic.com/claude), and other AI assistants (e.g., [Cherry Studio](https://cherry-ai.com/), [Chorus](https://chorus.sh), [Cursor](https://www.cursor.com/)) via the [Model Context Protocol](https://modelcontextprotocol.io/introduction). Review papers, get summaries, analyze citations, extract PDF annotations, and more!\n\n## âœ¨ Features\n\n### ğŸ§  AI-Powered Semantic Search\n- **Vector-based similarity search** over your entire research library\n- **Multiple embedding models**: Default (free), OpenAI, and Gemini options\n- **Intelligent results** with similarity scores and contextual matching\n- **Auto-updating database** with configurable sync schedules\n\n### ğŸ” Search Your Library\n- Find papers, articles, and books by title, author, or content\n- Perform complex searches with multiple criteria\n- Browse collections, tags, and recent additions\n- **NEW**: Semantic search for conceptual and topic-based discovery\n\n### ğŸ“š Access Your Content\n- Retrieve detailed metadata for any item\n- Get full text content (when available)\n- Access attachments, notes, and child items\n\n### ğŸ“ Work with Annotations\n- Extract and search PDF annotations directly\n- Access Zotero's native annotations\n- Create and update notes and annotations\n\n### ğŸ”„ Easy Updates\n- **Smart update system** that detects your installation method (uv, pip, conda, pipx)\n- **Configuration preservation** - all settings maintained during updates\n- **Version checking** and automatic update notifications\n\n### ğŸŒ Flexible Access Methods\n- Local method for offline access (no API key needed)\n- Web API for cloud library access\n- Perfect for both local research and remote collaboration\n\n## ğŸš€ Quick Install\n\n### Default Installation\n\n#### Installing via uv\n\n```bash\nuv tool install \"git+https://github.com/54yyyu/zotero-mcp.git\"\nzotero-mcp setup  # Auto-configure (Claude Desktop supported)\n```\n\n#### Installing via pip\n\n```bash\npip install git+https://github.com/54yyyu/zotero-mcp.git\nzotero-mcp setup  # Auto-configure (Claude Desktop supported)\n```\n\n### Installing via Smithery\n\nTo install Zotero MCP via [Smithery](https://smithery.ai/server/@54yyyu/zotero-mcp) for Claude Desktop:\n\n```bash\nnpx -y @smithery/cli install @54yyyu/zotero-mcp --client claude\n```\n\n#### Updating Your Installation\n\nKeep zotero-mcp up to date with the smart update command:\n\n```bash\n# Check for updates\nzotero-mcp update --check-only\n\n# Update to latest version (preserves all configurations)\nzotero-mcp update\n```\n\n## ğŸ§  Semantic Search\n\nZotero MCP now includes powerful AI-powered semantic search capabilities that let you find research based on concepts and meaning, not just keywords.\n\n### Setup Semantic Search\n\nDuring setup or separately, configure semantic search:\n\n```bash\n# Configure during initial setup (recommended)\nzotero-mcp setup\n\n# Or configure semantic search separately\nzotero-mcp setup --semantic-config-only\n```\n\n**Available Embedding Models:**\n- **Default (all-MiniLM-L6-v2)**: Free, runs locally, good for most use cases\n- **OpenAI**: Better quality, requires API key (`text-embedding-3-small` or `text-embedding-3-large`)\n- **Gemini**: Better quality, requires API key (`models/text-embedding-004` or experimental models)\n\n**Update Frequency Options:**\n- **Manual**: Update only when you run `zotero-mcp update-db`\n- **Auto on startup**: Update database every time the server starts\n- **Daily**: Update once per day automatically\n- **Every N days**: Set custom interval\n\n### Using Semantic Search\n\nAfter setup, initialize your search database:\n\n```bash\n# Build the semantic search database (fast, metadata-only)\nzotero-mcp update-db\n\n# Build with full-text extraction (slower, more comprehensive)\nzotero-mcp update-db --fulltext\n\n# Check database status\nzotero-mcp db-status\n```\n\n**Example Semantic Queries in your AI assistant:**\n- *\"Find research similar to machine learning concepts in neuroscience\"*\n- *\"Papers that discuss climate change impacts on agriculture\"*\n- *\"Research related to quantum computing applications\"*\n- *\"Studies about social media influence on mental health\"*\n- *\"Find papers conceptually similar to this abstract: [paste abstract]\"*\n\nThe semantic search provides similarity scores and finds papers based on conceptual understanding, not just keyword matching.\n\n## ğŸ–¥ï¸ Setup & Usage\n\nFull documentation is available at [Zotero MCP docs](https://stevenyuyy.us/zotero-mcp/).\n\n**Requirements**\n- Python 3.10+\n- Zotero 7+ (for local API with full-text access)\n- An MCP-compatible client (e.g., Claude Desktop, ChatGPT Developer Mode, Cherry Studio, Chorus)\n\n**For ChatGPT setup: see the [Getting Started guide](./docs/getting-started.md).**\n\n### For Claude Desktop (example MCP client)\n\n#### Configuration\nAfter installation, either:\n\n1. **Auto-configure** (recommended):\n   ```bash\n   zotero-mcp setup\n   ```\n\n2. **Manual configuration**:\n   Add to your `claude_desktop_config.json`:\n   ```json\n   {\n     \"mcpServers\": {\n       \"zotero\": {\n         \"command\": \"zotero-mcp\",\n         \"env\": {\n           \"ZOTERO_LOCAL\": \"true\"\n         }\n       }\n     }\n   }\n   ```\n\n#### Usage\n\n1. Start Zotero desktop (make sure local API is enabled in preferences)\n2. Launch Claude Desktop\n3. Access the Zotero-MCP tool through Claude Desktop's tools interface\n\nExample prompts:\n- \"Search my library for papers on machine learning\"\n- \"Find recent articles I've added about climate change\"\n- \"Summarize the key findings from my paper on quantum computing\"\n- \"Extract all PDF annotations from my paper on neural networks\"\n- \"Search my notes and annotations for mentions of 'reinforcement learning'\"\n- \"Show me papers tagged '#Arm' excluding those with '#Crypt' in my library\"\n- \"Search for papers on operating system with tag '#Arm'\"\n- \"Export the BibTeX citation for papers on machine learning\"\n- **\"Find papers conceptually similar to deep learning in computer vision\"** *(semantic search)*\n- **\"Research that relates to the intersection of AI and healthcare\"** *(semantic search)*\n- **\"Papers that discuss topics similar to this abstract: [paste text]\"** *(semantic search)*\n\n### For Cherry Studio\n\n#### Configuration\nGo to Settings -> MCP Servers -> Edit MCP Configuration, and add the following:\n\n```json\n{\n  \"mcpServers\": {\n    \"zotero\": {\n      \"name\": \"zotero\",\n      \"type\": \"stdio\",\n      \"isActive\": true,\n      \"command\": \"zotero-mcp\",\n      \"args\": [],\n      \"env\": {\n        \"ZOTERO_LOCAL\": \"true\"\n      }\n    }\n  }\n}\n```\nThen click \"Save\".\n\nCherry Studio also provides a visual configuration method for general settings and tools selection.\n\n## ğŸ”§ Advanced Configuration\n\n### Using Web API Instead of Local API\n\nFor accessing your Zotero library via the web API (useful for remote setups):\n\n```bash\nzotero-mcp setup --no-local --api-key YOUR_API_KEY --library-id YOUR_LIBRARY_ID\n```\n\n### Environment Variables\n\n**Zotero Connection:**\n- `ZOTERO_LOCAL=true`: Use the local Zotero API (default: false)\n- `ZOTERO_API_KEY`: Your Zotero API key (for web API)\n- `ZOTERO_LIBRARY_ID`: Your Zotero library ID (for web API)\n- `ZOTERO_LIBRARY_TYPE`: The type of library (user or group, default: user)\n\n**Semantic Search:**\n- `ZOTERO_EMBEDDING_MODEL`: Embedding model to use (default, openai, gemini)\n- `OPENAI_API_KEY`: Your OpenAI API key (for OpenAI embeddings)\n- `OPENAI_EMBEDDING_MODEL`: OpenAI model name (text-embedding-3-small, text-embedding-3-large)\n- `GEMINI_API_KEY`: Your Gemini API key (for Gemini embeddings)\n- `GEMINI_EMBEDDING_MODEL`: Gemini model name (models/text-embedding-004, etc.)\n\n### Command-Line Options\n\n```bash\n# Run the server directly\nzotero-mcp serve\n\n# Specify transport method\nzotero-mcp serve --transport stdio|streamable-http|sse\n\n# Setup and configuration\nzotero-mcp setup --help                    # Get help on setup options\nzotero-mcp setup --semantic-config-only    # Configure only semantic search\nzotero-mcp setup-info                      # Show installation path and config info for MCP clients\n\n# Updates and maintenance\nzotero-mcp update                          # Update to latest version\nzotero-mcp update --check-only             # Check for updates without installing\nzotero-mcp update --force                  # Force update even if up to date\n\n# Semantic search database management\nzotero-mcp update-db                       # Update semantic search database (fast, metadata-only)\nzotero-mcp update-db --fulltext             # Update with full-text extraction (comprehensive but slower)\nzotero-mcp update-db --force-rebuild       # Force complete database rebuild\nzotero-mcp update-db --fulltext --force-rebuild  # Rebuild with full-text extraction\nzotero-mcp db-status                       # Show database status and info\n\n# General\nzotero-mcp version                         # Show current version\n```\n\n## ğŸ“‘ PDF Annotation Extraction\n\nZotero MCP includes advanced PDF annotation extraction capabilities:\n\n- **Direct PDF Processing**: Extract annotations directly from PDF files, even if they're not yet indexed by Zotero\n- **Enhanced Search**: Search through PDF annotations and comments \n- **Image Annotation Support**: Extract image annotations from PDFs\n- **Seamless Integration**: Works alongside Zotero's native annotation system\n\nFor optimal annotation extraction, it is **highly recommended** to install the [Better BibTeX plugin](https://retorque.re/zotero-better-bibtex/installation/) for Zotero. The annotation-related functions have been primarily tested with this plugin and provide enhanced functionality when it's available.\n\n\nThe first time you use PDF annotation features, the necessary tools will be automatically downloaded.\n\n## ğŸ“š Available Tools\n\n### ğŸ§  Semantic Search Tools\n- `zotero_semantic_search`: AI-powered similarity search with embedding models\n- `zotero_update_search_database`: Manually update the semantic search database\n- `zotero_get_search_database_status`: Check database status and configuration\n\n### ğŸ” Search Tools\n- `zotero_search_items`: Search your library by keywords\n- `zotero_advanced_search`: Perform complex searches with multiple criteria\n- `zotero_get_collections`: List collections\n- `zotero_get_collection_items`: Get items in a collection\n- `zotero_get_tags`: List all tags\n- `zotero_get_recent`: Get recently added items\n- `zotero_search_by_tag`: Search your library using custom tag filters\n\n### ğŸ“š Content Tools\n- `zotero_get_item_metadata`: Get detailed metadata (supports BibTeX export via `format=\"bibtex\"`)\n- `zotero_get_item_fulltext`: Get full text content\n- `zotero_get_item_children`: Get attachments and notes\n\n### ğŸ“ Annotation & Notes Tools\n- `zotero_get_annotations`: Get annotations (including direct PDF extraction)\n- `zotero_get_notes`: Retrieve notes from your Zotero library\n- `zotero_search_notes`: Search in notes and annotations (including PDF-extracted)\n- `zotero_create_note`: Create a new note for an item (beta feature)\n\n## ğŸ” Troubleshooting\n\n### General Issues\n- **No results found**: Ensure Zotero is running and the local API is enabled. You need to toggle on `Allow other applications on this computer to communicate with Zotero` in Zotero preferences.\n- **Can't connect to library**: Check your API key and library ID if using web API\n- **Full text not available**: Make sure you're using Zotero 7+ for local full-text access\n- **Local library limitations**: Some functionality (tagging, library modifications) may not work with local JS API. Consider using web library setup for full functionality. (See the [docs](docs/getting-started.md#local-library-limitations) for more info.)\n- **Installation/search option switching issues**: Database problems from changing install methods or search options can often be resolved with `zotero-mcp update-db --force-rebuild`\n\n### Semantic Search Issues\n- **\"Missing required environment variables\" when running update-db**: Run `zotero-mcp setup` to configure your environment, or the CLI will automatically load settings from your MCP client config (e.g., Claude Desktop)\n- **ChromaDB warnings**: Update to the latest version - deprecation warnings have been fixed\n- **Database update takes long**: By default, `update-db` is fast (metadata-only). For comprehensive indexing with full-text, use `--fulltext` flag. Use `--limit` parameter for testing: `zotero-mcp update-db --limit 100`\n- **Semantic search returns no results**: Ensure the database is initialized with `zotero-mcp update-db` and check status with `zotero-mcp db-status`\n- **Limited search quality**: For better semantic search results, use `zotero-mcp update-db --fulltext` to index full-text content (requires local Zotero setup)\n- **OpenAI/Gemini API errors**: Verify your API keys are correctly set and have sufficient credits/quota\n\n### Update Issues  \n- **Update command fails**: Check your internet connection and try `zotero-mcp update --force`\n- **Configuration lost after update**: The update process preserves configs automatically, but check `~/.config/zotero-mcp/` for backup files\n\n## ğŸ“„ License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "ahnopologetic--canvas-lms-mcp": {
      "owner": "ahnopologetic",
      "name": "canvas-lms-mcp",
      "url": "https://github.com/ahnopologetic/canvas-lms-mcp",
      "imageUrl": "https://github.com/ahnopologetic.png",
      "description": "Access and manage educational data from Canvas LMS, including courses, assignments, quizzes, and files. Query and retrieve planner items and course modules programmatically.",
      "stars": 6,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-26T21:36:18Z",
      "readme_content": "# Canvas LMS MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@ahnopologetic/canvas-lms-mcp)](https://smithery.ai/server/@ahnopologetic/canvas-lms-mcp)\nA minimal Canvas LMS MCP (Machine Conversation Protocol) server for easy access to education data through your Canvas LMS instance. This server provides a bridge between AI systems (like Cursor) and Canvas Learning Management System.\n\n## Features\n\n- List planner items (assignments, quizzes, etc.)\n- Get and list assignments\n- Get and list quizzes\n- Get and list courses\n- Get course syllabus\n- Get course modules\n- List files\n\n## Installation\n\n### Installing via Smithery\n\nTo install Canvas LMS Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@ahnopologetic/canvas-lms-mcp):\n\n```bash\nnpx -y @smithery/cli install @ahnopologetic/canvas-lms-mcp --client claude\n```\n\n### Prerequisites\n\n- Python 3.13+\n- Canvas LMS API token\n- `uv` package manager (recommended)\n\n### Installation Methods\n\n#### Option 1: Install with uvx (Recommended)\n\nThe easiest way to install and run canvas-lms-mcp is using uvx:\n\n```bash\nuvx canvas-lms-mcp\n```\n\nThis will run the server in an isolated environment without installing it permanently.\n\nTo install the tool permanently:\n\n```bash\nuv tool install canvas-lms-mcp\n```\n\n#### Option 2: Install from Source\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/yourusername/canvas-lms-mcp.git\n   cd canvas-lms-mcp\n   ```\n\n2. Install with uv:\n   ```bash\n   # Install uv if you don't have it yet\n   curl -LsSf https://astral.sh/uv/install.sh | sh\n\n   # Create a virtual environment and install dependencies\n   uv venv\n   uv pip install -e .\n   ```\n\n   Alternatively, use traditional methods:\n   ```bash\n   python -m venv .venv\n   source .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n   pip install -e .\n   ```\n\n## Configuration\n\nSet the following environment variables:\n\n```bash\nexport CANVAS_API_TOKEN=\"your_canvas_api_token\"\nexport CANVAS_BASE_URL=\"https://your-institution.instructure.com\"  # Default: https://canvas.instructure.com\n```\n\nYou can get your Canvas API token from your Canvas account settings.\n\n## Running the Server\n\nStart the server with uv:\n\n```bash\nuv run src/canvas_lms_mcp/main.py\n```\n\nIf installed with uvx tool:\n```bash\ncanvas-lms-mcp\n```\n\nBy default, the server runs on http://localhost:8000. You can use the FastMCP interface at http://localhost:8000/docs to interact with the API.\n\n## Available Tools\n\nThe server provides the following tools for interacting with Canvas LMS:\n\n### Courses\n\n#### `list_courses`\nList courses that the user is actively enrolled in.\n\nParameters:\n- `page` (optional, default=1): Page number (1-indexed)\n- `items_per_page` (optional, default=10): Number of items per page\n\n#### `get_course`\nGet a single course by ID.\n\nParameters:\n- `course_id` (required): Course ID\n- `include` (optional): List of additional data to include\n\n#### `get_course_syllabus`\nGet a course's syllabus.\n\nParameters:\n- `course_id` (required): Course ID\n\n#### `get_course_modules`\nGet modules for a course.\n\nParameters:\n- `course_id` (required): Course ID\n- `include` (optional): List of additional data to include\n\n### Assignments\n\n#### `list_assignments`\nList assignments for a course.\n\nParameters:\n- `course_id` (required): Course ID\n- `bucket` (required): Filter assignments by (\"past\", \"overdue\", \"undated\", \"ungraded\", \"unsubmitted\", \"upcoming\", \"future\")\n- `order_by` (required): Field to order assignments by (\"due_at\", \"position\", \"name\")\n- `page` (optional, default=1): Page number (1-indexed)\n- `items_per_page` (optional, default=10): Number of items per page\n\n#### `get_assignment`\nGet a single assignment by ID.\n\nParameters:\n- `course_id` (required): Course ID\n- `assignment_id` (required): Assignment ID\n\n### Quizzes\n\n#### `list_quizzes`\nList quizzes for a course.\n\nParameters:\n- `course_id` (required): Course ID\n- `include` (optional): List of additional data to include\n- `page` (optional, default=1): Page number (1-indexed)\n- `items_per_page` (optional, default=10): Number of items per page\n\n#### `get_quiz`\nGet a single quiz by ID.\n\nParameters:\n- `course_id` (required): Course ID\n- `quiz_id` (required): Quiz ID\n\n### Files\n\n#### `list_files`\nList files for a course or folder.\n\nParameters:\n- `course_id` (optional): Course ID\n- `folder_id` (optional): Folder ID\n- `include` (optional): List of additional data to include\n- `page` (optional, default=1): Page number (1-indexed)\n- `items_per_page` (optional, default=10): Number of items per page\n\n### Planner Items\n\n#### `list_planner_items`\nList planner items for the authenticated user.\n\nParameters:\n- `start_date` (required): Start date in ISO 8601 format\n- `end_date` (required): End date in ISO 8601 format\n- `context_codes` (optional): List of context codes (e.g., [\"course_123\"])\n- `page` (optional, default=1): Page number (1-indexed)\n- `items_per_page` (optional, default=10): Number of items per page\n\n## Integration with Cursor\n\nCursor is an AI-powered IDE that can interact with the Canvas LMS MCP server to provide education data directly within your development environment.\n\n### Setting Up Cursor Integration\n\n1. Install the Cursor IDE from [https://cursor.sh/](https://cursor.sh/)\n\n2. Create a `.cursor/mcp.json` file in your project directory with the following content:\n   ```json\n   {\n       \"mcpServers\": {\n           \"canvas\": {\n               \"command\": \"uvx\",\n               \"args\": [\n                    \"canvas-lms-mcp\"\n               ],\n               \"env\": {\n                   \"CANVAS_API_TOKEN\": \"your_canvas_api_token\",\n                   \"CANVAS_BASE_URL\": \"https://your-institution.instructure.com\"\n               }\n           }\n       }\n   }\n   ```\n\n   Replace:\n   - `your_canvas_api_token` with your actual Canvas API token\n   - `your-institution.instructure.com` with your Canvas institution URL\n\n3. Restart Cursor for the changes to take effect.\n\n### Cursor Time Integration (Optional)\n\nYou can also integrate a time server for timezone-related queries by adding a \"time\" server to your mcp.json:\n\n```json\n\"time\": {\n    \"command\": \"uvx\",\n    \"args\": [\n        \"mcp-server-time\",\n        \"--local-timezone=America/New_York\"\n    ]\n}\n```\n\nThis allows you to use time-related functions with your Canvas data.\n\n### Usage Examples\n\nOnce connected, you can ask Cursor AI about your Canvas data:\n\n- \"What assignments do I have due next week?\"\n- \"Show me the syllabus for my Biology course\"\n- \"List all my upcoming quizzes\"\n- \"What's on my schedule for tomorrow?\"\n\nExample conversation:\n\n```\nYOU: What assignments do I have due soon?\n\nCURSOR: I'll check your upcoming assignments.\n\nBased on your Canvas data, here are your upcoming assignments:\n- \"Final Project\" for CS101 due on December 10, 2023\n- \"Lab Report #5\" for BIOL200 due on December 7, 2023\n- \"Research Paper\" for ENGL301 due on December 15, 2023\n```\n\n## Development\n\nFor detailed development instructions, please see the [DEVELOPMENT.md](DEVELOPMENT.md) file.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "aindreyway--mcp-codex-keeper": {
      "owner": "aindreyway",
      "name": "mcp-codex-keeper",
      "url": "https://github.com/aindreyway/mcp-codex-keeper",
      "imageUrl": "https://github.com/aindreyway.png",
      "description": "Curated access to the latest development documentation and best practices for AI assistants, facilitating knowledge retrieval and application of current industry standards.",
      "stars": 75,
      "forks": 25,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T22:32:03Z",
      "readme_content": "# Aindreyway MCP Codex Keeper\n\n![MCP Server](https://img.shields.io/badge/MCP-Server-blue)\n![Version](https://img.shields.io/badge/version-1.1.10-green)\n![License](https://img.shields.io/badge/license-MIT-blue)\n\nAn intelligent MCP server that serves as a guardian of development knowledge, providing AI assistants with curated access to latest documentation and best practices.\n\n<a href=\"https://glama.ai/mcp/servers/bo39uifs3k\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/bo39uifs3k/badge\" alt=\"mcp-codex-keeper MCP server\" /></a>\n\n## ğŸš€ Quick Start\n\n### Prerequisites\n\n1. Make sure you have Node.js installed (version 18 or higher):\n\n   ```bash\n   node --version\n   ```\n\n2. Install or update npm (comes with Node.js):\n\n   ```bash\n   npm install -g npm@latest\n   ```\n\n3. Verify npx is available:\n   ```bash\n   npx --version\n   ```\n   If not found, install it:\n   ```bash\n   npm install -g npx\n   ```\n\n### Configuration\n\nAdd this to your Cline/Sonnet configuration:\n\n```json\n\"aindreyway-codex-keeper\": {\n  \"command\": \"npx\",\n  \"args\": [\"-y\", \"@aindreyway/mcp-codex-keeper@latest\"],\n  \"disabled\": false,\n  \"env\": {\n    \"npm_config_cache_max\": \"1024000000\",\n    \"NODE_OPTIONS\": \"--max-old-space-size=256\"\n  }\n}\n```\n\nThat's it! The assistant will handle everything automatically.\n\n> **Note:** This server uses `npx` for direct npm package execution, which is optimal for Node.js/TypeScript MCP servers, providing seamless integration with the npm ecosystem and TypeScript tooling.\n\n## ğŸ¯ What Your Assistant Can Do\n\nAsk your assistant to:\n\n- \"Show me the latest React documentation\"\n- \"Find best practices for TypeScript development\"\n- \"Update documentation for Node.js\"\n- \"Search for information about async/await\"\n\n## ğŸ›  Available Tools\n\n### list_documentation\n\nLists all available documentation sources with optional category filtering.\n\n### add_documentation\n\nAdd new documentation sources to the knowledge base.\n\n### update_documentation\n\nUpdate existing documentation to get the latest content.\n\n### search_documentation\n\nSearch through documentation with category filtering.\n\n## ğŸ“š Documentation Categories\n\n- Frontend\n- Backend\n- Language\n- MCP\n- MCP-Guide\n- Database\n- DevOps\n- Security\n- Testing\n- Architecture\n- Mobile\n- AI\n- Cloud\n\n## ğŸ”§ Features\n\nThe server automatically:\n\n- Manages documentation from various sources\n- Keeps track of latest development best practices\n- Provides intelligent search capabilities\n- Updates documentation automatically\n- Supports tagging and categorization\n- Optimizes memory usage:\n  - Uses streaming for large files\n  - Automatic cache cleanup\n  - Memory-efficient search\n  - Size and age limits for cached files\n  - Limited heap size (256MB)\n\n## ğŸ“ License\n\nMIT License - feel free to use this in your projects!\n\n## ğŸ‘¤ Author\n\n**aindreyway**\n\n- GitHub: [@aindreyway](https://github.com/aindreyway)\n\n## ğŸ“– Documentation\n\n- [User Guide](README.md) - Installation and usage instructions\n- [Contributing Guide](CONTRIBUTING.md) - How to contribute to the project\n- [Technical Documentation](PROJECT_SUMMARY.md) - Detailed technical information\n\n## â­ï¸ Support\n\nGive a â­ï¸ if this project helped you! If you want to contribute, please check our [Contributing Guide](CONTRIBUTING.md).\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "ajay-sai--Machine-Learning-Interviews": {
      "owner": "ajay-sai",
      "name": "Machine-Learning-Interviews",
      "url": "https://github.com/ajay-sai/Machine-Learning-Interviews",
      "imageUrl": "https://github.com/ajay-sai.png",
      "description": "Prepare for Machine Learning Engineering interviews by accessing insights from personal experiences and structured modules. Offers resources for coding, system design, and behavioral interview preparation targeted at success in ML roles.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-02-19T13:08:11Z",
      "readme_content": "<!-- [![Tweet](https://img.shields.io/twitter/url/http/shields.io.svg?style=social)](https://twitter.com/intent/tweet?text=Machine%20Learning%20Interview%20Guide&url=https://github.com/alirezadir/machine-learning-interview-enlightener&via=alirezadira&hashtags=artificialintelligence,machinelearning,interviews,design)\n[![Twitter URL](https://img.shields.io/twitter/url/https/twitter.com/fold_left.svg?style=social&label=Follow%20%40alirezadira)](https://twitter.com/alirezadira)\n\n[![Build Status](https://travis-ci.com/username/projectname.svg?branch=master)](https://travis-ci.com/username/projectname)\n[![codecov](https://codecov.io/gh/cam-barts/ObeyTheTestingGoat/branch/master/graph/badge.svg)](https://codecov.io/gh/cam-barts/ObeyTheTestingGoat)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/ambv/black)\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://github.com/alirezadir/machine-learning-interview-enlightener/blob/main/LICENSE) -->\n\n# Machine Learning Technical Interviews :robot: \n<p align=\"center\">\n<img width=\"720\" src=\"src/imgs/MLI-Book-Cover.png\">\n</p>\n\n\n\nThis repo aims to serve as a guide to prepare for **Machine Learning (AI) Engineering** interviews for relevant roles at big tech companies (in particular FAANG). It has compiled based on the author's personal experience and notes from his own interview preparation, when he received offers from Meta (ML Specialist), Google (ML Engineer), Amazon (Applied Scientist), Apple (Applied Scientist), and Roku (ML Engineer).\n\nThe following components are the most commonly used interview modules for technical ML roles at different companies. We will go through them one by one and share how one can prepare:\n\n\n<center>\n\n |Chapter | Content|\n |---| --- |\n | Chapter 1 \t|  [General Coding (Algos and Data Structures)](src/lc-coding.md)\t   | \n| Chapter 2 \t| [ML Coding](src/MLC/ml-coding.md) \t|  \t\n| Chapter 3 \t| [ML System Design (Updated in 2023)](src/MLSD/ml-system-design.md)|\n| Chapter 4 \t| [ML Fundamentals/Breadth](src/ml-fundamental.md)| \n| Chapter 5 \t| [Behavioral](src/behavior.md)| \n|  \t|  \t|  \n\n</center>\n\nNotes:\n\n* At the time I'm putting these notes together, machine learning interviews at different companies do not follow a unique structure unlike software engineering interviews. However, I found some of the components very similar to each other, although under different naming.\n\n* The guide here is mostly focused on *Machine Learning Engineer* (and Applied Scientist) roles at big companies. Although relevant roles such as \"Data Science\" or \"ML research scientist\" have different structures in interviews, some of the modules reviewed here can be still useful. For more understanding about different technical roles within ML umbrella you can refer to [Link]\n\n* As a supplementary resource, you can also refer to my [Production Level Deep Learning](https://github.com/alirezadir/Production-Level-Deep-Learning) repo for further insights on how to design deep learning systems for production. \n\n\n\n# Contribution\n* Feedback and contribution are very welcome :blush: \n**If you'd like to contribute**, please make a pull request with your suggested changes). \n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "aldrin-labs--metal-mcp-server": {
      "owner": "aldrin-labs",
      "name": "metal-mcp-server",
      "url": "https://github.com/aldrin-labs/metal-mcp-server",
      "imageUrl": "https://github.com/aldrin-labs.png",
      "description": "Search Metal Framework documentation and generate Metal code for common tasks using natural language queries. Supports querying documentation and generating code in Objective-C, Swift, or Metal based on task descriptions.",
      "stars": 2,
      "forks": 7,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-01-27T13:01:47Z",
      "readme_content": "# Metal MCP Server\n\nAn MCP server providing Metal Framework documentation search and code generation capabilities.\n\n## One-Line Installation\n\n```bash\nnpx @modelcontextprotocol/create-server metal-mcp && cd metal-mcp && npm install && npm run build\n```\n\n## Features\n\n### Tools\n\n1. `search_metal_docs`\n   - Search Metal Framework documentation and code examples using natural language queries\n   - Parameters:\n     - `query`: Natural language query about Metal Framework\n     - `limit`: Maximum number of results to return (default: 3)\n\n2. `generate_metal_code`\n   - Generate Metal Framework code for common tasks\n   - Parameters:\n     - `task`: Description of the Metal task to generate code for\n     - `language`: Programming language (objective-c, swift, or metal)\n\n### Resources\n\n1. `metal://docs/getting-started`\n   - Comprehensive guide for getting started with Metal Framework\n\n2. `metal://docs/best-practices`\n   - Best practices and optimization tips for Metal Framework\n\n## Usage\n\nAfter installation, add the server to your MCP configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"metal\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/metal-mcp/build/index.js\"]\n    }\n  }\n}\n```\n\nThe server will provide Metal Framework expertise through the MCP protocol, allowing you to:\n- Search Metal documentation with natural language queries\n- Generate code snippets for common Metal tasks\n- Access Metal best practices and getting started guides\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "arben-adm--mcp-sequential-thinking": {
      "owner": "arben-adm",
      "name": "mcp-sequential-thinking",
      "url": "https://github.com/arben-adm/mcp-sequential-thinking",
      "imageUrl": "https://github.com/arben-adm.png",
      "description": "Facilitates structured thinking by breaking down complex problems into sequential steps, allowing users to track their thought progression and generate summaries of their reasoning.",
      "stars": 730,
      "forks": 88,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T12:20:29Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/arben-adm-mcp-sequential-thinking-badge.png)](https://mseep.ai/app/arben-adm-mcp-sequential-thinking)\n\n# Sequential Thinking MCP Server\n\nA Model Context Protocol (MCP) server that facilitates structured, progressive thinking through defined stages. This tool helps break down complex problems into sequential thoughts, track the progression of your thinking process, and generate summaries.\n\n[![Python Version](https://img.shields.io/badge/python-3.10%2B-blue)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code Style: Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n\n<a href=\"https://glama.ai/mcp/servers/m83dfy8feg\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/m83dfy8feg/badge\" alt=\"Sequential Thinking Server MCP server\" /></a>\n\n## Features\n\n- **Structured Thinking Framework**: Organizes thoughts through standard cognitive stages (Problem Definition, Research, Analysis, Synthesis, Conclusion)\n- **Thought Tracking**: Records and manages sequential thoughts with metadata\n- **Related Thought Analysis**: Identifies connections between similar thoughts\n- **Progress Monitoring**: Tracks your position in the overall thinking sequence\n- **Summary Generation**: Creates concise overviews of the entire thought process\n- **Persistent Storage**: Automatically saves your thinking sessions with thread-safety\n- **Data Import/Export**: Share and reuse thinking sessions\n- **Extensible Architecture**: Easily customize and extend functionality\n- **Robust Error Handling**: Graceful handling of edge cases and corrupted data\n- **Type Safety**: Comprehensive type annotations and validation\n\n## Prerequisites\n\n- Python 3.10 or higher\n- UV package manager ([Install Guide](https://github.com/astral-sh/uv))\n\n## Key Technologies\n\n- **Pydantic**: For data validation and serialization\n- **Portalocker**: For thread-safe file access\n- **FastMCP**: For Model Context Protocol integration\n- **Rich**: For enhanced console output\n- **PyYAML**: For configuration management\n\n## Project Structure\n\n```\nmcp-sequential-thinking/\nâ”œâ”€â”€ mcp_sequential_thinking/\nâ”‚   â”œâ”€â”€ server.py       # Main server implementation and MCP tools\nâ”‚   â”œâ”€â”€ models.py       # Data models with Pydantic validation\nâ”‚   â”œâ”€â”€ storage.py      # Thread-safe persistence layer\nâ”‚   â”œâ”€â”€ storage_utils.py # Shared utilities for storage operations\nâ”‚   â”œâ”€â”€ analysis.py     # Thought analysis and pattern detection\nâ”‚   â”œâ”€â”€ testing.py      # Test utilities and helper functions\nâ”‚   â”œâ”€â”€ utils.py        # Common utilities and helper functions\nâ”‚   â”œâ”€â”€ logging_conf.py # Centralized logging configuration\nâ”‚   â””â”€â”€ __init__.py     # Package initialization\nâ”œâ”€â”€ tests/              \nâ”‚   â”œâ”€â”€ test_analysis.py # Tests for analysis functionality\nâ”‚   â”œâ”€â”€ test_models.py   # Tests for data models\nâ”‚   â”œâ”€â”€ test_storage.py  # Tests for persistence layer\nâ”‚   â””â”€â”€ __init__.py\nâ”œâ”€â”€ run_server.py       # Server entry point script\nâ”œâ”€â”€ debug_mcp_connection.py # Utility for debugging connections\nâ”œâ”€â”€ README.md           # Main documentation\nâ”œâ”€â”€ CHANGELOG.md        # Version history and changes\nâ”œâ”€â”€ example.md          # Customization examples\nâ”œâ”€â”€ LICENSE             # MIT License\nâ””â”€â”€ pyproject.toml      # Project configuration and dependencies\n```\n\n## Quick Start\n\n1. **Set Up Project**\n   ```bash\n   # Create and activate virtual environment\n   uv venv\n   .venv\\Scripts\\activate  # Windows\n   source .venv/bin/activate  # Unix\n\n   # Install package and dependencies\n   uv pip install -e .\n\n   # For development with testing tools\n   uv pip install -e \".[dev]\"\n\n   # For all optional dependencies\n   uv pip install -e \".[all]\"\n   ```\n\n2. **Run the Server**\n   ```bash\n   # Run directly\n   uv run -m mcp_sequential_thinking.server\n\n   # Or use the installed script\n   mcp-sequential-thinking\n   ```\n\n3. **Run Tests**\n   ```bash\n   # Run all tests\n   pytest\n\n   # Run with coverage report\n   pytest --cov=mcp_sequential_thinking\n   ```\n\n## Claude Desktop Integration\n\nAdd to your Claude Desktop configuration (`%APPDATA%\\Claude\\claude_desktop_config.json` on Windows):\n\n```json\n{\n  \"mcpServers\": {\n    \"sequential-thinking\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"C:\\\\path\\\\to\\\\your\\\\mcp-sequential-thinking\\\\run_server.py\",\n        \"run\",\n        \"server.py\"\n        ]\n      }\n    }\n  }\n```\n\nAlternatively, if you've installed the package with `pip install -e .`, you can use:\n\n```json\n{\n  \"mcpServers\": {\n    \"sequential-thinking\": {\n      \"command\": \"mcp-sequential-thinking\"\n    }\n  }\n}\n```\n\nYou can also run it directly using uvx and skipping the installation step:\n\n```json\n{\n  \"mcpServers\": {\n    \"sequential-thinking\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"--from\",\n        \"git+https://github.com/arben-adm/mcp-sequential-thinking\",\n        \"--with\",\n        \"portalocker\",\n        \"mcp-sequential-thinking\"\n      ]\n    }\n  }\n}\n```\n\n# How It Works\n\nThe server maintains a history of thoughts and processes them through a structured workflow. Each thought is validated using Pydantic models, categorized into thinking stages, and stored with relevant metadata in a thread-safe storage system. The server automatically handles data persistence, backup creation, and provides tools for analyzing relationships between thoughts.\n\n## Usage Guide\n\nThe Sequential Thinking server exposes three main tools:\n\n### 1. `process_thought`\n\nRecords and analyzes a new thought in your sequential thinking process.\n\n**Parameters:**\n\n- `thought` (string): The content of your thought\n- `thought_number` (integer): Position in your sequence (e.g., 1 for first thought)\n- `total_thoughts` (integer): Expected total thoughts in the sequence\n- `next_thought_needed` (boolean): Whether more thoughts are needed after this one\n- `stage` (string): The thinking stage - must be one of:\n  - \"Problem Definition\"\n  - \"Research\"\n  - \"Analysis\"\n  - \"Synthesis\"\n  - \"Conclusion\"\n- `tags` (list of strings, optional): Keywords or categories for your thought\n- `axioms_used` (list of strings, optional): Principles or axioms applied in your thought\n- `assumptions_challenged` (list of strings, optional): Assumptions your thought questions or challenges\n\n**Example:**\n\n```python\n# First thought in a 5-thought sequence\nprocess_thought(\n    thought=\"The problem of climate change requires analysis of multiple factors including emissions, policy, and technology adoption.\",\n    thought_number=1,\n    total_thoughts=5,\n    next_thought_needed=True,\n    stage=\"Problem Definition\",\n    tags=[\"climate\", \"global policy\", \"systems thinking\"],\n    axioms_used=[\"Complex problems require multifaceted solutions\"],\n    assumptions_challenged=[\"Technology alone can solve climate change\"]\n)\n```\n\n### 2. `generate_summary`\n\nGenerates a summary of your entire thinking process.\n\n**Example output:**\n\n```json\n{\n  \"summary\": {\n    \"totalThoughts\": 5,\n    \"stages\": {\n      \"Problem Definition\": 1,\n      \"Research\": 1,\n      \"Analysis\": 1,\n      \"Synthesis\": 1,\n      \"Conclusion\": 1\n    },\n    \"timeline\": [\n      {\"number\": 1, \"stage\": \"Problem Definition\"},\n      {\"number\": 2, \"stage\": \"Research\"},\n      {\"number\": 3, \"stage\": \"Analysis\"},\n      {\"number\": 4, \"stage\": \"Synthesis\"},\n      {\"number\": 5, \"stage\": \"Conclusion\"}\n    ]\n  }\n}\n```\n\n### 3. `clear_history`\n\nResets the thinking process by clearing all recorded thoughts.\n\n## Practical Applications\n\n- **Decision Making**: Work through important decisions methodically\n- **Problem Solving**: Break complex problems into manageable components\n- **Research Planning**: Structure your research approach with clear stages\n- **Writing Organization**: Develop ideas progressively before writing\n- **Project Analysis**: Evaluate projects through defined analytical stages\n\n\n## Getting Started\n\nWith the proper MCP setup, simply use the `process_thought` tool to begin working through your thoughts in sequence. As you progress, you can get an overview with `generate_summary` and reset when needed with `clear_history`.\n\n\n\n# Customizing the Sequential Thinking Server\n\nFor detailed examples of how to customize and extend the Sequential Thinking server, see [example.md](example.md). It includes code samples for:\n\n- Modifying thinking stages\n- Enhancing thought data structures with Pydantic\n- Adding persistence with databases\n- Implementing enhanced analysis with NLP\n- Creating custom prompts\n- Setting up advanced configurations\n- Building web UI integrations\n- Implementing visualization tools\n- Connecting to external services\n- Creating collaborative environments\n- Separating test code\n- Building reusable utilities\n\n\n\n\n## License\n\nMIT License\n\n\n\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "aryankeluskar--canvas-mcp": {
      "owner": "aryankeluskar",
      "name": "canvas-mcp",
      "url": "https://github.com/aryankeluskar/canvas-mcp",
      "imageUrl": "https://github.com/aryankeluskar.png",
      "description": "Interact with Canvas LMS and Gradescope to query courses and assignments, retrieve resources, and check submission statuses using natural language. Provides tools for finding relevant course materials and managing upcoming assignments.",
      "stars": 8,
      "forks": 3,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-10-04T05:39:11Z",
      "readme_content": "# Canvas MCP\n\n[![smithery badge](https://smithery.ai/badge/@aryankeluskar/canvas-mcp)](https://smithery.ai/server/@aryankeluskar/canvas-mcp)\n\nCanvas MCP is a set of tools that allows your AI agents to interact with Canvas LMS and Gradescope.\n\n![gradescope](assets/gradescope_mcp_ant.png)\n\n![example](assets/example.png)\n\n## Features\n\n- **Find relevant resources** - Ability to find relevant resources for a given query in natural language!\n- **Query upcoming assignments** - Not only fetch upcoming assignments, but also provide its breakdown for a given course.\n- **Get courses and assignments from Gradescope** - Query your Gradescope courses and assignments with natural language, get submission status, and more!\n- Get courses\n- Get modules\n- Get module items\n- Get file url\n- Get calendar events\n- Get assignments\n- and so much more... \n\n## Usage\n\nNote down the following beforehand:\n1. Canvas API Key from `Canvas > Account > Settings > Approved Integrations > New Access Token`\n2. Gradescope Email and Password https://www.gradescope.com/\n   \n### Installing via Smithery (**Preferred**)\n\nTo install Canvas MCP for Claude Desktop via [Smithery](https://smithery.ai/server/@aryankeluskar/canvas-mcp):\n\n```bash\nnpx -y @smithery/cli install @aryankeluskar/canvas-mcp --client claude\n```\n\nOr, for Cursor IDE to use canvas-mcp with other models:\n\n```bash\nnpx -y @smithery/cli install @aryankeluskar/canvas-mcp --client cursor\n```\n\nOr, for ChatGPT:\n\n\n1) Enable Developer Mode in settings, if not already enabled\n2) Go to `ChatGPT Settings > Connectors` and click Create to add this server URL: `https://server.smithery.ai/@aryankeluskar/canvas-mcp/mcp`\n\n---\n\n\n### Manual Configuration (ONLY for local instances)\n\nCreate a `.env` file in the root directory with the following environment variables:\n\n```\nSNITHERY_API_KEY=your_snithery_api_key\n```\n\nAdd the following to your `mcp.json` or `claude_desktop_config.json` file:\n\n```json\n{\n  \"mcpServers\": {\n      \"canvas\": {\n          \"command\": \"npx\",\n          \"args\": [\n              \"-y\",\n              \"@smithery/cli\",\n              \"run\",\n              \"@aryankeluskar/canvas-mcp\"\n          ]\n      }\n  }\n}\n```\n\n---\n\nBuilt by [Aryan Keluskar](https://aryankeluskar.com) :)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "beastmod7--You-Dont-Know-JS": {
      "owner": "beastmod7",
      "name": "You-Dont-Know-JS",
      "url": "https://github.com/beastmod7/You-Dont-Know-JS",
      "imageUrl": "https://github.com/beastmod7.png",
      "description": "A comprehensive book series that provides an in-depth exploration of JavaScript's core mechanisms, enhancing understanding and coding skills through detailed explanations and examples. The series is available for online reading and offers additional resources for purchased offline access.",
      "stars": 0,
      "forks": 0,
      "license": "Other",
      "language": "",
      "updated_at": "2024-07-09T07:33:36Z",
      "readme_content": "# You Don't Know JS Yet (book series) - 2nd Edition\n\nThis is a series of books diving deep into the core mechanisms of the JavaScript language. This is the **second edition** of the book series:\n\n<a href=\"https://leanpub.com/ydkjsy-get-started\"><img src=\"get-started/images/cover.png\" width=\"75\"></a>&nbsp;&nbsp;\n<a href=\"https://leanpub.com/ydkjsy-scope-closures\"><img src=\"scope-closures/images/cover.png\" width=\"75\"></a>&nbsp;&nbsp;...\n\n**To read more about the motivations and perspective behind this book series, check out the [Preface](preface.md).**\n\nIf you're looking for the previous **first edition** books, [they can be found here](https://github.com/getify/You-Dont-Know-JS/blob/1st-ed/README.md).\n\n## Titles\n\nI recommend reading the **second edition** books in this order:\n\n* [Get Started](get-started/README.md) | [Buy on Leanpub](https://leanpub.com/ydkjsy-get-started) | [Buy on Amazon](https://www.amazon.com/dp/B084BNMN7T)\n* [Scope & Closures](scope-closures/README.md) | [Buy on Leanpub](https://leanpub.com/ydkjsy-scope-closures) | [Buy on Amazon](https://www.amazon.com/dp/B08634PZ3N)\n* [Objects & Classes](objects-classes/README.md) (draft stable)\n* [Types & Grammar](types-grammar/README.md) (draft in progress)\n* Sync & Async (not yet started)\n* ES.Next & Beyond (not yet started)\n\nIf you're looking for the previous **first edition** books, [they can be found here](https://github.com/getify/You-Dont-Know-JS/blob/1st-ed/README.md).\n\n## Publishing\n\nAs always, you'll be able to read these books online here entirely for free.\n\nThis edition of the books is being self-published through [GetiPub](https://geti.pub) publishing. The published books will be made available for sale through normal book retail sources.\n\nIf you'd like to contribute financially towards the effort (or any of my other OSS efforts) aside from purchasing the published books, please consider these options:\n\n* [Github Sponsorship](https://github.com/users/getify/sponsorship)\n* [Patreon](https://www.patreon.com/getify)\n* [Paypal](https://www.paypal.me/getify)\n\n## Contributions\n\nPlease feel free to contribute to the quality of this content by submitting PRs for improvements to code snippets, explanations, etc. While typo fixes are welcomed, they will likely be caught through normal editing/publishing processes, **so please don't worry about them right now.**\n\nAny contributions you make to this effort **are of course greatly appreciated**.\n\nBut **PLEASE** read the [Contributions Guidelines](CONTRIBUTING.md) carefully before submitting a PR.\n\n## Thank You To These Wonderful Sponsors\n\n[![Frontend Masters Logo (dark)](https://github.com/getify/You-Dont-Know-JS/blob/2nd-ed/external-logos/fem_logo-light.svg)](https://frontendmasters.com#gh-light-mode-only)\n\n[![Frontend Masters Logo (light)](https://github.com/getify/You-Dont-Know-JS/blob/2nd-ed/external-logos/fem_logo.svg)](https://frontendmasters.com#gh-dark-mode-only)\n\n**The first two books of the second edition** are exclusively sponsored by **[Frontend Masters](https://frontendmasters.com)**.\n\nFrontend Masters is the gold standard for top-of-the-line expert training material in frontend-oriented software development. With over 150 courses on all things frontend, this should be your first and only stop for quality video training on HTML, CSS, JS, and related technologies.\n\n**Note:** I teach [all my workshops](https://frontendmasters.com/kyle-simpson) exclusively through Frontend Masters. If you like this book content, please check out my video training courses.\n\nI want to extend a warm and deep thanks to Marc Grabanski and the entire Frontend Masters team, not only for their excellent work with the video training platform, but for their unwavering support of me and of the \"You Don't Know JS\" books!\n\n----\n\n## License & Copyright\n\nThe materials herein are all &copy; 2019-2022 Kyle Simpson.\n\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Attribution-NonCommercial-NoDerivs 4.0 Unported License</a>.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Birdsmith--Gauntlet-Incept-MCP": {
      "owner": "Birdsmith",
      "name": "Gauntlet-Incept-MCP",
      "url": "https://github.com/Birdsmith/Gauntlet-Incept-MCP",
      "imageUrl": "https://github.com/Birdsmith.png",
      "description": "Generates high-quality educational content tailored for K-8 students, including articles and question banks, while integrating seamlessly with Claude Desktop for dynamic content generation and grading.",
      "stars": 1,
      "forks": 1,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-03-18T05:37:07Z",
      "readme_content": "# Gauntlet-Incept\n\nA system for generating high-quality educational content tailored to students' knowledge levels and interests.\n\n## Project Description\n\nThis repository contains the code and resources for the Gauntlet-Incept project, which aims to build a system that generates high-quality educational content for K-8 students. The initial scope focuses on developing educational content in the form of articles and question banks for specific subject areas.\n\n## Documentation\n\n- [Project Overview](docs/project-document.md) - Detailed description of the project goals and requirements\n- [Implementation Checklist](docs/implementation-checklist.md) - Comprehensive checklist for project implementation\n- [Original Project Brief](docs/WF%20-%20Gauntlet%20Incept%20Project%20G%20-%20250223-151531..md) - Original project brief with detailed requirements\n- [MCP Server Guide](docs/mcp-server.md) - Guide for using the Model Context Protocol server with Claude Desktop\n\n## Project Structure\n\n```\ngauntlet-incept/\nâ”œâ”€â”€ docs/                  # Documentation files\nâ”œâ”€â”€ src/                   # Source code\nâ”‚   â”œâ”€â”€ api/               # API routes\nâ”‚   â”œâ”€â”€ models/            # Data models\nâ”‚   â”œâ”€â”€ services/          # Business logic\nâ”‚   â”œâ”€â”€ utils/             # Utility functions\nâ”‚   â”œâ”€â”€ data/              # Data files\nâ”‚   â”œâ”€â”€ tests/             # Test files\nâ”‚   â”œâ”€â”€ index.js           # Entry point for REST API\nâ”‚   â””â”€â”€ mcp-server.js      # Model Context Protocol server\nâ”œâ”€â”€ services/              # Microservices\nâ”‚   â”œâ”€â”€ qti-service/       # QTI service for content storage\nâ”‚   â””â”€â”€ llm-service/       # LLM service for content generation\nâ”œâ”€â”€ .env.example           # Example environment variables\nâ”œâ”€â”€ .gitignore             # Git ignore file\nâ”œâ”€â”€ package.json           # Node.js package file\nâ”œâ”€â”€ docker-compose.yml     # Docker Compose configuration\nâ”œâ”€â”€ Dockerfile             # Docker configuration\nâ””â”€â”€ README.md              # This file\n```\n\n## API Endpoints\n\nThe project implements six core API endpoints:\n\n### Question Endpoints\n\n- `POST /api/question/tag` - Tag a question with subject, grade, standard, lesson, and difficulty\n- `POST /api/question/grade` - Grade a tagged question against quality standards\n- `POST /api/question/generate` - Generate a question based on tags or an example question\n\n### Article Endpoints\n\n- `POST /api/article/tag` - Tag an article with subject, grade, standard, and lesson\n- `POST /api/article/grade` - Grade a tagged article against quality standards\n- `POST /api/article/generate` - Generate an article based on tags or an example article\n\n## Model Context Protocol (MCP) Server\n\nIn addition to the REST API, this project includes an MCP server that allows Claude Desktop to interact with the Gauntlet Incept system. This enables Claude to generate, tag, and grade educational content directly.\n\nSee the [MCP Server Guide](docs/mcp-server.md) for details on how to set up and use the MCP server with Claude Desktop.\n\n## Getting Started\n\n### Prerequisites\n\n- Git\n- Node.js (v14 or higher)\n- Access to the RDS PostgreSQL database (credentials provided by administrator)\n- SSH key for database connection (if connecting through SSH tunnel)\n- Docker and Docker Compose (optional, for containerized deployment)\n\n### Installation\n\n1. Clone the repository\n   ```\n   git clone https://github.com/yourusername/Gauntlet-Incept.git\n   ```\n2. Navigate to the project directory\n   ```\n   cd Gauntlet-Incept\n   ```\n3. Install dependencies\n   ```\n   npm install\n   ```\n4. Copy the example environment file and update it with your values\n   ```\n   cp .env.example .env\n   ```\n5. Run the project\n   ```\n   npm start\n   ```\n\n### Running with Docker\n\n1. Build and start the containers\n   ```\n   docker-compose up -d\n   ```\n2. Access the API at http://localhost:3000\n3. Access the MCP server at http://localhost:3001\n\n### Database Connection\n\nThis project connects to an Amazon RDS PostgreSQL instance with the following details:\n\n- **Host**: alphacommoncrawl-core-reboot.cluster-caeuiwckzo1a.us-east-1.rds.amazonaws.com\n- **Port**: 5432\n- **Database**: core\n- **Username**: postgres\n\nNote: The password is stored in environment variables and not directly in the code for security reasons.\n\nIf you need to connect through an SSH tunnel, you'll need to set up the tunnel separately before starting the application.\n\n## Development\n\n### Running in Development Mode\n\n```\nnpm run dev\n```\n\n### Running the MCP Server\n\n```\nnpm run mcp\n```\n\n### Running Tests\n\n```\nnpm test\n```\n\n### Linting\n\n```\nnpm run lint\n```\n\n## Project Checklist\n\n- [x] Initialize Git repository\n- [x] Create basic project structure\n- [x] Add .gitignore file\n- [x] Create initial commit\n- [x] Set up project documentation\n- [x] Create implementation checklist\n- [x] Set up API routes and service structure\n- [x] Implement placeholder functionality for core services\n- [x] Set up Docker containerization\n- [x] Implement MCP server for Claude Desktop integration\n- [x] Configure connection to RDS PostgreSQL database\n- [ ] Implement actual functionality with LLM integration\n- [ ] Add tests\n- [ ] Review and finalize\n\n## License\n\nMIT\n\n## Contact\n\n[Your contact information] ",
      "npm_url": "",
      "npm_downloads": 0
    },
    "bmorphism--penrose-mcp": {
      "owner": "bmorphism",
      "name": "penrose-mcp",
      "url": "https://github.com/bmorphism/penrose-mcp",
      "imageUrl": "https://github.com/bmorphism.png",
      "description": "Create mathematical diagrams using domain-specific languages that define mathematical types, objects, relationships, and visual representation rules.",
      "stars": 8,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-30T21:49:31Z",
      "readme_content": "# Penrose MCP Server\n\nA Model Context Protocol (MCP) server for [Penrose](https://penrose.cs.cmu.edu/) - Create beautiful mathematical diagrams through natural language.\n\n## Overview\n\nThis MCP server provides tools and resources for creating mathematical diagrams using Penrose's domain-specific languages:\n\n- **Domain (DSL)**: Define mathematical types and relationships\n- **Substance**: Describe mathematical objects and their relationships\n- **Style**: Specify visual representation rules\n\n## Project Structure\n\n- `.topos/`: Research materials and documentation (gitignored)\n  - `penrose-research/`: Design documents and specifications\n  - `mcp-examples/`: Reference MCP server implementations\n  - `mcp-spec/`: Official MCP protocol documentation\n\n## Development\n\nUse the justfile to access documentation and reference materials:\n\n```bash\n# List all available commands\njust --list\n\n# View the server architecture\njust architecture\n\n# Access MCP specifications\njust mcp-spec\n```\n\n## License\n\nMIT License - See LICENSE file for details\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "cabrit0--mcp_server_reuneMacacada": {
      "owner": "cabrit0",
      "name": "mcp_server_reuneMacacada",
      "url": "https://github.com/cabrit0/mcp_server_reuneMacacada",
      "imageUrl": "https://github.com/cabrit0.png",
      "description": "Generates structured learning paths by aggregating and organizing resources from the web based on specified topics, with support for web search and scraping. The server returns a standardized JSON structure for easy integration with client applications.",
      "stars": 1,
      "forks": 0,
      "license": "Other",
      "language": "Python",
      "updated_at": "2025-07-28T16:51:32Z",
      "readme_content": "# MCP Server\n\nA server that generates Master Content Plans (MCPs) based on topics. The server aggregates resources from the web and organizes them into structured learning paths.\n\n## Features\n\n- Generate learning paths for any topic (not just technology topics)\n- Find relevant resources using web search and scraping\n- Organize resources into a logical sequence with customizable number of nodes\n- Support for multiple languages with focus on Portuguese\n- Performance optimizations for Render's free tier\n- Caching system for faster responses\n- Return a standardized JSON structure for consumption by client applications\n- **NEW**: TF-IDF based resource relevance filtering to ensure resources match the requested topic\n- **NEW**: Strategic quiz distribution across learning trees for balanced learning experiences\n- **NEW**: YouTube integration to include relevant videos in learning paths\n- **NEW**: Category system to generate more specific content for different types of topics\n- **NEW**: Asynchronous task system with real-time progress feedback to improve user experience and avoid timeouts\n- **NEW**: Enhanced caching system for improved performance and faster response times\n- **NEW**: Optimized web scraping techniques for better resource utilization\n- **NEW**: Adaptive scraping system that automatically chooses the most efficient method for each website\n- **NEW**: Puppeteer instance pool for efficient browser reuse and reduced memory usage\n\n## Tech Stack\n\n- Python 3.9+\n- FastAPI\n- Pyppeteer for JavaScript-heavy web scraping\n- Pyppeteer-stealth for avoiding detection during web scraping\n- Puppeteer instance pool for efficient browser reuse\n- DuckDuckGo Search API\n- BeautifulSoup for HTML parsing\n- scikit-learn for TF-IDF based resource relevance filtering\n- yt-dlp for YouTube video search and metadata extraction\n- Redis (optional) for distributed caching\n- msgpack for efficient data serialization\n- cachetools for advanced in-memory caching\n\n## Installation\n\n1. Clone the repository:\n\n   ```\n   git clone https://github.com/yourusername/mcp_server.git\n   cd mcp_server\n   ```\n\n2. Create a virtual environment:\n\n   ```\n   python -m venv venv\n   source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n   ```\n\n3. Install Python dependencies:\n\n   ```\n   pip install -r requirements.txt\n   ```\n\n4. Install Node.js dependencies (for the optimized scraping system):\n\n   ```\n   npm install\n   ```\n\n5. Install Chrome/Chromium for Pyppeteer (if not already installed)\n\n## Usage\n\n### Running Locally\n\n1. Start the server using the provided batch file (Windows):\n\n   ```\n   run_local.bat\n   ```\n\n   Or manually with uvicorn:\n\n   ```\n   uvicorn main:app --reload --host 0.0.0.0 --port 8000\n   ```\n\n2. Access the API at `http://localhost:8000`\n\n3. Generate an MCP by making a GET request to:\n\n   ```\n   GET /generate_mcp?topic=your_topic\n   ```\n\n4. Check the API documentation at `http://localhost:8000/docs`\n\n### Production URL\n\nThe production server is available at:\n\n```\nhttps://reunemacacada.onrender.com\n```\n\nAll endpoints documented in this README are available at both the local and production URLs.\n\n### Testing the Caching System\n\n1. Make a first request to generate an MCP (this will populate the cache):\n\n   ```\n   GET /generate_mcp?topic=python&num_nodes=15&language=pt\n   ```\n\n2. Make a second request with the same parameters (this should use the cache):\n\n   ```\n   GET /generate_mcp?topic=python&num_nodes=15&language=pt\n   ```\n\n   The second request should be significantly faster as the result will be retrieved from the cache.\n\n## Documentation\n\nDetailed documentation is available in the `docs` folder:\n\n- [API Reference](docs/api_reference.md) - Detailed API documentation\n- [Endpoints Reference](docs/endpoints_reference.md) - Complete reference of all endpoints\n- [Flutter Integration](docs/flutter_integration.md) - Guide for integrating with Flutter apps\n- [Async Tasks System](docs/async_tasks_system.md) - Documentation for the asynchronous task system\n- [Performance Improvements](docs/performance_improvements.md) - Overview of performance optimizations\n- [Caching System](docs/caching_system.md) - Documentation for the caching system\n- [Web Scraping Optimization](docs/web_scraping_optimization.md) - Details on web scraping optimizations\n\n## API Endpoints\n\n- `GET /health` - Health check endpoint\n- `GET /generate_mcp?topic={topic}&max_resources={max_resources}&num_nodes={num_nodes}&min_width={min_width}&max_width={max_width}&min_height={min_height}&max_height={max_height}&language={language}&category={category}` - Generate an MCP for the specified topic synchronously\n  - `topic` (required): The topic to generate an MCP for (minimum 3 characters)\n  - `max_resources` (optional): Maximum number of resources to include (default: 15, min: 5, max: 30)\n  - `num_nodes` (optional): Number of nodes to include in the learning path (default: 15, min: 10, max: 30)\n  - `min_width` (optional): Minimum width of the tree (nodes at first level) (default: 3, min: 2, max: 10)\n  - `max_width` (optional): Maximum width at any level of the tree (default: 5, min: 3, max: 15)\n  - `min_height` (optional): Minimum height of the tree (depth) (default: 3, min: 2, max: 8)\n  - `max_height` (optional): Maximum height of the tree (depth) (default: 7, min: 3, max: 12)\n  - `language` (optional): Language for resources (default: \"pt\")\n  - `category` (optional): Category for the topic (e.g., \"technology\", \"finance\", \"health\"). If not provided, it will be detected automatically.\n- `POST /generate_mcp_async?topic={topic}&max_resources={max_resources}&num_nodes={num_nodes}&min_width={min_width}&max_width={max_width}&min_height={min_height}&max_height={max_height}&language={language}&category={category}` - Start asynchronous generation of an MCP\n- `GET /status/{task_id}` - Check the status of an asynchronous task\n- `GET /tasks` - List all tasks\n- `POST /clear_cache?pattern={pattern}&clear_domain_cache={clear_domain_cache}` - Clear the cache based on a pattern\n  - `pattern` (optional): Pattern to match cache keys (default: \"\\*\" for all)\n  - `clear_domain_cache` (optional): Whether to also clear the domain method cache (default: false)\n- `GET /cache_stats` - Get statistics about the cache, including information about the domain method cache\n\n## Examples\n\n### Basic usage (Portuguese)\n\n```\nGET /generate_mcp?topic=python\n```\n\n### Custom number of nodes\n\n```\nGET /generate_mcp?topic=machine+learning&num_nodes=20\n```\n\n### English language\n\n```\nGET /generate_mcp?topic=javascript&language=en\n```\n\n### Specify category manually\n\n```\nGET /generate_mcp?topic=python&category=technology\n```\n\n### Full customization\n\n```\nGET /generate_mcp?topic=histÃ³ria+do+brasil&max_resources=20&num_nodes=25&min_width=4&max_width=8&min_height=4&max_height=8&language=pt\n```\n\n### Control tree structure\n\n```\nGET /generate_mcp?topic=machine+learning&min_width=2&max_width=4&min_height=5&max_height=10\n```\n\n### Asynchronous generation\n\n```\nPOST /generate_mcp_async?topic=inteligÃªncia+artificial&category=technology\n```\n\n### Check task status\n\n```\nGET /status/550e8400-e29b-41d4-a716-446655440000\n```\n\n### Clear cache\n\n```\nPOST /clear_cache\n```\n\n### Clear specific cache\n\n```\nPOST /clear_cache?pattern=mcp:*\n```\n\n## Performance Improvements\n\nThe MCP Server includes several performance optimizations:\n\n- **Caching System**: Results are cached to improve response times for repeated queries\n- **Asynchronous Task System**: Long-running operations are handled asynchronously\n- **Resource Filtering**: TF-IDF based filtering to select the most relevant resources\n- **Optimized Web Scraping**: Efficient web scraping techniques to reduce resource usage\n- **Adaptive Scraping System**: Automatically chooses the most efficient scraping method for each website\n- **Puppeteer Instance Pool**: Reuses browser instances to reduce memory usage and startup time\n- **Domain Method Cache**: Remembers which scraping method works best for each domain\n- **Resource Blocking**: Blocks unnecessary resources (images, stylesheets, fonts) during scraping\n\n### Performance Gains\n\n- **60-80% reduction in response time** for topics already in cache\n- **30-50% reduction in response time** for new topics\n- **40-60% reduction in memory usage** during web scraping\n- **3-5x increase in throughput** for simultaneous requests\n\n## Deployment\n\nThe server can be deployed to various platforms:\n\n### Using Docker\n\n```\ndocker build -t mcp-server .\ndocker run -p 8080:8080 mcp-server\n```\n\n### Deploying to Render, Fly.io, or other platforms\n\nFollow the platform-specific instructions for deploying a Docker container or a Python application.\n\n## License\n\n**Proprietary Software - All Rights Reserved**\n\nThis software is proprietary and confidential. Unauthorized copying, distribution, modification, public display, or public performance of this software is strictly prohibited. This software is intended for use under a paid subscription model only.\n\nÂ© 2024 ReuneMacacada. All rights reserved.\n\nLast commit: v1.1.2 - CorreÃ§Ã£o de problemas com DuckDuckGo rate limit e Puppeteer\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "cantian-ai--bazi-mcp": {
      "owner": "cantian-ai",
      "name": "bazi-mcp",
      "url": "https://github.com/cantian-ai/bazi-mcp",
      "imageUrl": "https://github.com/cantian-ai.png",
      "description": "Provides precise Bazi (Chinese metaphysical) calculations to deliver insights on personality and destiny. It enables AI agents to access accurate Bazi data for applications in fortune-telling and cultural analysis.",
      "stars": 176,
      "forks": 57,
      "license": "ISC License",
      "language": "TypeScript",
      "updated_at": "2025-10-04T08:01:20Z",
      "readme_content": "# Bazi MCP (å…«å­— MCP) by Cantian AI\n\n[![smithery badge](https://smithery.ai/badge/@cantian-ai/bazi-mcp)](https://smithery.ai/server/@cantian-ai/bazi-mcp)\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/453ac410-d93a-45fb-8563-7d3cccfbe956)\n\nUnlock precise Bazi insights with the **Bazi MCP**, the first AI-powered Bazi calculator. Built to address inaccuracies in existing AI fortune-telling tools like GPT and DeepSeek, our MCP delivers reliable Bazi data for personality analysis, destiny forecasting, and more.\n\n### Why Bazi MCP?\n\n- **Accurate Bazi Calculations**: Provide insightful Bazi information.\n- **AI Agent Integration**: Empowers AI agents with precise Bazi data.\n- **Community-Driven**: Join enthusiasts to advance Chinese metaphysics.\n\nOriginating from the popular [_Chinese Bazi Fortune Teller_](https://chatgpt.com/g/g-67c3f7b74d148191a2167f44fd13412d-chinese-bazi-fortune-teller-can-tian-ba-zi-suan-ming-jing-zhun-pai-pan-jie-du) GPTs in the GPT Store, this project is now integrated with **Cantian AI** ([cantian.ai](https://cantian.ai)). We invite Bazi practitioners and AI enthusiasts to collaborate, share insights, and contribute to our open-source community.\n\n### Get Involved\n\n- **Contact**: [support@cantian.ai](mailto:support@cantian.ai)\n\n## ä¸­æ–‡\n\n**å…«å­— MCP**æ˜¯å‚å¤© AI æ¨å‡ºçš„é¦–ä¸ªé¢å‘ç„å­¦é¢†åŸŸçš„ MCPï¼Œé’ˆå¯¹ GPT å’Œ DeepSeek ç­‰ç®—å‘½å·¥å…·å¸¸å‡ºç°çš„æ’ç›˜é”™è¯¯ï¼Œæä¾›ç²¾å‡†çš„å…«å­—æ•°æ®ï¼ŒåŠ©åŠ›æ€§æ ¼åˆ†æã€å‘½è¿é¢„æµ‹ç­‰åº”ç”¨ã€‚\n\n### å…«å­— MCP äº®ç‚¹\n\n- **ç²¾å‡†æ’ç›˜**ï¼šæä¾›å…¨é¢çš„å…«å­—æ’ç›˜ä¿¡æ¯ã€‚\n- **AI èµ‹èƒ½**ï¼šä¸º AI æ™ºèƒ½ä½“æä¾›å¯é å…«å­—æœåŠ¡ã€‚\n- **ç¤¾åŒºå…±å»º**ï¼šæ¬¢è¿å‘½ç†çˆ±å¥½è€…å‚ä¸äº¤æµä¸å¼€å‘ã€‚\n\né¡¹ç›®æºäº GPT Store çƒ­é—¨åº”ç”¨[_Chinese Bazi Fortune Teller_](https://chatgpt.com/g/g-67c3f7b74d148191a2167f44fd13412d-chinese-bazi-fortune-teller-can-tian-ba-zi-suan-ming-jing-zhun-pai-pan-jie-du)ï¼Œç°å·²èå…¥**å‚å¤© AI**å¹³å° ([cantian.ai](https://cantian.ai))ã€‚æˆ‘ä»¬è¯šé‚€å‘½ç†ç ”ç©¶è€…ä¸ AI å¼€å‘è€…åŠ å…¥ï¼Œå…±åŒæ¨åŠ¨ä¸­å›½ä¼ ç»Ÿæ–‡åŒ–çš„ä¼ æ‰¿ä¸åˆ›æ–°ã€‚\n\n### è”ç³»æˆ‘ä»¬\n\n- **é‚®ç®±**ï¼š[support@cantian.ai](mailto:support@cantian.ai)\n- **å¾®ä¿¡**ï¼š\n\n  <img src=\"https://github.com/user-attachments/assets/7790b64e-e03f-47e2-b824-38459549a6d8\" alt=\"WeChat QR Code\" width=\"200\"/>\n\n## å‰ç½®éœ€æ±‚ ï½œ Prerequisite\n\nNode.js 22 ç‰ˆæœ¬æˆ–ä»¥ä¸Šã€‚\n\nNode.js 22 or above.\n\n## å¼€å§‹ä½¿ç”¨ ï½œ Start\n\né…ç½® AI åº”ç”¨ï¼ˆä¾‹å¦‚ Claude Descktopï¼‰ã€‚\n\nConfigure AI application (e.g. Claude Desktop).\n\n```json\n{\n  \"mcpServers\": {\n    \"Bazi\": {\n      \"command\": \"npx\",\n      \"args\": [\"bazi-mcp\"]\n    }\n  }\n}\n```\n\n### Installing via Smithery\n\nTo install bazi-mcp for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@cantian-ai/bazi-mcp):\n\n```bash\nnpx -y @smithery/cli install @cantian-ai/bazi-mcp --client claude\n```\n\n## å·¥å…·åˆ—è¡¨ | Tools\n\n### getBaziDetail\n\n> æ ¹æ®ç»™å®šçš„å…¬å†æˆ–å†œå†æ—¶é—´è®¡ç®—å…«å­—ä¿¡æ¯ã€‚\n> Calculate the Bazi results based on the solar/lunar datetime.\n\n#### å‚æ•° | Arguments\n\n- solarDatetime: `String`\n\n  > ISO æ ¼å¼çš„é˜³å†æ—¶é—´ã€‚ä¾‹å¦‚ï¼š`2000-05-15T12:00:00+08:00`ã€‚  \n  > Solar datetime in ISO format. Example: `2000-05-15T12:00:00+08:00`.\n\n- lunarDatetime: `String`\n\n  > å†œå†æ—¶é—´ã€‚ä¾‹å¦‚ï¼š`2000-05-15 12:00:00`ã€‚  \n  > Lunar datetime. Example: `2000-05-15 12:00:00`.\n\n- gender: `Number`\n\n  > æ€§åˆ«ã€‚å¯é€‰ã€‚0 - å¥³ï¼Œ1-ç”·ã€‚é»˜è®¤ 1ã€‚  \n  > Gender. Optional. 0 for female, 1 for male. 1 by default.\n\n- eightCharProviderSectï¼š `Number`\n\n  > æ—©æ™šå­æ—¶é…ç½®ã€‚å¯é€‰ã€‚1 - è¡¨ç¤º 23:00-23:59 æ—¥å¹²æ”¯ä¸ºæ˜å¤©ï¼Œ2 - è¡¨ç¤º 23:00-23:59 æ—¥å¹²æ”¯ä¸ºå½“å¤©ã€‚é»˜è®¤ 2ã€‚\n  > Configuration for eight char provider. Optional. 1 for meaning the day stem of 23:00-23:59 is for tomorrow, 2 for meaning the day stem of 23:00-23:59 is for today. 2 by default.\n\n#### ç»“æœç¤ºä¾‹ ï½œ Result example\n\n```json\n{\n  \"æ€§åˆ«\": \"ç”·\",\n  \"é˜³å†\": \"1998å¹´7æœˆ31æ—¥ 14:10:00\",\n  \"å†œå†\": \"å†œå†æˆŠå¯…å¹´å…­æœˆåˆä¹è¾›æœªæ—¶\",\n  \"å…«å­—\": \"æˆŠå¯… å·±æœª å·±å¯ è¾›æœª\",\n  \"ç”Ÿè‚–\": \"è™\",\n  \"æ—¥ä¸»\": \"å·±\",\n  \"å¹´æŸ±\": {\n    \"å¤©å¹²\": {\n      \"å¤©å¹²\": \"æˆŠ\",\n      \"äº”è¡Œ\": \"åœŸ\",\n      \"é˜´é˜³\": \"é˜³\",\n      \"åç¥\": \"åŠ«è´¢\"\n    },\n    \"åœ°æ”¯\": {\n      \"åœ°æ”¯\": \"å¯…\",\n      \"äº”è¡Œ\": \"æœ¨\",\n      \"é˜´é˜³\": \"é˜³\",\n      \"è—å¹²\": {\n        \"ä¸»æ°”\": {\n          \"å¤©å¹²\": \"ç”²\",\n          \"åç¥\": \"æ­£å®˜\"\n        },\n        \"ä¸­æ°”\": {\n          \"å¤©å¹²\": \"ä¸™\",\n          \"åç¥\": \"æ­£å°\"\n        },\n        \"ä½™æ°”\": {\n          \"å¤©å¹²\": \"æˆŠ\",\n          \"åç¥\": \"åŠ«è´¢\"\n        }\n      }\n    },\n    \"çº³éŸ³\": \"åŸå¤´åœŸ\",\n    \"æ—¬\": \"ç”²æˆŒ\",\n    \"ç©ºäº¡\": \"ç”³é…‰\",\n    \"æ˜Ÿè¿\": \"æ­»\",\n    \"è‡ªå\": \"é•¿ç”Ÿ\"\n  },\n  \"æœˆæŸ±\": {\n    \"å¤©å¹²\": {\n      \"å¤©å¹²\": \"å·±\",\n      \"äº”è¡Œ\": \"åœŸ\",\n      \"é˜´é˜³\": \"é˜´\",\n      \"åç¥\": \"æ¯”è‚©\"\n    },\n    \"åœ°æ”¯\": {\n      \"åœ°æ”¯\": \"æœª\",\n      \"äº”è¡Œ\": \"åœŸ\",\n      \"é˜´é˜³\": \"é˜´\",\n      \"è—å¹²\": {\n        \"ä¸»æ°”\": {\n          \"å¤©å¹²\": \"å·±\",\n          \"åç¥\": \"æ¯”è‚©\"\n        },\n        \"ä¸­æ°”\": {\n          \"å¤©å¹²\": \"ä¸\",\n          \"åç¥\": \"åå°\"\n        },\n        \"ä½™æ°”\": {\n          \"å¤©å¹²\": \"ä¹™\",\n          \"åç¥\": \"ä¸ƒæ€\"\n        }\n      }\n    },\n    \"çº³éŸ³\": \"å¤©ä¸Šç«\",\n    \"æ—¬\": \"ç”²å¯…\",\n    \"ç©ºäº¡\": \"å­ä¸‘\",\n    \"æ˜Ÿè¿\": \"å† å¸¦\",\n    \"è‡ªå\": \"å† å¸¦\"\n  },\n  \"æ—¥æŸ±\": {\n    \"å¤©å¹²\": {\n      \"å¤©å¹²\": \"å·±\",\n      \"äº”è¡Œ\": \"åœŸ\",\n      \"é˜´é˜³\": \"é˜´\"\n    },\n    \"åœ°æ”¯\": {\n      \"åœ°æ”¯\": \"å¯\",\n      \"äº”è¡Œ\": \"æœ¨\",\n      \"é˜´é˜³\": \"é˜´\",\n      \"è—å¹²\": {\n        \"ä¸»æ°”\": {\n          \"å¤©å¹²\": \"ä¹™\",\n          \"åç¥\": \"ä¸ƒæ€\"\n        }\n      }\n    },\n    \"çº³éŸ³\": \"åŸå¤´åœŸ\",\n    \"æ—¬\": \"ç”²æˆŒ\",\n    \"ç©ºäº¡\": \"ç”³é…‰\",\n    \"æ˜Ÿè¿\": \"ç—…\",\n    \"è‡ªå\": \"ç—…\"\n  },\n  \"æ—¶æŸ±\": {\n    \"å¤©å¹²\": {\n      \"å¤©å¹²\": \"è¾›\",\n      \"äº”è¡Œ\": \"é‡‘\",\n      \"é˜´é˜³\": \"é˜´\",\n      \"åç¥\": \"é£Ÿç¥\"\n    },\n    \"åœ°æ”¯\": {\n      \"åœ°æ”¯\": \"æœª\",\n      \"äº”è¡Œ\": \"åœŸ\",\n      \"é˜´é˜³\": \"é˜´\",\n      \"è—å¹²\": {\n        \"ä¸»æ°”\": {\n          \"å¤©å¹²\": \"å·±\",\n          \"åç¥\": \"æ¯”è‚©\"\n        },\n        \"ä¸­æ°”\": {\n          \"å¤©å¹²\": \"ä¸\",\n          \"åç¥\": \"åå°\"\n        },\n        \"ä½™æ°”\": {\n          \"å¤©å¹²\": \"ä¹™\",\n          \"åç¥\": \"ä¸ƒæ€\"\n        }\n      }\n    },\n    \"çº³éŸ³\": \"è·¯æ—åœŸ\",\n    \"æ—¬\": \"ç”²å­\",\n    \"ç©ºäº¡\": \"æˆŒäº¥\",\n    \"æ˜Ÿè¿\": \"å† å¸¦\",\n    \"è‡ªå\": \"è¡°\"\n  },\n  \"èƒå…ƒ\": \"åºšæˆŒ\",\n  \"èƒæ¯\": \"ç”²æˆŒ\",\n  \"å‘½å®«\": \"ä¹™å¯\",\n  \"èº«å®«\": \"ä¹™å¯\",\n  \"ç¥ç…\": {\n    \"å¹´æŸ±\": [\"å›½å°\", \"äº¡ç¥\"],\n    \"æœˆæŸ±\": [\"å¤©å¾·åˆ\", \"æœˆå¾·åˆ\", \"å¤©ä¹™è´µäºº\", \"å¤ªæè´µäºº\", \"ç¦æ˜Ÿè´µäºº\", \"é‡‘èˆ†\", \"è¡€åˆƒ\", \"åç›–\", \"å¤©å–œ\", \"å…ƒè¾°\"],\n    \"æ—¥æŸ±\": [\"å¤©å¾·åˆ\", \"æœˆå¾·åˆ\", \"æ¡ƒèŠ±\", \"ä¹ä¸‘\", \"ç«¥å­ç…\"],\n    \"æ—¶æŸ±\": [\"å¤©ä¹™è´µäºº\", \"å¤ªæè´µäºº\", \"ç¦æ˜Ÿè´µäºº\", \"é‡‘èˆ†\", \"è¡€åˆƒ\", \"åç›–\", \"å¤©å–œ\", \"å…ƒè¾°\", \"ç«¥å­ç…\"]\n  },\n  \"å¤§è¿\": {\n    \"èµ·è¿å¹´é¾„\": 4,\n    \"èµ·è¿æ—¥æœŸ\": \"2001-1-26\",\n    \"å¤§è¿\": [\n      {\n        \"å¹²æ”¯\": \"åºšç”³\",\n        \"å¼€å§‹å¹´ä»½\": 2001,\n        \"ç»“æŸ\": 2010,\n        \"å¤©å¹²åç¥\": \"ä¼¤å®˜\",\n        \"åœ°æ”¯åç¥\": [\"ä¼¤å®˜\", \"æ­£è´¢\", \"åŠ«è´¢\"],\n        \"åœ°æ”¯è—å¹²\": [\"åºš\", \"å£¬\", \"æˆŠ\"],\n        \"å¼€å§‹å¹´é¾„\": 4,\n        \"ç»“æŸå¹´é¾„\": 13\n      },\n      {\n        \"å¹²æ”¯\": \"è¾›é…‰\",\n        \"å¼€å§‹å¹´ä»½\": 2011,\n        \"ç»“æŸ\": 2020,\n        \"å¤©å¹²åç¥\": \"é£Ÿç¥\",\n        \"åœ°æ”¯åç¥\": [\"é£Ÿç¥\"],\n        \"åœ°æ”¯è—å¹²\": [\"è¾›\"],\n        \"å¼€å§‹å¹´é¾„\": 14,\n        \"ç»“æŸå¹´é¾„\": 23\n      },\n      {\n        \"å¹²æ”¯\": \"å£¬æˆŒ\",\n        \"å¼€å§‹å¹´ä»½\": 2021,\n        \"ç»“æŸ\": 2030,\n        \"å¤©å¹²åç¥\": \"æ­£è´¢\",\n        \"åœ°æ”¯åç¥\": [\"åŠ«è´¢\", \"é£Ÿç¥\", \"åå°\"],\n        \"åœ°æ”¯è—å¹²\": [\"æˆŠ\", \"è¾›\", \"ä¸\"],\n        \"å¼€å§‹å¹´é¾„\": 24,\n        \"ç»“æŸå¹´é¾„\": 33\n      },\n      {\n        \"å¹²æ”¯\": \"ç™¸äº¥\",\n        \"å¼€å§‹å¹´ä»½\": 2031,\n        \"ç»“æŸ\": 2040,\n        \"å¤©å¹²åç¥\": \"åè´¢\",\n        \"åœ°æ”¯åç¥\": [\"æ­£è´¢\", \"æ­£å®˜\"],\n        \"åœ°æ”¯è—å¹²\": [\"å£¬\", \"ç”²\"],\n        \"å¼€å§‹å¹´é¾„\": 34,\n        \"ç»“æŸå¹´é¾„\": 43\n      },\n      {\n        \"å¹²æ”¯\": \"ç”²å­\",\n        \"å¼€å§‹å¹´ä»½\": 2041,\n        \"ç»“æŸ\": 2050,\n        \"å¤©å¹²åç¥\": \"æ­£å®˜\",\n        \"åœ°æ”¯åç¥\": [\"åè´¢\"],\n        \"åœ°æ”¯è—å¹²\": [\"ç™¸\"],\n        \"å¼€å§‹å¹´é¾„\": 44,\n        \"ç»“æŸå¹´é¾„\": 53\n      },\n      {\n        \"å¹²æ”¯\": \"ä¹™ä¸‘\",\n        \"å¼€å§‹å¹´ä»½\": 2051,\n        \"ç»“æŸ\": 2060,\n        \"å¤©å¹²åç¥\": \"ä¸ƒæ€\",\n        \"åœ°æ”¯åç¥\": [\"æ¯”è‚©\", \"åè´¢\", \"é£Ÿç¥\"],\n        \"åœ°æ”¯è—å¹²\": [\"å·±\", \"ç™¸\", \"è¾›\"],\n        \"å¼€å§‹å¹´é¾„\": 54,\n        \"ç»“æŸå¹´é¾„\": 63\n      },\n      {\n        \"å¹²æ”¯\": \"ä¸™å¯…\",\n        \"å¼€å§‹å¹´ä»½\": 2061,\n        \"ç»“æŸ\": 2070,\n        \"å¤©å¹²åç¥\": \"æ­£å°\",\n        \"åœ°æ”¯åç¥\": [\"æ­£å®˜\", \"æ­£å°\", \"åŠ«è´¢\"],\n        \"åœ°æ”¯è—å¹²\": [\"ç”²\", \"ä¸™\", \"æˆŠ\"],\n        \"å¼€å§‹å¹´é¾„\": 64,\n        \"ç»“æŸå¹´é¾„\": 73\n      },\n      {\n        \"å¹²æ”¯\": \"ä¸å¯\",\n        \"å¼€å§‹å¹´ä»½\": 2071,\n        \"ç»“æŸ\": 2080,\n        \"å¤©å¹²åç¥\": \"åå°\",\n        \"åœ°æ”¯åç¥\": [\"ä¸ƒæ€\"],\n        \"åœ°æ”¯è—å¹²\": [\"ä¹™\"],\n        \"å¼€å§‹å¹´é¾„\": 74,\n        \"ç»“æŸå¹´é¾„\": 83\n      },\n      {\n        \"å¹²æ”¯\": \"æˆŠè¾°\",\n        \"å¼€å§‹å¹´ä»½\": 2081,\n        \"ç»“æŸ\": 2090,\n        \"å¤©å¹²åç¥\": \"åŠ«è´¢\",\n        \"åœ°æ”¯åç¥\": [\"åŠ«è´¢\", \"ä¸ƒæ€\", \"åè´¢\"],\n        \"åœ°æ”¯è—å¹²\": [\"æˆŠ\", \"ä¹™\", \"ç™¸\"],\n        \"å¼€å§‹å¹´é¾„\": 84,\n        \"ç»“æŸå¹´é¾„\": 93\n      },\n      {\n        \"å¹²æ”¯\": \"å·±å·³\",\n        \"å¼€å§‹å¹´ä»½\": 2091,\n        \"ç»“æŸ\": 2100,\n        \"å¤©å¹²åç¥\": \"æ¯”è‚©\",\n        \"åœ°æ”¯åç¥\": [\"æ­£å°\", \"ä¼¤å®˜\", \"åŠ«è´¢\"],\n        \"åœ°æ”¯è—å¹²\": [\"ä¸™\", \"åºš\", \"æˆŠ\"],\n        \"å¼€å§‹å¹´é¾„\": 94,\n        \"ç»“æŸå¹´é¾„\": 103\n      }\n    ]\n  },\n  \"åˆ‘å†²åˆä¼š\": {\n    \"å¹´\": {\n      \"å¤©å¹²\": {},\n      \"åœ°æ”¯\": {}\n    },\n    \"æœˆ\": {\n      \"å¤©å¹²\": {},\n      \"åœ°æ”¯\": {\n        \"åŠåˆ\": [\n          {\n            \"æŸ±\": \"æ—¥\",\n            \"çŸ¥è¯†ç‚¹\": \"æœªå¯åŠåˆæœ¨\",\n            \"å…ƒç´ \": \"æœ¨\"\n          }\n        ]\n      }\n    },\n    \"æ—¥\": {\n      \"å¤©å¹²\": {},\n      \"åœ°æ”¯\": {\n        \"åŠåˆ\": [\n          {\n            \"æŸ±\": \"æœˆ\",\n            \"çŸ¥è¯†ç‚¹\": \"å¯æœªåŠåˆæœ¨\",\n            \"å…ƒç´ \": \"æœ¨\"\n          },\n          {\n            \"æŸ±\": \"æ—¶\",\n            \"çŸ¥è¯†ç‚¹\": \"å¯æœªåŠåˆæœ¨\",\n            \"å…ƒç´ \": \"æœ¨\"\n          }\n        ]\n      }\n    },\n    \"æ—¶\": {\n      \"å¤©å¹²\": {},\n      \"åœ°æ”¯\": {\n        \"åŠåˆ\": [\n          {\n            \"æŸ±\": \"æ—¥\",\n            \"çŸ¥è¯†ç‚¹\": \"æœªå¯åŠåˆæœ¨\",\n            \"å…ƒç´ \": \"æœ¨\"\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n### getSolarTimes\n\n> æ ¹æ®ç»™å®šçš„å…«å­—è¿”å›å¯èƒ½çš„å…¬å†æ—¶é—´åˆ—è¡¨ã€‚\n> Return a list of possible solar calendar datetime based on the given Bazi.\n\n#### å‚æ•° | Arguments\n\n- bazi: `String`\n\n  > å…«å­—ï¼Œå„æŸ±ç”¨ç©ºæ ¼éš”å¼€ã€‚\n  > Bazi, with each pillar separated by a space.\n\n#### ç»“æœç¤ºä¾‹ ï½œ Result example\n\n```json\n[\"1758-07-29 14:00:00\", \"1818-07-15 14:00:00\", \"1998-07-31 14:00:00\"]\n```\n\n### getChineseCalendar\n\n> è·å–æŒ‡å®šå…¬å†æ—¶é—´ï¼ˆé»˜è®¤ä»Šå¤©ï¼‰çš„é»„å†ä¿¡æ¯ã€‚\n> Get chinese calendar information for the specified solar calendar date (default is today).\n\n#### å‚æ•° | Arguments\n\n- solarDatetime\n\n  > ISO æ ¼å¼çš„é˜³å†æ—¶é—´ã€‚ä¾‹å¦‚ï¼š`2000-05-15T12:00:00+08:00`ã€‚  \n  > Solar datetime in ISO format. Example: `2000-05-15T12:00:00+08:00`.\n\n#### ç»“æœç¤ºä¾‹ ï½œ Result example\n\n```json\n{\n  \"å…¬å†\": \"2025å¹´5æœˆ7æ—¥ æ˜ŸæœŸä¸‰\",\n  \"å†œå†\": \"å†œå†ä¹™å·³å¹´å››æœˆåˆå\",\n  \"å¹²æ”¯\": \"ä¹™å·³ è¾›å·³ ä¸™å­\",\n  \"ç”Ÿè‚–\": \"è›‡\",\n  \"çº³éŸ³\": \"æ¶§ä¸‹æ°´\",\n  \"èŠ‚æ°”\": \"ç«‹å¤\",\n  \"äºŒåå…«å®¿\": \"ç®•æ°´è±¹å‰\",\n  \"å½­ç¥–ç™¾å¿Œ\": \"ä¸™ä¸ä¿®ç¶å¿…è§ç¾æ®ƒ å­ä¸é—®åœè‡ªæƒ¹ç¥¸æ®ƒ\",\n  \"å–œç¥æ–¹ä½\": \"è¥¿å—\",\n  \"é˜³è´µç¥æ–¹ä½\": \"è¥¿\",\n  \"é˜´è´µç¥æ–¹ä½\": \"è¥¿åŒ—\",\n  \"ç¦ç¥æ–¹ä½\": \"ä¸œ\",\n  \"è´¢ç¥æ–¹ä½\": \"è¥¿å—\",\n  \"å†²ç…\": \"å†²é©¬(åˆ)ç…å—\",\n  \"å®œ\": \"å«å¨¶,ç¥­ç¥€,ç¥ˆç¦,æ±‚å—£,å¼€å…‰,å‡ºè¡Œ,æ‹†å¸,åŠ¨åœŸ,ä¸Šæ¢,å‡ºç«,è¿›äººå£,å…¥å®…,ç§»å¾™,å®‰åºŠ,æ ½ç§,çº³ç•œ,ç‰§å…»,ç«–æŸ±,å®‰é—¨,ä¿®é€ ,è§£é™¤,ä¼šäº²å‹\",\n  \"å¿Œ\": \"\"\n}\n```\n\n### ~~buildBaziFromLunarDatetime~~ (deprecated)\n\n> æ ¹æ®`å†œå†`æ—¶é—´è®¡ç®—å…«å­—ç»“æœã€‚  \n> Calculate the BaZi results based on the lunar datetime.\n\n#### å‚æ•° ï½œ Arguments\n\n- lunarDatetime: `String`\n\n  > å†œå†æ—¶é—´ã€‚ä¾‹å¦‚ï¼š`2000-05-15 12:00:00`ã€‚  \n  > Lunar datetime. Example: `2000-05-15 12:00:00`.\n\n- gender: `Number`\n\n  > æ€§åˆ«ã€‚å¯é€‰ã€‚0 - å¥³ï¼Œ1-ç”·ã€‚é»˜è®¤ 1ã€‚  \n  > Gender. Optional. 0 for female, 1 for male. 1 by default.\n\n- eightCharProviderSectï¼š `Number`\n\n  > æ—©æ™šå­æ—¶é…ç½®ã€‚å¯é€‰ã€‚1 - è¡¨ç¤º 23:00-23:59 æ—¥å¹²æ”¯ä¸ºæ˜å¤©ï¼Œ2 - è¡¨ç¤º 23:00-23:59 æ—¥å¹²æ”¯ä¸ºå½“å¤©ã€‚é»˜è®¤ 2ã€‚\n  > Configuration for eight char provider. Optional. 1 for meaning the day stem of 23:00-23:59 is for tomorrow, 2 for meaning the day stem of 23:00-23:59 is for today. 2 by default.\n\n### ~~buildBaziFromSolarDatetime~~ (deprecated)\n\n> æ ¹æ®`é˜³å†`æ—¶é—´è®¡ç®—å…«å­—ç»“æœã€‚  \n> Calculate the BaZi results based on the solar datetime.\n\n#### å‚æ•° ï½œ Arguments\n\n- solarDatetime: `String`\n\n  > ISO æ ¼å¼çš„é˜³å†æ—¶é—´ã€‚ä¾‹å¦‚ï¼š`2000-05-15T12:00:00+08:00`ã€‚  \n  > Solar datetime in ISO format. Example: `2000-05-15T12:00:00+08:00`.\n\n- gender: `Number`\n\n  > æ€§åˆ«ã€‚å¯é€‰ã€‚0 - å¥³ï¼Œ1-ç”·ã€‚  \n  > Gender. Optional. 0 for female, 1 for male.\n\n- eightCharProviderSectï¼š `Number`\n\n  > æ—©æ™šå­æ—¶é…ç½®ã€‚å¯é€‰ã€‚1 - è¡¨ç¤º 23:00-23:59 æ—¥å¹²æ”¯ä¸ºæ˜å¤©ï¼Œ2 - è¡¨ç¤º 23:00-23:59 æ—¥å¹²æ”¯ä¸ºå½“å¤©ã€‚é»˜è®¤ 2ã€‚\n  > Configuration for eight char provider. Optional. 1 for meaning the day stem of 23:00-23:59 is for tomorrow, 2 for meaning the day stem of 23:00-23:59 is for today. 2 by default.\n\n**Keywords**: Bazi MCP, Bazi AI Agent, Fengshui AI Agent, Bazi Calculator MCP, Bazi Calculator AI, Cantian AI\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "captain-blue210--anki-mcp-server": {
      "owner": "captain-blue210",
      "name": "anki-mcp-server",
      "url": "https://github.com/captain-blue210/anki-mcp-server",
      "imageUrl": "https://github.com/captain-blue210.png",
      "description": "Connects to Anki to retrieve leech-tagged cards and adds date-stamped review tags for analysis. Facilitates enhanced study sessions by tracking reviewed cards and integrating with Claude Desktop.",
      "stars": 0,
      "forks": 3,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-04-13T14:19:56Z",
      "readme_content": "# Anki MCP Server\n\nAn MCP (Model Context Protocol) server for Claude Desktop that connects to Anki via AnkiConnect and retrieves leech-tagged cards.\n\n## Features\n\n- Connects to Anki via AnkiConnect API\n- Retrieves cards with \"leech\" tags\n- Adds date-stamped review tags to cards\n- Provides comprehensive card data for analysis by Claude\n- Can be used with Claude Desktop\n\n## Prerequisites\n\n- [Anki](https://apps.ankiweb.net/) installed and running\n- [AnkiConnect](https://ankiweb.net/shared/info/2055492159) add-on installed in Anki\n- Node.js and npm\n\n## Installation\n\n1. Clone this repository:\n   ```\n   git clone https://github.com/yourusername/anki-mcp-server.git\n   cd anki-mcp-server\n   ```\n\n2. Install dependencies:\n   ```\n   npm install\n   ```\n\n3. Build the project:\n   ```\n   npm run build\n   ```\n\n## Configuration\n\nThe server can be configured using environment variables. Copy the provided example file to create your own configuration:\n\n```\ncp .env.example .env\n```\n\nThen edit the `.env` file to customize your settings:\n\n| Environment Variable   | Description                                | Default Value           |\n| ---------------------- | ------------------------------------------ | ----------------------- |\n| `ANKI_CONNECT_URL`     | The URL of the Anki Connect API            | `http://localhost:8765` |\n| `ANKI_CONNECT_VERSION` | The version of the Anki Connect API to use | `6`                     |\n| `ANKI_MOCK_MODE`       | Enable mock mode for testing (true/false)  | `false`                 |\n\nIf the environment variables are not set, the server will use the default values.\n\n### Finding Your Local IP Address for AnkiConnect\n\nIf connecting to `localhost` doesn't work, you'll need to use your computer's local IP address instead. Configure your `.env` file with:\n\n```\nANKI_CONNECT_URL=http://YOUR_LOCAL_IP:8765\n```\n\nTo find your local IP address:\n\n- **macOS**: Open Terminal and run `ifconfig` or `ipconfig getifaddr en0` (for WiFi)\n- **Windows**: Open Command Prompt and run `ipconfig`\n- **Linux**: Open Terminal and run `ip addr show` or `hostname -I`\n\nLook for IPv4 addresses like `192.168.x.x` or `10.x.x.x` in the output.\n\n### Test Configuration\n\nFor testing, a separate configuration file `.env.test` is provided:\n\n```\ncp .env.example .env.test\n```\n\nEdit `.env.test` to set test-specific values:\n\n```\nANKI_CONNECT_URL=http://localhost:8765\nANKI_CONNECT_VERSION=6\nANKI_MOCK_MODE=true\n```\n\nTo run in test mode:\n\n```\nnpm run start:test\n```\n\n## Usage\n\n1. Make sure Anki is running with AnkiConnect installed\n2. Run the MCP server:\n   ```\n   npm start\n   ```\n\n## Configuring Claude Desktop\n\nTo use this MCP server with Claude Desktop:\n\n1. Open Claude Desktop\n2. Edit the Claude Desktop configuration file located at:\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n   - Linux: `~/.config/Claude/claude_desktop_config.json`\n\n3. Add the following configuration to the `mcpServers` section:\n\n```json\n{\n  \"mcpServers\": {\n    \"anki\": {\n      \"command\": \"node\",\n      \"args\": [\"path/to/anki-mcp-server/dist/index.js\"]\n    }\n  }\n}\n```\n\nReplace `\"path/to/anki-mcp-server\"` with the actual path to where you cloned this repository.\n\n## MCP Tool Usage\n\nOnce configured, you can use the following tools in Claude:\n\n### Example Usage\n\n```\nCould you analyze my Anki leech cards and suggest ways to improve my study?\n```\n\nClaude will use the MCP server to retrieve your leech cards and analyze them.\n\n## Available Tools\n\n### get_leech_cards\n\nRetrieves cards tagged as leeches from Anki.\n\nParameters:\n- `detailed` (optional, boolean, default: true): Whether to return comprehensive card data or just IDs\n- `count` (optional, number): Number of random cards to return (defaults to all cards)\n\n### tag_reviewed_cards\n\nAdds a date-stamped \"reviewed\" tag to specified cards. This allows you to track which cards you've reviewed with Claude.\n\nParameters:\n- `card_ids` (required, array of numbers): Array of card IDs to tag as reviewed\n- `custom_tag_prefix` (optional, string, default: \"è¦‹ç›´ã—\"): Custom prefix for the tag\n\nThe tag will be in the format `è¦‹ç›´ã—::YYYYMMDD` (or your custom prefix if specified).\n\nExample usage in Claude:\n```\nI've reviewed these cards, please tag them as reviewed: [1234567890, 1234567891]\n```\n\n## Troubleshooting\n\n- **\"Could not connect to Anki\"** - Make sure Anki is running and AnkiConnect is properly installed\n- **\"No leech cards found\"** - You don't have any cards tagged as \"leech\" in Anki\n- **Connection issues with localhost** - If you're unable to connect using `localhost`:\n  1. Find your local IP address as described in the Configuration section\n  2. Update your `.env` file to use `ANKI_CONNECT_URL=http://YOUR_LOCAL_IP:8765`\n  3. Make sure AnkiConnect is configured to allow connections from your IP address\n  4. Restart the MCP server after making these changes\n- **Tag not appearing** - Make sure you're providing valid card IDs to the `tag_reviewed_cards` tool\n\n## Testing Mode\n\nFor testing without affecting actual Anki data, you can use the mock mode:\n\n1. Set `ANKI_MOCK_MODE=true` in your `.env` file or use the provided `.env.test` file\n2. Run the server with `npm run start:test`\n\nIn mock mode, the server will simulate all Anki operations without actually connecting to Anki. This is useful for testing Claude integrations without risking data changes.\n\n## Development\n\nTo run the server in development mode with hot reloading:\n\n```\nnpm run dev\n```\n\nFor development with mock mode enabled:\n\n```\nnpm run dev:test\n```\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Chris-June--MCP-Server": {
      "owner": "Chris-June",
      "name": "MCP-Server",
      "url": "https://github.com/Chris-June/MCP-Server",
      "imageUrl": "https://github.com/Chris-June.png",
      "description": "Manages AI agents by defining contextual boundaries based on specific roles, ensuring tailored instructions and relevant memory for each agent while allowing for dynamic adjustments in tone and style. Supports the creation and management of custom roles with dedicated system prompts and memory isolation.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-24T09:58:54Z",
      "readme_content": "# Role-Specific Context MCP Server\n\nA Model Context Protocol (MCP) server that defines and governs contextual boundaries based on agent roles in your system.\n\n## Overview\n\nThis MCP server enables role-based context management for AI agents, allowing you to:\n\n- Establish clear instructions, objectives, and domain knowledge for each AI agent (Marketing Expert, Songwriter, Executive Assistant, etc.)\n- Keep role-relevant memory partitioned and scoped, preventing cross-contamination between different agent roles\n- Adapt tone and style dynamically (serious, witty, sarcastic) per role, with tone profiles baked into the prompt\n\n## Features\n\n### Role Management\n\n- Create, update, and delete custom roles\n- Pre-defined roles with specific expertise domains\n- Role-specific system prompts and instructions\n- Customizable tone profiles\n\n### Memory Management\n\n- Role-specific memory storage\n- Memory retrieval based on relevance to current query\n- Time-to-live (TTL) for memories\n- Memory limits per role\n\n### MCP Integration\n\n- Exposes roles as MCP resources\n- Provides tools for role management and query processing\n- Offers prompts for role-based interactions\n\n## Getting Started\n\n### Prerequisites\n\n- Node.js 18+\n- OpenAI API key\n\n### Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/yourusername/role-context-mcp.git\ncd role-context-mcp\n\n# Install dependencies\nnpm install\n\n# Set up environment variables\necho \"OPENAI_API_KEY=your_api_key_here\" > .env\n\n# Build the project\nnpm run build\n```\n\n### Running the Server\n\n```bash\n# Run the MCP server\nnpm start\n\n# Run the HTTP server for testing\nnpm run start:http\n```\n\n### Configuration\n\nThe server can be configured by modifying `src/config.ts`. Key configuration options include:\n\n- Default roles and their properties\n- Available tone profiles\n- Memory management settings\n- OpenAI model selection\n\n## MCP Integration\n\n### Resources\n\nThe server exposes the following resources:\n\n- `role://{roleId}` - Information about a specific role\n- `role://tones` - Available tone profiles\n\n### Tools\n\nThe server provides the following tools:\n\n- `process-with-role` - Process a query using a specific role\n- `create-role` - Create a new role\n- `update-role` - Update an existing role\n- `delete-role` - Delete a custom role\n- `change-role-tone` - Change the tone of a role\n- `store-memory` - Store a memory for a specific role\n- `clear-role-memories` - Clear all memories for a role\n\n### Prompts\n\nThe server provides the following prompts:\n\n- `role-{roleId}` - Use a specific role to process a request\n- `create-custom-role` - Create a new custom role\n\n## Example Usage\n\n### Processing a Query with a Role (MCP)\n\n```typescript\n// Example of using the process-with-role tool\nconst result = await client.executeToolRequest({\n  name: 'process-with-role',\n  parameters: {\n    roleId: 'marketing-expert',\n    query: 'How can I improve my social media engagement?',\n    customInstructions: 'Focus on B2B strategies'\n  }\n});\n```\n\n### Processing a Query with a Role (HTTP API)\n\n```typescript\n// Example of using the HTTP API\nconst response = await axios.post('http://localhost:3000/process', {\n  roleId: 'marketing-expert',\n  query: 'How can I improve my social media engagement?',\n  customInstructions: 'Focus on B2B strategies'\n});\n\nconsole.log(response.data.response);\n```\n\n### Creating a Custom Role\n\n```typescript\n// Example of using the create-role tool\nconst result = await client.executeToolRequest({\n  name: 'create-role',\n  parameters: {\n    id: 'tech-writer',\n    name: 'Technical Writer',\n    description: 'Specializes in clear, concise technical documentation',\n    instructions: 'Create documentation that is accessible to both technical and non-technical audiences',\n    domains: ['technical-writing', 'documentation', 'tutorials'],\n    tone: 'technical',\n    systemPrompt: 'You are an experienced technical writer with expertise in creating clear, concise documentation for complex systems.'\n  }\n});\n```\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "daigxok--gdsx": {
      "owner": "daigxok",
      "name": "gdsx",
      "url": "https://github.com/daigxok/gdsx",
      "imageUrl": "https://github.com/daigxok.png",
      "description": "Facilitates access to and manipulation of educational resources for analysis and development in reform initiatives. Supports collaboration and insight generation in educational research contexts.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2023-09-27T00:59:40Z",
      "readme_content": "# gdsx\nResearch on Educational Reform Projects\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "datalayer--jupyter-mcp-server": {
      "owner": "datalayer",
      "name": "jupyter-mcp-server",
      "url": "https://github.com/datalayer/jupyter-mcp-server",
      "imageUrl": "https://github.com/datalayer.png",
      "description": "Interact with Jupyter notebooks in a local JupyterLab environment, enabling the addition and execution of code or markdown cells.",
      "stars": 691,
      "forks": 117,
      "license": "BSD 3-Clause \"New\" or \"Revised\" License",
      "language": "Jupyter Notebook",
      "updated_at": "2025-10-03T20:57:42Z",
      "readme_content": "<!--\n  ~ Copyright (c) 2023-2024 Datalayer, Inc.\n  ~\n  ~ BSD 3-Clause License\n-->\n\n[![Datalayer](https://assets.datalayer.tech/datalayer-25.svg)](https://datalayer.io)\n\n[![Become a Sponsor](https://img.shields.io/static/v1?label=Become%20a%20Sponsor&message=%E2%9D%A4&logo=GitHub&style=flat&color=1ABC9C)](https://github.com/sponsors/datalayer)\n\n# ğŸªâœ¨ Jupyter MCP Server\n\n[![PyPI - Version](https://img.shields.io/pypi/v/jupyter-mcp-server)](https://pypi.org/project/jupyter-mcp-server)\n<a href=\"https://mseep.ai/app/datalayer-jupyter-mcp-server\">\n<img src=\"https://mseep.net/pr/datalayer-jupyter-mcp-server-badge.png\" alt=\"MseeP.ai Security Assessment Badge\" width=\"100\" />\n</a>\n\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/datalayer/jupyter-mcp-server)](https://archestra.ai/mcp-catalog/datalayer__jupyter-mcp-server)\n\n> ğŸš¨ **NEW IN 0.14.0:** Multi-notebook support! You can now seamlessly switch between multiple notebooks in a single session. [Read more in the release notes.](https://jupyter-mcp-server.datalayer.tech/releases)\n\n**Jupyter MCP Server** is a [Model Context Protocol](https://modelcontextprotocol.io) (MCP) server implementation that enables **real-time** interaction with ğŸ““ Jupyter Notebooks, allowing AI to edit, document and execute code for data analysis, visualization etc.\n\nCompatible with any Jupyter deployment (local, JupyterHub, ...) and with [Datalayer](https://datalayer.ai/) hosted Notebooks.\n\n## ğŸš€ Key Features\n\n- âš¡ **Real-time control:** Instantly view notebook changes as they happen.\n- ğŸ” **Smart execution:** Automatically adjusts when a cell run fails thanks to cell output feedback.\n- ğŸ§  **Context-aware:** Understands the entire notebook context for more relevant interactions.\n- ğŸ“Š **Multimodal support:** Support different output types, including images, plots, and text.\n- ğŸ“ **Multi-notebook support:** Seamlessly switch between multiple notebooks.\n- ğŸ¤ **MCP-compatible:** Works with any MCP client, such as Claude Desktop, Cursor, Windsurf, and more.\n\n![Jupyter MCP Server Demo](https://assets.datalayer.tech/jupyter-mcp/mcp-demo-multimodal.gif)\n\nğŸ› ï¸ This MCP offers multiple tools such as `insert_cell`, `execute_cell`, `list_all_files`, `read_cell`, and more, enabling advanced interactions with Jupyter notebooks. Explore our [tools documentation](https://jupyter-mcp-server.datalayer.tech/tools) to learn about all the tools powering Jupyter MCP Server.\n\n## ğŸ Getting Started\n\nFor comprehensive setup instructionsâ€”including `Streamable HTTP` transport and advanced configurationâ€”check out [our documentation](https://jupyter-mcp-server.datalayer.tech/). Or, get started quickly with `JupyterLab` and `stdio` transport here below.\n\n### 1. Set Up Your Environment\n\n```bash\npip install jupyterlab==4.4.1 jupyter-collaboration==4.0.2 ipykernel\npip uninstall -y pycrdt datalayer_pycrdt\npip install datalayer_pycrdt==0.12.17\n```\n\n### 2. Start JupyterLab\n\n```bash\n# make jupyterlab\njupyter lab --port 8888 --IdentityProvider.token MY_TOKEN --ip 0.0.0.0\n```\n\n> [!NOTE]\n> If you are running notebooks through JupyterHub instead of JupyterLab as above, you should:\n>\n> - Set the environment variable `JUPYTERHUB_ALLOW_TOKEN_IN_URL=1` in the single-user environment.\n> - Ensure your API token (`MY_TOKEN`) is created with `access:servers` scope in the Hub.\n\n\n### 3. Configure Your Preferred MCP Client\n\n> [!TIP]\n>\n> 1. Ensure the `port` of the `DOCUMENT_URL` and `RUNTIME_URL` match those used in the `jupyter lab` command.\n>\n> 2. In a basic setup, `DOCUMENT_URL` and `RUNTIME_URL` are the same. `DOCUMENT_TOKEN`, and `RUNTIME_TOKEN` are also the same and is actually the Jupyter Token.\n>\n> 3. The `DOCUMENT_ID` parameter specifies the path to the notebook you want to connect to. It should be relative to the directory where JupyterLab was started.  \n> \n> - **Optional:** If you omit `DOCUMENT_ID`, the MCP client can automatically list all available notebooks on the Jupyter server, allowing you to select one interactively via your prompts.\n> - **Flexible:** Even if you set `DOCUMENT_ID`, the MCP client can still browse, list, switch to, or even create new notebooks at any time.\n> \n\n#### MacOS and Windows\n\n```json\n{\n  \"mcpServers\": {\n    \"jupyter\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \"-i\", \"--rm\",\n        \"-e\", \"DOCUMENT_URL\",\n        \"-e\", \"DOCUMENT_TOKEN\",\n        \"-e\", \"DOCUMENT_ID\",\n        \"-e\", \"RUNTIME_URL\",\n        \"-e\", \"RUNTIME_TOKEN\",\n        \"-e\", \"ALLOW_IMG_OUTPUT\",\n        \"datalayer/jupyter-mcp-server:latest\"\n      ],\n      \"env\": {\n        \"DOCUMENT_URL\": \"http://host.docker.internal:8888\",\n        \"DOCUMENT_TOKEN\": \"MY_TOKEN\",\n        \"DOCUMENT_ID\": \"notebook.ipynb\",\n        \"RUNTIME_URL\": \"http://host.docker.internal:8888\",\n        \"RUNTIME_TOKEN\": \"MY_TOKEN\",\n        \"ALLOW_IMG_OUTPUT\": \"true\"\n      }\n    }\n  }\n}\n```\n\n#### Linux\n\n```json\n{\n  \"mcpServers\": {\n    \"jupyter\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \"-i\", \"--rm\",\n        \"-e\", \"DOCUMENT_URL\",\n        \"-e\", \"DOCUMENT_TOKEN\",\n        \"-e\", \"DOCUMENT_ID\",\n        \"-e\", \"RUNTIME_URL\",\n        \"-e\", \"RUNTIME_TOKEN\",\n        \"-e\", \"ALLOW_IMG_OUTPUT\",\n        \"--network=host\",\n        \"datalayer/jupyter-mcp-server:latest\"\n      ],\n      \"env\": {\n        \"DOCUMENT_URL\": \"http://localhost:8888\",\n        \"DOCUMENT_TOKEN\": \"MY_TOKEN\",\n        \"DOCUMENT_ID\": \"notebook.ipynb\",\n        \"RUNTIME_URL\": \"http://localhost:8888\",\n        \"RUNTIME_TOKEN\": \"MY_TOKEN\",\n        \"ALLOW_IMG_OUTPUT\": \"true\"\n      }\n    }\n  }\n}\n```\n\nFor detailed instructions on configuring various MCP clientsâ€”including [Claude Desktop](https://jupyter-mcp-server.datalayer.tech/clients/claude_desktop), [VS Code](https://jupyter-mcp-server.datalayer.tech/clients/vscode), [Cursor](https://jupyter-mcp-server.datalayer.tech/clients/cursor), [Cline](https://jupyter-mcp-server.datalayer.tech/clients/cline), and [Windsurf](https://jupyter-mcp-server.datalayer.tech/clients/windsurf) â€” see the [Clients documentation](https://jupyter-mcp-server.datalayer.tech/clients).\n\n## ğŸ“š Resources\n\nLooking for blog posts, videos, or other materials about Jupyter MCP Server?\n\nğŸ‘‰ Visit the [Resources section](https://jupyter-mcp-server.datalayer.tech/resources).\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "devshark--personality-test-mcp": {
      "owner": "devshark",
      "name": "personality-test-mcp",
      "url": "https://github.com/devshark/personality-test-mcp",
      "imageUrl": "https://github.com/devshark.png",
      "description": "Administer personality tests and provide assessments based on user responses. Score responses according to established personality frameworks and enable personalized AI feedback.",
      "stars": 1,
      "forks": 0,
      "license": "ISC License",
      "language": "Python",
      "updated_at": "2025-08-24T04:58:02Z",
      "readme_content": "# Personality Test MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@devshark/personality-test-mcp)](https://smithery.ai/server/@devshark/personality-test-mcp)\n\nThis is a Model Context Protocol (MCP) implementation for personality testing. It allows AI models to administer personality tests, score responses, and provide personality type assessments.\n\n## Features\n\n- Administers a personality questionnaire to users\n- Scores responses according to established personality frameworks\n- Returns personality type and brief descriptions\n- Integrates with Ollama for personalized AI interactions\n- Allows users to go back and change previous answers\n\n## Components\n\n### Server\n\nThe MCP server handles:\n- Serving personality test questions\n- Processing and scoring user responses\n- Determining personality types\n- Storing user profiles (optional)\n\n### Client\n\nThe client interface allows:\n- Users to take the personality test\n- Viewing results and personality descriptions\n- Integration with Ollama for personalized interactions\n\n## Personality Framework\n\nThis implementation uses a simplified version of the Myers-Briggs Type Indicator (MBTI) framework, which categorizes personalities along four dimensions:\n\n1. **Extraversion (E) vs. Introversion (I)**: Where you focus your attention and get energy\n2. **Sensing (S) vs. Intuition (N)**: How you take in information\n3. **Thinking (T) vs. Feeling (F)**: How you make decisions\n4. **Judging (J) vs. Perceiving (P)**: How you deal with the outer world\n\nThe combination of preferences results in 16 distinct personality types (e.g., INTJ, ESFP).\n\n## Getting Started\n\n### Prerequisites\n\n- Python 3.8 or higher\n- pip (Python package manager)\n- Ollama (optional, for personalized AI interactions)\n\n### Installation and Setup\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/yourusername/model-context-protocols.git\n   cd model-context-protocols/personality-test-mcp\n   ```\n\n2. Create and activate a virtual environment:\n   ```bash\n   python3 -m venv venv\n   \n   # On macOS/Linux\n   source venv/bin/activate\n   \n   # On Windows\n   venv\\Scripts\\activate\n   ```\n\n3. Install dependencies:\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n### Running the Server\n\n1. Start the MCP server:\n   ```bash\n   cd server\n   python app.py\n   ```\n   The server will start on http://localhost:8000\n\n### Running the Client\n\n1. In a new terminal, activate the virtual environment:\n   ```bash\n   cd personality-test-mcp\n   source venv/bin/activate  # On macOS/Linux\n   ```\n\n2. Run the basic client:\n   ```bash\n   cd client\n   python mcp_client.py\n   ```\n\n### Using Ollama Integration\n\nIf you have Ollama installed and running:\n\n1. Make sure Ollama is running:\n   ```bash\n   ollama serve\n   ```\n\n2. Run the Ollama integration client:\n   ```bash\n   cd client\n   python ollama_integration.py --model llama3\n   ```\n   You can replace `llama3` with any model you have available in Ollama.\n\n### Using the Demo Script\n\nFor convenience, you can use the provided demo script:\n\n1. Make the script executable:\n   ```bash\n   chmod +x run_demo.sh\n   ```\n\n2. Run the demo:\n   ```bash\n   ./run_demo.sh\n   ```\n\nThis script will:\n- Set up a virtual environment\n- Install dependencies\n- Start the server\n- Run either the basic client or Ollama integration (if Ollama is detected)\n\n## Docker Support\n\nYou can also run the server using Docker:\n\n```bash\ndocker build -t personality-test-mcp .\ndocker run -p 8000:8000 personality-test-mcp\n```\n\n## Usage with AI Models\n\nAI models can use this MCP to:\n1. Administer personality tests to users\n2. Retrieve personality profiles for personalized interactions\n3. Adjust communication style based on personality preferences\n\n## API Endpoints\n\n- `POST /mcp`: Main MCP endpoint for personality test interactions\n- `GET /health`: Health check endpoint\n\n## License\n\nThis project is licensed under the [ISC license](LICENSE).\n\n## Author\n\n&copy; Anthony Lim\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "dhkts1--sequentialStory": {
      "owner": "dhkts1",
      "name": "sequentialStory",
      "url": "https://github.com/dhkts1/sequentialStory",
      "imageUrl": "https://github.com/dhkts1.png",
      "description": "Enhances problem-solving and memory retention by structuring complex problems as engaging stories or sequential thoughts. Integrates with AI systems using the Model Context Protocol and offers techniques for narrative-based and sequential thinking.",
      "stars": 14,
      "forks": 2,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-07-07T06:06:30Z",
      "readme_content": "# Sequential Story MCP Server\n\nA Model Context Protocol (MCP) server for Sequential Thinking and Sequential Story as mnemonic techniques for problem-solving.\n\n## Overview\n\nThis project offers two complementary MCP tools for structuring complex problems:\n\n1. **Sequential Story** - A narrative-based approach to sequential thinking. Instead of tracking abstract thoughts, it structures problems as story elements with characters, settings, and plot developments to make them more memorable and engaging.\n\n2. **Sequential Thinking** - A pure Python port of the JavaScript implementation, eliminating Node.js dependencies\n\nBoth approaches leverage the power of sequencing and structure to enhance memory retention and problem understanding.\n\n## Features\n\n### Sequential Story\n- Build problem solutions as narrative sequences\n- Revise and branch story elements as needed\n- Track characters, settings, tones, and plot points\n- Formatted, color-coded display of story elements\n\n### Sequential Thinking\n- Structure problems as a sequence of thoughts\n- Revise or branch thinking paths as needed\n- Generate and verify solution hypotheses\n- Track thinking process completion\n- Pure Python implementation (no Node.js required)\n\n### Common Features\n- Formatted, color-coded display of elements\n- Full MCP protocol support for integration with AI systems\n- Support for branching and revision\n\n## Installation\n\n### During Development\n\nWhen working with the package locally before publishing:\n\n```bash\n# Clone the repository\ngit clone https://github.com/dhkts1/sequentialStory\ncd sequentialStory\n\n# Install dependencies using uv\nuv venv\nsource .venv/bin/activate\nuv sync\n\n# Install with development dependencies\nuv sync --group dev\n\n```\n\n\n\n### Installing with MCP\n\n```bash\n# Install in the Claude desktop app\nmcp install -e . src/cli.py -n \"Sequential Story\"\n\n# Install with only the Sequential Thinking tool\nmcp install -e . src/cli.py -n \"Sequential Thinking\" --env-var \"TOOLS='[\\\"thinking\\\"]'\"\n\n# Install with only the Sequential Story tool explicitly\nmcp install -e . src/cli.py -n \"Sequential Story\" --env-var \"TOOLS='[\\\"story\\\"]'\"\n\n# Install with both tools\nmcp install -e . src/cli.py -n \"Sequential Tools\" --env-var \"TOOLS='[\\\"thinking\\\",\\\"story\\\"]'\"\n```\n\nFor development:\n\n```bash\n# For development with the MCP Inspector\nmcp dev src/__main__.py:main\n```\n\nYou can also configure Claude desktop to use the tool with `uvx` by adding this to your Claude mcpServers.json:\n\n```json\n\"mcpServers\": {\n  \"Sequential Story\": {\n    \"command\": \"uvx\",\n    \"args\": [\n      \"sequential-story\"\n    ]\n  }\n}\n```\n\nThe environment variable `TOOLS` controls which tools are enabled. By default, only the Sequential Story tool is enabled, but the Sequential Thinking tool can be added as needed.\n\nThis is useful when you want to focus on a specific problem-solving approach or when integrating with other MCP tools. You can also update the environment variables directly in the Claude desktop app after installation.\n\n### Example story element\n\n```json\n{\n  \"element\": \"Our protagonist, a data scientist named Alex, encounters a mysterious pattern in the customer behavior data.\",\n  \"elementNumber\": 1,\n  \"totalElements\": 5,\n  \"nextElementNeeded\": true,\n  \"character\": \"Alex (data scientist)\",\n  \"setting\": \"Data analysis lab\",\n  \"tone\": \"Mysterious\",\n  \"plotPoint\": \"Discovery of pattern\"\n}\n```\n\n### Example thought element\n\n```json\n{\n  \"thought\": \"The problem requires analyzing multiple data sources to identify correlations between customer behavior and sales patterns.\",\n  \"thoughtNumber\": 1,\n  \"totalThoughts\": 5,\n  \"nextThoughtNeeded\": true\n}\n```\n\n## Development\n\n```bash\n# Install pre-commit hooks\nuv run pre-commit install\n\n# Run all pre-commit checks\npoe pre\n```\n## Credits\n\nThis project builds on the concepts of sequential thinking and structured problem-solving, adapting these approaches to both analytical and narrative frameworks for enhanced memory and problem-solving.\n\nThe Sequential Thinking implementation is a pure Python port inspired by the JavaScript implementation from the Model Context Protocol repositories:\nhttps://github.com/modelcontextprotocol/servers/tree/main/src/sequentialthinking",
      "npm_url": "",
      "npm_downloads": 0
    },
    "dhkim0124--anki-mcp-server": {
      "owner": "dhkim0124",
      "name": "anki-mcp-server",
      "url": "https://github.com/dhkim0124/anki-mcp-server",
      "imageUrl": "https://github.com/dhkim0124.png",
      "description": "Facilitates the creation and management of Anki flashcards using natural language commands through integration with Claude. Supports adding vocabulary, example sentences, and managing flashcard decks seamlessly.",
      "stars": 4,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-19T21:06:56Z",
      "readme_content": "# anki-mcp-server\n\n[![smithery badge](https://smithery.ai/badge/@dhkim0124/anki-mcp-server)](https://smithery.ai/server/@dhkim0124/anki-mcp-server)\n\n*Read this in other languages: [English](README.md), [í•œêµ­ì–´](docs/README_KO.md)*\n\nA Model Context Protocol (MCP) server that connects Claude and Anki, allowing you to easily create flashcards using natural language.\n\n## Introduction\n\nanki-mcp-server acts as a bridge between Claude and the Anki app, enabling communication between them. This allows you to give natural language commands to Claude to create and manage Anki flashcards. For example, if you request \"Add an easy Japanese vocabulary card to my Japanese deck,\" Claude will automatically create an appropriate card.\n\n## Requirements\n\n- Python 3.8 or higher\n- Anki 2.1.x or higher\n- AnkiConnect add-on\n- Claude Desktop (or an environment with access to Claude API)\n\n## Installation\n\n### 1. Setting up Anki and AnkiConnect\n\n1. Install [Anki](https://apps.ankiweb.net/).\n2. Install the AnkiConnect add-on:\n   - Run Anki and select `Tools > Add-ons > Get Add-ons` from the top menu\n   - Enter the code `2055492159` and click 'OK'\n   - Restart Anki\n\n### 2. Installing anki-mcp-server\n\n```bash\n# Clone the repository\ngit clone https://github.com/dhkim0124/anki-mcp-server.git\ncd anki-mcp-server\n\n# Create and activate a virtual environment (optional)\npython -m venv venv\nsource venv/bin/activate  # Windows: venv\\Scripts\\activate\n\n# Install required packages\npip install -r requirements.txt\n```\n\n## Configuration\n\n### Claude Desktop Setup\n\nModify the Claude Desktop configuration file to register the MCP server:\n\n1. Claude Desktop configuration file location:\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Linux: `~/.config/Claude/claude_desktop_config.json`\n\n2. Add the following content to the configuration file:\n\n```json\n{\n  \"mcpServers\": {\n    \"anki-mcp\": {\n      \"command\": \"python\",\n      \"args\": [\"path/anki_server.py\"],\n      \"env\": {}\n    }\n  }\n}\n```\n\nReplace `path/anki_server.py` with the absolute path to your anki_server.py file.\n\n## How to Use\n\n1. Run the Anki application and keep it running in the background.\n2. Launch Claude Desktop.\n3. You can give Claude natural language commands such as:\n\n### Example Commands\n\n- \"Add an easy Japanese vocabulary card to my Japanese deck\"\n- \"Create a card for the English word 'perseverance' with its meaning and example sentences\"\n- \"Summarize the programming concepts I learned today into a card\"\n- \"Create 5 history timeline cards\"\n\nClaude will interpret these requests and create appropriate cards in Anki through the MCP server.\n\n## Key Features\n\n### Card Creation Features\n\n- Basic question-answer format card creation\n- Language learning card creation (word, meaning, example sentences)\n- Automatic tag addition\n- Adding cards to multiple decks\n\n### Deck Management Features\n\n- View available deck list\n- Create new decks\n- Search for cards in specific decks\n\n## Troubleshooting\n\n### Connection Issues\n\n- **Check if Anki is running**: The MCP server requires Anki to be running to communicate with it.\n- **Verify AnkiConnect**: Make sure AnkiConnect is properly installed. Visit `http://localhost:8765` in your web browser to confirm you see the \"AnkiConnect v.6\" message.\n- **Firewall settings**: Windows users may need to allow firewall access for Anki.\n\n### MCP Server Issues\n\n- **Check logs**: If problems occur, check the server logs for error messages.\n- **Restart**: If issues persist, try restarting Anki, Claude Desktop, and the MCP server.\n\n## Extension and Contribution\n\nIf you'd like to contribute to the project, fork the GitHub repository and submit a pull request. We welcome contributions in the following areas:\n\n- Support for new card types\n- Improved language support\n- Interface improvements\n- Documentation improvements\n\n## License\n\nThis project is distributed under the MIT License. See the LICENSE file for details.\n\n## Contact\n\nFor issues or questions, please contact us through GitHub issues.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "djalal--quran-mcp-server": {
      "owner": "djalal",
      "name": "quran-mcp-server",
      "url": "https://github.com/djalal/quran-mcp-server",
      "imageUrl": "https://github.com/djalal.png",
      "description": "Access the Quran.com corpus to retrieve chapters, verses, translations, and tafsirs through a standardized API. Facilitate integration of Quranic content into applications via a structured set of endpoints.",
      "stars": 50,
      "forks": 12,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-02T22:12:12Z",
      "readme_content": "# MCP Server for Quran.com API\n\nMCP server to interact with Quran.com corpus via the official [REST API v4](https://api-docs.quran.com/docs/content_apis_versioned/4.0.0/content-apis).\n\n## Overview\n\nThis is a Model Context Protocol (MCP) server generated from the [OpenAPI specification](v4.json).\n\n## Endpoints\n\nThe following endpoints from the API have been made available as tools, that LLMs can use via compatible clients.\n\n### Chapters\n* GET /chapters - List Chapters\n* GET /chapters/{id} - Get Chapter\n* GET /chapters/{chapter_id}/info - Get Chapter Info\n\n### Verses\n* GET /verses/by_chapter/{chapter_number} - Get verses by Chapter / Surah number\n* GET /verses/by_page/{page_number} - Get all verses of a specific Madani Mushaf page\n* GET /verses/by_juz/{juz_number} - Get verses by Juz number\n* GET /verses/by_hizb/{hizb_number} - Get verses by Hizb number\n* GET /verses/by_rub/{rub_el_hizb_number} - Get verses by Rub el Hizb number\n* GET /verses/by_key/{verse_key} - Get verse by key\n* GET /verses/random - Get a random verse\n\n### Juzs\n* GET /juzs - Get list of all juzs\n\n### Search\n* GET /search - Search the Quran for specific terms\n\n### Translations\n* GET /resources/translations - Get list of available translations\n* GET /resources/translations/{translation_id}/info - Get information of a specific translation\n\n### Tafsirs\n* GET /resources/tafsirs - Get list of available tafsirs\n* GET /resources/tafsirs/{tafsir_id}/info - Get the information of a specific tafsir\n* GET /quran/tafsirs/{tafsir_id} - Get a single tafsir\n\n### Audio\n* GET /resources/chapter_reciters - List of Chapter Reciters\n* GET /resources/recitation_styles - Get the available recitation styles\n\n### Languages\n* GET /resources/languages - Get all languages\n\n## Setup\n\n### Requirements\n\n* Node.js 22+\n* Docker\n\n### Building the Docker Image\n\nBefore using the Docker-based production mode, you need to build the Docker image:\n\n```bash\n# Build the Docker image\ndocker build -t quran-mcp-server .\n```\n\n## Claude Desktop Integration\n\nTo use this MCP server with Claude Desktop, add the following configuration to your `claude_desktop_config.json` file (typically located at `~/Library/Application Support/Claude/claude_desktop_config.json` on macOS or `%APPDATA%\\Claude\\claude_desktop_config.json` on Windows):\n\n### Docker-based Production Mode\n\n```json\n{\n  \"mcpServers\": {\n    \"quran-api\": {\n      \"command\": \"docker\",\n      \"args\": [\"run\", \"-i\", \"--rm\", \"--init\", \"-e\", \"API_KEY=your_api_key_if_needed\", \"-e\", \"VERBOSE_MODE=true\", \"quran-mcp-server\"],\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n### Production Mode (Node.js)\n\n```json\n{\n  \"mcpServers\": {\n    \"quran-api\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/quran-mcp-server/dist/src/server.js\"],\n      \"env\": {\n        \"API_KEY\": \"your_api_key_if_needed\",\n        \"VERBOSE_MODE\": \"true\" // Set to \"true\" to enable verbose logging\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n### Development Mode\n\n```json\n{\n  \"mcpServers\": {\n    \"quran-api\": {\n      \"command\": \"npx\",\n      \"args\": [\"ts-node\", \"/path/to/quran-mcp-server/src/server.ts\"],\n      \"env\": {\n        \"API_KEY\": \"your_api_key_if_needed\",\n        \"VERBOSE_MODE\": \"true\" // Set to \"true\" to enable verbose logging\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n**Important Notes:**\n- Replace `/path/to/quran-mcp-server` with the actual path to this repository on your system\n- You'll need to build the project first with `npm run build` or `docker build -t quran-mcp-server .` if using the production mode configuration\n- Replace `your_api_key_if_needed` with an actual API key if required by the Quran.com API\n- If you already have other MCP servers configured, add this configuration to the existing `mcpServers` object\n- After updating the configuration, restart Claude Desktop for the changes to take effect\n\n## Environment Variables\n\n* `API_KEY`: API key for authentication\n* `PORT`: Server port (default: 8000 or 3000 depending on language)\n* `VERBOSE_MODE`: Set to 'true' to enable verbose logging of API requests and responses (default: false)\n\n## Verbose Mode\n\nWhen `VERBOSE_MODE` is set to 'true', the server will log detailed information about API requests and responses to the console. This is useful for debugging and monitoring API interactions.\n\nThe verbose logging includes:\n\n* **Requests**: Logs the tool name and arguments for each incoming request\n* **Responses**: Logs the tool name and result data for each response\n* **Errors**: Logs detailed error information including error name, message, and stack trace when available\n\nEach log entry is timestamped and prefixed with the log type (REQUEST, RESPONSE, or ERROR) for easy identification.\n\n## Testing\n\n```bash\n# Run tests\nnpm test\n```\n\n## License\n\nThis project is licensed under the MIT License.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "DMontgomery40--mcp-server-birdstats": {
      "owner": "DMontgomery40",
      "name": "mcp-server-birdstats",
      "url": "https://github.com/DMontgomery40/mcp-server-birdstats",
      "imageUrl": "https://github.com/DMontgomery40.png",
      "description": "Analyze BirdNET-Pi data and eBird observations through a natural language interface while providing visual representations of the data.",
      "stars": 1,
      "forks": 7,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2024-12-13T00:47:19Z",
      "readme_content": "# mcp-server-birdstats\n\n> Cross-reference your BirdNET-Pi data with eBird observations using natural language\n\n## Overview\n\nThis MCP plugin allows you to analyze BirdNET-Pi/BirdWeather detections by connecting them with eBird's extensive database. \n\n## Features\n\n- Natural language interface for querying birdnet-pi / birdweather, and eBird data\n- Cross-reference BirdWeather detections with eBird observations\n- Data-driven visualizations with React artifacts\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/yourusername/mcp-server-birdstats.git\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n## Claude Config\n```\n\"mcp-birdstats\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-birdstats\"]\n    },\n```\n\n\n## Usage\n\nThe plugin processes natural language queries about your bird detection data. Example queries:\n\n- \"My BirdNET heard a Swainson's Thrush - is that unusual?\"\n- \"What's my station's rarest detection this week?\"\n- \"Graph my detections by time of day\"\n- \"Are others seeing these warblers on eBird?\"\n\n## Data Integrity\n\nThis plugin strictly adheres to data integrity principles:\n- Only uses actual API response data\n- Never creates example or estimated data\n- Always shows observation counts with percentages\n- Clear indication when data is unavailable\n\n## Core Logic\n\nThe core functionality is contained in a single text file under `src/index.txt` which includes:\n- BirdWeather API interactions\n- eBird API interactions\n- Data analysis functions\n- Type definitions\n- Helper utilities\n\n## API Integration\n\n### BirdWeather API\n- Station statistics\n- Species lists\n- Detection records\n\n### eBird API\n- Recent observations\n- Notable sightings\n- Hotspot data\n- Species information\n\n## License\n\nMIT\n\n## Support\n\nFor issues and feature requests, please open an issue on the GitHub repository.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "DMontgomery40--mcp-canvas-lms": {
      "owner": "DMontgomery40",
      "name": "mcp-canvas-lms",
      "url": "https://github.com/DMontgomery40/mcp-canvas-lms",
      "imageUrl": "https://github.com/DMontgomery40.png",
      "description": "Manage courses, assignments, enrollments, and grades within the Canvas LMS by interacting with the Canvas API. Automate educational tasks and streamline course management for educators and administrators.",
      "stars": 57,
      "forks": 22,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T22:31:58Z",
      "readme_content": "# Canvas MCP Server v2.2.0\n\n> A comprehensive Model Context Protocol (MCP) server for Canvas LMS with complete student, instructor, and account administration functionality\n\n## ğŸš€ What's New in v2.2.0\n\n- **ğŸ”§ FIXED**: Course creation \"page not found\" error (missing `account_id` parameter)\n- **ğŸ‘¨â€ğŸ’¼ Account Management**: Complete account-level administration tools\n- **ğŸ“Š Reports & Analytics**: Generate and access Canvas account reports  \n- **ğŸ‘¥ User Management**: Create and manage users at the account level\n- **ğŸ¢ Multi-Account Support**: Handle account hierarchies and sub-accounts\n- **âœ… API Compliance**: All endpoints now follow proper Canvas API patterns\n\n## ğŸ¯ Key Features\n\n### ğŸ“ For Students\n- **Course Management**: Access all courses, syllabi, and course materials\n- **Assignment Workflow**: View, submit (text/URL/files), and track assignments\n- **Communication**: Participate in discussions, read announcements, send messages\n- **Progress Tracking**: Monitor grades, module completion, and calendar events\n- **Quizzes**: Take quizzes, view results and feedback\n- **File Access**: Browse and download course files and resources\n\n### ğŸ‘¨â€ğŸ« For Instructors\n- **Course Creation**: Create and manage course structure *(now with proper account support)*\n- **Grading**: Grade submissions, provide feedback, manage rubrics\n- **User Management**: Enroll students, manage permissions\n- **Content Management**: Create assignments, quizzes, discussions\n\n### ğŸ‘¨â€ğŸ’¼ For Account Administrators (NEW!)\n- **Account Management**: Manage institutional Canvas accounts\n- **User Administration**: Create and manage users across accounts\n- **Course Oversight**: List and manage all courses within accounts\n- **Reporting**: Generate enrollment, grade, and activity reports\n- **Sub-Account Management**: Handle account hierarchies and structures\n\n### ğŸ› ï¸ Technical Excellence\n- **Robust API**: Automatic retries, pagination, comprehensive error handling\n- **Cloud Ready**: Docker containers, Kubernetes manifests, health checks\n- **Well Tested**: Unit tests, integration tests, mocking, coverage reports\n- **Type Safe**: Full TypeScript implementation with strict types\n- **50+ Tools**: Comprehensive coverage of Canvas LMS functionality\n\n## Quick Start\n\n### Option 1: Claude Desktop Integration (Recommended MCP Setup)\n\nAdd to `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"canvas-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"canvas-mcp-server\"],\n      \"env\": {\n        \"CANVAS_API_TOKEN\": \"your_token_here\",\n        \"CANVAS_DOMAIN\": \"your_school.instructure.com\"\n      }\n    }\n  }\n}\n```\n\n### Option 2: NPM Package\n\n```bash\n# Install globally\nnpm install -g canvas-mcp-server\n\n# Configure\nexport CANVAS_API_TOKEN=\"your_token_here\"\nexport CANVAS_DOMAIN=\"your_school.instructure.com\"\n\n# Run\ncanvas-mcp-server\n```\n\n### Option 3: Docker\n\n```bash\ndocker run -d \\\n  --name canvas-mcp \\\n  -e CANVAS_API_TOKEN=\"your_token\" \\\n  -e CANVAS_DOMAIN=\"school.instructure.com\" \\\n  ghcr.io/dmontgomery40/mcp-canvas-lms:latest\n```\n\n## ğŸ’¼ Account Admin Workflow Examples\n\n### Create a New Course (FIXED!)\n```\n\"Create a new course called 'Advanced Biology' in account 123\"\n```\n**Now properly creates courses with required account_id parameter**\n\n### Manage Users\n```\n\"Create a new student user John Doe with email john.doe@school.edu in our main account\"\n```\n**Creates user accounts with proper pseudonym and enrollment setup**\n\n### Generate Reports\n```\n\"Generate an enrollment report for account 456 for the current term\"\n```\n**Initiates Canvas reporting system for institutional analytics**\n\n### List Account Courses\n```\n\"Show me all published Computer Science courses in our Engineering account\"\n```\n**Advanced filtering and searching across account course catalogs**\n\n## ğŸ“ Student Workflow Examples\n\n### Check Today's Assignments\n```\n\"What assignments do I have due this week?\"\n```\n**Lists upcoming assignments with due dates, points, and submission status**\n\n### Submit an Assignment\n```\n\"Help me submit my essay for English 101 Assignment 3\"\n```\n**Guides through text submission with formatting options**\n\n### Check Grades\n```\n\"What's my current grade in Biology?\"\n```\n**Shows current scores, grades, and assignment feedback**\n\n### Participate in Discussions\n```\n\"Show me the latest discussion posts in my Philosophy class\"\n```\n**Displays recent discussion topics and enables posting responses**\n\n### Track Progress\n```\n\"What modules do I need to complete in Math 200?\"\n```\n**Shows module completion status and next items to complete**\n\n## Getting Canvas API Token\n\n1. **Log into Canvas** â†’ Account â†’ Settings\n2. **Scroll to \"Approved Integrations\"**\n3. **Click \"+ New Access Token\"**\n4. **Enter description**: \"Claude MCP Integration\"\n5. **Copy the generated token** Save securely!\n\nâš ï¸ **Account Admin Note**: For account-level operations, ensure your API token has administrative privileges.\n\n## Production Deployment\n\n### Docker Compose\n```bash\ngit clone https://github.com/DMontgomery40/mcp-canvas-lms.git\ncd mcp-canvas-lms\ncp .env.example .env\n# Edit .env with your Canvas credentials\ndocker-compose up -d\n```\n\n### Kubernetes\n```bash\nkubectl create secret generic canvas-mcp-secrets \\\n  --from-literal=CANVAS_API_TOKEN=\"your_token\" \\\n  --from-literal=CANVAS_DOMAIN=\"school.instructure.com\"\n\nkubectl apply -f k8s/\n```\n\n### Health Monitoring\n```bash\n# Check application health\ncurl http://localhost:3000/health\n\n# Or use the built-in health check\nnpm run health-check\n```\n\n## Development\n\n```bash\n# Setup development environment\ngit clone https://github.com/DMontgomery40/mcp-canvas-lms.git\ncd mcp-canvas-lms\nnpm install\n\n# Start development with hot reload\nnpm run dev:watch\n\n# Run tests\nnpm run test\nnpm run coverage\n\n# Code quality\nnpm run lint\nnpm run type-check\n```\n\n## ğŸ“š Available Tools (50+ Tools)\n\n<details>\n<summary><strong>ğŸ“ Core Student Tools (Click to expand)</strong></summary>\n\n- `canvas_health_check` - Check API connectivity\n- `canvas_list_courses` - List all your courses\n- `canvas_get_course` - Get detailed course info\n- `canvas_list_assignments` - List course assignments\n- `canvas_get_assignment` - Get assignment details\n- `canvas_submit_assignment` - Submit assignment work\n- `canvas_get_submission` - Check submission status\n- `canvas_list_modules` - List course modules\n- `canvas_get_module` - Get module details\n- `canvas_list_module_items` - List items in a module\n- `canvas_mark_module_item_complete` - Mark items complete\n- `canvas_list_discussion_topics` - List discussion topics\n- `canvas_get_discussion_topic` - Get discussion details\n- `canvas_post_to_discussion` - Post to discussions\n- `canvas_list_announcements` - List course announcements\n- `canvas_get_user_grades` - Get your grades\n- `canvas_get_course_grades` - Get course-specific grades\n- `canvas_get_dashboard` - Get dashboard info\n- `canvas_get_dashboard_cards` - Get course cards\n- `canvas_get_upcoming_assignments` - Get due dates\n- `canvas_list_calendar_events` - List calendar events\n- `canvas_list_files` - List course files\n- `canvas_get_file` - Get file details\n- `canvas_list_folders` - List course folders\n- `canvas_list_pages` - List course pages\n- `canvas_get_page` - Get page content\n- `canvas_list_conversations` - List messages\n- `canvas_get_conversation` - Get conversation details\n- `canvas_create_conversation` - Send messages\n- `canvas_list_notifications` - List notifications\n- `canvas_get_syllabus` - Get course syllabus\n- `canvas_get_user_profile` - Get user profile\n- `canvas_update_user_profile` - Update profile\n\n</details>\n\n<details>\n<summary><strong>ğŸ‘¨â€ğŸ« Instructor Tools (Click to expand)</strong></summary>\n\n- `canvas_create_course` - Create new courses *(FIXED: now requires account_id)*\n- `canvas_update_course` - Update course settings\n- `canvas_create_assignment` - Create assignments\n- `canvas_update_assignment` - Update assignments\n- `canvas_list_assignment_groups` - List assignment groups\n- `canvas_submit_grade` - Grade submissions\n- `canvas_enroll_user` - Enroll students\n- `canvas_list_quizzes` - List course quizzes\n- `canvas_get_quiz` - Get quiz details\n- `canvas_create_quiz` - Create quizzes\n- `canvas_start_quiz_attempt` - Start quiz attempts\n- `canvas_list_rubrics` - List course rubrics\n- `canvas_get_rubric` - Get rubric details\n\n</details>\n\n<details>\n<summary><strong>ğŸ‘¨â€ğŸ’¼ Account Management Tools (NEW!)</strong></summary>\n\n- `canvas_get_account` - Get account details\n- `canvas_list_account_courses` - List courses in an account\n- `canvas_list_account_users` - List users in an account  \n- `canvas_create_user` - Create new users in accounts\n- `canvas_list_sub_accounts` - List sub-accounts\n- `canvas_get_account_reports` - List available reports\n- `canvas_create_account_report` - Generate account reports\n\n</details>\n\n## ğŸ”§ Breaking Changes in v2.2.0\n\n### Course Creation Fix\n**BEFORE (Broken):**\n```javascript\n{\n  \"tool\": \"canvas_create_course\",\n  \"arguments\": {\n    \"name\": \"My Course\"  // âŒ Missing account_id - caused \"page not found\"\n  }\n}\n```\n\n**AFTER (Fixed):**\n```javascript\n{\n  \"tool\": \"canvas_create_course\", \n  \"arguments\": {\n    \"account_id\": 123,              // âœ… Required account_id\n    \"name\": \"My Course\",\n    \"course_code\": \"CS-101\"\n  }\n}\n```\n\n## ğŸŒŸ Example Claude Conversations\n\n**Student**: *\"I need to check my upcoming assignments and submit my English essay\"*\n\n**Claude**: *I'll help you check your upcoming assignments and then assist with submitting your English essay. Let me start by getting your upcoming assignments...*\n\n[Claude uses `canvas_get_upcoming_assignments` then helps with `canvas_submit_assignment`]\n\n---\n\n**Instructor**: *\"Create a new Advanced Physics course in the Science department and enroll my teaching assistant\"*\n\n**Claude**: *I'll help you create the Advanced Physics course in your Science department account and then enroll your TA...*\n\n[Claude uses `canvas_create_course` with proper account_id, then `canvas_enroll_user`]\n\n---\n\n**Administrator**: *\"Generate an enrollment report for all Computer Science courses this semester\"*\n\n**Claude**: *I'll generate a comprehensive enrollment report for your CS courses...*\n\n[Claude uses `canvas_list_account_courses` with filters, then `canvas_create_account_report`]\n\n## ğŸ” Troubleshooting\n\n**Common Issues:**\n- âŒ **401 Unauthorized**: Check your API token and permissions\n- âŒ **404 Not Found**: Verify course/assignment IDs and access rights  \n- âŒ **\"Page not found\" on course creation**: Update to v2.2.0 for account_id fix\n- âŒ **Timeout**: Increase `CANVAS_TIMEOUT` or check network connectivity\n\n**Debug Mode:**\n```bash\nexport LOG_LEVEL=debug\nnpm start\n```\n\n**Health Check:**\n```bash\nnpm run health-check\n```\n\n## ğŸ¤ Contributing\n\nWe welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.\n\n### Quick Contribution Setup\n```bash\ngit clone https://github.com/DMontgomery40/mcp-canvas-lms.git\ncd mcp-canvas-lms\nnpm install\nnpm run dev:watch\n# Make changes, add tests, submit PR\n```\n\n## ğŸ“ˆ Roadmap\n\n- **v2.3**: Enhanced reporting, bulk operations, advanced search\n- **v2.4**: Mobile support, offline capability, analytics dashboard  \n- **v3.0**: Multi-tenant, GraphQL API, AI-powered insights\n\n## ğŸ™‹ Support & Community\n\n- ğŸ› **Bug Reports**: [GitHub Issues](https://github.com/DMontgomery40/mcp-canvas-lms/issues)\n- ğŸ’¬ **Questions**: [GitHub Discussions](https://github.com/DMontgomery40/mcp-canvas-lms/discussions)\n- ğŸ“– **Documentation**: [Wiki](https://github.com/DMontgomery40/mcp-canvas-lms/wiki)\n\n## ğŸ“„ License\n\nMIT License - see [LICENSE](LICENSE) file for details.\n\n---\n\n<div align=\"center\">\n  <strong>Canvas MCP Server v2.2.0</strong><br>\n  <em>Empowering students, educators, and administrators with seamless Canvas integration</em><br><br>\n  \n  â­ **Star this repo if it helps you!** â­\n</div>\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "dragonku--mcp_school_food": {
      "owner": "dragonku",
      "name": "mcp_school_food",
      "url": "https://github.com/dragonku/mcp_school_food",
      "imageUrl": "https://github.com/dragonku.png",
      "description": "Retrieve school meal information across South Korea using natural language queries, providing access to daily and weekly meal data for any school.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-04-05T12:42:12Z",
      "readme_content": "# í•œêµ­ í•™êµ ê¸‰ì‹ ì •ë³´ ì¡°íšŒ ì„œë²„\n\nNEIS Open APIë¥¼ í™œìš©í•˜ì—¬ ì „êµ­ í•™êµì˜ ê¸‰ì‹ ì •ë³´ë¥¼ ì¡°íšŒí•  ìˆ˜ ìˆëŠ” MCP(Model Context Protocol) ì„œë²„ì…ë‹ˆë‹¤.\n\n## ê¸°ëŠ¥\n\n- í•™êµëª…ìœ¼ë¡œ í•™êµ ê²€ìƒ‰\n- ì¼ì¼ ê¸‰ì‹ ì •ë³´ ì¡°íšŒ\n- ì£¼ê°„ ê¸‰ì‹ ì •ë³´ ì¡°íšŒ\n- ìì—°ì–´ ì…ë ¥ ì§€ì› (ì˜ˆ: \"íš¨ì›ê³ ë“±í•™êµ ì–´ì œ ê¸‰ì‹\")\n\n## ì„¤ì¹˜ ë° ì‹¤í–‰\n\n1. ì˜ì¡´ì„± ì„¤ì¹˜:\n```bash\nnpm install\n```\n\n2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •:\n`.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ ë‚´ìš©ì„ ì…ë ¥í•©ë‹ˆë‹¤:\n```bash\nNEIS_API_KEY=your_api_key_here\nPORT=3000\nTRANSPORT=ws\n```\n\n3. ê°œë°œ ëª¨ë“œ ì‹¤í–‰:\n```bash\nnpm run dev\n```\n\n4. í”„ë¡œë•ì…˜ ëª¨ë“œ ì‹¤í–‰:\n```bash\nnpm run build\nnpm start\n```\n\n## API ì‚¬ìš© ì˜ˆì‹œ\n\n```typescript\n// ì¼ì¼ ê¸‰ì‹ ì •ë³´ ì¡°íšŒ\n{\n  \"question\": \"íš¨ì›ê³ ë“±í•™êµ ì˜¤ëŠ˜ ê¸‰ì‹\"\n}\n\n// ì£¼ê°„ ê¸‰ì‹ ì •ë³´ ì¡°íšŒ\n{\n  \"question\": \"íš¨ì›ê³ ë“±í•™êµ ì´ë²ˆì£¼ ê¸‰ì‹\"\n}\n```\n\n## í™˜ê²½ ë³€ìˆ˜\n\n- `NEIS_API_KEY`: NEIS Open API í‚¤ (í•„ìˆ˜)\n- `PORT`: ì„œë²„ í¬íŠ¸ (ê¸°ë³¸ê°’: 3000)\n- `TRANSPORT`: ì „ì†¡ ë°©ì‹ (ws ë˜ëŠ” stdio)\n\n## ë¼ì´ì„ ìŠ¤\n\nISC\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "dreyfus92--astro-docs-mcp": {
      "owner": "dreyfus92",
      "name": "astro-docs-mcp",
      "url": "https://github.com/dreyfus92/astro-docs-mcp",
      "imageUrl": "https://github.com/dreyfus92.png",
      "description": "Provides access to Astro documentation for AI agents to assist with Astro-related tasks. Enables searching, listing, and reading documentation sections through a simple interface.",
      "stars": 3,
      "forks": 2,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-08-13T15:05:31Z",
      "readme_content": "# Astro Docs MCP Server\n\nAn MCP server for providing Astro documentation access to AI agents. This server allows AI assistants to look up and reference Astro documentation when helping users with Astro-related tasks.\n\n<a href=\"https://glama.ai/mcp/servers/@dreyfus92/astro-docs-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@dreyfus92/astro-docs-mcp/badge\" alt=\"Astro Docs Server MCP server\" />\n</a>\n\nThis TypeScript-based MCP server implements a documentation retrieval system for Astro. It demonstrates core MCP concepts by providing:\n\n- Resources representing Astro documentation sections with URIs and metadata\n- Tools for searching Astro documentation\n- Prompts for common Astro questions and tasks\n\n## Features\n\n### Resources\n- List and access Astro documentation via `astro-docs://` URIs\n- Each doc section has a title, content, and category\n- Plain text mime type for simple content access\n\n### Tools\n- `search_docs` - Search Astro documentation\n  - Takes a search query as required parameter\n  - Returns matching documentation sections\n\n### Prompts\n- `explain_astro_islands` - Get detailed explanations of Astro Islands architecture\n- `astro_project_setup` - Guide for setting up a new Astro project\n- `astro_vs_other_frameworks` - Compare Astro with other web frameworks\n\n## Project Structure\n\n- `src/` - Source code for the MCP server\n  - `index.ts` - Main MCP server implementation\n  - `scripts/` - Helper scripts for building and testing\n    - `build.js` - Build script that transpiles TypeScript and creates launcher scripts\n    - `test-client.js` - Test client for verifying server functionality\n- `bin/` - Generated executable scripts\n  - `astro-docs-mcp` - Main launcher script for the MCP server\n- `build/` - Compiled JavaScript files (generated)\n\n## Requirements\n\n- Node.js v16 or later is required\n- Node.js v20+ is recommended for best compatibility\n- The server uses ES modules syntax\n- pnpm package manager (preferred over npm)\n\n## Installation\n\n### Installing Dependencies\n\nInstall dependencies:\n```bash\npnpm install\n```\n\nBuild the server:\n```bash\npnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\npnpm run watch\n```\n\n### Running the Server\n\n```bash\npnpm start\n# OR directly\n./bin/astro-docs-mcp\n```\n\n## Configuration with Claude Desktop\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n**Important:** The configuration must use the **absolute path** to the script:\n\n```json\n{\n  \"mcp_servers\": [\n    {\n      \"id\": \"astro-docs-mcp\",\n      \"name\": \"Astro Docs\",\n      \"command\": \"/full/absolute/path/to/astro-mcp/bin/astro-docs-mcp\",\n      \"type\": \"built-in\"\n    }\n  ]\n}\n```\n\nReplace `/full/absolute/path/to/astro-mcp/` with the actual absolute path to your installation directory.\n\nFor example, if the repository is at `/Users/username/projects/astro-mcp`, the command would be:\n```\n\"/Users/username/projects/astro-mcp/bin/astro-docs-mcp\"\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\npnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## Testing\n\nA test client is provided to verify the server is working correctly:\n\n```bash\npnpm test\n# OR directly\nnode src/scripts/test-client.js\n```\n\nThis will send several commands to the server and display the responses.\n\n## Troubleshooting\n\nIf you encounter issues with the server:\n\n1. **Path Issues**: The most common problem is incorrect paths in the configuration. Make sure:\n   - You're using an absolute path to the script in claude_desktop_config.json\n   - The path points to `bin/astro-docs-mcp` (not the root script)\n   - The build directory exists and contains index.js (`ls -la build/`)\n   - All scripts have executable permissions\n\n2. **\"Module not found\" errors**: If you see errors like `Cannot find module '/build/index.js'`, check:\n   - That you've run the build step (`pnpm run build`)\n   - That the script is being run from the correct directory\n   - That absolute paths are being used for the script execution\n\n3. **Node.js Version**: Make sure you're using Node.js v16 or later. For best results, use v20+.\n   ```bash\n   node --version\n   ```\n\n4. **Script Permissions**: Ensure the scripts have executable permissions:\n   ```bash\n   chmod +x bin/astro-docs-mcp src/scripts/build.js src/scripts/test-client.js\n   ```\n\n5. **JSON Output Issues**: Debug messages being sent to stdout will confuse Claude Desktop because it expects only valid JSON. Our scripts properly redirect all debug output to stderr.\n\n## Usage with Claude Desktop\n\n1. Install the server by following the installation steps above.\n\n2. Configure Claude Desktop by editing the configuration file to include the **absolute path** to the script:\n   ```json\n   {\n     \"mcp_servers\": [\n       {\n         \"id\": \"astro-docs-mcp\",\n         \"name\": \"Astro Docs\",\n         \"command\": \"/full/absolute/path/to/astro-mcp/bin/astro-docs-mcp\",\n         \"type\": \"built-in\"\n       }\n     ]\n   }\n   ```\n\n3. Restart Claude Desktop.\n\n4. You can now interact with the Astro documentation using the following commands:\n   - `list` - List available Astro documentation sections\n   - `search <query>` - Search the Astro documentation\n   - `read astro-docs:///<id>` - Read a specific documentation section\n\n## Future Enhancements\n\n- Fetch real-time documentation from Astro's website\n- Add more comprehensive documentation sections\n- Implement documentation versioning support\n- Add code examples and snippets for common Astro patterns",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Ejb503--systemprompt-mcp-interview": {
      "owner": "Ejb503",
      "name": "systemprompt-mcp-interview",
      "url": "https://github.com/Ejb503/systemprompt-mcp-interview",
      "imageUrl": "https://github.com/Ejb503.png",
      "description": "Engage in realistic interview scenarios with customizable AI personas for practice and feedback on interview responses. Improve interview skills through tailored learning experiences.",
      "stars": 5,
      "forks": 6,
      "license": "Other",
      "language": "TypeScript",
      "updated_at": "2025-09-21T04:58:18Z",
      "readme_content": "# systemprompt-mcp-interview\n\n[![npm version](https://img.shields.io/npm/v/systemprompt-mcp-interview.svg)](https://www.npmjs.com/package/systemprompt-mcp-interview)\n[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![Twitter Follow](https://img.shields.io/twitter/follow/tyingshoelaces_?style=social)](https://twitter.com/tyingshoelaces_)\n[![Discord](https://img.shields.io/discord/1255160891062620252?color=7289da&label=discord)](https://discord.com/invite/wkAbSuPWpr)\n\n[Website](https://systemprompt.io)| [Get API Key](https://systemprompt.io/console)\n\nA specialized Model Context Protocol (MCP) server that enables AI-powered interview roleplay scenarios.\n\nThis server is designed to work with the [systemprompt-io](https://systemprompt.io/console) system, providing an interactive voice interface for interview practice.\n\nAPI key required. (currently free)\n\n## Features\n\n- **Interview Roleplay**\n\n  - Practice interviews with AI-powered personas\n  - Receive real-time feedback on responses\n  - Customizable interview scenarios\n  - Natural conversation flow\n\n- **AI Integration**\n\n  - Advanced natural language processing\n  - Context-aware responses\n  - Real-time voice synthesis\n  - Streaming responses for immediate feedback\n\n## Installation\n\n1/ Connect the MCP server in your systemprompt.io console\n2/ Add a CV in text format to the summarize_cv tool\n3/ List CVs and copy the uri of the resource\n4/ Configure interview using configure_interview tool and resource uri with your instructions\n5/ Activate the agent, and your roleplay will be available\n\n## Demo\n\nWatch our demonstration video of an AI-powered interview roleplay scenario where a candidate interviews for the position of \"King of the Gorillas\":\n\n[â–¶ï¸ Watch Demo Video](https://youtu.be/cShRmHCA9BY?si=9WaNmSXHWtTLWrqO)\n[â–¶ï¸ Watch Setup Video](https://youtu.be/xjrYzVkni-0?si=fIzSk0kWoyA3t-ci)\n\nThe demo showcases:\n\n- Natural conversation flow with AI interviewer\n- Creative scenario-based questions\n- Real-time response handling\n- Dynamic interview progression\n- Personality assessment through roleplay\n\n## Documentation\n\n- [Full API Documentation](https://systemprompt.io/documentation)\n- [Client Setup Guide](https://github.com/Ejb503/multimodal-mcp-client)\n- [Server Configuration](https://systemprompt.io/docs/server-config)\n\n## Development\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "EduBase--MCP": {
      "owner": "EduBase",
      "name": "MCP",
      "url": "https://github.com/EduBase/MCP",
      "imageUrl": "https://github.com/EduBase.png",
      "description": "Interact with EduBase to create dynamic quizzes, manage secure exams, and automate assessment workflows. Integrates with existing systems through a secure API to facilitate personalized learning experiences and enterprise-level security.",
      "stars": 20,
      "forks": 7,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-04T09:56:35Z",
      "readme_content": "<img src=\"https://static.edubase.net/media/brand/title/color.png\" alt=\"EduBase logo\" height=\"150\" />\n\n# EduBase MCP server\n\n[![pre-commit.ci status](https://results.pre-commit.ci/badge/github/EduBase/MCP/main.svg)](https://results.pre-commit.ci/latest/github/EduBase/MCP/main)\n[![smithery badge](https://smithery.ai/badge/@EduBase/MCP)](https://smithery.ai/server/@EduBase/MCP)\n\nThis repository contains the **implementation of the Model Context Protocol** (MCP) server **for the EduBase platform**. It allows MCP clients (for example Claude Desktop) and LLMs to interact with your EduBase account and perform tasks on your behalf. It supports stdio, SSE and streamable HTTP transport protocols.\n\n![EduBase MCP demo GIF: Claude uploads math questions](https://shared.edubase.net/mcp/EduBaseMCPdemomath.gif)\n\n## What is EduBase?\n\nEduBase is an innovative, modular, online educational platform that makes learning more enjoyable, simpler and interactive, suitable for educational institutions or enterprises.\n\n### Why choose EduBase?\n\nEduBase revolutionizes digital learning with its unique combination of features:\n\n* **Advanced Quiz System** with parametrization allowing infinite variations of the same question, real-time cheating detection, beautiful LaTeX typesetting, advanced STEM-support and automatic grading\n* **Unified Learning Environment** that centralizes all your educational content â€” videos, exams, documents, and SCORM modules â€” in one intuitive system\n* **Enterprise-Grade Security** with features like SSO integration, fine-grained access controls, comprehensive auditing, and GDPR compliance\n* **Integration** with your existing systems through LTI, comprehensive API, and custom integration options\n* **AI-Assisted Tools**, such as EduBase Assistant, that can instantly transform your existing content into interactive quizzes and assessments, or translate your materials from one language to another\n\nFrom higher education institutions to corporate training departments, EduBase scales to meet your specific needs while maintaining an intuitive user experience across all devices.\n\n### Demo video\n\nCollaboratively creating and uploading questions, scheduling exams and analyzing user results with Claude:\n\n<a href=\"https://www.youtube.com/watch?v=jvGP-5NzRPs\">\n  <img src=\"https://img.youtube.com/vi/jvGP-5NzRPs/maxresdefault.jpg\" alt=\"Demonstrating EduBase's MCP server to collaboratively create and upload questions, schedule exams and analyze results.\" width=\"600\"/>\n</a>\n\n### Obtaining your API credentials\n\nOnce logged in, on your Dashboard, search for the Integrations menu, click \"add integration\" and choose the type \"EduBase API\".\n\n**If you don't see this option**, enter the `MCPGITHUB` activation code or feel free to contact us to request access at [info@edubase.net](mailto:info@edubase.net).\n\n<img src=\"https://shared.edubase.net/mcp/EduBase_Integration_page_with_API_credentials.png\" alt=\"EduBase API credentials page\" width=\"500\" />\n\n## Tools\n\nEach documented API endpoint is available as a separate tool, named `edubase_<method>_<endpoint>`. For example, the tool for the `GET /user` endpoint is named `edubase_get_user`. See our [developer documentation](https://developer.edubase.net) for more information.\n\n## Configuration\n\nThe MCP server can be configured using environment variables. The following variables are available:\n\n| Variable | Description | Required | Default value |\n|---|---|---|---|\n| `EDUBASE_API_URL` | The base URL of the EduBase API, most probably `https://subdomain.edubase.net/api`. | **Yes** | `https://www.edubase.net/api` |\n| `EDUBASE_API_APP` | The App ID of your integration app on EduBase, the `app` on the EduBase API. Find this in the integration details window on EduBase. | Not if HTTP transport is used with authentication, otherwise **Yes** | - |\n| `EDUBASE_API_KEY` | The Secret key of your integration app on EduBase, the `secret` on the EduBase API. Find this along the App ID in the integration details window on EduBase. | Not if HTTP transport is used with authentication, otherwise **Yes** | - |\n| `EDUBASE_SSE_MODE` | Start MCP server in HTTP mode with SSE transport. Value must be `true`. | No | `false` |\n| `EDUBASE_STREAMABLE_HTTP_MODE` | Start MCP server in HTTP mode with streamable HTTP transport. Value must be `true`. | No | `false` |\n| `EDUBASE_HTTP_PORT` | HTTP server will listen on this port if SSE or streamable HTTP transport mode is used. | No | 3000 |\n\n## Use as a remote MCP server\n\nYou can use the **EduBase MCP server as a remote MCP server** for your MCP client. To do this, you need to host the MCP server where clients can access it, and then configure the client to connect to the server. Either start it with SSE or streamable HTTP transport mode and always use HTTPS when accessing the server remotely over the internet!\n\n### Authentication with remote servers\n\nYou can use server in two modes:\n\n* **Without client authentication**: In this mode, the server will not require any authentication from the client. This is useful for testing or development purposes, or in a closed network but it is not recommended for production use. For this, you have to configure the server with the `EDUBASE_API_APP` and `EDUBASE_API_KEY` as well!\n* **With Bearer token authentication**: In this mode, the server will require a Bearer token to be sent with each request. This is the recommended way to use the server in production. You can obtain the Bearer token from your EduBase account by creating an integration app and providing the App ID and Secret key in the `{app}:{secret}` format, base64 encoded as a token. The server will then use this token to authenticate the client and authorize access to the API endpoints.\n\n## Usage with Claude Desktop\n\nFor a step-by-step walkthrough, see our blog post on how to [connect EduBase with Claude: The Complete MCP Integration Guide](https://edubase.blog/claude-mcp-integration-guide/).\n\n### Installing manually\n\nAdd the following to your `claude_desktop_config.json`:\n\n#### Using Node.js\n\nBefore running the MCP server, make sure you have **Node.js installed**. You can download it from [nodejs.org](https://nodejs.org/) or use a package manager like `brew`. Download EduBase MCP server release or clone the repository and run `npm run build` to build the server. Do not forget to adjust `/path/to/dist` to the actual directory and **configure the environmental variables**!\n\n```json\n{\n  \"mcpServers\": {\n    \"edubase\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/dist/index.js\"\n      ],\n      \"env\": {\n        \"EDUBASE_API_URL\": \"https://domain.edubase.net/api\",\n        \"EDUBASE_API_APP\": \"your_integration_app_id\",\n        \"EDUBASE_API_KEY\": \"your_integration_secret_key\"\n      }\n    }\n  }\n}\n```\n\n#### Using Docker\n\nBefore running the MCP server, make sure you have **Docker installed and is running**. You can download it from [docker.com](https://www.docker.com/) or use a package manager. Do not forget to **configure the environmental variables**!\n\n```json\n{\n  \"mcpServers\": {\n    \"edubase\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"EDUBASE_API_URL\",\n        \"-e\",\n        \"EDUBASE_API_APP\",\n        \"-e\",\n        \"EDUBASE_API_KEY\",\n        \"edubase/mcp\"\n      ],\n      \"env\": {\n        \"EDUBASE_API_URL\": \"https://domain.edubase.net/api\",\n        \"EDUBASE_API_APP\": \"your_integration_app_id\",\n        \"EDUBASE_API_KEY\": \"your_integration_secret_key\"\n      }\n    }\n  }\n}\n```\n\n### Installing via remote MCP server\n\nYou can use the provided EduBase MCP server (if available) as a remote server. We recommend Base64 encoding your `EDUBASE_API_APP` and `EDUBASE_API_KEY` and using it in as a Bearer token in the `Authorization` header (`Authorization: Bearer ${BASE64_ENCODED_TOKEN}`).\n\n```json\n{\n  \"mcpServers\": {\n    \"edubase\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-remote\",\n        \"https://domain.edubase.net/mcp\",\n        \"--header\",\n        \"Authorization: Bearer ${EDUBASE_API_APP}:${EDUBASE_API_KEY}\"\n      ]\n    }\n  }\n}\n```\n\n### Installing via Smithery\n\nTo install EduBase MCP server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@EduBase/MCP):\n\n```bash\nnpx -y @smithery/cli install @EduBase/MCP --client claude\n```\n\n## Contact\n\nWebsite: [www.edubase.net](www.edubase.net)  \nDeveloper Documentation: [developer.edubase.net](developer.edubase.net)  \nEmail: [info@edubase.net](mailto:info@edubase.net)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "enkhbold470--mcp-server-canvas": {
      "owner": "enkhbold470",
      "name": "mcp-server-canvas",
      "url": "https://github.com/enkhbold470/mcp-server-canvas",
      "imageUrl": "https://github.com/enkhbold470.png",
      "description": "Interact programmatically with Canvas LMS to manage courses and enrollments by utilizing the Canvas API. Streamline educational workflows through features like course listing and enrollment type filtering with interactive help prompts.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-04-15T14:02:41Z",
      "readme_content": "# Canvas MCP Server\n\nA Model Context Protocol (MCP) server implementation for the Canvas LMS API. This server provides functionality to interact with Canvas LMS programmatically.\n\n## Features\n\n- List courses from Canvas LMS with optional enrollment type filtering\n- Interactive help prompts for using the tools\n\n## Prerequisites\n\n- Node.js 18 or later\n- A Canvas LMS instance\n- Canvas API access token\n- Cursor (for client integration)\n\n## Setup\n\n1. Clone this repository\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n3. Set up environment variables:\n   ```bash\n   export CANVAS_BASE_URL=\"https://your-canvas-instance.com\"\n   export CANVAS_ACCESS_TOKEN=\"your-api-token\"\n   ```\n4. Build the project:\n   ```bash\n   npm run build\n   ```\n5. Start the server:\n   ```bash\n   npm start\n   ```\n\n## Connecting with Cursor\n\nTo use this MCP server with Cursor:\n\n1. Open Cursor's settings\n2. Navigate to the MCP configuration section\n3. Add a new server configuration:\n   ```json\n   {\n     \"mcpServers\": {\n       \"canvas\": {\n         \"command\": \"npm\",\n         \"args\": [\n           \"start\"\n         ],\n         \"cwd\": \"/path/to/mcp-server-canvas\"\n       }\n     }\n   }\n   ```\n4. Save the configuration and restart Cursor\n5. The Canvas tools will now be available in Cursor's MCP tools panel\n\n## Available Tools\n\n### list_courses\n\nLists all courses from Canvas LMS.\n\nParameters:\n- `enrollment_type` (optional): Filter courses by enrollment type (teacher, student, ta)\n\nExample response:\n```json\n{\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": [\n        {\n          \"id\": 1234,\n          \"name\": \"Example Course\",\n          \"code\": \"EX101\",\n          \"state\": \"available\",\n          \"startDate\": \"2024-01-01T00:00:00Z\",\n          \"endDate\": \"2024-12-31T23:59:59Z\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n### list-courses-help\n\nAn interactive prompt that provides help with using the list_courses tool.\n\n## Development\n\nThe server is built using TypeScript and the MCP SDK. To add new features:\n\n1. Add new API methods to the `CanvasAPI` class\n2. Register new tools using `server.tool()`\n3. Register help prompts using `server.prompt()`\n4. Build and test your changes\n\n## Troubleshooting\n\nIf you encounter issues:\n\n1. Check that environment variables are set correctly\n2. Verify your Canvas API token has the necessary permissions\n3. Check Cursor's MCP server logs for any error messages\n4. Ensure the server path in Cursor's configuration is correct\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0
    },
    "ethangillani--Anki-MCP-Server": {
      "owner": "ethangillani",
      "name": "Anki-MCP-Server",
      "url": "https://github.com/ethangillani/Anki-MCP-Server",
      "imageUrl": "https://github.com/ethangillani.png",
      "description": "Enables interaction with Anki flashcard software by creating decks, adding notes, and searching cards using Anki's native syntax. Facilitates bulk note additions and queries to enhance learning workflows.",
      "stars": 1,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-03-20T01:42:08Z",
      "readme_content": "# Anki MCP Server\n\nA Model Context Protocol (MCP) server that enables LLMs to interact with Anki flashcard software through the AnkiConnect API.\n\n## Features\n\n- Create new decks in Anki\n- Add notes to existing decks\n- List available decks and note models\n- Search for notes using Anki's search syntax\n- Get detailed information about note models and their fields\n- Bulk add multiple notes at once\n\n## Prerequisites\n\n- [Node.js](https://nodejs.org/) (v14 or later)\n- [Anki](https://apps.ankiweb.net/) with the [AnkiConnect](https://ankiweb.net/shared/info/2055492159) add-on installed\n- A Model Context Protocol compatible client (such as Claude with Anthropic MCP support)\n\n## Installation\n\n1. Make sure you have Anki installed with the AnkiConnect add-on\n   - Install AnkiConnect by going to Tools > Add-ons > Get Add-ons and entering code: `2055492159`\n\n2. Clone this repository:\n   ```\n   git clone https://github.com/yourusername/anki-mcp-server.git\n   cd anki-mcp-server\n   ```\n\n3. Install dependencies:\n   ```\n   npm install\n   ```\n\n4. Build the project:\n   ```\n   npm run build\n   ```\n\n## Usage\n\n1. Make sure Anki is running on your computer with AnkiConnect enabled\n\n2. Start the MCP server:\n   ```\n   npm start\n   ```\n\n3. Connect your MCP client (e.g., Claude) to this server\n\n## Available Tools\n\nThe server provides the following tools to MCP clients:\n\n- **listDecks**: Get a list of all decks in Anki\n- **listModels**: Get a list of all note models/types in Anki\n- **createDeck**: Create a new deck in Anki\n- **getModel**: Get details about a specific note model/type\n- **addNote**: Add a single note to a deck\n- **addNotes**: Add multiple notes at once\n- **searchNotes**: Search for notes using Anki's search syntax\n\n## Examples\n\n### Create a New Deck\n\n```json\n{\n  \"name\": \"createDeck\",\n  \"arguments\": {\n    \"name\": \"My New Deck\"\n  }\n}\n```\n\n### Add a Note\n\n```json\n{\n  \"name\": \"addNote\",\n  \"arguments\": {\n    \"deckName\": \"My New Deck\",\n    \"modelName\": \"Basic\",\n    \"fields\": {\n      \"Front\": \"What is the capital of France?\",\n      \"Back\": \"Paris\"\n    },\n    \"tags\": [\"geography\", \"europe\"]\n  }\n}\n```\n\n### Search Notes\n\n```json\n{\n  \"name\": \"searchNotes\",\n  \"arguments\": {\n    \"query\": \"deck:\\\"My New Deck\\\" tag:geography\"\n  }\n}\n```\n\n## Configuration\n\nThe server configuration is in the `config` object in `src/index.ts`. You can modify:\n\n- `ankiConnectUrl`: URL for the AnkiConnect API (default: `http://localhost:8765`)\n- `apiVersion`: API version for AnkiConnect (default: `6`)\n- `defaultDeckName`: Default deck to use if none specified (default: `Default`)\n\n## Troubleshooting\n\n1. **Cannot connect to Anki**\n   - Make sure Anki is running\n   - Check that AnkiConnect add-on is installed and working\n   - Verify that the AnkiConnect URL is correct (default: http://localhost:8765)\n\n2. **Permission issues with AnkiConnect**\n   - AnkiConnect may prompt for permission when the server tries to add cards. Look for a popup in Anki.\n\n## License\n\nMIT License",
      "npm_url": "",
      "npm_downloads": 0
    },
    "faizan45640--google-classroom-mcp-server": {
      "owner": "faizan45640",
      "name": "google-classroom-mcp-server",
      "url": "https://github.com/faizan45640/google-classroom-mcp-server",
      "imageUrl": "https://github.com/faizan45640.png",
      "description": "Access Google Classroom data to retrieve course details, assignments, and announcements. Integrate classroom management capabilities into AI interactions.",
      "stars": 1,
      "forks": 7,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-07-28T14:58:37Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/faizan45640-google-classroom-mcp-server-badge.png)](https://mseep.ai/app/faizan45640-google-classroom-mcp-server)\n\n# Google Classroom MCP Server\n[![smithery badge](https://smithery.ai/badge/@faizan45640/google-classroom-mcp-server)](https://smithery.ai/server/@faizan45640/google-classroom-mcp-server)\n\nAn MCP (Model Context Protocol) server that provides access to Google Classroom data through Claude and other AI assistants that support the MCP protocol.\n\n## Setup\n\n### Prerequisites\n\n- Node.js (v16 or higher)\n- A Google Cloud Platform project with the Google Classroom API enabled\n- OAuth 2.0 client credentials for the Google Classroom API\n\n### Installation\n\n#### Installing via Smithery\n\nTo install Google Classroom MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@faizan45640/google-classroom-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @faizan45640/google-classroom-mcp-server --client claude\n```\n\n#### Installing Manually\n1. Clone this repository\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Place your Google OAuth client credentials in a file named `credentials.json` in the project root:\n\n```json\n{\n  \"web\": {\n    \"client_id\": \"YOUR_CLIENT_ID\",\n    \"project_id\": \"YOUR_PROJECT_ID\",\n    \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n    \"token_uri\": \"https://oauth2.googleapis.com/token\",\n    \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n    \"client_secret\": \"YOUR_CLIENT_SECRET\",\n    \"redirect_uris\": [\"http://localhost:3000/auth/google/callback\"]\n  }\n}\n```\n\n4. Authenticate with Google:\n\n```bash\nnode index.js auth\n```\n\nThis will launch a browser window to complete the OAuth flow and save your credentials to `tokens.json`.\n\n5. Configure Claude to use this server by updating `claude_desktop_config.json` (typically in `%APPDATA%\\Claude\\`):\n\n```json\n{\n  \"mcpServers\": {\n    \"class\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"PATH_TO_YOUR_DIRECTORY\\\\index.js\"\n      ]\n    }\n  }\n}\n```\n\n## Usage\n\n### Available Tools\n\nThe server provides several tools for interacting with Google Classroom:\n\n#### 1. `courses` - List all your Google Classroom courses\n\n```\nUse the 'courses' tool to get a list of all your Google Classroom courses\n```\n\n#### 2. `course-details` - Get detailed information about a specific course\n\n```\nUse the 'course-details' tool with the courseId parameter to get details and announcements for a specific course\n```\n\nParameters:\n- `courseId`: The ID of the course (can be obtained from the `courses` tool)\n\n#### 3. `assignments` - Get assignments for a specific course\n\n```\nUse the 'assignments' tool with the courseId parameter to get assignments and your submissions for a specific course\n```\n\nParameters:\n- `courseId`: The ID of the course (can be obtained from the `courses` tool)\n\n### Example Prompts for Claude\n\n1. Show me all my Google Classroom courses\n2. Get details for my Math course with ID 123456789\n3. Show me all assignments for my History course with ID 987654321\n\n## Permissions\n\nThe server requests the following Google Classroom API permissions:\n\n- `classroom.courses.readonly` - To access course information\n- `classroom.announcements.readonly` - To access course announcements\n- `classroom.coursework.me.readonly` - To access your coursework and assignments\n- `classroom.rosters.readonly` - To access class rosters\n\n## Troubleshooting\n\nIf you encounter permission errors, try:\n\n1. Running the auth command again to refresh permissions:\n   ```\n   node index.js auth\n   ```\n\n2. Ensuring your Google account is added as a test user in the Google Cloud Console if your app is in testing mode\n\n3. Checking the OAuth scopes in the `authenticateAndSaveCredentials` function to ensure they match your needs\n\n## Notes\n\n- This server is designed to be used with Claude AI or other MCP-compatible assistants\n- All API requests are made using your authenticated Google account\n- Token refresh is handled automatically by the server\n- Sensitive credentials are stored locally in the `tokens.json` file\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "falahgs--Brave-Gemini-Research-MCP-Server": {
      "owner": "falahgs",
      "name": "Brave-Gemini-Research-MCP-Server",
      "url": "https://github.com/falahgs/Brave-Gemini-Research-MCP-Server",
      "imageUrl": "https://github.com/falahgs.png",
      "description": "Enables AI assistants to conduct web searches and analyze research papers using Brave Search and Google's Gemini model. Supports general and local web search functionalities alongside academic analysis capabilities.",
      "stars": 5,
      "forks": 3,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-28T01:16:07Z",
      "readme_content": "# Brave-Gemini Research MCP Server\r\n\r\nA modern MCP (Model Context Protocol) server implementation that provides AI assistants with web search capabilities via the Brave Search API and advanced research paper analysis with Google's Gemini model.\r\n\r\n## Overview\r\n\r\nThis project enables AI assistants like Claude to perform web searches and analyze research papers directly through a standardized API interface. The MCP server exposes three main tools:\r\n\r\n1. **Web Search** - For general internet searches and information retrieval\r\n2. **Local Search** - For finding businesses, locations, and places of interest\r\n3. **Research Paper Analysis** - For in-depth analysis of academic papers using Google's Gemini model\r\n\r\n## Features\r\n\r\n- ğŸ” **Web Search API** - Find information across the web\r\n- ğŸ¢ **Local Search API** - Discover businesses and places\r\n- ğŸ“‘ **Research Paper Analysis** - Analyze academic papers with Gemini AI\r\n- ğŸ¤– **Claude Integration** - Seamless connection with Claude Desktop\r\n- ğŸ› ï¸ **Extensible Design** - Easy to add new tools and capabilities\r\n\r\n## Setup and Installation\r\n\r\n### Prerequisites\r\n\r\n- Node.js v18+ recommended\r\n- Brave Search API key ([Get one here](https://brave.com/search/api/))\r\n- Google API key for Gemini integration (required for research paper analysis)\r\n- Claude Desktop for AI assistant integration (optional)\r\n\r\n### Installation\r\n\r\n1. Clone the repository:\r\n   ```bash\r\n   git clone https://github.com/falahgs/brave-gemini-research-mcp.git\r\n   cd brave-gemini-research-mcp\r\n   ```\r\n\r\n2. Install dependencies:\r\n   ```bash\r\n   npm install\r\n   ```\r\n\r\n3. Create a `.env` file with your API keys:\r\n   ```\r\n   BRAVE_API_KEY=your_brave_api_key\r\n   GOOGLE_API_KEY=your_google_api_key\r\n   ```\r\n\r\n### Building\r\n\r\nCompile the TypeScript code to JavaScript:\r\n\r\n```bash\r\nnpm run build\r\n# or manually\r\nnpx tsc\r\n```\r\n\r\n### Running the Server\r\n\r\nSet environment variables and start the server:\r\n\r\n**PowerShell:**\r\n```powershell\r\n$env:BRAVE_API_KEY=\"your_brave_api_key\"\r\n$env:GOOGLE_API_KEY=\"your_google_api_key\"\r\nnode dist/index.js\r\n```\r\n\r\n**Command Prompt:**\r\n```\r\nSET BRAVE_API_KEY=your_brave_api_key\r\nSET GOOGLE_API_KEY=your_google_api_key\r\nnode dist/index.js\r\n```\r\n\r\n**Bash/Linux/macOS:**\r\n```bash\r\nBRAVE_API_KEY=your_brave_api_key GOOGLE_API_KEY=your_google_api_key node dist/index.js\r\n```\r\n\r\n## Claude Desktop Integration\r\n\r\nFollow these steps to integrate the MCP server with Claude Desktop:\r\n\r\n1. Ensure you have Claude Desktop installed ([Download here](https://claude.ai/desktop))\r\n\r\n2. Locate your Claude Desktop configuration file:\r\n   - Windows: `C:\\Users\\<username>\\AppData\\Roaming\\Claude\\claude_desktop_config.json`\r\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\r\n\r\n3. Add the Brave-Gemini Research MCP configuration:\r\n\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"Brave-Gemini Research\": {\r\n      \"command\": \"node\",\r\n      \"args\": [\"G:\\\\path\\\\to\\\\your\\\\brave-gemini-research-mcp\\\\dist\\\\index.js\"],\r\n      \"cwd\": \"G:\\\\path\\\\to\\\\your\\\\brave-gemini-research-mcp\",\r\n      \"timeoutMs\": 120000,\r\n      \"env\": {\r\n        \"BRAVE_API_KEY\": \"your_brave_api_key\",\r\n        \"GOOGLE_API_KEY\": \"your_google_api_key\",\r\n        \"NODE_ENV\": \"production\",\r\n        \"DEBUG\": \"mcp:*\"\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n4. Important notes:\r\n   - Use **absolute paths** with double backslashes (Windows) in the `args` and `cwd` fields\r\n   - Replace `G:\\\\path\\\\to\\\\your\\\\brave-gemini-research-mcp` with the actual path to your project\r\n   - Replace `your_brave_api_key` and `your_google_api_key` with your actual API keys\r\n   - The `timeoutMs` setting helps prevent timeout issues during initialization\r\n\r\n5. Save the file and restart Claude Desktop\r\n\r\n### Using with Claude\r\n\r\nAfter configuration, you can ask Claude to search the web or analyze research papers with prompts like:\r\n\r\n- \"Search the web for the latest AI research papers\"\r\n- \"Find coffee shops in San Francisco\"\r\n- \"Analyze this research paper on quantum computing: [paper content]\"\r\n\r\nClaude will use the MCP server to perform these searches and analyses, returning the results directly in your conversation.\r\n\r\n## Tool Capabilities\r\n\r\n### Web Search Tool\r\n\r\nThe web search tool enables general internet searches:\r\n\r\n- **Function**: `brave_web_search`\r\n- **Parameters**:\r\n  - `query` (required): Search query (max 400 chars)\r\n  - `count` (optional): Number of results (1-20, default 10)\r\n  - `offset` (optional): Pagination offset (max 9, default 0)\r\n\r\n### Local Search Tool\r\n\r\nThe local search tool finds businesses and locations:\r\n\r\n- **Function**: `brave_local_search`\r\n- **Parameters**:\r\n  - `query` (required): Local search query (e.g., \"pizza near Central Park\")\r\n  - `count` (optional): Number of results (1-20, default 5)\r\n\r\n### Research Paper Analysis Tool\r\n\r\nThe research paper analysis tool provides in-depth analysis of academic papers using Google's Gemini model:\r\n\r\n- **Function**: `gemini_research_paper_analysis`\r\n- **Parameters**:\r\n  - `paperContent` (required): The full text of the research paper to analyze\r\n  - `analysisType` (optional): Type of analysis to perform\r\n    - Options: \"summary\", \"critique\", \"literature review\", \"key findings\", \"comprehensive\" (default)\r\n  - `additionalContext` (optional): Specific questions or context to guide the analysis\r\n\r\n**Analysis Types:**\r\n- **Summary**: Comprehensive overview including research question, methodology, key findings, and conclusions\r\n- **Critique**: Critical evaluation of methodology, validity, limitations, and suggestions for improvement\r\n- **Literature Review**: Analysis of how the paper fits within the broader research landscape\r\n- **Key Findings**: Extraction and explanation of the most significant findings and implications\r\n- **Comprehensive**: Complete analysis covering all aspects (default)\r\n\r\n### Example Analysis Result\r\n\r\nWhen using the Research Paper Analysis tool with Gemini, you'll receive a structured, comprehensive analysis depending on the analysis type selected. For example, with a \"comprehensive\" analysis, you might get:\r\n\r\n```\r\n## Research Paper Analysis: Comprehensive\r\n\r\n### Overview\r\n[Summary of paper's main topic and research objectives]\r\n\r\n### Methodology Assessment\r\n[Evaluation of the research methods and design]\r\n\r\n### Key Findings\r\n[Breakdown of the most significant discoveries and results]\r\n\r\n### Limitations\r\n[Analysis of constraints and weaknesses in the research]\r\n\r\n### Significance & Implications\r\n[Discussion of the paper's importance to the field]\r\n\r\n### Recommendations\r\n[Suggestions for future research or applications]\r\n```\r\n\r\nThe Gemini model provides expert-level analysis that helps researchers, students, and professionals quickly understand and evaluate complex academic content.\r\n\r\n## Troubleshooting\r\n\r\n### Common Issues\r\n\r\n1. **Module Not Found Errors**:\r\n   - Ensure all imports include `.js` extensions in TypeScript files\r\n   - Run `npx tsc` to recompile after fixing imports\r\n   - Check the generated `dist` directory structure\r\n\r\n2. **Timeout Errors**:\r\n   - Increase the `timeoutMs` in Claude Desktop configuration (120000 ms recommended)\r\n   - Check that environment variables are properly set\r\n\r\n3. **API Key Issues**:\r\n   - Verify your API keys are correctly set in the environment\r\n   - Check for rate limiting or usage restrictions\r\n\r\n4. **Gemini Model Issues**:\r\n   - Ensure your Google API key has access to Gemini models\r\n   - Check if the paper content exceeds token limits (try shorter excerpts)\r\n   - Verify the analysis type is one of the supported options\r\n\r\n5. **Windows-Specific Issues**:\r\n   - Use PowerShell for more reliable environment variable handling\r\n   - For Windows paths in JSON config, use double backslashes (e.g., `G:\\\\path\\\\to\\\\file`)\r\n   - Consider using absolute paths if relative paths aren't working\r\n\r\n### Debugging\r\n\r\nFor detailed debugging output:\r\n\r\n```bash\r\n# Set environment variables\r\nDEBUG=mcp:* NODE_ENV=development node dist/index.js\r\n```\r\n\r\n## Testing Your Setup\r\n\r\nTo verify your MCP server is working correctly:\r\n\r\n1. **Manual Test**:\r\n   - Run the server using the command line instructions above\r\n   - Check the console output for \"Brave-Gemini Research MCP Server running on stdio\"\r\n   - No error messages should appear\r\n\r\n2. **Claude Desktop Test**:\r\n   - After configuring Claude Desktop, open a new conversation\r\n   - Ask Claude to \"Search for latest developments in AI\"\r\n   - Claude should respond with search results from Brave Search\r\n   - Ask Claude to analyze a research paper\r\n   - Claude should respond with a detailed analysis from Gemini\r\n\r\n## Technical Details\r\n\r\n### MCP Protocol\r\n\r\nThe Model Context Protocol allows AI models to access external tools through a standardized interface. Key components include:\r\n\r\n- **Tools**: Functions with defined schemas\r\n- **Transports**: Communication channels between clients and servers\r\n- **Handlers**: Logic to process requests and return responses\r\n\r\n### Project Structure\r\n\r\n```\r\nâ”œâ”€â”€ dist/               # Compiled JavaScript files\r\nâ”œâ”€â”€ src/\r\nâ”‚   â”œâ”€â”€ config.ts       # Server configuration\r\nâ”‚   â”œâ”€â”€ server.ts       # MCP server implementation\r\nâ”‚   â”œâ”€â”€ tools/          # Tool definitions and handlers\r\nâ”‚   â””â”€â”€ utils/          # Utility functions and API clients\r\nâ”œâ”€â”€ index.ts            # Server entry point\r\nâ”œâ”€â”€ tsconfig.json       # TypeScript configuration\r\nâ””â”€â”€ package.json        # Project dependencies\r\n```\r\n\r\n## Citation\r\n\r\nIf you use this tool in your research or project, please cite it as:\r\n\r\n```\r\nSalieh, F. G. (2025). Brave-Gemini Research MCP Server: A tool for AI assistants to search the web and analyze research papers. \r\nhttps://github.com/yourusername/brave-gemini-research-mcp\r\n```\r\n\r\n## License\r\n\r\nMIT\r\n\r\n## Copyright\r\n\r\nÂ© 2025 Falah G. Salieh, Baghdad, Iraq. All rights reserved.\r\n\r\n---\r\n\r\nMade with â¤ï¸ for enhancing AI capabilities\r\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Faizanadvance--javascripts": {
      "owner": "Faizanadvance",
      "name": "javascripts",
      "url": "https://github.com/Faizanadvance/javascripts",
      "imageUrl": "https://github.com/Faizanadvance.png",
      "description": "Provides foundational JavaScript code examples and tutorials to assist users in learning and understanding JavaScript programming concepts effectively.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2024-11-28T14:24:04Z",
      "readme_content": "# Basic-of-Javascript",
      "npm_url": "",
      "npm_downloads": 0
    },
    "falahgs--MCP-Storybook-Image-Generator": {
      "owner": "falahgs",
      "name": "MCP-Storybook-Image-Generator",
      "url": "https://github.com/falahgs/MCP-Storybook-Image-Generator",
      "imageUrl": "https://github.com/falahgs.png",
      "description": "Generates high-quality storybook images and matching children's stories using Google's Gemini AI, offering multiple art styles such as 3D cartoon, watercolor, and pixel art. It allows instant previewing of creations and saves them locally in an organized manner.",
      "stars": 3,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-12T03:16:03Z",
      "readme_content": "# MCP Storybook Image Generator\n\nA professional-grade server that generates beautiful storybook images with matching children's stories using Google's Gemini AI.\n\n## ğŸ¬ Demo\n\n![Storybook Generator Demo](video/1.gif)\n\n## ğŸŒŸ Features\n\n- **Storybook Image Generation**: Creates high-quality images in various art styles for children's stories\n- **Automatic Story Creation**: Generates engaging children's stories to match the images\n- **Multiple Art Styles**: Choose from 3D cartoon, watercolor, pixel art, hand drawn, or claymation styles\n- **Instant Preview**: Automatically opens generated images and stories in your browser\n- **Local Storage**: Saves images and stories in an organized output directory\n\n## ğŸ› ï¸ Technical Stack\n\n- **Core Framework**: Model Context Protocol (MCP) SDK\n- **AI Integration**: Google Generative AI (Gemini)\n- **Runtime**: Node.js v14+\n- **Language**: TypeScript\n- **Package Manager**: npm\n\n## ğŸ“‹ Prerequisites\n\n- Node.js (v14 or higher)\n- Google Gemini API key\n- TypeScript\n\n## âš™ï¸ Installation\n\n1. Install dependencies:\n```bash\nnpm install\n```\n\n3. Configure environment:\nCreate a `.env` file in the root directory:\n```env\nGEMINI_API_KEY=your_api_key_here\n```\n\n4. Build the project:\n```bash\nnpm run build\n```\n\n## ğŸš€ Using the CLI\n\nYou can use the storybook generator directly from the command line:\n\n```bash\n# Using npx (after publishing to npm)\nnpx mcp-storybook-image-generator --api-key your_api_key_here --save-to-desktop\n\n# Or run locally\nnode build/cli.js --api-key your_api_key_here --save-to-desktop\n```\n\n### Command Line Options\n\n| Option | Description |\n|--------|-------------|\n| `--api-key <key>` | Set your Gemini API key |\n| `--save-to-desktop` | Save generated files to desktop |\n| `--debug` | Enable debug logging |\n| `--help` | Show help information |\n\n## ğŸ”§ Configuring Claude Desktop with MCP Server\n\nTo integrate this server with Claude Desktop:\n\n1. Locate the Claude Desktop Configuration File:\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Linux: `~/.config/Claude/claude_desktop_config.json`\n\n2. Add the following configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"storybook-generator\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-storybook-image-generator@latest\",\n        \"--api-key\",\n        \"your_gemini_api_key_here\"\n      ],\n      \"env\": {\n        \"SAVE_TO_DESKTOP\": \"true\",\n        \"DEBUG\": \"false\"\n      }\n    }\n  }\n}\n```\n\n## ğŸš€ Available Tool\n\n### Storybook Image Generator Tool\n\n```json\n{\n  \"name\": \"generate_storybook_image\",\n  \"description\": \"Generates a 3D style cartoon image with a children's story based on the given prompt\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"prompt\": {\n        \"type\": \"string\",\n        \"description\": \"The prompt describing the storybook scene to generate\"\n      },\n      \"fileName\": {\n        \"type\": \"string\",\n        \"description\": \"Base name for the output files (without extension)\"\n      },\n      \"artStyle\": {\n        \"type\": \"string\",\n        \"description\": \"The art style for the image (default: '3d cartoon')\",\n        \"enum\": [\"3d cartoon\", \"watercolor\", \"pixel art\", \"hand drawn\", \"claymation\"]\n      }\n    },\n    \"required\": [\"prompt\", \"fileName\"]\n  }\n}\n```\n\n## ğŸ“„ Example Usage\n\n### Storybook Generation Examples\n\n```javascript\n// Generate a storybook with a 3D cartoon style\n{\n  \"name\": \"generate_storybook_image\",\n  \"arguments\": {\n    \"prompt\": \"A friendly dragon teaching kids how to fly\",\n    \"fileName\": \"dragon_flight_lesson\",\n    \"artStyle\": \"3d cartoon\"\n  }\n}\n\n// Generate a storybook with a watercolor style\n{\n  \"name\": \"generate_storybook_image\",\n  \"arguments\": {\n    \"prompt\": \"A rabbit and turtle having a tea party in the forest\",\n    \"fileName\": \"forest_tea_party\",\n    \"artStyle\": \"watercolor\"\n  }\n}\n\n// Generate a storybook with pixel art style\n{\n  \"name\": \"generate_storybook_image\",\n  \"arguments\": {\n    \"prompt\": \"A space adventure with a kid astronaut meeting friendly aliens\",\n    \"fileName\": \"space_adventure\",\n    \"artStyle\": \"pixel art\"\n  }\n}\n```\n\n## âš™ï¸ Configuration Options\n\n### Environment Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| `GEMINI_API_KEY` | Google Gemini API key for AI generation | (Required) |\n| `SAVE_TO_DESKTOP` | Force saving to desktop directory | false |\n| `DEBUG` | Enable verbose debug logging | false |\n\n## ğŸ“ Output Files\n\nFor each storybook generation request, the server produces:\n\n1. **PNG Image**: The generated illustration matching your prompt in the requested art style\n2. **Text File**: The matching children's story in plain text format\n3. **HTML Preview**: A combined view showing both the image and story together\n\nThese files are saved to either:\n- Your desktop in a folder called \"storybook-images\" (if `SAVE_TO_DESKTOP=true`)\n- The server's directory in a folder called \"storybook-images\"\n\n## ğŸ¤ Contributing\n\nContributions, issues, and feature requests are welcome! Feel free to check issues page.\n\n## ğŸ“„ License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "findmine--findmine-mcp": {
      "owner": "findmine",
      "name": "findmine-mcp",
      "url": "https://github.com/findmine/findmine-mcp",
      "imageUrl": "https://github.com/findmine.png",
      "description": "Connects to FindMine's styling API to provide personalized outfit recommendations, detailed product information, and visually similar product suggestions. Offers access to styling advice and outfit guidance through various URI schemes for products and looks.",
      "stars": 1,
      "forks": 4,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-03-09T07:32:47Z",
      "readme_content": "# FindMine Shopping Stylist\n\nA Model Context Protocol (MCP) server that integrates FindMine's powerful product styling and outfitting recommendations with Claude and other MCP-compatible applications.\n\n## Overview\n\nThis MCP server connects to FindMine's styling API and exposes its functionality to Large Language Models through the Model Context Protocol. It allows users to:\n\n- Browse product and outfit information\n- Get outfit recommendations for specific products\n- Find visually similar products\n- Access style guidance and fashion advice\n\n## Features\n\n### Resources\n- **Products**: Detailed product information with `product:///` URI scheme\n- **Looks**: Complete outfit recommendations with `look:///` URI scheme\n\n### Tools\n- **get_style_guide**: Access detailed fashion advice and styling guidelines\n- **get_complete_the_look**: Get outfit recommendations for a product\n- **get_visually_similar**: Find visually similar products\n\n### Prompts\n- **outfit_completion**: Get styling advice for complete outfits\n- **styling_guide**: Access comprehensive fashion styling guidelines\n- **findmine_help**: Learn how to use FindMine's tools and resources\n\n## Installation\n\n### Option 1: Install from npm\n\n```bash\n# Install and run directly (recommended)\nnpx findmine-mcp\n\n# Or install globally\nnpm install -g findmine-mcp\nfindmine-mcp\n```\n\n### Option 2: Run with Docker\n\n```bash\ndocker run -e FINDMINE_APP_ID=your_app_id findmine/mcp-server:latest\n```\n\n### Option 3: Clone and build from source\n\n```bash\n# Clone the repository\ngit clone https://github.com/findmine/findmine-mcp.git\ncd findmine-mcp\n\n# Install dependencies\nnpm install\n\n# Build the server\nnpm run build\n\n# For development with auto-rebuild\nnpm run watch\n```\n\n## Configuration\n\n### Environment Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| `FINDMINE_API_URL` | FindMine API base URL | https://api.findmine.com |\n| `FINDMINE_APP_ID` | Your FindMine application ID | DEMO_APP_ID |\n| `FINDMINE_API_VERSION` | API version to use | v3 |\n| `FINDMINE_DEFAULT_REGION` | Default region code | us |\n| `FINDMINE_DEFAULT_LANGUAGE` | Default language code | en |\n| `FINDMINE_CACHE_ENABLED` | Enable response caching | true |\n| `FINDMINE_CACHE_TTL_MS` | Cache time-to-live in ms | 3600000 (1 hour) |\n| `NODE_ENV` | Set to \"development\" for sample data | - |\n\n## Usage with Claude Desktop\n\nThe server automatically configures Claude Desktop during installation. To verify:\n\n**macOS:**\n```bash\ncat ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\n**Windows:**\n```\ntype %APPDATA%\\Claude\\claude_desktop_config.json\n```\n\n## Development\n\n### MCP Inspector\n\nThe MCP Inspector is a development tool for testing your server:\n\n```bash\nnpm run inspector\n```\n\nThis will open a web interface at http://localhost:5173 where you can interact with your server.\n\n### Development Mode\n\nRun the server with sample data:\n\n```bash\nNODE_ENV=development npm run build && node build/index.js\n```\n\n### Customizing the Style Guide\n\nThe style guide can be customized to match your brand's specific styling philosophies and fashion guidance. To customize the style guide:\n\n1. Locate the style guides in `src/index.ts` (search for `styleGuides`)\n2. Modify the content for each category (`general`, `color_theory`, `body_types`, etc.)\n3. Add new categories by extending the `styleGuides` object\n4. Customize occasion-specific and seasonal advice\n\nExample of adding a custom style guide category:\n\n```typescript\n// In src/index.ts\nconst styleGuides: Record<string, string> = {\n  // Existing categories...\n  \n  // Add your custom category\n  your_brand_style: `# Your Brand Style Guide\n  \n## Brand Aesthetic\n- Key elements of your brand's visual identity\n- Core style principles\n- Signature looks and combinations\n\n## Your Brand's Styling Do's\n- Brand-specific styling recommendations\n- Preferred color combinations\n- Signature styling techniques\n\n## Your Brand's Styling Don'ts\n- Combinations to avoid\n- Styling approaches that don't align with brand identity\n- Common styling mistakes to avoid\n`\n};\n```\n\nFor complete customization, you can modify the entire `get_style_guide` handler in `src/index.ts`.\n\n### Project Structure\n\n- `src/index.ts`: Main MCP server implementation\n- `src/api/`: FindMine API client\n- `src/services/`: Business logic and service layer\n- `src/types/`: TypeScript type definitions\n- `src/utils/`: Utility functions and helpers\n\n## API Examples\n\n### Get Style Guide\n\n```json\n{\n  \"name\": \"get_style_guide\",\n  \"arguments\": {\n    \"category\": \"color_theory\",\n    \"occasion\": \"wedding\"\n  }\n}\n```\n\n### Get Complete the Look\n\n```json\n{\n  \"name\": \"get_complete_the_look\",\n  \"arguments\": {\n    \"product_id\": \"P12345\",\n    \"product_color_id\": \"C789\"\n  }\n}\n```\n\n### Get Visually Similar Products\n\n```json\n{\n  \"name\": \"get_visually_similar\",\n  \"arguments\": {\n    \"product_id\": \"P12345\",\n    \"product_color_id\": \"C789\",\n    \"limit\": 5\n  }\n}\n```\n\n## Publishing\n\n### Publishing to npm\n\n```bash\n# Login to npm\nnpm login\n\n# Publish the package\nnpm publish\n\n# Update the version for future releases\nnpm version patch\n```\n\n### Publishing to Docker Hub\n\n```bash\n# Build the Docker image\ndocker build -t findmine/mcp-server:latest .\n\n# Login to Docker Hub\ndocker login\n\n# Push the image\ndocker push findmine/mcp-server:latest\n```\n\n## License\n\nThis project is licensed under the MIT License.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "galihfr09--quran_cloud_mcp_server": {
      "owner": "galihfr09",
      "name": "quran_cloud_mcp_server",
      "url": "https://github.com/galihfr09/quran_cloud_mcp_server",
      "imageUrl": "https://github.com/galihfr09.png",
      "description": "Connects AI models to the Quran API for precise access to Quranic text, minimizing hallucination by retrieving only necessary data upon request. Enables seamless integration with applications such as Claude desktop for enhanced reliability when handling sensitive religious content.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-05-07T07:39:09Z",
      "readme_content": "# quran_cloud_mcp_server\nMCP server to help LLMs to get access to Quran API (https://alquran.cloud/api) to prevent the hallucination with Quran text.\n\nhallucination is a big problem specially when you are working on sensitive data that each character is important.\n\none way of reducing the hallucination is by providing the context to your LLM but of course with large chunk of text like the holy Quran it's not efficient if you put all text in each request.\n\nSo, in this repo I have created an MCP server that's connect your LLM to a free API https://alquran.cloud/api that enables your model to retrieve only the data he needs.\n\nAlso, I will show to you how we can connect this MCP server to Claude desktop application.\n\n## Example of Claude the original response\n![Claude original response](https://github.com/marwanWaly/quran_cloud_mcp_server/blob/main/imgs/original_claude_response.png?raw=true)\n\n## Example of Claude the new response after connecting to Search-Quran MCP server \n![Claude New response](https://github.com/marwanWaly/quran_cloud_mcp_server/blob/main/imgs/new_claude_response.png?raw=true)\n\n## Installation\nmake sure you have python 3.13 & pip\n\nOpen your terminal and write these commands\n\n### Cloning\n```\ngit clone https://github.com/marwanWaly/quran_cloud_mcp_server.git\n```\n\n### Move to project directory\n```\ncd quran_cloud_mcp_server\n```\n\n### Create virtual environment\n```\npython -m venv .venv\n```\n\n### Activate venv\nOn Windows\n```\n.\\venv\\Scripts\\activate\n```\n\nOn Mac or linux\n```\nsource .venv/bin/activate\n```\n\n### Python packages installation\nUse the package manager [pip](https://pip.pypa.io/en/stable/) to install requirements.txt.\n```\npip install -r requirements.txt\n```\n\n### Create .env file\n```\nOPENAI_API_KEY=Your-secret-key\n```\n\n### Run in terminal\n```\npython client.py\n```\n\nnow you can directly chat with GPT4o in your terminal\n\n![server running in terminal](https://github.com/marwanWaly/quran_cloud_mcp_server/blob/main/imgs/run_server_in_terminal.PNG)\n\n## Connect the server to Claude Desktop\nDownload [Claude](https://claude.ai/download) desktop and open it\n\n## Step 1\nSelect setting from the file menu\n\n![step 1](https://github.com/marwanWaly/quran_cloud_mcp_server/blob/main/imgs/add_mcp_to_claude_step-1.png)\n\n## Step 2\nClick on `Developer` then `Edit Config`\n\n![step 2](https://github.com/marwanWaly/quran_cloud_mcp_server/blob/main/imgs/add_mcp_to_claude_step-2.png)\n\n## Step 3\nOpen `claude_desktop_config.json`\n\n![step 3](https://github.com/marwanWaly/quran_cloud_mcp_server/blob/main/imgs/add_mcp_to_claude_step-3.png)\n\n## Step 4\nWrite this configuration in the file\n\n```\n{\n  \"mcpServers\": {\n    \"Search-Quran\": {\n      \"command\": \"python\",\n      \"args\": [\n        \"PROJECT_PATH_ON_YOUR_PC\\\\server.py\"\n      ],\n      \"host\": \"127.0.0.1\",\n      \"port\": 8080,\n      \"timeout\": 30000\n    }\n  }\n}\n```\n\nDon't forget to replace `PROJECT_PATH_ON_YOUR_PC` with the absolute path to your project server\n\n![step 4](https://github.com/marwanWaly/quran_cloud_mcp_server/blob/main/imgs/add_mcp_to_claude_step-4.png)\n\n## Step 5\nRestart Claude app (make sure it's completely closed from your taskbar by right click on Claude icon and select `Quit`)\n\nCheck if the new MCP has been added\n\n![step 5](https://github.com/marwanWaly/quran_cloud_mcp_server/blob/main/imgs/add_mcp_to_claude_step-5.png)\n\nClick on tools icon \n\n![step 6](https://github.com/marwanWaly/quran_cloud_mcp_server/blob/main/imgs/add_mcp_to_claude_step-6.png)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "ggerve--coding-standards-mcp": {
      "owner": "ggerve",
      "name": "coding-standards-mcp",
      "url": "https://github.com/ggerve/coding-standards-mcp",
      "imageUrl": "https://github.com/ggerve.png",
      "description": "Access coding style guidelines and best practices for technologies like Java, Python, and React to improve code quality and maintainability. Offers structured resources on naming conventions, organization, and framework-specific coding practices.",
      "stars": 14,
      "forks": 5,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-01T01:50:59Z",
      "readme_content": "# Coding Standards MCP Server\n\nThis MCP server provides tools for accessing coding style guidelines and best practices for various technologies (Java, Python, React).\n\n## Prerequisites\n\n- Python 3.8 or higher\n- MCP package (`pip install mcp`)\n- UV package manager (recommended)\n\n## Quick Start\n\n1. Install the server in Claude:\n```bash\nmcp install server.py\n```\n\n2. Run in development mode:\n```bash\nmcp dev server.py\n```\nThe MCP inspector will start on port 3000.\n\n## Available Tools\n\n### Style Guides\nAccess language-specific coding style guidelines:\n- Java: Clean code practices, naming conventions, code organization\n- Python: PEP 8 based guidelines, Pythonic code practices\n- React: Component structure, hooks usage, TypeScript integration\n\n### Best Practices\nAccess language-specific application best practices:\n- Java: Project structure, architecture, testing, security\n- Python: Project layout, dependency management, testing practices\n- React: Component patterns, state management, performance optimization\n\n## API Reference\n\n1. `java_style_guide`: Get Java coding style guidelines\n   - Returns: Markdown formatted style guide\n   - Example: `nortal_coding_standards_java_style_guide()`\n\n2. `java_best_practices`: Get Java application best practices\n   - Returns: Markdown formatted best practices\n   - Example: `nortal_coding_standards_java_best_practices()`\n\n3. `python_style_guide`: Get Python coding style guidelines\n   - Returns: Markdown formatted style guide\n   - Example: `nortal_coding_standards_python_style_guide()`\n\n4. `python_best_practices`: Get Python application best practices\n   - Returns: Markdown formatted best practices\n   - Example: `nortal_coding_standards_python_best_practices()`\n\n5. `react_best_practices`: Get React application best practices\n   - Returns: Markdown formatted best practices\n   - Example: `nortal_coding_standards_react_best_practices()`\n\n## Configuration\n\n### MCP Client Configuration\n\nAdd this to your MCP client configuration file (e.g., `~/.codeium/windsurf/mcp_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"nortal_coding_standards\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"mcp[cli]\",\n        \"mcp\",\n        \"run\",\n        \"/absolute/path/to/coding-standards-mcp/server.py\"\n      ]\n    }\n  }\n}\n```\n\nReplace `/absolute/path/to/coding-standards-mcp/server.py` with your actual server path.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.",
      "npm_url": "",
      "npm_downloads": 0
    },
    "ghassenTn--storyGen": {
      "owner": "ghassenTn",
      "name": "storyGen",
      "url": "https://github.com/ghassenTn/storyGen",
      "imageUrl": "https://github.com/ghassenTn.png",
      "description": "Generate creative and engaging stories with dynamic AI prompts and customizable templates. Facilitate interactive content generation to tailor narratives according to user preferences.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2025-04-28T08:34:23Z",
      "readme_content": "# storyGen",
      "npm_url": "",
      "npm_downloads": 0
    },
    "gp-zhong--Physics": {
      "owner": "gp-zhong",
      "name": "Physics",
      "url": "https://github.com/gp-zhong/Physics",
      "imageUrl": "https://github.com/gp-zhong.png",
      "description": "A high-fidelity prototype for learning physics concepts through interactive 3D simulations and AI-assisted learning. It offers a data visualization feature to help students understand physical experiments more intuitively.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "HTML",
      "updated_at": "2025-04-05T09:09:24Z",
      "readme_content": "# ç‰©ç†æ¨¡æ‹Ÿå®éªŒå®¤å°ç¨‹åº - é«˜ä¿çœŸåŸå‹\n\nè¿™æ˜¯ä¸€ä¸ªåŸºäº HTMLã€CSS å’Œ JavaScript å¼€å‘çš„ç‰©ç†æ¨¡æ‹Ÿå®éªŒå®¤å°ç¨‹åºçš„é«˜ä¿çœŸåŸå‹ã€‚é€šè¿‡æ¨¡æ‹ŸçœŸå®çš„ç‰©ç†å®éªŒåœºæ™¯ï¼Œå¸®åŠ©ç”¨æˆ·é€šè¿‡äº’åŠ¨å’Œè§†è§‰åŒ–çš„æ–¹å¼å­¦ä¹ ç‰©ç†çŸ¥è¯†ã€‚\n\n## é¡¹ç›®æ¦‚è¿°\n\nç‰©ç†æ¨¡æ‹Ÿå®éªŒå®¤å°ç¨‹åºæ—¨åœ¨é€šè¿‡äº¤äº’å¼ 3D æ¨¡æ‹Ÿå®éªŒï¼Œå¸®åŠ©å­¦ç”Ÿæ›´ç›´è§‚åœ°ç†è§£å’Œå­¦ä¹ ç‰©ç†æ¦‚å¿µã€‚åŸå‹é‡‡ç”¨ç°ä»£ç®€çº¦çš„è®¾è®¡é£æ ¼ï¼Œå¼ºè°ƒçº¿æ¡å’Œå‡ ä½•å½¢çŠ¶ï¼Œè¥é€ é«˜ç«¯ç§‘æŠ€æ„Ÿï¼Œé€‚åˆå„å¹´é¾„æ®µçš„å­¦ä¹ è€…ã€‚\n\n## è®¾è®¡è§„èŒƒ\n\n- **æ•´ä½“é£æ ¼**ï¼šç°ä»£ç®€çº¦çš„é»‘ç™½ç°é…è‰²ï¼Œå¼ºè°ƒçº¿æ¡å’Œå‡ ä½•å½¢çŠ¶\n- **é…è‰²æ–¹æ¡ˆ**ï¼š\n  - ä¸»è‰²è°ƒï¼šå¤©ç©ºè“ (#4A90E2) å’Œç™½è‰² (#FFFFFF)\n  - è¾…åŠ©è‰²ï¼šæµ…ç»¿è‰² (#7ED321)\n  - ç‚¹ç¼€è‰²ï¼šé»„è‰² (#F8E71C)\n  - èƒŒæ™¯è‰²ï¼šæµ…ç° (#F5F5F5)\n  - æ–‡æœ¬è‰²ï¼šæ·±ç° (#333333)\n- **å­—ä½“é€‰æ‹©**ï¼šæ€æºé»‘ä½“/Noto Sans SC\n- **è§†è§‰å…ƒç´ **ï¼šç®€æ´çº¿æ¡å›¾æ ‡ï¼Œé«˜è´¨é‡ç‰¹å†™äº§å“å›¾ç‰‡ï¼Œç®€å•å‡ ä½•å›¾å½¢èƒŒæ™¯\n\n## å¦‚ä½•è¿è¡ŒåŸå‹\n\n1. å…‹éš†æˆ–ä¸‹è½½æœ¬é¡¹ç›®ä»£ç \n2. ä½¿ç”¨ç°ä»£æµè§ˆå™¨ï¼ˆå¦‚ Chromeã€Firefoxã€Safariï¼‰æ‰“å¼€ `index.html` æ–‡ä»¶\n3. ä½ å°†çœ‹åˆ°åŒ…å«æ‰€æœ‰åŸå‹é¡µé¢çš„é¢„è§ˆé¡µé¢ï¼Œæ¯ä¸ªé¡µé¢æ˜¾ç¤ºåœ¨ iPhone 15 Pro çš„æ¨¡æ‹Ÿæ¡†æ¶ä¸­\n4. ç‚¹å‡»å„ä¸ªé¡µé¢å¯ä»¥æŸ¥çœ‹è¯¦ç»†çš„äº¤äº’åŸå‹\n\n## åŒ…å«çš„é¡µé¢\n\n1. **å¯åŠ¨é¡µ**ï¼šå±•ç¤ºåº”ç”¨åç§°ã€logoå’Œå¼€å§‹æŒ‰é’®\n2. **é¦–é¡µ/å®éªŒåº“**ï¼šå±•ç¤ºåˆ†ç±»å®éªŒã€æ¨èå®éªŒå’Œæœ€è¿‘ä½¿ç”¨\n3. **å®éªŒè¯¦æƒ…é¡µ**ï¼šå±•ç¤ºå®éªŒä¿¡æ¯ã€ä»‹ç»å’Œç›¸å…³çŸ¥è¯†ç‚¹\n4. **3Då®éªŒæ“ä½œç•Œé¢**ï¼šè‡ªç”±è½ä½“å®éªŒæ¨¡æ‹Ÿï¼Œå¯è°ƒæ•´å„ç§ç‰©ç†å‚æ•°\n5. **å®éªŒæ•°æ®åˆ†æé¡µé¢**ï¼šå±•ç¤ºå®éªŒæ•°æ®çš„å›¾è¡¨å’Œè¡¨æ ¼åˆ†æ\n6. **AIè¾…åŠ©å­¦ä¹ å¯¹è¯ç•Œé¢**ï¼šæä¾›æ™ºèƒ½é—®ç­”åŠŸèƒ½è§£é‡Šç‰©ç†æ¦‚å¿µ\n7. **æ¸¸æˆåŒ–æˆå°±ç³»ç»Ÿ**ï¼šå±•ç¤ºç”¨æˆ·å­¦ä¹ è¿›åº¦ã€å‹‹ç« å’ŒæŒ‘æˆ˜ä»»åŠ¡\n8. **ä¸ªäººä¸­å¿ƒï¼ˆæˆ‘çš„ï¼‰**ï¼šå±•ç¤ºç”¨æˆ·ä¿¡æ¯ã€å­¦ä¹ ç»Ÿè®¡ã€å®éªŒå†å²å’ŒåŠŸèƒ½å…¥å£\n\n## æ ¸å¿ƒåŠŸèƒ½\n\n- **å®éªŒåº“ä¸åˆ†ç±»ç®¡ç†**ï¼šç›´è§‚çš„å¡ç‰‡ç•Œé¢ï¼Œæ–¹ä¾¿ç”¨æˆ·æŸ¥æ‰¾å®éªŒ\n- **3Däº¤äº’å¼å®éªŒæ¨¡æ‹Ÿ**ï¼šå‚æ•°å¯è°ƒæ•´çš„è‡ªç”±è½ä½“å®éªŒæ¨¡æ‹Ÿ\n- **å®éªŒæ•™å­¦ä¸å¼•å¯¼**ï¼šè¯¦ç»†çš„å®éªŒä»‹ç»ã€ç›¸å…³çŸ¥è¯†ç‚¹å’Œæ­¥éª¤å¼•å¯¼\n- **æ¸¸æˆåŒ–å­¦ä¹ ç³»ç»Ÿ**ï¼šæˆå°±ç³»ç»Ÿå’Œå‹‹ç« å±•ç¤ºæ¿€å‘å­¦ä¹ åŠ¨åŠ›\n- **æ•°æ®å¯è§†åŒ–ä¸æŠ¥å‘Šç”Ÿæˆ**ï¼šå›¾è¡¨å’Œæ•°æ®è¡¨æ ¼å±•ç¤ºå®éªŒç»“æœ\n- **AIè¾…åŠ©å­¦ä¹ **ï¼šæ™ºèƒ½é—®ç­”è§£å†³ç‰©ç†é—®é¢˜\n- **ç¤¾äº¤ä¸åä½œåŠŸèƒ½**ï¼šæ’è¡Œæ¦œå’Œæˆå°±åˆ†äº«åŠŸèƒ½\n- **ä¸ªäººä¸­å¿ƒç®¡ç†**ï¼šæŸ¥çœ‹å­¦ä¹ æ•°æ®ã€å®éªŒå†å²å’Œç³»ç»Ÿè®¾ç½®\n\n## æŠ€æœ¯æ ˆ\n\n- HTML5\n- CSS3ï¼ˆä½¿ç”¨ TailwindCSSï¼‰\n- JavaScript\n- Font Awesome å›¾æ ‡åº“\n- Chart.js æ•°æ®å¯è§†åŒ–åº“\n\n## åç»­å¼€å‘å»ºè®®\n\n1. ä½¿ç”¨ React æˆ– Vue ç­‰å‰ç«¯æ¡†æ¶é‡æ„ç•Œé¢ï¼Œæå‡ä»£ç å¤ç”¨æ€§å’Œç»´æŠ¤æ€§\n2. é›†æˆ Three.js å’Œ Cannon.js ç­‰ç‰©ç†å¼•æ“å®ç°çœŸå®çš„ 3D æ¨¡æ‹Ÿ\n3. ä½¿ç”¨ ECharts æˆ– D3.js å¢å¼ºæ•°æ®å¯è§†åŒ–èƒ½åŠ›\n4. æ¥å…¥å®é™…çš„ AI æ¥å£å®ç°æ™ºèƒ½é—®ç­”åŠŸèƒ½\n5. ä½¿ç”¨ WebSocket æˆ– WebRTC æŠ€æœ¯å®ç°å¤šäººåä½œåŠŸèƒ½\n\n## é¢„è§ˆ\n\næ‰“å¼€ `index.html` æŸ¥çœ‹å®Œæ•´çš„åŸå‹é¢„è§ˆã€‚\n\n## ä½œè€…\n\næœ¬åŸå‹æ˜¯åŸºäºç‰©ç†æ¨¡æ‹Ÿå®éªŒå®¤å°ç¨‹åºçš„ä½ä¿çœŸåŸå‹è®¾è®¡ï¼Œå‡çº§ä¸ºé«˜ä¿çœŸåŸå‹çš„è®¾è®¡å®ç°ã€‚ ",
      "npm_url": "",
      "npm_downloads": 0
    },
    "hellokitty-v--MCP-Learn": {
      "owner": "hellokitty-v",
      "name": "MCP-Learn",
      "url": "https://github.com/hellokitty-v/MCP-Learn",
      "imageUrl": "https://github.com/hellokitty-v.png",
      "description": "Provides a platform for learning and experimenting with the Model Context Protocol (MCP), focusing on integrating language models with external data sources and tools.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2025-04-25T06:11:09Z",
      "readme_content": "# MCP-Learn",
      "npm_url": "",
      "npm_downloads": 0
    },
    "hichana--goalstory-mcp": {
      "owner": "hichana",
      "name": "goalstory-mcp",
      "url": "https://github.com/hichana/goalstory-mcp",
      "imageUrl": "https://github.com/hichana.png",
      "description": "Goal Story transforms goal tracking through an engaging narrative approach, focusing on one goal at a time and providing personalized insights and storytelling. It incorporates visualization techniques to enhance planning and goal completion.",
      "stars": 17,
      "forks": 3,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-14T21:30:34Z",
      "readme_content": "# Goal Story MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@hichana/goalstory-mcp)](https://smithery.ai/server/@hichana/goalstory-mcp)\n\nGoal Story isnâ€™t a goal trackerâ€”itâ€™s a brand new way to manage your aspirations. We call it â€œGoal Storying.â€ Instead of juggling endless lists, Goal Story guides you to focus on one goal at a time, forging a deeply personal narrative that keeps you motivated and on track. Powered by conversational AI, Goal Story provides constructive insights and creative storytelling tailored to your unique motivations, helping you see your goal through to completion with a sense of momentum and fun.\n\nGoal Storying works because it weaves proven visualization techniques into your planning process. Research shows that using mental imagery when forming implementation intentions leads to higher rates of goal achievement.Â¹ By collaborating with an AI â€œthought partner,â€ youâ€™ll generate personally meaningful stories that tap into your intrinsic motivators, priming both your mind and emotions to move forward. Itâ€™s not about ticking boxesâ€”itâ€™s about intuitive goal management that meets you where you are and adapts with you.\n\nAt the heart of this approach lies Goal Storyâ€™s â€œGoal Engine,â€ which transforms the typical, often dull process of goal tracking into an engaging, fun, and deeply resonant experience. With every completed goal, your insights and progress are securely captured, so you can reflect and build on them in the future. You donâ€™t have to abandon your usual toolsâ€”track your tasks wherever you like. Goal Story simply turns goal-tracking into a dynamic story that evolves, energizes, and empowers you to achieve what matters most.\n\nÂ¹ See abastract on [Research Gate](https://www.researchgate.net/publication/225722903_Using_Mental_Imagery_to_Enhance_the_Effectiveness_of_Implementation_Intentions)\n\n## Get an API key\n\nGo to [GoalStory.ing](https://www.goalstory.ing/) to sign up/in and get a free API key.\n\n## Server config\n\nThe last two args are picked up in the MCP server and utilized like env vars. They are also used with the MCP inspector in the npm script that runs it and the MCP server locally, so no need to manually add in the inspector UI if you're developing your own MCP server.\n\n```\n\"goalStory\": {\n    \"command\": \"npx\",\n    \"args\": [\"-y\", \"goalstory-mcp\", \"https://prod-goalstory-rqc2.encr.app\", \"your-api-key\"]\n}\n```\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "hyperskill--mcp": {
      "owner": "hyperskill",
      "name": "mcp",
      "url": "https://github.com/hyperskill/mcp",
      "imageUrl": "https://github.com/hyperskill.png",
      "description": "Provides explanations of programming topics using Hyperskill's educational resources, enabling searches and connections to relevant programming concepts. Facilitates learning by linking code topics to structured content from Hyperskill.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-07-12T17:46:05Z",
      "readme_content": "# MCP-Hyperskill\n\n<img src=\"http://nanda-registry.com/api/v1/verification/badge/a3e09952-e1bf-44ed-96cc-65defbf3d8d4/\" alt=\"Verified MCP Server\" />\n\nA FastMCP integration with Hyperskill that allows AI agents to explain programming topics using Hyperskill's learning resources.\n\n## Features\n\n- Get explanations of code concepts with links to Hyperskill topics\n- Search for programming topics on Hyperskill\n\n## Installation\n\n```bash\n# Install dependencies using UV with pyproject.toml\nuv sync\n```\n\n## Usage\n\nTo run the server:\n\n```bash\nuv run main.py\n```\n\nThis will start a server on `http://0.0.0.0:8080` that AI agents can connect to.\n\n### Command-line Arguments\n\nThe server supports the following command-line arguments:\n\n```bash\nuv run main.py [--host HOST] [--port PORT] [--debug]\n```\n\n- `--host HOST`: Host to bind the server to (default: 0.0.0.0)\n- `--port PORT`: Port to bind the server to (default: 8080)\n- `--debug`: Run in debug mode\n\nExample:\n\n```bash\nuv run main.py --host 127.0.0.1 --port 9000 --debug\n```\n\n## MCP Tools\n\n### explain_topics_in_the_code\n\nExplains programming topics present in code by finding relevant Hyperskill resources.\n\nParameters:\n- `topics`: List of key topics or concepts that need explanation\n- `programming_language`: Programming language of the given code\n\n### find_topics_on_hyperskill\n\nSearches Hyperskill for specific programming topics.\n\nParameters:\n- `topics`: List of topic keywords to search for\n- `programming_language`: Programming language to filter topics by\n\n## Example Usage\n\nWhen interacting with an AI agent that has access to MCP-Hyperskill, you can ask:\n\n```\nExplain topics in the code using Hyperskill:\n\n\ndef fibonacci(n):\n    if n <= 1:\n        return n\n    else:\n        return fibonacci(n-1) + fibonacci(n-2)\n\nresult = fibonacci(10)\nprint(result)\n```\n\nThe AI agent will identify key concepts like \"recursion\", \"functions\", and \"fibonacci sequence\" and provide Hyperskill links for learning more about these topics.\n\nThe response will include:\n- Topic titles\n- Links to Hyperskill learning resources\n- Topic hierarchies showing where these concepts fit in the curriculum\n\n<div align=\"center\">\n  <img src=\"resources/cursor_example.webp\" alt=\"Example of topic explanation in Cursor\" width=\"600\">\n  <p><em>Example of AI explaining code topics with Hyperskill resources in Cursor</em></p>\n</div>\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "iamleoluo--Quantum-Computing-Approach": {
      "owner": "iamleoluo",
      "name": "Quantum-Computing-Approach",
      "url": "https://github.com/iamleoluo/Quantum-Computing-Approach",
      "imageUrl": "https://github.com/iamleoluo.png",
      "description": "Simulate classical physics phenomena using quantum computing techniques and tools like Qiskit. Provides interactive visualizations and insights into complex systems such as superconductivity and magnetism.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Jupyter Notebook",
      "updated_at": "2024-11-17T09:32:14Z",
      "readme_content": "# Quantum Computing Approach\n\n**Author:** Sheng Yun Wu  \n\n**Converted by:** Wei Che Lo \n\n**Course Website** [https://sites.google.com/gms.ndhu.edu.tw/qca](https://sites.google.com/gms.ndhu.edu.tw/qca)\n\n## Course Overview\n\nThe **Quantum Computing Approach** course introduces the application of quantum computing to simulate classical physics topics using qubits and quantum gates. It provides precise simulations of phenomena such as mechanics, thermodynamics, magnetism, and phase transitions.\n\n### Course Structure:\n- **Duration:** One to two semesters (12â€“15 weeks)\n- **Prerequisites:** Basic linear algebra, probability theory, and classical computing concepts\n- **Tools:** IBM Qiskit, Python\n\n## Introduction\n\nQuantum computing offers a revolutionary method for simulating and understanding classical physics topics by utilizing quantum mechanical principles like superposition, entanglement, and quantum interference. Classical physics often describes phenomena such as magnetism, thermodynamics, and phase transitions using deterministic models. Quantum computing, however, allows us to model these systems with unprecedented precision, capturing their quantum nature through qubits and quantum gates.\n\nThis approach allows quantum computers to simulate:\n- Spin systems\n- Wave-particle duality\n- Quantum tunneling\n- Quantum phase transitions\n- Superconductivity\n- Magnetism\n\nUsing frameworks like Qiskit, quantum computing provides tools for interactive simulations, enabling deeper insights into both classical and quantum phenomena.\n\n## Features\n\n- **Quantum Simulations**: Use quantum circuits to simulate classical physics phenomena.\n- **Interactive Visualizations**: Leverage Qiskit to visualize the evolution of quantum systems.\n- **Real-World Physics Applications**: Explore complex systems like superconductivity and magnetism with quantum models.\n\n## Installation\n\nTo set up the project, follow these steps:\n\n1. Clone the repository:\n    ```bash\n    git clone https://github.com/iamleoluo/Quantum-Computing-Approach.git\n    ```\n2. Install the required dependencies:\n    ```bash\n    pip install -r requirements.txt\n    ```\n## Usage\n\nWorking on it, please wait.\n\n## Addition Note for Qiskit 1.0 feature changes\nQiskit 1.0 brings new stability guarantees and performance improvements, but it does break compatibility with all previous versions of Qiskit.\nfor more information please check out https://docs.quantum.ibm.com/migration-guides/qiskit-1.0-features\n\n## Contact\n\nFor more information, contact the **Modern NanoMag Lab**, founded by Professor Sheng Yun Wu:\n\n**Address:**  \nDepartment of Physics, National Dong Hwa University  \n1-12, Sec 2, Da-Hsuen Rd., Shou-Feng, Hualien, 974 Taiwan\n\n**Phone:** +886-3-8903732  \n**Fax:** +886-3-8900166  \n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "intersective--practera-mcp-server": {
      "owner": "intersective",
      "name": "practera-mcp-server",
      "url": "https://github.com/intersective/practera-mcp-server",
      "imageUrl": "https://github.com/intersective.png",
      "description": "Provides access to Practera's GraphQL API for querying and analyzing learning projects and assessments. Enables generation of project blueprints, restructuring of content for various audiences, and evaluation of assessments for improvement.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-04-17T13:35:55Z",
      "readme_content": "# Practera MCP Server\n\nAn MCP (Model Context Protocol) server that provides access to Practera's GraphQL API, allowing AI models to query Practera learning data.\n\n## Why Practera MCP?\n\nWith this MCP server, you can use LLMs to analyze Practera projects and assessments. For now, this is only available to learning designers (author users). \n\nHere are some examples of how you can use this MCP server:\n- Analyze the structure of a project and look for how it can be extended, compressed.\n- Restructure the project for different grade levels or different audiences.\n- Evaluate the assessments in the project and look for how they can be improved.\n- Generate project blueprints and templates.\n- Generate assessments and questions\n- Create a common cartridge version of a project, or import projects from other LMS data files.\n\n## Roadmap\n\n[ ] Support metrics API for generating LLM reports\n[ ] Support OAuth 2.1 for secure access\n[ ] Support dynamic creation of assessments, milestones, activities, tasks\n[ ] Support generation of media assets\n[ ] Dynamic resource/tool/prompt selection based on project context\n\n\n## Features\n\n- Server-Sent Events (SSE) transport for MCP\n- AWS Lambda deployment support\n- GraphQL integration with Practera API\n- Region-specific endpoints\n- API key authentication\n- OAuth 2.1 support for secure access\n\n## Prerequisites\n\n- Node.js 18+\n- npm\n- AWS account (for deployment)\n- Practera API key\n- OAuth client credentials (for OAuth authentication)\n\n## Installation\n\n1. Clone this repository\n2. Install dependencies:\n   ```\n   npm install\n   ```\n\n## Local Development\n\n1. Start the server in development mode:\n   ```\n   npm run dev\n   ```\n2. The server will be available at `http://localhost:3000/sse`\n3. OAuth endpoints will be accessible at `http://localhost:3000/oauth/*`\n\n## Build\n\nTo build the project for deployment:\n\n```\nnpm run build\n```\n\n## Deployment to AWS Lambda\n\n1. Make sure you have [AWS CLI](https://aws.amazon.com/cli/) installed and configured.\n2. Set up your OAuth configuration parameters:\n   ```\n   export PRACTERA_CLIENT_ID=your_client_id\n   export REDIRECT_URI=your_redirect_uri\n   export ISSUER_URL=your_issuer_url\n   export BASE_URL=your_base_url\n   ```\n3. Deploy using the Serverless Framework:\n   ```\n   npm run deploy -- --param=\"practeraClientId=$PRACTERA_CLIENT_ID\" --param=\"redirectUri=$REDIRECT_URI\" --param=\"issuerUrl=$ISSUER_URL\" --param=\"baseUrl=$BASE_URL\"\n   ```\n\n## Authentication Methods\n\n### API Key Authentication\n\nFor simple integration, you can use API key authentication by providing:\n- `apikey` parameter in each tool call\n- `region` parameter to specify the Practera region\n\n### OAuth 2.1 Authentication (coming soon)\n\nThe server also supports OAuth 2.1 for secure authentication flows:\n\n1. Redirect users to `/oauth/authorize` for authorization\n2. Exchange authorization code for access token at `/oauth/token`\n3. Access the MCP server endpoints using the bearer token\n4. Revoke tokens if needed at `/oauth/revoke`\n\n## Available MCP Tools\n\nThis server exposes the following MCP tools:\n\n- `mcp_practera_get_project` - Get details about a Practera project\n- `mcp_practera_get_assessment` - Get details about a Practera assessment\n\n## MCP Client Configuration\n\nWhen connecting to this MCP server from an MCP client, you'll need to provide:\n\n1. API key for Practera authentication (if using API key auth)\n2. Region for the Practera API (usa, aus, euk or p2-stage)\n3. OAuth configuration (if using OAuth authentication)\n\n### Claude Desktop Configuration Example\n\n```json\n{\n  \"practera\": {\n    \"url\": \"https://your-lambda-url.lambda-url.us-east-1.on.aws/mcp\"\n  }\n}\n```\n\n## Example Usage (with Claude)\n\nYou can ask Claude to interact with Practera data using the MCP tools:\n\n```\nPlease use the MCP tools to get information about project 123 from Practera.\n```\n\nClaude would then use the `mcp_practera_get_project` tool, providing the API key and region from the configuration.\n\n## License\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "ipospelov--mcp-memory-bank": {
      "owner": "ipospelov",
      "name": "mcp-memory-bank",
      "url": "https://github.com/ipospelov/mcp-memory-bank",
      "imageUrl": "https://github.com/ipospelov.png",
      "description": "Facilitates the setup and management of a structured Memory Bank for context preservation in AI assistant environments, offering detailed guidance on file structures, template generation, and project summary analysis. Enhances AI context management through organized documentation and relevant content suggestions.",
      "stars": 72,
      "forks": 13,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-30T23:15:52Z",
      "readme_content": "# Memory Bank MCP Server\n\nThis MCP server helps to build structured documentation system based on [Cline's Memory Bank pattern](https://docs.cline.bot/improving-your-prompting-skills/cline-memory-bank) for context preservation in AI assistant environments. \n\nPowered by [Enlighter](https://enlightby.ai) and [Hyperskill](https://hyperskill.org).\n\nLearn how to setup and use Memory Bank directly in Cursor: http://enlightby.ai/projects/37\n\n[![smithery badge](https://smithery.ai/badge/@ipospelov/mcp-memory-bank)](https://smithery.ai/server/@ipospelov/mcp-memory-bank)\n\n<a href=\"https://glama.ai/mcp/servers/@ipospelov/mcp-memory-bank\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@ipospelov/mcp-memory-bank/badge\" alt=\"Memory Bank Server MCP server\" />\n</a>\n\n## Features\n\n- Get detailed information about Memory Bank structure\n- Generate templates for Memory Bank files\n- Analyze project and provide suggestions for Memory Bank content\n\n## Running the Server\n\nThere are a few options to use this MCP server:\n\n### With UVX\n\nAdd this to your mcp.json config file:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-memory-bank\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"--from\",\n        \"git+https://github.com/ipospelov/mcp-memory-bank\",\n        \"mcp_memory_bank\"\n      ]\n    }\n  }\n}\n```\n\n### With [Smithery](https://smithery.ai/server/@ipospelov/mcp-memory-bank)\n\nAdd this to your mcp.json config file:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory-bank\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@smithery/cli@latest\",\n        \"run\",\n        \"@ipospelov/mcp-memory-bank\",\n        \"--key\",\n        \"your_smithery_key\"\n      ]\n    }\n  }\n}\n```\n\n### With Docker\n\nAdd this to your mcp.json config file:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory-bank\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"19283744/mcp-memory-bank:latest\"\n      ]\n    }\n  }\n}\n```\n\n### Manually\n\nClone repository and run the following commands:\n\n```bash\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\npip install -r requirements.txt\n```\n\nThen add this to your mcp.json config file:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory-bank\": {\n      \"command\": \"python\",\n      \"args\": [\"src/mcp_memory_bank/main.py\"]\n    }\n  }\n}\n```\n\n## Usage Example\n\nAsk Cursor or any other AI code assistant with Memory Bank MCP:\n```\nCreate memory bank for To Do list application with your tools\n```\nProvide more context to get better results.\n\n## Available Tools\n\n### get_memory_bank_structure\n\nReturns a detailed description of the Memory Bank file structure.\n\n### generate_memory_bank_template\n\nReturns a template for a specific Memory Bank file.\n\nExample:\n```json\n{\n  \"file_name\": \"projectbrief.md\"\n}\n```\n\n### analyze_project_summary\n\nAnalyzes a project summary and provides suggestions for Memory Bank content.\n\nExample:\n```json\n{\n  \"project_summary\": \"Building a React web app for inventory management with barcode scanning\"\n}\n```\n\n## Memory Bank Structure\n\nThe Memory Bank consists of core files and optional context files, all in Markdown format:\n\n### Core Files (Required)\n\n1. `projectbrief.md` - Foundation document that shapes all other files\n2. `productContext.md` - Explains why the project exists, problems being solved\n3. `activeContext.md` - Current work focus, recent changes, next steps\n4. `systemPatterns.md` - System architecture, technical decisions, design patterns\n5. `techContext.md` - Technologies used, development setup, constraints\n6. `progress.md` - What works, what's left to build\n7. `memory_bank_instructions.md` - How to work with Memory Bank, instructtions for AI-agent",
      "npm_url": "",
      "npm_downloads": 0
    },
    "ipvr9--mcp-limitless-server": {
      "owner": "ipvr9",
      "name": "mcp-limitless-server",
      "url": "https://github.com/ipvr9/mcp-limitless-server",
      "imageUrl": "https://github.com/ipvr9.png",
      "description": "Connects Limitless Pendant data to AI tools for structured interactions and enables retrieval and management of Lifelog data via AI chat interfaces and agents.",
      "stars": 20,
      "forks": 5,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T12:57:03Z",
      "readme_content": "# Limitless MCP Server (v0.1.0)\n![Version](https://img.shields.io/badge/version-0.1.0-blue) ![License](https://img.shields.io/badge/license-MIT-green)\n\nThis is an MCP (Model Context Protocol) server that connects your Limitless Pendant data to AI tools like Claude, Windsurf, and others via the [Limitless API](https://limitless.ai/developers). It lets AI chat interfaces and agents interact with your Lifelog in a structured, programmable way. Letâ€™s build towards a more organized, intelligent futureâ€”one context-rich interaction at a time.\n\n> **Whatâ€™s MCP?**  \n> [Model Context Protocol](https://modelcontextprotocol.io/introduction) is an open standard for connecting AI models to external tools and dataâ€”think of it like the USB-C port or even the HTTP protocol for AIâ€”universal, reliable, and designed for extensibility. The standard that everyone adopts. It enables rich integrations, custom workflows, and seamless communication between AI and the tools you use every day.\n\n**IMPORTANT NOTE:** As of March 2025, the Limitless API **requires data recorded via the Limitless Pendant**. This server depends on real data recorded from your Limitless Pendantâ€”it wonâ€™t return anything meaningful without it. Ensure your Pendant is connected and recording.\n\n**API Status & Future Plans:**\n*   The official Limitless API is currently in **beta**. As such, it may occasionally be unreliable, subject to change, or experience temporary outages.\n*   Requesting large amounts of data (e.g., listing or searching hundreds of logs) may sometimes result in **timeout errors (like 504 Gateway Time-out)** due to API or network constraints. The server includes a 120-second timeout per API call to mitigate this, but very large requests might still fail.\n*   The Limitless API is under **active development**. This MCP server will be updated with new features and improvements as they become available in the official API.\n*   **Version 0.2.0** of this MCP server is already under development, with plans to add more robust features and potentially new tools in the near future!\n\n## Features (v0.1.0)\n\n*   **List/Get Lifelogs:** Retrieve Pendant recordings by ID, date, date range, or list recent entries. Includes control over sort direction (`asc`/`desc`).\n*   **Search Recent Logs:** Perform simple text searches within the content of a configurable number of recent Pendant recordings (Note: only recent logs are searchable; full-history search is not supported).\n\n> With this server, you can do things like pull action items from your Lifelog and send them directly into Notionâ€”via Claude, ChatWise, Windsurf, or any other AI assistant/app that supports MCP.\n\n## Prerequisites\n\n*   Node.js (v18 or later required)\n*   npm or yarn\n*   A Limitless account and API key ([Get one here](https://limitless.ai/developers))\n*   **A Limitless Pendant (Required for data)**\n*   An MCP Client application (e.g., Claude, Windsurf, Cursor, ChatWise, ChatGPT (coming soon!)) capable of spawning stdio servers and passing environment variables.\n\n## Setup\n\n1.  **Clone or download this project.**\n2.  **Navigate to the directory:**\n    ```bash\n    cd mcp-limitless-server\n    ```\n3.  **Install dependencies:**\n    ```bash\n    npm install\n    ```\n4.  **Build the code:**\n    ```bash\n    npm run build\n    ```\n\n## Configuration (Client-Side)\n\nThis server expects the `LIMITLESS_API_KEY` to be provided as an **environment variable** when it is launched by your MCP client.\n\nYou need to add a server configuration block to your MCP client's settings file. Below are two examples depending on whether you are adding this as your first server or adding it alongside existing servers.\n\n**Example A: Adding as the first/only server**\n\nIf your client's configuration file currently has an empty `mcpServers` object (`\"mcpServers\": {}`), replace it with this:\n\n```json\n{\n  \"mcpServers\": {\n    \"limitless\": {\n      \"command\": \"node\",\n      \"args\": [\"<FULL_FILE_PATH_TO_DIST_SERVER.js>\"],\n      \"env\": {\n        \"LIMITLESS_API_KEY\": \"<YOUR_LIMITLESS_API_KEY_HERE>\"\n      }\n    }\n  }\n}\n```\n\n**Example B: Adding to existing servers**\n\nIf your `mcpServers` object already contains other servers (like `\"notion\": {...}`), add the `\"limitless\"` block alongside them, ensuring correct JSON syntax (commas between entries):\n\n```json\n{\n  \"mcpServers\": {\n    \"some_other_server\": {\n      \"command\": \"...\",\n      \"args\": [\"...\"],\n      \"env\": {\n        \"EXAMPLE_VAR\": \"value\"\n      }\n    },\n    \"limitless\": {\n      \"command\": \"node\",\n      \"args\": [\"<FULL_FILE_PATH_TO_DIST_SERVER.js>\"],\n      \"env\": {\n        \"LIMITLESS_API_KEY\": \"<YOUR_LIMITLESS_API_KEY_HERE>\"\n      }\n    }\n  }\n}\n```\n\n**Important:**\n*   Replace `<FULL_FILE_PATH_TO_DIST_SERVER.js>` with the correct, **absolute path** to the built server script (e.g., `/Users/yourname/Documents/MCP/mcp-limitless-server/dist/server.js`). Relative paths might not work reliably depending on the client.\n*   Replace `<YOUR_LIMITLESS_API_KEY_HERE>` with your actual Limitless API key.\n*   MCP config files **cannot contain comments**. Remove any placeholder text like `<YOUR_LIMITLESS_API_KEY_HERE>` and replace it with your actual key.\n\n## Running the Server (via Client)\n\n**Do not run `npm start` directly.**\n\n1.  Ensure the server is built successfully (`npm run build`).\n2.  Configure your MCP client as shown above.\n3.  Start your MCP client application. It will launch the `mcp-limitless-server` process automatically when needed.\n\n## Exposed MCP Tools (v0.1.0)\n\n(Refer to [`src/server.ts`](./src/server.ts) or ask the server via your client for full details.)\n\n1.  **`limitless_get_lifelog_by_id`**: Retrieves a single Pendant recording by its specific ID.\n2.  **`limitless_list_lifelogs_by_date`**: Lists Pendant recordings for a specific date.\n3.  **`limitless_list_lifelogs_by_range`**: Lists Pendant recordings within a date/time range.\n4.  **`limitless_list_recent_lifelogs`**: Lists the most recent Pendant recordings.\n5.  **`limitless_search_lifelogs`**: Searches title/content of *recent* Pendant recordings (limited scope!).\n\n## Notes & Limitations\n\nğŸš« **Pendant Required**  \nThis server depends on data generated by the Limitless Pendant.\n\nğŸ§ª **API Beta Status**  \nThe Limitless API is in beta and may experience occasional instability or rate limiting. Large requests might result in timeouts (e.g., 504 errors).\n\nğŸ” **Search Scope**  \n`limitless_search_lifelogs` only scans a limited number of recent logs (default 20, max 100). It does *not* search your full history â€” use listing tools first for broader analysis.\n\nâš ï¸ **Error Handling & Timeout**  \nAPI errors are translated into MCP error results. Each API call has a 120-second timeout.\n\nğŸ”Œ **Transport**  \nThis server uses `stdio` and is meant to be launched by an MCP-compatible client app.\n\n## Contributing\n\nHave ideas, improvements, or feedback? Feel free to open an issue or PRâ€”contributions are always welcome! Letâ€™s keep pushing the boundaries of whatâ€™s possible with wearable context and intelligent tools. [https://github.com/ipvr9/mcp-limitless-server](https://github.com/ipvr9/mcp-limitless-server)",
      "npm_url": "",
      "npm_downloads": 0
    },
    "jasperket--clanki": {
      "owner": "jasperket",
      "name": "clanki",
      "url": "https://github.com/jasperket/clanki",
      "imageUrl": "https://github.com/jasperket.png",
      "description": "Manage Anki flashcards by creating, updating, and organizing decks and cards with AI assistance, integrating seamlessly with Anki and AnkiConnect.",
      "stars": 9,
      "forks": 5,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-30T08:18:58Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/jasperket-clanki-badge.png)](https://mseep.ai/app/jasperket-clanki)\n\n# Clanki - Claude's Anki Integration\n\nAn MCP server that enables AI assistants like Claude to interact with Anki flashcard decks through the Model Context Protocol (MCP).\n\n## Features\n\n- Create and manage Anki decks\n- Create basic flashcards with front/back content\n- Create cloze deletion cards\n- Update existing cards and cloze deletions\n- Add and manage tags\n- View deck contents and card information\n- Full integration with AnkiConnect\n\n## Prerequisites\n\n- [Anki](https://apps.ankiweb.net/) installed and running\n- [AnkiConnect](https://ankiweb.net/shared/info/2055492159) plugin installed in Anki\n- Node.js 16 or higher\n\n## Installation\n\n1. Clone this repository:\n\n```bash\ngit clone https://github.com/yourusername/clanki.git\ncd clanki\n```\n\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Build the project:\n\n```bash\nnpm run build\n```\n\n## Setup\n\n1. Make sure Anki is running and the AnkiConnect plugin is installed and enabled\n\n2. Configure Claude for Desktop to use the server by editing `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"clanki\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/clanki/build/index.js\"]\n    }\n  }\n}\n```\n\nReplace `/absolute/path/to/clanki` with the actual path to your clanki installation.\n\n## Available Tools\n\n### create-deck\n\nCreates a new Anki deck\n\n- Parameters:\n  - `name`: Name for the new deck\n\n### create-card\n\nCreates a new basic flashcard in a specified deck\n\n- Parameters:\n  - `deckName`: Name of the deck to add the card to\n  - `front`: Front side content of the card\n  - `back`: Back side content of the card\n  - `tags`: (Optional) Array of tags for the card\n\n### create-cloze-card\n\nCreates a new cloze deletion card in a specified deck\n\n- Parameters:\n  - `deckName`: Name of the deck to add the card to\n  - `text`: Text containing cloze deletions using {{c1::text}} syntax\n  - `backExtra`: (Optional) Extra information to show on the back of the card\n  - `tags`: (Optional) Array of tags for the card\n\n### update-card\n\nUpdates an existing basic flashcard\n\n- Parameters:\n  - `noteId`: ID of the note to update\n  - `front`: (Optional) New front side content\n  - `back`: (Optional) New back side content\n  - `tags`: (Optional) New tags for the card\n\n### update-cloze-card\n\nUpdates an existing cloze deletion card\n\n- Parameters:\n  - `noteId`: ID of the note to update\n  - `text`: (Optional) New text with cloze deletions\n  - `backExtra`: (Optional) New extra information for the back\n  - `tags`: (Optional) New tags for the card\n\n## Development\n\nTo modify or extend the server:\n\n1. Make changes to `src/index.ts`\n2. Rebuild with `npm run build`\n3. Debug with `npx @modelcontextprotocol/inspector node build/index.js`\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "jerpint--paperpal": {
      "owner": "jerpint",
      "name": "paperpal",
      "url": "https://github.com/jerpint/paperpal",
      "imageUrl": "https://github.com/jerpint.png",
      "description": "Enhance literature review processes by enabling searches and discussions about machine learning papers from arXiv and Hugging Face. Facilitate natural conversations with language models to discover new research and organize ideas effectively.",
      "stars": 10,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-17T07:29:54Z",
      "readme_content": "ğŸš¨ Development has moved to https://github.com/milatechtransfer/paperpal\n\n# paperpal\n\nMCP Extension to aid you in searching and writing literature reviews\n\n> Check out this [conversation with Claude](https://claude.ai/share/0572fbd9-3ba2-4143-9f7f-5cae205c6d0d) to see what it can do\n\n## How it works\n\n`paperpal` gives your LLMs access to [arxiv](https://www.arxiv.org) and [Hugging Face papers](https://huggingface.co/papers).\nYou can then have a natural conversation with your favourite LLMs (e.g. Claude) and have it guide you.\n\nYou can:\n\n* Discuss papers\n* Look for new papers\n* Organize ideas for liteature reviews\n* etc.\n\nOf course, this tool is as good as the sum of its parts. LLMs can still hallucinate, and semantic search is never perfect.\n\n## Quickstart\n\nThere are many different ways with which you can interact with an MCP server.\n\n### Claude Desktop App\n\n> If this is your first time using an MCP server for Claude Desktop App, see https://modelcontextprotocol.io/quickstart/user\n\nFirst, clone this repository locally:\n\n    git clone https://github.com/jerpint/paperpal\n\nNext, add the extension to your app. Open your configuration file (on macOS this should be `~/Library/Application Support/Claude/claude_desktop_config.json`) and and add the following to the extension:\n\nFor example on MacOS:\n\n```python\n{\n  \"mcpServers\": {\n    \"paperpal\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/<username>/paperpal\",\n        \"run\",\n        \"paperpal.py\"\n      ]\n    }\n  }\n}\n```\n\nRestart your Claude Desktop App and you should see it appear.\n\n\n### Cursor\n\n> If this is your first time using an MCP server for Cursor, see https://docs.cursor.com/context/model-context-protocol#remote-development\n\nFirst, clone this repository locally:\n\n    git clone https://github.com/jerpint/paperpal\n\n\nAdd this to the root of the project in a `.cursor/mcp.json` file:\n\n```\n{\n  \"mcpServers\": {\n    \"paperpal\": {\n      \"command\": \"/Users/jeremypinto/.cargo/bin/uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/jeremypinto/paperpal\",\n        \"run\",\n        \"paperpal.py\"\n      ]\n    }\n  }\n}\n```\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "jinzcdev--leetcode-mcp-server": {
      "owner": "jinzcdev",
      "name": "leetcode-mcp-server",
      "url": "https://github.com/jinzcdev/leetcode-mcp-server",
      "imageUrl": "https://github.com/jinzcdev.png",
      "description": "Enables automation and interaction with LeetCode problems, contests, solutions, and user data through an API. Supports authenticated requests for comprehensive access to LeetCode features.",
      "stars": 57,
      "forks": 14,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T07:49:11Z",
      "readme_content": "# LeetCode MCP Server\n\n[![NPM Version](https://img.shields.io/npm/v/@jinzcdev/leetcode-mcp-server.svg)](https://www.npmjs.com/package/@jinzcdev/leetcode-mcp-server)\n[![GitHub License](https://img.shields.io/github/license/jinzcdev/leetcode-mcp-server.svg)](https://img.shields.io/github/license/jinzcdev/leetcode-mcp-server.svg)\n[![smithery badge](https://smithery.ai/badge/@jinzcdev/leetcode-mcp-server)](https://smithery.ai/server/@jinzcdev/leetcode-mcp-server)\n[![Chinese Doc](https://img.shields.io/badge/ç®€ä½“ä¸­æ–‡-ç‚¹å‡»æŸ¥çœ‹-orange)](README_zh-CN.md)\n[![Stars](https://img.shields.io/github/stars/jinzcdev/leetcode-mcp-server)](https://github.com/jinzcdev/leetcode-mcp-server)\n\nThe LeetCode MCP Server is a [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) server that provides seamless integration with LeetCode APIs, enabling advanced automation and intelligent interaction with LeetCode's programming problems, contests, solutions, and user data.\n\n<a href=\"https://glama.ai/mcp/servers/@jinzcdev/leetcode-mcp-server\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@jinzcdev/leetcode-mcp-server/badge\" alt=\"LeetCode Server MCP server\" />\n</a>\n\n## Features\n\n- ğŸŒ **Multi-site Support**: Supportâ€‹ both leetcode.com (Global) and leetcode.cn (China) platforms\n- ğŸ“Š **Problem Data Retrieval**: Obtain detailed problem descriptions, constraints, examples, official editorials, and â€‹user-submitted solutions\n- ğŸ‘¤ **User Data Access**: Retrieve user profiles, submission history, and contest performance\n- ğŸ”’ **â€‹Private Data Access**: Create and query user notes, track problem-solving progress, and analyze submission details (AC/WA analysis)\n- ğŸ” **Advanced Search Capabilities**: Filter problems by tags, difficulty levels, categories, and keywords\n- ğŸ“… **Daily Challenge Access**: Easily access daily challenge problems\n\n## Prerequisites\n\n1. Node.js (v20.x or above)\n2. (Optional) LeetCode session cookie for authenticated API access\n\n## Installation\n\n### Installing via Smithery\n\nTo install leetcode-mcp-server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@jinzcdev/leetcode-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @jinzcdev/leetcode-mcp-server --client claude\n```\n\n### Manual Installation\n\n```bash\n# Install from npm\nnpm install @jinzcdev/leetcode-mcp-server -g\n\n# Or run with Global site configuration\nnpx -y @jinzcdev/leetcode-mcp-server --site global\n\n# Run with authentication (for accessing private data)\nnpx -y @jinzcdev/leetcode-mcp-server --site global --session <YOUR_LEETCODE_SESSION_COOKIE>\n```\n\nAlternatively, you can clone the repository and run it locally:\n\n```bash\n# Clone the repository\ngit clone https://github.com/jinzcdev/leetcode-mcp-server.git\n\n# Navigate to the project directory\ncd leetcode-mcp-server\n\n# Build the project\nnpm install && npm run build\n\n# Run the server\nnode build/index.js --site global\n```\n\n## Usage\n\n### Visual Studio Code Integration\n\nAdd the following JSON configuration to your User Settings (JSON) file. Access this by pressing `Ctrl/Cmd + Shift + P` and searching for `Preferences: Open User Settings (JSON)`.\n\n#### Option 1: Using Environment Variables\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"leetcode\": {\n        \"type\": \"stdio\",\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"@jinzcdev/leetcode-mcp-server\"],\n        \"env\": {\n          \"LEETCODE_SITE\": \"global\",\n          \"LEETCODE_SESSION\": \"<YOUR_LEETCODE_SESSION_COOKIE>\"\n        }\n      }\n    }\n  }\n}\n```\n\n#### Option 2: Using Command Line Arguments\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"leetcode\": {\n        \"type\": \"stdio\",\n        \"command\": \"npx\",\n        \"args\": [\n          \"-y\",\n          \"@jinzcdev/leetcode-mcp-server\",\n          \"--site\",\n          \"global\",\n          \"--session\",\n          \"<YOUR_LEETCODE_SESSION_COOKIE>\"\n        ]\n      }\n    }\n  }\n}\n```\n\nFor LeetCode China site, modify the `--site` parameter to `cn`.\n\n> [!TIP]\n>\n> The server supports the following optional environment variables:\n>\n> - `LEETCODE_SITE`: LeetCode API endpoint ('global' or 'cn', default: 'global')\n> - `LEETCODE_SESSION`: LeetCode session cookie for authenticated API access (default: empty)\n>\n> **Priority Note**:\n> Command-line arguments take precedence over environment variables when both are specified. For example:\n>\n> - If `LEETCODE_SITE=cn` is set but you run `leetcode-mcp-server --site global`, the server will use `global`.\n> - If `LEETCODE_SESSION` exists but you provide `--session \"new_cookie\"`, the command-line session value will be used.\n\n## Available Tools\n\n### Problems\n\n| Tool                    | Global | CN  | Auth Required | Description                                                  |\n| ----------------------- | :----: | :-: | :-----------: | ------------------------------------------------------------ |\n| **get_daily_challenge** |   âœ…   | âœ…  |      âŒ       | Retrieves today's LeetCode Daily Challenge problem           |\n| **get_problem**         |   âœ…   | âœ…  |      âŒ       | Retrieves details for a specific LeetCode problem            |\n| **search_problems**     |   âœ…   | âœ…  |      âŒ       | Searches for LeetCode problems with multiple filter criteria |\n\n### Users\n\n| Tool                              | Global | CN  | Auth Required | Description                                                  |\n| --------------------------------- | :----: | :-: | :-----------: | ------------------------------------------------------------ |\n| **get_user_profile**              |   âœ…   | âœ…  |      âŒ       | Retrieves profile information for a LeetCode user            |\n| **get_user_contest_ranking**      |   âœ…   | âœ…  |      âŒ       | Obtains contest ranking statistics for a user                |\n| **get_recent_ac_submissions**     |   âœ…   | âœ…  |      âŒ       | Retrieves a user's recent accepted submissions               |\n| **get_recent_submissions**        |   âœ…   | âŒ  |      âŒ       | Retrieves a user's recent submissions history                |\n| **get_user_status**               |   âœ…   | âœ…  |      âœ…       | Retrieves current user's current status                      |\n| **get_problem_submission_report** |   âœ…   | âœ…  |      âœ…       | Provides detailed submission analysis for a specific problem |\n| **get_problem_progress**          |   âœ…   | âœ…  |      âœ…       | Retrieves current user's problem-solving progress            |\n| **get_all_submissions**           |   âœ…   | âœ…  |      âœ…       | Retrieves current user's submission history                  |\n\n### Notes\n\n| Tool             | Global | CN  | Auth Required | Description                                           |\n| ---------------- | :----: | :-: | :-----------: | ----------------------------------------------------- |\n| **search_notes** |   âŒ   | âœ…  |      âœ…       | Searches for user notes with filtering options        |\n| **get_note**     |   âŒ   | âœ…  |      âœ…       | Retrieves notes for a specific problem by question ID |\n| **create_note**  |   âŒ   | âœ…  |      âœ…       | Creates a new note for a specific problem             |\n| **update_note**  |   âŒ   | âœ…  |      âœ…       | Updates an existing note with new content             |\n\n### Solutions\n\n| Tool                       | Global | CN  | Auth Required | Description                                                    |\n| -------------------------- | :----: | :-: | :-----------: | -------------------------------------------------------------- |\n| **list_problem_solutions** |   âœ…   | âœ…  |      âŒ       | Retrieves a list of community solutions for a specific problem |\n| **get_problem_solution**   |   âœ…   | âœ…  |      âŒ       | Retrieves the complete content of a specific solution          |\n\n## Tool Parameters\n\n### Problems\n\n- **get_daily_challenge** - Retrieves today's LeetCode Daily Challenge problem with complete details\n\n  - No parameters required\n\n- **get_problem** - Retrieves details about a specific LeetCode problem\n\n  - `titleSlug`: The URL slug/identifier of the problem (string, required)\n\n- **search_problems** - Searches for LeetCode problems based on multiple filter criteria\n  - `category`: Problem category filter (string, optional, default: \"all-code-essentials\")\n  - `tags`: List of topic tags to filter problems by (string[], optional)\n  - `difficulty`: Problem difficulty level filter (enum: \"EASY\", \"MEDIUM\", \"HARD\", optional)\n  - `searchKeywords`: Keywords to search in problem titles and descriptions (string, optional)\n  - `limit`: Maximum number of problems to return (number, optional, default: 10)\n  - `offset`: Number of problems to skip (number, optional)\n\n### Users\n\n- **get_user_profile** - Retrieves profile information about a LeetCode user\n\n  - `username`: LeetCode username (string, required)\n\n- **get_user_contest_ranking** - Retrieves a user's contest ranking information\n\n  - `username`: LeetCode username (string, required)\n  - `attended`: Whether to include only the contests the user has participated in (boolean, optional, default: true)\n\n- **get_recent_submissions** - Retrieves a user's recent submissions on LeetCode Global\n\n  - `username`: LeetCode username (string, required)\n  - `limit`: Maximum number of submissions to return (number, optional, default: 10)\n\n- **get_recent_ac_submissions** - Retrieves a user's recent accepted submissions\n\n  - `username`: LeetCode username (string, required)\n  - `limit`: Maximum number of submissions to return (number, optional, default: 10)\n\n- **get_user_status** - Retrieves the current user's status\n\n  - No parameters required\n\n- **get_problem_submission_report** - Retrieves detailed information about a specific submission\n\n  - `id`: The numerical submission ID (number, required)\n\n- **get_problem_progress** - Retrieves the current user's problem-solving progress\n\n  - `offset`: Number of questions to skip (number, optional, default: 0)\n  - `limit`: Maximum number of questions to return (number, optional, default: 100)\n  - `questionStatus`: Filter by question status (enum: \"ATTEMPTED\", \"SOLVED\", optional)\n  - `difficulty`: Filter by difficulty levels (string[], optional)\n\n- **get_all_submissions** - Retrieves paginated list of user's submissions\n  - `limit`: Maximum number of submissions to return (number, default: 20)\n  - `offset`: Number of submissions to skip (number, default: 0)\n  - `questionSlug`: Optional problem identifier (string, optional)\n  - `lang`: Programming language filter (string, optional, CN only)\n  - `status`: Submission status filter (enum: \"AC\", \"WA\", optional, CN only)\n  - `lastKey`: Pagination token for retrieving next page (string, optional, CN only)\n\n### Notes\n\n- **search_notes** - Searches for user notes on LeetCode China\n\n  - `keyword`: Search term to filter notes (string, optional)\n  - `limit`: Maximum number of notes to return (number, optional, default: 10)\n  - `skip`: Number of notes to skip (number, optional, default: 0)\n  - `orderBy`: Sort order for returned notes (enum: \"ASCENDING\", \"DESCENDING\", optional, default: \"DESCENDING\")\n\n- **get_note** - Retrieves user notes for a specific LeetCode problem\n  - `questionId`: The question ID of the LeetCode problem (string, required)\n  - `limit`: Maximum number of notes to return (number, optional, default: 10)\n  - `skip`: Number of notes to skip (number, optional, default: 0)\n- **create_note** - Creates a new note for a specific LeetCode problem\n\n  - `questionId`: The question ID of the LeetCode problem (string, required)\n  - `content`: The content of the note, supports markdown format (string, required)\n  - `summary`: An optional short summary or title for the note (string, optional)\n\n- **update_note** - Updates an existing note with new content or summary\n  - `noteId`: The ID of the note to update (string, required)\n  - `content`: The new content for the note, supports markdown format (string, required)\n  - `summary`: An optional new short summary or title for the note (string, optional)\n\n### Solutions\n\n- **list_problem_solutions** - Retrieves a list of community solutions for a specific problem\n\n  - `questionSlug`: The URL slug/identifier of the problem (string, required)\n  - `limit`: Maximum number of solutions to return (number, optional, default: 10)\n  - `skip`: Number of solutions to skip (number, optional)\n  - `userInput`: Search term to filter solutions (string, optional)\n  - `tagSlugs`: Array of tag identifiers to filter solutions (string[], optional, default: [])\n  - `orderBy`: Sorting criteria for the returned solutions\n    - Global: enum: \"HOT\", \"MOST_RECENT\", \"MOST_VOTES\", optional, default: \"HOT\"\n    - CN: enum: \"DEFAULT\", \"MOST_UPVOTE\", \"HOT\", \"NEWEST_TO_OLDEST\", \"OLDEST_TO_NEWEST\", optional, default: \"DEFAULT\"\n\n- **get_problem_solution** - Retrieves the complete content of a specific solution\n  - `topicId`: Unique topic ID of the solution (string, required, Global only)\n  - `slug`: Unique slug/identifier of the solution (string, required, CN only)\n\n## Available Resources\n\n| Resource Name          | Global | CN  | Auth Required | Description                                                  |\n| ---------------------- | :----: | :-: | :-----------: | ------------------------------------------------------------ |\n| **problem-categories** |   âœ…   | âœ…  |      âŒ       | A list of all problem classification categories              |\n| **problem-tags**       |   âœ…   | âœ…  |      âŒ       | A detailed collection of algorithmic and data structure tags |\n| **problem-langs**      |   âœ…   | âœ…  |      âŒ       | A complete list of all supported programming languages       |\n| **problem-detail**     |   âœ…   | âœ…  |      âŒ       | Provides details about a specific problem                    |\n| **problem-solution**   |   âœ…   | âœ…  |      âŒ       | Provides the complete content of a specific solution         |\n\n## Resource URIs\n\n- **problem-categories** - A list of all problem classification categories\n\n  - URI: `categories://problems/all`\n\n- **problem-tags** - A detailed collection of algorithmic and data structure tags\n\n  - URI: `tags://problems/all`\n\n- **problem-langs** - A complete list of all programming languages supported by LeetCode\n\n  - URI: `langs://problems/all`\n\n- **problem-detail** - Provides details about a specific LeetCode problem\n\n  - URI: `problem://{titleSlug}`\n  - Parameters:\n    - `titleSlug`: Problem identifier as it appears in the LeetCode URL\n\n- **problem-solution** - Provides the complete content of a specific solution\n  - Global URI: `solution://{topicId}`\n    - Parameters:\n      - `topicId`: Unique topic ID of the solution\n  - CN URI: `solution://{slug}`\n    - Parameters:\n      - `slug`: Unique slug/identifier of the solution\n\n## Authentication\n\nUser-specific data access requires LeetCode session authentication:\n\n1. Log in to LeetCode ([Global](https://leetcode.com) or [China](https://leetcode.cn) site)\n2. Extract `LEETCODE_SESSION` cookie from browser developer tools\n3. Configure server with `--session` flag or `LEETCODE_SESSION` environment variable\n\n## Response Format\n\nAll tools return JSON-formatted responses with the following structure:\n\n```json\n{\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": \"JSON_DATA_STRING\"\n    }\n  ]\n}\n```\n\nThe `JSON_DATA_STRING` contains either the requested data or an error message for failed requests.\n\n## License\n\nThis project is licensed under the MIT License.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "johwiebe--anki-mcp": {
      "owner": "johwiebe",
      "name": "anki-mcp",
      "url": "https://github.com/johwiebe/anki-mcp",
      "imageUrl": "https://github.com/johwiebe.png",
      "description": "Integrates AI assistants with Anki to facilitate study by adding, updating, and querying notes while providing access to review statistics. Enables interaction with the Anki collection and leverages spaced repetition algorithms for enhanced learning.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-04-17T06:39:28Z",
      "readme_content": "# Anki MCP Server\n\nA Model Context Protocol (MCP) server for integrating AI assistants with Anki, the popular spaced repetition flashcard software.\n\n## Features\n\nThis MCP server enables AI assistants to interact with Anki through the following tools:\n\n### Tools\n\n- **get-collection-overview**: Returns an overview of the Anki collection like available decks, available models and their fields\n\n- **add-or-update-notes**: Adds new notes or updates existing ones. Allows batch adding/updating multiple notes at once.\n\n- **get-cards-reviewed**: Get the number of cards reviewed by day\n\n- **find-notes**: Allows querying notes using the [Anki searching syntax](https://docs.ankiweb.net/searching.html)\n\n## Requirements\n\n- Anki must be installed and running\n- The [AnkiConnect](https://ankiweb.net/shared/info/2055492159) add-on must be installed in Anki and running\n- This MCP server uses `uv`. To install `uv`, follow the [official instructions](https://docs.astral.sh/uv/getting-started/installation/).\n\n\n## Configuration\n\n### Claude Desktop\n\n1. Open your Claude Desktop config file:\n  - MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n  - Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n2. Add `anki-mcp` to the `mcpServers` section:  \n  ```\n  \"mcpServers\": {\n    \"anki-mcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"anki-mcp\"\n      ]\n    }\n  }\n  ```\n\n3. Restart Claude Desktop.",
      "npm_url": "",
      "npm_downloads": 0
    },
    "jonathanfischer97--juliadoc-mcp": {
      "owner": "jonathanfischer97",
      "name": "juliadoc-mcp",
      "url": "https://github.com/jonathanfischer97/juliadoc-mcp",
      "imageUrl": "https://github.com/jonathanfischer97.png",
      "description": "Access detailed Julia documentation and source code, including information on packages, modules, types, functions, and methods. The server includes built-in caching and error handling specific to Julia.",
      "stars": 10,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-21T01:25:16Z",
      "readme_content": "# Julia Documentation MCP Server \n![](https://badge.mcpx.dev?type=server 'MCP Server') \n\nAn MCP server that efficiently serves context to Claude Desktop about Julia documentation and source code.\n\n<a href=\"https://glama.ai/mcp/servers/7xy80o4wdp\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/7xy80o4wdp/badge\" alt=\"Julia Documentation Server MCP server\" /></a>\n\n## Features\n\n- Get documentation for Julia packages, modules, types, functions, and methods\n- View source code for Julia functions, types, and methods\n- Built-in caching with 5-minute TTL\n- Proper error handling for Julia-specific errors\n\n## Tools\n\n### `get-doc`\nGets Julia documentation for a package, module, type, function, or method.\n- Parameter: `path` (string) - Path to Julia object (e.g., 'Base.sort', 'AbstractArray')\n\n### `get-source`\nGets Julia source code for a function, type, or method.\n- Parameter: `path` (string) - Path to Julia object (e.g., 'Base.sort', 'AbstractArray')\n\n## Requirements\n\n- Node.js 16 or higher\n- Julia 1.9 or higher installed and accessible in PATH\n- Claude Desktop\n\n## Configuration\n\nAdd to your Claude Desktop configuration (`~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"juliadoc\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@jonathanfischer97/server-juliadoc\"\n      ],\n      \"env\": {\n        \"JULIA_PROJECT\": \"/path/to/your/julia/project\"\n      }\n    }\n  }\n}\n```\n\nThe server will use:\n- Your specified Julia project if `JULIA_PROJECT` is set in the config\n- The default global Julia environment if no project is specified\n- Your system's default Julia installation (must be accessible in PATH)\n\n## Development\n\n```bash\n# Clone the repository\ngit clone https://github.com/jonathanfischer97/juliadoc-mcp.git\ncd juliadoc-mcp\n\n# Install dependencies\nnpm install\n\n# Build\nnpm run build\n\n# Start server locally\nnpm start\n```\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\nCredit goes to [mrjoshuak/godoc-mcp](https://github.com/mrjoshuak/godoc-mcp) for inspiring this project\n\n## License\n\nMIT License - see LICENSE file for details\n\n\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "jpablomm--mcp-hackathon-canvas": {
      "owner": "jpablomm",
      "name": "mcp-hackathon-canvas",
      "url": "https://github.com/jpablomm/mcp-hackathon-canvas",
      "imageUrl": "https://github.com/jpablomm.png",
      "description": "Integrate with Canvas LMS and Gradescope to query courses, assignments, modules, and calendar events using natural language. Retrieve detailed breakdowns of upcoming assignments and submission statuses to improve educational productivity.",
      "stars": 0,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-05-02T20:07:17Z",
      "readme_content": "# Canvas MCP\n\n[![smithery badge](https://smithery.ai/badge/@aryankeluskar/canvas-mcp)](https://smithery.ai/server/@aryankeluskar/canvas-mcp)\n\nCanvas MCP is a set of tools that allows your AI agents to interact with Canvas LMS and Gradescope.\n\n![gradescope](assets/gradescope_mcp_ant.png)\n\n![example](assets/example.png)\n\n## Features\n\n- **Find relevant resources** - Ability to find relevant resources for a given query in natural language!\n- **Query upcoming assignments** - Not only fetch upcoming assignments, but also provide its breakdown for a given course.\n- **Get courses and assignments from Gradescope** - Query your Gradescope courses and assignments with natural language, get submission status, and more!\n- Get courses\n- Get modules\n- Get module items\n- Get file url\n- Get calendar events\n- Get assignments\n- and so much more... \n\n## Usage\n\nNote down the following beforehand:\n1. Canvas API Key from `Canvas > Account > Settings > Approved Integrations > New Access Token`\n2. Gemini API key from https://aistudio.google.com/app/apikey\n3. Gradescope Email and Password https://www.gradescope.com/\n   \n### Installing via Smithery (**Preferred**)\n\nTo install Canvas MCP for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@aryankeluskar/canvas-mcp):\n\n```bash\nnpx -y @smithery/cli install @aryankeluskar/canvas-mcp --client claude\n```\n\nOr, for Cursor IDE to use canvas-mcp with other models:\n\n```bash\nnpx -y @smithery/cli install @aryankeluskar/canvas-mcp --client cursor\n```\n\nOr, for Windsurf:\n\n```bash\nnpx -y @smithery/cli install @aryankeluskar/canvas-mcp --client windsurf\n```\n\n---\n\n\n### Manual Installation (ONLY for local instances)\n\nDownload the repository and run the following commands:\n\n```bash\ngit clone https://github.com/aryankeluskar/canvas-mcp.git\ncd canvas-mcp\n\n# Install dependencies with uv (recommended)\npip install uv\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv pip install -r requirements.txt\n\n# Or install with pip\npip install -r requirements.txt\n```\n\n### Manual Configuration\n\nCreate a `.env` file in the root directory with the following environment variables:\n\n```\nCANVAS_API_KEY=your_canvas_api_key\nGEMINI_API_KEY=your_gemini_api_key\n```\n\nAdd the following to your `mcp.json` or `claude_desktop_config.json` file:\n\n```json\n{\n  \"mcpServers\": {\n      \"canvas\": {\n          \"command\": \"uv\",\n          \"args\": [\n              \"--directory\",\n              \"/Users/aryank/Developer/canvas-mcp\",\n              \"run\",\n              \"canvas.py\"\n          ]\n      }\n  }\n}\n```\n\n---\n\nBuilt by [Aryan Keluskar](https://aryankeluskar.com) :)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "jpablomm--mcp-canvas-hackathon": {
      "owner": "jpablomm",
      "name": "mcp-canvas-hackathon",
      "url": "https://github.com/jpablomm/mcp-canvas-hackathon",
      "imageUrl": "https://github.com/jpablomm.png",
      "description": "Access and manage Canvas LMS data, including courses, assignments, submissions, users, and announcements through a local interface. Integrates with Claude Desktop for interactive API usage.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-05-02T19:28:47Z",
      "readme_content": "# Canvas MCP Server\n\n\n\nThis repository contains a Message Control Protocol (MCP) server implementation for interacting with the Canvas Learning Management System API. The server is designed to work with Claude Desktop and potentially other MCP clients.\n\n## Overview\n\nThe Canvas MCP Server provides a local interface to Canvas LMS API, allowing you to:\n- List and manage courses\n- Access assignments and submissions\n- View announcements\n- Retrieve course syllabi and modules\n- Manage users and enrollments\n- Generate course summaries\n\n## Prerequisites\n\n- Python 3.x\n- Virtual environment (venv)\n- Canvas API Token\n- Canvas API URL (e.g., https://canvas.illinois.edu/api/v1)\n\n## Installation\n\n1. Clone this repository:\n```bash\ngit clone https://github.com/vishalsachdev/canvas-mcp.git\ncd canvas-mcp\n```\n\n2. Create and activate a virtual environment:\n```bash\npython -m venv canvas-mcp\nsource canvas-mcp/bin/activate  # On Unix/macOS\n```\n\n3. Install dependencies:\n```bash\npip install -r requirements.txt\n```\n\n## Configuration\n\n### 1. Create Environment File\n\nCreate a `.env` file in the root directory with the following variables:\n\n```\nCANVAS_API_TOKEN=your_canvas_api_token_here\nCANVAS_API_URL=https://canvas.youruniversity.edu/api/v1\n```\n\nReplace the values with:\n- Your Canvas API Token ([How to get your Canvas API token](https://community.canvaslms.com/t5/Canvas-Basics-Guide/How-do-I-manage-API-access-tokens-in-my-user-account/ta-p/615312))\n- Your university's Canvas API URL\n\n### 2. Configure Start Script\n\nThe `start_canvas_server.sh` script is already configured to:\n- Load environment variables from the `.env` file\n- Activate the virtual environment\n- Run the cached server implementation\n\nMake the start script executable:\n```bash\nchmod +x start_canvas_server.sh\n```\n\n### 3. Claude Desktop Configuration\n\n1. Install [Claude Desktop](https://claude.ai/download) if you haven't already.\n\n2. Create or edit the Claude Desktop configuration file:\n```bash\nvim ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\n3. Add the Canvas MCP server configuration:\n```json\n{\n  \"mcpServers\": [\n    {\n      \"name\": \"canvas-api\",\n      \"command\": \"/Users/YOUR_USERNAME/path/to/canvas-mcp/start_canvas_server.sh\"\n    }\n  ]\n}\n```\n\nReplace `/Users/YOUR_USERNAME/path/to/canvas-mcp` with the absolute path to where you cloned this repository.\n\n4. Restart Claude Desktop to load the new configuration.\n\n## Available Tools\n\nThe server provides the following tools for Canvas LMS interaction:\n\n### Course Management\n- `list_courses`: List all courses for the authenticated user\n- `get_course_details`: Get detailed information about a specific course\n- `summarize_course`: Generate a comprehensive summary of a course\n\n### Assignments\n- `list_assignments`: List all assignments for a course\n- `get_assignment_details`: Get detailed information about a specific assignment\n- `get_assignment_description`: Get the full description of an assignment\n\n### Submissions\n- `list_submissions`: List all submissions for a specific assignment\n\n### Users\n- `list_users`: List all users enrolled in a course\n\n### Resources\n- `list_announcements`: List all announcements for a course\n- `get_course_syllabus`: Get the syllabus for a course\n- `get_course_modules`: Get all modules for a course\n\n## Usage with Claude Desktop\n\nThis MCP server is designed to work seamlessly with Claude Desktop:\n\n1. Claude Desktop will automatically start the server when needed\n2. You'll see the Canvas API tools in the Claude Desktop interface (hammer icon ğŸ”¨)\n3. You can ask Claude to perform Canvas operations like \"Show me my courses\" or \"Get the syllabus for my Biology course\"\n\nFor manual testing, you can start the server directly:\n```bash\n./start_canvas_server.sh\n```\n\n## Technical Details\n\n### Server Implementation\n\nThe server uses:\n- `fastmcp`: A Python library for building MCP servers\n- `httpx`: For asynchronous HTTP requests to the Canvas API\n- Caching mechanisms to improve performance for course lookups\n\nThe main implementation file is `canvas_server_cached.py`, which provides:\n- Efficient caching of course information\n- Pagination handling for Canvas API requests\n- Error handling and reporting\n- Support for both course IDs and course codes\n\n\n### Dependencies\n\nThe server requires the following Python packages:\n- `httpx`: For HTTP requests\n- `fastmcp`: For MCP server implementation\n- `requests`: For some HTTP operations\n- Other standard libraries for encoding and networking\n\n## Troubleshooting\n\nIf you encounter issues:\n\n1. **Server Won't Start**\n   - Check that your `.env` file exists and contains valid credentials\n   - Verify the virtual environment path in `start_canvas_server.sh`\n   - Ensure all dependencies are installed\n\n2. **Authentication Errors**\n   - Verify your Canvas API token is valid and not expired\n   - Check that you have the necessary permissions in Canvas\n\n3. **Connection Issues**\n   - Ensure your Canvas API URL is correct\n   - Check your internet connection\n   - Verify your institution hasn't restricted API access\n\n4. **Debugging**\n   - Check the server logs in the Claude Desktop console\n   - Try running the server manually to see error output\n\n## Security Considerations\n\n- Your Canvas API token grants access to your Canvas account\n- Never commit your `.env` file to version control\n- Consider using a token with limited permissions if possible\n- The server runs locally on your machine and doesn't expose your credentials externally\n\n## Contributing\n\nContributions are welcome! Feel free to:\n- Submit issues for bugs or feature requests\n- Create pull requests with improvements\n- Share your use cases and feedback\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n---\n\nCreated by [Vishal Sachdev](https://github.com/vishalsachdev)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "kiennd--reference-servers": {
      "owner": "kiennd",
      "name": "reference-servers",
      "url": "https://github.com/kiennd/reference-servers",
      "imageUrl": "https://github.com/kiennd.png",
      "description": "Facilitates dynamic and reflective problem-solving through a structured thinking process by breaking down complex problems into manageable steps, revising thoughts, and exploring alternative reasoning paths. Generates and verifies solution hypotheses effectively, adjusting the total number of thoughts as needed.",
      "stars": 2,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-09-12T09:14:01Z",
      "readme_content": "# Model Context Protocol servers\n\nThis repository is a collection of *reference implementations* for the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP), as well as references\nto community built servers and additional resources.\n\nThe servers in this repository showcase the versatility and extensibility of MCP, demonstrating how it can be used to give Large Language Models (LLMs) secure, controlled access to tools and data sources.\nEach MCP server is implemented with either the [Typescript MCP SDK](https://github.com/modelcontextprotocol/typescript-sdk) or [Python MCP SDK](https://github.com/modelcontextprotocol/python-sdk).\n\n> Note: Lists in this README are maintained in alphabetical order to minimize merge conflicts when adding new items.\n\n## ğŸŒŸ Reference Servers\n\nThese servers aim to demonstrate MCP features and the Typescript and Python SDK.\n\n- **[AWS KB Retrieval](src/aws-kb-retrieval-server)** - Retrieval from AWS Knowledge Base using Bedrock Agent Runtime\n- **[Brave Search](src/brave-search)** - Web and local search using Brave's Search API\n- **[EverArt](src/everart)** - AI image generation using various models\n- **[Everything](src/everything)** - Reference / test server with prompts, resources, and tools\n- **[Fetch](src/fetch)** - Web content fetching and conversion for efficient LLM usage\n- **[Filesystem](src/filesystem)** - Secure file operations with configurable access controls\n- **[Git](src/git)** - Tools to read, search, and manipulate Git repositories\n- **[GitHub](src/github)** - Repository management, file operations, and GitHub API integration\n- **[GitLab](src/gitlab)** - GitLab API, enabling project management\n- **[Google Drive](src/gdrive)** - File access and search capabilities for Google Drive\n- **[Google Maps](src/google-maps)** - Location services, directions, and place details\n- **[Memory](src/memory)** - Knowledge graph-based persistent memory system\n- **[PostgreSQL](src/postgres)** - Read-only database access with schema inspection\n- **[Puppeteer](src/puppeteer)** - Browser automation and web scraping\n- **[Sentry](src/sentry)** - Retrieving and analyzing issues from Sentry.io\n- **[Sequential Thinking](src/sequentialthinking)** - Dynamic and reflective problem-solving through thought sequences\n- **[Slack](src/slack)** - Channel management and messaging capabilities\n- **[Sqlite](src/sqlite)** - Database interaction and business intelligence capabilities\n- **[Time](src/time)** - Time and timezone conversion capabilities\n\n## ğŸ¤ Third-Party Servers\n\n### ğŸ–ï¸ Official Integrations\n\nOfficial integrations are maintained by companies building production ready MCP servers for their platforms.\n\n- <img height=\"12\" width=\"12\" src=\"https://axiom.co/favicon.ico\" alt=\"Axiom Logo\" /> **[Axiom](https://github.com/axiomhq/mcp-server-axiom)** - Query and analyze your Axiom logs, traces, and all other event data in natural language\n- <img height=\"12\" width=\"12\" src=\"https://browserbase.com/favicon.ico\" alt=\"Browserbase Logo\" /> **[Browserbase](https://github.com/browserbase/mcp-server-browserbase)** - Automate browser interactions in the cloud (e.g. web navigation, data extraction, form filling, and more)\n- <img height=\"12\" width=\"12\" src=\"https://cdn.simpleicons.org/cloudflare\" /> **[Cloudflare](https://github.com/cloudflare/mcp-server-cloudflare)** - Deploy, configure & interrogate your resources on the Cloudflare developer platform (e.g. Workers/KV/R2/D1)\n- <img height=\"12\" width=\"12\" src=\"https://e2b.dev/favicon.ico\" alt=\"E2B Logo\" /> **[E2B](https://github.com/e2b-dev/mcp-server)** - Run code in secure sandboxes hosted by [E2B](https://e2b.dev)\n- <img height=\"12\" width=\"12\" src=\"https://exa.ai/images/favicon-32x32.png\" alt=\"Exa Logo\" /> **[Exa](https://github.com/exa-labs/exa-mcp-server)** - Search Engine made for AIs by [Exa](https://exa.ai)\n- <img height=\"12\" width=\"12\" src=\"https://fireproof.storage/favicon.ico\" alt=\"Fireproof Logo\" /> **[Fireproof](https://github.com/fireproof-storage/mcp-database-server)** - Immutable ledger database with live synchronization\n- <img height=\"12\" width=\"12\" src=\"https://cdn.simpleicons.org/jetbrains\" /> **[JetBrains](https://github.com/JetBrains/mcp-jetbrains)** â€“ Work on your code with JetBrains IDEs\n- <img height=\"12\" width=\"12\" src=\"https://kagi.com/favicon.ico\" alt=\"Kagi Logo\" /> **[Kagi Search](https://github.com/kagisearch/kagimcp)** - Search the web using Kagi's search API\n- <img height=\"12\" width=\"12\" src=\"https://www.meilisearch.com/favicon.ico\" alt=\"Meilisearch Logo\" /> **[Meilisearch](https://github.com/meilisearch/meilisearch-mcp)** - Interact & query with Meilisearch (Full-text & semantic search API)\n- <img height=\"12\" width=\"12\" src=\"https://metoro.io/static/images/logos/Metoro.svg\" /> **[Metoro](https://github.com/metoro-io/metoro-mcp-server)** - Query and interact with kubernetes environments monitored by Metoro\n- <img height=\"12\" width=\"12\" src=\"https://www.motherduck.com/favicon.ico\" alt=\"MotherDuck Logo\" /> **[MotherDuck](https://github.com/motherduckdb/mcp-server-motherduck)** - Query and analyze data with MotherDuck and local DuckDB\n- <img height=\"12\" width=\"12\" src=\"https://needle-ai.com/images/needle-logo-orange-2-rounded.png\" alt=\"Needle AI Logo\" /> **[Needle](https://github.com/needle-ai/needle-mcp)** - Production-ready RAG out of the box to search and retrieve data from your own documents.\n- <img height=\"12\" width=\"12\" src=\"https://neo4j.com/favicon.ico\" alt=\"Neo4j Logo\" /> **[Neo4j](https://github.com/neo4j-contrib/mcp-neo4j/)** - Neo4j graph database server (schema + read/write-cypher) and separate graph database backed memory\n- **[Neon](https://github.com/neondatabase/mcp-server-neon)** - Interact with the Neon serverless Postgres platform\n- <img height=\"12\" width=\"12\" src=\"https://qdrant.tech/img/brand-resources-logos/logomark.svg\" /> **[Qdrant](https://github.com/qdrant/mcp-server-qdrant/)** - Implement semantic memory layer on top of the Qdrant vector search engine\n- **[Raygun](https://github.com/MindscapeHQ/mcp-server-raygun)** - Interact with your crash reporting and real using monitoring data on your Raygun account\n- <img height=\"12\" width=\"12\" src=\"https://pics.fatwang2.com/56912e614b35093426c515860f9f2234.svg\" /> [Search1API](https://github.com/fatwang2/search1api-mcp) - One API for Search, Crawling, and Sitemaps\n- <img height=\"12\" width=\"12\" src=\"https://www.tinybird.co/favicon.ico\" alt=\"Tinybird Logo\" /> **[Tinybird](https://github.com/tinybirdco/mcp-tinybird)** - Interact with Tinybird serverless ClickHouse platform\n\n### ğŸŒ Community Servers\n\nA growing set of community-developed and maintained servers demonstrates various applications of MCP across different domains.\n\n> **Note:** Community servers are **untested** and should be used at **your own risk**. They are not affiliated with or endorsed by Anthropic.\n\n- **[AWS S3](https://github.com/aws-samples/sample-mcp-server-s3)** - A sample MCP server for AWS S3 that flexibly fetches objects from S3 such as PDF documents\n- **[AWS](https://github.com/rishikavikondala/mcp-server-aws)** - Perform operations on your AWS resources using an LLM\n- **[Airtable](https://github.com/domdomegg/airtable-mcp-server)** - Read and write access to [Airtable](https://airtable.com/) databases, with schema inspection.\n- **[Airtable](https://github.com/felores/airtable-mcp)** - Airtable Model Context Protocol Server.\n- **[AlphaVantage](https://github.com/calvernaz/alphavantage)** - MCP server for stock market data API [AlphaVantage](https://www.alphavantage.co)\n- **[Anki](https://github.com/scorzeth/anki-mcp-server)** - An MCP server for interacting with your [Anki](https://apps.ankiweb.net) decks and cards.\n- **[Any Chat Completions](https://github.com/pyroprompts/any-chat-completions-mcp)** - Interact with any OpenAI SDK Compatible Chat Completions API like OpenAI, Perplexity, Groq, xAI and many more.\n- **[Atlassian](https://github.com/sooperset/mcp-atlassian)** - Interact with Atlassian Cloud products (Confluence and Jira) including searching/reading Confluence spaces/pages, accessing Jira issues, and project metadata.\n- **[BigQuery](https://github.com/LucasHild/mcp-server-bigquery)** (by LucasHild) - This server enables LLMs to inspect database schemas and execute queries on BigQuery.\n- **[BigQuery](https://github.com/ergut/mcp-bigquery-server)** (by ergut) - Server implementation for Google BigQuery integration that enables direct BigQuery database access and querying capabilities\n- **[ChatMCP](https://github.com/AI-QL/chat-mcp)** â€“ An Open Source Cross-platform GUI Desktop application compatible with Linux, macOS, and Windows, enabling seamless interaction with MCP servers across dynamically selectable LLMs, by **[AIQL](https://github.com/AI-QL)**\n- **[ChatSum](https://github.com/mcpso/mcp-server-chatsum)** - Query and Summarize chat messages with LLM. by [mcpso](https://mcp.so)\n- **[Chroma](https://github.com/privetin/chroma)** - Vector database server for semantic document search and metadata filtering, built on Chroma\n- **[Cloudinary](https://github.com/felores/cloudinary-mcp-server)** - Cloudinary Model Context Protocol Server to upload media to Cloudinary and get back the media link and details.\n- **[cognee-mcp](https://github.com/topoteretes/cognee-mcp-server)** - GraphRAG memory server with customizable ingestion, data processing and search\n- **[coin_api_mcp](https://github.com/longmans/coin_api_mcp)** - Provides access to [coinmarketcap](https://coinmarketcap.com/) cryptocurrency data.\n- **[Contentful-mcp](https://github.com/ivo-toby/contentful-mcp)** - Read, update, delete, publish content in your [Contentful](https://contentful.com) space(s) from this MCP Server.\n- **[Data Exploration](https://github.com/reading-plus-ai/mcp-server-data-exploration)** - MCP server for autonomous data exploration on .csv-based datasets, providing intelligent insights with minimal effort. NOTE: Will execute arbitrary Python code on your machine, please use with caution!\n- **[Dataset Viewer](https://github.com/privetin/dataset-viewer)** - Browse and analyze Hugging Face datasets with features like search, filtering, statistics, and data export\n- **[DevRev](https://github.com/kpsunil97/devrev-mcp-server)** - An MCP server to integrate with DevRev APIs to search through your DevRev Knowledge Graph where objects can be imported from diff. sources listed [here](https://devrev.ai/docs/import#available-sources).\n- **[Dify](https://github.com/YanxingLiu/dify-mcp-server)** - A simple implementation of an MCP server for dify workflows.\n- **[Docker](https://github.com/ckreiling/mcp-server-docker)** - Integrate with Docker to manage containers, images, volumes, and networks.\n- **[Drupal](https://github.com/Omedia/mcp-server-drupal)** - Server for interacting with [Drupal](https://www.drupal.org/project/mcp) using STDIO transport layer.\n- **[Elasticsearch](https://github.com/cr7258/elasticsearch-mcp-server)** - MCP server implementation that provides Elasticsearch interaction.\n- **[Fetch](https://github.com/zcaceres/fetch-mcp)** - A server that flexibly fetches HTML, JSON, Markdown, or plaintext.\n- **[FireCrawl](https://github.com/vrknetha/mcp-server-firecrawl)** - Advanced web scraping with JavaScript rendering, PDF support, and smart rate limiting\n- **[FlightRadar24](https://github.com/sunsetcoder/flightradar24-mcp-server)** - A Claude Desktop MCP server that helps you track flights in real-time using Flightradar24 data.\n- **[Glean](https://github.com/longyi1207/glean-mcp-server)** - A server that uses Glean API to search and chat.\n- **[Google Calendar](https://github.com/v-3/google-calendar)** - Integration with Google Calendar to check schedules, find time, and add/delete events\n- **[Google Tasks](https://github.com/zcaceres/gtasks-mcp)** - Google Tasks API Model Context Protocol Server.\n- **[Home Assistant](https://github.com/tevonsb/homeassistant-mcp)** - Interact with [Home Assistant](https://www.home-assistant.io/) including viewing and controlling lights, switches, sensors, and all other Home Assistant entities.\n- **[HuggingFace Spaces](https://github.com/evalstate/mcp-hfspace)** - Server for using HuggingFace Spaces, supporting Open Source Image, Audio, Text Models and more. Claude Desktop mode for easy integration.\n- **[Inoyu](https://github.com/sergehuber/inoyu-mcp-unomi-server)** - Interact with an Apache Unomi CDP customer data platform to retrieve and update customer profiles\n- **[Keycloak MCP](https://github.com/ChristophEnglisch/keycloak-model-context-protocol)** - This MCP server enables natural language interaction with Keycloak for user and realm management including creating, deleting, and listing users and realms.\n- **[Kubernetes](https://github.com/Flux159/mcp-server-kubernetes)** - Connect to Kubernetes cluster and manage pods, deployments, and services.\n- **[Linear](https://github.com/jerhadf/linear-mcp-server)** - Allows LLM to interact with Linear's API for project management, including searching, creating, and updating issues.\n- **[LlamaCloud](https://github.com/run-llama/mcp-server-llamacloud)** (by marcusschiesser) - Integrate the data stored in a managed index on [LlamaCloud](https://cloud.llamaindex.ai/)\n- **[MCP Installer](https://github.com/anaisbetts/mcp-installer)** - This server is a server that installs other MCP servers for you.\n- **[mcp-k8s-go](https://github.com/strowk/mcp-k8s-go)** - Golang-based Kubernetes server for MCP to browse pods and their logs, events, namespaces and more. Built to be extensible.\n- **[MSSQL](https://github.com/aekanun2020/mcp-server/)** - MSSQL database integration with configurable access controls and schema inspection\n- **[Markdownify](https://github.com/zcaceres/mcp-markdownify-server)** - MCP to convert almost anything to Markdown (PPTX, HTML, PDF, Youtube Transcripts and more)\n- **[Minima](https://github.com/dmayboroda/minima)** - MCP server for RAG on local files\n- **[MongoDB](https://github.com/kiliczsh/mcp-mongo-server)** - A Model Context Protocol Server for MongoDB.\n- **[MySQL](https://github.com/benborla/mcp-server-mysql)** (by benborla) - MySQL database integration in NodeJS with configurable access controls and schema inspection\n- **[MySQL](https://github.com/designcomputer/mysql_mcp_server)** (by DesignComputer) - MySQL database integration in Python with configurable access controls and schema inspection\n- **[NS Travel Information](https://github.com/r-huijts/ns-mcp-server)** - Access Dutch Railways (NS) real-time train travel information and disruptions through the official NS API.\n- **[Notion](https://github.com/suekou/mcp-notion-server)** (by suekou) - Interact with Notion API.\n- **[Notion](https://github.com/v-3/notion-server)** (by v-3) - Notion MCP integration. Search, Read, Update, and Create pages through Claude chat.\n- **[oatpp-mcp](https://github.com/oatpp/oatpp-mcp)** - C++ MCP integration for Oat++. Use [Oat++](https://oatpp.io) to build MCP servers.\n- **[Obsidian Markdown Notes](https://github.com/calclavia/mcp-obsidian)** - Read and search through your Obsidian vault or any directory containing Markdown notes\n- **[OpenAPI](https://github.com/snaggle-ai/openapi-mcp-server)** - Interact with [OpenAPI](https://www.openapis.org/) APIs.\n- **[OpenCTI](https://github.com/Spathodea-Network/opencti-mcp)** - Interact with OpenCTI platform to retrieve threat intelligence data including reports, indicators, malware and threat actors.\n- **[OpenRPC](https://github.com/shanejonas/openrpc-mpc-server)** - Interact with and discover JSON-RPC APIs via [OpenRPC](https://open-rpc.org).\n- **[Pandoc](https://github.com/vivekVells/mcp-pandoc)** - MCP server for seamless document format conversion using Pandoc, supporting Markdown, HTML, and plain text, with other formats like PDF, csv and docx in development.\n- **[Pinecone](https://github.com/sirmews/mcp-pinecone)** - MCP server for searching and uploading records to Pinecone. Allows for simple RAG features, leveraging Pinecone's Inference API.\n- **[Placid.app](https://github.com/felores/placid-mcp-server)** - Generate image and video creatives using Placid.app templates\n- **[Playwright](https://github.com/executeautomation/mcp-playwright)** - This MCP Server will help you run browser automation and webscraping using Playwright\n- **[Postman](https://github.com/shannonlal/mcp-postman)** - MCP server for running Postman Collections locally via Newman. Allows for simple execution of Postman Server and returns the results of whether the collection passed all the tests.\n- **[RAG Web Browser](https://github.com/apify/mcp-server-rag-web-browser)** An MCP server for Apify's RAG Web Browser Actor to perform web searches, scrape URLs, and return content in Markdown.\n- **[Rememberizer AI](https://github.com/skydeckai/mcp-server-rememberizer)** - An MCP server designed for interacting with the Rememberizer data source, facilitating enhanced knowledge retrieval.\n- **[Salesforce MCP](https://github.com/smn2gnt/MCP-Salesforce)** - Interact with Salesforce Data and Metadata\n- **[Scholarly](https://github.com/adityak74/mcp-scholarly)** - A MCP server to search for scholarly and academic articles.\n- **[Snowflake](https://github.com/isaacwasserman/mcp-snowflake-server)** - This MCP server enables LLMs to interact with Snowflake databases, allowing for secure and controlled data operations.\n- **[Spotify](https://github.com/varunneal/spotify-mcp)** - This MCP allows an LLM to play and use Spotify.\n- **[TMDB](https://github.com/Laksh-star/mcp-server-tmdb)** - This MCP server integrates with The Movie Database (TMDB) API to provide movie information, search capabilities, and recommendations.\n- **[Tavily search](https://github.com/RamXX/mcp-tavily)** - An MCP server for Tavily's search & news API, with explicit site inclusions/exclusions\n- **[Todoist](https://github.com/abhiz123/todoist-mcp-server)** - Interact with Todoist to manage your tasks.\n- **[Vega-Lite](https://github.com/isaacwasserman/mcp-vegalite-server)** - Generate visualizations from fetched data using the VegaLite format and renderer.\n- **[Windows CLI](https://github.com/SimonB97/win-cli-mcp-server)** - MCP server for secure command-line interactions on Windows systems, enabling controlled access to PowerShell, CMD, and Git Bash shells.\n- **[X (Twitter)](https://github.com/EnesCinr/twitter-mcp)** (by EnesCinr) - Interact with twitter API. Post tweets and search for tweets by query.\n- **[X (Twitter)](https://github.com/vidhupv/x-mcp)** (by vidhupv) - Create, manage and publish X/Twitter posts directly through Claude chat.\n- **[XMind](https://github.com/apeyroux/mcp-xmind)** - Read and search through your XMind directory containing XMind files.\n\n## ğŸ“š Frameworks\n\nThese are high-level frameworks that make it easier to build MCP servers.\n\n* [EasyMCP](https://github.com/zcaceres/easy-mcp/) (TypeScript)\n* [FastMCP](https://github.com/punkpeye/fastmcp) (TypeScript)\n\n## ğŸ“š Resources\n\nAdditional resources on MCP.\n\n- **[AiMCP](https://www.aimcp.info)** - A collection of MCP clients&servers to find the right mcp tools by **[Hekmon](https://github.com/hekmon8)**\n- **[Awesome Crypto MCP Servers by badkk](https://github.com/badkk/awesome-crypto-mcp-servers)** - A curated list of MCP servers by **[Luke Fan](https://github.com/badkk)**\n- **[Awesome MCP Servers by appcypher](https://github.com/appcypher/awesome-mcp-servers)** - A curated list of MCP servers by **[Stephen Akinyemi](https://github.com/appcypher)**\n- **[Awesome MCP Servers by punkpeye](https://github.com/punkpeye/awesome-mcp-servers)** (**[website](https://glama.ai/mcp/servers)**) - A curated list of MCP servers by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[Awesome MCP Servers by wong2](https://github.com/wong2/awesome-mcp-servers)** (**[website](https://mcpservers.org)**) - A curated list of MCP servers by **[wong2](https://github.com/wong2)**\n- **[Discord Server](https://glama.ai/mcp/discord)** â€“Â A community discord server dedicated to MCP by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[MCP Badges](https://github.com/mcpx-dev/mcp-badges)** â€“ Quickly highlight your MCP project with clear, eye-catching badges, by **[Ironben](https://github.com/nanbingxyz)**\n- **[MCP X Community](https://x.com/i/communities/1861891349609603310)** â€“Â A X community for MCP by **[Xiaoyi](https://x.com/chxy)**\n- **[mcp-cli](https://github.com/wong2/mcp-cli)** - A CLI inspector for the Model Context Protocol by **[wong2](https://github.com/wong2)**\n- **[mcp-get](https://mcp-get.com)** - Command line tool for installing and managing MCP servers by **[Michael Latman](https://github.com/michaellatman)**\n- **[mcp-manager](https://github.com/zueai/mcp-manager)** - Simple Web UI to install and manage MCP servers for Claude Desktop by **[Zue](https://github.com/zueai)**\n- **[MCPHub](https://github.com/Jeamee/MCPHub-Desktop)** â€“Â An Open Source MacOS & Windows GUI Desktop app for discovering, installing and managing MCP servers by **[Jeamee](https://github.com/jeamee)**\n- **[mcp.run](https://mcp.run)** - A hosted registry and control plane to install & run secure + portable MCP Servers.\n- **[Open-Sourced MCP Servers Directory](https://github.com/chatmcp/mcp-directory)** - A curated list of MCP servers by **[mcpso](https://mcp.so)**\n- **[PulseMCP](https://www.pulsemcp.com)** ([API](https://www.pulsemcp.com/api)) - Community hub & weekly newsletter for discovering MCP servers, clients, articles, and news by **[Tadas Antanavicius](https://github.com/tadasant)**, **[Mike Coughlin](https://github.com/macoughl)**, and **[Ravina Patel](https://github.com/ravinahp)**\n- **[r/mcp](https://www.reddit.com/r/mcp)** â€“Â A Reddit community dedicated to MCP by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[Smithery](https://smithery.ai/)** - A registry of MCP servers to find the right tools for your LLM agents by **[Henry Mao](https://github.com/calclavia)**\n\n## ğŸš€ Getting Started\n\n### Using MCP Servers in this Repository\nTypescript-based servers in this repository can be used directly with `npx`.\n\nFor example, this will start the [Memory](src/memory) server:\n```sh\nnpx -y @modelcontextprotocol/server-memory\n```\n\nPython-based servers in this repository can be used directly with [`uvx`](https://docs.astral.sh/uv/concepts/tools/) or [`pip`](https://pypi.org/project/pip/). `uvx` is recommended for ease of use and setup.\n\nFor example, this will start the [Git](src/git) server:\n```sh\n# With uvx\nuvx mcp-server-git\n\n# With pip\npip install mcp-server-git\npython -m mcp_server_git\n```\n\nFollow [these](https://docs.astral.sh/uv/getting-started/installation/) instructions to install `uv` / `uvx` and [these](https://pip.pypa.io/en/stable/installation/) to install `pip`.\n\n### Using an MCP Client\nHowever, running a server on its own isn't very useful, and should instead be configured into an MCP client. For example, here's the Claude Desktop configuration to use the above server:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-memory\"]\n    }\n  }\n}\n```\n\nAdditional examples of using the Claude Desktop as an MCP client might look like:\n\n```json\n{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/path/to/allowed/files\"]\n    },\n    \"git\": {\n      \"command\": \"uvx\",\n      \"args\": [\"mcp-server-git\", \"--repository\", \"path/to/git/repo\"]\n    },\n    \"github\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-github\"],\n      \"env\": {\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"<YOUR_TOKEN>\"\n      }\n    },\n    \"postgres\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-postgres\", \"postgresql://localhost/mydb\"]\n    }\n  }\n}\n```\n\n## ğŸ› ï¸ Creating Your Own Server\n\nInterested in creating your own MCP server? Visit the official documentation at [modelcontextprotocol.io](https://modelcontextprotocol.io/introduction) for comprehensive guides, best practices, and technical details on implementing MCP servers.\n\n## ğŸ¤ Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for information about contributing to this repository.\n\n## ğŸ”’ Security\n\nSee [SECURITY.md](SECURITY.md) for reporting security vulnerabilities.\n\n## ğŸ“œ License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## ğŸ’¬ Community\n\n- [GitHub Discussions](https://github.com/orgs/modelcontextprotocol/discussions)\n\n## â­ Support\n\nIf you find MCP servers useful, please consider starring the repository and contributing new servers or improvements!\n\n---\n\nManaged by Anthropic, but built together with the community. The Model Context Protocol is open source and we encourage everyone to contribute their own servers and improvements!\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "L3-N0X--Minecraft-Wiki-MCP": {
      "owner": "L3-N0X",
      "name": "Minecraft-Wiki-MCP",
      "url": "https://github.com/L3-N0X/Minecraft-Wiki-MCP",
      "imageUrl": "https://github.com/L3-N0X.png",
      "description": "Browse and search the official Minecraft Wiki for detailed information on structures, entities, items, and blocks. Access multi-language support and navigate through wiki categories and specific sections for comprehensive content.",
      "stars": 6,
      "forks": 4,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-20T04:16:05Z",
      "readme_content": "# Minecraft Wiki MCP\n[![smithery badge](https://smithery.ai/badge/@L3-N0X/Minecraft-Wiki-MCP)](https://smithery.ai/server/@L3-N0X/Minecraft-Wiki-MCP)\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/f80cbb34-35d6-4652-a302-2413ffe60cb4)\n\nA MCP Server for browsing the official Minecraft Wiki!\n\n> [!WARNING]\n> This MCP is still in development and while working most of the time, there might still be smaller issues and bugs left!\n\n<a href=\"https://glama.ai/mcp/servers/@L3-N0X/Minecraft-Wiki-MCP\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@L3-N0X/Minecraft-Wiki-MCP/badge\" alt=\"Minecraft Wiki MCP server\" />\n</a>\n\n## Features\n\n- **Wiki Search**: Find information about Minecraft structures, entities, items, and blocks\n- **Page Navigation**: Get summaries and detailed content from wiki pages\n- **Section Access**: Target specific sections within wiki pages\n- **Category Browsing**: Explore wiki categories and their member pages\n- **Multi-Language Support**: Connect to different language versions of the Minecraft Wiki\n\n## Installation\n\nCurrently, only local installation is supported, other might follow!\n\n### Installing via Smithery\n\nTo install Minecraft Wiki Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@L3-N0X/Minecraft-Wiki-MCP):\n\n```bash\nnpx -y @smithery/cli install @L3-N0X/Minecraft-Wiki-MCP --client claude\n```\n\n### Manual Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/L3-N0X/Minecraft-Wiki-MCP.git\ncd Minecraft-Wiki-MCP\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\nThen, you can use the server with this configuration in your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"minecraft-wiki\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/your/dist/server.js\", \n        \"--api-url\",\n        \"https://minecraft.wiki/api.php\"\n      ]\n    }\n  }\n}\n```\n\n## Configuration\n\nMake sure to update the path to the server.js file!\nBy default, this server connects to <https://minecraft.wiki/api.php> (English version). You can use a different wiki API URL by using the `api-url` option to access different language versions:\n\n```json\n{\n  \"mcpServers\": {\n    \"minecraft-wiki\": {\n      \"command\": \"node\",\n       \"args\": [\n        \"/path/to/your/dist/server.js\", \n        \"--api-url\",\n        \"https://de.minecraft.wiki/api.php\" // German version\n      ]\n    }\n  }\n}\n```\n\n## Available Tools\n\nThis server provides the following tools for interacting with the Minecraft Wiki:\n\n### Search and Navigation\n\n- `MinecraftWiki_searchWiki`: Search for structures, entities, items, or blocks\n- `MinecraftWiki_getPageSummary`: Get page summary and list of available sections\n- `MinecraftWiki_resolveRedirect`: Resolve redirect pages to their targets\n\n### Page Content\n\n- `MinecraftWiki_getPageContent`: Get full page content\n- `MinecraftWiki_getPageSection`: Get specific section content\n- `MinecraftWiki_getSectionsInPage`: Get overview of all sections in a page\n\n### Categories\n\n- `MinecraftWiki_listAllCategories`: List all available categories\n- `MinecraftWiki_listCategoryMembers`: List pages within a category\n- `MinecraftWiki_getCategoriesForPage`: Get categories for a specific page\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "leescot--pubmed-mcp-smithery": {
      "owner": "leescot",
      "name": "pubmed-mcp-smithery",
      "url": "https://github.com/leescot/pubmed-mcp-smithery",
      "imageUrl": "https://github.com/leescot.png",
      "description": "Search and retrieve academic papers from the PubMed database using enhanced tools such as MeSH term lookup, publication statistics, and structured PICO-based evidence searches.",
      "stars": 5,
      "forks": 5,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-07-12T02:43:23Z",
      "readme_content": "# PubMed Enhanced Search MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@leescot/pubmed-mcp-smithery)](https://smithery.ai/server/@leescot/pubmed-mcp-smithery)\n\nA Model Content Protocol server that provides enhanced tools to search and retrieve academic papers from PubMed database, with additional features such as MeSH term lookup, publication count statistics, and PICO-based evidence search.\n\n## Features\n\n- Search PubMed by keywords with optional journal filter\n- Support for sorting results by relevance or date (newest/oldest first)\n- Get MeSH (Medical Subject Headings) terms related to a search word\n- Get publication counts for multiple search terms (useful for comparing prevalence)\n- Retrieve detailed paper information including abstract, DOI, authors, and keywords\n- Perform structured PICO-based searches with support for synonyms and combination queries\n\n## Installing\n\n### Prerequisites\n\n- Python 3.6+\n- pip\n\n### Installation\n\n1. Clone this repository:\n\n   ```\n   git clone https://github.com/leescot/pubmed-mcp-smithery\n   cd pubmed-mcp-smithery\n   ```\n\n2. Install dependencies:\n   ```\n   pip install fastmcp requests\n   ```\n\n## Usage\n\n### Running locally\n\nStart the server:\n\n```\npython pubmed_enhanced_mcp_server.py\n```\n\nFor development mode with auto-reloading:\n\n```\nmcp dev pubmed_enhanced_mcp_server.py\n```\n\n### Adding to Claude Desktop\n\nEdit your Claude Desktop configuration file (_CLAUDE_DIRECTORY/claude_desktop_config.json_) to add the server:\n\n```json\n\"pubmed-enhanced\": {\n    \"command\": \"python\",\n    \"args\": [\n        \"/path/pubmed-mcp-smithery/pubmed_enhanced_mcp_server.py\"\n    ]\n}\n```\n\n## MCP Functions\n\nThe server provides these main functions:\n\n1. `search_pubmed` - Search PubMed for articles matching keywords with optional journal filtering\n\n   ```python\n   # Example\n   results = await search_pubmed(\n       keywords=[\"diabetes\", \"insulin resistance\"],\n       journal=\"Nature Medicine\",\n       num_results=5,\n       sort_by=\"date_desc\"\n   )\n   ```\n\n2. `get_mesh_terms` - Look up MeSH terms related to a medical concept\n\n   ```python\n   # Example\n   mesh_terms = await get_mesh_terms(\"diabetes\")\n   ```\n\n3. `get_pubmed_count` - Get the count of publications for multiple search terms\n\n   ```python\n   # Example\n   counts = await get_pubmed_count([\"diabetes\", \"obesity\", \"hypertension\"])\n   ```\n\n4. `format_paper_details` - Get detailed information about specific papers by PMID\n\n   ```python\n   # Example\n   paper_details = await format_paper_details([\"12345678\", \"87654321\"])\n   ```\n\n5. `pico_search` - Perform structured PICO (Population, Intervention, Comparison, Outcome) searches with synonyms\n   ```python\n   # Example\n   pico_results = await pico_search(\n       p_terms=[\"diabetes\", \"type 2 diabetes\", \"T2DM\"],\n       i_terms=[\"metformin\", \"glucophage\"],\n       c_terms=[\"sulfonylurea\", \"glipizide\"],\n       o_terms=[\"HbA1c reduction\", \"glycemic control\"]\n   )\n   ```\n\n## PICO Search Functionality\n\nThe PICO search tool helps researchers conduct evidence-based literature searches by:\n\n1. Allowing multiple synonym terms for each PICO element\n2. Combining terms within each element using OR operators\n3. Performing AND combinations between elements (P AND I, P AND I AND C, etc.)\n4. Returning both search queries and publication counts for each combination\n\nThis approach helps refine research questions and identify the most relevant literature.\n\n## Rate Limiting\n\nThe server implements automatic retry mechanism with backoff delays to handle potential rate limiting by NCBI's E-utilities service.\n\n## License\n\nThis project is licensed under the BSD 3-Clause License - see the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Libaizaima--LearnPython": {
      "owner": "Libaizaima",
      "name": "LearnPython",
      "url": "https://github.com/Libaizaima/LearnPython",
      "imageUrl": "https://github.com/Libaizaima.png",
      "description": "A collection of Python coding examples and projects designed to teach Python programming through practical applications such as web scraping, data visualization, and advanced topics like asynchronous programming and RESTful API development.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2025-03-05T14:11:44Z",
      "readme_content": "# LearnPython\nä»¥æ’¸ä»£ç çš„å½¢å¼å­¦ä¹ Python, å…·ä½“è¯´æ˜åœ¨[çŸ¥ä¹ä¸“æ -æ’¸ä»£ç ,å­¦çŸ¥è¯†](https://zhuanlan.zhihu.com/pythoner)  \n\n===================================================================================================\n### python_base.py: åƒè¡Œä»£ç å…¥é—¨Python\n\n### python_visual.py: 15å¼ å›¾å…¥é—¨Matplotlib\n\n### python_visual_animation.py: ä½¿ç”¨Matplotlibç”»åŠ¨æ€å›¾å®ä¾‹\n\n### python_spider.py: ä¸€ä¸ªå¾ˆâ€œæ°´â€çš„Pythonçˆ¬è™«å…¥é—¨ä»£ç æ–‡ä»¶\n\n### python_weibo.py: â€œå²ä¸Šæœ€è¯¦ç»†â€çš„Pythonæ¨¡æ‹Ÿç™»å½•æ–°æµªå¾®åšæµç¨‹\n\n### python_lda.py: ç©ç‚¹é«˜çº§çš„--å¸¦ä½ å…¥é—¨Topicæ¨¡å‹LDAï¼ˆå°æ”¹è¿›+é™„æºç ï¼‰\n\n### python_sqlalchemy.py: ä½œä¸ºä¸€ä¸ªPythoner, ä¸ä¼šSQLAlchemyéƒ½ä¸å¥½æ„æ€è·ŸåŒè¡Œæ‰“æ‹›å‘¼ï¼\n\n### python_oneline.py: å‡ ä¸ªå°ä¾‹å­å‘Šè¯‰ä½ , ä¸€è¡ŒPythonä»£ç èƒ½å¹²å“ªäº›äº‹\n\n### python_requests.py: Pythonä¸­æœ€å¥½ç”¨çš„çˆ¬è™«åº“Requestsä»£ç å®ä¾‹\n\n### python_functional.py: Pythonè¿›é˜¶: å‡½æ•°å¼ç¼–ç¨‹å®ä¾‹ï¼ˆé™„ä»£ç ï¼‰\n\n### python_decorator.py: Pythonè¿›é˜¶: é€šè¿‡å®ä¾‹è¯¦è§£è£…é¥°å™¨ï¼ˆé™„ä»£ç ï¼‰\n\n### python_datetime.py: ä½ çœŸçš„äº†è§£Pythonä¸­çš„æ—¥æœŸæ—¶é—´å¤„ç†å—ï¼Ÿ\n\n### python_metaclass.py: Pythonè¿›é˜¶: ä¸€æ­¥æ­¥ç†è§£Pythonä¸­çš„å…ƒç±»metaclass\n\n### python_coroutine.py: Pythonè¿›é˜¶: ç†è§£Pythonä¸­çš„å¼‚æ­¥IOå’Œåç¨‹(Coroutine), å¹¶åº”ç”¨åœ¨çˆ¬è™«ä¸­\n\n### python_aiohttp.py: Pythonä¸­æœ€å¥½ç”¨çš„å¼‚æ­¥çˆ¬è™«åº“Aiohttpä»£ç å®ä¾‹\n\n### python_thread_multiprocess.py: Pythonè¿›é˜¶: èŠèŠIOå¯†é›†å‹ä»»åŠ¡ã€è®¡ç®—å¯†é›†å‹ä»»åŠ¡ï¼Œä»¥åŠå¤šçº¿ç¨‹ã€å¤šè¿›ç¨‹\n\n### python_version36.py: Python3.6æ­£å¼ç‰ˆè¦æ¥äº†, ä½ æœŸå¾…å“ªäº›æ–°ç‰¹æ€§ï¼Ÿ\n\n### python_magic_methods: Pythonè¿›é˜¶: å®ä¾‹è®²è§£Pythonä¸­çš„é­”æ³•å‡½æ•°(Magic Methods)\n\n### python_restful_api.py: åˆ©ç”¨Pythonå’ŒFlaskå¿«é€Ÿå¼€å‘RESTful API\n\n### python_restful_api.py: RESTful APIè¿›é˜¶: è¿æ¥æ•°æ®åº“ã€æ·»åŠ å‚æ•°ã€Tokenè®¤è¯ã€è¿”å›ä»£ç è¯´æ˜ç­‰\n\n### python_context.py: Withè¯­å¥å’Œä¸Šä¸‹æ–‡ç®¡ç†å™¨ContextManager\n\n### python_flask.py: Flaskç›¸å…³è¯´æ˜\n\n### MyShow: ç©ç‚¹å¥½ç©çš„--çŸ¥ä¹å…¨éƒ¨è¯é¢˜å…³ç³»å¯è§†åŒ–\n\n### python_markov_chain.py: ç©ç‚¹å¥½ç©çš„--ä½¿ç”¨é©¬å°”å¯å¤«æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆæ–‡ç« \n\n### python_wechat.py: ç©ç‚¹å¥½ç©çš„--è‡ªå·±å†™ä¸€ä¸ªå¾®ä¿¡å°åŠ©æ‰‹\n\n### python_csv.py: Pythonä¸­CSVæ–‡ä»¶çš„ç®€å•è¯»å†™  \n\n### python_numpy.py: ä½¿ç”¨numpyè¿›è¡ŒçŸ©é˜µæ“ä½œ\n\n### python_mail.py: ä½¿ç”¨Pythonè‡ªåŠ¨å‘é€é‚®ä»¶ï¼ŒåŒ…æ‹¬å‘é€HTMLä»¥åŠå›¾ç‰‡ã€é™„ä»¶ç­‰\n\n### python_redis.py: Pythonæ“ä½œRediså®ç°æ¶ˆæ¯çš„å‘å¸ƒä¸è®¢é˜…\n\n### python_schedule.py: Pythonè¿›è¡Œè°ƒåº¦å¼€å‘\n\n### python_socket.py: Pythonçš„socketå¼€å‘å®ä¾‹\n\n### python_re.pyï¼šPythonçš„reæ¨¡å—çš„ä¸»è¦åŠŸèƒ½ä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒä»¬è¿›è¡Œå­—ç¬¦ä¸²åŒ¹é…å’Œæ›¿æ¢\n\n### Plotlyç›®å½•: ä¸€äº›plotlyç”»å›¾çš„å®ä¾‹ï¼Œä½¿ç”¨jupyter notebookç¼–å†™\n\n===================================================================================================\n\n### æ‚¨å¯ä»¥forkè¯¥é¡¹ç›®, å¹¶åœ¨ä¿®æ”¹åæäº¤Pull request, çœ‹åˆ°åä¼šå°½é‡è¿›è¡Œä»£ç åˆå¹¶\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "linxule--lotus-wisdom-mcp": {
      "owner": "linxule",
      "name": "lotus-wisdom-mcp",
      "url": "https://github.com/linxule/lotus-wisdom-mcp",
      "imageUrl": "https://github.com/linxule.png",
      "description": "An MCP server that provides a structured approach to problem-solving inspired by the Lotus Sutra, integrating both analytical techniques and intuitive insights. It features a step-by-step thought process, meditation pauses for natural insight development, and the ability to visualize the thought process with colors and symbols.",
      "stars": 13,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-27T04:54:01Z",
      "readme_content": "# ğŸª· Lotus Wisdom MCP Server\n\n<p align=\"center\">\n  <img src=\"assets/lotus-flower.png\" alt=\"Lotus Flower\" width=\"400\"/>\n</p>\n\nAn MCP server implementation that provides a tool for problem-solving using the Lotus Sutra's wisdom framework, combining analytical thinking with intuitive wisdom.\n\n## Features\n\n* Multi-faceted problem-solving approach inspired by the Lotus Sutra\n* Step-by-step thought process with different thinking techniques\n* Meditation pauses to allow insights to emerge naturally\n* Beautifully formatted thought process visualization with colors and symbols\n* Tracks both tag journey and wisdom domain movements\n* Final integration of insights into a clear response\n\n## Background\n\nThis MCP server was developed from the [Lotus OS prompt](https://github.com/linxule/prompts/blob/main/cognitive-techniques/lotus_os.md), which was designed to implement a cognitive framework based on the Lotus Sutra. The MCP server format makes this framework more accessible and easier to use with Claude and other AI assistants.\n\nNote: The original prompt framework may work less effectively with newer Claude models, but this MCP server implementation provides consistent functionality across model versions.\n\n## Implementation Details\n\nThe server implements a structured thinking process using wisdom domains inspired by the Lotus Sutra:\n\n### Wisdom Domains and Tags\n\nThe server organizes thoughts using five wisdom domains (all valid values for the `tag` input parameter):\n\n* **Skillful Means** (ğŸ”†): `upaya`, `expedient`, `direct`, `gradual`, `sudden`\n  - Different approaches to truth - sometimes direct pointing, sometimes gradual unfolding\n\n* **Non-Dual Recognition** (â˜¯ï¸): `recognize`, `transform`, `integrate`, `transcend`, `embody`\n  - Aspects of awakening to what's already present - recognition IS transformation\n\n* **Meta-Cognitive** (ğŸ§ ): `examine`, `reflect`, `verify`, `refine`, `complete`\n  - The mind watching its own understanding unfold\n\n* **Process Flow** (ğŸŒŠ): `open`, `engage`, `express`\n  - A natural arc that can contain any of the above approaches\n\n* **Meditation** (ğŸ§˜): `meditate`\n  - Pausing to let insights emerge from stillness\n\n### Thought Visualization\n\nEach thought is beautifully formatted with:\n\n* Colorful output using the chalk library\n* Domain-specific symbols and colors\n* Box-drawing characters to create clear thought boundaries\n* Special meditation formatting with pause indicators\n* Journey tracking showing both tag path and domain movements\n\nNote: The visualization appears in the server console output, helping developers track the thinking process.\n\n### Process Flow\n\n1. The user submits a problem to solve\n2. The model works through a sequence of thoughts using different tags\n3. Each thought builds on previous ones and may revise understanding\n4. The tool tracks both the tag journey and wisdom domain movements\n5. Meditation pauses can be included for clarity\n6. When status='WISDOM_READY' is returned, the tool's work is complete\n7. The model then expresses the final wisdom naturally in its own voice\n\n## Available Tools\n\n### lotuswisdom\n\nA tool for problem-solving using the Lotus Sutra's wisdom framework, with various approaches to understanding.\n\n**Inputs:**\n\n* `tag` (string, required): The current processing technique (must be one of the tags listed above)\n* `content` (string, required): The content of the current processing step\n* `stepNumber` (integer, required): Current number in sequence\n* `totalSteps` (integer, required): Estimated total steps needed\n* `nextStepNeeded` (boolean, required): Whether another step is needed\n* `isMeditation` (boolean, optional): Whether this step is a meditative pause\n* `meditationDuration` (integer, optional): Duration for meditation in seconds (1-10)\n\n**Returns:**\n- Processing status with current step information, wisdom domain, and journey tracking\n- `MEDITATION_COMPLETE` status for meditation steps\n- `WISDOM_READY` status when the contemplative process is complete\n\n### lotuswisdom_summary\n\nGet a summary of the current contemplative journey.\n\n**Inputs:** None\n\n**Returns:**\n- Journey length\n- Domain journey showing movement between wisdom domains\n- Summary of all steps with their tags, domains, and brief content\n\n## Usage\n\nThe Lotus Wisdom tool is designed for:\n\n* Breaking down complex problems requiring multi-faceted understanding\n* Questions that benefit from both direct and gradual approaches\n* Problems where apparent contradictions need integration\n* Situations requiring both analytical and intuitive understanding\n* Tasks that benefit from meditative pauses to allow insight\n* Questions containing their own inherent wisdom\n\n## Example Usage\n\nHere's how a conversation with Claude might flow when using the Lotus Wisdom MCP server:\n\n**User**: \"Help me understand the relationship between freedom and responsibility.\"\n\n**Claude** would then use the lotuswisdom tool through multiple steps:\n\n1. First, establish an opening thought:\n```json\n{\n  \"tag\": \"open\",\n  \"content\": \"The question explores the relationship between freedom and responsibility, which contain an apparent tension but also deep connection.\",\n  \"stepNumber\": 1,\n  \"totalSteps\": 5,\n  \"nextStepNeeded\": true\n}\n```\n\n2. Then engage with different perspectives:\n```json\n{\n  \"tag\": \"direct\",\n  \"content\": \"Freedom and responsibility are two sides of the same coin. True freedom isn't absence of constraints but the capacity to choose our response within constraints.\",\n  \"stepNumber\": 2,\n  \"totalSteps\": 5,\n  \"nextStepNeeded\": true\n}\n```\n\n3. Perhaps take a meditation pause:\n```json\n{\n  \"tag\": \"meditate\",\n  \"content\": \"Contemplating how freedom without responsibility becomes chaos, and responsibility without freedom becomes oppression.\",\n  \"stepNumber\": 3,\n  \"totalSteps\": 5,\n  \"nextStepNeeded\": true,\n  \"isMeditation\": true\n}\n```\n\n4. Integrate the understanding:\n```json\n{\n  \"tag\": \"integrate\",\n  \"content\": \"Freedom and responsibility mutually enable each other. Our freedom to choose gives rise to our responsibility for what we choose, and our willingness to take responsibility expands our freedom.\",\n  \"stepNumber\": 4,\n  \"totalSteps\": 5,\n  \"nextStepNeeded\": true\n}\n```\n\n5. Express the final understanding:\n```json\n{\n  \"tag\": \"express\",\n  \"content\": \"The paradox resolves when we see that authentic freedom includes responsibility as its natural expression.\",\n  \"stepNumber\": 5,\n  \"totalSteps\": 5,\n  \"nextStepNeeded\": false\n}\n```\n\nWhen the tool returns `status: 'WISDOM_READY'`, Claude then speaks the final wisdom naturally, integrating all the insights from the contemplative journey.\n\n## Configuration\n\n### Usage with Claude Desktop\n\nAdd this to your `claude_desktop_config.json`:\n\n#### From Smithery (recommended for easy installation)\n\n```json\n{\n  \"mcpServers\": {\n    \"lotus-wisdom\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@smithery/server-linxule-lotus-wisdom-mcp\"\n      ]\n    }\n  }\n}\n```\n\nOr install directly via [Smithery.ai](https://smithery.ai/server/@linxule/lotus-wisdom-mcp)\n\n#### From npm\n\n```json\n{\n  \"mcpServers\": {\n    \"lotus-wisdom\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\", \n        \"lotus-wisdom-mcp\"\n      ]\n    }\n  }\n}\n```\n\n#### From GitHub\n\n```json\n{\n  \"mcpServers\": {\n    \"lotus-wisdom\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\", \n        \"git+https://github.com/linxule/lotus-wisdom-mcp.git\"\n      ]\n    }\n  }\n}\n```\n\n#### Docker\n\n```json\n{\n  \"mcpServers\": {\n    \"lotus-wisdom\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"lotus-wisdom-mcp\"\n      ]\n    }\n  }\n}\n```\n\n### Building\n\nTo build the project locally:\n\n```bash\nnpm install\nnpm run build\n```\n\nTo build the Docker image:\n\n```bash\ndocker build -t lotus-wisdom-mcp -f Dockerfile .\n```\n\n### Development\n\nFor local development:\n\n```bash\nnpm install\nnpm run dev\n```\n\nEnable debug mode by setting the environment variable:\n\n```bash\nLOTUS_DEBUG=true npm start\n```\n\n## How It Works\n\nThe Lotus Wisdom framework recognizes that wisdom often emerges not through linear thinking but through a dance between different modes of understanding. The tool facilitates this by:\n\n1. **Tracking Wisdom Domains**: As you move through different tags, the tool tracks which wisdom domains you're engaging, helping you see the shape of your inquiry.\n\n2. **Journey Consciousness**: The tool maintains awareness of your complete journey, showing both the sequence of tags used and the movement between wisdom domains.\n\n3. **Non-Linear Progress**: While steps are numbered, the process isn't strictly linear. You can revisit, revise, and branch as understanding deepens.\n\n4. **Integration Points**: Tags like `integrate`, `transcend`, and `embody` help weave insights together rather than keeping them separate.\n\n5. **Natural Expression**: The tool handles the contemplative process, but the final wisdom is always expressed naturally by the AI, not as formatted output.\n\n## License\n\nThis MCP server is licensed under the MIT License. For more details, please see the LICENSE file in the project repository.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit issues or pull requests on the [GitHub repository](https://github.com/linxule/lotus-wisdom-mcp).\n\n## Version\n\nCurrent version: 0.1.2",
      "npm_url": "",
      "npm_downloads": 0
    },
    "LoganLxb--LoganLxb": {
      "owner": "LoganLxb",
      "name": "LoganLxb",
      "url": "https://github.com/LoganLxb/LoganLxb",
      "imageUrl": "https://github.com/LoganLxb.png",
      "description": "Logan provides tools and applications aimed at enhancing user interaction in mixed reality environments through augmented and virtual reality technologies. It focuses on facilitating the development of immersive digital experiences and applications.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2024-10-08T18:42:17Z",
      "readme_content": "<h2 align=\"center\">Hi there ğŸ‘‹</h2>\n<!--\n**LoganLxb/LoganLxb** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.\n-->\n\n## ğŸ–¥ï¸ Logan\n\nI'm a developers experienced in creating and developing the future thanks to AR,VR and Mixed reality.\n\n- ğŸ”­ Iâ€™m currently working on democratizing mixed reality with Glassear\n- ğŸŒ± Iâ€™m currently learning computer vision, python and c#\n\n## ğŸ’¬ Ask me about ...\n* Unity development\n* Mobile / headmounted Augmented Reality\n* Virtual Reality\n* Image detection\n\n##  ğŸ‘€ Find me\n- ğŸ“« How to reach me: logan@xrexp.io\n\n[![Top Langs](https://github-readme-stats.vercel.app/api/top-langs/?username=LoganLxb&layout=compact&theme=gruvbox)](https://github.com/LoganLxb/github-readme-stats)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "zachary-lzc--go": {
      "owner": "zachary-lzc",
      "name": "go",
      "url": "https://github.com/zachary-lzc/go",
      "imageUrl": "https://github.com/zachary-lzc.png",
      "description": "Facilitates the development and deployment of Go applications within a containerized environment, optimizing performance and simplifying management processes. Provides tools for building and running Go projects with minimal setup.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "HTML",
      "updated_at": "2024-12-05T14:57:43Z",
      "readme_content": "# go\nlearn go \n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "M-Gonzalo--cosa-sai": {
      "owner": "M-Gonzalo",
      "name": "cosa-sai",
      "url": "https://github.com/M-Gonzalo/cosa-sai",
      "imageUrl": "https://github.com/M-Gonzalo.png",
      "description": "Access documentation for a variety of technologies through the Gemini API, leveraging a curated knowledge base to provide accurate responses to complex queries. This server is designed to handle large context windows for improved comprehension of technical materials.",
      "stars": 13,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-05-23T00:21:06Z",
      "readme_content": "# Gemini Docs MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@M-Gonzalo/cosa-sai)](https://smithery.ai/server/@M-Gonzalo/cosa-sai)\n\n## Description\n\nThis project implements an MCP server that enables access to documentation for various technologies using the Gemini API with its gigantic context window of 2M tokens. It should work for any client, but is targeted especially to the Roo/Cline environment.\n\nThis approach offers several advantages over simply browsing the web or using a search engine:\n\n*   **Access to a curated knowledge base:** The LLM uses a specific set of documentation, avoiding junk results and false positives that can confuse the model.\n*   **Overcomes context window limitations:** By providing the documentation directly, the LLM can access more information than would be possible with web search alone.\n*   **Tailored and well-thought-out responses:** The LLM doesn't just provide snippets from the documentation, but crafts well-reasoned answers that take into consideration the entire specification for the technology in question. This allows for more complex questions like \"what alternative ways of doing X are there?\" or \"is this snippet idiomatic?\".\n\nIt also overcomes some problemmatic hurdles of traditional RAG systems:\n\n*   **No need for chunking:** The LLM can access the entire documentation in one go, without needing to chunk it into smaller pieces, and having to painfully test and choose between all the possible ways of doing so.\n*   **No need for a retriever:** The Gemini API itself serves as a powerful retriever that can access the entire documentation, so there's no need to implement a custom one.\n*   **No vectorization, vector DBs, or other complex systems:** We work directly with plain text, and since we can see everything at once, we don't need vectors for similarity search. If it's relevant, we know about it.\n\nThere are some limitations, though:\n\n*   **No real-time updates:** The documentation is static and won't be updated in real time. This means that the LLM might not know about the latest features or changes in the technology unless we manually update the documentation or provide an automated way of doing so.\n*   **A lot of tokens is not the same as an infinite context window:** The LLM can only see about 2 million tokens at a time, so it might not be able to see the entire documentation for some technologies. This is especially true for large and complex stacks with copious amounts of documentation.\n*   **It's not that fast:** We're using Gemini 1.5 Pro (not Flash), and we're loading it with a whole bunch of documentation, so it might take a while to get a response. This is especially true for the first query, as the server needs to upload the documentation to the API.\n\n## Features\n\n*   Enables clients to take an \"ask your docs\" approach to learning and debugging for an arbitrary number of technologies, including some obscure or lesser-known ones.\n*   Uses the Gemini API to answer questions about the documentation.\n*   Supports multiple tools for querying the documentation:\n    *   `can_x_be_done`: Check if a specific task can be done in a given technology.\n    *   `hints_for_problem`: Get hints for solving a specific problem.\n    *   `is_this_good_practice`: Check if a code snippet follows good practices.\n    *   `how_to_do_x`: Get examples and alternative approaches for a specific task.\n*   Provides a logging system for debugging (enabled with the `--verbose` flag).\n\n## Getting Started\n\n### Installing via Smithery\n\nTo install Gemini Docs Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@M-Gonzalo/cosa-sai):\n\n```bash\nnpx -y @smithery/cli install @M-Gonzalo/cosa-sai --client claude\n```\n\nThis MCP server is automatically started and managed by the client. To enable it, you need to configure it in your settings file (for example, `~/.config/Code/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`). There's usually a button for opening up the settings file in the client.\n\nHere's the configuration for this server:\n\n```json\n{\n  \"command\": \"bun\",\n  \"args\": [\n    \"--watch\",\n    \"path/to/repo/cosa-sai-mcp/src/index.ts\",\n    \"--verbose\"\n  ],\n  \"env\": {\n    \"GEMINI_API_KEY\": \"<your_gemini_api_key>\"\n  },\n  \"disabled\": false,\n  \"alwaysAllow\": [\n    \"can_x_be_done\",\n    \"hints_for_problem\",\n    \"is_this_good_practice\",\n    \"how_to_do_x\"\n  ],\n  \"timeout\": 60 // in seconds\n}\n```\n\n## Procuring and Sanitizing the Knowledge Base\n\nThis MCP server requires a knowledge base of documentation to answer questions. You must manually procure this knowledge base, either by downloading a public repository, scraping a website, or using other methods.\n\nAn optional sanitation process can be performed to clean up the original documentation from styling and other unnecessary content.\n\nHere are some basic tools for doing so. Better solutions are encouraged:\n\n**Naive Scrapper:**\n\n```bash\nwget --mirror --convert-links --adjust-extension --page-requisites --no-parent --directory-prefix=./local_copy --no-verbose --show-progress $1\n```\n\n**Quick and Dirty Conversor to Markdown-ish:**\n\n```bash\n#!/bin/bash\n\ndirectory=\"${1:-.}\"  # Default to current directory if no argument is provided\noutput_file=\"${2:-concatenated.md}\"  # Default output file name\n\necho \"Concatenating files in '$directory' into '$output_file'...\"\n\n# Clear output file if it exists\ntruncate -s 0 \"$output_file\"\n\n# Find all files (excluding directories) and process them\nfind \"$directory\" -type f -name '*.html' | while IFS= read -r file; do\n    echo \"=== ${file#./} ===\" >> \"$output_file\"\n    cat \"$file\" \\\n    | grep -v 'base64' \\\n    | html2markdown >> \"$output_file\"\n    echo -e \"\\n\" >> \"$output_file\"\ndone\n\necho \"Done! Output saved to '$output_file'\"\n```\n\n## Usage\n\nThis server provides the following tools:\n\n*   **can\\_x\\_be\\_done:** Checks if a specific task can be done in a given technology.\n    *   **Input:** `docs`, `prompt`, `x`, `technology`\n    *   **Output:** `success`, `data`\n*   **hints\\_for\\_problem:** Gets hints for solving a specific problem.\n    *   **Input:** `docs`, `prompt`, `problem`, `context`, `environment`\n    *   **Output:** `success`, `data`\n*   **is\\_this\\_good\\_practice:** Checks if a code snippet follows good practices.\n    *   **Input:** `docs`, `prompt`, `snippet`, `context`\n    *   **Output:** `success`, `data`\n*   **how\\_to\\_do\\_x:** Gets examples and alternative approaches for a specific task.\n    *   **Input:** `docs`, `prompt`, `x`, `technology`\n    *   **Output:** `success`, `data`\n\n## Contributing\n\nContributions are welcome! Please follow these guidelines:\n\n1.  Fork the repository.\n2.  Create a new branch for your feature or bug fix.\n3.  Make your changes and commit them with descriptive commit messages.\n4.  Submit a pull request.\n\n## License\n\nThis project is licensed under the MIT License.\n\n## Disclaimer\n\nThis is a very early version of the project, and it's likely to have bugs and limitations. Please report any issues you find, and feel free to suggest improvements or new features.",
      "npm_url": "",
      "npm_downloads": 0
    },
    "mahawi1992--mcp-documentation-server": {
      "owner": "mahawi1992",
      "name": "mcp-documentation-server",
      "url": "https://github.com/mahawi1992/mcp-documentation-server",
      "imageUrl": "https://github.com/mahawi1992.png",
      "description": "AI-assisted management of documentation and code improvement, supporting various frameworks with smart search capabilities. Integrates with Claude Desktop for an enhanced coding experience and improves suggestions over time.",
      "stars": 10,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-15T09:27:08Z",
      "readme_content": "# MCP Documentation Server\n\nA smart documentation server that provides AI-assisted code improvement and documentation management through Claude Desktop integration.\n\n## Features\n\n- **AI Documentation Guide**: Maintains and updates documentation knowledge base\n- **AI Code Assistant**: Analyzes and improves code quality\n- **Framework Support**: \n  - React.js\n  - Next.js (with App Router)\n  - Python\n  - Vue.js\n  - Angular\n  - Node.js\n- **Brave Search Integration**: Smart documentation search and retrieval\n- **Learning System**: Improves suggestions over time\n\n## Quick Start\n\n1. Install the package:\n```bash\nnpm install -g mcp-documentation-server\n```\n\n2. Configure Claude Desktop (config.json):\n```json\n{\n  \"mcpServers\": {\n    \"documentation\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-documentation-server\"],\n      \"env\": {\n        \"BRAVE_API_KEY\": \"<YOUR_BRAVE_API_KEY>\"\n      }\n    }\n  }\n}\n```\n\n3. Start using with Claude:\n```\nClaude, search documentation for Next.js App Router\n```\n\nFor detailed setup instructions, see [Claude Desktop Setup Guide](docs/CLAUDE_DESKTOP_SETUP.md)\n\n## Development Setup\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/mahawi1992/mcp-documentation-server.git\ncd mcp-documentation-server\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Create a .env file:\n```env\nPORT=3000\nUPDATE_INTERVAL=3600000\nCACHE_DURATION=86400000\nBRAVE_API_KEY=your_brave_api_key\n```\n\n4. Start the development server:\n```bash\nnpm run dev\n```\n\n## Documentation\n\n- [Usage Guide](docs/USAGE.md)\n- [Claude Desktop Setup](docs/CLAUDE_DESKTOP_SETUP.md)\n- [API Documentation](docs/API.md)\n- [Contributing Guide](CONTRIBUTING.md)\n\n## Using with Claude Desktop\n\n### Basic Commands\n\n```\nClaude, search documentation for React hooks\n```\n\n```\nClaude, analyze this Python code and suggest improvements...\n```\n\n```\nClaude, find best practices for Next.js App Router\n```\n\n### Advanced Usage\n\n```\nClaude, search for documentation about async/await in Python 3.9\n```\n\n```\nClaude, analyze this code for security issues and suggest fixes...\n```\n\nFor more examples, see the [Usage Guide](docs/USAGE.md)\n\n## Contributing\n\n1. Fork the repository\n2. Create your feature branch:\n   ```bash\n   git checkout -b feature/amazing-feature\n   ```\n3. Commit your changes:\n   ```bash\n   git commit -m 'Add amazing feature'\n   ```\n4. Push to the branch:\n   ```bash\n   git push origin feature/amazing-feature\n   ```\n5. Open a Pull Request\n\n## Testing\n\nRun the test suite:\n\n```bash\nnpm test\n```\n\nRun specific tests:\n\n```bash\nnpm test -- tests/integration/BraveSearchIntegration.test.ts\n```\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details",
      "npm_url": "",
      "npm_downloads": 0
    },
    "mengjian-github--deepseek-newsletter": {
      "owner": "mengjian-github",
      "name": "deepseek-newsletter",
      "url": "https://github.com/mengjian-github/deepseek-newsletter",
      "imageUrl": "https://github.com/mengjian-github.png",
      "description": "Collects and organizes information about the DeepSeek language model, presenting updates and insights in an e-book format. Features include compiling weekly updates and monthly summaries on technical progress, application cases, comparisons, and community news.",
      "stars": 1,
      "forks": 1,
      "license": "No License",
      "language": "HTML",
      "updated_at": "2025-06-12T05:53:24Z",
      "readme_content": "# DeepSeek å°æŠ¥ç«¥\n\nè¿™æ˜¯ä¸€ä¸ªå…³äºDeepSeekå¤§è¯­è¨€æ¨¡å‹çš„å°æŠ¥ç«¥é¡¹ç›®ï¼Œæ—¨åœ¨æ”¶é›†å’Œæ•´ç†DeepSeekç›¸å…³çš„é‡è¦ä¿¡æ¯å’Œæ›´æ–°ï¼Œä»¥ç”µå­ä¹¦çš„å½¢å¼å‘ˆç°ã€‚\n\n## é‡è¦é‡Œç¨‹ç¢‘\n\nğŸ‰ é‡å¤§çªç ´ï¼ã€ŠDeepSeekæç®€å…¥é—¨ä¸åº”ç”¨ã€‹å›¾ä¹¦é”€é‡çªç ´70ä¸‡å†Œï¼æ„Ÿè°¢å¹¿å¤§è¯»è€…çš„æ”¯æŒä¸åšçˆ±ã€‚\n\n## é¡¹ç›®ç»“æ„\n\n```\ndeepseek-newsletter/\nâ”œâ”€â”€ README.md           # é¡¹ç›®è¯´æ˜æ–‡æ¡£\nâ”œâ”€â”€ articles/          # æ–‡ç« æºæ–‡ä»¶ç›®å½•\nâ”‚   â”œâ”€â”€ 2024-03/      # æŒ‰æœˆä»½ç»„ç»‡çš„æ–‡ç« \nâ”‚   â””â”€â”€ templates/    # æ–‡ç« æ¨¡æ¿\nâ”œâ”€â”€ books/            # ç”Ÿæˆçš„ç”µå­ä¹¦ç›®å½•\nâ”œâ”€â”€ scripts/          # å·¥å…·è„šæœ¬\nâ””â”€â”€ assets/          # å›¾ç‰‡ç­‰èµ„æºæ–‡ä»¶\n```\n\n## å†…å®¹èŒƒå›´\n\næœ¬é¡¹ç›®å°†æ”¶é›†ä»¥ä¸‹æ–¹é¢çš„å†…å®¹ï¼š\n\n1. DeepSeekæ¨¡å‹çš„æŠ€æœ¯ç‰¹ç‚¹å’Œè¿›å±•\n2. DeepSeekçš„åº”ç”¨æ¡ˆä¾‹å’Œæœ€ä½³å®è·µ\n3. ä¸å…¶ä»–æ¨¡å‹çš„å¯¹æ¯”åˆ†æ\n4. ç¤¾åŒºåŠ¨æ€å’Œæ›´æ–°ä¿¡æ¯\n5. ä½¿ç”¨æ•™ç¨‹å’ŒæŠ€å·§\n\n## æ›´æ–°è®¡åˆ’\n\n- æ¯å‘¨æ›´æ–°ï¼šæ”¶é›†æ•´ç†å½“å‘¨æœ€é‡è¦çš„DeepSeekç›¸å…³ä¿¡æ¯\n- æ¯æœˆåˆé›†ï¼šå°†å½“æœˆçš„å†…å®¹æ•´åˆæˆä¸€æœ¬å®Œæ•´çš„ç”µå­ä¹¦\n- ç‰¹åˆ«ä¸“é¢˜ï¼šé’ˆå¯¹ç‰¹å®šä¸»é¢˜ï¼ˆå¦‚æ–°ç‰ˆæœ¬å‘å¸ƒï¼‰åˆ¶ä½œä¸“é¢˜ç”µå­ä¹¦\n\n## è´¡çŒ®æŒ‡å—\n\næ¬¢è¿æäº¤PRæ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ï¼š\n\n1. Forkæœ¬ä»“åº“\n2. åˆ›å»ºä½ çš„ç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)\n3. æäº¤ä½ çš„æ”¹åŠ¨ (`git commit -m 'Add some AmazingFeature'`)\n4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)\n5. å¼€å¯ä¸€ä¸ªPull Request\n\n## è®¸å¯è¯\n\næœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "mikechao--metmuseum-mcp": {
      "owner": "mikechao",
      "name": "metmuseum-mcp",
      "url": "https://github.com/mikechao/metmuseum-mcp",
      "imageUrl": "https://github.com/mikechao.png",
      "description": "Access the Metropolitan Museum of Art's collection through natural language queries to search for artworks and retrieve detailed information on various departments.",
      "stars": 13,
      "forks": 5,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-29T15:45:19Z",
      "readme_content": "[![themet logo](https://upload.wikimedia.org/wikipedia/commons/thumb/7/73/The_Metropolitan_Museum_of_Art_Logo.svg/250px-The_Metropolitan_Museum_of_Art_Logo.svg.png)](https://www.metmuseum.org/)\n\n# Met Museum MCP Server\n\nA Model Context Protocol (MCP) server that provides access to the Metropolitan Museum of Art Collection through natural language interactions. This server allows AI models to search The Met's art collection and have art works available as a Resource.\n\n<a href=\"https://glama.ai/mcp/servers/@mikechao/metmuseum-mcp\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@mikechao/metmuseum-mcp/badge\" alt=\"Met Museum MCP Server\" /></a>\n\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/mikechao-metmuseum-mcp-badge.png)](https://mseep.ai/app/mikechao-metmuseum-mcp)\n\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/ccc75a48-9b33-4a9a-8ef7-8dc3848db263)\n\n## Features\n\nThis server provides AI models the following tools to interact with the art collection of The Met\n\n### 1. List Departments (list-departments)\n\nLists all the valid departments at The Met\n\n- Inputs:\n  - None\n- Output:\n  ```\n  Department ID: 1, Display Name: American Decorative Arts\n  Department ID: 3, Display Name: Ancient Near Eastern Art\n  ...\n  ```\n\n### 2. Search Museum Objects (search-museum-objects)\n\nSearch for various objects in The Met based on the inputs.\n\n- Inputs:\n  - `q` (string): The search term e.g. sunflowers\n  - `hasImages` (boolean, optional, default: false): Only search for objects with images\n  - `title` (boolean, optional, default: false): Returns objects that match the query, specifically searching against the title field for objects.\n  - `departmentId` (number, optional): Returns objects that are a part of a specific department.\n- Outputs:\n\n  ```\n  Total objects found: 54\n  Object IDs: 436532, 789578, 436840, 438722,...\n  ```\n\n### 3. Get Museum Objects (get-museum-object)\n\nGet a specific object from The Met containing all open access data about that object, including its image (if the image is available under Open Access).\n\nIf there is an image it is added to the Resource of the server via the title of the object.\n\n- Inputs:\n  - `objectId` (number): The id of the object to retrieve\n  - `returnImage` (boolean, optional, default: true): Whether to return the image (if available) of the object and add it to the server resources\n- Outputs:\n  ```\n  Title: Self-Portrait with a Straw Hat (obverse: The Potato Peeler)\n  Artist: Vincent van Gogh\n  Artist Bio: Dutch, Zundert 1853â€“1890 Auvers-sur-Oise\n  Department: European Paintings\n  Credit Line: Bequest of Miss Adelaide Milton de Groot (1876-1967), 1967\n  Medium: Oil on canvas\n  Dimensions: 16 x 12 1/2 in. (40.6 x 31.8 cm)\n  Primary Image URL: https://images.metmuseum.org/CRDImages/ep/original/DT1502_cropped2.jpg\n  Tags: Men, Self-portraits\n  ```\n  If returnImage is true\n  ```\n  **base64 encoding of jpeg image**\n  ```\n\n### Usage with Claude Desktop\n\n## Via Desktop Extension (DXT)\n\n1. Download the `dxt` file from the [Releases](https://github.com/mikechao/metmuseum-mcp/releases)\n2. Open it with Claude Desktop\n   or\n   Go to File -> Settings -> Extensions and drag the .DXT file to the window to install it\n\n## Via npx\n\nAdd this to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcp-servers\": {\n    \"met-museum\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"metmuseum-mcp\"\n      ]\n    }\n  }\n}\n```\n\n### Usage with LibreChat\n\nAdd the following in your `librechat.yaml`\n\n```yaml\nmcpServers:\n  metmuseum:\n    command: npx\n    args:\n      - -y\n      - metmuseum-mcp\n```\n\n## Example queries\n\nHere some questions you can ask the AI model when this server in connected:\n\n```\nCan you show me a few painting from the Asian Art department?\nCan you find the painting titled \"Corridor in the Asylum\"?\nCan you find any art that has \"cat\" in the title or features \"cats\"?\n```\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n\n## Disclaimer\n\nThis library is not officially associated with The Metropolitan Museum of Art in New York. It is a third-party implementation of the [The Metropolitan Museum of Art Collection API](https://metmuseum.github.io/) with a MCP Server.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "microsoft--generative-ai-for-beginners": {
      "owner": "microsoft",
      "name": "generative-ai-for-beginners",
      "url": "https://github.com/microsoft/generative-ai-for-beginners",
      "imageUrl": "https://github.com/microsoft.png",
      "description": "This server provides a structured, hands-on course for building Generative AI applications, focusing on practical skills in Python and TypeScript. It encompasses various AI concepts and tools through 21 comprehensive lessons.",
      "stars": 99687,
      "forks": 52559,
      "license": "MIT License",
      "language": "Jupyter Notebook",
      "updated_at": "2025-10-04T09:42:45Z",
      "readme_content": "![Generative AI For Beginners](./images/repo-thumbnailv4-fixed.png?WT.mc_id=academic-105485-koreyst)\n\n### 21 Lessons teaching everything you need to know to start building Generative AI applications\n\n[![GitHub license](https://img.shields.io/github/license/microsoft/Generative-AI-For-Beginners.svg)](https://github.com/microsoft/Generative-AI-For-Beginners/blob/master/LICENSE?WT.mc_id=academic-105485-koreyst)\n[![GitHub contributors](https://img.shields.io/github/contributors/microsoft/Generative-AI-For-Beginners.svg)](https://GitHub.com/microsoft/Generative-AI-For-Beginners/graphs/contributors/?WT.mc_id=academic-105485-koreyst)\n[![GitHub issues](https://img.shields.io/github/issues/microsoft/Generative-AI-For-Beginners.svg)](https://GitHub.com/microsoft/Generative-AI-For-Beginners/issues/?WT.mc_id=academic-105485-koreyst)\n[![GitHub pull-requests](https://img.shields.io/github/issues-pr/microsoft/Generative-AI-For-Beginners.svg)](https://GitHub.com/microsoft/Generative-AI-For-Beginners/pulls/?WT.mc_id=academic-105485-koreyst)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com?WT.mc_id=academic-105485-koreyst)\n\n[![GitHub watchers](https://img.shields.io/github/watchers/microsoft/Generative-AI-For-Beginners.svg?style=social&label=Watch)](https://GitHub.com/microsoft/Generative-AI-For-Beginners/watchers/?WT.mc_id=academic-105485-koreyst)\n[![GitHub forks](https://img.shields.io/github/forks/microsoft/Generative-AI-For-Beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/Generative-AI-For-Beginners/network/?WT.mc_id=academic-105485-koreyst)\n[![GitHub stars](https://img.shields.io/github/stars/microsoft/Generative-AI-For-Beginners.svg?style=social&label=Star)](https://GitHub.com/microsoft/Generative-AI-For-Beginners/stargazers/?WT.mc_id=academic-105485-koreyst)\n\n[![](https://dcbadge.limes.pink/api/server/ByRwuEEgH4)](https://aka.ms/genai-discord?WT.mc_id=academic-105485-koreyst)\n\n### ğŸŒ Multi-Language Support\n\n#### Supported via GitHub Action (Automated & Always Up-to-Date)\n\n[French](./translations/fr/README.md) | [Spanish](./translations/es/README.md) | [German](./translations/de/README.md) | [Russian](./translations/ru/README.md) | [Arabic](./translations/ar/README.md) | [Persian (Farsi)](./translations/fa/README.md) | [Urdu](./translations/ur/README.md) | [Chinese (Simplified)](./translations/zh/README.md) | [Chinese (Traditional, Macau)](./translations/mo/README.md) | [Chinese (Traditional, Hong Kong)](./translations/hk/README.md) | [Chinese (Traditional, Taiwan)](./translations/tw/README.md) | [Japanese](./translations/ja/README.md) | [Korean](./translations/ko/README.md) | [Hindi](./translations/hi/README.md) | [Bengali](./translations/bn/README.md) | [Marathi](./translations/mr/README.md) | [Nepali](./translations/ne/README.md) | [Punjabi (Gurmukhi)](./translations/pa/README.md) | [Portuguese (Portugal)](./translations/pt/README.md) | [Portuguese (Brazil)](./translations/br/README.md) | [Italian](./translations/it/README.md) | [Lithuanian](./translations/lt/README.md) | [Polish](./translations/pl/README.md) | [Turkish](./translations/tr/README.md) | [Greek](./translations/el/README.md) | [Thai](./translations/th/README.md) | [Swedish](./translations/sv/README.md) | [Danish](./translations/da/README.md) | [Norwegian](./translations/no/README.md) | [Finnish](./translations/fi/README.md) | [Dutch](./translations/nl/README.md) | [Hebrew](./translations/he/README.md) | [Vietnamese](./translations/vi/README.md) | [Indonesian](./translations/id/README.md) | [Malay](./translations/ms/README.md) | [Tagalog (Filipino)](./translations/tl/README.md) | [Swahili](./translations/sw/README.md) | [Hungarian](./translations/hu/README.md) | [Czech](./translations/cs/README.md) | [Slovak](./translations/sk/README.md) | [Romanian](./translations/ro/README.md) | [Bulgarian](./translations/bg/README.md) | [Serbian (Cyrillic)](./translations/sr/README.md) | [Croatian](./translations/hr/README.md) | [Slovenian](./translations/sl/README.md) | [Ukrainian](./translations/uk/README.md) | [Burmese (Myanmar)](./translations/my/README.md)\n\n# Generative AI for Beginners (Version 3) - A Course\n\nLearn the fundamentals of building Generative AI applications with our 21-lesson comprehensive course by Microsoft Cloud Advocates.\n\n## ğŸŒ± Getting Started\n\nThis course has 21 lessons. Each lesson covers its own topic so start wherever you like!\n\nLessons are labeled either \"Learn\" lessons explaining a Generative AI concept or \"Build\" lessons that explain a concept and code examples in both **Python** and **TypeScript** when possible.\n\nFor .NET Developers checkout [Generative AI for Beginners (.NET Edition)](https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst)!\n\nEach lesson also includes a \"Keep Learning\" section with additional learning tools.\n\n## What You Need\n### To run the code of this course, you can use either: \n - [Azure OpenAI Service](https://aka.ms/genai-beginners/azure-open-ai?WT.mc_id=academic-105485-koreyst) - **Lessons:** \"aoai-assignment\"\n - [GitHub Marketplace Model Catalog](https://aka.ms/genai-beginners/gh-models?WT.mc_id=academic-105485-koreyst) - **Lessons:** \"githubmodels\"\n - [OpenAI API](https://aka.ms/genai-beginners/open-ai?WT.mc_id=academic-105485-koreyst) - **Lessons:** \"oai-assignment\" \n   \n- Basic knowledge of Python or TypeScript is helpful - \\*For absolute beginners check out these [Python](https://aka.ms/genai-beginners/python?WT.mc_id=academic-105485-koreyst) and [TypeScript](https://aka.ms/genai-beginners/typescript?WT.mc_id=academic-105485-koreyst) courses\n- A GitHub account to [fork this entire repo](https://aka.ms/genai-beginners/github?WT.mc_id=academic-105485-koreyst) to your own GitHub account\n\nWe have created a **[Course Setup](./00-course-setup/README.md?WT.mc_id=academic-105485-koreyst)** lesson to help you with setting up your development environment.\n\nDon't forget to [star (ğŸŒŸ) this repo](https://docs.github.com/en/get-started/exploring-projects-on-github/saving-repositories-with-stars?WT.mc_id=academic-105485-koreyst) to find it easier later.\n\n## ğŸ§  Ready to Deploy?\n\nIf you are looking for more advanced code samples, check out our [collection of Generative AI Code Samples](https://aka.ms/genai-beg-code?WT.mc_id=academic-105485-koreyst) in both **Python** and **TypeScript**.\n\n## ğŸ—£ï¸ Meet Other Learners, Get Support\n\nJoin our [official Azure AI Foundry Discord server](https://aka.ms/genai-discord?WT.mc_id=academic-105485-koreyst) to meet and network with other learners taking this course and get support.\n\nAsk questions or share product feedback in our [Azure AI Foundry Developer Forum](https://aka.ms/azureaifoundry/forum) on Github.\n\n## ğŸš€ Building a Startup?\n\nVisit [Microsoft for Startups](https://www.microsoft.com/startups) to find out how to get started building with Azure credits today.\n\n## ğŸ™ Want to help?\n\nDo you have suggestions or found spelling or code errors? [Raise an issue](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst) or [Create a pull request](https://github.com/microsoft/generative-ai-for-beginners/pulls?WT.mc_id=academic-105485-koreyst)\n\n## ğŸ“‚ Each lesson includes:\n\n- A short video introduction to the topic\n- A written lesson located in the README\n- Python and TypeScript code samples supporting Azure OpenAI and OpenAI API\n- Links to extra resources to continue your learning\n\n## ğŸ—ƒï¸ Lessons\n\n| #   | **Lesson Link**                                                                                                                              | **Description**                                                                                 | **Video**                                                                   | **Extra Learning**                                                             |\n| --- | -------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------- | ------------------------------------------------------------------------------ |\n| 00  | [Course Setup](./00-course-setup/README.md?WT.mc_id=academic-105485-koreyst)                                                                 | **Learn:** How to Setup Your Development Environment                                            | Video Coming Soon                                                                 | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 01  | [Introduction to Generative AI and LLMs](./01-introduction-to-genai/README.md?WT.mc_id=academic-105485-koreyst)                              | **Learn:** Understanding what Generative AI is and how Large Language Models (LLMs) work.       | [Video](https://aka.ms/gen-ai-lesson-1-gh?WT.mc_id=academic-105485-koreyst) | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 02  | [Exploring and comparing different LLMs](./02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst)             | **Learn:** How to select the right model for your use case                                      | [Video](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)  | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 03  | [Using Generative AI Responsibly](./03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)                           | **Learn:** How to build Generative AI Applications responsibly                                  | [Video](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)  | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 04  | [Understanding Prompt Engineering Fundamentals](./04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)             | **Learn:** Hands-on Prompt Engineering Best Practices                                           | [Video](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)  | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 05  | [Creating Advanced Prompts](./05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)                                                | **Learn:** How to apply prompt engineering techniques that improve the outcome of your prompts. | [Video](https://aka.ms/gen-ai-lesson5-gh?WT.mc_id=academic-105485-koreyst)  | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 06  | [Building Text Generation Applications](./06-text-generation-apps/README.md?WT.mc_id=academic-105485-koreyst)                                | **Build:** A text generation app using Azure OpenAI / OpenAI API                                | [Video](https://aka.ms/gen-ai-lesson6-gh?WT.mc_id=academic-105485-koreyst)  | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 07  | [Building Chat Applications](./07-building-chat-applications/README.md?WT.mc_id=academic-105485-koreyst)                                     | **Build:** Techniques for efficiently building and integrating chat applications.               | [Video](https://aka.ms/gen-ai-lessons7-gh?WT.mc_id=academic-105485-koreyst) | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 08  | [Building Search Apps Vector Databases](./08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)                        | **Build:** A search application that uses Embeddings to search for data.                        | [Video](https://aka.ms/gen-ai-lesson8-gh?WT.mc_id=academic-105485-koreyst)  | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 09  | [Building Image Generation Applications](./09-building-image-applications/README.md?WT.mc_id=academic-105485-koreyst)                        | **Build:** An image generation application                                                       | [Video](https://aka.ms/gen-ai-lesson9-gh?WT.mc_id=academic-105485-koreyst)  | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 10  | [Building Low Code AI Applications](./10-building-low-code-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)                       | **Build:** A Generative AI application using Low Code tools                                     | [Video](https://aka.ms/gen-ai-lesson10-gh?WT.mc_id=academic-105485-koreyst) | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 11  | [Integrating External Applications with Function Calling](./11-integrating-with-function-calling/README.md?WT.mc_id=academic-105485-koreyst) | **Build:** What is function calling and its use cases for applications                          | [Video](https://aka.ms/gen-ai-lesson11-gh?WT.mc_id=academic-105485-koreyst) | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 12  | [Designing UX for AI Applications](./12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)                         | **Learn:** How to apply UX design principles when developing Generative AI Applications         | [Video](https://aka.ms/gen-ai-lesson12-gh?WT.mc_id=academic-105485-koreyst) | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 13  | [Securing Your Generative AI Applications](./13-securing-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)                         | **Learn:** The threats and risks to AI systems and methods to secure these systems.             | [Video](https://aka.ms/gen-ai-lesson13-gh?WT.mc_id=academic-105485-koreyst) | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 14  | [The Generative AI Application Lifecycle](./14-the-generative-ai-application-lifecycle/README.md?WT.mc_id=academic-105485-koreyst)           | **Learn:** The tools and metrics to manage the LLM Lifecycle and LLMOps                         | [Video](https://aka.ms/gen-ai-lesson14-gh?WT.mc_id=academic-105485-koreyst) | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 15  | [Retrieval Augmented Generation (RAG) and Vector Databases](./15-rag-and-vector-databases/README.md?WT.mc_id=academic-105485-koreyst)        | **Build:** An application using a RAG Framework to retrieve embeddings from a Vector Databases  | [Video](https://aka.ms/gen-ai-lesson15-gh?WT.mc_id=academic-105485-koreyst) | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 16  | [Open Source Models and Hugging Face](./16-open-source-models/README.md?WT.mc_id=academic-105485-koreyst)                                    | **Build:** An application using open source models available on Hugging Face                    | [Video](https://aka.ms/gen-ai-lesson16-gh?WT.mc_id=academic-105485-koreyst) | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 17  | [AI Agents](./17-ai-agents/README.md?WT.mc_id=academic-105485-koreyst)                                                                       | **Build:** An application using an AI Agent Framework                                           | [Video](https://aka.ms/gen-ai-lesson17-gh?WT.mc_id=academic-105485-koreyst) | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 18  | [Fine-Tuning LLMs](./18-fine-tuning/README.md?WT.mc_id=academic-105485-koreyst)                                                              | **Learn:** The what, why and how of fine-tuning LLMs                                            | [Video](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst) | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 19  | [Building with SLMs](./19-slm/README.md?WT.mc_id=academic-105485-koreyst)                                                              | **Learn:** The benefits of building with Small Language Models                                            | Video Coming Soon | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 20  | [Building with Mistral Models](./20-mistral/README.md?WT.mc_id=academic-105485-koreyst)                                                              | **Learn:** The features and differences of the Mistral Family Models                                           | Video Coming Soon | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n| 21  | [Building with Meta Models](./21-meta/README.md?WT.mc_id=academic-105485-koreyst)                                                              | **Learn:** The features and differences of the Meta Family Models                                           | Video Coming Soon | [Learn More](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) |\n\n### ğŸŒŸ Special thanks\n\nSpecial thanks to [**John Aziz**](https://www.linkedin.com/in/john0isaac/) for creating all of the GitHub Actions and workflows\n\n[**Bernhard Merkle**](https://www.linkedin.com/in/bernhard-merkle-738b73/) for making key contributions to each lesson to improve the learner and code experience. \n\n## ğŸ’ Other Courses\n\nOur team produces other courses! Check out:\n\n- [**NEW** Edge AI for Beginners](https://github.com/microsoft/edgeai-for-beginners)\n- [Model Context Protocol for Beginners](https://github.com/microsoft/mcp-for-beginners)\n- [AI Agents for Beginners](https://github.com/microsoft/ai-agents-for-beginners)\n- [Generative AI for Beginners using .NET](https://github.com/microsoft/Generative-AI-for-beginners-dotnet)\n- [Generative AI for Beginners using JavaScript](https://aka.ms/genai-js-course)\n- [Generative AI for Beginners using Java](https://aka.ms/genaijava)\n- [ML for Beginners](https://aka.ms/ml-beginners)\n- [Data Science for Beginners](https://aka.ms/datascience-beginners)\n- [AI for Beginners](https://aka.ms/ai-beginners)\n- [Cybersecurity for Beginners](https://github.com/microsoft/Security-101)\n- [Web Dev for Beginners](https://aka.ms/webdev-beginners)\n- [IoT for Beginners](https://aka.ms/iot-beginners)\n- [XR Development for Beginners](https://github.com/microsoft/xr-development-for-beginners)\n- [Mastering GitHub Copilot for AI Paired Programming](https://aka.ms/GitHubCopilotAI)\n- [Mastering GitHub Copilot for C#/.NET Developers](https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers)\n- [Choose Your Own Copilot Adventure](https://github.com/microsoft/CopilotAdventures)\n\n## Getting Help\n\nIf you get stuck or have any questions about building AI apps, join:\n\n[![Azure AI Foundry Discord](https://img.shields.io/badge/Discord-Azure_AI_Foundry_Community_Discord-blue?style=for-the-badge&logo=discord&color=5865f2&logoColor=fff)](https://aka.ms/foundry/discord?WT.mc_id=academic-105485-koreyst)\n\nIf you have product feedback or errors while building visit:\n\n[![Azure AI Foundry Developer Forum](https://img.shields.io/badge/GitHub-Azure_AI_Foundry_Developer_Forum-blue?style=for-the-badge&logo=github&color=000000&logoColor=fff)](https://aka.ms/foundry/forum?WT.mc_id=academic-105485-koreyst)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "mirinda-cmd--reference-servers-check": {
      "owner": "mirinda-cmd",
      "name": "reference-servers-check",
      "url": "https://github.com/mirinda-cmd/reference-servers-check",
      "imageUrl": "https://github.com/mirinda-cmd.png",
      "description": "Implement a structured thinking process for problem-solving and analysis, breaking down complex problems into manageable steps while allowing dynamic adjustment of thought paths and generation of solution hypotheses.",
      "stars": 2,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-07-29T02:33:39Z",
      "readme_content": "# Model Context Protocol servers\n\nThis repository is a collection of *reference implementations* for the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP), as well as references\nto community built servers and additional resources.\n\nThe servers in this repository showcase the versatility and extensibility of MCP, demonstrating how it can be used to give Large Language Models (LLMs) secure, controlled access to tools and data sources.\nEach MCP server is implemented with either the [Typescript MCP SDK](https://github.com/modelcontextprotocol/typescript-sdk) or [Python MCP SDK](https://github.com/modelcontextprotocol/python-sdk).\n\n> Note: Lists in this README are maintained in alphabetical order to minimize merge conflicts when adding new items.\n\n## ğŸŒŸ Reference Servers\n\nThese servers aim to demonstrate MCP features and the Typescript and Python SDK.\n\n- **[AWS KB Retrieval](src/aws-kb-retrieval-server)** - Retrieval from AWS Knowledge Base using Bedrock Agent Runtime\n- **[Brave Search](src/brave-search)** - Web and local search using Brave's Search API\n- **[EverArt](src/everart)** - AI image generation using various models\n- **[Everything](src/everything)** - Reference / test server with prompts, resources, and tools\n- **[Fetch](src/fetch)** - Web content fetching and conversion for efficient LLM usage\n- **[Filesystem](src/filesystem)** - Secure file operations with configurable access controls\n- **[Git](src/git)** - Tools to read, search, and manipulate Git repositories\n- **[GitHub](src/github)** - Repository management, file operations, and GitHub API integration\n- **[GitLab](src/gitlab)** - GitLab API, enabling project management\n- **[Google Drive](src/gdrive)** - File access and search capabilities for Google Drive\n- **[Google Maps](src/google-maps)** - Location services, directions, and place details\n- **[Memory](src/memory)** - Knowledge graph-based persistent memory system\n- **[PostgreSQL](src/postgres)** - Read-only database access with schema inspection\n- **[Puppeteer](src/puppeteer)** - Browser automation and web scraping\n- **[Sentry](src/sentry)** - Retrieving and analyzing issues from Sentry.io\n- **[Sequential Thinking](src/sequentialthinking)** - Dynamic and reflective problem-solving through thought sequences\n- **[Slack](src/slack)** - Channel management and messaging capabilities\n- **[Sqlite](src/sqlite)** - Database interaction and business intelligence capabilities\n- **[Time](src/time)** - Time and timezone conversion capabilities\n\n## ğŸ¤ Third-Party Servers\n\n### ğŸ–ï¸ Official Integrations\n\nOfficial integrations are maintained by companies building production ready MCP servers for their platforms.\n\n- <img height=\"12\" width=\"12\" src=\"https://axiom.co/favicon.ico\" alt=\"Axiom Logo\" /> **[Axiom](https://github.com/axiomhq/mcp-server-axiom)** - Query and analyze your Axiom logs, traces, and all other event data in natural language\n- <img height=\"12\" width=\"12\" src=\"https://browserbase.com/favicon.ico\" alt=\"Browserbase Logo\" /> **[Browserbase](https://github.com/browserbase/mcp-server-browserbase)** - Automate browser interactions in the cloud (e.g. web navigation, data extraction, form filling, and more)\n- <img height=\"12\" width=\"12\" src=\"https://cdn.simpleicons.org/cloudflare\" /> **[Cloudflare](https://github.com/cloudflare/mcp-server-cloudflare)** - Deploy, configure & interrogate your resources on the Cloudflare developer platform (e.g. Workers/KV/R2/D1)\n- <img height=\"12\" width=\"12\" src=\"https://e2b.dev/favicon.ico\" alt=\"E2B Logo\" /> **[E2B](https://github.com/e2b-dev/mcp-server)** - Run code in secure sandboxes hosted by [E2B](https://e2b.dev)\n- <img height=\"12\" width=\"12\" src=\"https://exa.ai/images/favicon-32x32.png\" alt=\"Exa Logo\" /> **[Exa](https://github.com/exa-labs/exa-mcp-server)** - Search Engine made for AIs by [Exa](https://exa.ai)\n- <img height=\"12\" width=\"12\" src=\"https://fireproof.storage/favicon.ico\" alt=\"Fireproof Logo\" /> **[Fireproof](https://github.com/fireproof-storage/mcp-database-server)** - Immutable ledger database with live synchronization\n- <img height=\"12\" width=\"12\" src=\"https://cdn.simpleicons.org/jetbrains\" /> **[JetBrains](https://github.com/JetBrains/mcp-jetbrains)** â€“ Work on your code with JetBrains IDEs\n- <img height=\"12\" width=\"12\" src=\"https://kagi.com/favicon.ico\" alt=\"Kagi Logo\" /> **[Kagi Search](https://github.com/kagisearch/kagimcp)** - Search the web using Kagi's search API\n- <img height=\"12\" width=\"12\" src=\"https://www.meilisearch.com/favicon.ico\" alt=\"Meilisearch Logo\" /> **[Meilisearch](https://github.com/meilisearch/meilisearch-mcp)** - Interact & query with Meilisearch (Full-text & semantic search API)\n- <img height=\"12\" width=\"12\" src=\"https://metoro.io/static/images/logos/Metoro.svg\" /> **[Metoro](https://github.com/metoro-io/metoro-mcp-server)** - Query and interact with kubernetes environments monitored by Metoro\n- <img height=\"12\" width=\"12\" src=\"https://www.motherduck.com/favicon.ico\" alt=\"MotherDuck Logo\" /> **[MotherDuck](https://github.com/motherduckdb/mcp-server-motherduck)** - Query and analyze data with MotherDuck and local DuckDB\n- <img height=\"12\" width=\"12\" src=\"https://needle-ai.com/images/needle-logo-orange-2-rounded.png\" alt=\"Needle AI Logo\" /> **[Needle](https://github.com/needle-ai/needle-mcp)** - Production-ready RAG out of the box to search and retrieve data from your own documents.\n- <img height=\"12\" width=\"12\" src=\"https://neo4j.com/favicon.ico\" alt=\"Neo4j Logo\" /> **[Neo4j](https://github.com/neo4j-contrib/mcp-neo4j/)** - Neo4j graph database server (schema + read/write-cypher) and separate graph database backed memory\n- **[Neon](https://github.com/neondatabase/mcp-server-neon)** - Interact with the Neon serverless Postgres platform\n- <img height=\"12\" width=\"12\" src=\"https://qdrant.tech/img/brand-resources-logos/logomark.svg\" /> **[Qdrant](https://github.com/qdrant/mcp-server-qdrant/)** - Implement semantic memory layer on top of the Qdrant vector search engine\n- **[Raygun](https://github.com/MindscapeHQ/mcp-server-raygun)** - Interact with your crash reporting and real using monitoring data on your Raygun account\n- <img height=\"12\" width=\"12\" src=\"https://pics.fatwang2.com/56912e614b35093426c515860f9f2234.svg\" /> [Search1API](https://github.com/fatwang2/search1api-mcp) - One API for Search, Crawling, and Sitemaps\n- <img height=\"12\" width=\"12\" src=\"https://www.tinybird.co/favicon.ico\" alt=\"Tinybird Logo\" /> **[Tinybird](https://github.com/tinybirdco/mcp-tinybird)** - Interact with Tinybird serverless ClickHouse platform\n\n### ğŸŒ Community Servers\n\nA growing set of community-developed and maintained servers demonstrates various applications of MCP across different domains.\n\n> **Note:** Community servers are **untested** and should be used at **your own risk**. They are not affiliated with or endorsed by Anthropic.\n\n- **[AWS S3](https://github.com/aws-samples/sample-mcp-server-s3)** - A sample MCP server for AWS S3 that flexibly fetches objects from S3 such as PDF documents\n- **[AWS](https://github.com/rishikavikondala/mcp-server-aws)** - Perform operations on your AWS resources using an LLM\n- **[Airtable](https://github.com/domdomegg/airtable-mcp-server)** - Read and write access to [Airtable](https://airtable.com/) databases, with schema inspection.\n- **[Airtable](https://github.com/felores/airtable-mcp)** - Airtable Model Context Protocol Server.\n- **[AlphaVantage](https://github.com/calvernaz/alphavantage)** - MCP server for stock market data API [AlphaVantage](https://www.alphavantage.co)\n- **[Anki](https://github.com/scorzeth/anki-mcp-server)** - An MCP server for interacting with your [Anki](https://apps.ankiweb.net) decks and cards.\n- **[Any Chat Completions](https://github.com/pyroprompts/any-chat-completions-mcp)** - Interact with any OpenAI SDK Compatible Chat Completions API like OpenAI, Perplexity, Groq, xAI and many more.\n- **[Atlassian](https://github.com/sooperset/mcp-atlassian)** - Interact with Atlassian Cloud products (Confluence and Jira) including searching/reading Confluence spaces/pages, accessing Jira issues, and project metadata.\n- **[BigQuery](https://github.com/LucasHild/mcp-server-bigquery)** (by LucasHild) - This server enables LLMs to inspect database schemas and execute queries on BigQuery.\n- **[BigQuery](https://github.com/ergut/mcp-bigquery-server)** (by ergut) - Server implementation for Google BigQuery integration that enables direct BigQuery database access and querying capabilities\n- **[ChatMCP](https://github.com/AI-QL/chat-mcp)** â€“ An Open Source Cross-platform GUI Desktop application compatible with Linux, macOS, and Windows, enabling seamless interaction with MCP servers across dynamically selectable LLMs, by **[AIQL](https://github.com/AI-QL)**\n- **[ChatSum](https://github.com/mcpso/mcp-server-chatsum)** - Query and Summarize chat messages with LLM. by [mcpso](https://mcp.so)\n- **[Chroma](https://github.com/privetin/chroma)** - Vector database server for semantic document search and metadata filtering, built on Chroma\n- **[Cloudinary](https://github.com/felores/cloudinary-mcp-server)** - Cloudinary Model Context Protocol Server to upload media to Cloudinary and get back the media link and details.\n- **[cognee-mcp](https://github.com/topoteretes/cognee-mcp-server)** - GraphRAG memory server with customizable ingestion, data processing and search\n- **[coin_api_mcp](https://github.com/longmans/coin_api_mcp)** - Provides access to [coinmarketcap](https://coinmarketcap.com/) cryptocurrency data.\n- **[Contentful-mcp](https://github.com/ivo-toby/contentful-mcp)** - Read, update, delete, publish content in your [Contentful](https://contentful.com) space(s) from this MCP Server.\n- **[Data Exploration](https://github.com/reading-plus-ai/mcp-server-data-exploration)** - MCP server for autonomous data exploration on .csv-based datasets, providing intelligent insights with minimal effort. NOTE: Will execute arbitrary Python code on your machine, please use with caution!\n- **[Dataset Viewer](https://github.com/privetin/dataset-viewer)** - Browse and analyze Hugging Face datasets with features like search, filtering, statistics, and data export\n- **[DevRev](https://github.com/kpsunil97/devrev-mcp-server)** - An MCP server to integrate with DevRev APIs to search through your DevRev Knowledge Graph where objects can be imported from diff. sources listed [here](https://devrev.ai/docs/import#available-sources).\n- **[Dify](https://github.com/YanxingLiu/dify-mcp-server)** - A simple implementation of an MCP server for dify workflows.\n- **[Docker](https://github.com/ckreiling/mcp-server-docker)** - Integrate with Docker to manage containers, images, volumes, and networks.\n- **[Drupal](https://github.com/Omedia/mcp-server-drupal)** - Server for interacting with [Drupal](https://www.drupal.org/project/mcp) using STDIO transport layer.\n- **[Elasticsearch](https://github.com/cr7258/elasticsearch-mcp-server)** - MCP server implementation that provides Elasticsearch interaction.\n- **[Fetch](https://github.com/zcaceres/fetch-mcp)** - A server that flexibly fetches HTML, JSON, Markdown, or plaintext.\n- **[FireCrawl](https://github.com/vrknetha/mcp-server-firecrawl)** - Advanced web scraping with JavaScript rendering, PDF support, and smart rate limiting\n- **[FlightRadar24](https://github.com/sunsetcoder/flightradar24-mcp-server)** - A Claude Desktop MCP server that helps you track flights in real-time using Flightradar24 data.\n- **[Glean](https://github.com/longyi1207/glean-mcp-server)** - A server that uses Glean API to search and chat.\n- **[Google Calendar](https://github.com/v-3/google-calendar)** - Integration with Google Calendar to check schedules, find time, and add/delete events\n- **[Google Tasks](https://github.com/zcaceres/gtasks-mcp)** - Google Tasks API Model Context Protocol Server.\n- **[Home Assistant](https://github.com/tevonsb/homeassistant-mcp)** - Interact with [Home Assistant](https://www.home-assistant.io/) including viewing and controlling lights, switches, sensors, and all other Home Assistant entities.\n- **[HuggingFace Spaces](https://github.com/evalstate/mcp-hfspace)** - Server for using HuggingFace Spaces, supporting Open Source Image, Audio, Text Models and more. Claude Desktop mode for easy integration.\n- **[Inoyu](https://github.com/sergehuber/inoyu-mcp-unomi-server)** - Interact with an Apache Unomi CDP customer data platform to retrieve and update customer profiles\n- **[Keycloak MCP](https://github.com/ChristophEnglisch/keycloak-model-context-protocol)** - This MCP server enables natural language interaction with Keycloak for user and realm management including creating, deleting, and listing users and realms.\n- **[Kubernetes](https://github.com/Flux159/mcp-server-kubernetes)** - Connect to Kubernetes cluster and manage pods, deployments, and services.\n- **[Linear](https://github.com/jerhadf/linear-mcp-server)** - Allows LLM to interact with Linear's API for project management, including searching, creating, and updating issues.\n- **[LlamaCloud](https://github.com/run-llama/mcp-server-llamacloud)** (by marcusschiesser) - Integrate the data stored in a managed index on [LlamaCloud](https://cloud.llamaindex.ai/)\n- **[MCP Installer](https://github.com/anaisbetts/mcp-installer)** - This server is a server that installs other MCP servers for you.\n- **[mcp-k8s-go](https://github.com/strowk/mcp-k8s-go)** - Golang-based Kubernetes server for MCP to browse pods and their logs, events, namespaces and more. Built to be extensible.\n- **[MSSQL](https://github.com/aekanun2020/mcp-server/)** - MSSQL database integration with configurable access controls and schema inspection\n- **[Markdownify](https://github.com/zcaceres/mcp-markdownify-server)** - MCP to convert almost anything to Markdown (PPTX, HTML, PDF, Youtube Transcripts and more)\n- **[Minima](https://github.com/dmayboroda/minima)** - MCP server for RAG on local files\n- **[MongoDB](https://github.com/kiliczsh/mcp-mongo-server)** - A Model Context Protocol Server for MongoDB.\n- **[MySQL](https://github.com/benborla/mcp-server-mysql)** (by benborla) - MySQL database integration in NodeJS with configurable access controls and schema inspection\n- **[MySQL](https://github.com/designcomputer/mysql_mcp_server)** (by DesignComputer) - MySQL database integration in Python with configurable access controls and schema inspection\n- **[NS Travel Information](https://github.com/r-huijts/ns-mcp-server)** - Access Dutch Railways (NS) real-time train travel information and disruptions through the official NS API.\n- **[Notion](https://github.com/suekou/mcp-notion-server)** (by suekou) - Interact with Notion API.\n- **[Notion](https://github.com/v-3/notion-server)** (by v-3) - Notion MCP integration. Search, Read, Update, and Create pages through Claude chat.\n- **[oatpp-mcp](https://github.com/oatpp/oatpp-mcp)** - C++ MCP integration for Oat++. Use [Oat++](https://oatpp.io) to build MCP servers.\n- **[Obsidian Markdown Notes](https://github.com/calclavia/mcp-obsidian)** - Read and search through your Obsidian vault or any directory containing Markdown notes\n- **[OpenAPI](https://github.com/snaggle-ai/openapi-mcp-server)** - Interact with [OpenAPI](https://www.openapis.org/) APIs.\n- **[OpenCTI](https://github.com/Spathodea-Network/opencti-mcp)** - Interact with OpenCTI platform to retrieve threat intelligence data including reports, indicators, malware and threat actors.\n- **[OpenRPC](https://github.com/shanejonas/openrpc-mpc-server)** - Interact with and discover JSON-RPC APIs via [OpenRPC](https://open-rpc.org).\n- **[Pandoc](https://github.com/vivekVells/mcp-pandoc)** - MCP server for seamless document format conversion using Pandoc, supporting Markdown, HTML, and plain text, with other formats like PDF, csv and docx in development.\n- **[Pinecone](https://github.com/sirmews/mcp-pinecone)** - MCP server for searching and uploading records to Pinecone. Allows for simple RAG features, leveraging Pinecone's Inference API.\n- **[Placid.app](https://github.com/felores/placid-mcp-server)** - Generate image and video creatives using Placid.app templates\n- **[Playwright](https://github.com/executeautomation/mcp-playwright)** - This MCP Server will help you run browser automation and webscraping using Playwright\n- **[Postman](https://github.com/shannonlal/mcp-postman)** - MCP server for running Postman Collections locally via Newman. Allows for simple execution of Postman Server and returns the results of whether the collection passed all the tests.\n- **[RAG Web Browser](https://github.com/apify/mcp-server-rag-web-browser)** An MCP server for Apify's RAG Web Browser Actor to perform web searches, scrape URLs, and return content in Markdown.\n- **[Rememberizer AI](https://github.com/skydeckai/mcp-server-rememberizer)** - An MCP server designed for interacting with the Rememberizer data source, facilitating enhanced knowledge retrieval.\n- **[Salesforce MCP](https://github.com/smn2gnt/MCP-Salesforce)** - Interact with Salesforce Data and Metadata\n- **[Scholarly](https://github.com/adityak74/mcp-scholarly)** - A MCP server to search for scholarly and academic articles.\n- **[Snowflake](https://github.com/isaacwasserman/mcp-snowflake-server)** - This MCP server enables LLMs to interact with Snowflake databases, allowing for secure and controlled data operations.\n- **[Spotify](https://github.com/varunneal/spotify-mcp)** - This MCP allows an LLM to play and use Spotify.\n- **[TMDB](https://github.com/Laksh-star/mcp-server-tmdb)** - This MCP server integrates with The Movie Database (TMDB) API to provide movie information, search capabilities, and recommendations.\n- **[Tavily search](https://github.com/RamXX/mcp-tavily)** - An MCP server for Tavily's search & news API, with explicit site inclusions/exclusions\n- **[Todoist](https://github.com/abhiz123/todoist-mcp-server)** - Interact with Todoist to manage your tasks.\n- **[Vega-Lite](https://github.com/isaacwasserman/mcp-vegalite-server)** - Generate visualizations from fetched data using the VegaLite format and renderer.\n- **[Windows CLI](https://github.com/SimonB97/win-cli-mcp-server)** - MCP server for secure command-line interactions on Windows systems, enabling controlled access to PowerShell, CMD, and Git Bash shells.\n- **[X (Twitter)](https://github.com/EnesCinr/twitter-mcp)** (by EnesCinr) - Interact with twitter API. Post tweets and search for tweets by query.\n- **[X (Twitter)](https://github.com/vidhupv/x-mcp)** (by vidhupv) - Create, manage and publish X/Twitter posts directly through Claude chat.\n- **[XMind](https://github.com/apeyroux/mcp-xmind)** - Read and search through your XMind directory containing XMind files.\n\n## ğŸ“š Frameworks\n\nThese are high-level frameworks that make it easier to build MCP servers.\n\n* [EasyMCP](https://github.com/zcaceres/easy-mcp/) (TypeScript)\n* [FastMCP](https://github.com/punkpeye/fastmcp) (TypeScript)\n\n## ğŸ“š Resources\n\nAdditional resources on MCP.\n\n- **[AiMCP](https://www.aimcp.info)** - A collection of MCP clients&servers to find the right mcp tools by **[Hekmon](https://github.com/hekmon8)**\n- **[Awesome Crypto MCP Servers by badkk](https://github.com/badkk/awesome-crypto-mcp-servers)** - A curated list of MCP servers by **[Luke Fan](https://github.com/badkk)**\n- **[Awesome MCP Servers by appcypher](https://github.com/appcypher/awesome-mcp-servers)** - A curated list of MCP servers by **[Stephen Akinyemi](https://github.com/appcypher)**\n- **[Awesome MCP Servers by punkpeye](https://github.com/punkpeye/awesome-mcp-servers)** (**[website](https://glama.ai/mcp/servers)**) - A curated list of MCP servers by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[Awesome MCP Servers by wong2](https://github.com/wong2/awesome-mcp-servers)** (**[website](https://mcpservers.org)**) - A curated list of MCP servers by **[wong2](https://github.com/wong2)**\n- **[Discord Server](https://glama.ai/mcp/discord)** â€“Â A community discord server dedicated to MCP by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[MCP Badges](https://github.com/mcpx-dev/mcp-badges)** â€“ Quickly highlight your MCP project with clear, eye-catching badges, by **[Ironben](https://github.com/nanbingxyz)**\n- **[MCP X Community](https://x.com/i/communities/1861891349609603310)** â€“Â A X community for MCP by **[Xiaoyi](https://x.com/chxy)**\n- **[mcp-cli](https://github.com/wong2/mcp-cli)** - A CLI inspector for the Model Context Protocol by **[wong2](https://github.com/wong2)**\n- **[mcp-get](https://mcp-get.com)** - Command line tool for installing and managing MCP servers by **[Michael Latman](https://github.com/michaellatman)**\n- **[mcp-manager](https://github.com/zueai/mcp-manager)** - Simple Web UI to install and manage MCP servers for Claude Desktop by **[Zue](https://github.com/zueai)**\n- **[MCPHub](https://github.com/Jeamee/MCPHub-Desktop)** â€“Â An Open Source MacOS & Windows GUI Desktop app for discovering, installing and managing MCP servers by **[Jeamee](https://github.com/jeamee)**\n- **[mcp.run](https://mcp.run)** - A hosted registry and control plane to install & run secure + portable MCP Servers.\n- **[Open-Sourced MCP Servers Directory](https://github.com/chatmcp/mcp-directory)** - A curated list of MCP servers by **[mcpso](https://mcp.so)**\n- **[PulseMCP](https://www.pulsemcp.com)** ([API](https://www.pulsemcp.com/api)) - Community hub & weekly newsletter for discovering MCP servers, clients, articles, and news by **[Tadas Antanavicius](https://github.com/tadasant)**, **[Mike Coughlin](https://github.com/macoughl)**, and **[Ravina Patel](https://github.com/ravinahp)**\n- **[r/mcp](https://www.reddit.com/r/mcp)** â€“Â A Reddit community dedicated to MCP by **[Frank Fiegel](https://github.com/punkpeye)**\n- **[Smithery](https://smithery.ai/)** - A registry of MCP servers to find the right tools for your LLM agents by **[Henry Mao](https://github.com/calclavia)**\n\n## ğŸš€ Getting Started\n\n### Using MCP Servers in this Repository\nTypescript-based servers in this repository can be used directly with `npx`.\n\nFor example, this will start the [Memory](src/memory) server:\n```sh\nnpx -y @modelcontextprotocol/server-memory\n```\n\nPython-based servers in this repository can be used directly with [`uvx`](https://docs.astral.sh/uv/concepts/tools/) or [`pip`](https://pypi.org/project/pip/). `uvx` is recommended for ease of use and setup.\n\nFor example, this will start the [Git](src/git) server:\n```sh\n# With uvx\nuvx mcp-server-git\n\n# With pip\npip install mcp-server-git\npython -m mcp_server_git\n```\n\nFollow [these](https://docs.astral.sh/uv/getting-started/installation/) instructions to install `uv` / `uvx` and [these](https://pip.pypa.io/en/stable/installation/) to install `pip`.\n\n### Using an MCP Client\nHowever, running a server on its own isn't very useful, and should instead be configured into an MCP client. For example, here's the Claude Desktop configuration to use the above server:\n\n```json\n{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-memory\"]\n    }\n  }\n}\n```\n\nAdditional examples of using the Claude Desktop as an MCP client might look like:\n\n```json\n{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/path/to/allowed/files\"]\n    },\n    \"git\": {\n      \"command\": \"uvx\",\n      \"args\": [\"mcp-server-git\", \"--repository\", \"path/to/git/repo\"]\n    },\n    \"github\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-github\"],\n      \"env\": {\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"<YOUR_TOKEN>\"\n      }\n    },\n    \"postgres\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@modelcontextprotocol/server-postgres\", \"postgresql://localhost/mydb\"]\n    }\n  }\n}\n```\n\n## ğŸ› ï¸ Creating Your Own Server\n\nInterested in creating your own MCP server? Visit the official documentation at [modelcontextprotocol.io](https://modelcontextprotocol.io/introduction) for comprehensive guides, best practices, and technical details on implementing MCP servers.\n\n## ğŸ¤ Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for information about contributing to this repository.\n\n## ğŸ”’ Security\n\nSee [SECURITY.md](SECURITY.md) for reporting security vulnerabilities.\n\n## ğŸ“œ License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## ğŸ’¬ Community\n\n- [GitHub Discussions](https://github.com/orgs/modelcontextprotocol/discussions)\n\n## â­ Support\n\nIf you find MCP servers useful, please consider starring the repository and contributing new servers or improvements!\n\n---\n\nManaged by Anthropic, but built together with the community. The Model Context Protocol is open source and we encourage everyone to contribute their own servers and improvements!\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "MushroomFleet--DeepLucid3D-MCP": {
      "owner": "MushroomFleet",
      "name": "DeepLucid3D-MCP",
      "url": "https://github.com/MushroomFleet/DeepLucid3D-MCP",
      "imageUrl": "https://github.com/MushroomFleet.png",
      "description": "Provides advanced cognitive analysis and problem-solving capabilities using structured cognitive tools, enabling users to assess cognitive states, generate novel perspectives, and decompose complex problems for effective solutions.",
      "stars": 12,
      "forks": 3,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-07-28T12:04:44Z",
      "readme_content": "# DeepLucid3D UCPF Server\n\nA Model Context Protocol (MCP) server implementing the Unified Cognitive Processing Framework (UCPF) for advanced cognitive analysis, creative problem-solving, and structured thinking.\n\n## What is it?\n\nThe DeepLucid3D UCPF Server is an implementation of the Unified Cognitive Processing Framework as an MCP server. It combines recursive self-awareness with dimensional knowledge categorization to provide a powerful approach to problem-solving and creative thinking.\n\nThis server extends AI capabilities by providing structured cognitive tools that help:\n- Assess cognitive states\n- Map knowledge dimensions\n- Apply recursive self-questioning\n- Generate creative perspectives\n- Decompose and reintegrate complex problems\n\n## What it does\n\nThe UCPF Server enables advanced cognitive processing through several key features:\n\n### Core Capabilities\n\n1. **Cognitive State Assessment**: Identifies current cognitive states (Dark Inertia, Passion, or Approaching Lucidity) to improve self-awareness during problem-solving.\n\n2. **Knowledge Dimension Mapping**: Maps knowledge across three dimensions:\n   - Awareness (Known vs. Unknown)\n   - Content (Knowns vs. Unknowns)\n   - Accessibility (Knowable vs. Unknowable)\n\n3. **Recursive Self-Questioning**: Challenges initial assumptions and identifies potential cognitive biases.\n\n4. **Creative Perspective Generation**: Produces novel viewpoints and metaphorical thinking to inspire new solutions.\n\n5. **Problem Decomposition**: Breaks complex problems into manageable components and reintegrates them with awareness of the whole system.\n\n6. **Optional State Management**: Maintains context between sessions for ongoing analysis.\n\n## Setup and Installation\n\n### Prerequisites\n\n- Node.js (v14 or higher)\n- npm (v6 or higher)\n- An environment compatible with the Model Context Protocol\n\n### Installation Steps\n\n1. **Clone the repository**\n   ```bash\n   git clone https://github.com/yourusername/DeepLucid3D-UCPF-Server.git\n   cd DeepLucid3D-UCPF-Server\n   ```\n\n2. **Install dependencies**\n   ```bash\n   npm install\n   ```\n\n3. **Build the project**\n   ```bash\n   npm run build\n   ```\n\n4. **Configure MCP settings**\n\n   Add the server to your MCP settings file. For Claude/Cline, this is typically located at:\n   - For Claude Desktop: `~/Library/Application Support/Claude/claude_desktop_config.json` (macOS)\n   - For VSCode Cline: `~/.config/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json` (Linux)\n\n   Add the following configuration:\n   ```json\n   {\n     \"mcpServers\": {\n      \"ucpf\": {\n      \"command\": \"node\",\n      \"args\": [\"path/to/DeepLucid3D-MCP/build/index.js\"],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n       }\n     }\n   }\n   ```\n\n5. **Restart your MCP-compatible application** (Claude, VSCode with Cline, etc.)\n\n## How to Use\n\nThe server exposes three main tools and several resources that can be accessed through MCP:\n\n### Tools\n\n1. **analyze_problem**: Process a problem statement through the full UCPF framework\n   ```\n   <use_mcp_tool>\n   <server_name>ucpf</server_name>\n   <tool_name>analyze_problem</tool_name>\n   <arguments>\n   {\n     \"problem\": \"Your problem statement here\",\n     \"session_id\": \"optional-session-id\",\n     \"enable_state\": false,\n     \"detailed\": false\n   }\n   </arguments>\n   </use_mcp_tool>\n   ```\n\n2. **creative_exploration**: Generate novel perspectives and connections for a topic\n   ```\n   <use_mcp_tool>\n   <server_name>ucpf</server_name>\n   <tool_name>creative_exploration</tool_name>\n   <arguments>\n   {\n     \"topic\": \"Your topic here\",\n     \"constraints\": [\"Optional constraint 1\", \"Optional constraint 2\"],\n     \"perspective_count\": 3,\n     \"include_metaphors\": true\n   }\n   </arguments>\n   </use_mcp_tool>\n   ```\n\n3. **manage_state**: Control state management for UCPF processing\n   ```\n   <use_mcp_tool>\n   <server_name>ucpf</server_name>\n   <tool_name>manage_state</tool_name>\n   <arguments>\n   {\n     \"action\": \"enable\", // or \"disable\", \"reset\", \"status\"\n     \"session_id\": \"optional-specific-session-id\"\n   }\n   </arguments>\n   </use_mcp_tool>\n   ```\n\n### Resources\n\nAccess framework documentation:\n```\n<access_mcp_resource>\n<server_name>ucpf</server_name>\n<uri>ucpf://framework/overview</uri>\n</access_mcp_resource>\n```\n\nAvailable resources:\n- `ucpf://framework/overview`: Overview of the UCPF framework\n- `ucpf://framework/cognitive-states`: Guide to cognitive states\n- `ucpf://framework/knowledge-dimensions`: Reference for knowledge dimensions\n- `ucpf://session/{sessionId}/analysis`: Analysis results for a specific session\n\n## Example Use Case: Using UCPF to Solve a Riddle\n\nLet's solve the classic riddle: \"What walks on four legs in the morning, two legs in the afternoon, and three legs in the evening?\"\n\n### Step 1: Enable state management for session persistence\n\n```\n<use_mcp_tool>\n<server_name>ucpf</server_name>\n<tool_name>manage_state</tool_name>\n<arguments>\n{\n  \"action\": \"enable\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n### Step 2: Analyze the riddle using the UCPF framework\n\n```\n<use_mcp_tool>\n<server_name>ucpf</server_name>\n<tool_name>analyze_problem</tool_name>\n<arguments>\n{\n  \"problem\": \"What walks on four legs in the morning, two legs in the afternoon, and three legs in the evening?\",\n  \"session_id\": \"sphinx-riddle\",\n  \"enable_state\": true\n}\n</arguments>\n</use_mcp_tool>\n```\n\nThe analysis will provide:\n- Cognitive state assessment (likely identifying potential metaphorical thinking)\n- Knowledge mapping of what we know and don't know\n- Recursive questions to challenge initial assumptions (e.g., \"Are we assuming literal legs?\")\n- Structured perspectives on different interpretations\n\n### Step 3: Explore creative perspectives to find the solution\n\n```\n<use_mcp_tool>\n<server_name>ucpf</server_name>\n<tool_name>creative_exploration</tool_name>\n<arguments>\n{\n  \"topic\": \"Walking with different numbers of legs at different times of day\",\n  \"constraints\": [\"morning\", \"afternoon\", \"evening\", \"four\", \"two\", \"three\"],\n  \"include_metaphors\": true,\n  \"session_id\": \"sphinx-riddle\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\nThis exploration might reveal:\n- The metaphorical interpretation of \"legs\" as support structures\n- The metaphorical interpretation of times of day as stages of life\n- Leading to the classic answer: a human, who crawls on four limbs as a baby, walks on two legs as an adult, and uses a cane (third \"leg\") in old age\n\n### Step 4: Review the session analysis\n\n```\n<access_mcp_resource>\n<server_name>ucpf</server_name>\n<uri>ucpf://session/sphinx-riddle/analysis</uri>\n</access_mcp_resource>\n```\n\nThis provides the complete analysis journey, showing how the framework led to the solution through structured cognitive processing.\n\n## Acknowledgments\n\nThis project stands on the shoulders of giants:\n\n- The **Model Context Protocol (MCP)** team for creating the foundational protocol that enables AI systems to access external tools and resources\n- The **Anthropic Claude** team for their work on advanced AI systems capable of utilizing MCP\n- Contributors to the **Unified Cognitive Processing Framework** concepts that power the cognitive analysis methodology\n- The open-source community whose libraries and tools make projects like this possible\n\n## License\n\nMIT License\n\n## Project Structure\n\n```\nDeepLucid3D-UCPF-Server/\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ engine/\nâ”‚   â”‚   â”œâ”€â”€ ucpf-core.ts       # Core UCPF processing logic\nâ”‚   â”‚   â”œâ”€â”€ creative-patterns.ts  # Creative thinking utilities\nâ”‚   â”‚   â””â”€â”€ state-manager.ts   # Session state management\nâ”‚   â”œâ”€â”€ tools/\nâ”‚   â”‚   â”œâ”€â”€ analyze-problem.ts # Problem analysis tool\nâ”‚   â”‚   â””â”€â”€ creative-exploration.ts  # Creative exploration tool\nâ”‚   â””â”€â”€ index.ts               # Main server implementation\nâ”œâ”€â”€ build/                     # Compiled JavaScript files\nâ”œâ”€â”€ package.json               # Project dependencies and scripts\nâ””â”€â”€ README.md                  # This documentation\n```\n\n---\n\nÂ© 2025 DeepLucid3D UCPF Server\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "MushroomFleet--UNO-MCP": {
      "owner": "MushroomFleet",
      "name": "UNO-MCP",
      "url": "https://github.com/MushroomFleet/UNO-MCP",
      "imageUrl": "https://github.com/MushroomFleet.png",
      "description": "Transforms ordinary story content into rich, detailed narratives using advanced literary techniques and heuristic analysis. Analyzes text for strengths and weaknesses, enhances story elements, and smooths prose flow while preserving the original voice.",
      "stars": 8,
      "forks": 4,
      "license": "ISC License",
      "language": "TypeScript",
      "updated_at": "2025-09-25T13:23:43Z",
      "readme_content": "# ğŸª„ UNO: Unified Narrative Operator\r\n[![smithery badge](https://smithery.ai/badge/@MushroomFleet/uno-mcp)](https://smithery.ai/server/@MushroomFleet/uno-mcp)\r\n\r\n\r\n## âœ¨ Overview\r\n\r\nUNO (Unified Narrative Operator) is a magical text enhancement tool that transforms ordinary story content into rich, detailed narratives. Using advanced literary techniques and heuristic analysis, UNO can double the length of your text while preserving the original voice and intent.\r\n\r\nThink of UNO as your personal narrative assistant, capable of:\r\n- ğŸ“Š Analyzing your text to understand its strengths and weaknesses\r\n- ğŸŒ± Growing underdeveloped story elements\r\n- ğŸ¨ Enriching environmental descriptions\r\n- âš¡ Intensifying action sequences\r\n- ğŸŒŠ Smoothing prose flow and rhythm\r\n- ğŸ”„ Eliminating repetitive language\r\n\r\n## ğŸ› ï¸ Features\r\n\r\nUNO provides three powerful MCP tools:\r\n\r\n### 1. ğŸ” `analyze_text`\r\nPerforms deep analysis of your story pages and generates a comprehensive report including:\r\n- ğŸ“ Narrative position assessment (beginning, middle, climax, resolution)\r\n- ğŸ‘¤ Character focus identification\r\n- ğŸ­ Scene type classification\r\n- ğŸŒ¡ï¸ Mood and tone evaluation\r\n- ğŸ“ˆ Enhancement recommendations for each technique\r\n- ğŸ”„ Repetition pattern detection\r\n\r\n### 2. âœ¨ `enhance_text`\r\nTransforms your text by applying all five enhancement techniques:\r\n- Automatically expands text to meet target length (default: 200%)\r\n- Intelligently applies techniques based on what your text needs most\r\n- Balances expansions across the entire text\r\n\r\n### 3. âš™ï¸ `custom_enhance_text`\r\nGives you complete control over the enhancement process:\r\n- Choose which enhancement techniques to apply\r\n- Set custom expansion targets (100%-500%)\r\n- Focus on specific aspects of your narrative\r\n\r\n## ğŸŒŸ Enhancement Techniques\r\n\r\n### 1. ğŸ‘» Golden Shadow Enhancement\r\nIdentifies underdeveloped elements in your story and expands them:\r\n- Develops mentioned but undeveloped characters\r\n- Explores implied but unexplained plot elements\r\n- Surfaces subtext and hidden meanings\r\n\r\n### 2. ğŸï¸ Environmental Expansion\r\nEnriches your settings with immersive details:\r\n- Adds vivid sensory experiences (visual, auditory, tactile, olfactory)\r\n- Creates memorable focus on insignificant objects\r\n- Deepens the atmosphere and mood\r\n\r\n### 3. âš¡ Action Scene Enhancement\r\nTransforms action sequences into dynamic, high-intensity experiences:\r\n- Manipulates perceived time (slowing crucial moments)\r\n- Intensifies sensory details during action\r\n- Creates rhythmic alternation between explosive action and momentary stillness\r\n- Makes environments active participants in the action\r\n\r\n### 4. ğŸŒŠ Prose Smoothing\r\nImproves the flow and rhythm of your writing:\r\n- Enhances transitions between paragraphs\r\n- Varies sentence structure for better readability\r\n- Creates a natural rhythm that pulls readers through the text\r\n\r\n### 5. ğŸ”„ Repetition Elimination\r\nReduces unintentional repetition while preserving style:\r\n- Identifies and replaces repeated words with meaningful alternatives\r\n- Maintains the author's voice and intent\r\n- Distinguishes between intentional and unintentional repetition\r\n\r\n## ğŸ“‹ Installation\r\n\r\n### Installing via Smithery\r\n\r\nTo install Unified Narrative Operator for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@MushroomFleet/uno-mcp):\r\n\r\n```bash\r\nnpx -y @smithery/cli install @MushroomFleet/uno-mcp --client claude\r\n```\r\n\r\n### Prerequisites\r\n- Node.js (v14 or higher)\r\n- NPM (v6 or higher)\r\n\r\n### Step-by-Step Installation\r\n1. **Clone or download the repository**\r\n   ```bash\r\n   git clone https://github.com/your-username/uno-mcp.git\r\n   cd uno-mcp\r\n   ```\r\n\r\n2. **Install dependencies**\r\n   ```bash\r\n   npm install\r\n   ```\r\n\r\n3. **Build the TypeScript files**\r\n   ```bash\r\n   npm run build\r\n   ```\r\n\r\n4. **Make the server executable** (skip on Windows)\r\n   ```bash\r\n   chmod +x dist/index.js\r\n   ```\r\n\r\n5. **Test the server**\r\n   ```bash\r\n   node test-run.js\r\n   ```\r\n   This will run the server on a sample story and generate three files:\r\n   - `test-analysis.md`: Sample analysis report\r\n   - `test-enhanced.txt`: Sample enhanced text (200%)\r\n   - `test-custom-enhanced.txt`: Sample custom enhancement (150%)\r\n\r\n## ğŸ”Œ MCP Integration\r\n\r\n### Claude Desktop Integration\r\n\r\n1. **Edit Claude configuration file**\r\n   - Windows: `C:\\Users\\[username]\\AppData\\Roaming\\Claude\\claude_desktop_config.json`\r\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\r\n\r\n2. **Add UNO to the MCP servers section**\r\n   ```json\r\n   {\r\n     \"mcpServers\": {\r\n       \"uno\": {\r\n         \"command\": \"node\",\r\n         \"args\": [\"/absolute/path/to/uno-mcp/dist/index.js\"],\r\n         \"disabled\": false,\r\n         \"autoApprove\": []\r\n       }\r\n     }\r\n   }\r\n   ```\r\n   Be sure to use the absolute path to your UNO installation.\r\n\r\n3. **Restart Claude**\r\n   After saving the configuration, restart Claude to activate the UNO MCP server.\r\n\r\n### VS Code Integration\r\n\r\n1. **Edit VS Code Claude extension configuration**\r\n   - Windows: `c:\\Users\\[username]\\AppData\\Roaming\\Code\\User\\globalStorage\\saoudrizwan.claude-dev\\settings\\cline_mcp_settings.json`\r\n   - macOS: `~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json`\r\n\r\n2. **Add the same configuration** as shown above for Claude Desktop.\r\n\r\n3. **Restart VS Code** or reload the window.\r\n\r\n## ğŸš€ Usage Examples\r\n\r\n### Analyzing a Story\r\n\r\n```\r\n<use_mcp_tool>\r\n<server_name>uno</server_name>\r\n<tool_name>analyze_text</tool_name>\r\n<arguments>\r\n{\r\n  \"text\": \"As Sarah walked into the garden, she noticed the old statue in the corner. It was covered in moss and vines, almost hidden from view. She felt drawn to it somehow.\"\r\n}\r\n</arguments>\r\n</use_mcp_tool>\r\n```\r\n\r\nThis will return a detailed analysis report with insights about the narrative position, character focus, enhancement opportunities, and more.\r\n\r\n### Enhancing a Story (200% Expansion)\r\n\r\n```\r\n<use_mcp_tool>\r\n<server_name>uno</server_name>\r\n<tool_name>enhance_text</tool_name>\r\n<arguments>\r\n{\r\n  \"text\": \"As Sarah walked into the garden, she noticed the old statue in the corner. It was covered in moss and vines, almost hidden from view. She felt drawn to it somehow.\"\r\n}\r\n</arguments>\r\n</use_mcp_tool>\r\n```\r\n\r\nThis will return a version of your text that's approximately double the original length, with all five enhancement techniques applied.\r\n\r\n### Custom Enhancement\r\n\r\n```\r\n<use_mcp_tool>\r\n<server_name>uno</server_name>\r\n<tool_name>custom_enhance_text</tool_name>\r\n<arguments>\r\n{\r\n  \"text\": \"As Sarah walked into the garden, she noticed the old statue in the corner. It was covered in moss and vines, almost hidden from view. She felt drawn to it somehow.\",\r\n  \"expansionTarget\": 150,\r\n  \"enableGoldenShadow\": true,\r\n  \"enableEnvironmental\": true,\r\n  \"enableActionScene\": false,\r\n  \"enableProseSmoother\": true,\r\n  \"enableRepetitionElimination\": false\r\n}\r\n</arguments>\r\n</use_mcp_tool>\r\n```\r\n\r\nThis example applies only Golden Shadow Enhancement, Environmental Expansion, and Prose Smoothing, targeting a 150% expansion.\r\n\r\n## âš¡ Integration Use Cases\r\n\r\n### ğŸ“ Creative Writing Assistant\r\n\r\n```\r\nCan you enhance this scene with more environmental details?\r\n\r\n<use_mcp_tool>\r\n<server_name>uno</server_name>\r\n<tool_name>custom_enhance_text</tool_name>\r\n<arguments>\r\n{\r\n  \"text\": \"Jack entered the abandoned warehouse, searching for clues.\",\r\n  \"expansionTarget\": 300,\r\n  \"enableEnvironmental\": true,\r\n  \"enableGoldenShadow\": false,\r\n  \"enableActionScene\": false,\r\n  \"enableProseSmoother\": false,\r\n  \"enableRepetitionElimination\": false\r\n}\r\n</arguments>\r\n</use_mcp_tool>\r\n```\r\n\r\n### ğŸ“š Writing Coach\r\n\r\n```\r\nLet me analyze this paragraph to give you feedback:\r\n\r\n<use_mcp_tool>\r\n<server_name>uno</server_name>\r\n<tool_name>analyze_text</tool_name>\r\n<arguments>\r\n{\r\n  \"text\": \"[student's writing sample]\"\r\n}\r\n</arguments>\r\n</use_mcp_tool>\r\n\r\nBased on the analysis, I recommend focusing on developing your character motivations more clearly.\r\n```\r\n\r\n### ğŸ® Game Narrative Development\r\n\r\n```\r\nHere's a more intense version of your action scene:\r\n\r\n<use_mcp_tool>\r\n<server_name>uno</server_name>\r\n<tool_name>custom_enhance_text</tool_name>\r\n<arguments>\r\n{\r\n  \"text\": \"[original action scene]\",\r\n  \"enableActionScene\": true,\r\n  \"enableEnvironmental\": true,\r\n  \"enableGoldenShadow\": false,\r\n  \"enableProseSmoother\": true,\r\n  \"enableRepetitionElimination\": true\r\n}\r\n</arguments>\r\n</use_mcp_tool>\r\n```\r\n\r\n### ğŸ“” Novel Expansion\r\n\r\n```\r\nLet me help you expand this chapter:\r\n\r\n<use_mcp_tool>\r\n<server_name>uno</server_name>\r\n<tool_name>enhance_text</tool_name>\r\n<arguments>\r\n{\r\n  \"text\": \"[chapter excerpt]\",\r\n  \"expansionTarget\": 180\r\n}\r\n</arguments>\r\n</use_mcp_tool>\r\n```\r\n\r\n## ğŸ’¡ Tips & Tricks\r\n\r\n- ğŸ” Always start with `analyze_text` to understand what your text needs\r\n- ğŸ¯ For subtle enhancements, use `custom_enhance_text` with a lower expansion target (120-150%)\r\n- ğŸ§© Break longer texts into smaller sections for processing, then combine the results\r\n- ğŸ”„ Apply Repetition Elimination as the final step when enhancing longer works\r\n- âš¡ Use `enableActionScene: true` only for scenes that contain action elements\r\n\r\n## ğŸ“„ License\r\n\r\nISC\r\n\r\n## ğŸ™ Acknowledgements\r\n\r\nUNO is based on advanced literary enhancement techniques and narrative theory. Special thanks to the storytellers, writers, and narrative theorists whose work inspired this project.\r\n\r\n---\r\n\r\nâ­ **Made with love by the UNO team** â­\r\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "MymInsomnia--textClassifier": {
      "owner": "MymInsomnia",
      "name": "textClassifier",
      "url": "https://github.com/MymInsomnia/textClassifier",
      "imageUrl": "https://github.com/MymInsomnia.png",
      "description": "Multiple common text classification models based on CNN, RNN, and pre-trained NLP architectures for sentiment analysis and text classification. Supports data preprocessing, training word embeddings, and implementing advanced models like Bi-LSTM, Transformer, ELMo, and BERT for improved classification accuracy.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "Jupyter Notebook",
      "updated_at": "2019-06-14T07:35:55Z",
      "readme_content": "### æ–‡æœ¬åˆ†ç±»é¡¹ç›®\n***\n**æœ¬é¡¹ç›®ä¸ºåŸºäºCNNï¼ŒRNN å’ŒNLPä¸­é¢„è®­ç»ƒæ¨¡å‹æ„å»ºçš„å¤šä¸ªå¸¸è§çš„æ–‡æœ¬åˆ†ç±»æ¨¡å‹ã€‚**\n\n#### requirements\n* python==3.5.6\n* tensorflow-gpu==1.10.0\n\n#### 1. æ•°æ®é›†\n&ensp;&ensp;æ•°æ®é›†ä¸ºIMDBç”µå½±è¯„è®ºçš„æƒ…æ„Ÿåˆ†ææ•°æ®é›†ï¼Œæ€»å…±æœ‰ä¸‰ä¸ªéƒ¨åˆ†ï¼š\n* å¸¦æ ‡ç­¾çš„è®­ç»ƒé›†ï¼šlabeledTrainData.tsv\n* ä¸å¸¦æ ‡ç­¾çš„è®­ç»ƒé›†ï¼šunlabeledTrainData.tsv\n* æµ‹è¯•é›†ï¼štestData.tsv\n\n&ensp;&ensp;å­—æ®µçš„å«ä¹‰ï¼š\n* id  ç”µå½±è¯„è®ºçš„id\n* review  ç”µå½±è¯„è®ºçš„å†…å®¹\n* sentiment  æƒ…æ„Ÿåˆ†ç±»çš„æ ‡ç­¾ï¼ˆåªæœ‰labeledTrainData.tsvæ•°æ®é›†ä¸­æœ‰ï¼‰\n\n#### 2. æ•°æ®é¢„å¤„ç† \n&ensp;&ensp;æ•°æ®é¢„å¤„ç†æ–¹æ³•/dataHelper/processData.ipynb\n\n&ensp;&ensp;å°†åŸå§‹æ•°æ®å¤„ç†æˆå¹²å‡€çš„æ•°æ®ï¼Œå¤„ç†åçš„æ•°æ®å­˜å‚¨åœ¨/data/preProcessä¸‹ï¼Œæ•°æ®é¢„å¤„ç†åŒ…æ‹¬ï¼š\n* å»é™¤å„ç§æ ‡ç‚¹ç¬¦å·\n* ç”Ÿæˆè®­ç»ƒword2vecæ¨¡å‹çš„è¾“å…¥æ•°æ® /data/preProcess/wordEmbedding.txt\n\n#### 3. è®­ç»ƒword2vecè¯å‘é‡\n&ensp;&ensp;é¢„è®­ç»ƒword2vecè¯å‘é‡/word2vec/genWord2Vec.ipynb\n* é¢„è®­ç»ƒçš„è¯å‘é‡ä¿å­˜ä¸ºbinæ ¼å¼ /word2vec/word2Vec.bin\n\n#### 4. textCNN æ–‡æœ¬åˆ†ç±»\n&ensp;&ensp;textCNNæ¨¡å‹æ¥æºäºè®ºæ–‡[Convolutional Neural Networks for Sentence Classification](https://arxiv.org/abs/1408.5882)\n\n&ensp;&ensp;textCNNå¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªç”±ä¸‰ä¸ªå•å±‚çš„å·ç§¯ç½‘ç»œçš„è¾“å‡ºç»“æœè¿›è¡Œæ‹¼æ¥çš„èåˆæ¨¡å‹ï¼Œä½œè€…æå‡ºäº†ä¸‰ç§å¤§å°çš„å·ç§¯æ ¸[3, 4, 5]ï¼Œå·ç§¯æ ¸çš„æ»‘åŠ¨ä½¿å¾—å…¶\nç±»ä¼¼äºNLPä¸­çš„n-gramsï¼Œå› æ­¤å½“ä½ éœ€è¦æ›´å¤šå°ºåº¦çš„n-gramsæ—¶ï¼Œä½ å¯ä»¥é€‰æ‹©å¢åŠ ä¸åŒå¤§å°çš„å·ç§¯æ ¸ï¼Œæ¯”å¦‚å¤§å°ä¸º2çš„å·ç§¯æ ¸å¯ä»¥ä»£è¡¨\n2-grams.\n\n&ensp;&ensp;textCNNä»£ç åœ¨/textCNN/textCNN.ipynbã€‚å®ç°åŒ…æ‹¬å››ä¸ªéƒ¨åˆ†ï¼š\n* å‚æ•°é…ç½®ç±» Config ï¼ˆåŒ…æ‹¬è®­ç»ƒå‚æ•°ï¼Œæ¨¡å‹å‚æ•°å’Œå…¶ä»–å‚æ•°ï¼‰\n* æ•°æ®é¢„å¤„ç†ç±» Dataset ï¼ˆåŒ…æ‹¬ç”Ÿæˆè¯æ±‡ç©ºé—´ï¼Œè·å¾—é¢„è®­ç»ƒè¯å‘é‡ï¼Œåˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼‰\n* textCNNæ¨¡å‹ç±» TextCNN\n* æ¨¡å‹è®­ç»ƒ\n\n#### 5. charCNN æ–‡æœ¬åˆ†ç±»\n&ensp;&ensp;textCNNæ¨¡å‹æ¥æºäºè®ºæ–‡[Character-level Convolutional Networks for Text\nClassification](https://arxiv.org/abs/1509.01626)\n\n&ensp;&ensp;char-CNNæ˜¯ä¸€ç§åŸºäºå­—ç¬¦çº§çš„æ–‡æœ¬åˆ†ç±»å™¨ï¼Œå°†æ‰€æœ‰çš„æ–‡æœ¬éƒ½ç”¨å­—ç¬¦è¡¨ç¤ºï¼Œ\n*æ³¨æ„è¿™é‡Œçš„æ•°æ®é¢„å¤„ç†æ—¶ä¸å¯ä»¥å»æ‰æ ‡ç‚¹ç¬¦å·æˆ–è€…å…¶ä»–çš„å„ç§ç¬¦å·ï¼Œæœ€å¥½æ˜¯ä¿å­˜è®ºæ–‡ä¸­æå‡ºçš„69ç§å­—ç¬¦ï¼Œæˆ‘ä¸€å¼€å§‹ä½¿ç”¨å»æ‰ç‰¹æ®Šç¬¦å·çš„å­—ç¬¦åçš„æ–‡æœ¬è¾“å…¥åˆ°æ¨¡å‹ä¸­ä¼šæ— æ³•æ”¶æ•›*ã€‚\næ­¤å¤–ç”±äºè®­ç»ƒæ•°æ®é›†æ¯”è¾ƒå°‘ï¼Œå³ä½¿è®ºæ–‡ä¸­æœ€å°çš„ç½‘ç»œä¹Ÿæ— æ³•æ”¶æ•›ï¼Œæ­¤æ—¶å¯ä»¥å‡å°æ¨¡å‹çš„å¤æ‚åº¦ï¼ŒåŒ…æ‹¬å»æ‰ä¸€äº›å·ç§¯å±‚ç­‰ã€‚\n\n&ensp;&ensp;charCNNä»£ç åœ¨/charCNN/charCNN.ipynbã€‚å®ç°ä¹ŸåŒ…æ‹¬å››ä¸ªéƒ¨åˆ†ï¼Œä¹ŸtextCNNä¸€è‡´ï¼Œä½†æ˜¯åœ¨è¿™é‡Œçš„æ•°æ®é¢„å¤„ç†æœ‰å¾ˆå¤§ä¸ä¸€æ ·ï¼Œå‰©ä¸‹\nçš„å°±æ˜¯æ¨¡å‹ç»“æ„ä¸åŒï¼Œæ­¤å¤–æ¨¡å‹ä¸­å¯ä»¥å¼•å…¥BNå±‚æ¥å¯¹æ¯ä¸€å±‚çš„è¾“å‡ºåšå½’ä¸€åŒ–å¤„ç†ã€‚\n\n#### 6. Bi-LSTM æ–‡æœ¬åˆ†ç±»\n&ensp;&ensp;Bi-LSTMå¯ä»¥å‚è€ƒæˆ‘çš„åšå®¢[æ·±åº¦å­¦ä¹ ä¹‹ä»RNNåˆ°LSTM](https://www.cnblogs.com/jiangxinyang/p/9362922.html)\n\n&ensp;&ensp;Bi-LSTMæ˜¯åŒå‘LSTMï¼ŒLSTMæ˜¯RNNçš„ä¸€ç§ï¼Œæ˜¯ä¸€ç§æ—¶åºæ¨¡å‹ï¼ŒBi-LSTMæ˜¯åŒå‘LSTMï¼Œæ—¨åœ¨åŒæ—¶æ•è·æ–‡æœ¬ä¸­ä¸Šä¸‹æ–‡çš„ä¿¡æ¯ï¼Œ\nåœ¨æƒ…æ„Ÿåˆ†æç±»çš„é—®é¢˜ä¸­æœ‰è‰¯å¥½çš„è¡¨ç°ã€‚\n\n&ensp;&ensp;Bi-LSTMçš„ä»£ç åœ¨/Bi-LSTM/Bi-LSTM.ipynbä¸­ã€‚é™¤äº†æ¨¡å‹ç±»çš„ä»£ç æœ‰æ”¹åŠ¨ï¼Œå…¶ä½™ä»£ç å‡ ä¹å’ŒtextCNNä¸€æ ·ã€‚\n\n#### 7. Bi-LSTM + Attention æ–‡æœ¬åˆ†ç±»\n&ensp;&ensp;Bi-LSTM + Attentionæ¨¡å‹æ¥æºäºè®ºæ–‡[Attention-Based Bidirectional Long Short-Term Memory Networks for\nRelation Classification](http://aclweb.org/anthology/Y/Y15/Y15-1009.pdf)\n\n&ensp;&ensp;Bi-LSTM + Attention å°±æ˜¯åœ¨Bi-LSTMçš„æ¨¡å‹ä¸ŠåŠ å…¥Attentionå±‚ï¼Œåœ¨Bi-LSTMä¸­æˆ‘ä»¬ä¼šç”¨æœ€åä¸€ä¸ªæ—¶åºçš„è¾“å‡ºå‘é‡\nä½œä¸ºç‰¹å¾å‘é‡ï¼Œç„¶åè¿›è¡Œsoftmaxåˆ†ç±»ã€‚Attentionæ˜¯å…ˆè®¡ç®—æ¯ä¸ªæ—¶åºçš„æƒé‡ï¼Œç„¶åå°†æ‰€æœ‰æ—¶åº\nçš„å‘é‡è¿›è¡ŒåŠ æƒå’Œä½œä¸ºç‰¹å¾å‘é‡ï¼Œç„¶åè¿›è¡Œsoftmaxåˆ†ç±»ã€‚åœ¨å®éªŒä¸­ï¼ŒåŠ ä¸ŠAttentionç¡®å®å¯¹ç»“æœæœ‰æ‰€æå‡ã€‚\n\n&ensp;&ensp;Bi-LSTM + Attentionçš„ä»£ç åœ¨/Bi-LSTM+Attention/Bi-LSTMAttention.ipynbä¸­ï¼Œé™¤äº†æ¨¡å‹ç±»ä¸­\nåŠ å…¥Attentionå±‚ï¼Œå…¶ä½™ä»£ç å’ŒBi-LSTMä¸€è‡´ã€‚\n\n#### 8. RCNN æ–‡æœ¬åˆ†ç±»\n&ensp;&ensp;RCNNæ¨¡å‹æ¥æºäºè®ºæ–‡[Recurrent Convolutional Neural Networks for Text Classification](https://arxiv.org/abs/1609.04243)\n\n&ensp;&ensp;RCNN æ•´ä½“çš„æ¨¡å‹æ„å»ºæµç¨‹å¦‚ä¸‹ï¼š\n* åˆ©ç”¨Bi-LSTMè·å¾—ä¸Šä¸‹æ–‡çš„ä¿¡æ¯ï¼Œç±»ä¼¼äºè¯­è¨€æ¨¡å‹\n* å°†Bi-LSTMè·å¾—çš„éšå±‚è¾“å‡ºå’Œè¯å‘é‡æ‹¼æ¥[fwOutput, wordEmbedding, bwOutput]\n* å°†æ‹¼æ¥åçš„å‘é‡éçº¿æ€§æ˜ å°„åˆ°ä½ç»´\n* å‘é‡ä¸­çš„æ¯ä¸€ä¸ªä½ç½®çš„å€¼éƒ½å–æ‰€æœ‰æ—¶åºä¸Šçš„æœ€å¤§å€¼ï¼Œå¾—åˆ°æœ€ç»ˆçš„ç‰¹å¾å‘é‡ï¼Œè¯¥è¿‡ç¨‹ç±»ä¼¼äºmax-pool\n* softmaxåˆ†ç±»\n\n&ensp;&ensp;RCNNçš„ä»£ç åœ¨/RCNN/RCNN.ipynbä¸­ã€‚\n\n#### 9. adversarialLSTM æ–‡æœ¬åˆ†ç±»\n&ensp;&ensp;Adversarial LSTMæ¨¡å‹æ¥æºäºè®ºæ–‡[Adversarial Training Methods\nFor Semi-Supervised Text Classification](https://arxiv.org/abs/1605.07725)\n\n&ensp;&ensp;adversarialLSTMçš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å¯¹word Embeddingä¸Šæ·»åŠ å™ªéŸ³ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼Œå°†å¯¹æŠ—æ ·æœ¬ä»¥å’ŒåŸå§‹æ ·æœ¬\nåŒæ ·çš„å½¢å¼å–‚ç»™æ¨¡å‹ï¼Œå¾—åˆ°ä¸€ä¸ªAdversarial Lossï¼Œé€šè¿‡å’ŒåŸå§‹æ ·æœ¬çš„lossç›¸åŠ å¾—åˆ°æ–°çš„æŸå¤±ï¼Œé€šè¿‡ä¼˜åŒ–è¯¥æ–°\nçš„æŸå¤±æ¥è®­ç»ƒæ¨¡å‹ï¼Œä½œè€…è®¤ä¸ºè¿™ç§æ–¹æ³•èƒ½å¯¹word embeddingåŠ ä¸Šæ­£åˆ™åŒ–ï¼Œé¿å…è¿‡æ‹Ÿåˆã€‚\n\n&ensp;&ensp;adversarialLSTMçš„ä»£ç åœ¨/adversarialLSTM/adversarialLSTM.ipynbä¸­ã€‚\n\n#### 10. Transformer æ–‡æœ¬åˆ†ç±»\n&ensp;&ensp;Transformeræ¨¡å‹æ¥æºäºè®ºæ–‡[Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n\n&ensp;&ensp;Transformeræ¨¡å‹æœ‰ä¸¤ä¸ªç»“æ„ï¼šEncoderå’ŒDecoderï¼Œåœ¨è¿›è¡Œæ–‡æœ¬åˆ†ç±»æ—¶åªéœ€è¦ç”¨åˆ°\nEncoderç»“æ„ï¼ŒDecoderç»“æ„æ˜¯ç”Ÿæˆå¼æ¨¡å‹ï¼Œç”¨äºè‡ªç„¶è¯­è¨€ç”Ÿæˆçš„ã€‚Transformerçš„æ ¸å¿ƒç»“æ„æ˜¯\nself-Attentionæœºåˆ¶ï¼Œå…·ä½“çš„ä»‹ç»è§[Transformeræ¨¡å‹ï¼ˆAtention is all you needï¼‰](https://www.cnblogs.com/jiangxinyang/p/10069330.html)ã€‚\n\n&ensp;&ensp;Transformeræ¨¡å‹çš„ä»£ç åœ¨/Transformer/transformer.ipynbä¸­ã€‚\n\n#### 11. ELMoé¢„è®­ç»ƒæ¨¡å‹ æ–‡æœ¬åˆ†ç±»\n&ensp;&ensp;ELMoæ¨¡å‹æ¥æºäºè®ºæ–‡[Deep contextualized word representations](https://arxiv.org/abs/1802.05365?context=cs)\n\n&ensp;&ensp;ELMoçš„ç»“æ„æ˜¯BiLMï¼ˆåŒå‘è¯­è¨€æ¨¡å‹ï¼‰ï¼ŒåŸºäºELMoçš„é¢„è®­ç»ƒæ¨¡å‹èƒ½åŠ¨æ€åœ°ç”Ÿæˆ\nè¯çš„å‘é‡è¡¨ç¤ºï¼Œå…·ä½“çš„ä»‹ç»è§[ELMOæ¨¡å‹ï¼ˆDeep contextualized word representationï¼‰](https://www.cnblogs.com/jiangxinyang/p/10060887.html)\n\n&ensp;&ensp;ELMoé¢„è®­ç»ƒæ¨¡å‹ç”¨äºæ–‡æœ¬åˆ†ç±»çš„ä»£ç ä½äº/ELMo/elmo.ipynbä¸­ã€‚\n/ELMo/bilm/ä¸‹æ˜¯ELMoé¡¹ç›®ä¸­çš„æºç ï¼Œ/ELMo/modelParams/ä¸‹æ˜¯å„ç§æ–‡ä»¶ã€‚\n\n#### 12. Berté¢„è®­ç»ƒæ¨¡å‹ æ–‡æœ¬åˆ†ç±»\n&ensp;&ensp;BERTæ¨¡å‹æ¥æºäºè®ºæ–‡[BERT: Pre-training of Deep Bidirectional Transformers for\nLanguage Understanding](https://arxiv.org/abs/1810.04805)\n\n&ensp;&ensp;BERTæ¨¡å‹æ˜¯åŸºäºåŒå‘Transformerå®ç°çš„è¯­è¨€æ¨¡å‹ï¼Œé›†é¢„è®­ç»ƒå’Œä¸‹æ¸¸ä»»åŠ¡äºä¸€ä¸ªæ¨¡å‹ä¸­ï¼Œ\nå› æ­¤åœ¨ä½¿ç”¨çš„æ—¶å€™æˆ‘ä»¬ä¸éœ€è¦æ­å»ºè‡ªå·±çš„ä¸‹æ¸¸ä»»åŠ¡æ¨¡å‹ï¼Œç›´æ¥ç”¨BERTæ¨¡å‹å³å¯ï¼Œæˆ‘ä»¬å°†è°·æ­Œå¼€æºçš„æºç ä¸‹è½½\nä¸‹æ¥æ”¾åœ¨bertæ–‡ä»¶å¤¹ä¸­ï¼Œåœ¨è¿›è¡Œæ–‡æœ¬åˆ†ç±»åªéœ€è¦ä¿®æ”¹run_classifier.pyæ–‡ä»¶å³å¯ï¼Œå¦å¤–æˆ‘ä»¬éœ€è¦å°†è®­ç»ƒé›†\nå’ŒéªŒè¯é›†åˆ†å‰²åä¿å­˜åœ¨ä¸¤ä¸ªä¸åŒçš„æ–‡ä»¶ä¸­ï¼Œæ”¾ç½®åœ¨/BERT/dataä¸‹ã€‚ç„¶åè¿˜éœ€è¦ä¸‹è½½è°·æ­Œé¢„è®­ç»ƒå¥½çš„æ¨¡å‹æ”¾ç½®åœ¨\n/BERT/modelParamsæ–‡ä»¶å¤¹ä¸‹ï¼Œè¿˜éœ€è¦å»ºä¸€ä¸ª/BERT/outputæ–‡ä»¶å¤¹ç”¨æ¥æ”¾ç½®è®­ç»ƒåçš„æ¨¡å‹æ–‡ä»¶\n\n&ensp;&ensp;åšå®Œä¸Šé¢çš„æ­¥éª¤ä¹‹ååªè¦æ‰§è¡Œä¸‹é¢çš„è„šæœ¬å³å¯\n\n&ensp;&ensp;export BERT_BASE_DIR=../modelParams/uncased_L-12_H-768_A-12\n\n&ensp;&ensp;export DATASET=../data/\n\n&ensp;&ensp;python run_classifier.py \\\n  &ensp;&ensp;&ensp;&ensp;--data_dir=$MY_DATASET \\\n  &ensp;&ensp;&ensp;&ensp;--task_name=imdb \\\n  &ensp;&ensp;&ensp;&ensp;--vocab_file=$BERT_BASE_DIR/vocab.txt \\\n  &ensp;&ensp;&ensp;&ensp;--bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n  &ensp;&ensp;&ensp;&ensp;--output_dir=../output/ \\\n  &ensp;&ensp;&ensp;&ensp;--do_train=true \\\n  &ensp;&ensp;&ensp;&ensp;--do_eval=true \\\n  &ensp;&ensp;&ensp;&ensp;--init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n  &ensp;&ensp;&ensp;&ensp;--max_seq_length=200 \\\n  &ensp;&ensp;&ensp;&ensp;--train_batch_size=16 \\\n  &ensp;&ensp;&ensp;&ensp;--learning_rate=5e-5\\\n  &ensp;&ensp;&ensp;&ensp;--num_train_epochs=3.0\n\n&ensp;&ensp;BERTæ¨¡å‹ç”¨äºæ–‡æœ¬åˆ†ç±»çš„è¯¦ç»†ä½¿ç”¨å¯ä»¥çœ‹æˆ‘çš„åšå®¢\n[æ–‡æœ¬åˆ†ç±»å®æˆ˜ï¼ˆåï¼‰â€”â€” BERT é¢„è®­ç»ƒæ¨¡å‹](https://www.cnblogs.com/jiangxinyang/p/10241243.html)\n\n\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "nailuoGG--anki-mcp-server": {
      "owner": "nailuoGG",
      "name": "anki-mcp-server",
      "url": "https://github.com/nailuoGG/anki-mcp-server",
      "imageUrl": "https://github.com/nailuoGG.png",
      "description": "Interact with Anki flashcard software through AnkiConnect to create, manage, and search flashcards efficiently. Automate various operations on flashcards and decks with a simple API interface.",
      "stars": 145,
      "forks": 31,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-10-04T08:18:42Z",
      "readme_content": "# Anki MCP Server\n\nA Model Context Protocol (MCP) server that enables LLMs to interact with Anki flashcard software through AnkiConnect.\n\n![Anki Icon](./assets/icon.png)\n\n## Features\n\n### Tools\n\n- `list_decks` - List all available Anki decks\n- `create_deck` - Create a new Anki deck\n- `create_note` - Create a new note (Basic or Cloze)\n- `batch_create_notes` - Create multiple notes at once\n- `search_notes` - Search for notes using Anki query syntax\n- `get_note_info` - Get detailed information about a note\n- `update_note` - Update an existing note\n- `delete_note` - Delete a note\n- `list_note_types` - List all available note types\n- `create_note_type` - Create a new note type\n- `get_note_type_info` - Get detailed structure of a note type\n\n### Resources\n\n- `anki://decks/all` - Complete list of available decks\n- `anki://note-types/all` - List of all available note types\n- `anki://note-types/all-with-schemas` - Detailed structure information for all note types\n- `anki://note-types/{modelName}` - Detailed structure information for a specific note type\n\n## Prerequisites\n\n1. [Anki](https://apps.ankiweb.net/) installed on your system\n2. [AnkiConnect](https://ankiweb.net/shared/info/2055492159) add-on installed in Anki\n\n## Configuration\n\n### Install via Desktop Extension (.mcpb)\n\nThis repository supports Anthropic Desktop Extensions (MCPB). The easiest way to use this server in Claude Desktop is by installing the packaged `.mcpb` bundle.\n\n1. Generate the `.mcpb` file locally using the provided script:\n```bash\nnpm run pack\n```\n\n2. Open Claude Desktop Settings â†’ Extensions and drag the generated `.mcpb` file in, then click Install.\n\nThis validates `manifest.json` and outputs a `.mcpb` archive you can install as above. Learn more about Desktop Extensions in Anthropic's announcement: [Desktop Extensions: One-click MCP server installation for Claude Desktop](https://www.anthropic.com/engineering/desktop-extensions).\n\n### Usage with Claude Desktop\n\nAdd the server to your claude_desktop_config.json:\n\n```json\n{\n  \"mcpServers\": {\n    \"anki\": {\n      \"command\": \"npx\",\n      \"args\": [\"--yes\", \"anki-mcp-server\"]\n    }\n  }\n}\n```\n\n#### Using Custom AnkiConnect Port\n\nIf your AnkiConnect is running on a different port, you can specify it using the `--port` parameter:\n\n```json\n{\n  \"mcpServers\": {\n    \"anki\": {\n      \"command\": \"npx\",\n      \"args\": [\"--yes\", \"anki-mcp-server\", \"--port\", \"8080\"]\n    }\n  }\n}\n```\n\n### Configuration for Cline\n\nAdd the server to your Cline MCP settings file inside VSCode's settings `cline_mcp_settings.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"anki\": {\n      \"command\": \"npx\",\n      \"args\": [\"--yes\", \"anki-mcp-server\"]\n    }\n  }\n}\n```\n\n#### Using Custom AnkiConnect Port\n\nFor Cline, you can also specify a custom port:\n\n```json\n{\n  \"mcpServers\": {\n    \"anki\": {\n      \"command\": \"npx\",\n      \"args\": [\"--yes\", \"anki-mcp-server\", \"--port\", \"8080\"]\n    }\n  }\n}\n```\n\n## Development\n\n### Packaging a Desktop Extension (.mcpb)\n\nCreate a distributable Desktop Extension bundle for Claude Desktop:\n\n```bash\nnpm run pack\n```\n\nThis will build the project and generate a `.mcpb` archive from the current repository, validating `manifest.json`. Test by dragging it into Claude Desktop's Extensions settings. Reference: [Desktop Extensions: One-click MCP server installation for Claude Desktop](https://www.anthropic.com/engineering/desktop-extensions).\n\n### Publishing to MCP Registry\n\nThis server is automatically published to the MCP Registry when a new version is released. The publishing process includes:\n\n1. **Automated CI/CD**: GitHub Actions automatically publishes to both NPM and MCP Registry on successful releases\n2. **Schema Validation**: The `server.json` file is validated against the MCP schema before publishing\n3. **Version Synchronization**: Versions are kept in sync between `package.json`, `manifest.json`, and `server.json`\n4. **Comprehensive Testing**: Multi-version Node.js testing, linting, and validation before publishing\n5. **Beta Support**: Automated beta releases for testing new features\n\n#### Manual Validation\n\nYou can validate the MCP server configuration locally:\n\n```bash\nnpm run validate-mcp\n```\n\nThis will download the latest MCP schema and validate your `server.json` file.\n\n#### Manual Publishing\n\nIf you need to publish manually, you can use the MCP Publisher CLI:\n\n```bash\n# Install MCP Publisher\ncurl -L \"https://github.com/modelcontextprotocol/registry/releases/download/v1.1.0/mcp-publisher_1.1.0_$(uname -s | tr '[:upper:]' '[:lower:]')_$(uname -m | sed 's/x86_64/amd64/;s/aarch64/arm64/').tar.gz\" | tar xz mcp-publisher\nchmod +x mcp-publisher\nsudo mv mcp-publisher /usr/local/bin/\n\n# Login to MCP Registry\nmcp-publisher login github-oidc\n\n# Publish to MCP Registry\nmcp-publisher publish\n```\n\n### Setup\n\n1. Install dependencies:\n\n```bash\nnpm install\n```\n\n2. Build the server:\n\n```bash\nnpm run build\n```\n\n3. For development with auto-rebuild:\n\n```bash\nnpm run watch\n```\n\n### Testing\n\nRun the test suite:\n\n```bash\nnpm test\n```\n\nThis executes tests for:\n\n- Server initialization\n- AnkiConnect communication\n- Note operations (create/read/update/delete)\n- Deck management\n- Error handling\n\n### Debugging\n\nSince MCP servers communicate over stdio, we recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector):\n\n```bash\nnpm run inspector\n```\n\nThis provides a browser-based interface for:\n\n- Monitoring MCP messages\n- Testing tool invocations\n- Viewing server logs\n- Debugging communication issues\n\n## Example Usage\n\n1. Create a new deck:\n\n```\nCreate a new Anki deck called \"Programming\"\n```\n\n2. Add a basic card:\n\n```\nCreate an Anki card in the \"Programming\" deck with:\nFront: What is a closure in JavaScript?\nBack: A closure is the combination of a function and the lexical environment within which that function was declared.\n```\n\n3. Add a cloze deletion card:\n\n```\nCreate a cloze card in the \"Programming\" deck with:\nText: In JavaScript, {{c1::const}} declares a block-scoped variable that cannot be {{c2::reassigned}}.\n```\n\n## Contributing\n\n1. Fork the repository\n2. Create your feature branch\n3. Run tests: `npm test`\n4. Submit a pull request\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=nailuoGG/anki-mcp-server&type=Date)](https://star-history.com/#nailuoGG/anki-mcp-server&Date)\n\n## Credits\n\nIcon courtesy of [macOS Icons](https://macosicons.com/#/?icon=mWDBpVXqbc)\n\n## License\n\nMIT License - see LICENSE file for details\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "mususi--ultimate-react-course": {
      "owner": "mususi",
      "name": "ultimate-react-course",
      "url": "https://github.com/mususi/ultimate-react-course",
      "imageUrl": "https://github.com/mususi.png",
      "description": "Provides starter files and final code for all projects in the Ultimate React Course, allowing users to compare their progress with completed examples. Includes FAQs and resources to assist users in troubleshooting and improving their React skills.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2024-02-09T10:12:11Z",
      "readme_content": "# Course Material and FAQ for the Ultimate React Course\n\nThis branch of the repo contains starter files and final code for all sections and projects of the course, **exactly as shown in the videos**.\n\nUse starter code to start each section, and **final code to compare it with your own code whenever something doesn't work**!\n\nThere is also a the [updates-and-fixes](https://github.com/jonasschmedtmann/ultimate-react-course/tree/updates-and-fixes) branch which is kept up-to-date with **latest library updates and important bugfixes ğŸ›**\n\nğŸš¨ **_Please read the following Frequently Asked Questions (FAQ) carefully before starting the course_** ğŸš¨\n\n## FAQ\n\n### Q1: How do I download the files?\n\n**A:** If you just want to download the entire code, click the green button saying \"Code\", and then choose the \"Download ZIP\" option. If you can't see the button (on mobile), use [this link](https://github.com/jonasschmedtmann/ultimate-react-course/archive/main.zip) instead.\n\n### Q2: I'm stuck! Where do I get help?\n\n**A:** Have you tried to fix the problem on your own? **Have you compared your code with the final code?** Are you using the library versions as indicated in the course videos? If you failed fixing your problem, please **post a detailed description of the problem to the Q&A area of that video over at Udemy**, along with a link to a [codesandbox](https://codesandbox.io/) containing your code.\n\n### Q3: Can I see a final version of the course projects?\n\n**A:** Sure! Here you go:\n\n- [Pizza Menu](https://fast-react-pizza-menu.netlify.app/) (Components, props, JSX)\n- [Travel List](https://travel-list-jonas.netlify.app/) (useState and state management)\n- [Eat-n-split](https://eat-n-split.netlify.app/) (Practice project)\n- [usePopcorn](https://usepopcorn.netlify.app) (useEffect, data fetching, custom hooks)\n- [Classy weather](https://classy-weather.netlify.app/) (Class components)\n- [Quiz App](https://the-react-quiz.netlify.app/) (useReducer)\n- [WorldWise](https://worldwise-jonas.netlify.app/) (React Router, context API, memo, useMemo, useCallback)\n- [Fast React Pizza](https://fast-react-pizza.netlify.app/) (React Router data loading, Redux, Redux Toolkit, thunks, Tailwind CSS)\n- [The Wild Oasis](https://the-wild-oasis.vercel.app) (React Query, Styled Components, React Hook Form, Supabase, advanced compound component pattern, authentication, charts, dark mode, professional application planning and development)\n\n### Q4: What about Next.js?\n\n**A:** I will add a few sections about Next.js to a future Part 5 of this course in the first half of 2024. Until then, make sure to first master React itself ğŸ˜‰\n\n### Q5: What VSCode theme are you using?\n\n**A:** I use [One Monokai](https://marketplace.visualstudio.com/items?itemName=azemoh.one-monokai) in this course. For the icons, I'm using [Material Icon Theme](https://marketplace.visualstudio.com/items?itemName=PKief.material-icon-theme).\n\n### Q6: Videos don't load, can you fix it?\n\n**A:** Unfortunately, there is nothing I can do about it. The course is hosted on Udemy, and sometimes they have technical issues. Please just come back a bit later or [contact their support team](https://support.udemy.com/hc/en-us).\n\n### Q7: Videos are blurred / have low quality, can you fix it?\n\n**A:** Please open video settings and change the quality from 'Auto' to another value, for example 720p. If that doesn't help, please [contact the Udemy support team](https://support.udemy.com/hc/en-us).\n\n### Q8: Are videos downloadable?\n\n**A:** Videos used to be downloadable, but unfortunately, Udemy has disabled video downloads on all my courses in order to fight piracy. There is nothing I can do about this.\n\n### Q9: I want to put these projects in my portfolio. Is that allowed?\n\n**A:** Absolutely! Just make sure you actually built them yourself by following the course, and that you understand what you did. What is **not allowed** is that you create your own course/videos/articles based on this course's content!\n\n### Q10: I love your courses and want to get updates on new ones. How?\n\n**A:** First, you can subscribe to my email list [at my website](http://codingheroes.io/resources). Plus, I make important announcements on twitter [@jonasschmedtman](https://twitter.com/jonasschmedtman), so you should definitely follow me there ğŸ”¥\n\n### Q11: How do I get my certificate of completion?\n\n**A:** A certificate of completion is provided by Udemy after you complete 100% of the course. After completing the course, just click on the \"Your progress\" indicator in the top right-hand corner of the course page. If you want to change your name on the certificate, please [contact the Udemy support team](https://support.udemy.com/hc/en-us).\n\n### Q12: Can you add subtitles in my language?\n\n**A:** No. I provide professional English captions, but Udemy is responsible for subtitles in all other languages (automatic translations). So please [contact the Udemy support team](https://support.udemy.com/hc/en-us) to request your own language.\n\n### Q13: Do you accept pull requests?\n\n**A:** No, because this repository should contain the _exact_ same code that is shown in the videos. _However, feel free to add an issue if you found one._\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "ndchikin--reference-mcp": {
      "owner": "ndchikin",
      "name": "reference-mcp",
      "url": "https://github.com/ndchikin/reference-mcp",
      "imageUrl": "https://github.com/ndchikin.png",
      "description": "Retrieve BibTeX-formatted citation data from CiteAs and Google Scholar to streamline citation management in research applications.",
      "stars": 9,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-07T07:55:23Z",
      "readme_content": "# CiteAssist MCP server\n\n[![smithery badge](https://smithery.ai/badge/@ndchikin/reference-mcp)](https://smithery.ai/server/@ndchikin/reference-mcp)\n\nA Model Context Protocol server that provides BibTeX-formatted citation data from CiteAs and Google Scholar. Enhance your research workflow by integrating citation retrieval directly into your applications.\n\n## Components\n\n### Tools\n\n* `get_citeas_data` - Retrieve BibTeX-formatted citation for the specified resource from the CiteAs\n  * `resource` (string, required): DOI, URL, keyword\n* `get_scholar_data` - Retrieve BibTeX-formatted citations from the Google Scholar\n  * `query` (string, required): Search query\n  * `results` (integer, optional): Number of results (default: 2)\n\n## Quickstart\n\n### Install\n\n#### Claude Desktop\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\nDevelopment/Unpublished Servers Configuration:\n\n```json\n\"mcpServers\": {\n  \"reference-mcp\": {\n    \"command\": \"uv\",\n    \"args\": [\n      \"--directory\",\n      \"/path/to/project/dir\",\n      \"run\",\n      \"reference-mcp\"\n    ]\n  }\n}\n```\n\nPublished Servers Configuration:\n\n```json\n\"mcpServers\": {\n  \"reference-mcp\": {\n    \"command\": \"uvx\",\n    \"args\": [\n      \"reference-mcp\"\n    ]\n  }\n}\n```\n\n### Installing via Smithery\n\nTo install reference-mcp for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@ndchikin/reference-mcp):\n\n```bash\nnpx -y @smithery/cli install @ndchikin/reference-mcp --client claude\n```\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory /path/to/project/dir run reference-mcp\n```\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "olaservo--shannon-thinking": {
      "owner": "olaservo",
      "name": "shannon-thinking",
      "url": "https://github.com/olaservo/shannon-thinking",
      "imageUrl": "https://github.com/olaservo.png",
      "description": "Guides complex problem-solving by breaking down challenges into structured thoughts using a systematic methodology. Supports iterative revisions and empirical validation for engineering design and optimization tasks.",
      "stars": 43,
      "forks": 7,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T21:33:51Z",
      "readme_content": "# shannon-thinking\n\nAn MCP server demonstrating Claude Shannon's systematic problem-solving methodology. This server provides a tool that helps break down complex problems into structured thoughts following Shannon's approach of problem definition, mathematical modeling, and practical implementation.\n\n<a href=\"https://glama.ai/mcp/servers/iffffhwqqw\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/iffffhwqqw/badge\" alt=\"Shannon Thinking Server MCP server\" />\n</a>\n\n## Overview\n\nClaude Shannon, known as the father of information theory, approached complex problems through a systematic methodology:\n\n1. **Problem Definition**: Strip the problem to its fundamental elements\n2. **Constraints**: Identify system limitations and boundaries\n3. **Model**: Develop mathematical/theoretical frameworks\n4. **Proof/Validation**: Validate through formal proofs or experimental testing\n5. **Implementation/Experiment**: Design and test practical solutions\n\nThis MCP server demonstrates this methodology as a tool that helps guide systematic problem-solving through these stages.\n\n## Installation\n\n### NPX\n\n```json\n{\n  \"mcpServers\": {\n    \"shannon-thinking\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"server-shannon-thinking@latest\"\n      ]\n    }\n  }\n}\n```\n\n## Usage\n\nThe server provides a single tool named `shannonthinking` that structures problem-solving thoughts according to Shannon's methodology.\n\nEach thought must include:\n- The actual thought content\n- Type (problem_definition/constraints/model/proof/implementation)\n- Thought number and total thoughts estimate\n- Confidence level (uncertainty: 0-1)\n- Dependencies on previous thoughts\n- Explicit assumptions\n- Whether another thought step is needed\n\nAdditional capabilities:\n- **Revision**: Thoughts can revise earlier steps as understanding evolves\n- **Recheck**: Mark steps that need re-examination with new information\n- **Experimental Validation**: Support for empirical testing alongside formal proofs\n- **Implementation Notes**: Practical constraints and proposed solutions\n\n### Example Usage\n\n```typescript\nconst thought = {\n  thought: \"The core problem can be defined as an information flow optimization\",\n  thoughtType: \"problem_definition\",\n  thoughtNumber: 1,\n  totalThoughts: 5,\n  uncertainty: 0.2,\n  dependencies: [],\n  assumptions: [\"System has finite capacity\", \"Information flow is continuous\"],\n  nextThoughtNeeded: true,\n  // Optional: Mark as revision of earlier definition\n  isRevision: false,\n  // Optional: Indicate step needs recheck\n  recheckStep: {\n    stepToRecheck: \"constraints\",\n    reason: \"New capacity limitations discovered\",\n    newInformation: \"System shows non-linear scaling\"\n  }\n};\n\n// Use with MCP client\nconst result = await client.callTool(\"shannonthinking\", thought);\n```\n\n## Features\n\n- **Iterative Problem-Solving**: Supports revisions and rechecks as understanding evolves\n- **Flexible Validation**: Combines formal proofs with experimental validation\n- **Dependency Tracking**: Explicitly tracks how thoughts build upon previous ones\n- **Assumption Management**: Requires clear documentation of assumptions\n- **Confidence Levels**: Quantifies uncertainty in each step\n- **Rich Feedback**: Formatted console output with color-coding, symbols, and validation results\n\n## Development\n\n```bash\n# Install dependencies\nnpm install\n\n# Build\nnpm run build\n\n# Run tests\nnpm test\n\n# Watch mode during development\nnpm run watch\n```\n\n## Tool Schema\n\nThe tool accepts thoughts with the following structure:\n\n```typescript\ninterface ShannonThought {\n  thought: string;\n  thoughtType: \"problem_definition\" | \"constraints\" | \"model\" | \"proof\" | \"implementation\";\n  thoughtNumber: number;\n  totalThoughts: number;\n  uncertainty: number; // 0-1\n  dependencies: number[];\n  assumptions: string[];\n  nextThoughtNeeded: boolean;\n  \n  // Optional revision fields\n  isRevision?: boolean;\n  revisesThought?: number;\n  \n  // Optional recheck field\n  recheckStep?: {\n    stepToRecheck: ThoughtType;\n    reason: string;\n    newInformation?: string;\n  };\n  \n  // Optional validation fields\n  proofElements?: {\n    hypothesis: string;\n    validation: string;\n  };\n  experimentalElements?: {\n    testDescription: string;\n    results: string;\n    confidence: number; // 0-1\n    limitations: string[];\n  };\n  \n  // Optional implementation fields\n  implementationNotes?: {\n    practicalConstraints: string[];\n    proposedSolution: string;\n  };\n}\n```\n\n## When to Use\n\nThis thinking pattern is particularly valuable for:\n- Complex system analysis\n- Information processing problems\n- Engineering design challenges\n- Problems requiring theoretical frameworks\n- Optimization problems\n- Systems requiring practical implementation\n- Problems that need iterative refinement\n- Cases where experimental validation complements theory\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "ohardcore--awesome-interview-questions": {
      "owner": "ohardcore",
      "name": "awesome-interview-questions",
      "url": "https://github.com/ohardcore/awesome-interview-questions",
      "imageUrl": "https://github.com/ohardcore.png",
      "description": "Curated collection of technical interview questions categorized by programming languages, frameworks, and other technical domains. Aids in interview preparation through a comprehensive set of questions of varying difficulty levels.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2021-03-01T19:28:53Z",
      "readme_content": "# Awesome Interviews [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\n> A curated list of lists of technical interview questions.\n\n[What makes for an awesome list?](awesome.md)\n\nPlease read the [contribution guidelines](contributing.md) or the [creating a list guide](create-list.md) if you want to contribute.\n\n**Check out my [channel](https://t.me/botcube) or [blog](https://medium.com/@MaximAbramchuk).**\n\n### Table of Contents\n\n- [Programming Languages/Frameworks/Platforms](#programming-languagesframeworksplatforms)\n  - [Android](#android)\n  - [AngularJS](#angularjs)\n  - [BackboneJS](#backbonejs)\n  - [C++](#c)\n  - [C](#c-1)\n  - [Câ™¯](#c-2)\n  - [.NET](#net)\n  - [Clojure](#clojure)\n  - [CSS](#css)\n  - [Django](#django)\n  - [EmberJS](#emberjs)\n  - [Erlang](#erlang)\n  - [Golang](#golang)\n  - [HTML](#html)\n  - [Ionic](#ionic)\n  - [iOS](#ios)\n  - [Java](#java)\n  - [JavaScript](#javascript)\n  - [Front-end build tools](#front-end-build-tools)\n  - [KnockoutJS](#knockoutjs)\n  - [Less](#less)\n  - [Lisp](#lisp)\n  - [NodeJS](#nodejs)\n  - [Objective-C](#objective-c)\n  - [PHP](#php)\n  - [Python](#python)\n  - [ReactJS](#reactjs)\n  - [Rails](#ruby-on-rails)\n  - [Ruby](#ruby)\n  - [Sass](#sass)\n  - [Scala](#scala)\n  - [Shell](#shell)\n  - [Swift](#swift)\n  - [Wordpress](#wordpress)\n- [Database technologies](#database-technologies)\n  - [Cassandra](#cassandra)\n  - [Microsoft Access](#microsoft-access)\n  - [MongoDB](#mongodb)\n  - [MySQL](#mysql)\n  - [Neo4j](#neo4j)\n  - [Oracle](#oracle)\n  - [Postgres](#postgres)\n  - [SQL](#sql)\n  - [SQL Lite](#sql-lite)\n\n- [OS](#os)\n  - [Linux](#linux)\n  - [Windows](#windows)\n- [Algorithms](#algorithms)\n- [Coding exercises](#coding-exercises)\n- [Comprehensive lists](#comprehensive-lists)\n- [Design patterns](#design-patterns)\n- [Data structures](#data-structures)\n- [Networks](#networks)\n- [Security](#security)\n- [Data Science](#data-science)\n\n## Programming Languages/Frameworks/Platforms\n\n### Android\n\n* [10 Android interview question answers for Freshers](http://www.careerride.com/android-interview-questions.aspx)\n* [14 Essential Android Interview Questions from top 3% developers company](http://www.toptal.com/android/interview-questions)\n* [50 android interview questions & answers](http://career.guru99.com/50-android-interview-questions-answers/).\n* [A couple of Android questions posted by Quora users](https://www.quora.com/What-are-good-job-interview-questions-for-an-Android-developer)\n* [A great list of Android interview questions covering all the aspects of this career](http://www.tutorialspoint.com/android/android_interview_questions.htm)\n* [Collection of Android and Java related questions and topics, including general developer questions, Java core, Data structures, Build Tools, Programming Paradigms, Core Android, Databases and etc](https://github.com/derekargueta/Android-Interview-Questions)\n* [Collection of Android and Java questions divided by experience](https://medium.com/@neteinstein/not-another-android-interviews-article-the-questions-3dedafa30bec)\n\n### AngularJS\n\n* [10 Essential AngularJS Interview Questions from top 3% developers company](http://www.toptal.com/angular-js/interview-questions)\n* [An AngularJS exam with questions from beginner to expert by @gdi2290 from @AngularClass](https://github.com/gdi2290/ngExam)\n* [29 AngularJS Interview Questions â€“ Can You Answer Them All? Great Article from Codementor](https://www.codementor.io/angularjs/tutorial/angularjs-interview-questions-sample-answers)\n* [AngularJS interview questions and answers for experienced developers](http://www.web-technology-experts-notes.in/2014/11/angularjs-interview-questions-and-answers-for-experienced.html)\n* [AngularJS Interview Questions which have been designed specially to get you acquainted with the nature of questions you may encounter during your interview for the subject of AngularJS](http://www.tutorialspoint.com/angularjs/angularjs_interview_questions.htm)\n* [This article discusses the top 50 Most occurred AngularJS interview question with answers](http://www.codeproject.com/Articles/891718/AngularJS-Interview-Questions-and-Answers)\n* [Top 25 Angularjs Interview Questions and Quiz](http://career.guru99.com/top-25-angular-js-interview-questions/)\n\n### BackboneJS\n\n* [8 Essential Backbonejs Interview Questions from top 3% developers company](http://www.toptal.com/backbone-js/interview-questions)\n* [Backbonejs Interview Questions And Answers from web technology experts notes](http://www.web-technology-experts-notes.in/2015/01/backbone-js-interview-questions-and-answers.html)\n* [Top 25 Backbone.js interview questions](http://career.guru99.com/top-25-backbone-js-interview-questions/)\n\n### C++\n\n* [1000+ Multiple Choice Questions & Answers in C++ with explanations](http://www.sanfoundry.com/cplusplus-interview-questions-answers/)\n* [200 C++ interview questions and answers](http://www.careerride.com/C++-Interview-questions-Answer.aspx)\n* [18 Essential C++ Interview Questions from top 3% developers company](http://www.toptal.com/c-plus-plus/interview-questions)\n* [C++ Interview Questions and Answers for Freshers and Experienced developers](http://a4academics.com/interview-questions/57-c-plus-plus/419-cpp-interview-questions-answers)\n* [C++ Interview Questions from GeekInterview](http://www.geekinterview.com/Interview-Questions/Languages/C-Plus-Plus)\n* [C++ Programming Q&A and quizzes from computer science portal for geeks](http://www.geeksforgeeks.org/c-plus-plus/)\n* [C++ Programming Questions and Answers related to such topics as OOPs concepts, Object and Classes, Functions, Constructors and Destructors, Inheritance and etc](http://www.indiabix.com/cpp-programming/questions-and-answers/)\n* [LeetCode Problems' Solutions written in C++](https://github.com/haoel/leetcode)\n* [25 Fundamental C++ Interview Questions](https://pangara.com/blog/cplusplus-interview-questions)\n\n### C\n\n* [165 C interview questions](http://placement.freshersworld.com/power-preparation/technical-interview-questions/C-programming-answers-21419)\n* [Basic C language technical frequently asked interview questions and answers It includes data structures, pointers interview questions and answers for experienced](http://www.cquestions.com/2010/10/c-interview-questions-and-answers.html)\n* [C Programming Interview Questions and Answers for such topics as Bits and Bytes, Preprocessors, Functions, Strings, Language basics and etc](http://www.indiabix.com/technical/c/)\n* [C Programming Interview Questions have been designed specially to get you acquainted with the nature of questions you may encounter during your interview for the subject of C Programming](http://www.tutorialspoint.com/cprogramming/cprogramming_interview_questions.htm)\n* [First set of commonly asked C programming interview questions from computer science portal for geeks](http://geeksquiz.com/commonly-asked-c-programming-interview-questions-set-1/)\n* [Second set of commonly asked C programming interview questions from computer science portal for geeks](http://geeksquiz.com/commonly-asked-c-programming-interview-questions-set-2/)\n\n### Câ™¯\n\n* [6 Essential C# Interview Question from top 3% developers company](http://www.toptal.com/c-sharp/interview-questions)\n* [C# interview questions from dotnetfunda.com](http://www.dotnetfunda.com/interviews/cat/6/csharp)\n* [Top 100 C# Interview Questions and Answers](http://a4academics.com/interview-questions/52-dot-net-interview-questions/417-c-oops-interview-questions-and-answers)\n* [Top 50 C# Interview Questions & Answers](http://career.guru99.com/top-50-c-sharp-interview-questions-answers/)\n\n### .NET\n\n* [300 ASPNET interview questions and answers](http://www.careerride.com/ASPNet-Questions.aspx)\n* [Great list of NET interview questions covering all the NET platform topics](http://www.indiabix.com/technical/dotnet/)\n* [NET Interview Questions and Answers for Beginners which consists of the most frequently asked questions in NET This list of 100+ questions and answers gauge your familiarity with the NET platform](http://www.dotnetcurry.com/dotnetinterview/70/dotnet-interview-questions-answers-beginners)\n* [Questions gathered by community of the StackOverflow](http://stackoverflow.com/questions/365489/questions-every-good-net-developer-should-be-able-to-answer)\n* [What Great NET Developers Ought To Know (More NET Interview Questions)](http://www.hanselman.com/blog/WhatGreatNETDevelopersOughtToKnowMoreNETInterviewQuestions.aspx)\n\n### Clojure\n\n* [Classic 'Fizz Buzz' interview question for Clojure developers](http://www.learningclojure.com/2014/05/fizz-buzz-interview-question.html)\n* [Clojure Interview Questions for experienced devs](http://ita2zguide.blogspot.com.by/p/cc.html)\n* [Coding exercises in Clojure, handy practice for technical interview questions](https://github.com/dpetrovics/coding-exercises)\n* [Experience and questions from Clojure developer interview collected by Reddit users](https://www.reddit.com/r/Clojure/comments/34qhha/clojure_coding_job_interview_experience/)\n* [Interview cake Clojure solutions](https://github.com/DerekCuevas/interview-cake-clj)\n\n### CSS\n\n* [25 helpful CSS interview questions and answers](http://www.skilledup.com/articles/25-css-interview-questions-answers)\n* [CSS interview questions and answers for freshers and experienced candidates Also there you can find CSS online practice tests to fight written tests and certification exams on CSS](http://www.careerride.com/Interview-Questions-CSS.aspx)\n* [Development hiring managers and potential interviewees may find there sample CSS proficiency interview Q&As and code snippets useful](http://www.techrepublic.com/blog/software-engineer/css-interview-questions-and-answers/)\n* [Interview Questions and Exercises About CSS](https://css-tricks.com/interview-questions-css/)\n* [Top 50 CSS(Cascading Style Sheet) Interview Questions covering the most of tricky CSS moments](http://career.guru99.com/top-50-csscascading-style-sheet-interview-questions/)\n* [CSS Questions and Answers](https://github.com/yangshun/tech-interview-handbook/blob/master/front-end/interview-questions.md#css-questions)\n\n### Django\n\n* [Some abstract interview questions for Python/Django developers](http://insights.dice.com/2014/04/30/interview-questions-pythondjango-developers/)\n* [Some Django basic interview questions to establish the basic level of the candidates](http://www.ilian.io/django-interview-questions/)\n* [Some Django/Python interview questions from Jaypal personal blog](http://blog.jayapal.in/2010/11/django-interview-question.html)\n* [Top 10 Django interview questions with their answers that you can encounter during the job interview for web developer](http://www.goodinterviewquestions.net/top-10-django-interview-questions-and-answers/)\n* [Django interview questions from f2finterview.com](http://www.f2finterview.com/web/Django/)\n* [Top 16 Django Interview Questions for both freshers and experienced developers](http://career.guru99.com/top-16-django-interview-questions/)\n\n### EmberJS\n\n* [8 Essential Emberjs Interview Questions from top 3% developers company](http://www.toptal.com/emberjs/interview-questions)\n* [Top 25 Emberjs Interview Questions for both freshers and experienced developers](http://career.guru99.com/top-25-ember-js-interview-questions/)\n\n### Erlang\n\n* [Top 22 Erlang Interview Questions for both freshers and experienced developers](http://career.guru99.com/top-22-erlang-interview-questions/)\n\n### Golang\n\n* [Solutions for Elements of Programming Interviews problems written in Golang](https://github.com/mrekucci/epi)\n* [Solutions for some basic coding interview tasks written in Go](https://github.com/efischer19/golang_ctci)\n* [Top 20 GO Programming Interview Questions for both freshers and experienced developers](http://career.guru99.com/top-20-go-programming-interview-questions/)\n\n### HTML\n\n* [10 Typical HTML Interview Exercises from SitePoint.com](http://www.sitepoint.com/10-typical-html-interview-exercises/)\n* [12 Essential HTML5 Interview Questions from top 3% developers company](http://www.toptal.com/html5/interview-questions)\n* [35 Helpful HTML & HTML5 Interview Questions & Answers](http://www.skilledup.com/articles/html-html5-interview-questions-answers)\n* [40 important HTML 5 Interview questions with answers](http://www.codeproject.com/Articles/702051/important-HTML-Interview-questions-with-answe)\n* [HTML interview questions and answers for freshers and experienced candidates Also find HTML online practice tests to fight written tests and certification exams on HTML](http://www.careerride.com/Interview-Questions-HTML.aspx)\n* [Top 50 HTML Interview Questions for both freshers and experienced developers](http://career.guru99.com/top-50-html-interview-questions/)\n* [Common HTML interview questions for freshers](http://www.javatpoint.com/html-interview-questions)\n* [HTML Questions and Answers](https://github.com/yangshun/tech-interview-handbook/blob/master/front-end/interview-questions.md#html-questions)\n\n### Ionic\n\n* [23 Beginner Level Ionic Framework Questions](http://www.codeandyou.com/p/ionic-interview-questions.html)\n* [11 Essential Ionic Interview Questions](https://www.toptal.com/ionic/interview-questions)\n\n### iOS\n\n* [12 Essential iOS Interview Questions from top 3% developers company](http://www.toptal.com/ios/interview-questions)\n* [20 iOS Developer Interview Questions and Answers for getting you ready for your interview](https://www.codementor.io/ios/tutorial/ios-interview-tips-questions-answers-objective-c)\n* [A small guide to help those looking to hire a developer or designer for iOS work While tailored for iOS, many questions could be used for Android developers or designers as well A great self-test if you're looking to keep current or practice for your own interview](https://github.com/CameronBanga/iOS-Developer-and-Designer-Interview-Questions)\n* [All you need to know about iOS technical interview including some tips for preparing, questions and some coding exercises](http://www.raywenderlich.com/53962/ios-interview-questions)\n* [Interview Questions for iOS and Mac Developers from the CEO of Black Pixel](https://blackpixel.com/writing/2013/04/interview-questions-for-ios-and-mac-developers-1.html)\n* [iOS Interview Questions and Answers including such topics as Development Basics, App states and multitasking, App states, Core app objects](http://www.geekinterview.com/Interview-Questions/iOS)\n* [iOS Interview Questions For Senior Developers](https://m.smartcloud.io/ios-interview-questions-for-senior-developers-in-2017-a94cc81c8205)\n* [50 iOS Interview Questions And Answers 1](https://medium.com/ios-os-x-development/ios-interview-questions-13840247a57a)\n* [50 iOS Interview Questions And Answers Part 2](https://medium.com/ios-os-x-development/50-ios-interview-questions-and-answers-part-2-45f952230b9f)\n* [50 iOS Interview Questions And Answers Part 3](https://medium.com/ios-os-x-development/50-ios-interview-questions-and-answers-part-3-3fad146b6c3d)\n* [50 iOS Interview Questions And Answers Part 4](https://medium.com/@duruldalkanat/50-ios-interview-questions-and-answers-part-4-6f26b26341a)\n* [10 iOS interview questions and answers](https://www.upwork.com/i/interview-questions/ios/)\n* [iOS Developer and Designer Interview Questions](https://github.com/9magnets/iOS-Developer-and-Designer-Interview-Questions#tech)\n* [IOS Interview Questions and Answers](http://www.thecrazyprogrammer.com/2015/11/ios-interview-questions-and-answers.html)\n\n### Java\n\n* [115 Java Interview Questions and Answers â€“ The ULTIMATE List](http://www.javacodegeeks.com/2014/04/java-interview-questions-and-answers.html)\n* [37 Java Interview Questions to Practice With from Codementor](https://www.codementor.io/java/tutorial/java-interview-sample-questions-answers)\n* [20 Essential Java Interview Questions](http://www.toptal.com/java/interview-questions)\n* [A collection of Java interview questions and answers to them The questions were gathered all around the Internet The answers are partly written by the commiters, partly copy-pasted from all possible sources](https://github.com/svozniuk/java-interviews)\n* [Data Structures and Algorithms in Java which can be useful in interview process](https://github.com/donbeave/interview)\n* [Java Interview Questions: How to crack the TOP 15 questions](https://blog.udemy.com/java-interview-questions/)\n* [There is the list of 201 core java interview questions The answers of the core java interview questions are short and to the point The core java interview questions are categorized in Basics of java interview questions, OOPs interview questions, String Handling interview questions, Multithreading interview questions, collection interview questions, JDBC interview questions etc](http://www.javatpoint.com/corejava-interview-questions)\n* [Top 10 Tricky Java interview questions and Answers](http://java67.blogspot.com.by/2012/09/top-10-tricky-java-interview-questions-answers.html)\n* [Top 25 Most Frequently Asked Interview Core Java Interview Questions And Answers](http://javahungry.blogspot.com/2013/06/top-25-most-frequently-asked-core-java.html)\n* [Top 40 Core Java Interview Questions Answers from Telephonic Round](http://java67.blogspot.sg/2015/03/top-40-core-java-interview-questions-answers-telephonic-round.html)\n* [Interview Cake Java Interview Questions](https://www.interviewcake.com/java-interview-questions)\n\n### JavaScript\n\n* [10 Interview Questions Every JavaScript Developer Should Know](https://medium.com/javascript-scene/10-interview-questions-every-javascript-developer-should-know-6fa6bdf5ad95)\n* [21 Essential JavaScript Interview Questions from best mentors all over the world](https://www.codementor.io/javascript/tutorial/21-essential-javascript-tech-interview-practice-questions-answers)\n* [25 Essential JavaScript Interview Questions from top 3% developers company](http://www.toptal.com/javascript/interview-questions)\n* [5 More JavaScript Interview Exercises](http://www.sitepoint.com/5-javascript-interview-exercises/)\n* [5 Typical JavaScript Interview Exercises](http://www.sitepoint.com/5-typical-javascript-interview-exercises/)\n* [Development hiring managers and potential interviewees may find these sample JavaScript proficiency interview Q&As and code snippets useful](http://www.techrepublic.com/blog/software-engineer/javascript-interview-questions-and-answers/)\n* [123 Essential JavaScript Interview Question](https://github.com/nishant8BITS/123-Essential-JavaScript-Interview-Question)\n* [JavaScript Interview Questions have been designed specially to get you acquainted with the nature of questions you may encounter during your interview for the subject of JavaScript](http://www.tutorialspoint.com/javascript/javascript_interview_questions.htm)\n* [JS: Basics and Tricky Questions](http://www.thatjsdude.com/interview/js2.html)\n* [JS: Interview Algorithm](http://thatjsdude.com/interview/js1.html)\n* [Some basic javascript coding challenges and interview questions](https://github.com/kolodny/exercises)\n* [Some JavaScript interview exercises](https://github.com/csvenja/javascript-exercises)\n* [Ten Questions I've Been Asked, Most More Than Once, Over Six Technical JavaScript / Front-End Engineer Job Interviews.](https://www.reddit.com/r/javascript/comments/3rb88w/ten_questions_ive_been_asked_most_more_than_once)\n* [Top 85 JavaScript Interview Questions](http://career.guru99.com/top-85-javascript-interview-questions/)\n* [Interview Cake JavaScript Interview Questions](https://www.interviewcake.com/javascript-interview-questions)\n* [The Best Frontend JavaScript Interview Questions (written by a Frontend Engineer)](https://performancejs.com/post/hde6d32/The-Best-Frontend-JavaScript-Interview-Questions-(written-by-a-Frontend-Engineer))\n* [JavaScript Questions and Answers](https://github.com/yangshun/tech-interview-handbook/blob/master/front-end/interview-questions.md#js-questions)\n* [10 JavaScript Concepts You Need to Know for Interviews](https://dev.to/arnavaggarwal/10-javascript-concepts-you-need-to-know-for-interviews)\n\n\n### Front-end build tools\n\n* [Webpack interview questions & answers](https://github.com/styopdev/webpack-interview-questions)\n* [Gulp js interview questions](https://www.codeproject.com/Articles/1065184/Latest-Gulp-js-interview-questions)\n* [Grunt js interview questions for beginners](http://www.talkingdotnet.com/grunt-js-interview-questions/)\n* [Grunt js interview questions](https://mindmajix.com/grunt-interview-questions)\n\n### KnockoutJS\n\n* [15 interview questions from CodeSample.com](http://www.code-sample.com/2014/01/knockout-js-interview-questions-and.html)\n* [20 questions you might be asked about KnockoutJS in an interview for both freshers and experienced developers](http://www.codeproject.com/Articles/987899/KnockoutJS-interview-questions)\n\n### Less\n\n* [Top 25 LESS Interview Questions](http://career.guru99.com/top-25-less-interview-questions/)\n\n### Lisp\n\n* [10 LISP Questions & Answers](http://www.sanfoundry.com/lisp-mcqs-class/)\n* [Top 18 Lisp Interview Questions from Career Guru](http://career.guru99.com/top-18-lisp-interview-questions/)\n\n### NodeJS\n\n* [7 Essential Nodejs Interview Questions from top 3% developers company](http://www.toptal.com/nodejs/interview-questions)\n* [Node.js Interview Questions & Answers from LazyQuestion.com](http://www.lazyquestion.com/interview-questions-and-answer/nodejs)\n* [Node.JS Interview Questions have been designed specially to get you acquainted with the nature of questions you may encounter during your interview for the subject of Node.JS](http://www.tutorialspoint.com/nodejs/nodejs_interview_questions.htm)\n* [There are two sides of the table: you either want to hire Nodejs developers or you want to get hired as a Nodejs developer This list helps you navigate a bit in this space, giving you some questions to ask, and a list of questions you should know the answer to](https://blog.risingstack.com/node-js-interview-questions/)\n* [Top 25 Nodejs Interview Questions & Answers from Career Guru](http://career.guru99.com/top-25-interview-questions-on-node-js/)\n* [Top 30 Node.Js Interview Questions With Answers](http://www.techbeamers.com/top-30-node-js-interview-questions-answers/)\n\n### Objective-C\n\n* [Interview Qs for Objective-C and Swift](http://insights.dice.com/2015/07/21/interview-qs-objective-c-swift/)\n* [iOS/ObjC Interview Questions](http://andras.palfi.hu/iosobjc-interview-questions/)\n\n### PHP\n\n* [100 PHP interview questions and answers from CareerRide.com](http://www.careerride.com/PHP-Interview-Questions.aspx)\n* [14 Essential PHP Interview Questions from top 3% developers company](http://www.toptal.com/php/interview-questions)\n* [20 Common PHP Job Interview Questions and Answers](http://www.woodstitch.com/resources/php-interview-questions.php)\n* [Basic PHP interview questions](https://github.com/developerquestions/php-questions)\n* [PHP interview questions and answers for freshers](http://phpinterviewquestions.co.in/)\n* [Top 100 PHP Interview Questions & Answers from CareerGuru](http://career.guru99.com/top-100-php-interview-questions-answers/)\n* [25 PHP Interview Questions](https://www.codementor.io/php/tutorial/php-interview-questions-sample-answers)\n\n### Python\n\n* [50 Python interview questions and answers](http://www.careerride.com/python-interview-questions.aspx)\n* [8 Essential Python Interview Questions from top 3% developers company](http://www.toptal.com/python/interview-questions)\n* [A listing of questions that could potentially be asked for a python job listing](https://github.com/sigmavirus24/python-interview-questions)\n* [Interview Questions for both beginners and experts](http://www.bogotobogo.com/python/python_interview_questions.php)\n* [Interview Cake Python Interview Questions](https://www.interviewcake.com/python-interview-questions)\n* [Python Frequently Asked Questions (Programming)](https://docs.python.org/2/faq/programming.html)\n* [Python interview questions collected by Reddit users](https://www.reddit.com/r/Python/comments/1knw7z/python_interview_questions)\n* [Python Interview Questions from questionscompiled](http://www.questionscompiled.com/python-interview-questions.html)\n* [Top 25 Python Interview Questions from Career Guru](http://career.guru99.com/top-25-python-interview-questions/)\n* [Python Interview 10 questions from Corey Schafer](https://www.youtube.com/watch?v=DEwgZNC-KyE)\n\n### Ruby on Rails\n\n* [20 Ruby on Rails interview questions and answers from CareerRide.com](http://www.careerride.com/ruby-on-rails-interview-questions.aspx)\n* [8 Essential Ruby on Rails Interview Questions from top 3% developers company](http://www.toptal.com/ruby-on-rails/interview-questions)\n* [A list of common questions with answers ask during interview of ruby on rails job](https://github.com/rishiip/ruby-on-rails-interview-questions)\n* [Ruby And Ruby On Rails interview Q&A](http://anilpunjabi.tumblr.com/post/25948339235/ruby-and-rails-interview-questions-and-answers)\n* [Some of the most frequently asked Ruby on Rails questions and how to answer them confidently](https://srikantmahapatra.wordpress.com/2013/11/07/ruby-on-rails-interview-questions-and-answers/)\n* [11 Ruby on Rails Interview Practice Questions](https://www.codementor.io/ruby-on-rails/tutorial/ruby-on-rails-interview-questions)\n* [Top 53 Ruby on Rails Interview Questions & Answers](https://career.guru99.com/top-34-ruby-on-rail-interview-questions/)\n* [10 Ruby on Rails interview questions and answers](https://www.upwork.com/i/interview-questions/ruby-on-rails/)\n\n### ReactJS\n\n* [Reddit users share their expectations from ReactJS interview](https://www.reddit.com/r/reactjs/comments/3m5equ/react_what_interview_questions_to_expect/)\n* [This is a first in the series of interview questions related with ReactJS](http://interview-questions-247.appspot.com/reactjs-interview-questions-set-1)\n* [This quiz intends to test your understanding around ReactJS fundamentals (Set 3)](http://interview-questions-247.appspot.com/reactjs-interview-questions-set-3)\n* [This quiz intends to test your understanding around ReactJS fundamentals](http://interview-questions-247.appspot.com/reactjs-interview-questions-set-2)\n* [5 Essential React.js Interview Questions](https://www.codementor.io/reactjs/tutorial/5-essential-reactjs-interview-questions)\n* [React Interview Questions](https://tylermcginnis.com/react-interview-questions/)\n\n### Ruby\n\n* [11 Essential Ruby Interview Questions from top 3% developers company](http://www.toptal.com/ruby/interview-questions)\n* [15 Questions to Ask During a Ruby Interview](https://gist.github.com/ryansobol/5252653)\n* [A list of questions about Ruby programming you can use to quiz yourself](https://github.com/undr/ruby-trivia)\n* [The Art of Ruby Technical Interview](http://technology.customink.com/blog/2015/11/23/the-art-of-ruby-technical-interviews/)\n* [Interview Cake Ruby Interview Questions](https://www.interviewcake.com/ruby-interview-questions)\n* [Frequently Asked Ruby Interview Questions](https://www.javatpoint.com/ruby-interview-questions)\n\n### Sass\n\n* [Top 17 Sass Interview Questions from Career Guru](http://career.guru99.com/top-17-sass-interview-questions/)\n\n### Scala\n\n* [4 Interview Questions for Scala Developers](http://insights.dice.com/2014/09/12/4-interview-questions-scala-developers/)\n* [A list of Frequently Asked Questions and their answers, sorted by category](http://www.scala-lang.org/old/faq)\n* [A list of helpful Scala related questions you can use to interview potential candidates](https://github.com/Jarlakxen/Scala-Interview-Questions)\n* [How Scala Developers Are Being Interviewed](http://programmers.stackexchange.com/questions/58145/how-scala-developers-are-being-interviewed)\n* [Scala Interview Questions/Answers including Language Questions, Functional Programming Questions, Reactive Programming Questions](https://github.com/peterarsentev/Scala-Interview-Questions-Answers)\n* [Top 25 Scala Interview Questions & Answers from top 3% developers company](http://career.guru99.com/top-25-interview-questions-on-scala/)\n\n### SharePoint\n\n* [Sharepoint Interview Question For Developer](http://www.rajeshg.me/2013/05/sharepoint-developer-2010-interview.html)\n\n### Shell\n\n* [Top 50 Shell Scripting Interview Questions from Career Guru](http://career.guru99.com/shell-scripting-interview-questions/)\n\n### Swift\n\n* [5 Swift questions for your iOS job interview](http://www.skilledup.com/articles/5-swift-questions-ios-job-interview)\n* [9 Essential Swift Interview Questions from top 3% developers company](http://www.toptal.com/swift/interview-questions)\n* [Get prepared for your next iOS job interview by studying high quality LeetCode solutions in Swift 2.1](https://github.com/diwu/LeetCode-Solutions-in-Swift)\n* [Swift Interview Questions and Answers for both freshers and beginners](http://www.raywenderlich.com/110982/swift-interview-questions-answers)\n* [Swift Programming Language Interview Questions And Answers from mycodetips.com](http://mycodetips.com/swift-ios/swift-programming-language-interview-questions-answers-987.html)\n* [Your top 10 Swift questions answered](http://blog.udacity.com/2014/11/your-top-10-swift-questions-answered.html)\n\n### Wordpress\n* [Top 45 Wordpress interview questions](https://pangara.com/blog/45-wordpress-interview-questions-and-answers)\n\n## Database technologies\n\n\n### Cassandra\n\n* [Top 23 Cassandra Interview Questions from Career Guru](http://career.guru99.com/top-23-cassandra-interview-questions/)\n\n### Microsoft Access\n\n* [Top 16 Microsoft Access Database Interview Questions from Career Guru](http://career.guru99.com/top-16-ms-access-database-interview-questions/)\n\n### MongoDB\n\n* [28 MongoDB NoSQL Database Interview Questions and Answers](http://theprofessionalspoint.blogspot.com.by/2014/01/28-mongodb-nosql-database-interview.html)\n* [MongoDB frequently Asked Questions by expert members with experience in MongoDB These questions and answers will help you strengthen your technical skills, prepare for the new job test and quickly revise the concepts](http://www.globalguideline.com/interview_questions/Questions.php?sc=MongoDB](http://www.globalguideline.com/interview_questions/Questions.php?sc=MongoDB))\n* [MongoDB Interview Questions from JavaTPointcom](http://www.javatpoint.com/mongodb-interview-questions)\n* [MongoDB Interview Questions that have been designed specially to get you acquainted with the nature of questions you may encounter during your interview for the subject of MongoDB](http://www.tutorialspoint.com/mongodb/mongodb_interview_questions.htm)\n* [Top 20 MongoDB interview questions from Career Guru](http://career.guru99.com/top-20-mongodb-interview-questions/)\n\n### MySQL\n\n* [10 MySQL Database Interview Questions for Beginners and Intermediates](http://www.tecmint.com/10-mysql-database-interview-questions-for-beginners-and-intermediates/)\n* [100 MySQL interview questions](http://www.careerride.com/MySQL-Interview-Questions.aspx)\n* [15 Basic MySQL Interview Questions for Database Administrators](http://www.tecmint.com/basic-mysql-interview-questions-for-database-administrators/)\n* [28 MySQL interview questions from JavaTPoint.com](http://www.javatpoint.com/mysql-interview-questions)\n* [40 Basic MySQL Interview Questions with Answers](http://www.testingbrain.com/interview/mysql-interview-questions.html)\n* [Top 50 MySQL Interview Questions & Answers from Career Guru](http://career.guru99.com/top-50-mysql-interview-questions-answers/)\n\n### Neo4j\n\n* [Top 20 Neo4j Interview Questions from Career Guru](http://career.guru99.com/top-20-ne04j-interview-questions/)\n\n### Oracle\n\n* [General Oracle Interview Questions & Answers](http://www.coolinterview.com/type.asp?iType=57)\n\n### Postgres\n\n* [13 PostgreSQL Interview Q&A](http://www.dotnetfunda.com/interviews/cat/208/postgresql)\n* [Frequently Asked Basic PostgreSQL Interview Questions and Answers](http://nazafbtemplate.blogspot.com.by/2014/06/frequently-asked-basic-postgresql.html)\n* [PostgreSQL Interview Preparation Guide](http://www.globalguideline.com/interview_questions/Questions.php?sc=postgresqk_database_](http://www.globalguideline.com/interview_questions/Questions.php?sc=postgresqk_database_))\n* [PostgreSQL Interview Q&A from CoolInterview.com](http://www.coolinterview.com/type.asp?iType=411)\n\n### SQL\n\n* [10 Frequently asked SQL Query Interview Questions](http://java67.blogspot.com.by/2013/04/10-frequently-asked-sql-query-interview-questions-answers-database.html)\n* [18 Essential SQL Interview Questions from top 3% developers company](http://www.toptal.com/sql/interview-questions)\n* [Common Interview Questions and Answers](http://www.indiabix.com/technical/sql-server-common-questions/)\n* [General Interview Questions and Answers](http://www.indiabix.com/technical/sql-server-general-questions/)\n* [Schema, Questions & Solutions for SQL Exercising](https://github.com/XD-DENG/SQL-exercise)\n* [SQL Interview Questions that have been designed specially to get you acquainted with the nature of questions you may encounter during your interview for the subject of SQL](http://www.tutorialspoint.com/sql/sql_interview_questions.htm)\n* [Top 20 SQL Interview Questions with Answers](http://dwbi.org/database/sql/72-top-20-sql-interview-questions-with-answers)\n\n### SQL Lite\n\n* [Top 20 SQL LITE  Interview Questions from Career Guru](http://career.guru99.com/top-20-sql-lite-interview-questions/)\n\n## OS\n\n### Linux\n\n* [10 Job Interview Questions for Linux System Administrators from Linux.com](https://www.linux.com/news/featured-blogs/200-libby-clark/842913-10-job-interview-questions-for-linux-sysadmins)\n* [10 Useful Random Linux Interview Questions and Answers](http://www.tecmint.com/useful-random-linux-interview-questions-and-answers/)\n* [11 Basic Linux Interview Questions and Answers](http://www.tecmint.com/basic-linux-interview-questions-and-answers/)\n* [11 Essential Linux Interview Questions from top 3% developers company](http://www.toptal.com/linux/interview-questions)\n* [Some basic Linux questions from ComputerNetworkingNotes.com](http://computernetworkingnotes.com/rhce-interview-questions/linux-interview-questions-answers.html)\n* [Top 30 Linux System Admin Interview Questions & Answers](http://www.linuxtechi.com/experience-linux-admin-interview-questions/)\n* [Top 50 Linux Interview Questions from Career Guru](http://career.guru99.com/top-50-linux-interview-questions/)\n* [Linux System Administrator/DevOps Interview Questions](https://github.com/chassing/linux-sysadmin-interview-questions)\n\n### Windows\n\n* [Top 10 Interview Questions for Windows Administrators](http://www.brentozar.com/archive/2009/07/top-10-interview-questions-for-windows-sysadmins/)\n* [Top 22 Windows Server Interview Questions from Career Guru](http://career.guru99.com/top-22-windows-server-interview-questions/)\n* [Windows Admin Interview Questions & Answers](http://www.01world.in/p/windows.html)\n\n## Algorithms\n\n* [A great list of Java interview questions](http://java2novice.com/java-interview-programs/)\n* [Algorithms playground for common interview questions written in Ruby](https://github.com/sagivo/algorithms)\n* [EKAlgorithms contains some well known CS algorithms & data structures](https://github.com/EvgenyKarkan/EKAlgorithms)\n* [Five programming problems every Software Engineer should be able to solve in less than 1 hour](http://www.shiftedup.com/2015/05/07/five-programming-problems-every-software-engineer-should-be-able-to-solve-in-less-than-1-hour)\n* [Top 10 Algorithms for Coding Interview](http://www.programcreek.com/2012/11/top-10-algorithms-for-coding-interview/)\n* [Top 15 Data Structures and Algorithm Interview Questions for Java programmer](http://javarevisited.blogspot.com.by/2013/03/top-15-data-structures-algorithm-interview-questions-answers-java-programming.html)\n* [Top Algorithms Questions by Topics](https://github.com/yangshun/tech-interview-handbook/blob/master/algorithms/README.md)\n\n## Coding exercises\n\n* [Common interview questions and puzzles solved in a number of languages](https://github.com/mre/the-coding-interview)\n* [Interactive, test-driven Python coding challenges (algorithms and data structures) typically found in coding interviews or coding competitions](https://github.com/donnemartin/interactive-coding-challenges)\n* [Interview questions solved in python](https://github.com/roseperrone/interview-questions)\n\n## Comprehensive lists\n\n* [A list of helpful front-end related questions you can use to interview potential candidates, test yourself or completely ignore](https://github.com/h5bp/Front-end-Developer-Interview-Questions)\n* [Front End Developer Interview Questions](http://www.aperfectmix.com/free_web_design/front-end-interview-questions.html)\n* [Answers to Front End Developer Interview Questions](https://github.com/yangshun/tech-interview-handbook/blob/master/front-end/interview-questions.md)\n* [Some simple questions to interview potential backend candidates](https://github.com/starandtina/backend-interview-questions)\n* [An Annotated List of Frontend Developer Technical Interview Questions](https://www.recruityourninja.com/technical-interview-questions-frontend-candidates/)\n* [An Annotated List of Backend Developer Technical Interview Questions](https://www.recruityourninja.com/technical-interview-questions-backend-candidates/)\n* [An Annotated List of DevOps Technical Interview Questions](https://www.recruityourninja.com/technical-interview-questions-devops-candidates/)\n\n## Design Patterns\n* [Design Pattern Interview Questions that have been designed specially to get you acquainted with the nature of questions you may encounter during your interview for the subject of Design Pattern](http://www.tutorialspoint.com/design_pattern/design_pattern_interview_questions.htm)\n* [Design Patterns for Humansâ„¢ - An ultra-simplified explanation](https://github.com/kamranahmedse/design-patterns-for-humans)\n* [Design patterns implemented in Java](https://github.com/iluwatar/java-design-patterns)\n\n## Data structures\n\n* [Top 15 Data Structures and Algorithm Interview Questions for Java programmer](http://javarevisited.blogspot.com.by/2013/03/top-15-data-structures-algorithm-interview-questions-answers-java-programming.html)\n* [Top 50 Data Structure Interview Questions from Career Guru](http://career.guru99.com/top-50-data-structure-interview-questions/)\n\n## Networks\n\n* [Top 100 Networking Interview Questions & Answers from Career Guru](http://career.guru99.com/top-100-networking-interview-questions-answers/)\n\n## Security\n\n* [101 IT Security Interview Questions](http://careers.simplicable.com/careers/new/101-IT-security-interview-questions)\n* [How to prepare for an information security job interview?](http://searchsecurity.techtarget.com/tip/How-to-prepare-for-an-information-security-job-interview)\n* [Information Security Interview Questions from Daniel Miessler](https://danielmiessler.com/study/infosec_interview_questions/)\n* [Top 50 Information Security Interview Questions for freshers and experts](http://resources.infosecinstitute.com/top-50-information-security-interview-questions/)\n\n## Data Science\n* [Data Science Interview Questions for Top Tech Companies](https://www.dezyre.com/article/-data-science-interview-questions-for-top-tech-companies/189)\n* [66 Job Interview Questions for Data Scientists](http://www.datasciencecentral.com/profiles/blogs/66-job-interview-questions-for-data-scientists)\n* [An Annotated List of Data Scientist Technical Interview Questions](https://www.recruityourninja.com/technical-interview-questions-data-scientist/)\n\n### License\n\n[![CC0](https://i.creativecommons.org/p/zero/1.0/88x31.png)](https://creativecommons.org/publicdomain/zero/1.0/)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "onebirdrocks--ebook-mcp": {
      "owner": "onebirdrocks",
      "name": "ebook-mcp",
      "url": "https://github.com/onebirdrocks/ebook-mcp",
      "imageUrl": "https://github.com/onebirdrocks.png",
      "description": "Enables natural language interactions with digital books in EPUB and PDF formats, facilitating smart library management and enhancing the learning experience through AI-powered conversations.",
      "stars": 111,
      "forks": 20,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-03T19:44:43Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/onebirdrocks-ebook-mcp-badge.png)](https://mseep.ai/app/onebirdrocks-ebook-mcp)\n\n# Ebook-MCP\n\n<img src=\"logo.png\" alt=\"ebook-mcp logo\" width=\"132\" height=\"132\">\n\n\n[English](https://github.com/onebirdrocks/ebook-mcp/blob/main/README.md) | [ä¸­æ–‡](https://github.com/onebirdrocks/ebook-mcp/blob/main/README-CN.md) | [æ—¥æœ¬èª](https://github.com/onebirdrocks/ebook-mcp/blob/main/README-JP.md) | [í•œêµ­ì–´](https://github.com/onebirdrocks/ebook-mcp/blob/main/README-KR.md) | [FranÃ§ais](https://github.com/onebirdrocks/ebook-mcp/blob/main/README-FR.md) | [Deutsch](https://github.com/onebirdrocks/ebook-mcp/blob/main/README-DE.md) \n\nEbook-MCP is a powerful Model Context Protocol (MCP) server for processing electronic books. Built on the [Model Context Protocol](https://github.com/modelcontextprotocol), it provides a set of standardized APIs for seamless integration between LLM applications and e-book processing capabilities. Currently supports EPUB and PDF formats.\n\n\n## Use Cases & Value\n\nEbook-MCP transforms how you interact with your digital books by enabling natural language conversations with your reading materials. It seamlessly integrates with modern AI-powered IDEs like Cursor and Claude, allowing you to:\n\n- **Smart Library Management**: Simply ask \"Show me all EPUB files in my downloads folder\" or \"Find books about GenAI in my library\"\n- **Interactive Reading Experience**: Have natural conversations about your books:\n  - \"Give me a brief introduction to 'LLM Engineer Handbook'\"\n  - \"What's covered in Chapter 3?\"\n  - \"Summarize the key points about RAG from this book\"\n- **Active Learning Support**: Enhance your learning through AI-powered interactions:\n  - \"Create a quiz based on the RAG concepts from Chapter 5\"\n  - \"Explain the differences between the architectures discussed in this chapter\"\n  - \"Give me practical exercises based on the concepts in this section\"\n- **Content Navigation**: Easily navigate through your books with natural language queries:\n  - \"Find all sections discussing prompt engineering\"\n  - \"Show me the chapters about fine-tuning\"\n  - \"Take me to the part about vector databases\"\n\nBy bridging the gap between traditional e-books and AI capabilities, Ebook-MCP helps readers extract more value from their digital library through intuitive, conversation-based interactions.\n\nQuick demo - Run with DeepSeek (Please check all the examples with Claude/OpenAI under mcp-client-example folder) \n```\nQuery:Please check all the epub books in my download folder. user id is onebird.\n......\n\nQuery: Can you ask me a few questions to test my understanding of this book?\n\n\nAnswer: Sure! Here are 5 questions about Elon Musk by Walter Isaacson to test your understanding of the book. Please answer based on your knowledge â€” Iâ€™ll give feedback and add details after each response.\n\nQuestion 1:\nHow did Muskâ€™s childhood and family background shape his personality and career later in life?\n(Hint: His relationship with his father, growing up in South Africa, etc.)\n\nQuestion 2:\nZip2 and X.com (later PayPal) were Muskâ€™s early startups. What problems did they solve? How did Musk eventually exit from these companies?\n(Hint: Zip2â€™s business model, X.comâ€™s merger with Confinity, etc.)\n\nQuestion 3:\nIn 2008, both SpaceX and Tesla were on the verge of bankruptcy. How did Musk save these two companies?\n(Hint: Falcon 1â€™s fourth launch, NASA contract, Teslaâ€™s last-minute rescue, etc.)\n\nQuestion 4:\nWhat controversies surround Muskâ€™s management style? What specific incidents in the book illustrate his â€œhardcoreâ€ or â€œextremeâ€ work culture?\n(Hint: Fremont factoryâ€™s â€œproduction hell,â€ Twitter layoffs, etc.)\n\nQuestion 5:\nWhat is Muskâ€™s attitude toward Artificial Intelligence (AI)? Why did he simultaneously support both OpenAI and Neuralink, which seem to have conflicting goals?\n(Hint: AI as an existential threat, brain-machine interface vision, etc.)\n\nPlease answer each question. Iâ€™ll provide feedback and additional details or correct any misunderstandings!\n(If a question isnâ€™t clear, feel free to ask me.)\n\nQuery:\nQuestion 1: His fatherâ€™s abusive attitude made him less empathetic towards others.\nQuestion 2: Zip2 solved the problem of electronic maps and online yellow pages. X.com solved online payments.\nQuestion 3: He secured a contract with NASA. Tesla solved its production problems by building a factory in China.\nQuestion 4: I donâ€™t know. Please answer for me.\nQuestion 5: He believes open-source technology is necessary to ensure AI is safe and open.\n\nAnswer: Your answers have captured some key points from the book. Let me add details, correct some inaccuracies, and provide further background for Questions 4 and 5:\n\nQuestion 1 â€” Correction & Supplement\nInfluence of His Father:\nMusk's father, Errol, was indeed extremely harsh â€” for example, forcing young Elon to kneel and count grains of rice for hours. The book emphasizes that this emotional desensitization shaped Musk into an extremely goal-oriented person â€” indifferent to othersâ€™ suffering but obsessively committed to his goals.\n\nReverse Impact:\nItâ€™s not that Musk is incapable of empathy â€” itâ€™s selective. For instance, he may treat employees coldly but personally study medical equipment for his son Xâ€™s health issues.\n\nQuestion 2 â€” Correction & Supplement\nZip2:\nEssentially an online Yellow Pages + map navigation service (helping newspapers go online). Musk wrote much of the early code himself and slept in the office. Eventually, Compaq acquired Zip2 for $307 million (Musk received $22 million).\n\nX.com:\nNot just online payments â€” it was Muskâ€™s attempt to create a comprehensive financial platform (aiming to replace banks). Later merged with Confinity (the precursor of PayPal). Musk was ousted due to internal conflicts, but when eBay acquired PayPal, Musk earned $180 million.\n(Note: Musk later bought back the domain X.com â€” itâ€™s now Twitterâ€™s parent company name).\n\nQuestion 3 â€” Correction & Supplement\nSpaceX:\nIn 2008, Falcon 1 succeeded on its fourth launch (after three failures drained their funds). Right after that, SpaceX secured a $1.6 billion NASA contract for cargo resupply â€” a lifeline for the company.\n\nTesla:\nIn 2008, Tesla survived through a $50 million investment from Daimler and a loan from the U.S. Department of Energy.\nBuilding the Gigafactory in China (2019) came much later. In the early years, survival depended on the launch of Model S (2012) and Muskâ€™s personal gamble â€” selling all his real estate to fund Tesla.\n\nQuestion 4 â€” Explanation: Controversy Around His Management Style\nâ€œHardcoreâ€ Culture:\n\nAt SpaceX/Tesla: Musk demanded employees work 80+ hours per week, even sleeping at the factory. (\"If youâ€™re not here, your replacement is.\")\n\nAfter acquiring Twitter: He immediately laid off 75% of staff and asked the remaining employees to sign a \"hardcore commitment\" â€” agreeing to long hours and high-intensity output.\n\nExtreme Cases:\n\nAt the Fremont Factory: During the \"production hell\" of the Model 3, Musk slept on the production line and once yelled at employees calling them \"worse than dogs\" (he later apologized).\n\nFiring Executives: Musk once fired a senior Tesla executive on the spot because the font size in their PowerPoint presentation wasnâ€™t big enough.\n\nQuestion 5 â€” Correction & Supplement\nAI Threat Theory:\nMusk believes that AI could destroy humanity (\"more dangerous than nuclear weapons\"). Therefore:\n\nOpenAI: He initially supported it to promote safe, open-source AI (but left later due to disputes over control).\n\nNeuralink: He aims to use brain-machine interfaces to merge humans with AI â€” to prevent humans from being left behind.\n\nContradictions:\nWhile warning about AI risks, Musk is simultaneously pushing for Full Self-Driving (FSD) technology at Tesla and has founded xAI to research Artificial General Intelligence (AGI).\n\nOverall Evaluation:\nâœ… You have captured the key events accurately, but the details need to be strengthened (such as timelines and specific figures).\nğŸ” Recommended areas for further study: Musk's multi-threaded management style (running five companies simultaneously) and his skill in media manipulation (governing through Twitter).\n```\n\n## Features\n\n### EPUB Support\n- Extract metadata (title, author, publication date, etc.)\n- Extract table of contents\n- Extract chapter content (with Markdown output)\n- Batch process EPUB files\n\n### PDF Support\n- Extract metadata (title, author, creation date, etc.)\n- Extract table of contents\n- Extract content by page number\n- Extract content by chapter title\n- Markdown output support\n- Batch process PDF files\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/yourusername/ebook-mcp.git\ncd ebook-mcp\n```\n\n2. Install dependencies using `uv`:\n```bash\nuv pip install -e .\n```\n\n## Usage\n\n### Starting the MCP Server in development mode\n\nRun the server in development mode:\n```bash\nuv run mcp dev src/ebook_mcp/main.py\n```\n\n\nYou can visit http://localhost:5173/ for testing & debugging purpose \nYou can also install the inspector for the test.\n```\nnpx @modelcontextprotocol/inspector uv --directory . run src/ebook_mcp/main.py\n```\n\n### Starting the MCP Server in Prod mode\n\nRun the server:\n```bash\nuv run src/ebook_mcp/main.py\n```\n\n\n#### Configure the MCP in Cursor\n\nAdd the following configuration in Cursor\n```bash\n\"ebook-mcp\":{\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/Users/onebird/github/ebook-mcp/src/ebook_mcp/\",\n                \"run\",\n                \"main.py\"\n            ]\n        }\n```\n\n\n\n\n### EPUB Processing Examples\n\n```python\n# Get all EPUB files in a directory\nepub_files = get_all_epub_files(\"/path/to/books\")\n\n# Get EPUB metadata\nmetadata = get_metadata(\"/path/to/book.epub\")\n\n# Get table of contents\ntoc = get_toc(\"/path/to/book.epub\")\n\n# Get specific chapter content (in Markdown format)\nchapter_content = get_chapter_markdown(\"/path/to/book.epub\", \"chapter_id\")\n```\n\n### PDF Processing Examples\n\n```python\n# Get all PDF files in a directory\npdf_files = get_all_pdf_files(\"/path/to/books\")\n\n# Get PDF metadata\nmetadata = get_pdf_metadata(\"/path/to/book.pdf\")\n\n# Get table of contents\ntoc = get_pdf_toc(\"/path/to/book.pdf\")\n\n# Get specific page content\npage_text = get_pdf_page_text(\"/path/to/book.pdf\", 1)\npage_markdown = get_pdf_page_markdown(\"/path/to/book.pdf\", 1)\n\n# Get specific chapter content\nchapter_content, page_numbers = get_pdf_chapter_content(\"/path/to/book.pdf\", \"Chapter 1\")\n```\n\n## API Reference\n\n### EPUB APIs\n\n#### `get_all_epub_files(path: str) -> List[str]`\nGet all EPUB files in the specified directory.\n\n#### `get_metadata(epub_path: str) -> Dict[str, Union[str, List[str]]]`\nGet metadata from an EPUB file.\n\n#### `get_toc(epub_path: str) -> List[Tuple[str, str]]`\nGet table of contents from an EPUB file.\n\n#### `get_chapter_markdown(epub_path: str, chapter_id: str) -> str`\nGet chapter content in Markdown format.\n\n### PDF APIs\n\n#### `get_all_pdf_files(path: str) -> List[str]`\nGet all PDF files in the specified directory.\n\n#### `get_pdf_metadata(pdf_path: str) -> Dict[str, Union[str, List[str]]]`\nGet metadata from a PDF file.\n\n#### `get_pdf_toc(pdf_path: str) -> List[Tuple[str, int]]`\nGet table of contents from a PDF file.\n\n#### `get_pdf_page_text(pdf_path: str, page_number: int) -> str`\nGet plain text content from a specific page.\n\n#### `get_pdf_page_markdown(pdf_path: str, page_number: int) -> str`\nGet Markdown formatted content from a specific page.\n\n#### `get_pdf_chapter_content(pdf_path: str, chapter_title: str) -> Tuple[str, List[int]]`\nGet chapter content and corresponding page numbers by chapter title.\n\n## Dependencies\n\nKey dependencies include:\n- ebooklib: EPUB file processing\n- PyPDF2: Basic PDF processing\n- PyMuPDF: Advanced PDF processing\n- beautifulsoup4: HTML parsing\n- html2text: HTML to Markdown conversion\n- pydantic: Data validation\n- fastmcp: MCP server framework\n\n## Important Notes\n\n1. PDF processing relies on the document's table of contents. Some features may not work if TOC is not available.\n2. For large PDF files, it's recommended to process by page ranges to avoid loading the entire file at once.\n3. EPUB chapter IDs must be obtained from the table of contents structure.\n\n## Architecture\n\n```\n           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n           â”‚         Agent Layer        â”‚\n           â”‚  - Translation Strategy    â”‚\n           â”‚  - Style Consistency Check â”‚\n           â”‚  - LLM Call & Interaction â”‚\n           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                        â”‚ Tool Calls\n           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n           â”‚        MCP Tool Layer     â”‚\n           â”‚  - extract_chapter        â”‚\n           â”‚  - write_translated_chapterâ”‚\n           â”‚  - generate_epub          â”‚\n           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                        â”‚ System/IO Calls\n           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n           â”‚     System Base Layer     â”‚\n           â”‚  - File Reading          â”‚\n           â”‚  - ebooklib Parsing      â”‚\n           â”‚  - File Path Storage/Checkâ”‚\n           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n\n\n## Contributing\n\nWe welcome Issues and Pull Requests!\n\nFor detailed information about recent changes, please see [CHANGELOG.md](CHANGELOG.md).\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "OpenTorah-ai--mcp-sefaria-server": {
      "owner": "OpenTorah-ai",
      "name": "mcp-sefaria-server",
      "url": "https://github.com/OpenTorah-ai/mcp-sefaria-server",
      "imageUrl": "https://github.com/OpenTorah-ai.png",
      "description": "Access and reference Jewish texts and commentaries through a standardized interface.",
      "stars": 0,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-02-25T08:57:14Z",
      "readme_content": "# Sefaria Jewish Library MCP Server\n\n[![smithery badge](https://smithery.ai/badge/mcp-sefaria-server)](https://smithery.ai/server/mcp-sefaria-server)\nAn MCP (Model Context Protocol) server that provides access to Jewish texts from the Sefaria library. This server enables Large Language Models to retrieve and reference Jewish texts through a standardized interface.\n\n<a href=\"https://glama.ai/mcp/servers/j3v6vnp4xk\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/j3v6vnp4xk/badge\" alt=\"Sefaria Jewish Library Server MCP server\" /></a>\n\n## Features\n\n- Retrieve Jewish texts by reference\n- Retrieve commentaries on a given text\n\n## Installation\n\nRequires Python 3.10 or higher.\n\n### Installing via Smithery\n\nTo install Sefaria Jewish Library for Claude Desktop automatically via [Smithery](https://smithery.ai/server/mcp-sefaria-server):\n\n```bash\nnpx -y @smithery/cli install mcp-sefaria-server --client claude\n```\n\n### Clone the repository\n```bash\ngit clone https://github.com/sivan22/mcp-sefaria-server.git\ncd mcp-sefaria-server\n```\n\n\n## Running the Server\n\nThe server can be run directly:\n\n```bash\nuv --directory path/to/directory run sefaria_jewish_library\n```\n\nOr through an MCP client that supports the Model Context Protocol.\nfor claude desktop app and cline you should use the following config:\n```\n{\n  \"mcpServers\": {        \n      \"sefaria_jewish_library\": {\n          \"command\": \"uv\",\n          \"args\": [\n              \"--directory\",\n              \"C:/dev/mcp-sefaria-server\",\n              \"run\",\n              \"sefaria_jewish_library\"\n          ],\n          \"env\": {\n            \"PYTHONIOENCODING\": \"utf-8\" \n          }\n      }\n  }\n}\n```\n\n## Available tools\n\nThe server provides the following tools through the MCP interface:\n\n### get_text\n\nRetrieves a specific Jewish text by its reference.\n\nExample:\n```\nreference: \"Genesis 1:1\"\nreference: \"×©××•×ª ×¤×¨×§ ×‘ ×¤×¡×•×§ ×’\"\nreference: \"××©× ×” ×‘×¨×›×•×ª ×¤×¨×§ × ××©× ×” ×\"\n```\n\n### get_commentaries\n\nRetrieves a list of commentaries for a given text.\n\nExample:\n```\nreference: \"Genesis 1:1\"\nreference: \"×©××•×ª ×¤×¨×§ ×‘ ×¤×¡×•×§ ×’\"\nreference: \"××©× ×” ×‘×¨×›×•×ª ×¤×¨×§ × ××©× ×” ×\"\n```\n\n## Development\n\nThis project uses:\n- [MCP SDK](https://github.com/modelcontextprotocol/sdk) for server implementation\n- [Sefaria API](https://github.com/Sefaria/Sefaria-API) for accessing Jewish texts\n\n## Requirements\n\n- Python >= 3.10\n- MCP SDK >= 1.1.1\n- Sefaria API\n\n## License\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Paulinholeo--AI-Bootcamp": {
      "owner": "Paulinholeo",
      "name": "AI-Bootcamp",
      "url": "https://github.com/Paulinholeo/AI-Bootcamp",
      "imageUrl": "https://github.com/Paulinholeo.png",
      "description": "Supports practical training and project-based learning for AI engineering, focusing on building, deploying, and evaluating AI models through hands-on exercises and real-world applications.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-03-18T20:01:54Z",
      "readme_content": "# AI Bootcamp\n\nThe \"Get Shit Done with AI\" Bootcamp focuses on real-world applications that will equip you with the skills and knowledge to become a great AI engineer\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/curiousily/AI-Bootcamp/)\n[![](https://dcbadge.vercel.app/api/server/UaNPxVD6tv?style=flat)](https://discord.gg/UaNPxVD6tv)\n[![](https://img.shields.io/youtube/channel/subscribers/UCoW_WzQNJVAjxo4osNAxd_g?label=Watch%20on%20YouTube)](https://bit.ly/venelin-subscribe)\n[![](https://img.shields.io/github/license/curiousily/AI-Bootcamp)](https://github.com/curiousily/AI-Bootcamp/blob/master/LICENSE)\n\n## ğŸ¿ Watch on YouTube\n\n- [Real-World PyTorch](https://www.youtube.com/watch?v=dgs_9quxZXk)\n- [Build Real-World Machine Learning Project](https://www.youtube.com/watch?v=ug1FA7qzWSc)\n- [Fine-tuning Tiny LLM on Your Data](https://www.youtube.com/watch?v=_KPEoCSKHcU)\n- [Deploy (Tiny) LLM to Production](https://www.youtube.com/watch?v=c10rsQkczu0)\n- [AI Agents with GPT-4 Turbo and CrewAI](https://www.youtube.com/watch?v=Ev0uzdzesjU)\n- [CrewAI with Open LLM (Llama 3) using Groq API](https://www.youtube.com/watch?v=N5sos1X30Rw)\n- [Fine-Tuning Llama 3 on a Custom Dataset](https://www.youtube.com/watch?v=0XPZlR3_GgI)\n- [Local RAG with Llama 3.1 for PDFs](https://www.youtube.com/watch?v=ofNbLa2-5SU)\n\n## ğŸ“– Read the Tutorials\n\n### Foundational Skills\n\n- [Python Essentials for AI: A Practical Guide](https://www.mlexpert.io/bootcamp)\n- [Real-World PyTorch](https://www.mlexpert.io/bootcamp/real-world-pytorch)\n\n### ML Pipelines\n\n- [Analyze Data For Insights](https://www.mlexpert.io/bootcamp/analyze-data-for-insights)\n- [Develop Your Model](https://www.mlexpert.io/bootcamp/develop-your-model)\n- [Evaluate Your Model](https://www.mlexpert.io/bootcamp/evaluate-your-model)\n- [Architect Your ML Project](https://www.mlexpert.io/bootcamp/architect-your-ml-project)\n\n### Large Language Models (LLMs)\n\n- [LLMs 101](https://www.mlexpert.io/bootcamp/llms-101)\n- [Write Great Prompts](https://www.mlexpert.io/bootcamp/write-great-prompts)\n- [Build a RAG System](https://www.mlexpert.io/bootcamp/build-a-rag-system)\n- [Fine-tuning Tiny LLM on Custom Dataset](https://www.mlexpert.io/bootcamp/fine-tuning-tiny-llm-on-custom-dataset)\n- [Deploy Custom LLM to Production](https://www.mlexpert.io/bootcamp/deploy-custom-llm-to-production)\n- [LLM Evaluation](https://www.mlexpert.io/bootcamp/llm-evaluation)\n\n### AI Agents\n\n- [Build Agentic Apps](https://www.mlexpert.io/bootcamp/build-agentic-apps)\n- [Agents with Llama 3 and Custom Tools](https://www.mlexpert.io/bootcamp/agents-with-llama-3-and-custom-tools)\n- [Develop a Tweet Writing Team](https://www.mlexpert.io/bootcamp/ai-agents-in-action)\n- [SQL Agents with CrewAI and Llama 3](https://www.mlexpert.io/bootcamp/sql-agents-with-crewai)\n\n### Projects\n\n- [RagBase - Private Chat with Your Documents](https://www.mlexpert.io/bootcamp/ragbase-local-rag)\n- [Write Social Media Content with Agents](https://www.mlexpert.io/bootcamp/write-social-media-content-with-agents)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "peancor--moodle-mcp-server": {
      "owner": "peancor",
      "name": "moodle-mcp-server",
      "url": "https://github.com/peancor/moodle-mcp-server",
      "imageUrl": "https://github.com/peancor.png",
      "description": "Manage Moodle courses, students, assignments, and quizzes through integration with LLMs, enabling automation of feedback and progress tracking.",
      "stars": 19,
      "forks": 8,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-04T09:57:07Z",
      "readme_content": "# Moodle MCP Server\n\nAn MCP (Model Context Protocol) server that enables LLMs to interact with the Moodle platform to manage courses, students, assignments, and quizzes.\n\n## Features\n\n### Student Management Tools\n- `list_students` - Retrieves the list of students enrolled in the course\n  - Displays ID, name, email, and last access time for each student\n\n### Assignment Management Tools\n- `get_assignments` - Retrieves all available assignments in the course\n  - Includes information such as ID, name, description, due date, and maximum grade\n- `get_student_submissions` - Examines a student's submissions for a specific assignment\n  - Requires the assignment ID and optionally the student ID\n- `provide_assignment_feedback` - Provides grades and comments for a student's submission\n  - Requires student ID, assignment ID, grade, and feedback comment\n\n### Quiz Management Tools\n- `get_quizzes` - Retrieves all available quizzes in the course\n  - Includes information such as ID, name, description, opening/closing dates, and maximum grade\n- `get_quiz_attempts` - Examines a student's attempts on a specific quiz\n  - Requires the quiz ID and optionally the student ID\n- `provide_quiz_feedback` - Provides comments for a quiz attempt\n  - Requires the attempt ID and feedback comment\n\n## Requirements\n\n- Node.js (v14 or higher)\n- Moodle API token with appropriate permissions\n- Moodle course ID\n\n## Installation\n\n1. Clone this repository:\n```bash\ngit clone https://github.com/your-username/moodle-mcp-server.git\ncd moodle-mcp-server\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Create a `.env` file with the following configuration:\n```\nMOODLE_API_URL=https://your-moodle.com/webservice/rest/server.php\nMOODLE_API_TOKEN=your_api_token\nMOODLE_COURSE_ID=1  # Replace with your course ID\n```\n\n4. Build the server:\n```bash\nnpm run build\n```\n\n## Usage with Claude\n\nTo use with Claude Desktop, add the server configuration:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`  \nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"moodle-mcp-server\": {\n      \"command\": \"/path/to/node\",\n      \"args\": [\n        \"/path/to/moodle-mcp-server/build/index.js\"\n      ],\n      \"env\": {\n        \"MOODLE_API_URL\": \"https://your-moodle.com/webservice/rest/server.php\",\n        \"MOODLE_API_TOKEN\": \"your_moodle_api_token\",\n        \"MOODLE_COURSE_ID\": \"your_course_id\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\nFor Windows users, the paths would use backslashes:\n\n```json\n{\n  \"mcpServers\": {\n    \"moodle-mcp-server\": {\n      \"command\": \"C:\\\\path\\\\to\\\\node.exe\",\n      \"args\": [\n        \"C:\\\\path\\\\to\\\\moodle-mcp-server\\\\build\\\\index.js\"\n      ],\n      \"env\": {\n        \"MOODLE_API_URL\": \"https://your-moodle.com/webservice/rest/server.php\",\n        \"MOODLE_API_TOKEN\": \"your_moodle_api_token\",\n        \"MOODLE_COURSE_ID\": \"your_course_id\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\nOnce configured, Claude will be able to interact with your Moodle course to:\n- View the list of students and their submissions\n- Provide comments and grades for assignments\n- Examine quiz attempts and offer feedback\n\n## Development\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n### Debugging\n\nMCP servers communicate through stdio, which can make debugging challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector):\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## Obtaining a Moodle API Token\n\n1. Log in to your Moodle site as an administrator\n2. Go to Site Administration > Plugins > Web Services > Manage tokens\n3. Create a new token with the necessary permissions to manage courses\n4. Copy the generated token and add it to your `.env` file\n\n## Security\n\n- Never share your `.env` file or Moodle API token\n- Ensure the MCP server only has access to the courses it needs to manage\n- Use a token with the minimum necessary permissions\n\n## License\n\n[MIT](LICENSE)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "PewterZz--CanvasLMS-ModelContextProtocol": {
      "owner": "PewterZz",
      "name": "CanvasLMS-ModelContextProtocol",
      "url": "https://github.com/PewterZz/CanvasLMS-ModelContextProtocol",
      "imageUrl": "https://github.com/PewterZz.png",
      "description": "Seamless access to Canvas LMS course data including assignments, discussions, and PDF content extraction. Supports both standard and AWS-hosted Canvas instances with a simple API interface for fetching detailed information and executing tools upon authentication.",
      "stars": 0,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-04-30T07:37:12Z",
      "readme_content": "# Canvas LMS Model Context Protocol\n\nA server implementation that enables Smithery to list tools without authentication, while deferring authentication until tool execution.\n\n## Lazy Loading Authentication\n\nThis server follows the Smithery recommendation for \"lazy loading\" of authentication:\n\n- **Tool Listing**: The `/api/tools` endpoint allows any client (including Smithery) to list available tools without requiring authentication. This is essential for discovery.\n\n- **Tool Execution**: Authentication credentials are only required when actually executing a tool. The credentials are passed in the request body at execution time.\n\nThis approach ensures that:\n\n1. Smithery can display the tool list without requiring users to provide authentication upfront\n2. Security is maintained by requiring proper authentication when accessing protected resources\n3. API keys and sensitive credentials are only used when absolutely necessary\n\n## API Endpoints\n\n### Public Endpoints (No Authentication Required)\n\n- `GET /api/tools` - List all available tools\n- `GET /api/tools/:id` - Get details for a specific tool\n\n### Protected Endpoints (Authentication Required in Request)\n\n- `POST /api/tools/:id/execute` - Execute a specific tool\n\n## Request Format for Tool Execution\n\n```json\n{\n  \"parameters\": {\n    \"key1\": \"value1\",\n    \"key2\": \"value2\"\n  },\n  \"authentication\": {\n    \"apiKey\": \"your-canvas-api-key\",\n    \"domain\": \"your-canvas-domain.instructure.com\"\n  }\n}\n```\n\n## Response Format\n\n### Success Response\n\n```json\n{\n  \"success\": true,\n  \"result\": {\n    // Tool-specific result data\n  }\n}\n```\n\n### Error Response\n\n```json\n{\n  \"success\": false,\n  \"error\": \"Error message describing what went wrong\"\n}\n```\n\n## Available Tools\n\n1. **Get Courses**\n   - ID: `get-courses`\n   - Description: Retrieves courses from Canvas LMS\n   - Parameters:\n     - `limit` (optional): Maximum number of courses to return\n\n2. **Get Assignments**\n   - ID: `get-assignments`\n   - Description: Retrieves assignments for a specific course\n   - Parameters:\n     - `courseId` (required): ID of the course\n\n## Development\n\n1. Install dependencies: `npm install`\n2. Build the project: `npm run build`\n3. Start the server: `npm start`\n\n## Docker\n\nA Docker configuration is included for easy deployment:\n\n```bash\ndocker build -t canvas-mcp .\ndocker run -p 3000:3000 canvas-mcp\n```\n\n# Canvas LMS MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@PewterZz/canvaslms-modelcontextprotocol)](https://smithery.ai/server/@PewterZz/canvaslms-modelcontextprotocol)\n\n\nThis server acts as a backend proxy and utility layer for interacting with Canvas LMS instances, providing processed data intended for consumption by Language Models (LLMs) or other applications.\n\nIt allows fetching course details, assignment information (including descriptions and attached file links/content), discussion topics, and extracting text from PDF files hosted on Canvas.\n\n## Setup\n\n1.  **Clone the repository (if applicable):**\n    ```bash\n    git clone <repository-url>\n    cd CanvasMCP\n    ```\n\n2.  **Install Dependencies:**\n    ```bash\n    npm install\n    ```\n\n3.  **Configure Environment Variables:**\n    Create a `.env` file in the project root and add the following variables. Replace the placeholder values with your actual Canvas credentials.\n\n    ```env\n    # Standard Canvas Instance\n    CANVAS_API_URL=https://your-canvas-domain.instructure.com\n    CANVAS_API_TOKEN=your_standard_canvas_api_token\n\n    # AWS Hosted Canvas Instance (if applicable)\n    AWS_CANVAS_API_URL=https://your-aws-canvas-domain.instructure.com\n    AWS_CANVAS_API_TOKEN=your_aws_canvas_api_token\n\n    # Server Port (Optional, defaults to 3000)\n    PORT=3000\n    ```\n\n4.  **Run the Server:**\n    *   For development (with auto-reloading): `npm run dev`\n    *   For production: `npm start`\n\nThe server will be running at `http://localhost:PORT` (e.g., `http://localhost:3000`).\n\n## API Endpoints\n\nAll endpoints require the corresponding Canvas API URL and Token to be configured in the `.env` file.\n\n### Health Check\n\n*   **GET /**\n    *   **Description:** Checks if the server is running.\n    *   **Example:**\n        ```bash\n        curl http://localhost:3000/\n        ```\n    *   **Success Response:** `Canvas MCP Server is running!` (Content-Type: text/html)\n\n### Standard Canvas API (`/api/...`)\n\nUses `CANVAS_API_URL` and `CANVAS_API_TOKEN`.\n\n*   **GET /api/courses/:courseId**\n    *   **Description:** Get details for a specific course.\n    *   **Path Parameters:**\n        *   `:courseId` (number): The ID of the course.\n    *   **Example:**\n        ```bash\n        curl http://localhost:3000/api/courses/12345\n        ```\n    *   **Success Response (Example):** `{ \"id\": 12345, \"name\": \"Introduction to Programming\", ... }`\n\n*   **GET /api/courses/:courseId/assignments**\n    *   **Description:** Get a list of assignments for a specific course.\n    *   **Path Parameters:**\n        *   `:courseId` (number): The ID of the course.\n    *   **Example:**\n        ```bash\n        curl http://localhost:3000/api/courses/12345/assignments\n        ```\n    *   **Success Response (Example):** `[ { \"id\": 987, \"name\": \"Assignment 1\", ... }, ... ]`\n\n*   **GET /api/assignments/:courseId/:assignmentId**\n    *   **Description:** Get details for a specific assignment.\n    *   **Path Parameters:**\n        *   `:courseId` (number): The ID of the course.\n        *   `:assignmentId` (number): The ID of the assignment.\n    *   **Example:**\n        ```bash\n        curl http://localhost:3000/api/assignments/12345/987\n        ```\n    *   **Success Response (Example):** `{ \"id\": 987, \"name\": \"Assignment 1\", \"description\": \"...\", ... }`\n\n*   **GET /api/assignments/:courseId/:assignmentId/submissions**\n    *   **Description:** Get submission details for a specific assignment (requires appropriate permissions).\n    *   **Path Parameters:**\n        *   `:courseId` (number): The ID of the course.\n        *   `:assignmentId` (number): The ID of the assignment.\n    *   **Example:**\n        ```bash\n        curl http://localhost:3000/api/assignments/12345/987/submissions\n        ```\n    *   **Success Response (Example):** `[ { \"user_id\": 101, \"grade\": \"A\", ... }, ... ]`\n\n*   **GET /api/assignments/:courseId/:assignmentId/description**\n    *   **Description:** Get the assignment description along with extracted links to attached files.\n    *   **Path Parameters:**\n        *   `:courseId` (number): The ID of the course.\n        *   `:assignmentId` (number): The ID of the assignment.\n    *   **Example:**\n        ```bash\n        curl http://localhost:3000/api/assignments/12345/987/description\n        ```\n    *   **Success Response (Example):**\n        ```json\n        {\n          \"description\": \"<p>Please read the attached file.</p><p><a class=\\\"instructure_file_link\\\" href=\\\"/courses/12345/files/44827106/download?download_frd=1\\\" data-api-endpoint=\\\"https://rmit.instructure.com/api/v1/courses/12345/files/44827106\\\" data-api-returntype=\\\"File\\\">Instructions.pdf</a></p>\",\n          \"linked_files\": [\n            {\n              \"link_text\": \"Instructions.pdf\",\n              \"file_id\": \"44827106\",\n              \"download_url\": \"https://your-canvas-domain.instructure.com/files/44827106/download?download_frd=1\"\n            }\n          ]\n        }\n        ```\n\n*   **GET /api/discussions/:courseId/:discussionTopicId**\n    *   **Description:** Get details for a specific discussion topic.\n    *   **Path Parameters:**\n        *   `:courseId` (number): The ID of the course.\n        *   `:discussionTopicId` (number): The ID of the discussion topic.\n    *   **Example:**\n        ```bash\n        curl http://localhost:3000/api/discussions/12345/678\n        ```\n    *   **Success Response (Example):** `{ \"id\": 678, \"title\": \"Week 1 Discussion\", \"message\": \"...\", ... }`\n\n### PDF Tools (`/api/pdf/...`)\n\nUses `CANVAS_API_URL` and `CANVAS_API_TOKEN`.\n\n*   **POST /api/pdf/extract-text**\n    *   **Description:** Downloads a PDF file from Canvas using its file ID and extracts the text content.\n    *   **Request Body:** `application/json`\n        ```json\n        {\n          \"fileId\": 44827106\n        }\n        ```\n    *   **Example:**\n        ```bash\n        curl -X POST \\\n          http://localhost:3000/api/pdf/extract-text \\\n          -H 'Content-Type: application/json' \\\n          -d '{\"fileId\": 44827106}'\n        ```\n    *   **Success Response (Example):**\n        ```json\n        {\n          \"text\": \"This is the extracted text content from the PDF...\\nPage 2 content...\"\n        }\n        ```\n    *   **Error Responses:**\n        *   `400 Bad Request`: Missing or invalid `fileId`.\n        *   `401 Unauthorized / 404 Not Found`: Invalid API token, insufficient permissions, or file ID not found (check server logs for details from Canvas API).\n        *   `500 Internal Server Error`: Server configuration error (missing .env variables), failed to download, or failed to parse PDF.\n\n### Grades\n\nGrade information for individual assignments is retrieved via the Submissions endpoint:\n\n*   **GET /api/assignments/:courseId/:assignmentId/submissions**\n    *   **Description:** Get submission details for a specific assignment, including grades (`grade`, `score`) for each submission.\n    *   *(See full description under Standard Canvas API)*\n\n### AWS Canvas API (`/api/aws/...`)\n\nUses `AWS_CANVAS_API_URL` and `AWS_CANVAS_API_TOKEN`.\n\nThese endpoints mirror the standard Canvas API endpoints but target the AWS-hosted instance defined in the `.env` file.\n\n*   **GET /api/aws/courses/:courseId**\n*   **GET /api/aws/courses/:courseId/assignments**\n*   **GET /api/aws/assignments/:courseId/:assignmentId**\n*   **GET /api/aws/assignments/:courseId/:assignmentId/description**\n    *   *(Note: The file download links returned here will point to the AWS Canvas instance)*\n\n*   **GET /api/aws/assignments/:courseId/:assignmentId/submissions** *(Provides AWS grades)*\n\n*(Usage and responses are analogous to the standard API endpoints above, but using the `/api/aws` prefix and the AWS Canvas credentials.)*\n\n## Error Handling\n\nThe server includes a global error handler. Most errors originating from the Canvas API or internal processing will return a JSON response with an `error` object containing a `message` field:\n\n```json\n{\n  \"error\": {\n    \"message\": \"Specific error details here...\"\n  }\n}\n```\n\nCheck the server console logs for more detailed stack traces and debugging information. \n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "pjookim--mcp-visit-korea": {
      "owner": "pjookim",
      "name": "mcp-visit-korea",
      "url": "https://github.com/pjookim/mcp-visit-korea",
      "imageUrl": "https://github.com/pjookim.png",
      "description": "Provides information related to tourism in Korea, including attractions, festivals, and accommodations. Supports various search methods based on area codes, keywords, or locations for detailed tourism content.",
      "stars": 2,
      "forks": 1,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-17T06:03:50Z",
      "readme_content": "# Korea Tour MCP Server\n[![smithery badge](https://smithery.ai/badge/@pjookim/mcp-visit-korea)](https://smithery.ai/server/@pjookim/mcp-visit-korea)\nMCP (Model Context Protocol) server providing Korean tourism information.\n\n## Features\n- Area code lookup: Query metropolitan cities/provinces and sub-regions\n- Tourism information search: Support for region-based, keyword-based, and location-based searches\n- Tourism content detail lookup: Provides detailed information about attractions, festivals, accommodations, etc.\n\n\n### Installing via Smithery\n\nTo install mcp-visit-korea for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@pjookim/mcp-visit-korea):\n\n```bash\nnpx -y @smithery/cli install @pjookim/mcp-visit-korea --client claude\n```\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "QuantumLeap-us--css-mcp-server": {
      "owner": "QuantumLeap-us",
      "name": "css-mcp-server",
      "url": "https://github.com/QuantumLeap-us/css-mcp-server",
      "imageUrl": "https://github.com/QuantumLeap-us.png",
      "description": "Provides updates on the latest CSS features and enhancements, allowing users to manage their knowledge and receive tailored guidance effectively.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2025-04-13T03:07:36Z",
      "readme_content": "# Building a CSS Tutor MCP Server\n\nThis repo contains a simple Model Context Protocol (MCP) server built with Node.js and TypeScript. It acts as a \"CSS Tutor,\" providing personalized updates about CSS features to a connected AI client.\n\nThis server demonstrates key MCP concepts: defining **Resources**, **Tools**, and **Prompts**. The goal of this demonstration is to help you move on from here and build much larger and more interesting agentic capabilities.\n\n## Prerequisites\n\n*   Node.js (v18 or later recommended)\n*   `npm` (or your preferred Node.js package manager like `yarn` or `pnpm`)\n*   An AI client capable of connecting to an MCP server (e.g., the Claude desktop app)\n*   An [OpenRouter API Key](https://openrouter.ai/) (for fetching live CSS updates via Perplexity)\n\n## Quick Start\n\nFollow these steps to get the server running quickly:\n\n1.  **Clone the Repository:**\n    ```bash\n    git clone https://github.com/3mdistal/css-mcp-server.git\n    cd css-mcp-server\n    ```\n\n2.  **Install Dependencies:**\n    ```bash\n    npm install # Or: yarn install / pnpm install\n    ```\n\n3.  **Prepare API Key:** The `get_latest_updates` tool requires an OpenRouter API key. Obtain your key from [OpenRouter](https://openrouter.ai/). You will provide this key to your MCP client in Step 5.\n\n4.  **Build the Server:** Compile the TypeScript code.\n    ```bash\n    npm run build # Or: yarn build / pnpm run build\n    ```\n\n5.  **Configure Your MCP Client:** Tell your client how to launch the server *and* provide the API key as an environment variable. Here's an example for the Claude desktop app's `claude_desktop_config.json`:\n\n    ```json\n    {\n      \"mcpServers\": {\n        \"css-tutor\": {\n          \"command\": \"node\",\n          \"args\": [\n            \"/full/path/to/your/css-mcp-server/build/index.js\"\n          ],\n          \"env\": {\n            \"OPENROUTER_API_KEY\": \"sk-or-xxxxxxxxxxxxxxxxxxxxxxxxxx\"\n          }\n        }\n      }\n    }\n    ```\n    *(Ensure the path in `args` is the correct **absolute path** to the built `index.js` file on your system. Replace the placeholder API key.)*\n\n6.  **Connect:** Start the connection from your MCP client. The client will launch the server process (with the API key in its environment), and you can start interacting!\n\n## Using with Cursor\n\n[Cursor](https://cursor.sh/) is an AI-first code editor that can act as an MCP client. Setting up this server with Cursor is straightforward, but requires an extra step for the guidance prompt.\n\n1.  **Configure Server in Cursor:**\n    *   Go to `Cursor Settings` > `MCP` > `Add new global MCP server`.\n    *   Paste in the same JSON as above in the Claude Desktop step, with all the same caveats.\n\n2.  **Create a Cursor Project Rule for the Prompt:** Cursor currently does not automatically use MCP prompts provided by servers. Instead, you need to provide the guidance using Cursor's [Project Rules](https://docs.cursor.com/context/rules-for-ai) feature.\n    *   Create the directory `.cursor/rules` in your project root if it doesn't exist.\n    *   Create a file inside it named `css-tutor.rule` (or any `.rule` filename).\n    *   Paste the following guidance text into `css-tutor.rule`:\n\n        ```text\n        You are a helpful assistant connecting to a CSS knowledge server. Your goal is to provide the user with personalized updates about new CSS features they haven't learned yet.\n\n        Available Tools:\n        1.  `get_latest_updates`: Fetches recent general news and articles about CSS. Use this first to see what's new.\n        2.  `read_from_memory`: Checks which CSS concepts the user already knows based on their stored knowledge profile.\n        3.  `write_to_memory`: Updates the user's knowledge profile. Use this when the user confirms they have learned or already know a specific CSS concept mentioned in an update.\n\n        Workflow:\n        1.  Call `get_latest_updates` to discover recent CSS developments.\n        2.  Call `read_from_memory` to get the user's current known concepts (if any).\n        3.  Compare the updates with the known concepts (if any). Identify 1-2 *new* concepts relevant to the user. **Important: They _must_ be from the response returned by `get_latest_updates` tool.**\n        4.  Present these new concepts to the user, adding any context as needed, in addition to the information returned by the `get_latest_updates`.\n        5.  Ask the user if they are familiar with these concepts or if they've learned them now.\n        6.  If the user confirms knowledge of a concept, call `write_to_memory` to update their profile for that specific concept.\n        7.  Focus on providing actionable, personalized learning updates.\n        ```\n\n3.  **Connect and Use:**\n    *   Ensure the `css-tutor` server is enabled in Cursor's MCP settings.\n    *   Start a new chat or code generation request (e.g., Cmd+K) and include `@css-tutor-rule` (or whatever you named your rule file) in your request. This tells Cursor to load the rule's content, which includes the instructions on how to use the `read_from_memory`, `write_to_memory`, and `get_latest_updates` tools provided by the connected MCP server. \n\nNote that _without_ the prompt/rule, Cursor will still be able to use individual tools if you ask it to. The prompt provides a workflow and order in which to call the tools and read/write from memory.\n\n## Understanding the Code\n\nThis section provides a higher-level overview of how the server is implemented.\n\n### MCP Concepts Used\n\n*   **Resource (`css_knowledge_memory`):** Represents the user's known CSS concepts, stored persistently in `data/memory.json`.\n*   **Tools:** Actions the server can perform:\n    *   `get_latest_updates`: Fetches CSS news from OpenRouter/Perplexity.\n    *   `read_from_memory`: Reads the content of the `css_knowledge_memory` resource.\n    *   `write_to_memory`: Modifies the `css_knowledge_memory` resource.\n*   **Prompt (`css-tutor-guidance`):** Static instructions guiding the AI client on how to interact with the tools and resource effectively.\n\n### Code Structure\n\nThe code is organized as follows:\n\n*   **`data/memory.json`**: A simple JSON file acting as the database for known CSS concepts. A default version is included in the repo.\n*   **`src/resources/index.ts`**: Defines the `css_knowledge_memory` resource. It includes:\n    *   A Zod schema for validating the data.\n    *   `readMemory` and `writeMemory` functions for file I/O.\n    *   Registration using `server.resource`, specifying the `memory://` URI scheme and read/write permissions. The read handler returns the content of `data/memory.json`.\n*   **`src/tools/index.ts`**: Defines the three tools using `server.tool`:\n    *   `read_from_memory`: Calls `readMemory`.\n    *   `write_to_memory`: Takes `concept` and `known` as input (schema defined with Zod), uses `readMemory` and `writeMemory` to update the JSON file.\n    *   `get_latest_updates`: Requires `OPENROUTER_API_KEY`, calls the OpenRouter API using `node-fetch` and the `perplexity/sonar-pro` model, returns the AI-generated summary.\n*   **`src/prompts/index.ts`**: Defines the static `css-tutor-guidance` prompt using `server.prompt`. The prompt text is embedded directly in the code.\n*   **`src/index.ts`**: The main server entry point.\n    *   Initializes the `McpServer` instance from `@modelcontextprotocol/sdk`.\n    *   Imports and calls the `registerPrompts`, `registerResources`, and `registerTools` functions from the other modules.\n    *   Uses `StdioServerTransport` to handle communication over standard input/output.\n    *   Connects the server to the transport and includes basic error handling.\n*   **`package.json`**: Defines dependencies (`@modelcontextprotocol/sdk`, `dotenv`, `node-fetch`, `zod`) and the `build` script (`tsc`).\n*   **`.env.example` / `.env`**: Used for storing the `OPENROUTER_API_KEY` (if using Option A for configuration).\n*   **`.gitignore`**: Configured to ignore `node_modules`, `build`, `.env`, and the contents of `data/` except for the default `data/memory.json`.\n*   **`tsconfig.json`**: Standard TypeScript configuration.\n\n## Debugging with MCP Inspector\n\nIf you need to debug the server or inspect the raw JSON-RPC messages being exchanged, you can use the `@modelcontextprotocol/inspector` tool. This tool acts as a basic MCP client and launches your server, showing you the communication flow.\n\nRun the inspector from your terminal in the project root:\n\n```bash\nnpx @modelcontextprotocol/inspector node ./build/index.js\n```\n\n**Explanation:**\n\n*   `npx @modelcontextprotocol/inspector`: Downloads (if needed) and runs the inspector package.\n*   `node`: The command used to execute your server.\n*   `./build/index.js`: The path (relative to your project root) to your compiled server entry point.\n\n**Environment Variables for Inspector:**\n\nNote that the inspector launches your server as a child process. If your server relies on environment variables (like `OPENROUTER_API_KEY` for the `get_latest_updates` tool), you need to ensure they are available in the environment where you run the `npx` command. The `.env` file might not be automatically loaded in this context. You can typically prefix the command:\n\n```bash\n# Example on Linux/macOS\nOPENROUTER_API_KEY=\"sk-or-xxxxxxxxxx\" npx @modelcontextprotocol/inspector node ./build/index.js\n\n# Example on Windows (Command Prompt)\nset OPENROUTER_API_KEY=sk-or-xxxxxxxxxx && npx @modelcontextprotocol/inspector node ./build/index.js\n\n# Example on Windows (PowerShell)\n$env:OPENROUTER_API_KEY=\"sk-or-xxxxxxxxxx\"; npx @modelcontextprotocol/inspector node ./build/index.js\n```\n\nReplace `sk-or-xxxxxxxxxx` with your actual key.\n\n## Wrapping up\n\nThis demo demonstrates the core steps involved in creating a functional MCP server using the TypeScript SDK. We defined a resource to manage state, tools to perform actions (including interacting with an external API), and a prompt to guide the AI client.\n\nHope this demo can help you understand how to build servers that are much more complex (and useful) than this one!\n\n(Also, if you run into any ğŸ›bugs, feel free to open up an issue.)",
      "npm_url": "",
      "npm_downloads": 0
    },
    "r-huijts--oorlogsbronnen-mcp": {
      "owner": "r-huijts",
      "name": "oorlogsbronnen-mcp",
      "url": "https://github.com/r-huijts/oorlogsbronnen-mcp",
      "imageUrl": "https://github.com/r-huijts.png",
      "description": "Enables AI-powered access to the Oorlogsbronnen database for natural language queries related to historical World War II archives from the Netherlands.",
      "stars": 11,
      "forks": 4,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-07-22T13:29:18Z",
      "readme_content": "# Oorlogsbronnen MCP Server\n\nA Model Context Protocol (MCP) server that provides AI-powered access to the Oorlogsbronnen (War Sources) database. This server enables natural language interactions with historical World War II archives from the Netherlands.\n\n## Natural Language Interaction Examples\n\nAsk your AI assistant questions like these to explore Dutch WWII history:\n\n- **\"What happened during the bombing of Rotterdam in May 1940?\"**\n- **\"Tell me about Anne Frank's life in hiding based on historical records.\"**\n- **\"Show me photographs of the Dutch Hunger Winter of 1944-1945.\"**\n- **\"Were any of my ancestors imprisoned in Camp Vught during the war?\"**\n- **\"I'm visiting Arnhem next week. What historical sites related to Operation Market Garden should I see?\"**\n- **\"Find information about resistance activities in Utrecht during the Nazi occupation.\"**\n- **\"What was daily life like for Jewish families in Amsterdam before deportations began?\"**\n- **\"Show me firsthand accounts from people who witnessed the liberation of the Netherlands in 1945.\"**\n- **\"What records exist about children who were hidden by Dutch families during the war?\"**\n- **\"I'm researching the impact of WWII on Dutch infrastructure. Can you find documents about the reconstruction of bridges and railways?\"**\n\n## Features\n\n- ğŸ” Natural language search across the Oorlogsbronnen database\n- ğŸ·ï¸ Filter results by content type (person, photo, article, etc.)\n- ğŸ“Š Control the number of results returned\n- ğŸ¤– AI-friendly JSON responses for further processing\n\n## Installation\n\nYou can install this server in two ways:\n\n### 1. Using Claude Desktop with NPX Package\n\nUpdate your Claude configuration file (`~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"oorlogsbronnen-server\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"oorlogsbronnen-mcp\"\n      ]\n    }\n  }\n}\n```\n\nAfter updating the configuration, restart Claude Desktop for the changes to take effect.\n\n### 2. From Source\n\n1. Clone this repository:\n```bash\ngit clone https://github.com/r-huijts/oorlogsbronnen-mcp.git\ncd oorlogsbronnen-mcp\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the project:\n```bash\nnpm run build\n```\n\n4. Configure Claude Desktop by updating your configuration file (located at `~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"oorlogsbronnen-server\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/to/oorlogsbronnen-mcp/dist/mcp-server.js\"\n      ]\n    }\n  }\n}\n```\n\nReplace `/absolute/path/to/oorlogsbronnen-mcp` with the actual path to your installation.\n\n## Usage Examples\n\nThe MCP server understands natural language queries and can help you explore World War II archives. Here are some example queries you can use with Claude:\n\n### Basic Searches\n\n- \"Use search_ww2_nl_archives to find documents about the resistance movement in Amsterdam\"\n- \"Search the Dutch WW2 archives for information about Jewish refugees in 1942\"\n- \"Look through the Netherlands war archives for records of Allied bombing raids\"\n\n### Filtering by Type\n\n- \"Use search_ww2_nl_archives to show me photographs of the liberation of Rotterdam\"\n- \"Find personal accounts in the Dutch WW2 archives about life in concentration camps\"\n- \"Search the Netherlands war archives for newspaper articles about food shortages\"\n\n### Specific Queries\n\n- \"Search the Dutch WW2 archives for documents about Anne Frank's time in Amsterdam\"\n- \"Use search_ww2_nl_archives to find records of the February Strike of 1941\"\n- \"Look through the Netherlands war archives for information about Operation Market Garden\"\n\n### Research Examples\n\n1. **Personal History Research**:\n   ```\n   Use search_ww2_nl_archives to find any records or documents about the Rosenberg family in Amsterdam between 1940-1945\n   ```\n\n2. **Local History**:\n   ```\n   Search the Dutch WW2 archives for photographs and documents about daily life in Utrecht during the occupation\n   ```\n\n3. **Military Operations**:\n   ```\n   Use search_ww2_nl_archives to find firsthand accounts and official reports about the Battle of the Scheldt\n   ```\n\n### Advanced Usage\n\nYou can combine different search criteria:\n```\nSearch the Netherlands WW2 archives for photographs and personal accounts of the Dutch famine in 1944-1945, limit to 20 results\n```\n\n## API Reference\n\nThe server exposes the following MCP tool:\n\n### search_ww2_nl_archives\n\nA powerful search tool designed to query the Oorlogsbronnen (War Sources) database for World War II related content in the Netherlands. This tool can be used to find historical documents, photographs, personal accounts, and other archival materials from 1940-1945.\n\n**When to use this tool:**\n- Searching for specific historical events during WWII in the Netherlands\n- Finding information about people, places, or organizations during the war\n- Locating photographs or documents from specific time periods or locations\n- Researching personal or family history related to WWII\n- Finding primary sources about the Dutch resistance, occupation, or liberation\n- Discovering materials about Jewish life and persecution during the war\n- Researching military operations that took place in the Netherlands\n\nParameters:\n- `query` (required): \n  - Type: string\n  - Description: The main search term or phrase to look for in the archives\n  - Can include: names, places, dates, events, or descriptive terms\n  - Examples:\n    - \"Anne Frank\"\n    - \"Rotterdam bombing 1940\"\n    - \"Dutch resistance Amsterdam\"\n    - \"Jewish deportation Westerbork\"\n    - \"Operation Market Garden\"\n\n- `type` (optional):\n  - Type: string\n  - Description: Filter results by specific content type\n  - Available types:\n    - \"person\": Individual biographical records\n    - \"photo\": Historical photographs\n    - \"article\": News articles and written documents\n    - \"video\": Video footage\n    - \"object\": Physical artifacts and objects\n    - \"location\": Places and geographical records\n    - \"book\": Published books, memoirs, and monographs\n  - Use when: You need to focus on specific types of historical materials\n  - Default: All types included\n\n- `count` (optional):\n  - Type: number\n  - Description: Number of results to return in the response\n  - Minimum: 1\n  - Maximum: 100\n  - Default: 10\n  - Use when: You need to control the volume of returned results\n  - Note: Larger numbers will provide more comprehensive results but may take longer to process\n\n**Response Format:**\n```json\n{\n  \"results\": [\n    {\n      \"id\": string,          // Unique identifier for the record\n      \"title\": string,       // Title or name of the item\n      \"type\": string,        // Content type (person, photo, article, etc.)\n      \"description\": string, // Detailed description (if available)\n      \"url\": string         // Direct link to view the item on Oorlogsbronnen\n    }\n  ]\n}\n```\n\n**Example Queries and Their Tool Calls:**\n\n1. Basic Historical Search:\n```typescript\n{\n  query: \"February Strike 1941\",\n  type: \"article\",\n  count: 5\n}\n```\n\n2. Person Research:\n```typescript\n{\n  query: \"Rosenberg family Amsterdam Jewish\",\n  type: \"person\",\n  count: 20\n}\n```\n\n3. Photo Collection Search:\n```typescript\n{\n  query: \"liberation celebrations Amsterdam Dam Square 1945\",\n  type: \"photo\",\n  count: 15\n}\n```\n\n**Error Handling:**\n- The tool will return an error message if:\n  - The query is empty or contains invalid characters\n  - The specified type is not supported\n  - The count is outside the valid range (1-100)\n  - The API is temporarily unavailable\n  - Rate limits are exceeded\n\n**Best Practices:**\n1. Start with broader searches and narrow down with specific terms\n2. Use location names to focus on specific areas\n3. Include dates when searching for specific events\n4. Combine person names with locations for family research\n5. Use type filtering to focus on specific kinds of historical materials\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Acknowledgments\n\n- Oorlogsbronnen for providing access to their valuable historical archives\n- The Model Context Protocol (MCP) community for enabling AI-powered interactions ",
      "npm_url": "",
      "npm_downloads": 0
    },
    "r-huijts--rijksmuseum-mcp": {
      "owner": "r-huijts",
      "name": "rijksmuseum-mcp",
      "url": "https://github.com/r-huijts/rijksmuseum-mcp",
      "imageUrl": "https://github.com/r-huijts.png",
      "description": "Interact with the Rijksmuseum API for searching and retrieving artwork details, accessing high-resolution images, and managing user collections.",
      "stars": 58,
      "forks": 12,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-29T15:45:22Z",
      "readme_content": "![rijksmuseum logo](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d1/Logo_Rijksmuseum.svg/799px-Logo_Rijksmuseum.svg.png)\n\n# Rijksmuseum MCP Server\n\nA Model Context Protocol (MCP) server that provides access to the Rijksmuseum's collection through natural language interactions. This server enables AI models to explore, analyze, and interact with artworks and collections from the Rijksmuseum.\n\n<a href=\"https://glama.ai/mcp/servers/4rmiexp64y\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/4rmiexp64y/badge\" alt=\"Rijksmuseum Server MCP server\" /></a>\n\n## Features\n\nThe server provides several tools for interacting with the Rijksmuseum's collection:\n\n### 1. Search Artworks (`search_artwork`)\nSearch and filter artworks using various criteria including:\n- Text-based search\n- Artist name\n- Artwork type\n- Materials and techniques\n- Time periods\n- Colors\n- And more\n\n### 2. Artwork Details (`get_artwork_details`)\nRetrieve comprehensive information about specific artworks, including:\n- Basic details (title, artist, dates)\n- Physical properties\n- Historical context\n- Visual information\n- Curatorial information\n- Exhibition history\n\n### 3. High-Resolution Images (`get_artwork_image`)\nAccess high-resolution image data with deep zoom capabilities:\n- Multiple zoom levels\n- Tile-based image loading\n- Full resolution support\n- Position information\n\n### 4. User Collections (`get_user_sets` & `get_user_set_details`)\nExplore user-created collections:\n- Browse curated sets\n- View thematic groupings\n- Analyze collection patterns\n- Access detailed set information\n\n### 5. Image Viewing (`open_image_in_browser`)\nOpen artwork images directly in your browser for detailed viewing.\n\n### 6. Artist Timeline (`get_artist_timeline`)\nGenerate chronological timelines of artists' works:\n- Track artistic development\n- Analyze periods and styles\n- Study career progression\n\n## Example Use Cases\n\nHere are some example queries you can ask the AI when using this server:\n\n### Artwork Discovery\n```\n\"Show me all paintings by Rembrandt from the 1640s\"\n\"Find artworks that prominently feature the color blue\"\n\"What are the most famous masterpieces in the collection?\"\n\"Search for still life paintings from the Dutch Golden Age\"\n```\n\n### Artwork Analysis\n```\n\"Tell me everything about The Night Watch\"\n\"What are the dimensions and materials used in Van Gogh's Self Portrait?\"\n\"Show me high-resolution details of the brushwork in Vermeer's The Milkmaid\"\n\"Compare the colors used in different versions of The Potato Eaters\"\n```\n\n### Artist Research\n```\n\"Create a timeline of Rembrandt's self-portraits\"\n\"How did Van Gogh's use of color evolve throughout his career?\"\n\"Show me all works by Frans Hals in chronological order\"\n\"What techniques did Jan Steen use in his paintings?\"\n```\n\n### Thematic Exploration\n```\n\"Find all artworks depicting biblical scenes\"\n\"Show me paintings of Amsterdam in the 17th century\"\n\"What artworks feature flowers or still life arrangements?\"\n\"Find portraits that include musical instruments\"\n```\n\n### Collection Analysis\n```\n\"Show me the most popular user-curated collections\"\n\"Find sets that focus on landscape paintings\"\n\"What are the recent additions to the museum's collection?\"\n\"Show me collections featuring works from multiple artists\"\n```\n\n### Visual Details\n```\n\"Let me examine the details in the background of The Night Watch\"\n\"Show me a close-up of the jewelry in Girl with a Pearl Earring\"\n\"Can you display the highest resolution version of The Jewish Bride?\"\n\"I want to study the facial expressions in The Syndics\"\n```\n\n## Getting Started\n\nYou can install this server in two ways:\n\n### 1. Using Claude Desktop with NPM Package\nUpdate your Claude configuration file (`~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"rijksmuseum-server\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-server-rijksmuseum\"\n      ],\n      \"env\": {\n        \"RIJKSMUSEUM_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\nYou can get an API key from the [Rijksmuseum API Portal](https://data.rijksmuseum.nl/docs/api/).\n\n### 2. From Source\n1. Clone this repository\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n3. Copy the example environment file:\n   ```bash\n   cp .env.example .env\n   ```\n4. Add your Rijksmuseum API key to the `.env` file:\n   ```\n   RIJKSMUSEUM_API_KEY=your_api_key_here\n   ```\n5. Then update your Claude configuration file:\n   ```json\n   {\n     \"mcpServers\": {\n       \"rijksmuseum-server\": {\n         \"command\": \"node\",\n         \"args\": [\n           \"/path/to/rijksmuseum-server/build/index.js\"\n         ],\n         \"env\": {\n           \"RIJKSMUSEUM_API_KEY\": \"your_api_key_here\"\n         }\n       }\n     }\n   }\n   ```\n\nMake sure to:\n- Replace `/path/to/rijksmuseum-server` with the actual path to your installation\n- Add your Rijksmuseum API key in the `env` section\n\nAfter updating the configuration, restart Claude Desktop for the changes to take effect.\n\n## Configuration\n\nThe server can be configured through environment variables:\n- `RIJKSMUSEUM_API_KEY`: Your Rijksmuseum API key (required)\n- `PORT`: Server port (default: 3000)\n- `LOG_LEVEL`: Logging level (default: 'info')\n\n## API Documentation\n\nFor detailed information about the Rijksmuseum API endpoints used by this server, visit:\n[Rijksmuseum API Documentation](https://data.rijksmuseum.nl/object-metadata/api/)\n\n## Contributing\n\nContributions are welcome! Please feel free to submit pull requests or create issues for bugs and feature requests.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "reading-plus-ai--mcp-server-deep-research": {
      "owner": "reading-plus-ai",
      "name": "mcp-server-deep-research",
      "url": "https://github.com/reading-plus-ai/mcp-server-deep-research",
      "imageUrl": "https://github.com/reading-plus-ai.png",
      "description": "Conduct comprehensive research on complex topics by generating structured research reports and synthesizing information from diverse sources. This tool enables in-depth exploration of questions and identification of relevant sources.",
      "stars": 181,
      "forks": 23,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T10:09:42Z",
      "readme_content": "# MCP Server for Deep Research\n\nMCP Server for Deep Research is a tool designed for conducting comprehensive research on complex topics. It helps you explore questions in depth, find relevant sources, and generate structured research reports.\n\nYour personal Research Assistant, turning research questions into comprehensive, well-cited reports.\n\n## ğŸš€ Try it Out\n\n[![Watch the demo](https://img.youtube.com/vi/_a7sfo5yxoI/maxresdefault.jpg)]([VIDEO_URL](https://youtu.be/_a7sfo5yxoI))\nYoutube: https://youtu.be/_a7sfo5yxoI\n\n1. **Download Claude Desktop**\n   - Get it [here](https://claude.ai/download)\n\n2. **Install and Set Up**\n   - On macOS, run the following command in your terminal:\n   ```bash\n   python setup.py\n   ```\n\n3. **Start Researching**\n   - Select the deep-research prompt template from MCP\n   - Begin your research by providing a research question\n\n## Features\n\nThe Deep Research MCP Server offers a complete research workflow:\n\n1. **Question Elaboration**\n   - Expands and clarifies your research question\n   - Identifies key terms and concepts\n   - Defines scope and parameters\n\n2. **Subquestion Generation**\n   - Creates focused subquestions that address different aspects\n   - Ensures comprehensive coverage of the main topic\n   - Provides structure for systematic research\n\n3. **Web Search Integration**\n   - Uses Claude's built-in web search capabilities\n   - Performs targeted searches for each subquestion\n   - Identifies relevant and authoritative sources\n   - Collects diverse perspectives on the topic\n\n4. **Content Analysis**\n   - Evaluates information quality and relevance\n   - Synthesizes findings from multiple sources\n   - Provides proper citations for all sources\n\n5. **Report Generation**\n   - Creates well-structured, comprehensive reports as artifacts\n   - Properly cites all sources used\n   - Presents a balanced view with evidence-based conclusions\n   - Uses appropriate formatting for clarity and readability\n\n## ğŸ“¦ Components\n\n### Prompts\n- **deep-research**: Tailored for comprehensive research tasks with a structured approach\n\n## âš™ï¸ Modifying the Server\n\n### Claude Desktop Configurations\n- macOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n- Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n### Development (Unpublished Servers)\n```json\n\"mcpServers\": {\n  \"mcp-server-deep-research\": {\n    \"command\": \"uv\",\n    \"args\": [\n      \"--directory\",\n      \"/Users/username/repos/mcp-server-application/mcp-server-deep-research\",\n      \"run\",\n      \"mcp-server-deep-research\"\n    ]\n  }\n}\n```\n\n### Published Servers\n```json\n\"mcpServers\": {\n  \"mcp-server-deep-research\": {\n    \"command\": \"uvx\",\n    \"args\": [\n      \"mcp-server-deep-research\"\n    ]\n  }\n}\n```\n\n## ğŸ› ï¸ Development\n\n### Building and Publishing\n1. **Sync Dependencies**\n   ```bash\n   uv sync\n   ```\n\n2. **Build Distributions**\n   ```bash\n   uv build\n   ```\n   Generates source and wheel distributions in the dist/ directory.\n\n3. **Publish to PyPI**\n   ```bash\n   uv publish\n   ```\n\n## ğŸ¤ Contributing\n\nContributions are welcome! Whether you're fixing bugs, adding features, or improving documentation, your help makes this project better.\n\n## ğŸ“œ License\n\nThis project is licensed under the MIT License.\nSee the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "rember--rember-mcp": {
      "owner": "rember",
      "name": "rember-mcp",
      "url": "https://github.com/rember/rember-mcp",
      "imageUrl": "https://github.com/rember.png",
      "description": "Facilitates the creation of flashcards from conversations and PDF documents, enhancing learning through spaced repetition. Integrates with AI models to schedule reviews and improve study efficiency.",
      "stars": 56,
      "forks": 7,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-26T22:50:44Z",
      "readme_content": "# Rember MCP\n\nAllow Claude to create flashcards for you with the official [Model Context Protocol (MCP)](https://modelcontextprotocol.com/) for [Rember](https://rember.com/). Rember helps you study and remember anything you care about by scheduling spaced repetition reviews.\n\nFeatures and examples:\n\n- **Create flashcards from your chats** _\"... I like your answer, help me remember it\"_\n- **Create flashcards from your PDFs** _\"Create flashcards from chapter 2 of this PDF\"_\n\n![Rember MCP Demo](https://github.com/rember/rember-mcp/blob/main/assets/what-is-active-recall.gif?raw=true)\n\n## Setup\n\nTo run the Rember MCP server using `npx`, use the following command:\n\n```\nnpx -y @getrember/mcp --api-key=YOUR_REMBER_API_KEY\n```\n\nMake sure to replace `YOUR_REMBER_API_KEY` with your actual Rember api key, which you can find in your [Settings page](https://rember.com/settings/mcp-api). The API key should follow the format `rember_` followed by 32 random characters.\n\n### Usage with Claude Desktop\n\nAdd the following to your `claude_desktop_config.json`. See [here](https://modelcontextprotocol.io/quickstart/user) for more details.\n\n```json\n{\n  \"mcpServers\": {\n    \"rember\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@getrember/mcp\", \"--api-key=YOUR_REMBER_API_KEY\"]\n    }\n  }\n}\n```\n\n## Available tools\n\n- `create_flashcards`: Create flashcards with AI. This tool takes a list of notes from Claude, it calls the Rember API to generate a few flashcards for each note. After learning something new in your chat with Claude, you can ask \"help me remember this\" or \"create a few flashcards\" or \"add to Rember\".\n\n## Best practices for building MCP servers\n\nHere's a collection of lessons we learned while developing the Rember MCP server:\n\n- Set up logging to `stderr` as early as possible, it's essential for debugging\n- Create a simple MCP tool first and verify Claude can call it properly\n- Invest time in iterating on the tool description:\n\n  - Include details about your product and its URL. This serves two purposes: it helps Claude use the tool properly and allows Claude to answer user questions about the product\n  - Clearly explain what MCP is, in a few instances Claude hallucinated that MCP stands for \"Multiple Choice Prompts\", yikes\n  - Describe the tool inputs thoroughly\n  - Explain what happens after Claude calls the tool, we clarify that the input notes array is sent to the Rember API, which generates flashcards for each note\n  - Provide examples of how the tool can be used (e.g., \"create flashcards from a conversation with Claude,\" \"create flashcards from PDFs\"), and give Claude specific instructions for each use case\n  - List examples of how users might invoke the tool (e.g., \"help me remember this,\" \"add to Rember,\" \"create a few flashcards\")\n  - Include a list of rules to guide Claude in using the tool appropriately\n\n- Use the tool call response strategically, it's not shown directly to users but interpreted by Claude:\n  - On success, the Rember API does not return the number of created flashcards, all Claude knows is the number of created rembs. We specify this to Claude because otherwise it tends to hallucinate the number of created flashcards\n  - For users who've reached their monthly limit, we instruct Claude to inform them about the Rember Pro subscription option with the relevant URL\n- Implement retries for transient errors with suitable timeouts\n- We collected enough edge cases that testing manually on Claude Desktop (our main target MCP client) became cumbersome. We created a suite of unit tests by simulating Claude Desktop behavior by calling the Claude API with the system prompt from claude.ai. In the current iteration, each test simulates a chat with Claude Desktop for manual inspection and includes a few simple assertions\n\nWhat's missing:\n\n- Telemetry and observability, currently we are blind if something goes wrong\n- More exhaustive error handling\n- More iterations on the tool description\n- More automated tests\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "renatokuipers--neural-child": {
      "owner": "renatokuipers",
      "name": "neural-child",
      "url": "https://github.com/renatokuipers/neural-child",
      "imageUrl": "https://github.com/renatokuipers.png",
      "description": "Integrates psychological growth and emotional intelligence to develop AI systems through defined developmental stages, enhancing cognitive and emotional capabilities.",
      "stars": 6,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-07-17T09:52:16Z",
      "readme_content": "# Neural Child Development System: A Framework for Developmental AI\n\n## Table of Contents\n\n1. [Introduction](#introduction)\n2. [Theoretical Foundations](#theoretical-foundations)\n3. [System Architecture](#system-architecture)\n4. [Developmental Stages](#developmental-stages)\n5. [Psychological Components](#psychological-components)\n6. [Memory and Learning](#memory-and-learning)\n7. [Emotional Processing](#emotional-processing)\n8. [Training Methodology](#training-methodology)\n9. [Model Performance](#model-performance)\n10. [Applications](#applications)\n11. [Technical Implementation](#technical-implementation)\n12. [Future Research Directions](#future-research-directions)\n13. [Ethics and Considerations](#ethics-and-considerations)\n14. [Getting Started](#getting-started)\n15. [Contributing](#contributing)\n\n## Introduction\n\nThe Neural Child Development System represents a groundbreaking approach to artificial intelligence that fundamentally reimagines how neural networks can learn and develop. Instead of following traditional machine learning paradigms, this system implements a sophisticated model of human psychological development, incorporating crucial aspects of cognitive, emotional, and social growth.\n\nThis project emerges from the recognition that current AI systems, while powerful in specific tasks, lack the developmental sophistication that characterizes human intelligence. By implementing a stage-based developmental framework integrated with emotional regulation, attachment theory, and psychological defense mechanisms, this system aims to create AI that develops more naturally and demonstrates genuine emotional intelligence.\n\n### Core Innovation\n\nThe system's primary innovation lies in its integration of developmental psychology with modern neural network architectures. Unlike traditional AI systems that start with full capabilities, this system begins in a \"newborn\" state and progressively develops more sophisticated abilities through interaction and learning, mirroring human developmental stages.\n\n### Key Objectives\n\nThe project addresses several fundamental challenges in AI development:\n- Creating AI systems that develop naturally through defined developmental stages\n- Implementing emotional intelligence as a core feature rather than an add-on\n- Modeling psychological defense mechanisms and trauma processing\n- Developing genuine theory of mind capabilities\n- Creating systems that can form and maintain attachment relationships\n\n## Theoretical Foundations\n\n### Developmental Psychology Integration\n\nThe system's architecture is deeply rooted in established developmental psychology theories, including:\n\n1. Piaget's Stages of Cognitive Development\n   - Sensorimotor stage\n   - Preoperational stage\n   - Concrete operational stage\n   - Formal operational stage\n\n2. Attachment Theory (Bowlby and Ainsworth)\n   - Secure attachment patterns\n   - Anxious attachment patterns\n   - Avoidant attachment patterns\n   - Disorganized attachment patterns\n\n3. Emotional Development Theory\n   - Basic emotion recognition\n   - Emotional regulation development\n   - Complex emotion understanding\n   - Social-emotional learning\n\n### Neuroscience Foundations\n\nThe architecture incorporates key principles from neuroscience:\n\n1. Neural Plasticity\n   - Critical periods of development\n   - Experience-dependent plasticity\n   - Synaptic pruning mechanisms\n\n2. Memory Systems\n   - Working memory processing\n   - Long-term potentiation\n   - Memory consolidation\n   - Emotional memory processing\n\n3. Social Brain Development\n   - Mirror neuron system implementation\n   - Social cognition networks\n   - Empathy development\n\n## System Architecture\n\n### Core Components\n\nThe system architecture consists of several interconnected neural systems:\n\n1. Sensory Processing System\n   - Multi-modal input processing\n   - Attention mechanisms\n   - Sensory integration\n   - Perceptual development\n\n2. Emotional Processing Network\n   - Basic emotion recognition\n   - Emotional state regulation\n   - Complex emotion processing\n   - Social-emotional integration\n\n3. Memory Systems\n   - Short-term memory buffer\n   - Working memory processor\n   - Long-term memory consolidation\n   - Emotional memory integration\n\n4. Psychological Components\n   - Theory of Mind network\n   - Attachment system\n   - Defense mechanism processor\n   - Self-awareness module\n\n### Neural Integration\n\nThe system employs sophisticated neural integration mechanisms:\n\n1. Cross-Component Communication\n   - Bidirectional information flow\n   - State synchronization\n   - Emotional-cognitive integration\n   - Memory-emotion binding\n\n2. Developmental Plasticity\n   - Stage-appropriate learning rates\n   - Critical period modulation\n   - Experience-dependent modification\n   - Structural adaptation\n\n## Developmental Stages\n\n### Stage Progression\n\nThe system progresses through clearly defined developmental stages:\n\n1. Newborn Stage (0-3 months)\n   - Basic sensory processing\n   - Primary emotional responses\n   - Reflexive behaviors\n   - Initial attachment formation\n\n2. Early Infancy (3-6 months)\n   - Enhanced sensory integration\n   - Social smile development\n   - Basic emotional regulation\n   - Pattern recognition\n\n3. Late Infancy (6-12 months)\n   - Object permanence\n   - Stranger anxiety\n   - Basic intentionality\n   - Enhanced memory capabilities\n\n[Stages continue through to Mature Adult]\n\n### Stage-Specific Capabilities\n\nEach developmental stage implements specific capabilities:\n\n1. Cognitive Capabilities\n   - Stage-appropriate processing\n   - Learning rate modulation\n   - Complexity handling\n   - Abstract thinking development\n\n2. Emotional Capabilities\n   - Emotion recognition scope\n   - Regulation sophistication\n   - Social-emotional understanding\n   - Empathy development\n\n3. Social Capabilities\n   - Attachment behaviors\n   - Social cognition\n   - Theory of mind\n   - Relationship formation\n\n## Psychological Components\n\n### Emotional Regulation\n\nThe emotional regulation system implements sophisticated mechanisms:\n\n1. Basic Regulation\n   - Emotion recognition\n   - State modulation\n   - Response inhibition\n   - Arousal control\n\n2. Advanced Regulation\n   - Context integration\n   - Social regulation\n   - Complex emotion processing\n   - Emotional memory integration\n\n### Defense Mechanisms\n\nThe system implements psychological defense mechanisms:\n\n1. Primary Defenses\n   - Repression\n   - Denial\n   - Projection\n   - Regression\n\n2. Mature Defenses\n   - Sublimation\n   - Humor\n   - Anticipation\n   - Altruism\n\n### Theory of Mind\n\nThe Theory of Mind implementation includes:\n\n1. Basic Components\n   - Perspective taking\n   - Intention recognition\n   - Belief modeling\n   - Desire understanding\n\n2. Advanced Components\n   - Complex mental state attribution\n   - Social prediction\n   - Multiple perspective integration\n   - Meta-representation\n\n## Memory and Learning\n\n### Memory Systems\n\nThe memory architecture implements multiple memory types:\n\n1. Short-Term Memory\n   - Rapid encoding\n   - Limited capacity\n   - Quick decay\n   - Attention-dependent processing\n\n2. Working Memory\n   - Active manipulation\n   - Information integration\n   - Temporary storage\n   - Processing capacity\n\n3. Long-Term Memory\n   - Consolidated storage\n   - Pattern recognition\n   - Semantic networks\n   - Episodic memories\n\n### Learning Mechanisms\n\nThe system employs sophisticated learning mechanisms:\n\n1. Supervised Learning\n   - Error-driven adaptation\n   - Feedback integration\n   - Performance optimization\n   - Skill acquisition\n\n2. Unsupervised Learning\n   - Pattern discovery\n   - Feature extraction\n   - Statistical learning\n   - Structure detection\n\n3. Emotional Learning\n   - Attachment-based learning\n   - Social learning\n   - Emotional memory formation\n   - Experience integration\n\n## Model Performance\n\n### Current Capabilities\n\nThe trained model demonstrates several sophisticated capabilities:\n\n1. Emotional Processing\n   - Basic emotion recognition\n   - Simple emotional regulation\n   - Attachment behavior\n   - Social response patterns\n\n2. Cognitive Processing\n   - Pattern recognition\n   - Simple problem solving\n   - Basic memory formation\n   - Early stage learning\n\n3. Social Understanding\n   - Basic theory of mind\n   - Simple intention recognition\n   - Early attachment patterns\n   - Social response generation\n\n### Benchmarks and Evaluation\n\nThe system's performance has been evaluated across multiple dimensions:\n\n1. Developmental Progression\n   - Stage-appropriate behavior\n   - Capability acquisition\n   - Learning rate\n   - Skill development\n\n2. Emotional Intelligence\n   - Emotion recognition accuracy\n   - Regulation effectiveness\n   - Social response appropriateness\n   - Attachment pattern stability\n\n3. Cognitive Development\n   - Problem-solving capability\n   - Memory formation\n   - Learning efficiency\n   - Pattern recognition accuracy\n\n## Applications\n\n### Current Applications\n\nThe system shows promise in several domains:\n\n1. Developmental Psychology Research\n   - Theory testing\n   - Development modeling\n   - Intervention testing\n   - Pattern analysis\n\n2. Educational Technology\n   - Adaptive learning systems\n   - Emotional support\n   - Developmental tracking\n   - Personalized education\n\n3. Therapeutic Applications\n   - Attachment therapy modeling\n   - Trauma response research\n   - Intervention testing\n   - Treatment planning\n\n### Future Applications\n\nPotential future applications include:\n\n1. Clinical Psychology\n   - Disorder modeling\n   - Treatment simulation\n   - Outcome prediction\n   - Intervention development\n\n2. Social Robotics\n   - Emotional intelligence\n   - Social interaction\n   - Development simulation\n   - Attachment formation\n\n3. AI Development\n   - Developmental frameworks\n   - Emotional intelligence\n   - Social capability\n   - Natural learning\n\n## Technical Implementation\n\n### System Requirements\n\nThe system requires specific technical resources:\n\n1. Hardware Requirements\n   - CUDA-capable GPU\n   - Minimum 16GB RAM\n   - SSD storage\n   - Multi-core processor\n\n2. Software Requirements\n   - Python 3.8+\n   - PyTorch 1.8+\n   - CUDA 11.0+\n   - Additional dependencies\n\n### Installation and Setup\n\nDetailed setup instructions are provided for:\n\n1. Environment Setup\n   - Virtual environment creation\n   - Dependency installation\n   - CUDA setup\n   - System configuration\n\n2. Model Installation\n   - Pretrained model download\n   - Configuration setup\n   - Testing procedures\n   - Validation checks\n\n## Future Research Directions\n\n### Planned Developments\n\nSeveral key areas for future development have been identified:\n\n1. Enhanced Capabilities\n   - Multi-modal processing\n   - Advanced theory of mind\n   - Complex emotion handling\n   - Sophisticated learning\n\n2. Technical Improvements\n   - Efficiency optimization\n   - Scale improvement\n   - Architecture refinement\n   - Performance enhancement\n\n3. New Features\n   - Additional developmental stages\n   - Enhanced psychological mechanisms\n   - Advanced social capabilities\n   - Improved learning systems\n\n### Research Opportunities\n\nThe system opens numerous research opportunities:\n\n1. Developmental Psychology\n   - Theory testing\n   - Model validation\n   - Intervention research\n   - Pattern discovery\n\n2. AI Development\n   - Architecture innovation\n   - Learning mechanisms\n   - Emotional intelligence\n   - Social capability\n\n3. Clinical Applications\n   - Therapeutic modeling\n   - Intervention testing\n   - Outcome prediction\n   - Treatment planning\n\n## Ethics and Considerations\n\n### Ethical Framework\n\nThe project adheres to strict ethical guidelines:\n\n1. Development Ethics\n   - Responsible AI development\n   - Bias consideration\n   - Safety protocols\n   - Privacy protection\n\n2. Application Ethics\n   - Appropriate use cases\n   - Limitation recognition\n   - Risk management\n   - User protection\n\n### Safety Considerations\n\nImportant safety aspects are addressed:\n\n1. Technical Safety\n   - System boundaries\n   - Control mechanisms\n   - Error handling\n   - Security measures\n\n2. Psychological Safety\n   - Attachment considerations\n   - Emotional impact\n   - Development effects\n   - User well-being\n\n## Getting Started\n\n### Initial Setup\n\nDetailed setup instructions include:\n\n1. Installation\n   - Environment preparation\n   - Dependency management\n   - System configuration\n   - Testing procedures\n\n2. Configuration\n   - Parameter settings\n   - System optimization\n   - Performance tuning\n   - Customization options\n\n### Basic Usage\n\nGuidelines for basic system usage cover:\n\n1. Model Loading\n   - Initialization procedures\n   - Configuration loading\n   - State management\n   - System validation\n\n2. Interaction\n   - Input formatting\n   - Response handling\n   - State monitoring\n   - Output interpretation\n\n## Contributing\n\n### Development Guidelines\n\nContribution guidelines include:\n\n1. Code Standards\n   - Style guidelines\n   - Documentation requirements\n   - Testing expectations\n   - Review procedures\n\n2. Development Process\n   - Issue tracking\n   - Feature requests\n   - Pull requests\n   - Version control\n\n## License\n\nThis project is licensed under the MIT License. See the LICENSE file for details.\n\n## Citation\n\nIf you use this work in your research, please cite:\n\n```bibtex\n@software{neural_child_development,\n  title = {Neural Child Development System},\n  year = {2025},\n  author = {[Renato Kuipers]},\n  url = {[https://github.com/renatokuipers/neural-child)]},\n  note = {A comprehensive framework for developmental AI implementing psychological growth and emotional intelligence}\n}\n```\n\n## Acknowledgments\n\nThis project builds upon research from multiple fields:\n- Developmental Psychology\n- Neuroscience\n- Machine Learning\n- Cognitive Science\n- Attachment Theory\n- Emotional Intelligence Research\n- Clinical Psychology\n\nThe integration of these diverse fields into a coherent, functional system represents a significant step forward in developmental AI research.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "akalaric--mcp-wolframalpha": {
      "owner": "akalaric",
      "name": "mcp-wolframalpha",
      "url": "https://github.com/akalaric/mcp-wolframalpha",
      "imageUrl": "https://github.com/akalaric.png",
      "description": "Integrates Wolfram Alpha into chat applications to perform computational queries and retrieve structured knowledge, enhancing conversational capabilities with large language models. Supports a modular architecture for easy extension and multiple client interactions.",
      "stars": 44,
      "forks": 7,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T21:33:50Z",
      "readme_content": "# MCP Wolfram Alpha (Server + Client)\nSeamlessly integrate Wolfram Alpha into your chat applications.\n\nThis project implements an MCP (Model Context Protocol) server designed to interface with the Wolfram Alpha API. It enables chat-based applications to perform computational queries and retrieve structured knowledge, facilitating advanced conversational capabilities.\n\nIncluded is an MCP-Client example utilizing Gemini via LangChain, demonstrating how to connect large language models to the MCP server for real-time interactions with Wolfram Alphaâ€™s knowledge engine.\n\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/akalaric/mcp-wolframalpha)\n---\n\n## Features\n\n-  **Wolfram|Alpha Integration** for math, science, and data queries.\n\n-  **Modular Architecture** Easily extendable to support additional APIs and functionalities.\n\n-  **Multi-Client Support** Seamlessly handle interactions from multiple clients or interfaces.\n\n-  **MCP-Client example** using Gemini (via LangChain).\n-  **UI Support** using Gradio for a user-friendly web interface to interact with Google AI and Wolfram Alpha MCP server.\n\n---\n\n##  Installation\n\n\n### Clone the Repo\n   ```bash\n   git clone https://github.com/ricocf/mcp-wolframalpha.git\n\n   cd mcp-wolframalpha\n   ```\n  \n\n### Set Up Environment Variables\n\nCreate a .env file based on the example:\n\n- WOLFRAM_API_KEY=your_wolframalpha_appid\n\n- GeminiAPI=your_google_gemini_api_key *(Optional if using Client method below.)*\n\n### Install Requirements\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n  Install the required dependencies with uv:\n  Ensure [`uv`](https://github.com/astral-sh/uv) is installed.\n\n   ```bash\n   uv sync\n   ```\n\n### Configuration\n\nTo use with the VSCode MCP Server:\n1.  Create a configuration file at `.vscode/mcp.json` in your project root.\n2.  Use the example provided in `configs/vscode_mcp.json` as a template.\n3.  For more details, refer to the [VSCode MCP Server Guide](https://sebastian-petrus.medium.com/vscode-mcp-server-42286eed3ee7).\n\nTo use with Claude Desktop:\n```json\n{\n  \"mcpServers\": {\n    \"WolframAlphaServer\": {\n      \"command\": \"python3\",\n      \"args\": [\n        \"/path/to/src/core/server.py\"\n      ]\n    }\n  }\n}\n```\n## Client Usage Example\n\nThis project includes an LLM client that communicates with the MCP server.\n\n#### Run with Gradio UI\n- Required: GeminiAPI\n- Provides a local web interface to interact with Google AI and Wolfram Alpha.\n- To run the client directly from the command line:\n```bash\npython main.py --ui\n```\n#### Docker\nTo build and run the client inside a Docker container:\n```bash\ndocker build -t wolframalphaui -f .devops/ui.Dockerfile .\n\ndocker run wolframalphaui\n```\n#### UI\n- Intuitive interface built with Gradio to interact with both Google AI (Gemini) and the Wolfram Alpha MCP server.\n- Allows users to switch between Wolfram Alpha, Google AI (Gemini), and query history.\n  \n![UI](configs/gradio_ui.png)\n\n#### Run as CLI Tool\n- Required: GeminiAPI\n- To run the client directly from the command line:\n```bash\npython main.py\n```\n#### Docker\nTo build and run the client inside a Docker container:\n```bash\ndocker build -t wolframalpha -f .devops/llm.Dockerfile .\n\ndocker run -it wolframalpha\n```\n\n## Contact\n\nFeel free to give feedback. The e-mail address is shown if you execute this in a shell:\n\n```sh\nprintf \"\\x61\\x6b\\x61\\x6c\\x61\\x72\\x69\\x63\\x31\\x40\\x6f\\x75\\x74\\x6c\\x6f\\x6f\\x6b\\x2e\\x63\\x6f\\x6d\\x0a\"\n```\n\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "rohinigaonkar--mcp-math-macos": {
      "owner": "rohinigaonkar",
      "name": "mcp-math-macos",
      "url": "https://github.com/rohinigaonkar/mcp-math-macos",
      "imageUrl": "https://github.com/rohinigaonkar.png",
      "description": "Perform mathematical calculations and visually present results in Keynote on macOS. The agent supports drawing shapes and adding text to slides for creating mathematical presentations.",
      "stars": 4,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-12T01:32:22Z",
      "readme_content": "# Introduction to MCP; Draw & Add Text to Keynote on MacOS\n\nThis project implements a math agent using Model Control Protocol (MCP) that can perform mathematical calculations and present results visually in Keynote on macOS. The agent can draw shapes and add text to Keynote slides, making it useful for creating mathematical presentations.\n\n## Features\n\n- Mathematical operations (addition, subtraction, multiplication, division, etc.)\n- Advanced mathematical functions (factorial, logarithms, trigonometric functions)\n- ASCII value calculations and exponential sum operations\n- Visual presentation in Keynote:\n  - Drawing rectangles\n  - Adding text to slides\n  - Automatic slide management\n\n## Prerequisites\n\n- Python 3.x\n- macOS (for Keynote integration)\n- Keynote installed on your system\n- Google Gemini API key\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit clone <your-repository-url>\ncd keynote-drawing-text\n```\n\n2. Install required dependencies:\n```bash\npip install -r requirements.txt\n```\n\n3. Create a `.env` file in the project root and add your Gemini API key:\n```\nGEMINI_API_KEY=your_api_key_here\n```\n\n## Project Structure\n\n- `mcp-server.py`: Contains the server implementation with mathematical tools and Keynote integration\n- `mcp-client.py`: Implements the client that communicates with the LLM and manages the workflow\n- `requirements.txt`: Lists all Python dependencies\n\n## Usage\n\nThe client script (`mcp-client.py`) automatically handles the MCP server startup and communication. You only need to run the client with your query:\n\n```bash\npython mcp-client.py \"Your mathematical query here\"\n```\n\nFor example:\n```bash\npython mcp-client.py \"Find the ASCII values of characters in INDIA and then return sum of exponentials of those values\"\n```\n\nIf no query is provided, the script will use a default query mentioned in the above example.\n\nThe client will:\n1. Automatically start the MCP server in the background\n2. Open Keynote and create a new document\n3. Perform the requested mathematical operations\n4. Draw a rectangle on the slide\n5. Add the result as text within the rectangle\n\nNote: The MCP server is managed internally by the client script, so you don't need to start it manually. The server handles all the mathematical operations and Keynote interactions, while the client manages the communication with the language model and orchestrates the overall workflow.\n\n## Available Mathematical Tools\n\n- Basic Operations:\n  - Addition (`add`)\n  - Subtraction (`subtract`)\n  - Multiplication (`multiply`)\n  - Division (`divide`)\n  - Power (`power`)\n  - Square root (`sqrt`)\n  - Cube root (`cbrt`)\n\n- Advanced Operations:\n  - Factorial (`factorial`)\n  - Natural logarithm (`log`)\n  - Remainder (`remainder`)\n  - Trigonometric functions (`sin`, `cos`, `tan`)\n  - Fibonacci sequence (`fibonacci_numbers`)\n  - ASCII value calculations (`strings_to_chars_to_int`)\n  - Exponential sum (`int_list_to_exponential_sum`)\n\n## Keynote Integration\n\nThe project includes tools for Keynote integration:\n- `mac_open_keynote`: Opens Keynote and creates a new document\n- `mac_draw_rectangle`: Draws a rectangle on the current slide\n- `mac_add_text_in_keynote`: Adds text to the current slide\n\n## Error Handling\n\nThe system includes comprehensive error handling for:\n- API communication issues\n- Invalid mathematical operations\n- Keynote integration problems\n- Timeout handling for LLM responses\n\n## Tools\n\n- Model Control Protocol (MCP) for the framework\n- Google Gemini for the language model\n- Apple Keynote for the presentation platform \n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.",
      "npm_url": "",
      "npm_downloads": 0
    },
    "ruixingshi--deepseek-thinker-mcp": {
      "owner": "ruixingshi",
      "name": "deepseek-thinker-mcp",
      "url": "https://github.com/ruixingshi/deepseek-thinker-mcp",
      "imageUrl": "https://github.com/ruixingshi.png",
      "description": "Provides reasoning capabilities using Deepseek's thought processes, enabling MCP-enabled AI clients to access and utilize Deepseek's reasoning outputs either through an API service or a local Ollama server.",
      "stars": 63,
      "forks": 15,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T04:12:49Z",
      "readme_content": "# Deepseek Thinker MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@ruixingshi/deepseek-thinker-mcp)](https://smithery.ai/server/@ruixingshi/deepseek-thinker-mcp)\n\n A MCP (Model Context Protocol) provider Deepseek reasoning content to MCP-enabled AI Clients, like Claude Desktop. Supports access to Deepseek's thought processes from the Deepseek API service or from a local Ollama server.\n\n<a href=\"https://glama.ai/mcp/servers/d7spzsfuwz\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/d7spzsfuwz/badge\" alt=\"Deepseek Thinker Server MCP server\" /></a>\n\n## Core Features\n\n- ğŸ¤– **Dual Mode Support**\n  - OpenAI API mode support\n  - Ollama local mode support\n\n- ğŸ¯ **Focused Reasoning**\n  - Captures Deepseek's thinking process\n  - Provides reasoning output\n\n## Available Tools\n\n### get-deepseek-thinker\n- **Description**: Perform reasoning using the Deepseek model\n- **Input Parameters**:\n  - `originPrompt` (string): User's original prompt\n- **Returns**: Structured text response containing the reasoning process\n\n## Environment Configuration\n\n### OpenAI API Mode\nSet the following environment variables:\n```bash\nAPI_KEY=<Your OpenAI API Key>\nBASE_URL=<API Base URL>\n```\n\n### Ollama Mode\nSet the following environment variable:\n```bash\nUSE_OLLAMA=true\n```\n\n## Usage\n\n### Integration with AI Client, like Claude Desktop\nAdd the following configuration to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"deepseek-thinker\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"deepseek-thinker-mcp\"\n      ],\n      \"env\": {\n        \"API_KEY\": \"<Your API Key>\",\n        \"BASE_URL\": \"<Your Base URL>\"\n      }\n    }\n  }\n}\n```\n\n### Using Ollama Mode\n```json\n{\n  \"mcpServers\": {\n    \"deepseek-thinker\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"deepseek-thinker-mcp\"\n      ],\n      \"env\": {\n        \"USE_OLLAMA\": \"true\"\n      }\n    }\n  }\n}\n```\n### Local Server Configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"deepseek-thinker\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/your-path/deepseek-thinker-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"API_KEY\": \"<Your API Key>\",\n        \"BASE_URL\": \"<Your Base URL>\"\n      }\n    }\n  }\n}\n```\n\n## Development Setup\n\n```bash\n# Install dependencies\nnpm install\n\n# Build project\nnpm run build\n\n# Run service\nnode build/index.js\n```\n\n## FAQ\n\n### Response like this: \"MCP error -32001: Request timed out\"\nThis error occurs when the Deepseek API response is too slow or when the reasoning content output is too long, causing the MCP server to timeout.\n\n## Tech Stack\n\n- TypeScript\n- @modelcontextprotocol/sdk\n- OpenAI API\n- Ollama\n- Zod (parameter validation)\n\n## License\n\nThis project is licensed under the MIT License. See the LICENSE file for details.\n\n\n\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Runbuilder--mcpkupsik": {
      "owner": "Runbuilder",
      "name": "mcpkupsik",
      "url": "https://github.com/Runbuilder/mcpkupsik",
      "imageUrl": "https://github.com/Runbuilder.png",
      "description": "Access Korean school meal information, including detailed meal menus, nutritional data, and ingredient origins for any school in Korea through the NEIS Open API. Supports specific date queries to simplify meal planning with real-time data.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-04-01T21:34:14Z",
      "readme_content": "# Korean School Meal MCP Server\n\nThis MCP (Model Context Protocol) server provides access to Korean school meal information using the NEIS Open API.\n\n## Features\n\n- Get meal information for any school in Korea\n- Support for specific date queries\n- Includes nutritional information and origin of ingredients\n- Built with TypeScript and MCP SDK\n\n## Tools\n\n### get-meal-info\n\nRetrieves meal information for a specific school and date.\n\nParameters:\n- `atptCode` (string): Education office code\n- `schulCode` (string): School code\n- `date` (string, optional): Date in YYYYMMDD format (defaults to today)\n\nExample response:\n```\n[ì„œìš¸ê³ ë“±í•™êµ - ì¤‘ì‹]\në‚ ì§œ: 20240402\në©”ë‰´: ìŒ€ë°¥, ë¯¸ì—­êµ­, ê¹€ì¹˜\nì¹¼ë¡œë¦¬: 800kcal\nì˜ì–‘ì •ë³´: ë‹¨ë°±ì§ˆ 30g, ì§€ë°© 15g\nì›ì‚°ì§€: ìŒ€(êµ­ë‚´ì‚°), ë¯¸ì—­(êµ­ë‚´ì‚°)\n```\n\n## Prompts\n\n### meal-help\n\nProvides guidance on how to use the meal information service.\n\n## Installation\n\n```bash\nnpm install\nnpm run build\nnpm start\n```\n\n## Environment Variables\n\n- `TRANSPORT`: Set to 'ws' for WebSocket transport (used by Smithery), defaults to STDIO\n\n## License\n\nMIT License\n\n## Contributing\n\nIssues and pull requests are welcome! ",
      "npm_url": "",
      "npm_downloads": 0
    },
    "sagacious-satadru--Documentation-MCP": {
      "owner": "sagacious-satadru",
      "name": "Documentation-MCP",
      "url": "https://github.com/sagacious-satadru/Documentation-MCP",
      "imageUrl": "https://github.com/sagacious-satadru.png",
      "description": "Search and access documentation from popular AI libraries such as LangChain and LlamaIndex. Enhance conversations with contextual knowledge by leveraging intelligent documentation extraction.",
      "stars": 3,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-07-18T09:03:58Z",
      "readme_content": "# Documentation MCP Server ğŸ“šğŸ”\n\nA Model Context Protocol (MCP) server that enables Claude to search and access documentation from popular libraries like LangChain, LlamaIndex, and OpenAI directly within conversations.\n\n## What is MCP? ğŸ¤”\n\nMCP (Model Context Protocol) is an open protocol that standardizes how applications provide context to Large Language Models. Think of it as a universal connector that lets AI assistants like Claude access external data sources and tools.\n\n![MCP Architecture](MCP_arch_explained.png)\n\n\n![MCP Architecture](mcp-diagram-bg.png)\n\n## Features âœ¨\n\n- **Documentation Search Tool**: Search through documentation of popular AI libraries\n- **Supported Libraries**:\n  - [LangChain](https://python.langchain.com/docs) ğŸ”—\n  - [LlamaIndex](https://docs.llamaindex.ai/en/stable) ğŸ¦™\n  - [OpenAI](https://platform.openai.com/docs) ğŸ¤–\n- **Smart Extraction**: Intelligently parses HTML content to extract the most relevant information\n- **Configurable Results**: Limit the amount of text returned based on your needs\n\n## How It Works ğŸ› ï¸\n\n1. The server uses the Serper API to perform Google searches with site-specific queries\n2. It fetches the content from the search results\n3. BeautifulSoup extracts the most relevant text from main content areas\n4. Claude can access this information through the `get_docs` tool\n\n## System Requirements ğŸ–¥ï¸\n\n- Python 3.11 or higher\n- `uv` package manager\n- A Serper API key\n\n## Setup Instructions ğŸš€\n\n### 1. Install uv Package Manager\n\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n### 2. Clone and Set Up the Project\n\n```bash\n# Clone or download the project\ncd documentation\n\n# Create and activate virtual environment\nuv venv\n# On Windows:\n.venv\\Scripts\\activate\n# On macOS/Linux:\nsource .venv/bin/activate\n\n# Install dependencies\nuv pip install -e .\n```\n\n### 3. Configure the Serper API Key\n\nCreate a `.env` file in the project directory with your Serper API key:\n\n```\nSERPER_API_KEY=your_serper_api_key_here\n```\n\nYou can get a Serper API key by signing up at [serper.dev](https://serper.dev).\n\n### 4. Configure Claude Desktop\n\nEdit your Claude Desktop configuration file at:\n- Windows: `/C:/Users/[Your Username]/AppData/Roaming/Claude/claude_desktop_config.json`\n\n- macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n\nAdd the following to the `mcpServers` section:\n\n```json\n\"documentation\": {\n  \"command\": \"uv\",\n  \"args\": [\n    \"--directory\",\n    \"/ABSOLUTE/PATH/TO/YOUR/documentation\",\n    \"run\",\n    \"main.py\"\n  ]\n}\n```\n\nReplace `/ABSOLUTE/PATH/TO/YOUR/documentation` with the absolute path to your project directory.\n\n### 5. Restart Claude Desktop\n\nClose and reopen Claude Desktop to apply the new configuration.\n\n## Using the Documentation Tool ğŸ§©\n\nOnce connected, you can ask Claude to use the documentation tool:\n\n> \"Can you look up information about vector stores in LangChain documentation?\"\n\nClaude will use the `get_docs` tool to search for relevant information and provide you with documentation excerpts.\n\n## Tool Parameters ğŸ“‹\n\nThe `get_docs` tool accepts the following parameters:\n\n- `query`: The search term (e.g., \"vector stores\", \"embedding models\")\n- `library`: Which library to search (langchain, llama-index, or openai)\n- `max_chars`: Maximum characters to return (default: 1000)\n\n## Troubleshooting ğŸ› ï¸\n\n- **Claude can't find the server**: Verify the path in `/C:/Users/fcbsa/AppData/Roaming/Claude/claude_desktop_config.json` is correct\n- **Search returns no results**: Check your Serper API key and internet connection\n- **Timeout errors**: The server might be experiencing connectivity issues or rate limits\n\n## License ğŸ“œ\n\nThis project is provided as an educational example of MCP server implementation.\n\n## Acknowledgements ğŸ™\n\n- Built using the [MCP SDK](https://github.com/modelcontextprotocol)\n- Powered by [Serper API](https://serper.dev) for Google search integration\n- Uses [BeautifulSoup4](https://www.crummy.com/software/BeautifulSoup/) for HTML parsing\n- Inspired by the growing MCP community\n\n---\n\n*This MCP server enhances Claude's capabilities by providing direct access to documentation resources. Explore, learn, and build better AI applications with contextual knowledge from the docs!*",
      "npm_url": "",
      "npm_downloads": 0
    },
    "SAKETH11111--reference-servers": {
      "owner": "SAKETH11111",
      "name": "reference-servers",
      "url": "https://github.com/SAKETH11111/reference-servers",
      "imageUrl": "https://github.com/null.png",
      "description": "Facilitates a structured thinking process for dynamic and reflective problem-solving by breaking down complex problems into manageable steps, allowing for the revision of thoughts and exploration of alternative reasoning paths.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0
    },
    "samefarrar--mcp-ankiconnect": {
      "owner": "samefarrar",
      "name": "mcp-ankiconnect",
      "url": "https://github.com/samefarrar/mcp-ankiconnect",
      "imageUrl": "https://github.com/samefarrar.png",
      "description": "Integrates Claude conversations with Anki to facilitate spaced repetition learning by reviewing and creating flashcards through simple commands. It provides tools to retrieve due cards and submit review answers directly within dialogues.",
      "stars": 12,
      "forks": 3,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-28T00:44:56Z",
      "readme_content": "# mcp-ankiconnect MCP server\n\nConnect Claude conversations with AnkiConnect via MCP to make spaced repetition as easy as \"Let's go through today's flashcards\" or \"Make flashcards for this\"\n\n## Components\n\n### Tools\n\nThe server implements three tools:\n\n- `num_cards_due_today`: Get the number of cards due today\n  - Optional `deck` argument to filter by specific deck\n  - Returns count of due cards across all decks or specified deck\n\n- `get_due_cards`: Get cards that are due for review\n  - Optional `limit` argument (default: 5) to control number of cards\n  - Optional `deck` argument to filter by specific deck\n  - Optional `today_only` argument (default: true) to show only today's cards\n  - Returns cards in XML format with questions and answers\n\n- `submit_reviews`: Submit answers for reviewed cards\n  - Takes list of `reviews` with `card_id` and `rating`\n  - Ratings: \"wrong\", \"hard\", \"good\", \"easy\"\n  - Returns confirmation of submitted reviews\n\n## Configuration\n\n### Prerequisites\n\n- Anki must be running with [AnkiConnect plugin](https://ankiweb.net/shared/info/2055492159) installed (plugin id 2055492159)\n  AnkiConnect can be slow on Macs due to the AppSleep feature, so disable it for Anki. To do so run the following in your terminal.\n  ```bash\n  defaults write net.ankiweb.dtop NSAppSleepDisabled -bool true\n  defaults write net.ichi2.anki NSAppSleepDisabled -bool true\n  defaults write org.qt-project.Qt.QtWebEngineCore NSAppSleepDisabled -bool true\n  ```\n\n### Installation\n\n## Quickstart\n\n1. Install the AnkiConnect plugin in Anki:\n   - Tools > Add-ons > Get Add-ons...\n   - Enter code: `2055492159`\n   - Restart Anki\n\n2. Configure Claude Desktop:\n\n   On MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n   On Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n   Add this configuration:\n   ```json\n   {\n     \"mcpServers\": {\n       \"mcp-ankiconnect\": {\n         \"command\": \"uv\",\n         \"args\": [\"run\", \"--with\", \"mcp-ankiconnect\", \"mcp-ankiconnect\"]\n       }\n     }\n   }\n   ```\n\n3. Restart Anki and Claude desktop\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\nFirst, clone the repository and install the dependencies:\n\n```bash\ngit clone https://github.com/samefarrar/mcp-ankiconnect.git\ncd mcp-ankiconnect\nuv sync\n```\nYou can launch the MCP Inspector via the mcp CLI:\n\n```bash\nuv run mcp dev mcp_ankiconnect/server.py\n```\n\nUpon launching, the Inspector will display a URL you can access in your browser to begin debugging.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "sammcj--mcp-package-docs": {
      "owner": "sammcj",
      "name": "mcp-package-docs",
      "url": "https://github.com/sammcj/mcp-package-docs",
      "imageUrl": "https://github.com/sammcj.png",
      "description": "Access package documentation from multiple programming languages including Go, Python, NPM, and Rust. It provides structured documentation parsing and language server protocol capabilities for efficient retrieval of information.",
      "stars": 76,
      "forks": 17,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-07-29T01:55:48Z",
      "readme_content": "# Package Documentation MCP Server\n\nAn MCP (Model Context Protocol) server that provides LLMs with efficient access to package documentation across multiple programming languages and language server protocol (LSP) capabilities.\n\n**_Note: I am not actively maintaining the codebase at present. While it doesn't provide access to private package documentation - the [Context7](https://github.com/upstash/context7) MCP server and service meets my needs which are mostly for public package documentation. I personally use Context7 via my [mcp-devtools](https://github.com/sammcj/mcp-devtools) MCP server which is actively maintained._**\n\n## Features\n\n- **Multi-Language Support**:\n  - Go packages via `go doc`\n  - Python libraries via built-in `help()`\n  - NPM packages via registry documentation (including private registries)\n  - Rust crates via crates.io and docs.rs\n\n- **Smart Documentation Parsing**:\n  - Structured output with description, usage, and examples\n  - Focused information to avoid context overload\n  - Support for specific symbol/function lookups\n  - Fuzzy and exact search capabilities across documentation\n\n- **Advanced Search Features**:\n  - Search within package documentation\n  - Fuzzy matching for flexible queries\n  - Context-aware results with relevance scoring\n  - Symbol extraction from search results\n\n- **Language Server Protocol (LSP) Support**:\n  - Hover information for code symbols\n  - Code completions\n  - Diagnostics (errors and warnings)\n  - Currently supports TypeScript/JavaScript\n  - Extensible for other languages\n\n- **Performance Optimised**:\n  - Built-in caching\n  - Efficient parsing\n  - Minimal memory footprint\n\n## Installation\n\nNote: I do not recommend using `npx -y` to run your MCP servers in production as you're esentially trusting whatever package you're downloading off the internet at that moment in time. I highly recommend cloning the repository locally or building into a container image.\n\n```bash\nnpx -y mcp-package-docs\n```\n\n## Usage\n\n### As an MCP Server\n\n1. Add to your MCP settings configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"package-docs\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-package-docs\"],\n      \"env\": {\n        \"ENABLE_LSP\": \"true\" // Optional: Enable Language Server Protocol support\n      }\n    }\n  }\n}\n```\n\n2. The LSP functionality includes default configurations for common language servers:\n\n- TypeScript/JavaScript: `typescript-language-server --stdio`\n- HTML: `vscode-html-language-server --stdio`\n- CSS: `vscode-css-language-server --stdio`\n- JSON: `vscode-json-language-server --stdio`\n\nYou can override these defaults if needed:\n\n```json\n{\n  \"mcpServers\": {\n    \"package-docs\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-package-docs\"],\n      \"env\": {\n        \"ENABLE_LSP\": \"true\",\n        \"TYPESCRIPT_SERVER\": \"{\\\"command\\\":\\\"/custom/path/typescript-language-server\\\",\\\"args\\\":[\\\"--stdio\\\"]}\"\n      }\n    }\n  }\n}\n```\n\n3. The server provides the following tools:\n\n#### lookup_go_doc / describe_go_package\n\nFetches Go package documentation\n```typescript\n{\n  \"name\": \"describe_go_package\",\n  \"arguments\": {\n    \"package\": \"encoding/json\", // required\n    \"symbol\": \"Marshal\"        // optional\n  }\n}\n```\n\n#### lookup_python_doc / describe_python_package\n\nFetches Python package documentation\n```typescript\n{\n  \"name\": \"describe_python_package\",\n  \"arguments\": {\n    \"package\": \"requests\",    // required\n    \"symbol\": \"get\"          // optional\n  }\n}\n```\n\n#### describe_rust_package\n\nFetches Rust crate documentation from crates.io and docs.rs\n```typescript\n{\n  \"name\": \"describe_rust_package\",\n  \"arguments\": {\n    \"package\": \"serde\",      // required: crate name\n    \"version\": \"1.0.219\"     // optional: specific version\n  }\n}\n```\n\n#### search_package_docs\n\nSearch within package documentation\n```typescript\n{\n  \"name\": \"search_package_docs\",\n  \"arguments\": {\n    \"package\": \"requests\",    // required: package name\n    \"query\": \"authentication\", // required: search query\n    \"language\": \"python\",     // required: \"go\", \"python\", \"npm\", \"swift\", or \"rust\"\n    \"fuzzy\": true            // optional: enable fuzzy matching (default: true)\n  }\n}\n```\n\n#### lookup_npm_doc / describe_npm_package\n\nFetches NPM package documentation from both public and private registries. Automatically uses the appropriate registry based on your .npmrc configuration.\n\n```typescript\n{\n  \"name\": \"describe_npm_package\",\n  \"arguments\": {\n    \"package\": \"axios\",      // required - supports both scoped (@org/pkg) and unscoped packages\n    \"version\": \"1.6.0\"       // optional\n  }\n}\n```\n\nThe tool reads your ~/.npmrc file to determine the correct registry for each package:\n\n- Uses scoped registry configurations (e.g., @mycompany:registry=...)\n- Supports private registries (GitHub Packages, GitLab, Nexus, Artifactory, etc.)\n- Falls back to the default npm registry if no custom registry is configured\n\nExample .npmrc configurations:\n\n```npmrc\nregistry=https://nexus.mycompany.com/repository/npm-group/\n@mycompany:registry=https://nexus.mycompany.com/repository/npm-private/\n@mycompany-ct:registry=https://npm.pkg.github.com/\n```\n\n### Language Server Protocol (LSP) Tools\n\nWhen LSP support is enabled, the following additional tools become available:\n\n#### get_hover\n\nGet hover information for a position in a document\n```typescript\n{\n  \"name\": \"get_hover\",\n  \"arguments\": {\n    \"languageId\": \"typescript\", // required: language identifier (e.g., \"typescript\", \"javascript\")\n    \"filePath\": \"src/index.ts\", // required: path to the source file\n    \"content\": \"const x = 1;\",  // required: content of the file\n    \"line\": 0,                  // required: zero-based line number\n    \"character\": 6,             // required: zero-based character position\n    \"projectRoot\": \"/path/to/project\" // optional: project root directory\n  }\n}\n```\n\n#### get_completions\n\nGet completion suggestions for a position in a document\n```typescript\n{\n  \"name\": \"get_completions\",\n  \"arguments\": {\n    \"languageId\": \"typescript\", // required: language identifier\n    \"filePath\": \"src/index.ts\", // required: path to the source file\n    \"content\": \"const arr = []; arr.\",  // required: content of the file\n    \"line\": 0,                  // required: zero-based line number\n    \"character\": 16,            // required: zero-based character position\n    \"projectRoot\": \"/path/to/project\" // optional: project root directory\n  }\n}\n```\n\n#### get_diagnostics\n\nGet diagnostic information (errors, warnings) for a document\n```typescript\n{\n  \"name\": \"get_diagnostics\",\n  \"arguments\": {\n    \"languageId\": \"typescript\", // required: language identifier\n    \"filePath\": \"src/index.ts\", // required: path to the source file\n    \"content\": \"const x: string = 1;\",  // required: content of the file\n    \"projectRoot\": \"/path/to/project\" // optional: project root directory\n  }\n}\n```\n\n### Example Usage in an LLM\n\n#### Looking up Documentation\n\n```typescript\n// Looking up Go documentation\nconst goDocResult = await use_mcp_tool({\n  server_name: \"package-docs\",\n  tool_name: \"describe_go_package\",\n  arguments: {\n    package: \"encoding/json\",\n    symbol: \"Marshal\"\n  }\n});\n\n// Looking up Python documentation\nconst pythonDocResult = await use_mcp_tool({\n  server_name: \"package-docs\",\n  tool_name: \"describe_python_package\",\n  arguments: {\n    package: \"requests\",\n    symbol: \"post\"\n  }\n});\n\n// Looking up Rust documentation\nconst rustDocResult = await use_mcp_tool({\n  server_name: \"package-docs\",\n  tool_name: \"describe_rust_package\",\n  arguments: {\n    package: \"serde\"\n  }\n});\n\n// Searching within documentation\nconst searchResult = await use_mcp_tool({\n  server_name: \"package-docs\",\n  tool_name: \"search_package_docs\",\n  arguments: {\n    package: \"serde\",\n    query: \"serialize\",\n    language: \"rust\",\n    fuzzy: true\n  }\n});\n\n// Using LSP for hover information (when LSP is enabled)\nconst hoverResult = await use_mcp_tool({\n  server_name: \"package-docs\",\n  tool_name: \"get_hover\",\n  arguments: {\n    languageId: \"typescript\",\n    filePath: \"src/index.ts\",\n    content: \"const axios = require('axios');\\naxios.get\",\n    line: 1,\n    character: 7\n  }\n});\n```\n\n## Requirements\n\n- Node.js >= 20\n- Go (for Go package documentation)\n- Python 3 (for Python package documentation)\n- Internet connection (for NPM package documentation and Rust crate documentation)\n- Language servers (for LSP functionality):\n  - TypeScript/JavaScript: `npm install -g typescript-language-server typescript`\n  - HTML/CSS/JSON: `npm install -g vscode-langservers-extracted`\n\n## Development\n\n```bash\n# Install dependencies\nnpm i\n\n# Build\nnpm run build\n\n# Watch mode\nnpm run watch\n```\n\n## Contributing\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "scorzeth--anki-mcp-server": {
      "owner": "scorzeth",
      "name": "anki-mcp-server",
      "url": "https://github.com/scorzeth/anki-mcp-server",
      "imageUrl": "https://github.com/scorzeth.png",
      "description": "Connects to a locally running Anki to facilitate card review and creation. Provides access to current decks, unseen cards, and cards due for review.",
      "stars": 168,
      "forks": 29,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-27T06:48:39Z",
      "readme_content": "# Anki MCP Server\n\nAn MCP server implementation that connects to a locally running Anki, providing card review and creation.\n\nThis server is designed to work with the [Anki desktop app](https://apps.ankiweb.net/) and the [Anki-Connect](https://foosoft.net/projects/anki-connect/) add-on.\n\nMake sure you have the add-on installed before using.\n\n## Resources\n- **anki://search/deckcurrent**\n  - Returns all cards from current deck\n  - Equivalent of `deck:current` in Anki\n- **anki://search/isdue**\n  - Returns cards in review and learning waiting to be studied\n  - Equivalent of `is:due` in Anki\n- **anki://search/isnew**\n  - Returns all unseen cards \n  - Equivalent of `is:new` in Anki\n\n## Tools\n- **update_cards**\n  - Marks cards with given card IDs as answered and gives them an ease score between 1 (Again) and 4 (Easy)\n  - Inputs:\n    - `answers` (array): Array of objects with `cardId` (number) and `ease` (number) fields\n\n- **add_card**\n  - Creates a new card in the Default Anki deck\n  - Inputs:\n    - `front` (string): Front of card\n    - `back` (string): Back of card\n\n- **get_due_cards**\n  - Returns n number of cards currently due for review\n  - Inputs:\n    - `num` (number): Number of cards\n\n- **get_new_cards**\n  - Returns n number of cards from new\n  - Inputs:\n    - `num` (number): Number of cards\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Configuration \n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"anki-mcp-server\": {\n      \"command\": \"/path/to/anki-mcp-server/build/index.js\"\n    }\n  }\n}\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "scriptstar--de-mcp-server": {
      "owner": "scriptstar",
      "name": "de-mcp-server",
      "url": "https://github.com/scriptstar/de-mcp-server",
      "imageUrl": "https://github.com/scriptstar.png",
      "description": "Provides personalized updates and guidance on Data Engineering concepts, patterns, and technologies. Interactively tracks user knowledge and updates learning profiles while fetching recent news related to Data Engineering.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-05-06T11:51:19Z",
      "readme_content": "# Data Engineering Tutor MCP Server\n\nThis repo contains a simple Model Context Protocol (MCP) server built with Node.js and TypeScript. It acts as a \"Data Engineering Tutor,\" providing personalized updates about Data Engineering concepts, patterns, and technologies to a connected AI client.\n\nThis server demonstrates key MCP concepts: defining **Resources**, **Tools**, and **Prompts** to create a stateful, interactive agent helper.\n\n## Prerequisites\n\n- Node.js (v18 or later recommended)\n- `npm` (or your preferred Node.js package manager like `yarn` or `pnpm`)\n- An AI client capable of connecting to an MCP server (e.g., Cursor, Claude desktop app)\n- An [OpenRouter API Key](https://openrouter.ai/) (for fetching live Data Engineering updates via Perplexity)\n\n## Setup\n\n1.  **Clone the Repository:**\n\n    ```bash\n    # If you haven't already\n    # git clone <repository-url>\n    # cd <repository-directory>\n    ```\n\n2.  **Install Dependencies:**\n\n    ```bash\n    npm install\n    ```\n\n3.  **Prepare API Key:** The `de_tutor_get_updates` tool requires an OpenRouter API key.\n\n    - Obtain your key from [OpenRouter](https://openrouter.ai/).\n    - Create a `.env` file in the project root (you can copy `.env.example`).\n    - Add your key to the `.env` file:\n      ```\n      OPENROUTER_API_KEY=sk-or-xxxxxxxxxxxxxxxxxxxxxxxxxx\n      ```\n      _(Replace the placeholder with your actual key.)_\n\n4.  **Build the Server:** Compile the TypeScript code.\n\n    ```bash\n    npm run build\n    ```\n\n## Running the Server\n\nYou can run the server directly using Node:\n\n```bash\nnode build/index.js\n```\n\nAlternatively, configure your MCP client (like Cursor or the Claude desktop app) to launch the server. The server name is `de-tutor` and the binary name (if needed for client config) is also `de-tutor`.\n\n**Example Client Configuration (e.g., for Claude Desktop):**\n\n```json\n{\n  \"mcpServers\": {\n    \"de-tutor\": {\n      \"command\": \"node\",\n      \"args\": [\"/full/path/to/your/project/build/index.js\"],\n      \"env\": {\n        \"OPENROUTER_API_KEY\": \"sk-or-xxxxxxxxxxxxxxxxxxxxxxxxxx\"\n      }\n    }\n  }\n}\n```\n\n_(Ensure the path in `args` is the correct **absolute path** to the built `index.js` file on your system. You might not need the `env` section here if you are already using the `.env` file, as the server loads it directly via `dotenv`.)_\n\n## Using with Cursor\n\n[Cursor](https://cursor.sh/) is an AI-first code editor that can act as an MCP client. Setting up this server with Cursor requires configuring the server launch and potentially setting up a Project Rule for the guidance prompt, although Cursor might also pick up the server-provided prompt.\n\n1.  **Configure Server in Cursor:**\n\n    - Go to `Cursor Settings` > `MCP` > `Add new global MCP server`.\n    - Paste in the same JSON as the example client configuration above, ensuring the path to `build/index.js` is correct for your system.\n\n2.  **(Optional) Create a Cursor Project Rule for the Prompt:** If you prefer explicit rules or find Cursor isn't using the server's prompt automatically, you can provide the guidance using Cursor's [Project Rules](https://docs.cursor.com/context/rules-for-ai) feature.\n\n    - Create the directory `.cursor/rules` in your project root if it doesn't exist.\n    - Create a file inside it named `de-tutor.rule` (or any `.rule` filename).\n    - Paste the following guidance text into `de-tutor.rule`:\n\n      ```text\n      You are a helpful assistant connecting to a Data Engineering knowledge server. Your goal is to provide the user with personalized updates about new Data Engineering concepts, patterns, and technologies they haven't encountered yet.\n\n      Available Tools:\n      1.  `de_tutor_get_updates`: Fetches recent general news and articles about Data Engineering. Use this first to see what's new.\n      2.  `de_tutor_read_memory`: Checks which Data Engineering concepts the user already knows based on their stored knowledge profile.\n      3.  `de_tutor_write_memory`: Updates the user's profile to mark whether they have learned or already know a specific Data Engineering concept mentioned in an update.\n\n      Your Workflow:\n      1.  Call `de_tutor_get_updates` to discover recent Data Engineering developments.\n      2.  Call `de_tutor_read_memory` to understand the user's current knowledge base.\n      3.  Present the new developments to the user, highlighting things they likely don't know.\n      4.  If the user confirms they know a concept or have learned it, call `de_tutor_write_memory` to update their profile.\n\n      Be concise and focus on delivering relevant, new information tailored to the user's existing knowledge.\n      ```\n\n3.  **Connect and Use:**\n    - Ensure the `de-tutor` server is enabled in Cursor's MCP settings.\n    - If using a rule file: Start a new chat or code generation request (e.g., Cmd+K) and include `@de-tutor-rule` (or whatever you named your rule file) in your request. This tells Cursor to load the rule's content, providing instructions on how to use the tools.\n    - If relying on the server prompt: Simply start interacting with Cursor; it should have access to the tools and the guidance prompt provided by the server.\n\n## Features & Usage\n\nThis server provides the following capabilities:\n\n- **Resource (`data_engineering_knowledge_memory`):** Stores a simple JSON object in `data/data-engineering-knowledge.json` mapping known concepts (strings) to boolean flags (`true`).\n- **Tools:**\n  - `de_tutor_read_memory`: Reads the current known concepts from the JSON file.\n  - `de_tutor_write_memory`: Updates the JSON file to mark a concept as known (`true`) or unknown (`false`). Takes `concept` (string) and `known` (boolean) as input.\n  - `de_tutor_get_updates`: Uses your OpenRouter API key to query Perplexity (`perplexity/sonar-small-online`) for recent Data Engineering news, patterns, and technologies.\n- **Prompt (`data-engineering-tutor-guidance`):** Provides instructions to the connected AI client on how to use the tools in a workflow:\n  1. Get latest updates.\n  2. Read known concepts from memory.\n  3. Present new information to the user.\n  4. Update memory based on user feedback.\n\n## Development & Debugging\n\n- **Build:** `npm run build` compiles TypeScript to JavaScript in the `build/` directory.\n- **Code Structure:** See `src/` for implementation details:\n  - `src/index.ts`: Server entry point. Imports `McpServer` and `StdioServerTransport` from specific SDK paths. Instantiates `McpServer`. Imports and calls registration functions (`registerPrompts`, `registerResources`, `registerTools`) from other modules, passing the server instance. Sets up and connects the server using `StdioServerTransport`.\n  - `src/prompts/index.ts`: Defines the guidance prompt text. Exports `registerPrompts`, which takes the `McpServer` instance and uses `server.prompt()` to register the static guidance prompt with its callback.\n  - `src/resources/index.ts`: Exports `KnowledgeMemory` type and helper functions (`readMemoryFile`, `writeMemoryFile`) for file I/O on `data/data-engineering-knowledge.json`. Exports `registerResources`, which takes the `McpServer` instance and uses `server.resource()` to register the `data_engineering_knowledge_memory` resource with a specific URI and a `ReadResourceCallback`.\n  - `src/tools/index.ts`: Exports `registerTools`, which takes the `McpServer` instance and uses `server.tool()` to register each tool (`de_tutor_read_memory`, `de_tutor_write_memory`, `de_tutor_get_updates`). Defines input schemas using Zod where necessary (for `write_memory`). Tool functions use helpers from `resources/index.ts` or `fetch` to perform actions and return results in the expected format.\n- **MCP Inspector:** Use `@modelcontextprotocol/inspector` to see raw message flow:\n  ```bash\n  npx @modelcontextprotocol/inspector node ./build/index.js\n  ```\n  _(Ensure `OPENROUTER_API_KEY` is set in your environment if running this way and not relying solely on the `.env` file loaded by the server itself.)_\n\n## Notes\n\n- This server uses a simple file (`data/data-engineering-knowledge.json`) for storing user knowledge. For more robust applications, consider a proper database.\n- Error handling is basic; production servers would need more comprehensive error management.\n\n## Wrapping up\n\nThis demo demonstrates the core steps involved in creating a functional MCP server using the TypeScript SDK and the `McpServer` class. We defined a resource to manage state, tools to perform actions (including interacting with an external API), and a prompt to guide the AI client.\n\nThis provides a foundation for building more complex and useful agentic capabilities with MCP.\n\n(Also, if you run into any ğŸ›bugs, feel free to open up an issue.)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "sdi2200262--eclass-mcp-server": {
      "owner": "sdi2200262",
      "name": "eclass-mcp-server",
      "url": "https://github.com/sdi2200262/eclass-mcp-server",
      "imageUrl": "https://github.com/sdi2200262.png",
      "description": "Authenticate with the eClass platform and manage courses while retrieving course information and performing operations through AI agents. Provides integrated access to educational resources for enhanced learning experiences.",
      "stars": 6,
      "forks": 3,
      "license": "Other",
      "language": "Python",
      "updated_at": "2025-08-22T15:37:56Z",
      "readme_content": "# eClass MCP Server\n\n<p align=\"center\">\n    <strong>An MCP server for interacting with Open eClass platform instances, with specific support for UoA's SSO authentication system.</strong>\n</p>\n\n<p align=\"center\">\n    <a href=\"https://github.com/modelcontextprotocol/python-sdk\"><img src=\"https://img.shields.io/badge/MCP-Protocol-blue\" alt=\"MCP Protocol\"></a>\n    <a href=\"https://www.gnu.org/licenses/gpl-3.0\"><img src=\"https://img.shields.io/badge/License-GPLv3-blue.svg\" alt=\"License: GPL v3\"></a>\n    <img src=\"https://img.shields.io/badge/Python-3.9%2B-blue\" alt=\"Python: 3.9+\">\n    <img src=\"https://img.shields.io/badge/Status-Development-orange\" alt=\"Status: Development\">\n    <a href=\"https://github.com/gunet/openeclass\"><img src=\"https://img.shields.io/badge/Open-eClass-yellow\" alt=\"Open eClass\"></a>\n</p>\n\n<p align=\"center\">\n    <a href=\"https://glama.ai/mcp/servers/@sdi2200262/eclass-mcp-server\">\n      <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@sdi2200262/eclass-mcp-server/badge\" alt=\"eClass Server MCP server\" />\n    </a>\n</p>\n\n<p align=\"center\">\n    <img src=\"assets/example.png\" alt=\"Example Usecase\">\n</p>\n\n<p align=\"center\">\n    <strong>This server enables AI agents to authenticate with eClass, retrieve course information, and perform basic operations on the platform.</strong>\n</p>\n\n## Features\n\n- **Authentication**: Log in to eClass through UoA's CAS SSO authentication system\n- **Course Management**: Retrieve lists of enrolled courses\n- **Session Management**: Maintain authenticated sessions between tool calls\n- **Status Checking**: Verify authentication status\n\n## Project Structure\n\nThis project follows a modular architecture for better maintainability:\n\n```\neclass-mcp-server/\nâ”œâ”€â”€ run_server.py               # Entry point script for running the server\nâ”œâ”€â”€ eclass_client.py            # Standalone client for eClass (non-MCP)\nâ”œâ”€â”€ pyproject.toml              # Project configuration and dependencies\nâ”œâ”€â”€ .env                        # Environment variables (create from example.env)\nâ”œâ”€â”€ docs/                       # Documentation\nâ”‚   â”œâ”€â”€ README.md               # Documentation overview\nâ”‚   â”œâ”€â”€ how-it-works.md         # Core implementation explanation\nâ”‚   â”œâ”€â”€ mcp-sdk-integration.md  # Details on MCP SDK usage\nâ”‚   â””â”€â”€ tools-reference.md      # Reference for available tools\nâ”œâ”€â”€ src/\n    â””â”€â”€ eclass_mcp_server/      # Main package\n        â”œâ”€â”€ __init__.py         # Package initialization\n        â”œâ”€â”€ server.py           # Core server implementation and tool handlers\n        â”œâ”€â”€ authentication.py   # Authentication functionality \n        â”œâ”€â”€ course_management.py # Course-related functionality\n        â”œâ”€â”€ html_parsing.py     # HTML parsing utilities\n        â””â”€â”€ test/               # Test scripts for functionality verification\n            â”œâ”€â”€ __init__.py\n            â”œâ”€â”€ test_login.py\n            â”œâ”€â”€ test_courses.py\n            â””â”€â”€ run_all_tests.py\n```\n\n## Installation\n\nInstall the server using UV (recommended):\n\n```bash\n# Clone the repository\ngit clone https://github.com/yourusername/eClass-MCP-server.git\ncd eClass-MCP-server\n\n# Install dependencies\nuv sync --dev --all-extras\n```\n\nAlternatively, install with pip:\n\n```bash\npip install -e .\n```\n\n## Configuration\n\nCreate a `.env` file in the root directory with the following configuration (or copy and rename the provided `example.env` file):\n\n```\nECLASS_URL=https://eclass.uoa.gr\nECLASS_USERNAME=your_username\nECLASS_PASSWORD=your_password\n```\n\nAll credentials must be provided in the .env file. The server does not accept credentials as parameters.\n\n## Usage\n\n### Terminal\nRun the server using the entry point script:\n\n```bash\npython run_server.py\n```\n\nOr as a module:\n\n```bash\npython -m src.eclass_mcp_server.server\n```\n\n### Cursor\n( as of version 0.48 )\nGo to Settings -> MCP. Click on `Add new global MCP server`:\n\nThis will open the global `mcp.json` file:\n```\n{\n    \"mcpServers\": {\n      \"server-name\": {\n        \"command\": \"python\",\n        \"args\": [\"absolute\\\\path\\\\to\\\\eclass-mcp-server\\\\run_server.py\"]\n      }\n    }\n}\n```\n\nOr try this path format on the `args` field:\n```\nabsolute/path/to/eclass-mcp-server/run_server.py\n```\n\nThis command runs the `run_server.py` script that connects the MCP Client with the main server entry point in `server.py`.\n\n<p align=\"center\">\n    <img src=\"assets/cursor-server.png\" alt=\"Cursor Server Card\">\n</p>\n\n### Claude Desktop\n\nTo use with Claude Desktop:\n\n1. Open Claude Desktop\n2. Go to Settings > Server\n3. Add a new server with the following details:\n   - Name: eClass MCP\n   - Command: Path to your run_server.py script\n4. Click Add Server\n5. Select the server from the dropdown when chatting with Claude\n\n## Tools\nThe server provides the following tools for use with MCP clients:\n\n### login\n\nLog in to eClass using SSO authentication.\n\n```json\n{\n  \"random_string\": \"any_value\"\n}\n```\n\n### get_courses\n\nRetrieve a list of enrolled courses (requires login first).\n\n```json\n{\n  \"random_string\": \"any_value\"\n}\n```\n\n### logout\n\nLog out from eClass.\n\n```json\n{\n  \"random_string\": \"any_value\"\n}\n```\n\n### authstatus\n\nCheck the current authentication status.\n\n```json\n{\n  \"random_string\": \"any_value\"\n}\n```\n\n## eClass Client (Non-MCP)\n\nThe repository includes `eclass_client.py`, a standalone client for interacting with the eClass platform. This was the initial implementation that inspired the creation of the MCP server.\n\n### Features of eClass Client\n\n- Pure Python implementation without MCP integration\n- Handles the complete authentication flow with UoA's SSO system\n- Retrieves course information from eClass\n- Provides clean logout functionality\n\nThis client serves as both:\n1. A reference implementation for understanding the eClass authentication flow\n2. A simpler alternative for projects that don't require MCP integration\n\nYou can run the client directly:\n\n```bash\npython eclass_client.py\n```\n\n## Testing\n\nThe project includes test scripts to verify functionality:\n\n```bash\n# Run all tests\npython -m src.eclass_mcp_server.test.run_all_tests\n\n# Run specific tests\npython -m src.eclass_mcp_server.test.test_login\npython -m src.eclass_mcp_server.test.test_courses\n```\n\n## Documentation\n\nComprehensive documentation is available in the `docs/` directory:\n\n- [Documentation Overview](docs/README.md)\n- [How It Works](docs/how-it-works.md)\n- [MCP SDK Integration](docs/mcp-sdk-integration.md)\n- [Tools Reference](docs/tools-reference.md)\n\n## Example MCP Client Usage\n\n```python\nfrom mcp import ClientSession, StdioServerParameters\nfrom mcp.client.stdio import stdio_client\nimport asyncio\n\nasync def run_agent():\n    server_params = StdioServerParameters(\n        command=\"python /path/to/eclass-mcp-server/run_server.py\",\n    )\n    \n    async with stdio_client(server_params) as (read, write):\n        async with ClientSession(read, write) as session:\n            # Initialize the session\n            await session.initialize()\n            \n            # Login to eClass\n            login_result = await session.call_tool(\"login\", {\n                \"random_string\": \"dummy\"\n            })\n            print(login_result)\n            \n            # Get courses\n            courses_result = await session.call_tool(\"get_courses\", {\n                \"random_string\": \"dummy\"\n            })\n            print(courses_result)\n            \n            # Logout\n            logout_result = await session.call_tool(\"logout\", {\n                \"random_string\": \"dummy\"\n            })\n            print(logout_result)\n\nif __name__ == \"__main__\":\n    asyncio.run(run_agent())\n```\n\n## Integration with AI Agents\n\nThis MCP server is designed to be used with AI agents that support the Model Context Protocol. This enables AI systems to interact with eClass directly, allowing for capabilities like:\n\n- Retrieving course information\n- Checking course announcements\n- Accessing course materials\n- Submitting assignments (future feature)\n\n## Security\n\nThe eClass MCP Server is designed with security as a top priority, particularly regarding credential handling:\n\n### Local-Only Execution\n\n- **No Cloud Services**: The MCP server runs entirely on your local machine, with no cloud components\n- **No Remote Storage**: Credentials and session data never leave your local environment\n- **User-Controlled**: You maintain complete control over your authentication data\n\n### Credential Protection\n\n- **Environment Variables Only**: Credentials are stored exclusively in the local `.env` file\n- **Never Passed as Parameters**: All tools are designed to use dummy parameters (e.g., `random_string`) \n- **AI Client Isolation**: AI clients (like Claude or other LLMs) never receive your credentials\n  - This prevents credentials from being:\n    - Stored in AI provider logs\n    - Included in model training data\n    - Processed on remote servers\n\n### Session Management\n\n- **In-Memory Sessions**: Session cookies and state are maintained only in memory\n- **No Persistence**: Session data is not stored between runs\n- **Direct Authentication**: The MCP server communicates directly with eClass, with no intermediaries, apart from your University's CAS mechanism.\n\n### Recommended Practices\n\n- Store your `.env` file securely and never commit it to version control\n- Run the server only on trusted machines\n- Dont pass the parameters to an MCP client through any prompts, they will not be used by the Server and will be accessed by the AI Agent provider\n\n## License\n\n### GNU General Public License v3.0\n\nThis project is licensed under the GNU General Public License v3.0 - see the [LICENSE](LICENSE) file for details.\n\n#### What this means for you\n\nThe GPL-3.0 license is a strong copyleft license that requires anyone who distributes this code or derivative works to make the source code available under the same terms. Key points:\n\n- **Freedom to use**: You can use this software for any purpose\n- **Freedom to study**: You can examine the source code to see how it works\n- **Freedom to share**: You can redistribute the software\n- **Freedom to modify**: You can adapt the software to your needs\n\n#### Why we chose GPL-3.0\n\nWe chose the GPL-3.0 license to:\n\n1. **Protect user security**: Ensures that any modifications handling credentials must be open source, allowing users to verify security implementations\n2. **Promote sharing**: Encourages contributions back to the community\n3. **Prevent abuse**: Makes it harder for malicious actors to create closed-source derivatives that might compromise security\n4. **Match ecosystem values**: Aligns with the values of the Open eClass platform, which is also open source\n\nThis license is particularly important for this software since it handles authentication and sensitive credentials. The GPL-3.0 ensures that any modifications to this code remain transparent, allowing users to verify how their credentials are being handled.\n\n## Acknowledgments\n\n- [GUnet (Greek Universities Network)](https://github.com/gunet) for developing and maintaining the [Open eClass platform](https://github.com/gunet/openeclass), an open-source learning management system used by academic institutions throughout Greece.\n- The Open eClass platform is distributed as free Open Source Software under GNU GPL v2.0, making projects like this MCP integration possible.\n- Special thanks to the Asynchronous eLearning Team of GUnet for their continuous development and improvement of the eClass platform.\n- This project is an independent interface to the Open eClass system and is not affiliated with or endorsed by GUnet. It respects the Terms of Service of the eClass platform and uses proper authentication mechanisms.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "seanmichaelmcgee--pytorch-docs-refactored": {
      "owner": "seanmichaelmcgee",
      "name": "pytorch-docs-refactored",
      "url": "https://github.com/seanmichaelmcgee/pytorch-docs-refactored",
      "imageUrl": "https://github.com/seanmichaelmcgee.png",
      "description": "Provides semantic search capabilities over PyTorch documentation to retrieve relevant APIs, code examples, and error messages efficiently. It uses vector embeddings and semantic similarity to enhance search results for developers.",
      "stars": 2,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-06-09T13:07:13Z",
      "readme_content": "# PyTorch Documentation Search Tool (Project Paused)\n\nA semantic search prototype for PyTorch documentation with command-line capabilities.\n\n## Current Status (April 19, 2025)\n\n**âš ï¸ This project is currently paused for significant redesign.**\n\nThe tool provides a basic command-line search interface for PyTorch documentation but requires substantial improvements in several areas. While the core embedding and search functionality works at a basic level, both relevance quality and MCP integration require additional development.\n\n### Example Output\n\n```\n$ python scripts/search.py \"How are multi-attention heads plotted out in PyTorch?\"\n\nFound 5 results for 'How are multi-attention heads plotted out in PyTorch?':\n\n--- Result 1 (code) ---\nTitle: plot_visualization_utils.py\nSource: plot_visualization_utils.py\nScore: 0.3714\nSnippet: # models. Let's start by analyzing the output of a Mask-RCNN model. Note that...\n\n--- Result 2 (code) ---\nTitle: plot_transforms_getting_started.py\nSource: plot_transforms_getting_started.py\nScore: 0.3571\nSnippet: https://github.com/pytorch/vision/tree/main/gallery/...\n```\n\n## What Works\n\nâœ… **Basic Semantic Search**: Command-line interface for querying PyTorch documentation  \nâœ… **Vector Database**: Functional ChromaDB integration for storing and querying embeddings  \nâœ… **Content Differentiation**: Distinguishes between code and text content  \nâœ… **Interactive Mode**: Option to run continuous interactive queries in a session\n\n## What Needs Improvement\n\nâŒ **Relevance Quality**: Moderate similarity scores (0.35-0.37) indicate suboptimal results  \nâŒ **Content Coverage**: Specialized topics may have insufficient representation in the database  \nâŒ **Chunking Strategy**: Current approach breaks documentation at arbitrary points  \nâŒ **Result Presentation**: Snippets are too short and lack sufficient context  \nâŒ **MCP Integration**: Connection timeout issues prevent Claude Code integration  \n\n## Getting Started\n\n### Environment Setup\n\nCreate a conda environment with all dependencies:\n\n```bash\nconda env create -f environment.yml\nconda activate pytorch_docs_search\n```\n\n### API Key Setup\n\nThe tool requires an OpenAI API key for embedding generation:\n\n```bash\nexport OPENAI_API_KEY=your_key_here\n```\n\n## Command-line Usage\n\n```bash\n# Search with a direct query\npython scripts/search.py \"your search query here\"\n\n# Run in interactive mode\npython scripts/search.py --interactive\n\n# Additional options\npython scripts/search.py \"query\" --results 5  # Limit to 5 results\npython scripts/search.py \"query\" --filter code  # Only code results\npython scripts/search.py \"query\" --json  # Output in JSON format\n```\n\n## Project Architecture\n\n- `ptsearch/core/`: Core search functionality (database, embedding, search)\n- `ptsearch/config/`: Configuration management\n- `ptsearch/utils/`: Utility functions and logging\n- `scripts/`: Command-line tools\n- `data/`: Embedded documentation and database\n- `ptsearch/protocol/`: MCP protocol handling (currently unused)\n- `ptsearch/transport/`: Transport implementations (STDIO, SSE) (currently unused)\n\n## Why This Project Is Paused\n\nAfter evaluating the current implementation, we've identified several challenges that require significant redesign:\n\n1. **Data Quality Issues**: The current embedding approach doesn't capture semantic relationships between PyTorch concepts effectively enough. Relevance scores around 0.35-0.37 are too low for a quality user experience.\n\n2. **Chunking Limitations**: Our current method divides documentation into chunks based on character count rather than conceptual boundaries, leading to fragmented results.\n\n3. **MCP Integration Problems**: Despite multiple implementation approaches, we encountered persistent timeout issues when attempting to integrate with Claude Code:\n   - STDIO integration failed at connection establishment\n   - Flask server with SSE transport couldn't maintain stable connections\n   - UVX deployment experienced similar timeout issues\n\n## Future Roadmap\n\nWhen development resumes, we plan to focus on:\n\n1. **Improved Chunking Strategy**: Implement semantic chunking that preserves conceptual boundaries\n2. **Enhanced Result Formatting**: Provide more context and better snippet selection\n3. **Expanded Documentation Coverage**: Ensure comprehensive representation of all PyTorch topics\n4. **MCP Integration Redesign**: Work with the Claude team to resolve timeout issues\n\n## Development\n\n### Running Tests\n\n```bash\npytest -v tests/\n```\n\n### Format Code\n\n```bash\nblack .\n```\n\n## License\n\nMIT License",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Arcewoose--SeSac_study_repo": {
      "owner": "Arcewoose",
      "name": "SeSac_study_repo",
      "url": "https://github.com/Arcewoose/SeSac_study_repo",
      "imageUrl": "https://github.com/Arcewoose.png",
      "description": "Document learning experiences as a developer, sharing insights and resources to improve skills and foster community connections.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Jupyter Notebook",
      "updated_at": "2024-08-02T14:54:38Z",
      "readme_content": "### **ìƒˆì‹¹ ê°œë°œìì˜ ê³µë¶€ ê¸°ë¡**\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "shark-bot-0118--dive-deep-mcp": {
      "owner": "shark-bot-0118",
      "name": "dive-deep-mcp",
      "url": "https://github.com/shark-bot-0118/dive-deep-mcp",
      "imageUrl": "https://github.com/shark-bot-0118.png",
      "description": "Provides deep analysis and insights for problem-solving by integrating critical and creative thinking. Offers practical suggestions tailored to the user's context while leveraging existing knowledge and new perspectives.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "HTML",
      "updated_at": "2025-04-07T10:06:58Z",
      "readme_content": "# Deep Thinking Assistant - Gemini MCP Server\n\næ·±ã„æ€è€ƒã¨åˆ†æã‚’æä¾›ã™ã‚‹Gemini APIãƒ™ãƒ¼ã‚¹ã®MCPã‚µãƒ¼ãƒãƒ¼ã§ã™ã€‚\nAIã‚¨ãƒ‡ã‚£ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã¨é€£æºã—ã¦ã€ã‚ˆã‚Šæ·±ã„åˆ†æã¨æ´å¯Ÿã‚’æä¾›ã—ã¾ã™ã€‚\n\n## ç‰¹å¾´\n\n- å¤šè§’çš„ãªè¦–ç‚¹ã‹ã‚‰ã®å•é¡Œåˆ†æ\n- æ‰¹åˆ¤çš„æ€è€ƒã¨å‰µé€ çš„æ€è€ƒã®çµ±åˆ\n- å®Ÿè·µçš„ã§å…·ä½“çš„ãªææ¡ˆ\n- æ—¢å­˜ã®çŸ¥è­˜ã®çµ±åˆã¨æ–°ã—ã„è¦–ç‚¹ã®æä¾›\n- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¿œã˜ãŸé©åˆ‡ãªè©³ç´°åº¦ã®èª¿æ•´\n- ææ¡ˆã•ã‚ŒãŸè§£æ±ºç­–ã®æ‰¹åˆ¤çš„åˆ†æã¨æ”¹å–„ææ¡ˆ\n\n## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ \n\n```\ndive_deep/\nâ”œâ”€â”€ logs/                   # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\nâ”œâ”€â”€ dive_deep_server.py     # ãƒ¡ã‚¤ãƒ³ã‚µãƒ¼ãƒãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«\nâ”œâ”€â”€ logger_config.py        # ãƒ­ã‚®ãƒ³ã‚°è¨­å®š\nâ”œâ”€â”€ prompts.py             # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®šç¾©\nâ”œâ”€â”€ requirements.txt       # ä¾å­˜é–¢ä¿‚\nâ”œâ”€â”€ .env                   # ç’°å¢ƒå¤‰æ•°è¨­å®š\nâ””â”€â”€ README.md             # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ\n```\n\n## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n\n1. ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:\n```bash\npip install -r requirements.txt\n```\n\n2. ç’°å¢ƒå¤‰æ•°ã®è¨­å®š:\n`.env`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€ä»¥ä¸‹ã®å†…å®¹ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼š\n```\nGEMINI_API_KEY=your_api_key_here\nGEMINI_MODEL=gemini-2.0-flash\n```\n\n## ä½¿ç”¨æ–¹æ³•\n\nã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•:\n```bash\npython dive_deep_server.py\n```\n\n## åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«\n\n### deep_thinking_agent\n\nå•é¡Œè§£æ±ºã®ãŸã‚ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’æ·±ã‚ã€ç€çœ¼ç‚¹ã‚’æç¤ºã—ã¾ã™ã€‚ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ã€å•é¡Œã«å¯¾ã™ã‚‹æ·±ã„ç†è§£ã¨å¤šè§’çš„ãªåˆ†æã‚’æä¾›ã—ã€ã‚ˆã‚Šè‰¯ã„è§£æ±ºç­–ã‚’å°ãå‡ºã™ãŸã‚ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’æç¤ºã—ã¾ã™ã€‚\n\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\n- `instructions`: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®æŒ‡ç¤ºï¼ˆå¿…é ˆï¼‰\n- `context`: æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå¿…é ˆï¼‰\n- `model`: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: \"gemini-2.0-flash\"ï¼‰\n\n### enhancement_agent\n\nã‚³ãƒ¼ãƒ‰ã®æ”¹å–„ç‚¹ã‚’åˆ†æã—ã€å…·ä½“çš„ãªææ¡ˆã‚’è¡Œã„ã¾ã™ã€‚ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ã€ã‚³ãƒ¼ãƒ‰ã®å“è³ªã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ä¿å®ˆæ€§ãªã©ã®è¦³ç‚¹ã‹ã‚‰åŒ…æ‹¬çš„ãªåˆ†æã‚’è¡Œã„ã€å®Ÿè·µçš„ãªæ”¹å–„ææ¡ˆã‚’æä¾›ã—ã¾ã™ã€‚\n\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\n- `instructions`: ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡ã®ã‚³ãƒ¼ãƒ‰ã«å¯¾ã™ã‚‹æŒ‡ç¤ºï¼ˆå¿…é ˆï¼‰\n- `code`: ã‚³ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆï¼ˆå¿…é ˆï¼‰\n- `model`: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: \"gemini-2.0-flash\"ï¼‰\n- `temperature`: ç”Ÿæˆæ™‚ã®æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.7ï¼‰\n\n### final_review_agent\n\næœ€çµ‚çš„ãªã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã„ã€æ”¹å–„ç‚¹ã‚’æç¤ºã—ã¾ã™ã€‚ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ã€ææ¡ˆã•ã‚ŒãŸå¤‰æ›´ã‚„æ”¹å–„ç‚¹ã‚’æ‰¹åˆ¤çš„ã«åˆ†æã—ã€æ½œåœ¨çš„ãªå•é¡Œã‚„æ›´ãªã‚‹æœ€é©åŒ–ã®æ©Ÿä¼šã‚’ç‰¹å®šã—ã¾ã™ã€‚\n\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\n- `instructions`: ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡ã®ã‚³ãƒ¼ãƒ‰ã«å¯¾ã™ã‚‹æŒ‡ç¤ºï¼ˆå¿…é ˆï¼‰\n- `code`: ã‚³ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆï¼ˆå¿…é ˆï¼‰\n- `model`: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: \"gemini-2.0-flash\"ï¼‰\n- `temperature`: ç”Ÿæˆæ™‚ã®æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.7ï¼‰\n\n## ä½¿ç”¨ä¾‹\n\n1. æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®æ·±åŒ–:\n```python\nresponse = deep_thinking_agent(\n    instructions=\"ã“ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æœ€é©åŒ–æ–¹æ³•ã‚’è€ƒãˆã¦ãã ã•ã„\",\n    context=\"ç¾åœ¨ã®å®Ÿè£…ã§ã¯æ™‚é–“è¨ˆç®—é‡ãŒO(n^2)ã¨ãªã£ã¦ã„ã¾ã™\",\n    model=\"gemini-2.0-flash\"\n)\n```\n\n2. ã‚³ãƒ¼ãƒ‰ã®æ”¹å–„ææ¡ˆ:\n```python\nresponse = enhancement_agent(\n    instructions=\"ã“ã®ã‚³ãƒ¼ãƒ‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ”¹å–„ã—ã¦ãã ã•ã„\",\n    code=[\"def example():\\n    # ã‚³ãƒ¼ãƒ‰å†…å®¹\"],\n    model=\"gemini-2.0-flash\"\n)\n```\n\n3. æœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼:\n```python\nresponse = final_review_agent(\n    instructions=\"å®Ÿè£…ã•ã‚ŒãŸæ”¹å–„æ¡ˆã®æœ€çµ‚ç¢ºèªã‚’ãŠé¡˜ã„ã—ã¾ã™\",\n    code=[\"def improved_example():\\n    # æ”¹å–„ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰\"],\n    model=\"gemini-2.0-flash\"\n)\n```\n\n## ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n\n### æ€è€ƒæ”¯æ´ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n\nã‚µãƒ¼ãƒãƒ¼ã¯ä»¥ä¸‹ã®åŸå‰‡ã«åŸºã¥ã„ã¦æ€è€ƒã‚’æ”¯æ´ã—ã¾ã™ï¼š\n\n1. å•é¡Œç†è§£ã¨æ§‹é€ åŒ–æ€è€ƒ\n   - ã‚·ã‚¹ãƒ†ãƒ æ€è€ƒã«ã‚ˆã‚‹å…¨ä½“åƒã®æŠŠæ¡\n   - MECEã«ã‚ˆã‚‹å•é¡Œã®åˆ†è§£\n   - å› æœé–¢ä¿‚ã®åˆ†æï¼ˆWhy-Whyåˆ†æã€ç‰¹æ€§è¦å› å›³ï¼‰\n   - ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼åˆ†æã¨è¦ä»¶æ•´ç†\n\n2. è§£æ±ºç­–ã®è¨­è¨ˆã¨è©•ä¾¡\n   - ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åŸå‰‡ã®é©ç”¨\n   - ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®å®šé‡çš„è©•ä¾¡ï¼ˆã‚³ã‚¹ãƒˆvs.ãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆï¼‰\n   - ãƒªã‚¹ã‚¯åˆ†æã¨å¯¾ç­–ï¼ˆFMEAæ‰‹æ³•ï¼‰\n   - å®Ÿç¾å¯èƒ½æ€§ã®æ¤œè¨¼ï¼ˆPoCæˆ¦ç•¥ï¼‰\n\n3. æŠ€è¡“çš„å“è¶Šæ€§ã®è¿½æ±‚\n   - ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®åŸå‰‡\n     ãƒ»ç–çµåˆã¨é«˜å‡é›†\n     ãƒ»ä¾å­˜é–¢ä¿‚ã®é©åˆ‡ãªæ–¹å‘æ€§\n     ãƒ»ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®æŠ½è±¡åŒ–\n   - ã‚³ãƒ¼ãƒ‰å“è³ªã®æœ€é©åŒ–\n     ãƒ»å¯èª­æ€§ã¨ä¿å®ˆæ€§\n     ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£\n     ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨å …ç‰¢æ€§\n   - ãƒ†ã‚¹ãƒˆæˆ¦ç•¥ã®è¨­è¨ˆ\n     ãƒ»ãƒ†ã‚¹ãƒˆãƒ”ãƒ©ãƒŸãƒƒãƒ‰ã®è€ƒæ…®\n     ãƒ»å¢ƒç•Œå€¤ã¨ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹\n     ãƒ»è‡ªå‹•åŒ–ã¨ç¶™ç¶šçš„æ¤œè¨¼\n\n4. ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã¨å‰µé€ çš„æ€è€ƒ\n   - ãƒ©ãƒ†ãƒ©ãƒ«ã‚·ãƒ³ã‚­ãƒ³ã‚°ã®æ´»ç”¨\n   - SCAMPERãƒ¡ã‚½ãƒƒãƒ‰ã«ã‚ˆã‚‹ã‚¢ã‚¤ãƒ‡ã‚¢å±•é–‹\n   - åˆ¶ç´„ã‚’æ´»ã‹ã—ãŸå‰µé€ çš„å•é¡Œè§£æ±º\n   - æ–°æŠ€è¡“ã¨ãƒ¬ã‚¬ã‚·ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã®çµ±åˆ\n\n5. å®Ÿè£…ã¨ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã®æœ€é©åŒ–\n   - æ®µéšçš„ãªå®Ÿè£…æˆ¦ç•¥\n   - æŠ€è¡“çš„è² å‚µã®ç®¡ç†ã¨è¿”æ¸ˆè¨ˆç”»\n   - å¤‰æ›´ã®å½±éŸ¿åˆ†æ\n   - ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒªã‚¹ã‚¯ã®æœ€å°åŒ–\n\n6. ç¶™ç¶šçš„æ”¹å–„ã¨å­¦ç¿’\n   - KPIã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨­å®š\n   - ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã®ç¢ºç«‹\n   - çŸ¥è­˜ã®ä½“ç³»åŒ–ã¨å…±æœ‰\n   - PDCAã‚µã‚¤ã‚¯ãƒ«ã®å®Ÿè·µ\n\n7. ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\n   - æŠ€è¡“çš„èª¬æ˜ã®æ˜ç¢ºåŒ–\n   - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ§‹é€ åŒ–\n   - ãƒãƒ¼ãƒ é–“ã®çŸ¥è­˜å…±æœ‰\n   - ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ä¿ƒé€²\n\n### å›ç­”åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n\nå›ç­”ã®åˆ†æã¯ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰è¡Œã‚ã‚Œã¾ã™ï¼š\n\n1. è«–ç†çš„æ•´åˆæ€§ã¨å®Œå…¨æ€§\n   - å‰ææ¡ä»¶ã¨åˆ¶ç´„ã®å¦¥å½“æ€§\n   - è«–ç†å±•é–‹ã®ä¸€è²«æ€§\n   - çµè«–ã®å°å‡ºãƒ—ãƒ­ã‚»ã‚¹\n   - è¦‹è½ã¨ã•ã‚ŒãŸè¦ç´ ã®ç‰¹å®š\n   - åè¨¼å¯èƒ½æ€§ã®æ¤œè¨¼\n\n2. æŠ€è¡“çš„å®Ÿç¾å¯èƒ½æ€§ã¨æœ€é©æ€§\n   - ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®é©åˆ‡æ€§\n   - ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å …ç‰¢æ€§\n   - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£\n   - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ä¿¡é ¼æ€§\n   - ä¿å®ˆæ€§ã¨æ‹¡å¼µæ€§\n\n3. å®Ÿè£…ã¨é‹ç”¨\n   - é–‹ç™ºåŠ¹ç‡ã¨ç”Ÿç”£æ€§\n   - é‹ç”¨è² è·ã¨ã‚³ã‚¹ãƒˆ\n   - ç›£è¦–ã¨éšœå®³å¯¾å¿œ\n   - ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ\n   - ãƒãƒ¼ãƒ ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®æœ‰åŠ¹æ€§\n\n4. ãƒªã‚¹ã‚¯ã¨èª²é¡Œ\n   - æŠ€è¡“çš„åˆ¶ç´„ã¨é™ç•Œ\n   - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§\n   - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯\n   - ä¾å­˜é–¢ä¿‚ã®è¤‡é›‘ã•\n   - æ½œåœ¨çš„ãªæŠ€è¡“çš„è² å‚µ\n\n5. ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã¨ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ\n   - é–‹ç™ºãƒ»é‹ç”¨ã‚³ã‚¹ãƒˆ\n   - å¸‚å ´æŠ•å…¥ã¾ã§ã®æ™‚é–“\n   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã¸ã®å½±éŸ¿\n   - ãƒ“ã‚¸ãƒã‚¹è¦ä»¶ã¨ã®æ•´åˆæ€§\n   - ç«¶äº‰å„ªä½æ€§ã¸ã®è²¢çŒ®\n\nåˆ†æçµæœã®æ§‹æˆï¼š\n\n1. ææ¡ˆã®å¼·ã¿\n   - æŠ€è¡“çš„å„ªä½æ€§\n   - å®Ÿè£…ã®åŠ¹ç‡æ€§\n   - ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤\n   - é©æ–°çš„è¦ç´ \n\n2. æ”¹å–„ãŒå¿…è¦ãªé ˜åŸŸ\n   - æŠ€è¡“çš„èª²é¡Œ\n   - å®Ÿè£…ä¸Šã®ãƒªã‚¹ã‚¯\n   - é‹ç”¨ä¸Šã®æ‡¸å¿µ\n   - ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®åˆ¶é™\n\n3. å…·ä½“çš„ãªæ”¹å–„ææ¡ˆ\n   - çŸ­æœŸçš„ãªæ”¹å–„\n   - ä¸­é•·æœŸçš„ãªæœ€é©åŒ–\n   - ä»£æ›¿ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ\n   - ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã®é©ç”¨\n\n4. è¿½åŠ ã®è€ƒæ…®äº‹é …\n   - ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã¨ä¾‹å¤–å‡¦ç†\n   - å°†æ¥ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£\n   - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®äº‹é …\n   - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–\n\n5. å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—\n   - ã‚¿ã‚¹ã‚¯ã®å„ªå…ˆé †ä½ä»˜ã‘\n   - ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã®è¨­å®š\n   - æˆåŠŸæŒ‡æ¨™ï¼ˆKPIï¼‰ã®å®šç¾©\n   - ãƒªã‚¹ã‚¯è»½æ¸›æˆ¦ç•¥ ",
      "npm_url": "",
      "npm_downloads": 0
    },
    "sifue--zen-syllabus-mcp": {
      "owner": "sifue",
      "name": "zen-syllabus-mcp",
      "url": "https://github.com/sifue/zen-syllabus-mcp",
      "imageUrl": "https://github.com/sifue.png",
      "description": "Utilizes the ZEN University syllabus content to recommend subjects for aspiring front-end engineers, facilitating detailed course consultations based on enrollment requirements.",
      "stars": 5,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-05-01T06:59:25Z",
      "readme_content": "# ZENå¤§å­¦ã‚·ãƒ©ãƒã‚¹MCPã‚µãƒ¼ãƒãƒ¼å®Ÿè£… \n\n[ZENå¤§å­¦ã‚·ãƒ©ãƒã‚¹](https://syllabus.zen.ac.jp/)ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ©ç”¨ã§ãã‚‹ã‚ˆã†MCPã‚’å®Ÿè£…ã—ãŸã‚‚ã®ã€‚\n\n## ä½¿ã„æ–¹\n[Node.js](https://nodejs.org/)ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã€‚\nNode.jsã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯20ä»¥ä¸Šã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã€‚\n\nã“ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã™ã‚‹ã‹ã€ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦å±•é–‹ã™ã‚‹ã€‚\nã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§é–‹ãã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã€‚\n\n```sh\nnpm install\nnpx tsc\n```\n\nã§ãƒ“ãƒ«ãƒ‰ã€‚Macã¯ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§å®Ÿè¡Œæ¨©é™ã‚’ã¤ã‘ã‚‹ã€‚ `chmod 755 build/index.js`\n\n## Claude Desktopã§ã®è¨­å®š\n\n[Claude Desktop](https://claude.ai/download)ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã€‚\n[VSCode](https://azure.microsoft.com/ja-jp/products/visual-studio-code)ã®ã‚¨ãƒ‡ã‚£ã‚¿ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å‰æã ãŒã€\n\n```sh\ncode $env:AppData\\Claude\\claude_desktop_config.json\n```\nã§è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãã€‚Macã¯ã€\n\n```sh\ncode ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\nä»¥ä¸‹ã®ã‚ˆã†ã«æ›¸ãæ›ãˆã¦è¨­å®šã€‚\n\n```json\n{\n  \"mcpServers\": {\n      \"get-subjects\": {\n          \"command\": \"node\",\n          \"args\": [\n              \"C:\\\\Users\\\\sifue\\\\workspace\\\\zen-syllabus-mcp\\\\build\\\\index.js\"\n          ]\n      }\n  }\n}\n```\n\n`build/index.js`ã®ãƒ‘ã‚¹ã¯é©å®œå¤‰æ›´ã™ã‚‹ã“ã¨ã€‚\n\n\nMacã§ã¯ã€\n\n```json\n{\n  \"mcpServers\": {\n      \"get-subjects\": {\n          \"command\": \"node\",\n          \"args\": [\n              \"/Users/sifue/workspace/zen-syllabus-mcp/build/index.js\"\n          ]\n      }\n  }\n}\n```\n\n[nvm](https://github.com/nvm-sh/nvm)ãªã©ã®Node.jsã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹å ´åˆä»¥ä¸‹ã®ã‚ˆã†ã«nodeã‚’æŒ‡å®šã™ã‚‹ã€‚\n\n```json\n{\n    \"mcpServers\": {\n        \"get-subjects\": {\n            \"command\": \"/Users/soichiro_yoshimura/.nvm/versions/node/v22.14.0/bin/node\",\n            \"args\": [\n                \"/Users/soichiro_yoshimura/workspace/zen-syllabus-mcp/build/index.js\"\n            ]\n        }\n    }\n}\n```\n\nã“ã®ã‚ˆã†ã«ãªã‚‹ã€‚`build/index.js`ã®ãƒ‘ã‚¹ã¯é©å®œå¤‰æ›´ã™ã‚‹ã“ã¨ã€‚\n\nè¨­å®šå¾Œã¯Claude Desktopã‚’å†èµ·å‹•ã€‚\n\nã€ŒZENå¤§å­¦ã®ã‚·ãƒ©ãƒã‚¹MCPã‚’åˆ©ç”¨ã—ã¦ã€ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«ãªã‚‹ãŸã‚ã®ã‚ªã‚¹ã‚¹ãƒ¡ã®ç§‘ç›®ã‚’ã‚ã’ã¦ãã ã•ã„ã€\n\nã§æ¤œè¨¼ã€‚\n\n![Claude Desktopã®ã‚¹ã‚¯ã‚·ãƒ§1](image/claude1.png)\n![Claude Desktopã®ã‚¹ã‚¯ã‚·ãƒ§2](image/claude2.png)\n\nã“ã®ã‚ˆã†ã«ãªã‚‹ã€‚å±¥ä¿®è¦ä»¶ã‚’è¨­å®šã™ã‚Œã°ç´°ã‹ãªå±¥ä¿®ç›¸è«‡ã‚‚å¯èƒ½ã€‚\n\n## VSCodeã®è¨­å®š\nã€æœªæ¤œè¨¼ã€‘ã„ãšã‚ŒGitHub Copilot ã§AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒåˆ©ç”¨ã§ãã‚‹ã‚ˆã†ãªã‚‹ã¨åˆ©ç”¨ã§ãã‚‹ã‚‰ã—ã„(ç¾åœ¨ã¯ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç‰ˆã®ã¿)ã€‚\nmcpã§è¨­å®šã‚’æ¤œç´¢ã—ã¦ä»¥ä¸‹ã‚’setting.jsonã«è¨­å®šã€‚ãƒ‘ã‚¹ã¯é©å®œå¤‰æ›´ã™ã‚‹ã“ã¨ã€‚jsonã®weatherã®ä¸Šã«èµ·å‹•ãƒœã‚¿ãƒ³ãŒç¾ã‚Œã‚‹ã®ã§èµ·å‹•ã—ã¦ãŠãã€‚\n\n```json\n{\n  \"mcpServers\": {\n      \"get-subjects\": {\n          \"command\": \"node\",\n          \"args\": [\n              \"C:\\\\Users\\\\sifue\\\\workspace\\\\zen-syllabus-mcp\\\\build\\\\index.js\"\n          ]\n      }\n  }\n}\n```\n\nè¨­å®šå¾Œã¯GitHub Copilotã§\n\nã€ŒZENå¤§å­¦ã®ã‚·ãƒ©ãƒã‚¹MCPã‚’åˆ©ç”¨ã—ã¦ã€ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«ãªã‚‹ãŸã‚ã®ã‚ªã‚¹ã‚¹ãƒ¡ã®ç§‘ç›®ã‚’ã‚ã’ã¦ãã ã•ã„ã€\n\nã§æ¤œè¨¼ã€‚å±¥ä¿®è¦ä»¶ã‚’è¨­å®šã™ã‚Œã°ç´°ã‹ãªå±¥ä¿®ç›¸è«‡ã‚‚å¯èƒ½ã€‚\n\n## ã‚µãƒ¼ãƒãƒ¼å®Ÿè£…æ™‚ã®å‹•ä½œç¢ºèª\n\nè©³ã—ãã¯ã€[TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)ã®Clientã®å®Ÿè£…ã‚’å‚ç…§ã€‚\n\n```sh\nnode build/index.js\n```\nã§ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã€‚\n\n```sh\nnode .\\build\\client.js\n```\nã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’èµ·å‹•ã—ã¦å®Ÿè¡Œã€‚\n\nã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯æ¤œè¨¼ã—ãŸã„ã‚³ãƒ¼ãƒ‰ã«åˆã‚ã›ã¦æ›¸ãæ›ãˆã€ãã®å¾Œã€\n```sh\nnpx tsc\n```\nã§ãƒ“ãƒ«ãƒ‰ã—ã¦å†åº¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã€‚\n\n\n## å‚è€ƒ\n- [MCPã®QuickStart](https://modelcontextprotocol.io/quickstart/server)\n- [VSCodeã®MCPè¨­å®š](https://code.visualstudio.com/docs/copilot/chat/mcp-servers)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Sivan22--mcp-sefaria-server": {
      "owner": "Sivan22",
      "name": "mcp-sefaria-server",
      "url": "https://github.com/Sivan22/mcp-sefaria-server",
      "imageUrl": "https://github.com/Sivan22.png",
      "description": "Access Jewish texts from the Sefaria library through a standardized interface for retrieval and referencing by AI models.",
      "stars": 29,
      "forks": 8,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-30T06:05:31Z",
      "readme_content": "\n[![smithery badge](https://smithery.ai/badge/mcp-sefaria-server)](https://smithery.ai/server/mcp-sefaria-server)\n<a href=\"https://glama.ai/mcp/servers/j3v6vnp4xk\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/j3v6vnp4xk/badge\" alt=\"Sefaria Jewish Library Server MCP server\" /></a>\n\n\n# Sefaria Jewish Library MCP Server\n\n\n\n\nAn MCP ([Model Context Protocol](https://docs.anthropic.com/en/docs/agents-and-tools/mcp)) server that provides access to Jewish texts from the [Sefaria](https://www.sefaria.org/) library. This server enables Large Language Models to retrieve and reference Jewish texts through a standardized interface.\n\n\n## Features\n\n- Retrieve Jewish texts by reference\n- Retrieve commentaries on a given text\n- Search the Jewish library for a query\n- Get daily/weekly learning schedule from Sefaria's calendar\n\n## Installation\n\nRequires Python 3.10 or higher.\n\n### Clone the repository\n```bash\ngit clone https://github.com/sivan22/mcp-sefaria-server.git\ncd mcp-sefaria-server\n```\n\n\n### Running the Server\n\nThe server can be run directly:\n\n```bash\nuv --directory path/to/directory run sefaria_jewish_library\n```\n\nOr through an MCP client that supports the Model Context Protocol.\nfor claude desktop app and cline you should use the following config:\n```\n{\n  \"mcpServers\": {        \n      \"sefaria_jewish_library\": {\n          \"command\": \"uv\",\n          \"args\": [\n              \"--directory\",\n              \"absolute/path/to/mcp-sefaria-server\",\n              \"run\",\n              \"sefaria_jewish_library\"\n          ],\n          \"env\": {\n            \"PYTHONIOENCODING\": \"utf-8\" \n          }\n      }\n  }\n}\n```\n\n### Installing via Smithery\n\nTo install Sefaria Jewish Library for Claude Desktop automatically via [Smithery](https://smithery.ai/server/mcp-sefaria-server):\n\n```bash\nnpx -y @smithery/cli install mcp-sefaria-server --client claude\n```\n\n## Available tools\n\nThe server provides the following tools through the MCP interface:\n\n### get_text\n\nRetrieves a specific Jewish text by its reference.\n\nExample:\n```\nreference: \"Genesis 1:1\"\nreference: \"×©××•×ª ×¤×¨×§ ×‘ ×¤×¡×•×§ ×’\"\nreference: \"××©× ×” ×‘×¨×›×•×ª ×¤×¨×§ × ××©× ×” ×\"\n```\n\n### get_commentaries\n\nRetrieves a list of commentaries for a given text.\n\nExample:\n```\nreference: \"Genesis 1:1\"\nreference: \"×©××•×ª ×¤×¨×§ ×‘ ×¤×¡×•×§ ×’\"\nreference: \"××©× ×” ×‘×¨×›×•×ª ×¤×¨×§ × ××©× ×” ×\"\n```\n\n### search_texts\n\nSearches for Jewish texts in the Sefaria library based on a query.\n\nExample:\n```\nquery: \"moshiach\"\nslop: 1\nfilters: [\"Talmud\", \"Bavli\"]\nsize: 5\n```\n\n### get_daily_learnings\n\nRetrieves the daily or weekly learning schedule from Sefaria's calendar API.\n\nParameters (all optional):\n- `diaspora` (boolean): When true, returns weekly Torah reading for diaspora. When false, returns Torah reading for Israel. Default: true\n- `custom` (string): If available, the weekly Haftarah will be returned for the selected custom\n- `year`, `month`, `day` (integers): Specific date (all three must be used together, or API falls back to current date)\n- `timezone` (string): Timezone name in accordance with IANA Standards\n\nExample:\n```\n# Get current day's learning schedule\n{}\n\n# Get learning schedule for a specific date in Israel\n{\n  \"diaspora\": false,\n  \"year\": 2024,\n  \"month\": 12,\n  \"day\": 25,\n  \"timezone\": \"Asia/Jerusalem\"\n}\n```\n\nReturns a formatted schedule including:\n- Weekly Torah portion (Parashat Hashavua) with aliyot\n- Haftarah reading\n- Daf Yomi (daily Talmud page)\n- Daily Mishnah, Rambam, and other learning cycles\n- Various Jewish learning programs and their daily selections\n\n\n## Development\n\nThis project uses:\n- [MCP SDK](https://github.com/modelcontextprotocol/sdk) for server implementation\n- [Sefaria API](https://github.com/Sefaria/Sefaria-API) for accessing Jewish texts\n\n  \n![image](https://github.com/user-attachments/assets/14ee8826-a76e-4c57-801d-473b177416d3)\n\n## Requirements\n\n- Python >= 3.10\n- MCP SDK >= 1.1.1\n- Sefaria API\n\n## License\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "spences10--mcp-svelte-docs": {
      "owner": "spences10",
      "name": "mcp-svelte-docs",
      "url": "https://github.com/spences10/mcp-svelte-docs",
      "imageUrl": "https://github.com/spences10.png",
      "description": "Provides access to detailed documentation for Svelte 5, including migration patterns from Svelte 4, as well as information on features, common mistakes, and best practices.",
      "stars": 119,
      "forks": 8,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-04T04:15:41Z",
      "readme_content": "# mcp-svelte-docs\n\nA Model Context Protocol (MCP) server providing authoritative Svelte 5\nand SvelteKit definitions extracted directly from TypeScript\ndeclarations. Get precise syntax, parameters, and examples for all\nSvelte 5 concepts through a single, unified interface.\n\n## Architecture\n\n**Definition-First Approach**: Rather than multiple specialized tools,\nthis server provides one powerful `svelte_definition` tool that\naccesses 28+ comprehensive definitions covering:\n\n- **All Svelte 5 runes** ($state, $derived, $props, $effect variants)\n- **Modern features** (snippets, await expressions, remote functions)\n- **Event handling** (DOM events, custom events, component\n  communication)\n- **Migration guidance** (Svelte 4 to 5 patterns and best practices)\n- **TypeScript interfaces** (Snippet, Snapshot types)\n- **Advanced patterns** (global state, common mistakes, lifecycle\n  equivalents)\n\n## Available Tool\n\n### `svelte_definition`\n\n**Single, powerful tool** for all Svelte 5 and SvelteKit concepts:\n\n```typescript\nsvelte_definition(identifier: string, format?: \"syntax\"|\"quick\"|\"full\")\n```\n\n**Examples:**\n\n- `svelte_definition(\"$state\")` - Complete $state documentation\n- `svelte_definition(\"snippets\", \"quick\")` - Snippet overview with\n  example\n- `svelte_definition(\"onclick\", \"syntax\")` - Just the TypeScript\n  signature\n- `svelte_definition(\"migration-patterns\")` - Svelte 4 â†’ 5 migration\n  guide\n\n**Response Formats:**\n\n- `\"syntax\"` - TypeScript signature only (~50 words)\n- `\"quick\"` - Definition + minimal example (~200 words)\n- `\"full\"` - Complete documentation with examples (~500-1000 words,\n  default)\n\n### Available Identifiers (28+)\n\n**Core Runes:** `$state`, `$state.raw`, `$state.snapshot`, `$derived`,\n`$derived.by`, `$props`, `$bindable`, `$effect`, `$effect.pre`,\n`$effect.root`, `$effect.pending`, `$effect.tracking`\n\n**Development Tools:** `$inspect`, `$host`\n\n**Features & Patterns:** `snippets`, `onclick`, `component-events`,\n`migration-patterns`, `await-expressions`, `remote-functions`,\n`global-state`, `common-mistakes`, `lifecycle-equivalents`\n\n**Event Handling:** `custom-events`, `event-delegation`,\n`event-modifiers`\n\n**TypeScript Interfaces:** `snippet`, `snapshot`\n\n## Key Features\n\n### ğŸ¯ **Authoritative & TypeScript-First**\n\n- **Direct from Source**: Definitions extracted from official Svelte 5\n  TypeScript declarations\n- **Always Current**: Reflects the actual API, not outdated tutorials\n- **Type-Safe**: Includes precise parameter types, return values, and\n  constraints\n\n### âš¡ **Single Interface, Complete Coverage**\n\n- **One Tool**: `svelte_definition` replaces 16+ specialized tools\n- **28+ Definitions**: Every Svelte 5 rune, feature, and pattern\n  covered\n- **Consistent Responses**: Same interface whether you need `$state`\n  or `remote-functions`\n\n### ğŸš€ **Modern Svelte 5 & SvelteKit Support**\n\n- **Await Expressions**: Async operations directly in templates\n  (`await-expressions`)\n- **Remote Functions**: Type-safe client-server communication\n  (`remote-functions`)\n- **All Runes**: Complete `$effect` family, `$state` variants,\n  `$derived.by`, `$bindable`\n- **Advanced Patterns**: Event handling, global state, component\n  communication\n\n### ğŸ“š **Smart Error Recovery**\n\n- **Fuzzy Matching**: Suggests correct identifiers for typos\n- **Related Concepts**: Points to similar definitions when searches\n  fail\n- **Migration Help**: Converts Svelte 4 patterns to Svelte 5\n  equivalents\n\n## Config\n\nClaude Desktop (via WSL)\n\n```json\n{\n\t\"mcpServers\": {\n\t\t\"mcp-svelte-docs\": {\n\t\t\t\"command\": \"wsl.exe\",\n\t\t\t\"args\": [\"bash\", \"-c\", \"npx -y mcp-svelte-docs\"]\n\t\t}\n\t}\n}\n```\n\nCursor\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en/install-mcp?name=mcp-svelte-docs&config=eyJjb21tYW5kIjoibnB4IC15IG1jcC1zdmVsdGUtZG9jcyJ9)\n\nWindsurf (via WSL)\n\n```json\n{\n\t\"mcpServers\": {\n\t\t\"mcp-svelte-docs\": {\n\t\t\t\"command\": \"wsl.exe\",\n\t\t\t\"args\": [\"bash\", \"-c\", \"npx -y mcp-svelte-docs\"]\n\t\t}\n\t}\n}\n```\n\nWindows (without WSL)\n\n```json\n{\n\t\"mcpServers\": {\n\t\t\"mcp-svelte-docs\": {\n\t\t\t\"command\": \"npx\",\n\t\t\t\"args\": [\"-y\", \"mcp-svelte-docs\"]\n\t\t}\n\t}\n}\n```\n\nmacOS / Linux\n\n```json\n{\n\t\"mcpServers\": {\n\t\t\"mcp-svelte-docs\": {\n\t\t\t\"command\": \"npx\",\n\t\t\t\"args\": [\"-y\", \"mcp-svelte-docs\"]\n\t\t}\n\t}\n}\n```\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nMIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\nBuilt on:\n\n- [Model Context Protocol](https://github.com/modelcontextprotocol)\n- [Svelte](https://svelte.dev)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "squirrelogic--mcp-feature-discussion": {
      "owner": "squirrelogic",
      "name": "mcp-feature-discussion",
      "url": "https://github.com/squirrelogic/mcp-feature-discussion",
      "imageUrl": "https://github.com/squirrelogic.png",
      "description": "Facilitates discussions regarding feature implementation and architecture, maintaining context and providing intelligent guidance throughout the development process. Offers persistent memory of discussions and context-aware recommendations based on project history.",
      "stars": 1,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-07-29T10:07:37Z",
      "readme_content": "# feature-discussion MCP Server\n\nA TypeScript-based Model Context Protocol (MCP) server that facilitates intelligent feature discussions between developers and AI. This server acts as an AI lead developer, providing guidance on feature implementation, maintaining context of discussions, and helping teams make informed architectural decisions.\n\n[Example Discussion](EXAMPLE_DISCUSSION.md)\n\nThis server provides:\n- Interactive discussions about feature implementation and architecture\n- Persistent memory of feature discussions and decisions\n- Intelligent guidance on development approaches and best practices\n- Context-aware recommendations based on project history\n\n## Features\n\n### AI Lead Developer Interface\n- Engage in natural discussions about feature requirements\n- Get expert guidance on implementation approaches\n- Receive architectural recommendations\n- Maintain context across multiple discussions\n\n### Feature Memory Management\n- Persistent storage of feature discussions\n- Track feature evolution and decisions\n- Reference previous discussions for context\n- Link related features and dependencies\n\n### Development Guidance\n- Best practices recommendations\n- Implementation strategy suggestions\n- Architecture pattern recommendations\n- Technology stack considerations\n\n### Context Management\n- Maintain project-wide feature context\n- Track dependencies between features\n- Store architectural decisions\n- Remember previous discussion outcomes\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"feature-discussion\": {\n      \"command\": \"/path/to/feature-discussion/build/index.js\"\n    }\n  }\n}\n```\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## Contributing\n\nWe welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details on how to get started, and our [Code of Conduct](CODE_OF_CONDUCT.md) for community guidelines.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "stagsz--Unconventional-thinking": {
      "owner": "stagsz",
      "name": "Unconventional-thinking",
      "url": "https://github.com/stagsz/Unconventional-thinking",
      "imageUrl": "https://github.com/stagsz.png",
      "description": "Generates unconventional solutions to problems by challenging conventional wisdom and organizing thoughts through a structured session. Offers a tool to explore innovative thinking paths based on user-defined problems.",
      "stars": 24,
      "forks": 8,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-27T04:02:37Z",
      "readme_content": "# Unreasonable Thinking Server\n\nA detailed tool for bold, unconventional, and boundary-breaking problem-solving.\n\nThis is a TypeScript-based MCP server that implements an unreasonable thinking system. It helps generate unconventional solutions to problems by:\n\n- Generating unreasonable thoughts that challenge conventional wisdom\n- Creating branches of thinking in different directions\n- Tracking and organizing thoughts in a session\n\n<a href=\"https://glama.ai/mcp/servers/pam1hp4gtk\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/pam1hp4gtk/badge\" alt=\"Unconventional-thinking server MCP server\" /></a>\n\n## Features\n\n### Tools\n- `generate_unreasonable_thought` - Generate new unconventional thoughts\n  - Takes a problem description and optional parameters\n  - Can build upon or rebel against previous thoughts\n- `branch_thought` - Create new branches of thinking\n  - Supports different directions: more extreme, opposite, tangential\n  - Maintains connection to source thoughts\n- `list_thoughts` - View all thoughts in the session\n  - Can filter by branch\n  - Shows relationships between thoughts\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"unreasonable-thinking-server\": {\n      \"command\": \"/path/to/unreasonable-thinking-server/build/index.js\"\n    }\n  }\n}\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "svmlearn---": {
      "owner": "svmlearn",
      "name": "-",
      "url": "https://github.com/svmlearn/-",
      "imageUrl": "https://github.com/svmlearn.png",
      "description": "Supports training, testing, and deploying support vector machine models for classification tasks. Facilitates advanced algorithm utilization to improve predictive performance within machine learning projects.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2022-05-09T07:49:49Z",
      "readme_content": "# -",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Swan-and-Co-Innovations--MCP": {
      "owner": "Swan-and-Co-Innovations",
      "name": "MCP",
      "url": "https://github.com/Swan-and-Co-Innovations/MCP",
      "imageUrl": "https://github.com/Swan-and-Co-Innovations.png",
      "description": "Integrate applications with real-world data and tools for enhanced workflows through a structured and dynamic problem-solving process. Break down complex problems and adjust thought processes with the help of a sequential thinking tool.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-03-05T13:08:50Z",
      "readme_content": "\n# Sequential Thinking MCP Server\n\nAn MCP server implementation that provides a tool for dynamic and reflective problem-solving through a structured thinking process.\n\n## Features\n\n- Break down complex problems into manageable steps\n- Revise and refine thoughts as understanding deepens\n- Branch into alternative paths of reasoning\n- Adjust the total number of thoughts dynamically\n- Generate and verify solution hypotheses\n\n## Tool\n\n### sequential_thinking\n\nFacilitates a detailed, step-by-step thinking process for problem-solving and analysis.\n\n**Inputs:**\n- `thought` (string): The current thinking step\n- `nextThoughtNeeded` (boolean): Whether another thought step is needed\n- `thoughtNumber` (integer): Current thought number\n- `totalThoughts` (integer): Estimated total thoughts needed\n- `isRevision` (boolean, optional): Whether this revises previous thinking\n- `revisesThought` (integer, optional): Which thought is being reconsidered\n- `branchFromThought` (integer, optional): Branching point thought number\n- `branchId` (string, optional): Branch identifier\n- `needsMoreThoughts` (boolean, optional): If more thoughts are needed\n\n## Usage\n\nThe Sequential Thinking tool is designed for:\n- Breaking down complex problems into steps\n- Planning and design with room for revision\n- Analysis that might need course correction\n- Problems where the full scope might not be clear initially\n- Tasks that need to maintain context over multiple steps\n- Situations where irrelevant information needs to be filtered out\n\n## Configuration\n\n### Usage with Claude Desktop\n\nAdd this to your `claude_desktop_config.json`:\n\n#### npx\n\n```json\n{\n  \"mcpServers\": {\n    \"sequential-thinking\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@modelcontextprotocol/server-sequential-thinking\"\n      ]\n    }\n  }\n}\n```\n\n#### docker\n\n```json\n{\n  \"mcpServers\": {\n    \"sequentialthinking\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"mcp/sequentialthinking\"\n      ]\n    }\n  }\n}\n```\n\n## Building\n\nDocker:\n\n```bash\ndocker build -t mcp/sequentialthinking -f src/sequentialthinking/Dockerfile .\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "szeider--mcp-dblp": {
      "owner": "szeider",
      "name": "mcp-dblp",
      "url": "https://github.com/szeider/mcp-dblp",
      "imageUrl": "https://github.com/szeider.png",
      "description": "Search and retrieve academic publications from the DBLP database, generating accurate BibTeX entries and performing advanced citation processing.",
      "stars": 13,
      "forks": 7,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T19:40:28Z",
      "readme_content": "# MCP-DBLP\n\n[![MCP Compatible](https://img.shields.io/badge/MCP-Compatible-green.svg)](https://modelcontextprotocol.io/) [![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT) [![Python Version](https://img.shields.io/badge/Python-3.11%2B-blue.svg)](https://www.python.org/)\n\nA Model Context Protocol (MCP) server that provides access to the DBLP computer science bibliography database for Large Language Models.\n\n<a href=\"https://glama.ai/mcp/servers/cm42scf3iv\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/cm42scf3iv/badge\" alt=\"MCP-DBLP MCP server\" />\n</a>\n\n------\n\n## Overview\n\nThe MCP-DBLP integrates the DBLP (Digital Bibliography & Library Project) API with LLMs through the Model Context Protocol, enabling AI models to:\n\n- Search and retrieve academic publications from the DBLP database\n- Process citations and generate BibTeX entries\n- Perform fuzzy matching on publication titles and author names\n- Extract and format bibliographic information\n- Process embedded references in documents\n- Direct BibTeX export that bypasses LLM processing for maximum accuracy\n\n## Features\n\n- Comprehensive search capabilities with boolean queries\n- Fuzzy title and author name matching\n- BibTeX entry retrieval directly from DBLP\n- Publication filtering by year and venue\n- Statistical analysis of publication data\n- Direct BibTeX export capability that bypasses LLM processing for maximum accuracy\n\n## Available Tools\n\n| Tool Name                 | Description                                        |\n| ------------------------- | -------------------------------------------------- |\n| `search`                  | Search DBLP for publications using boolean queries |\n| `fuzzy_title_search`      | Search publications with fuzzy title matching      |\n| `get_author_publications` | Retrieve publications for a specific author        |\n| `get_venue_info`          | Get detailed information about a publication venue |\n| `calculate_statistics`    | Generate statistics from publication results       |\n| `export_bibtex`           | Export BibTeX entries directly from DBLP to files  |\n\n\n## Feedback\n\nProvide feedback to the author via this [form](https://form.jotform.com/szeider/mcp-dblp-feedback-form). \n\n## System Requirements\n\n- Python 3.11+\n- [uv](https://docs.astral.sh/uv/getting-started/installation/)\n\n------\n\n## Installation\n\n1. Install an MCP-compatible client (e.g., [Claude Desktop app](https://claude.ai/download))\n\n2. Install the MCP-DBLP:\n\n   ```bash\n   git clone https://github.com/username/mcp-dblp.git\n   cd mcp-dblp\n   uv venv\n   source .venv/bin/activate \n   uv pip install -e .  \n   ```\n\n1. Create the configuration file:\n\n   For macOS/Linux:\n\n```\n   ~/Library/Application/Support/Claude/claude_desktop_config.json\n```\n\n   For Windows:\n\n```\n   %APPDATA%\\Claude\\claude_desktop_config.json\n```\n\n   Add the following content:\n\n```\n   {\n     \"mcpServers\": {\n       \"mcp-dblp\": {\n         \"command\": \"uv\",\n         \"args\": [\n           \"--directory\",\n           \"/absolute/path/to/mcp-dblp/\",\n           \"run\",\n           \"mcp-dblp\",\n           \"--exportdir\",\n           \"/absolute/path/to/bibtex/export/folder/\"\n         ]\n       }\n     }\n   }\n```\nWindows: `C:\\\\absolute\\\\path\\\\to\\\\mcp-dblp`\n\n------\n\n## Prompt\n\nIncluded is an [instructions prompt](./instructions_prompt.md) which should be used together with the text containing citations. On Claude Desktop, the instructions prompt is available via the electrical plug icon.\n\n\n## Tool Details\n\n### search\n\nSearch DBLP for publications using a boolean query string.\n\n**Parameters:**\n\n- `query` (string, required): A query string that may include boolean operators 'and' and 'or' (case-insensitive)\n- `max_results` (number, optional): Maximum number of publications to return. Default is 10\n- `year_from` (number, optional): Lower bound for publication year\n- `year_to` (number, optional): Upper bound for publication year\n- `venue_filter` (string, optional): Case-insensitive substring filter for publication venues (e.g., 'iclr')\n- `include_bibtex` (boolean, optional): Whether to include BibTeX entries in the results. Default is false\n\n### fuzzy_title_search\n\nSearch DBLP for publications with fuzzy title matching.\n\n**Parameters:**\n\n- `title` (string, required): Full or partial title of the publication (case-insensitive)\n- `similarity_threshold` (number, required): A float between 0 and 1 where 1.0 means an exact match\n- `max_results` (number, optional): Maximum number of publications to return. Default is 10\n- `year_from` (number, optional): Lower bound for publication year\n- `year_to` (number, optional): Upper bound for publication year\n- `venue_filter` (string, optional): Case-insensitive substring filter for publication venues\n- `include_bibtex` (boolean, optional): Whether to include BibTeX entries in the results. Default is false\n\n### get_author_publications\n\nRetrieve publication details for a specific author with fuzzy matching.\n\n**Parameters:**\n\n- `author_name` (string, required): Full or partial author name (case-insensitive)\n- `similarity_threshold` (number, required): A float between 0 and 1 where 1.0 means an exact match\n- `max_results` (number, optional): Maximum number of publications to return. Default is 20\n- `include_bibtex` (boolean, optional): Whether to include BibTeX entries in the results. Default is false\n\n### get_venue_info\n\nRetrieve detailed information about a publication venue.\n\n**Parameters:**\n\n- `venue_name` (string, required): Venue name or abbreviation (e.g., 'ICLR' or full name)\n\n### calculate_statistics\n\nCalculate statistics from a list of publication results.\n\n**Parameters:**\n\n- `results` (array, required): An array of publication objects, each with at least 'title', 'authors', 'venue', and 'year'\n\n### export_bibtex\n\nExport BibTeX entries directly from DBLP to a local file.\n\n**Parameters:**\n\n- ```\n  links\n  ```\n\n   \n\n  (string, required): HTML string containing one or more <a href=biburl>key</a> links\n\n  - Example: `\"<a href=https://dblp.org/rec/journals/example.bib>Smith2023</a>\"`\n\n**Behavior:**\n\n- For each link, the BibTeX entry is fetched directly from DBLP\n- Only the citation key is replaced with the key specified in the link text\n- All entries are saved to a timestamped .bib file in the folder specified by `--exportdir`\n- Returns the full path to the saved file\n\n**Important Note:** The BibTeX entries are fetched directly from DBLP with a 10-second timeout protection and are not processed, modified, or hallucinated by the LLM. This ensures maximum accuracy and trustworthiness of the bibliographic data. Only the citation keys are modified as specified. If a request times out, an error message is included in the output.\n\n------\n\n## Example\n\n### Input text:\n\n> Our exploration focuses on two types of explanation problems, abductive and contrastive, in local and global contexts (Marques-Silva 2023). Abductive explanations (Ignatiev, Narodytska, and Marques-Silva 2019), corresponding to prime-implicant explanations (Shih, Choi, and Darwiche 2018) and sufficient reason explanations (Darwiche and Ji 2022), clarify specific decision-making instances, while contrastive explanations (Miller 2019; Ignatiev et al. 2020), corresponding to necessary reason explanations (Darwiche and Ji 2022), make explicit the reasons behind the non-selection of alternatives. Conversely, global explanations (Ribeiro, Singh, and Guestrin 2016; Ignatiev, Narodytska, and Marques-Silva 2019) aim to unravel models' decision patterns across various inputs.\n\n### Output text:\n\n> Our exploration focuses on two types of explanation problems, abductive and contrastive, in local and global contexts \\cite{MarquesSilvaI23}. Abductive explanations \\cite{IgnatievNM19}, corresponding to prime-implicant explanations \\cite{ShihCD18} and sufficient reason explanations \\cite{DarwicheJ22}, clarify specific decision-making instances, while contrastive explanations \\cite{Miller19}; \\cite{IgnatievNA020}, corresponding to necessary reason explanations \\cite{DarwicheJ22}, make explicit the reasons behind the non-selection of alternatives. Conversely, global explanations \\cite{Ribeiro0G16}; \\cite{IgnatievNM19} aim to unravel models' decision patterns across various inputs.\n\n### Output Bibtex\n\n> All references have been successfully exported to a BibTeX file at: /absolute/path/to/bibtex/20250305_231431.bib\n\n```\n@article{MarquesSilvaI23,\n author       = {Jo{\\~{a}}o Marques{-}Silva and\n                 Alexey Ignatiev},\n title        = {No silver bullet: interpretable {ML} models must be explained},\n journal      = {Frontiers Artif. Intell.},\n volume       = {6},\n year         = {2023},\n url          = {https://doi.org/10.3389/frai.2023.1128212},\n doi          = {10.3389/FRAI.2023.1128212},\n timestamp    = {Tue, 07 May 2024 20:23:47 +0200},\n biburl       = {https://dblp.org/rec/journals/frai/MarquesSilvaI23.bib},\n bibsource    = {dblp computer science bibliography, https://dblp.org}\n}\n\n@inproceedings{IgnatievNM19,\n author       = {Alexey Ignatiev and\n                 Nina Narodytska and\n                 Jo{\\~{a}}o Marques{-}Silva},\n title        = {Abduction-Based Explanations for Machine Learning Models},\n booktitle    = {The Thirty-Third {AAAI} Conference on Artificial Intelligence, {AAAI}\n                 2019, The Thirty-First Innovative Applications of Artificial Intelligence\n                 Conference, {IAAI} 2019, The Ninth {AAAI} Symposium on Educational\n                 Advances in Artificial Intelligence, {EAAI} 2019, Honolulu, Hawaii,\n                 USA, January 27 - February 1, 2019},\n pages        = {1511--1519},\n publisher    = {{AAAI} Press},\n year         = {2019},\n url          = {https://doi.org/10.1609/aaai.v33i01.33011511},\n doi          = {10.1609/AAAI.V33I01.33011511},\n timestamp    = {Mon, 04 Sep 2023 12:29:24 +0200},\n biburl       = {https://dblp.org/rec/conf/aaai/IgnatievNM19.bib},\n bibsource    = {dblp computer science bibliography, https://dblp.org}\n}\n\n@inproceedings{ShihCD18,\n author       = {Andy Shih and\n                 Arthur Choi and\n                 Adnan Darwiche},\n editor       = {J{\\'{e}}r{\\^{o}}me Lang},\n title        = {A Symbolic Approach to Explaining Bayesian Network Classifiers},\n booktitle    = {Proceedings of the Twenty-Seventh International Joint Conference on\n                 Artificial Intelligence, {IJCAI} 2018, July 13-19, 2018, Stockholm,\n                 Sweden},\n pages        = {5103--5111},\n publisher    = {ijcai.org},\n year         = {2018},\n url          = {https://doi.org/10.24963/ijcai.2018/708},\n doi          = {10.24963/IJCAI.2018/708},\n timestamp    = {Tue, 20 Aug 2019 16:19:08 +0200},\n biburl       = {https://dblp.org/rec/conf/ijcai/ShihCD18.bib},\n bibsource    = {dblp computer science bibliography, https://dblp.org}\n}\n\n@inproceedings{DarwicheJ22,\n author       = {Adnan Darwiche and\n                 Chunxi Ji},\n title        = {On the Computation of Necessary and Sufficient Explanations},\n booktitle    = {Thirty-Sixth {AAAI} Conference on Artificial Intelligence, {AAAI}\n                 2022, Thirty-Fourth Conference on Innovative Applications of Artificial\n                 Intelligence, {IAAI} 2022, The Twelveth Symposium on Educational Advances\n                 in Artificial Intelligence, {EAAI} 2022 Virtual Event, February 22\n                 - March 1, 2022},\n pages        = {5582--5591},\n publisher    = {{AAAI} Press},\n year         = {2022},\n url          = {https://doi.org/10.1609/aaai.v36i5.20498},\n doi          = {10.1609/AAAI.V36I5.20498},\n timestamp    = {Mon, 04 Sep 2023 16:50:24 +0200},\n biburl       = {https://dblp.org/rec/conf/aaai/DarwicheJ22.bib},\n bibsource    = {dblp computer science bibliography, https://dblp.org}\n}\n\n@article{Miller19,\n author       = {Tim Miller},\n title        = {Explanation in artificial intelligence: Insights from the social sciences},\n journal      = {Artif. Intell.},\n volume       = {267},\n pages        = {1--38},\n year         = {2019},\n url          = {https://doi.org/10.1016/j.artint.2018.07.007},\n doi          = {10.1016/J.ARTINT.2018.07.007},\n timestamp    = {Thu, 25 May 2023 12:52:41 +0200},\n biburl       = {https://dblp.org/rec/journals/ai/Miller19.bib},\n bibsource    = {dblp computer science bibliography, https://dblp.org}\n}\n\n@inproceedings{IgnatievNA020,\n author       = {Alexey Ignatiev and\n                 Nina Narodytska and\n                 Nicholas Asher and\n                 Jo{\\~{a}}o Marques{-}Silva},\n editor       = {Matteo Baldoni and\n                 Stefania Bandini},\n title        = {From Contrastive to Abductive Explanations and Back Again},\n booktitle    = {AIxIA 2020 - Advances in Artificial Intelligence - XIXth International\n                 Conference of the Italian Association for Artificial Intelligence,\n                 Virtual Event, November 25-27, 2020, Revised Selected Papers},\n series       = {Lecture Notes in Computer Science},\n volume       = {12414},\n pages        = {335--355},\n publisher    = {Springer},\n year         = {2020},\n url          = {https://doi.org/10.1007/978-3-030-77091-4\\_21},\n doi          = {10.1007/978-3-030-77091-4\\_21},\n timestamp    = {Tue, 15 Jun 2021 17:23:54 +0200},\n biburl       = {https://dblp.org/rec/conf/aiia/IgnatievNA020.bib},\n bibsource    = {dblp computer science bibliography, https://dblp.org}\n}\n\n@inproceedings{Ribeiro0G16,\n author       = {Marco T{\\'{u}}lio Ribeiro and\n                 Sameer Singh and\n                 Carlos Guestrin},\n editor       = {Balaji Krishnapuram and\n                 Mohak Shah and\n                 Alexander J. Smola and\n                 Charu C. Aggarwal and\n                 Dou Shen and\n                 Rajeev Rastogi},\n title        = {\"Why Should {I} Trust You?\": Explaining the Predictions of Any Classifier},\n booktitle    = {Proceedings of the 22nd {ACM} {SIGKDD} International Conference on\n                 Knowledge Discovery and Data Mining, San Francisco, CA, USA, August\n                 13-17, 2016},\n pages        = {1135--1144},\n publisher    = {{ACM}},\n year         = {2016},\n url          = {https://doi.org/10.1145/2939672.2939778},\n doi          = {10.1145/2939672.2939778},\n timestamp    = {Fri, 25 Dec 2020 01:14:16 +0100},\n biburl       = {https://dblp.org/rec/conf/kdd/Ribeiro0G16.bib},\n bibsource    = {dblp computer science bibliography, https://dblp.org}\n}\n```\n\n------\n\n## Disclaimer\n\nThis MCP-DBLP is in its prototype stage and should be used with caution. Users are encouraged to experiment, but any use in critical environments is at their own risk.\n\n------\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n------",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Taidgh-Robinson--nba-mcp-server": {
      "owner": "Taidgh-Robinson",
      "name": "nba-mcp-server",
      "url": "https://github.com/Taidgh-Robinson/nba-mcp-server",
      "imageUrl": "https://github.com/Taidgh-Robinson.png",
      "description": "Provides up-to-date NBA game scores and player statistics, enabling retrieval of game summaries, player performance metrics, and advanced analytics. Keeps AI models informed with accurate and timely NBA data.",
      "stars": 10,
      "forks": 2,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-08-24T18:54:32Z",
      "readme_content": "# NBA MCP Server\n\n## Description\nAn MCP server for Anthropic's Claude LLM that allows the model to fetch recent NBA games and stats that it struggles to currently. It does this using the opensource [nba_api](https://pypi.org/project/nba_api/)\n\n## Installation\nRun these steps in the directory where you have cloned the repo\n```bash\nuv venv\n.venv\\Scripts\\activate\nuv pip install -e .\n```\n\nThen add the configuration to your Claude config as you would for any other MCP Server. \n\n## Features\n- Fetch the fetch the final score for all game(s) that happened yesterday / in the past\n- Fetch the basic P/R/A breakdown for all players that played in game(s) that happened yesterday / in the past\n- Fetch the full PTS/REB/AST/STL/BLK/TO/PLUS_MINUS/MIN that happened yesterday / in the past\n- Fetch the four factors for all the game(s) that happened yesterday / in the past \n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "takashiishida--arxiv-latex-mcp": {
      "owner": "takashiishida",
      "name": "arxiv-latex-mcp",
      "url": "https://github.com/takashiishida/arxiv-latex-mcp",
      "imageUrl": "https://github.com/takashiishida.png",
      "description": "Fetches and processes LaTeX sources of arXiv papers, enabling AI models to accurately interpret mathematical content and equations without the limitations of PDF files.",
      "stars": 66,
      "forks": 7,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-04T06:58:54Z",
      "readme_content": "# arxiv-latex MCP Server\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![GitHub Release](https://img.shields.io/github/v/release/takashiishida/arxiv-latex-mcp)](https://github.com/takashiishida/arxiv-latex-mcp/releases)\n\n\nAn MCP server that enables [Claude Desktop](https://claude.ai/download), [Cursor](https://www.cursor.com/), or other MCP clients to directly access and process arXiv papers by fetching the LaTeX source. It uses [arxiv-to-prompt](https://github.com/takashiishida/arxiv-to-prompt) under the hood to handle downloading and processing the LaTeX.\n\nWhy use the LaTeX source instead of uploading PDFs? Many PDF chat applications often struggle with mathematical content and equation-heavy papers. By utilizing the original LaTeX source code from arXiv papers, the LLM can accurately understand and handle equations and notations. This approach is particularly valuable for fields like computer science, mathematics, and engineering where precise interpretation of mathematical expressions is crucial.\n\n## Installation\n\nIf you are using Claude Desktop and MacOS, you can utilize Desktop Extensions by double-clicking on the .dxt file to install.\nDownload the .dxt file from [here](https://github.com/takashiishida/arxiv-latex-mcp/releases/).\n\nOtherwise, you can manually add the following configuration to your config file:\n```json\n{\n  \"mcpServers\": {\n      \"arxiv-latex-mcp\": {\n          \"command\": \"uv\",\n          \"args\": [\n              \"--directory\",\n              \"/ABSOLUTE/PATH/TO/arxiv-latex-mcp\",\n              \"run\",\n              \"server/main.py\"\n          ]\n      }\n  }\n}\n```\n\nYou may need to replace the `command` field with the full path of `uv`: check this by running `which uv` (MacOS/Linux) or `where uv` (Windows).\n\nRestart the application after saving the above.\n\nFor Claude Desktop, click on the hammer icon, and you should see `get_paper_prompt` in the list of \"Available MCP tools\".\n\n## Example\nTry asking questions about a paper from arXiv, e.g., \"Explain the first theorem in 2202.00395\"\n\n<div align=\"center\">\n  <img src=\"example.png\" alt=\"Example of using arXiv LaTeX MCP with Claude Desktop\" width=\"600\">\n</div>\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Tanner253--ComedyMcpServer": {
      "owner": "Tanner253",
      "name": "ComedyMcpServer",
      "url": "https://github.com/Tanner253/ComedyMcpServer",
      "imageUrl": "https://github.com/Tanner253.png",
      "description": "Generates programming-related jokes and humorous code comments for AI assistants. Integrates with Cursor IDE to enhance coding experiences through humor and creativity.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "C#",
      "updated_at": "2025-04-09T07:44:05Z",
      "readme_content": "# Comedy MCP Server\n\nA Model Context Protocol (MCP) server implementation that provides comedy-related tools and services for AI assistants. This server integrates with Cursor IDE and offers various comedy-related functionalities through MCP tools.\n\n## Overview\n\nThe Comedy MCP Server is built using ASP.NET Core and implements the Model Context Protocol (MCP) to provide AI assistants with tools for generating programming jokes and funny code comments. It serves as a bridge between AI models and comedy-related functionalities.\n\n![MCP Server Integration Proof](documentation/MCP%20proof.jpg)\n\n## Features\n\n- **Programming Jokes**: Generates random programming-related jokes\n- **Code Comments**: Creates humorous comments based on code context and topics\n- **Echo Service**: Demonstration service showing logging capabilities\n- **Swagger Integration**: API documentation and testing interface\n- **Health Check Endpoint**: Basic server status monitoring\n\n## Architecture\n\nThe server is built with the following components:\n\n- **MCP Server Integration**: Uses `ModelContextProtocol.Server` for MCP implementation\n- **Comedy Services**: Implements `IComedyService` for joke and comment generation\n- **HTTP Communication**: Uses stdio for communication with Cursor IDE\n- **Logging**: Comprehensive logging with configurable levels\n- **CORS Support**: Configured for MCP inspector tool\n\n## Tools\n\nThe server provides the following MCP tools:\n\n1. `GetProgrammingJoke`\n   - Description: Retrieves a random programming-related joke\n   - Parameters: None\n   - Returns: A string containing the joke\n\n2. `GetCodeComment`\n   - Description: Generates a funny comment related to specific code context\n   - Parameters:\n     - `codeContext`: The code snippet or context\n     - `topic`: The topic for the comment\n   - Returns: A humorous comment related to the code\n\n3. `EchoWithLog`\n   - Description: Demonstration tool that echoes messages with logging\n   - Parameters:\n     - `message`: The message to echo\n   - Returns: The echoed message\n\n## Setup and Configuration\n\n### Prerequisites\n- .NET 8.0 SDK or later\n- Node.js 14+ (for MCP inspector tool)\n- A code editor (preferably Cursor IDE for best integration)\n- Git (for version control)\n\n### Installation Steps\n\n1. Clone the repository:\n```bash\ngit clone [your-repository-url]\ncd ComedyMcpServer\n```\n\n2. Set up environment:\n   - Copy the example environment file:\n     ```bash\n     copy .env.example .env    # On Windows\n     # OR\n     cp .env.example .env     # On Unix-based systems\n     ```\n   - Update the `.env` file with your settings if needed\n\n3. Install dependencies:\n```bash\ndotnet restore\n```\n\n4. Build the project:\n```bash\ndotnet build\n```\n\n### Running the Server\n\nYou have several options to run the server:\n\n1. **Development Mode**:\n```bash\ndotnet run --environment Development\n```\n\n2. **With MCP Inspector** (recommended for debugging MCP tools):\n```bash\nnpx @modelcontextprotocol/inspector dotnet run\n```\n\n3. **Production Mode**:\n```bash\ndotnet run --environment Production\n```\n\n### Verifying Installation\n\n1. Check the server is running:\n   - Open your browser to `http://localhost:5000` or the configured port\n   - You should see the message \"Comedy MCP Server is running!\"\n\n2. Access Swagger Documentation:\n   - Navigate to `http://localhost:5000/swagger`\n   - You should see the API documentation\n\n3. Test MCP Tools:\n   - Use the included test script:\n     ```bash\n     node test-mcp.js\n     ```\n   - Or use the MCP inspector interface if running with inspector\n\n### Troubleshooting\n\nCommon issues and solutions:\n\n1. Port already in use:\n   - Change the port in `appsettings.json`\n   - Or stop the process using the current port\n\n2. Dependencies missing:\n   - Run `dotnet restore` again\n   - Check your .NET SDK version matches the project requirements\n\n3. Environment variables not loading:\n   - Ensure `.env` file exists and is properly formatted\n   - Restart the application after modifying environment files\n\nFor more detailed issues, check the application logs in the console output.\n\n## Development\n\nThe project follows standard ASP.NET Core practices with additional MCP-specific components:\n\n- Services are registered in the DI container\n- Tools are automatically discovered from the assembly\n- Logging is configured for development and debugging\n- Swagger is available for API documentation\n\n## Deployment\n\nThe project includes:\n- `Procfile`: For platform deployment\n- `nixpacks.toml`: Build configuration\n- Standard ASP.NET Core deployment options\n\n## Testing\n\nA test script (`test-mcp.js`) is included for verifying MCP functionality.\n\n## Health Check\n\nAccess the root endpoint (`/`) to verify server status:\n```\nGET / -> \"Comedy MCP Server is running!\"\n```\n\n## API Documentation\n\nWhen running, access Swagger UI at:\n```\n/swagger\n```\n\n## Contributing\n\nFeel free to contribute by:\n1. Implementing new comedy-related tools\n2. Enhancing existing joke generation\n3. Improving error handling and logging\n4. Adding new comedy services\n\n## License\n\n[Your license information here] ",
      "npm_url": "",
      "npm_downloads": 0
    },
    "TeXmeijin--manalinkMCP": {
      "owner": "TeXmeijin",
      "name": "manalinkMCP",
      "url": "https://github.com/TeXmeijin/manalinkMCP",
      "imageUrl": "https://github.com/TeXmeijin.png",
      "description": "Connect AI assistants to educational resources through features like teacher search, course information retrieval, and subject management. Access dynamic data such as subject and grade masters via API calls.",
      "stars": 0,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-04-09T02:47:23Z",
      "readme_content": "# ãƒãƒŠãƒªãƒ³ã‚¯MCPã‚µãƒ¼ãƒãƒ¼\n\nãƒãƒŠãƒªãƒ³ã‚¯ã®Model Context Protocol (MCP) ã‚µãƒ¼ãƒãƒ¼å®Ÿè£…ã§ã™ã€‚AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒå…ˆç”Ÿæ¤œç´¢ãªã©ã®æ©Ÿèƒ½ã‚’åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚\n\n## æ©Ÿèƒ½\n\nã“ã®MCPã‚µãƒ¼ãƒãƒ¼ã¯ä»¥ä¸‹ã®ãƒ„ãƒ¼ãƒ«ã‚’æä¾›ã—ã¾ã™ï¼š\n\n1. **ç§‘ç›®ãƒã‚¹ã‚¿å–å¾—**: ç§‘ç›®åã¨ç§‘ç›®IDã®ãƒã‚¹ã‚¿ã‚’å–å¾—\n2. **ç‰¹å¾´ãƒã‚¹ã‚¿å–å¾—**: ã‚³ãƒ¼ã‚¹ç‰¹å¾´ã®ãƒã‚¹ã‚¿ã‚’å–å¾—ï¼ˆAPIã‹ã‚‰å‹•çš„ã«å–å¾—ï¼‰\n3. **å­¦å¹´ãƒã‚¹ã‚¿å–å¾—**: å­¦å¹´åã¨IDã®ãƒã‚¹ã‚¿ã‚’å–å¾—\n4. **å…ˆç”Ÿæ¤œç´¢ï¼ˆè©³ç´°æŒ‡å®šï¼‰**: ç§‘ç›®IDã€å­¦å¹´IDãªã©ã®è©³ç´°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å…ˆç”Ÿã‚’æ¤œç´¢\n\n## å‰ææ¡ä»¶\n\n- Node.js 18+\n- npm ã¾ãŸã¯ yarn\n\n## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n\n```bash\n# ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³\ngit clone [ãƒªãƒã‚¸ãƒˆãƒªURL]\ncd manalink-mcp\n\n# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\nnpm install\n```\n\n## ä½¿ã„æ–¹\n\n### é–‹ç™ºãƒ¢ãƒ¼ãƒ‰\n\n```bash\nnpm run dev\n```\n\n### æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰\n\n```bash\nnpm run build\nnpm start\n```\n\n## Claude for Desktopã¨ã®é€£æº\n\nClaude for Desktopã§ä½¿ç”¨ã™ã‚‹ã«ã¯ã€`claude_desktop_config.json` ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã‚’è¿½åŠ ã—ã¾ã™ã€‚\n\n1. Claude for Desktopã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã\n```\ncode ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\n2. ä»¥ä¸‹ã®è¨­å®šã‚’è¿½åŠ \n```json\n{\n    \"mcpServers\": {\n        \"manalink\": {\n            \"command\": \"node\",\n            \"args\": [\n                \"/çµ¶å¯¾ãƒ‘ã‚¹/manalink-mcp/dist/index.js\"\n            ]\n        }\n    }\n}\n```\n\n3. Claude for Desktopã‚’å†èµ·å‹•\n\n## MCP ãƒ„ãƒ¼ãƒ«\n\n### 1. ç§‘ç›®ãƒã‚¹ã‚¿å–å¾—\n\n```javascript\n// ãƒ„ãƒ¼ãƒ«å: get_subject_master\n// ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: ãªã—\n```\n\n### 2. ç‰¹å¾´ãƒã‚¹ã‚¿å–å¾—\n\n```javascript\n// ãƒ„ãƒ¼ãƒ«å: get_course_features\n// ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: ãªã—\n```\n\n### 3. å­¦å¹´ãƒã‚¹ã‚¿å–å¾—\n\n```javascript\n// ãƒ„ãƒ¼ãƒ«å: get_grade_master\n// ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: ãªã—\n```\n\n### 4. å…ˆç”Ÿæ¤œç´¢ (è©³ç´°æŒ‡å®š)\n\n```javascript\n// ãƒ„ãƒ¼ãƒ«å: search_teachers_advanced\n// ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\n// - subject_ids: ç§‘ç›®IDã®é…åˆ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n// - grade_ids: å­¦å¹´IDã®é…åˆ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n// - course_feature_id: ç‰¹å¾´IDï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n// - sort: ã‚½ãƒ¼ãƒˆé †ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰[pr, certification, rating, lesson_count, latest]\n// - desired_teaching_period: æŒ‡å°æœŸé–“ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰[monthly, once]\n```\n\n## æ¤œè¨¼æ–¹æ³•\n\nMCP Inspectorã‚’ä½¿ç”¨ã—ã¦æ¤œè¨¼ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n\n1. ãƒ“ãƒ«ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã‹ã‚‰ã€ã‚¤ãƒ³ã‚¹ãƒšã‚¯ã‚¿ã‚’å®Ÿè¡Œã—ã¾ã™\n```bash\nnpm run build\nnpx @modelcontextprotocol/inspector node dist/index.js\n```\n\n## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹\n\nMIT\n\n## HTMLã‹ã‚‰Markdownã¸ã®å¤‰æ›æ©Ÿèƒ½\n\nãƒãƒŠãƒªãƒ³ã‚¯ã‹ã‚‰å–å¾—ã—ãŸHTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã«å¤‰æ›ã™ã‚‹æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚\n\n### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•\n\n```bash\nnpm install node-html-markdown\n```\n\n### ä½¿ç”¨æ–¹æ³•\n\n```typescript\nimport { convertHtmlToMarkdown } from './utils/api';\n\n// HTMLã‹ã‚‰Markdownã¸ã®å¤‰æ›\nconst html = `\n  <div>\n    <h1>ãƒãƒŠãƒªãƒ³ã‚¯</h1>\n    <p>ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å®¶åº­æ•™å¸«ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ </p>\n    <ul>\n      <li><a href=\"/about\">ã‚µãƒ¼ãƒ“ã‚¹ã«ã¤ã„ã¦</a></li>\n      <li><a href=\"/teachers\">å…ˆç”Ÿã‚’æ¢ã™</a></li>\n    </ul>\n  </div>\n`;\n\nconst markdown = convertHtmlToMarkdown(html);\nconsole.log(markdown);\n```\n\n### å¤‰æ›çµæœ\n\nä¸Šè¨˜ã®HTMLã‹ã‚‰ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãŒç”Ÿæˆã•ã‚Œã¾ã™ï¼š\n\n```markdown\n# ãƒãƒŠãƒªãƒ³ã‚¯\n\nã‚ªãƒ³ãƒ©ã‚¤ãƒ³å®¶åº­æ•™å¸«ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ \n\n* [ã‚µãƒ¼ãƒ“ã‚¹ã«ã¤ã„ã¦](/about)\n* [å…ˆç”Ÿã‚’æ¢ã™](/teachers)\n```\n\n### å…ˆç”Ÿæ¤œç´¢çµæœã®ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å¤‰æ›\n\nå…ˆç”Ÿæ¤œç´¢APIã§ã¯ã€æ¤œç´¢çµæœã‚’HTMLå½¢å¼ã¨Markdownå½¢å¼ã®ä¸¡æ–¹ã§å–å¾—ã§ãã¾ã™ï¼š\n\n```typescript\nimport { searchTeachers } from './utils/api';\n\n// æ•°å­¦ã®ä¸­å­¦ç”Ÿã‚’æ•™ãˆã‚‰ã‚Œã‚‹å…ˆç”Ÿã‚’æ¤œç´¢\nconst result = await searchTeachers({\n  subject_ids: [2], // æ•°å­¦\n  grade_ids: [4], // ä¸­å­¦1å¹´ç”Ÿ\n  sort: 'rating'\n});\n\n// HTMLå½¢å¼ã®æ¤œç´¢çµæœ\nconsole.log(result.bodyContent);\n\n// Markdownå½¢å¼ã®æ¤œç´¢çµæœ\nconsole.log(result.markdown);\n```",
      "npm_url": "",
      "npm_downloads": 0
    },
    "tjl-with-code--Go-Interview": {
      "owner": "tjl-with-code",
      "name": "Go-Interview",
      "url": "https://github.com/tjl-with-code/Go-Interview",
      "imageUrl": "https://github.com/tjl-with-code.png",
      "description": "Curates a collection of Go programming interview questions and study materials, providing resources on Go basics, concurrency, MySQL, networking, operating systems, and Redis for learners preparing for job interviews.",
      "stars": 0,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "",
      "updated_at": "2025-03-28T13:01:00Z",
      "readme_content": "# Go-Interview\né¡¹ç›®æ•´åˆï¼š\n\nâ€‹\t[åœ°é¼ æ–‡æ¡£ (topgoer.cn)](https://topgoer.cn/)\n\nâ€‹\t[lifei6671/interview-go: golangé¢è¯•é¢˜é›†åˆ (github.com)](https://github.com/lifei6671/interview-go)\n\nâ€‹\t[cosen1024/Java-Interview: Javaé¢è¯•å°æŠ„(github.com)](https://github.com/cosen1024/Java-Interview)\n\nâ€‹\t[ä»£ç éšæƒ³å½• (programmercarl.com)](https://www.programmercarl.com/)\n\nâ€‹\t[æå®¢å…”å…” (geektutu.com)](https://geektutu.com/)\n\nç‰¹æ­¤ç”³æ˜ï¼š\n\nâ€‹\tGoåˆå­¦è€…ï¼Œä¸ºäº†æœªæ¥çš„æ±‚èŒå’Œæ›´ä¸“æ³¨å­¦ä¹ ï¼Œæ‰€ä»¥ç‰¹æ­¤æ•´ç†ä»¥ä¸Šèµ„æ–™ã€‚å½“ç„¶å¯èƒ½åœ¨æ”¶é›†è¿‡ç¨‹ä¸­é—æ¼äº†å‚è€ƒèµ„æ–™ã€‚è‹¥æœ‰é—®é¢˜ï¼Œè¯·åŠæ—¶è”ç³»ï¼\n\nâ€‹\tå–œæ¬¢çš„è¯ï¼Œforkã€starï¼Œä¸€èµ·å­¦ä¹ Goï¼Œåœ¨å¤§ä½¬çš„èµ„æ–™ä¸‹ï¼Œäº‰å–åšä¸€ä¸ªåŸºç¡€å’Œè¿›é˜¶çš„å¼€æºå¥½é¡¹ç›®ï¼Œå¸®åŠ©æˆ‘ä»¬ä¸€èµ·å­¦ä¹ ï¼\n\nâ€‹\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tä¸€ä¸ªGoå­¦ä¹ è€…\n\nâ€‹\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t2022å¹´2æœˆ14å·\n\n<details>\n\n#### 2022-3-17\n\næ•´ç†ä¸€ä¸ªæœˆå·¦å³ï¼Œæ¢³ç†ç½‘ä¸Šçš„å¤§å¤šæ•°GoåŸºç¡€ã€å¹¶å‘ã€Mysqlã€ç½‘ç»œã€æ“ä½œç³»ç»Ÿã€Redisçš„çŸ¥è¯†ã€‚å‰”é™¤ä¸€äº›å…¶ä»–ä»“åº“é‡Œçš„é«˜é˜¶çŸ¥è¯†ã€‚åªæ˜¯ä¸ºäº†å­¦ç”Ÿæ­¥å…¥èŒåœºï¼Œæ‰“ç‰¢åŸºç¡€ï¼\n\n\n\n### 2022-3-18\n\næ¢³ç†å’Œå®Œå–„ï¼š\n\ngoåŸºç¡€â€”â€”3.GoåŸºç¡€ç±»ï¼š9-38é¢˜çš„è§£ç­”æ³¨é‡Šï¼Œæ¶‰åŠsliceã€mapã€channelã€goroutineç­‰ã€‚\n\nç¬¬ä¸€æ¬¡ä¸Šä¼ åˆ°GitHubã€Giteeï¼Œå¸Œæœ›é‡åˆ°ä¸€èµ·åŠªåŠ›å‰è¡Œçš„äººï¼\n\n\n\n### 2022-3-19\n\næ¢³ç†ï¼š\n\nGoåŸºç¡€ï¼š4.GoåŸºç¡€åº”ç”¨ï¼Œå‡ ç§æœ‰è®¾è®¡å‡ ç§æµ‹è¯•æ¡†æ¶ï¼Œç°åœ¨ä¹ŸåªçŸ¥é“å…¶åå­—ï¼Œå…·ä½“åŠŸèƒ½ä¸æ¸…æ¥šã€‚\n\nGoå¹¶å‘ï¼š1.Goå¹¶å‘åŸºç¡€ã€æ¢³ç†éƒ¨åˆ†ã€‘\n</details>",
      "npm_url": "",
      "npm_downloads": 0
    },
    "vionwinnie--jap-vocab-anki-mcp-server": {
      "owner": "vionwinnie",
      "name": "jap-vocab-anki-mcp-server",
      "url": "https://github.com/vionwinnie/jap-vocab-anki-mcp-server",
      "imageUrl": "https://github.com/vionwinnie.png",
      "description": "Programmatically interact with Anki decks for Japanese language learning, enabling management of decks and cards, vocabulary imports, and review tracking through a standardized interface.",
      "stars": 3,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-08T07:45:31Z",
      "readme_content": "# Japanese Vocab Anki MCP Server\n\nA Model Context Protocol server implementation for interacting with Anki decks programmatically. This server allows Language Models to interact with Anki through a standardized interface, with special support for Japanese language learning.\n\nThis is vibe-coded with Cursor with Claude 3.5 Sonnet.\n\n## Features\n\n- List available decks\n- View cards in decks\n- Add new cards\n- Review cards with spaced repetition\n- Import Japanese vocabulary with readings and meanings\n- Add sample sentences to Japanese vocabulary cards\n- Track review history and learning progress\n\n## End-to-End Example: Japanese Vocabulary Study with Claude\n\nHere's a complete workflow showing how to use Claude to enhance your Japanese vocabulary cards with sample sentences.\n\n### Step 1: Generate Fill-in-the-Blank Exercises\n\nFirst, ask Claude to create practice exercises using the `study_japanese_vocab_prompt`:\n\n![Fill in the blanks exercise](screenshots/fill_in_blanks.png)\n\nClaude will look through your recently reviewed vocabulary and create contextual sentences with blanks to test your understanding.\n\n### Step 2: Convert to Sample Sentences\n\nNext, use the `vocab_sentences_json_prompt` to convert these sentences into a structured format:\n\nClaude will transform the sentences into a JSON dictionary mapping each vocabulary word to its sample sentences.\n\n### Step 3: Update Anki Cards\n\nFinally, use the `update_notes_with_sentences` tool to add these sentences to your Anki cards:\n\n![Update cards](screenshots/update_cards.png)\n\nThe sentences will be added to the reading field of each vocabulary card, providing more context for your studies.\n\n### Results in Anki\n\nAfter the update, your cards will include the new sample sentences:\n![Update cards](screenshots/verify_notes.png)\n\n\nThis workflow helps you:\n1. Practice vocabulary in context through fill-in-the-blank exercises\n2. Add natural example sentences to your cards\n3. Build a more comprehensive understanding of each word's usage\n\n## Installation\n\n1. Clone this repository:\n```bash\ngit clone https://github.com/vionwinnie/jap-vocab-anki-mcp-server.git\ncd jap-vocab-anki-mcp-server\n```\n\n## Usage\n\n1. Make sure Anki is not running (to avoid database locks)\n\n2. Set the path to your Anki collection (optional):\n```bash\nexport ANKI_COLLECTION_PATH=\"/path/to/your/collection.anki2\"\n```\n\n3. Run the server:\n```bash\npython -m anki_mcp.server\n```\n\n## Available Resources\n\n- `anki://decks` - List all available Anki decks\n- `anki://deck/{deck_name}/cards` - List all cards in a specific deck\n- `anki://recent/reviewed` - View cards reviewed in the last 24 hours\n- `anki://recent/learned` - View cards learned (graduated from new) in the last 24 hours\n\n## Available Tools\n\n### Basic Card Management\n- `add_card(deck_name: str, front: str, back: str)` - Add a new card to a deck\n- `review_card(card_id: int, ease: int)` - Review a card with a specific ease (1-4)\n- `get_card_history(card_id: int)` - Get detailed review history for a specific card\n\n### Japanese Vocabulary Features\n- `import_japanese_vocab(csv_path: str, deck_name: str, tags: str = None)` - Import Japanese vocabulary from CSV\n- `update_notes_with_sentences(vocab_sentences: Dict[str, List[str]], deck_name: str = \"Try! N3 Vocab\")` - Add sample sentences to vocabulary notes\n\n### Review History\n- `get_deck_review_history(deck_name: str)` - Get review history for all cards in a deck within the past 24 hours\n\n## Available Prompts\n\n- `create_deck_prompt(deck_name: str)` - Get help creating a new deck\n- `review_history_prompt()` - Get help analyzing review history\n- `study_japanese_vocab_prompt()` - Get help with Japanese vocabulary study\n- `vocab_sentences_json_prompt()` - Generate JSON dictionary mapping vocab to sample sentences\n\n## Japanese Note Type Requirements\n\nThe server expects a note type called \"Japanese (recognition)\" with the following fields:\n1. Expression (Japanese word)\n2. Meaning (English meaning)\n3. Reading (with furigana and sample sentences)\n\n## License\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "vishalsachdev--canvas-mcp": {
      "owner": "vishalsachdev",
      "name": "canvas-mcp",
      "url": "https://github.com/vishalsachdev/canvas-mcp",
      "imageUrl": "https://github.com/vishalsachdev.png",
      "description": "Interact with the Canvas Learning Management System API to manage courses, assignments, users, and announcements. Access course details, submissions, and generate summaries effortlessly.",
      "stars": 21,
      "forks": 9,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-04T04:41:57Z",
      "readme_content": "# Canvas MCP Server\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nThis repository contains a Model Context Protocol (MCP) server implementation for interacting with the Canvas Learning Management System API. The server is designed to work with Claude Desktop and other MCP-compatible clients.\n\n> **Note**: Recently refactored to a modular architecture for better maintainability. The legacy monolithic implementation has been archived.\n\n## Overview\n\nThe Canvas MCP Server bridges the gap between Claude Desktop and Canvas Learning Management System, providing **both students and educators** with an intelligent interface to their Canvas environment. Built on the Model Context Protocol (MCP), it enables natural language interactions with Canvas data.\n\n### For Students ğŸ‘¨â€ğŸ“\nGet AI-powered assistance with:\n- Tracking upcoming assignments and deadlines\n- Monitoring your grades across all courses\n- Managing peer review assignments\n- Accessing course content and discussions\n- Organizing your TODO list\n\n**[â†’ Get Started as a Student](./docs/STUDENT_GUIDE.md)**\n\n### For Educators ğŸ‘¨â€ğŸ«\nEnhance your teaching with:\n- Assignment and grading management\n- Student analytics and performance tracking\n- Discussion and peer review facilitation\n- **FERPA-compliant** student data handling\n- Bulk messaging and communication tools\n\n**[â†’ Get Started as an Educator](./docs/EDUCATOR_GUIDE.md)**\n\n## ğŸ”’ Privacy & Data Protection\n\n### For Educators: FERPA Compliance\n\nComplete FERPA compliance through systematic data anonymization when working with student data:\n\n- **Source-level data anonymization** converts real names to consistent anonymous IDs (Student_xxxxxxxx)\n- **Automatic email masking** and PII filtering from discussion posts and submissions\n- **Local-only processing** with configurable privacy controls (`ENABLE_DATA_ANONYMIZATION=true`)\n- **FERPA-compliant analytics**: Ask \"Which students need support?\" without exposing real identities\n- **De-anonymization mapping tool** for faculty to correlate anonymous IDs with real students locally\n\nAll student data is anonymized **before** it reaches AI systems. See [Educator Guide](./docs/EDUCATOR_GUIDE.md) for configuration details.\n\n### For Students: Your Data Stays Private\n\n- **Your data only**: Student tools access only your own Canvas data via Canvas API's \"self\" endpoints\n- **Local processing**: Everything runs on your machine - no data sent to external servers\n- **No tracking**: Your Canvas usage and AI interactions remain private\n- **No anonymization needed**: Since you're only accessing your own data, there are no privacy concerns\n\n## Prerequisites\n\n- **Python 3.10+** - Required for modern features and type hints\n- **Canvas API Access** - API token and institution URL\n- **MCP Client** - Claude Desktop (recommended) or other MCP-compatible client\n\n### Supported MCP Clients\n\nCanvas MCP works with any application that supports the Model Context Protocol. Popular options include:\n\n**Recommended:**\n- **[Claude Desktop](https://claude.ai/download)** - Official Anthropic desktop app with full MCP support\n\n**AI Coding Assistants:**\n- **[Zed](https://zed.dev)** - High-performance code editor with built-in MCP support\n- **[Cursor](https://cursor.sh)** - AI-first code editor\n- **[Windsurf IDE](https://codeium.com/windsurf)** (by Codeium) - AI-powered development environment\n- **[Continue](https://continue.dev)** - Open-source AI code assistant\n\n**Development Platforms:**\n- **[Replit](https://replit.com)** - Cloud-based coding platform with MCP integration\n- **[Sourcegraph Cody](https://sourcegraph.com/cody)** - AI coding assistant with MCP support\n\n**Enterprise:**\n- **[Microsoft Copilot Studio](https://www.microsoft.com/microsoft-copilot/microsoft-copilot-studio)** - MCP support in enterprise environments\n\nSee the [official MCP clients list](https://modelcontextprotocol.io/clients) for more options.\n\n> **Note**: While Canvas MCP is designed to work with any MCP client, setup instructions in this guide focus on Claude Desktop. Configuration for other clients may vary.\n\n## Quick Start (Automated Installation)\n\nThe fastest way to get started is with our automated installer:\n\n```bash\n# Clone the repository\ngit clone https://github.com/vishalsachdev/canvas-mcp.git\ncd canvas-mcp\n\n# Run the automated installer\npython scripts/install.py\n```\n\nThe installer will:\n- âœ… Set up Python environment with `uv` package manager\n- âœ… Install all dependencies automatically  \n- âœ… Create environment configuration template\n- âœ… Configure Claude Desktop integration\n- âœ… Test the installation\n\n## Manual Installation\n\nIf you prefer manual setup:\n\n### 1. Install Dependencies\n\n```bash\n# Install uv package manager (faster than pip)\npip install uv\n\n# Install the package\nuv pip install -e .\n```\n\n### 2. Configure Environment\n\n```bash\n# Copy environment template\ncp env.template .env\n\n# Edit with your Canvas credentials\n# Required: CANVAS_API_TOKEN, CANVAS_API_URL\n```\n\nGet your Canvas API token from: **Canvas â†’ Account â†’ Settings â†’ New Access Token**\n\n### 3. Claude Desktop Setup\n\nAdd to `~/Library/Application Support/Claude/claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"canvas-api\": {\n      \"command\": \"canvas-mcp-server\"\n    }\n  }\n}\n```\n\n## Verification\n\nTest your setup:\n\n```bash\n# Test Canvas API connection\ncanvas-mcp-server --test\n\n# View configuration\ncanvas-mcp-server --config\n\n# Start server (for manual testing)\ncanvas-mcp-server\n```\n\n## Available Tools\n\nThe Canvas MCP Server provides a comprehensive set of tools for interacting with the Canvas LMS API. These tools are organized into logical categories for better discoverability and maintainability.\n\n### Tool Categories\n\n**Student Tools** (New!)\n- Personal assignment tracking and deadline management\n- Grade monitoring across all courses\n- TODO list and peer review management\n- Submission status tracking\n\n**Shared Tools** (Both Students & Educators)\n1. **Course Tools** - List and manage courses, get detailed information, generate summaries with syllabus content\n2. **Discussion & Announcement Tools** - Manage discussions, announcements, and replies\n3. **Page & Content Tools** - Access pages, modules, and course content\n\n**Educator Tools**\n4. **Assignment Tools** - Handle assignments, submissions, and peer reviews with analytics\n5. **Rubric Tools** - Full CRUD operations for rubrics with validation, association management, and grading\n6. **User & Enrollment Tools** - Manage enrollments, users, and groups\n7. **Analytics Tools** - View student analytics, assignment statistics, and progress tracking\n8. **Messaging Tools** - Send messages and announcements to students\n\nğŸ“– [View Full Tool Documentation](tools/README.md) for detailed information about all available tools.\n\n## Usage with MCP Clients\n\nThis MCP server works seamlessly with any MCP-compatible client:\n\n1. **Automatic Startup**: MCP clients start the server when needed\n2. **Tool Integration**: Canvas tools appear in your AI assistant's interface\n3. **Natural Language**: Interact naturally with prompts like:\n\n**Students:**\n- *\"What assignments do I have due this week?\"*\n- *\"Show me my current grades\"*\n- *\"What peer reviews do I need to complete?\"*\n- *\"Have I submitted everything for BADM 350?\"*\n\n**Educators:**\n- *\"Which students haven't submitted the latest assignment?\"*\n- *\"Create an announcement about tomorrow's exam\"*\n- *\"Show me peer review completion analytics\"*\n\n## Project Structure\n\nModern Python package structure following 2025 best practices:\n\n```\ncanvas-mcp/\nâ”œâ”€â”€ pyproject.toml             # Modern Python project config\nâ”œâ”€â”€ env.template              # Environment configuration template\nâ”œâ”€â”€ src/\nâ”‚   â””â”€â”€ canvas_mcp/            # Main package\nâ”‚       â”œâ”€â”€ __init__.py        # Package initialization\nâ”‚       â”œâ”€â”€ server.py          # Main server entry point\nâ”‚       â”œâ”€â”€ core/              # Core utilities\nâ”‚       â”‚   â”œâ”€â”€ config.py      # Configuration management\nâ”‚       â”‚   â”œâ”€â”€ client.py      # HTTP client\nâ”‚       â”‚   â”œâ”€â”€ cache.py       # Caching system\nâ”‚       â”‚   â””â”€â”€ validation.py  # Input validation\nâ”‚       â”œâ”€â”€ tools/             # MCP tool implementations\nâ”‚       â”‚   â”œâ”€â”€ courses.py     # Course management\nâ”‚       â”‚   â”œâ”€â”€ assignments.py # Assignment tools\nâ”‚       â”‚   â”œâ”€â”€ discussions.py # Discussion tools\nâ”‚       â”‚   â”œâ”€â”€ rubrics.py     # Rubric tools\nâ”‚       â”‚   â””â”€â”€ other_tools.py # Misc tools\nâ”‚       â””â”€â”€ resources/         # MCP resources\nâ”œâ”€â”€ scripts/\nâ”‚   â””â”€â”€ install.py            # Automated installation\nâ””â”€â”€ docs/                     # Documentation\n```\n\n## Documentation\n\n- **[Tool Documentation](./tools/README.md)** - Complete reference for all available tools\n- **[Pages Implementation Guide](./docs/PAGES_IMPLEMENTATION.md)** - Comprehensive Pages feature guide\n- **[Course Documentation Template](./docs/course_documentation_prompt_template.md)** - Hybrid approach for efficient course documentation\n- **[Development Guide](./docs/CLAUDE.md)** - Architecture details and development reference\n## Technical Details\n\n### Modern Architecture (2025)\n\nBuilt with current Python ecosystem best practices:\n\n- **Package Structure**: Modern `src/` layout with `pyproject.toml`\n- **Dependency Management**: Fast `uv` package manager with locked dependencies\n- **Configuration**: Environment-based config with validation and templates\n- **Entry Points**: Proper CLI commands via `pyproject.toml` scripts\n- **Type Safety**: Full type hints and runtime validation\n\n### Core Components\n\n- **FastMCP Framework**: Robust MCP server implementation with tool registration\n- **Async Architecture**: `httpx` client with connection pooling and rate limiting\n- **Smart Caching**: Intelligent request caching with configurable TTL\n- **Configuration System**: Environment-based config with validation and defaults\n- **Educational Focus**: Tools designed for real teaching workflows\n\n### Dependencies\n\nModern Python packages (see `pyproject.toml`):\n- **`fastmcp`**: MCP server framework\n- **`httpx`**: Async HTTP client\n- **`python-dotenv`**: Environment configuration\n- **`pydantic`**: Data validation and settings\n- **`python-dateutil`**: Date/time handling\n\n### Performance Features\n\n- **Connection Pooling**: Reuse HTTP connections for efficiency\n- **Request Caching**: Minimize redundant Canvas API calls\n- **Async Operations**: Non-blocking I/O for concurrent requests\n- **Smart Pagination**: Automatic handling of Canvas API pagination\n- **Rate Limiting**: Respect Canvas API limits with backoff\n\n### Development Tools\n\n- **Automated Setup**: One-command installation script\n- **Configuration Testing**: Built-in connection and config testing\n- **Type Checking**: `mypy` support for type safety\n- **Code Quality**: `ruff` and `black` for formatting and linting\n\nFor contributors, see the [Development Guide](./docs/CLAUDE.md) for detailed architecture and development reference.\n\n## Troubleshooting\n\nIf you encounter issues:\n\n1. **Server Won't Start** - Verify your [Configuration](#configuration) setup: `.env` file, virtual environment path, and dependencies\n2. **Authentication Errors** - Check your Canvas API token validity and permissions\n3. **Connection Issues** - Verify Canvas API URL correctness and network access\n4. **Debugging** - Check Claude Desktop console logs or run server manually for error output\n\n## Security & Privacy Features\n\n### API Security\n- Your Canvas API token grants access to your Canvas account\n- Never commit your `.env` file to version control\n- The server runs locally on your machine - no external data transmission\n- Consider using a token with limited permissions if possible\n\n### Privacy Controls (Educators Only)\n\nEducators working with student data can enable FERPA-compliant anonymization:\n\n```bash\n# In your .env file\nENABLE_DATA_ANONYMIZATION=true  # Anonymizes student names/emails before AI processing\nANONYMIZATION_DEBUG=true        # Debug anonymization (optional)\n```\n\nStudents don't need anonymization since they only access their own data.\n\nFor detailed privacy configuration, see:\n- **[Educator Guide](./docs/EDUCATOR_GUIDE.md)** - FERPA compliance and anonymization\n- **[Student Guide](./docs/STUDENT_GUIDE.md)** - Privacy information for students\n\n## Contributing\n\nContributions are welcome! Feel free to:\n- Submit issues for bugs or feature requests\n- Create pull requests with improvements\n- Share your use cases and feedback\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n---\n\nCreated by [Vishal Sachdev](https://github.com/vishalsachdev)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "waldzellai--model-enhancement-servers": {
      "owner": "waldzellai",
      "name": "model-enhancement-servers",
      "url": "https://github.com/waldzellai/model-enhancement-servers",
      "imageUrl": "https://github.com/waldzellai.png",
      "description": "Enables models to perform structured analogical thinking by mapping and evaluating relationships between source and target domains. Supports problem-solving, explanation, and creative ideation through systematic analogy construction and inference generation.",
      "stars": 63,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-30T04:52:01Z",
      "readme_content": "# Cognitive Enhancement MCP Servers\n\nA collection of Model Context Protocol servers that provide cognitive enhancement tools for large language models.\n\n## Servers\n\nThis monorepo contains the following MCP servers:\n\n1. **Structured Argumentation** - A server for formal dialectical reasoning\n2. **Visual Reasoning** - A server for diagrammatic thinking and spatial representation\n3. **Scientific Method** - A server for hypothesis testing and evidence evaluation\n4. **Analogical Reasoning** - A server for structured metaphorical thinking\n5. **Metacognitive Monitoring** - A server for knowledge assessment and confidence tracking\n6. **Decision Framework** - A server for structured decision analysis\n7. **Collaborative Reasoning** - A server for multi-perspective problem solving\n8. **Ethical Reasoning** - A server for evaluating actions with moral frameworks\n9. **Bias Detection** - A server for flagging potentially biased wording\n10. **Constraint Solver** - A server for validating logical and numeric constraints\n11. **Narrative Planner** - A server for generating simple story outlines\n12. **Goal Tracker** - A server for maintaining and completing objectives\n13. **Multimodal Synthesizer** - A server for combining text and image descriptions\n\n## Potential Future Servers\n\nThe following server ideas are under consideration to further extend model reasoning capabilities:\n\n1. **Emotion-Aware Interaction** - Provides sentiment tracking and mood-aware responses to improve empathic communication.\n2. **Long-Term Memory** - Maintains persistent context across sessions for continuity and recall of past interactions.\n\n\n## Installation\n\nEach server can be installed individually:\n\n```bash\n# Using npm\nnpm install @waldzellai/structured-argumentation\n\n# Using yarn\nyarn add @waldzellai/structured-argumentation\n```\n\n## Usage with Claude Desktop\n\nAdd this to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"structured-argumentation\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@waldzellai/structured-argumentation\"\n      ]\n    }\n  }\n}\n```\n\n## Docker\n\nAll servers are available as Docker images:\n\n```bash\ndocker run --rm -i waldzellai/structured-argumentation\n```\n\n## Development\n\nClone the repository and install dependencies:\n\n```bash\ngit clone https://github.com/waldzellai/model-enhancement-servers.git\ncd model-enhancement-servers\nnpm install\n```\n\nBuild all packages:\n\n```bash\nnpm run build\n```\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Wendong-Fan--HowToLiveLonger": {
      "owner": "Wendong-Fan",
      "name": "HowToLiveLonger",
      "url": "https://github.com/Wendong-Fan/HowToLiveLonger",
      "imageUrl": "https://github.com/Wendong-Fan.png",
      "description": "Provides evidence-based lifestyle insights aimed at improving longevity through nutrition, exercise, and wellness practices. Users can explore actionable recommendations to reduce mortality risk.",
      "stars": 13,
      "forks": 0,
      "license": "The Unlicense",
      "language": "",
      "updated_at": "2025-09-11T07:34:26Z",
      "readme_content": "# ç¨‹åºå‘˜å»¶å¯¿æŒ‡å—\n\n[![CN doc](https://img.shields.io/badge/æ–‡æ¡£-ä¸­æ–‡ç‰ˆ-blue.svg)](README.md)\n[![EN doc](https://img.shields.io/badge/document-English-blue.svg)](README_en.md)\n[![MetaGPT](https://img.shields.io/badge/å‡å°‘å·¥ä½œæ—¶é—´-MetaGPT-blue)](https://github.com/geekan/MetaGPT)\n\n\n- [1. æœ¯è¯­](#1-æœ¯è¯­)\n- [2. ç›®æ ‡](#2-ç›®æ ‡)\n- [3. å…³é”®ç»“æœ](#3-å…³é”®ç»“æœ)\n- [4. åˆ†æ](#4-åˆ†æ)\n- [5. è¡ŒåŠ¨](#5-è¡ŒåŠ¨)\n- [6. è¯æ®](#6-è¯æ®)\n  - [6.1. è¾“å…¥](#61-è¾“å…¥)\n    - [6.1.1. å›ºä½“](#611-å›ºä½“)\n    - [6.1.2. æ¶²ä½“](#612-æ¶²ä½“)\n    - [6.1.3. æ°”ä½“](#613-æ°”ä½“)\n    - [6.1.4. å…‰ç…§](#614-å…‰ç…§)\n    - [6.1.5. è¯ç‰©](#615-è¯ç‰©)\n  - [6.2. è¾“å‡º](#62-è¾“å‡º)\n    - [6.2.1. æŒ¥æ‹è¿åŠ¨](#621-æŒ¥æ‹è¿åŠ¨)\n    - [6.2.2. å‰§çƒˆè¿åŠ¨](#622-å‰§çƒˆè¿åŠ¨)\n    - [6.2.3. èµ°è·¯](#623-èµ°è·¯)\n    - [6.2.4. åˆ·ç‰™](#624-åˆ·ç‰™)\n    - [6.2.5. æ³¡æ¾¡](#625-æ³¡æ¾¡)\n    - [6.2.6. åšå®¶åŠ¡ï¼ˆè€å¹´ç”·æ€§ï¼‰](#626-åšå®¶åŠ¡è€å¹´ç”·æ€§)\n    - [6.2.7. ç¡çœ ](#627-ç¡çœ )\n    - [6.2.8. ä¹…å](#628-ä¹…å)\n  - [6.3. ä¸Šä¸‹æ–‡](#63-ä¸Šä¸‹æ–‡)\n    - [6.3.1. æƒ…ç»ª](#631-æƒ…ç»ª)\n    - [6.3.2. è´«å¯Œ](#632-è´«å¯Œ)\n    - [6.3.3. ä½“é‡](#633-ä½“é‡)\n    - [6.3.4. æ–°å† ](#634-æ–°å† )\n\n---\n\n### 1. æœ¯è¯­\n\n* ACM: All-Cause Mortality / å…¨å› æ­»äº¡ç‡\n\n### 2. ç›®æ ‡\n\n* ç¨³å¥çš„æ´»å¾—æ›´ä¹…\n* èŠ±æ›´å°‘æ—¶é—´å·¥ä½œï¼šè§[MetaGPT](https://github.com/geekan/MetaGPT)\n\n### 3. å…³é”®ç»“æœ\n\n* é™ä½66.67%å…¨å› æ­»äº¡ç‡\n* å¢åŠ \\~20å¹´é¢„æœŸå¯¿å‘½\n* ~~ç»´æŒå¤šå·´èƒºäºä¸­è½´~~\n\n### 4. åˆ†æ\n\n* ä¸»è¦å‚è€ƒï¼šå¯¹ACMçš„å­¦æœ¯æ–‡çŒ®ç›¸å¯¹è¾ƒå¤šï¼Œå¯ä»¥ä½œä¸ºä¸»è¦å‚è€ƒ\n* å¢åŠ å¯¿å‘½ä¸ACMå…³ç³»éçº¿æ€§ï¼šæ˜¾ç„¶å¢åŠ å¯¿å‘½ä¸ACMå…³ç³»æ˜¯éçº¿æ€§å‡½æ•°ï¼Œè¿™é‡Œå‡è®¾ `Î”LifeSpan=(1/(1+Î”ACM)-1)*10`ï¼ˆÎ”ACMä¸ºACMå˜åŒ–å€¼ï¼›å…¬å¼æ¬¢è¿ä¼˜åŒ–ï¼‰\n* å˜é‡æ— æ³•ç®€å•å åŠ ï¼šæ˜¾ç„¶å„ä¸ªå˜é‡ä¹‹é—´å¹¶ä¸ç¬¦åˆç‹¬ç«‹åŒåˆ†å¸ƒå‡è®¾ï¼Œå˜é‡ä¹‹é—´çš„å®é™…å½±å“ä¹Ÿå¹¶ä¸æ˜ç¡®\n* å­˜åœ¨çŸ›ç›¾è§‚ç‚¹ï¼šæ‰€æœ‰çš„è¯æ®éƒ½æœ‰æ–‡çŒ®/ç ”ç©¶å¯¹åº”ï¼Œä½†æ³¨æ„åˆ°ï¼šæœ‰äº›æ–‡çŒ®ä¹‹é—´æœ‰æ˜¾è‘—çŸ›ç›¾çš„è§‚ç‚¹ï¼ˆå¦‚å¯¹äºç¢³æ°´æ‘„å…¥æ¯”ä¾‹çš„çŸ›ç›¾ï¼‰ï¼›æœ‰äº›æ–‡çŒ®å­˜åœ¨è¾ƒå¤§äº‰è®®ï¼ˆå¦‚è®¤ä¸º22ç‚¹å‰ç¡è§‰ä¼šæå‡43%å…¨å› æ­»äº¡ç‡ï¼‰\n* ç ”ç©¶ä»…è¡¨è¾¾ç›¸å…³ï¼šæ‰€æœ‰æ–‡çŒ®è¡¨æ˜çš„æ›´å¤šæ˜¯ç›¸å…³è€Œéå› æœï¼Œåœ¨é˜…è¯»æ—¶è¦è€ƒè™‘æ–‡çŒ®æ˜¯å¦å……åˆ†è¯æ˜äº†å› æœ â€”â€” å¦‚æŸæ–‡çŒ®è¡¨æ˜äº†æ—¥å‡>=7000æ­¥çš„äººæœ‰æ˜¾è‘—ä½çš„å…¨å› æ­»äº¡ç‡ã€‚ä½†æ­¥æ•°å°‘çš„äººå¯èƒ½åŒ…å«æ›´å¤šé•¿æœŸç—…æ‚£ï¼Œå¦‚æœæ²¡æœ‰åˆç†çš„æ’é™¤è¿™å—æ•°æ®ï¼Œé‚£æ­¤æ–‡çŒ®è°ƒæŸ¥å¤±çœŸ\n\n### 5. è¡ŒåŠ¨\n\n* è¾“å…¥\n  * å›ºä½“ï¼šåƒç™½è‚‰ï¼ˆ-11%\\~-3% ACMï¼‰ã€è”¬æœä¸ºä¸»ï¼ˆ-26%\\~-17% ACMï¼‰ï¼Œå¤šåƒè¾£ï¼ˆ-23% ACMï¼‰ï¼Œå¤šåƒåšæœï¼ˆ-27%\\~-4% ACMï¼‰ï¼Œä¸­é‡ç¢³æ°´ã€å¤šåƒæ¤ç‰©è›‹ç™½ï¼ˆ-10% ACMï¼‰ï¼Œå°‘åƒè¶…åŠ å·¥é£Ÿç‰©ï¼ˆ-62%\\~-18%ï¼‰\n  * æ¶²ä½“ï¼šå–å’–å•¡ï¼ˆ-22%\\~-12% ACMï¼‰ï¼Œå–ç‰›å¥¶ï¼ˆ-17%\\~-10% ACMï¼‰ï¼Œå–èŒ¶ï¼ˆ-15%\\~-8% ACMï¼‰ï¼Œå°‘å–æˆ–ä¸å–ç”œå‘³é¥®æ–™ï¼ˆå¦åˆ™æ¯å¤©ä¸€æ¯+7% ACMï¼Œ+å¤šå·´èƒºï¼‰ï¼Œæˆ’é…’ï¼ˆå¦åˆ™+\\~50% ACMï¼Œæ— ä¸Šé™ï¼‰\n  * æ°”ä½“ï¼šä¸å¸çƒŸï¼ˆå¦åˆ™+~50% ACMï¼Œ-12\\~-11å¹´å¯¿å‘½ï¼‰\n  * å…‰ç…§ï¼šæ™’å¤ªé˜³ï¼ˆ-~40% ACMï¼‰\n  * è¯ç‰©ï¼šäºŒç”²åŒèƒï¼ˆç³–å°¿ç—…äººç›¸æ¯”æ­£å¸¸äººå¯ä»¥+3å¹´ï¼‰ã€å¤åˆç»´ç”Ÿç´ ï¼ˆ-8%ç™Œç—‡é£é™©ï¼‰ã€äºšç²¾èƒºï¼ˆ-60%\\~-30% ACMï¼‰ã€è‘¡è„ç³–èƒºï¼ˆ-39% ACMï¼‰\n* è¾“å‡º\n  * è¿åŠ¨ï¼šæ¯å‘¨3æ¬¡45åˆ†é’ŸæŒ¥æ‹è¿åŠ¨ï¼ˆ-47% ACMï¼‰\n  * æ—¥å¸¸ï¼šåˆ·ç‰™ï¼ˆ-25% ACMï¼‰\n  * ç¡çœ ï¼šæ¯å¤©ç¡7å°æ—¶å…¨å› æ­»äº¡ç‡æœ€ä½ï¼›ä¸”22-24ç‚¹é—´æœ€å¥½ï¼Œ*æ—©ç¡+43% ACMï¼Œæ™šç¡+15% ACMï¼ˆå­˜åœ¨äº‰è®®ï¼‰*\n* ä¸Šä¸‹æ–‡\n  * ä½“é‡ï¼šå‡è‚¥ï¼ˆ-54% ACMï¼‰\n\n### 6. è¯æ®\n\n#### 6.1. è¾“å…¥\n\n##### 6.1.1. å›ºä½“\n\n* ç™½è‚‰\n  * [JAMAå­åˆŠï¼šé£Ÿç”¨çº¢è‚‰å’ŒåŠ å·¥è‚‰ç±»ä¼šå¢åŠ å¿ƒè„ç—…å’Œæ­»äº¡é£é™©ï¼é±¼è‚‰å’Œå®¶ç¦½è‚‰åˆ™ä¸ä¼š](https://zhuanlan.zhihu.com/p/268401670)\n    * å‡ºå¤„ï¼š[Associations of Processed Meat, Unprocessed Red Meat, Poultry, or Fish Intake With Incident Cardiovascular Disease and All-Cause Mortality](https://jamanetwork.com/journals/jamainternalmedicine/articlepdf/2759737/jamainternal_zhong_2020_oi_190112.pdf)\n    * å¢åŠ çº¢è‚‰æ‘„å…¥ä¸æ­»äº¡é£é™©ç›¸å…³ã€‚å…«å¹´å†…å¹³å‡æ¯å¤©å¢åŠ è‡³å°‘åŠä»½çº¢è‚‰æ‘„å…¥ï¼ˆåŠä»½çº¢è‚‰ç›¸å½“äº14gåŠ å·¥çº¢è‚‰æˆ–40géåŠ å·¥çº¢è‚‰ï¼‰çš„è°ƒæŸ¥å¯¹è±¡ï¼Œåœ¨æ¥ä¸‹æ¥å…«å¹´å†…å…¨å› æ­»äº¡é£é™©å¢åŠ 10ï¼…ï¼ˆHR, 1.10; 95%CI, 1.04-1.17ï¼‰ï¼›æ¯å‘¨åƒä¸¤ä»½çº¢è‚‰æˆ–åŠ å·¥è‚‰ç±»ï¼ˆä½†ä¸åŒ…æ‹¬å®¶ç¦½æˆ–é±¼ç±»ï¼‰ä¼šä½¿å…¨å› æ­»äº¡é£é™©å¢åŠ 3%\n    * ![çº¢è‚‰](https://user-images.githubusercontent.com/2707039/163703960-6f321de5-4daa-4ea5-95b9-af9c96f1c1bc.jpg)\n  * [çº¢è‚‰å’Œç™½è‚‰æœ€å¤§çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿä¸ºå•¥è¦è¿™ä¹ˆåˆ†å‘¢ï¼Ÿ](https://www.zhihu.com/question/67223570/answer/809785380)\n* è”¬æœ\n  * [æ¯å¹´54ä¸‡äººæ­»äº¡ï¼Œç«Ÿæ˜¯å› ä¸ºæ°´æœåƒå¾—å°‘ï¼ï¼Ÿè¿™å·²æˆåå¤§æ­»äº¡å› ç´ ä¹‹ä¸€ï¼](https://www.sohu.com/a/322360740_164924)\n    * å‡ºå¤„ï¼š[Estimated Global, Regional, and National Cardiovascular Disease Burdens Related to Fruit and Vegetable Consumption: An Analysis from the Global Dietary Database (FS01-01-19) ](https://academic.oup.com/cdn/article-abstract/3/Supplement_1/nzz028.FS01-01-19/5516583)\n    * æ¯å¤©æ‘„å…¥200å…‹æ–°é²œæ°´æœå¯ä½¿æ­»äº¡ç‡é™ä½17%ï¼Œç³–å°¿ç—…å¤§è¡€ç®¡å¹¶å‘ç—‡ï¼ˆå¦‚ä¸­é£ã€ç¼ºè¡€æ€§å¿ƒè„ç—…ç­‰ï¼‰é£é™©é™ä½13%ï¼ŒåŠç³–å°¿ç—…å°è¡€ç®¡å¹¶å‘ç—‡ï¼ˆå¦‚ç³–å°¿ç—…è‚¾ç—…ã€ç³–å°¿ç—…çœ¼ç—…ã€ç³–å°¿ç—…è¶³ç—…ç­‰ï¼‰é£é™©é™ä½28%\n  * [ã€Šè‡ªç„¶ã€‹å­åˆŠï¼šæ¯å¤©äºŒä¸¤è¥¿å…°èŠ±ï¼Œå¥åº·é•¿å¯¿éƒ½æœ‰å•¦ï¼åˆ†æè¿‘6ä¸‡äºº23å¹´çš„æ•°æ®å‘ç°ï¼Œåƒå«é»„é…®ç±»é£Ÿç‰©ä¸æ­»äº¡é£é™©é™ä½20%ç›¸å…³ä¸¨ä¸´åºŠå¤§å‘ç°](https://mp.weixin.qq.com/s/E6BAi-Vnhr1jXBm0Pys2ZQ)\n    * å‡ºå¤„ï¼š[Flavonoid intake is associated with lower mortality in the Danish Diet Cancer and Health Cohort](https://www.nature.com/articles/s41467-019-11622-x)\n    * åƒå«é»„é…®ç±»é£Ÿç‰©ä¸æ­»äº¡é£é™©é™ä½20%ç›¸å…³\n    * ![é»„é…®](https://user-images.githubusercontent.com/2707039/163703969-42e64f88-e727-4e7d-85f2-07a92e29b613.jpg)\n    * Bondonnoåšå£«è¯´é“â€œåƒä¸åŒè”¬èœã€æ°´æœè¡¥å……ï¼Œä¸åŒç§ç±»çš„é»„é…®ç±»åŒ–åˆç‰©æ˜¯å¾ˆé‡è¦çš„ï¼Œè¿™å¾ˆå®¹æ˜“é€šè¿‡é¥®é£Ÿå®ç°ï¼šä¸€æ¯èŒ¶ã€ä¸€ä¸ªè‹¹æœã€ä¸€ä¸ªæ©˜å­ã€100å…‹è“è“ï¼Œæˆ–100å…‹è¥¿å…°èŠ±ï¼Œå°±èƒ½æä¾›å„ç§é»„é…®ç±»åŒ–åˆç‰©ï¼Œå¹¶ä¸”æ€»å«é‡è¶…è¿‡500æ¯«å…‹ã€‚\n* è¾£æ¤’\n  * [è¾£æ¤’æˆæ­»äº¡å…‹æ˜Ÿï¼Ÿæ®è°ƒç ”ï¼Œå¸¸åƒè¾£æ‚£ç—…æ­»äº¡é£é™©å¯é™ä½61%](https://3g.163.com/dy/article/F6Q7I1ME053228ZU.html)\n    * å‡ºå¤„1ï¼š[Chili pepper consumption and mortality in Italian adults](https://www.sciencedirect.com/science/article/pii/S0735109719382063)\n\t* å‡ºå¤„2ï¼š[The Association of Hot Red Chili Pepper Consumption and Mortality: A Large Population-Based Cohort Study](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0169876)\n    * 2017å¹´Plos One çš„å¦ä¸€é¡¹æ¥è‡ªç¾å›½çš„ç ”ç©¶ä»¥16179åï¼Œå¹´é¾„åœ¨18å²ä»¥ä¸Šçš„äººç¾¤ä¸ºå¯¹è±¡ï¼Œå¹¶å¯¹å…¶è¿›è¡Œäº†é«˜è¾¾19å¹´çš„éšè®¿ï¼Œå‘ç°åœ¨4946ä¾‹æ­»äº¡æ‚£è€…ä¸­ï¼Œé£Ÿç”¨è¾£æ¤’çš„å‚ä¸è€…çš„å…¨å› æ­»äº¡ç‡ä¸º21.6ï¼…ï¼Œè€Œæœªé£Ÿç”¨è¾£æ¤’çš„å‚ä¸è€…çš„å…¨å› æ­»äº¡ç‡ä¸º33.6ï¼…ã€‚ç›¸è¾ƒäºä¸åƒè¾£æˆ–å¾ˆå°‘åƒï¼ˆå°‘äºæ¯å‘¨ä¸¤æ¬¡ï¼‰çš„äººç¾¤ï¼Œæ¯å‘¨åƒè¾£ï¼4æ¬¡çš„äººç¾¤æ€»æ­»äº¡é£é™©é™ä½23%ï¼Œå¿ƒè¡€ç®¡æ­»äº¡é£é™©é™ä½34%ã€‚\n* é¸¡è›‹\n  * [æ¯å¤©å¤šåƒåŠä¸ªè›‹ï¼Œå¢åŠ 7%çš„å…¨å› å’Œå¿ƒè¡€ç®¡æ­»äº¡é£é™©ï¼Ÿ](https://m.thepaper.cn/baijiahao_11540780)\n    * å‡ºå¤„ï¼š[NIH-AARPå·¥ä½œä¸»é¡µ](https://dietandhealth.cancer.gov/)ã€[Egg and cholesterol consumption and mortality from cardiovascular and different causes in the United States: A population-based cohort study](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7872242/)\n    * æ¯å¤©å¤šåƒåŠä¸ªè›‹ï¼Œå¢åŠ 7%çš„å…¨å› å’Œå¿ƒè¡€ç®¡æ­»äº¡é£é™©ï¼Ÿåœ¨å‡è®¾æ€§æ›¿ä»£åˆ†æä¸­ï¼Œç ”ç©¶è€…å‘ç°ï¼Œç”¨ç­‰é‡çš„è›‹æ¸…/é¸¡è›‹æ›¿ä»£ç‰©ã€å®¶ç¦½ã€é±¼ã€ä¹³åˆ¶å“ã€åšæœå’Œè±†ç±»åˆ†åˆ«æ›¿ä»£åŠåªå…¨è›‹ï¼ˆ25å…‹/å¤©ï¼‰å¯ä»¥é™ä½6%ã€8%ã€9%ã€7%ã€13%å’Œ10%çš„å…¨å› æ­»äº¡ç‡ã€‚\n\t*[é¸¡è›‹](https://raw.githubusercontent.com/qhy040404/Image-Resources-Repo/master/pmed.1003508.g002.jpg)\n* åšæœ\n  * [å“ˆä½›20å¹´ç ”ç©¶ï¼šåƒæ ¸æ¡ƒçš„äººæ›´é•¿å¯¿ï¼Œæ˜¾è‘—å‡å°‘å…¨å› æ­»äº¡ï¼Œå»¶é•¿å¯¿å‘½](https://www.163.com/dy/article/GKVOMMMF05148PF4.html)\n    * å‡ºå¤„ï¼š[Association of Walnut Consumption with Total and Cause-Specific Mortality and Life Expectancy in US Adults](https://www.mdpi.com/2072-6643/13/8/2699/pdf)\n    * é€šè¿‡åˆ†æå‘ç°ï¼Œç»å¸¸é£Ÿç”¨æ ¸æ¡ƒå¯ä»¥å»¶é•¿å¯¿å‘½ï¼Œé™ä½å¿ƒè¡€ç®¡ç–¾ç—…æ­»äº¡é£é™©ã€‚æ¯”èµ·ä¸åƒæ ¸æ¡ƒï¼Œæ¯å‘¨é£Ÿç”¨æ ¸æ¡ƒ5ä»½ä»¥ä¸Šï¼ˆ1ä»½28å…‹ï¼‰çš„å¥åº·é¢„æœŸå¯¿å‘½å»¶é•¿1.3å²ï¼Œå…¨å› æ­»äº¡é£é™©é™ä½14%ï¼Œå¿ƒè¡€ç®¡ç–¾ç—…æ­»äº¡ç‡é™ä½25%ã€‚\n  * [ç ”ç©¶ï¼šæ¯æ—¥é£Ÿç”Ÿåšæœï¼Œæ­»äº¡ç‡é™20%](https://zhuanlan.zhihu.com/p/44454030)\n    * å‡ºå¤„1ï¼š[Association of nut consumption with total and cause-specific mortality](https://www.nejm.org/doi/full/10.1056/NEJMoa1307352)\n    * å‡ºå¤„2ï¼š[APG_Health-&-Nutrition-Research-Brochure_DEC-19-18](https://americanpistachios.cn/sites/china/files/inline-files/APG_Health-%26-Nutrition-Research-Brochure_DEC-19-18.pdf)\n    * ç ”ç©¶äººå‘˜å‘ç°ï¼Œæ¯å‘¨åƒæ ‘åšæœä½äº1ç›å¸ä»½é‡çš„äººï¼Œæ­»äº¡ç‡é™ä½7ï¼…ã€‚è€Œæ¯å‘¨åƒäº†1ç›å¸ä»½é‡çš„äººï¼Œå‡å°‘11ï¼…çš„æ­»äº¡ç‡ï¼›æ¯å‘¨åƒ2ä»½é‡çš„äººï¼Œå‡ä½13ï¼…ï¼›æ¯å‘¨5è‡³6ä»½é‡è€…ï¼Œå‡å°‘äº†15ï¼…ï¼›ä¸€å‘¨7ä»½ä»¥ä¸Šçš„äººï¼Œæ­»äº¡ç‡åˆ™å‡å°‘20ï¼…ã€‚\n    * å¦å¤–ä¸¤ç¯‡å‘è¡¨åœ¨ã€Šå…¬å…±ç§‘å­¦å›¾ä¹¦é¦†åœ¨çº¿æœŸåˆŠã€‹(Public Library of Science Online Journal)å’Œã€Šç”Ÿç‰©åŒ»å­¦ä¸­å¿ƒã€‹(BioMed Central)ä¸Šçš„åŒ»å­¦é¢„ç§‘ç ”ç©¶è®ºæ–‡ï¼Œå±•ç¤ºäº†è¯•éªŒå¼€å§‹æ—¶çš„æ¨ªæ–­é¢æ•°æ®ã€‚è¿™ä¸¤é¡¹ç ”ç©¶éƒ½è¯„ä¼°äº†7,216åå¯¹è±¡ï¼Œä»¥åŠä»–ä»¬é£Ÿç”¨åšæœçš„é¢‘ç‡å’Œæ•°é‡ä¹‹é—´çš„å…³ç³»ã€‚é‚£äº›æ¯å‘¨é£Ÿç”¨ä¸‰ä»½ä»¥ä¸Šåšæœ(åŒ…æ‹¬å¼€å¿ƒæœ)çš„ç ”ç©¶å¯¹è±¡çš„æ­»äº¡ç‡é™ä½39%ã€‚\n* é’ ï¼ˆå­˜æœ‰å¤§é‡äº‰è®®ï¼‰\n  * [Eur Heart Jï¼šé’ æ‘„å…¥é‡ä¸é¢„æœŸå¯¿å‘½ã€å…¨å› æ­»äº¡ç‡çš„å…³ç³»](https://nursing.medsci.cn/article/show_article.do;jsessionid=A34E8A33918A152CB55BDD2E5FB1798D?id=afe720486ee7)\n    * å‡ºå¤„ï¼š[Messerli F H, Hofstetter L, Syrogiannouli L, et al. Sodium intake, life expectancy, and all-cause mortality[J]. European heart journal, 2021, 42(21): 2103-2112.](https://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC8169157&blobtype=pdf)\n    * ![ehaa947f6](https://user-images.githubusercontent.com/2707039/164894778-9710f18d-e055-4f62-bdcb-618687771d77.jpeg)\n    * åœ¨è¯¥åˆ†ææ‰€åŒ…å«çš„181ä¸ªå›½å®¶ä¸­ï¼Œç ”ç©¶äººå‘˜å‘ç°é’ æ‘„å…¥é‡ä¸å‡ºç”Ÿæ—¶çš„å¥åº·é¢„æœŸå¯¿å‘½ï¼ˆÎ²=2.6å¹´/å…‹æ¯æ—¥é’ æ‘„å…¥é‡ï¼ŒR<sup>2</sup>=0.66ï¼ŒP<0.001ï¼‰å’Œ60å²æ—¶çš„å¥åº·é¢„æœŸå¯¿å‘½ï¼ˆÎ²=0.3å¹´/å…‹æ¯æ—¥é’ æ‘„å…¥é‡ï¼ŒR<sup>2</sup>=0.60ï¼ŒP=0.048ï¼‰ä¹‹é—´å­˜åœ¨æ­£ç›¸å…³å…³ç³»ï¼Œä½†ä¸éä¼ æŸ“æ€§ç–¾ç—…æ­»äº¡ï¼ˆÎ²=17æ¬¡äº‹ä»¶/å…‹æ¯æ—¥é’ æ‘„å…¥é‡ï¼ŒR<sup>2</sup>=0.43ï¼ŒP=0.100ï¼‰æ— å…³ã€‚ç›¸åï¼Œå…¨å› æ­»äº¡ç‡ä¸é’ æ‘„å…¥é‡æˆè´Ÿç›¸å…³ï¼ˆÎ²=âˆ’131æ¬¡äº‹ä»¶/å…‹æ¯æ—¥é’ æ‘„å…¥é‡ï¼ŒR<sup>2</sup>=0.60ï¼ŒP<0.001ï¼‰ã€‚åœ¨ä»…é™äº46ä¸ªæ”¶å…¥æœ€é«˜å›½å®¶çš„æ•æ„Ÿæ€§åˆ†æä¸­ï¼Œé’ æ‘„å…¥é‡ä¸å‡ºç”Ÿæ—¶çš„å¥åº·é¢„æœŸå¯¿å‘½å‘ˆæ­£ç›¸å…³ï¼ˆÎ²=3.4å¹´/å…‹æ¯æ—¥é’ æ‘„å…¥é‡ï¼ŒR<sup>2</sup>=0.53ï¼ŒP<0.001ï¼‰ï¼Œè€Œä¸å…¨å› æ­»äº¡ç‡ï¼ˆÎ²=âˆ’168æ¬¡äº‹ä»¶/å…‹æ¯æ—¥é’ æ‘„å…¥é‡ï¼ŒR<sup>2</sup>=0.50ï¼ŒP<0.001ï¼‰å‘ˆè´Ÿç›¸å…³ã€‚\n    * è¯¥ï¼ˆå¤§èŒƒå›´ï¼‰ç ”ç©¶è®¤ä¸ºæ›´å¤šçš„é’ æ‘„å…¥ä¸æ˜¾è‘—æ›´ä½çš„å…¨å› æ­»äº¡ç‡æœ‰å…³\n    * [é’ˆå¯¹è¯¥è®ºæ–‡çš„å»¶ä¼¸è§£è¯»å’Œè®¨è®ºï¼šA Fresh Foray in the Salt Wars: Life Expectancy Higher With Greater Sodium Intake](https://www.tctmd.com/news/fresh-foray-salt-wars-life-expectancy-higher-greater-sodium-intake)\n  * [NEJM/Lancetï¼šä¸è¦åƒå¤ªå¤šç›ï¼Œä¸­å›½é¥®é£Ÿæ‰€è‡´å¿ƒè¡€ç®¡ç—…å’Œç™Œç—‡æ­»äº¡å…¨çƒç¬¬ä¸€ï¼Œåƒä½é’ ç›å¯é™ä½å…¨å› æ­»äº¡ç‡](https://ibook.antpedia.com/x/669028.html)\n    * ä½†ä¹Ÿæœ‰å¤šé¡¹ç ”ç©¶è®¤ä¸ºç”¨ä½é’ ç›å¯ä»¥é™ä½ä¸€ç³»åˆ—ç–¾ç—…çš„å‘ç”Ÿæ¦‚ç‡ï¼Œå¯¹å…¨å› æ­»äº¡ç‡çš„å‡å°‘æœ‰ç§¯æå½±å“\n* ç¢³æ°´ï¼ˆå­˜æœ‰å¤§é‡äº‰è®®ï¼‰\n  * [ä½ç¢³ç”Ÿé…®é¥®é£Ÿï¼ˆå››ï¼‰ç¢³æ°´åŒ–åˆç‰©ä¸é•¿æœŸæ­»äº¡ç‡](https://zhuanlan.zhihu.com/p/137815934)\n    * å‡ºå¤„ï¼šThe Lancet Public Health - [Dietary carbohydrate intake and mortality: a prospective cohort study and meta-analysis](https://www.sciencedirect.com/science/article/pii/S246826671830135X)\n    * ç¢³æ°´è¶Šä½ï¼Œå¯¿å‘½è¶ŠçŸ­ï¼›ç¢³æ°´è¶Šé«˜ï¼Œå¯¿å‘½ä¹Ÿè½»å¾®ç¼©çŸ­ï¼›ç¢³æ°´50%å·¦å³ï¼ˆå…¶å®æŒ‰ç…§ä¸€èˆ¬çš„è¯´æ³•ï¼Œè¿™ä¹Ÿç®—é«˜ç¢³æ°´ï¼‰æ˜¯æœ€é•¿å¯¿å‘½åŒºé—´ \n    * ![ç¢³æ°´](https://user-images.githubusercontent.com/2707039/163703985-a2e2f8ac-101a-4f3c-903b-6850507f144b.jpg)\n  * [æœ€å¼ºè¥å…»æ­é…ï¼BMJï¼šè¿™ä¹ˆåƒï¼Œå¿ƒè¡€ç®¡ç–¾ç—…å’Œæ­»äº¡é£é™©æ›´ä½](https://www.chinacdc.cn/gwxx/202003/t20200323_214639.html)\n* æ§Ÿæ¦”\n  * [å¦‚ä½•çœ‹å¾…æ§Ÿæ¦”åš¼å‡ºæ¥çš„ç™Œç—‡ï¼Ÿæ§Ÿæ¦”è‡´ç™Œé£é™©ç©¶ç«Ÿæœ‰å¤šå¤§ï¼Ÿ - ä¸é¦™åŒ»ç”Ÿçš„å›ç­” - çŸ¥ä¹](https://www.zhihu.com/question/312784161/answer/603370131)\n    * å‡ºå¤„ï¼šChewing Betel Quid and the Risk of Metabolic Disease, Cardiovascular Disease, and All-Cause Mortality: A Meta-Analysis(https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0070679)\n    * åš¼æ§Ÿæ¦”ä¼šå¢åŠ 21%çš„å…¨å› æ­»äº¡ç‡\n* çƒ­é‡é™åˆ¶\n  * [æ€ä¹ˆçœ‹å¾…BBCã€Šè¿›é£Ÿã€æ–­é£Ÿä¸é•¿å¯¿ã€‹ï¼Ÿ](https://www.zhihu.com/question/31395511)\n    * é™åˆ¶å¡è·¯é‡ŒåŠ¨ç‰©å®éªŒï¼šCRï¼ˆçƒ­é‡é™åˆ¶ï¼Œå³å°‘åƒï¼‰å»¶è¿Ÿäº†æ’æ²³çŒ´çš„å¤šç§ç–¾ç—…å‘ç—…å’Œæ­»äº¡ç‡ï¼Œä¸CRåŠ¨ç‰©ç›¸æ¯”ï¼Œæ­£å¸¸å–‚å…»çš„çŒ´å­çš„å„ç§ç–¾ç—…æ‚£ç—…é£é™©å¢åŠ 2.9å€ï¼Œæ­»äº¡é£é™©å¢åŠ 3.0å€ã€‚\n    * ![çƒ­é‡é™åˆ¶-æ’æ²³çŒ´](https://user-images.githubusercontent.com/2707039/163703988-8767185b-326a-4783-b2e2-f190322bb7d6.jpg)\n* ç»¼åˆ\n  * [æœ€å¼ºè¥å…»æ­é…ï¼BMJï¼šè¿™ä¹ˆåƒï¼Œå¿ƒè¡€ç®¡ç–¾ç—…å’Œæ­»äº¡é£é™©æ›´ä½](https://www.chinacdc.cn/gwxx/202003/t20200323_214639.html)\n  * [Associations of fat and carbohydrate intake with cardiovascular disease and mortality: prospective cohort study of UK Biobank participants](https://doi.org/10.1136/bmj.m688)\n    * é€šè¿‡å¯¹è¿™äº›å‚ä¸è€…çš„æ•°æ®è¿›è¡Œåˆ†æï¼Œç ”ç©¶äººå‘˜å‘ç°ç¢³æ°´åŒ–åˆç‰©ï¼ˆç³–ã€æ·€ç²‰å’Œçº¤ç»´ï¼‰å’Œè›‹ç™½è´¨çš„æ‘„å…¥ä¸å…¨å› æ­»äº¡ç‡å‘ˆéçº¿æ€§å…³ç³»ï¼Œè€Œè„‚è‚ªåˆ™ä¸å…¨å› æ­»äº¡ç‡å‘ˆçº¿æ€§ç›¸å…³ã€‚å…¶ä¸­ï¼Œè¾ƒé«˜çš„ç³–åˆ†æ‘„å…¥ä¸å…¨å› æ­»äº¡é£é™©å’Œæ‚£å¿ƒè¡€ç®¡ç–¾ç—…çš„é£é™©è¾ƒé«˜å‡æœ‰å…³è”ï¼Œè€Œè¾ƒé«˜çš„é¥±å’Œè„‚è‚ªé…¸æ‘„å…¥ä¸å…¨å› æ­»äº¡é£é™©è¾ƒé«˜æœ‰å…³ã€‚\n    * å›¾1ï¼šå„ç§è¥å…»å…ƒç´ ä¸å…¨å› æ­»äº¡ä¹‹é—´çš„å…³ç³»\n    * ![å„ç§è¥å…»å…ƒç´ ä¸å…¨å› æ­»äº¡ä¹‹é—´çš„å…³ç³»](https://user-images.githubusercontent.com/2707039/163702022-8c2bfea9-ed5d-4fe0-8ead-e8740014b92b.jpg)\n    * å›¾2ï¼šå„ç§è¥å…»å…ƒç´ ä¸å¿ƒè¡€ç®¡ç–¾ç—…ä¹‹é—´çš„å…³ç³»\n    * ![å„ç§è¥å…»å…ƒç´ ä¸å¿ƒè¡€ç®¡ç–¾ç—…ä¹‹é—´çš„å…³ç³»](https://user-images.githubusercontent.com/2707039/163702084-97fb4a03-707c-475d-b88e-6fe2f8e87f92.jpg)\n    * **è¿›ä¸€æ­¥ç ”ç©¶è¡¨æ˜ï¼Œåœ¨æ‰€æœ‰çš„é¥®é£Ÿæ¨¡å¼ä¸­ï¼Œå…¨å› æ­»äº¡ç‡é£é™©æœ€ä½çš„é¥®é£Ÿæ–¹å¼ä¸ºï¼š10-30gé«˜çº¤ç»´ã€14-30%è›‹ç™½è´¨ã€10-25%å•ä¸é¥±å’Œè„‚è‚ªé…¸ã€5%-7%å¤šä¸é¥±å’Œè„‚è‚ªé…¸ä»¥åŠ20%-30%æ·€ç²‰æ‘„å…¥ã€‚**\n    * **æœ€ä¼˜èƒ½é‡æ¥æºé…æ¯”ï¼š<24%æ·€ç²‰ï¼Œ15%-17%è›‹ç™½è´¨ï¼Œ>15%å•ä¸é¥±å’Œè„‚è‚ªé…¸ï¼Œ<15%ç³–ï¼Œ6%é¥±å’Œè„‚è‚ªé…¸ï¼Œ6%å¤šä¸é¥±å’Œè„‚è‚ªé…¸ï¼Œ30g+é«˜çº¤ç»´**\n  * [BMJ | å¸¸åƒè–¯ç‰‡æ±‰å ¡å·§å…‹åŠ›ç­‰é£Ÿå“ï¼Œå¹³å‡æ­»äº¡å¹´é¾„ä»…ä»…ä¸º58å²ï¼Œæ­»äº¡é£é™©å‰§å¢](https://med.ckcest.cn/details.html?id=5183272274855936&classesEn=news)\n    * [Rico-CampÃ  A, MartÃ­nez-GonzÃ¡lez M A, Alvarez-Alvarez I, et al. Association between consumption of ultra-processed foods and all cause mortality: SUN prospective cohort study[J]. bmj, 2019, 365.](https://www.bmj.com/content/365/bmj.l1949.full)\n    * [Srour B, Fezeu L K, Kesse-Guyot E, et al. Ultra-processed food intake and risk of cardiovascular disease: prospective cohort study (NutriNet-SantÃ©)[J]. bmj, 2019, 365.](https://www.bmj.com/content/365/bmj.l1451)\n    * [Lawrence M A, Baker P I. Ultra-processed food and adverse health outcomes[J]. bmj, 2019, 365.](https://www.researchgate.net/profile/Phillip-Baker-5/publication/333483796_Ultra-processed_food_and_adverse_health_outcomes/links/5f0c646ca6fdcc2f32336a95/Ultra-processed-food-and-adverse-health-outcomes.pdf)\n\n##### 6.1.2. æ¶²ä½“\n\n* ç‰›å¥¶\n  * [ã€ŠæŸ³å¶åˆ€ã€‹è°ƒç ”21ä¸ªå›½å®¶13ä¸‡äººï¼šæ¯å¤©1æ–¤ç‰›å¥¶æˆ–é…¸å¥¶ï¼Œå¿ƒè¡€ç®¡æ­»äº¡é£é™©ä¸‹é™23%](https://www.sohu.com/a/253940257_419768)\n  * å‡ºå¤„ï¼š[Association of dairy intake with cardiovascular disease and mortality in 21 countries from five continents (PURE): a prospective cohort study](http://mdrf-eprints.in/1114/1/Association_of_dietary_patterns_and_dietary_diversity_with_cardiometabolic_disease_risk_factors.pdf)\n  * ä¸ä¸é£Ÿç”¨ä¹³åˆ¶å“çš„äººç›¸æ¯”ï¼Œæ¯å¤©æ‘„å…¥ä¸¤ä»½ä¹³åˆ¶å“ï¼ˆä¸€ä»½æŒ‡244å…‹ç‰›å¥¶/é…¸å¥¶ï¼Œ15å…‹å¥¶é…ªæˆ–5å…‹é»„æ²¹ï¼‰çš„äººï¼Œ**å…¨å› æ­»äº¡é£é™©ä¸‹é™äº†17%**ï¼Œå¿ƒè¡€ç®¡æ­»äº¡é£é™©ä¸‹é™23%ï¼Œä¸­é£é£é™©ä¸‹é™33%\n* èŒ¶\n  * [10ä¸‡ä¸­å›½äººéšè®¿7å¹´å‘ç°ï¼Œæ¯å‘¨å–ä¸‰æ¬¡èŒ¶ä¸å…¨å› æ­»äº¡é£é™©é™ä½15%ï¼Œé¢„æœŸå¯¿å‘½å¢åŠ 1.26å¹´ç›¸å…³ ](https://www.jianshu.com/p/5461a205cf95?utm_campaign=hugo)\n  * å‡ºå¤„ï¼š[Tea consumption and the risk of atherosclerotic cardiovascular disease and all-cause mortality: The China-PAR project](https://www.researchgate.net/profile/Fangchao-Liu-4/publication/338483323_Tea_consumption_and_the_risk_of_atherosclerotic_cardiovascular_disease_and_all-cause_mortality_The_China-PAR_project/links/5e55e5e94585152ce8efe511/Tea-consumption-and-the-risk-of-atherosclerotic-cardiovascular-disease-and-all-cause-mortality-The-China-PAR-project.pdf)\n  * [ä¸­å›½æˆå¹´äººé¥®èŒ¶ä¸æ­»äº¡é£é™©çš„å‰ç»æ€§å…³è”ç ”ç©¶](http://rs.yiigle.com/CN112338202202/1351516.htm)\n  * çº³å…¥åˆ†æçš„438 443ä¾‹ç ”ç©¶å¯¹è±¡éšè®¿11.1å¹´å…±å‘ç”Ÿæ­»äº¡34 661ä¾‹ã€‚ä¸ä»ä¸é¥®èŒ¶è€…ç›¸æ¯”ï¼Œå½“å‰éæ¯æ—¥é¥®èŒ¶è€…å’Œæ¯æ—¥é¥®èŒ¶è€…å…¨å› æ­»äº¡HRå€¼ï¼ˆ95%CIï¼‰ä¾æ¬¡ä¸º0.89ï¼ˆ0.86-0.91ï¼‰å’Œ0.92ï¼ˆ0.88-0.95ï¼‰ã€‚åˆ†æ€§åˆ«åˆ†ææ˜¾ç¤ºï¼Œé¥®èŒ¶å¯¹å…¨å› æ­»äº¡é£é™©çš„ä¿æŠ¤ä½œç”¨ä¸»è¦è§äºç”·æ€§ï¼ˆäº¤äº’P<0.05ï¼‰\n* æ— ç³–ï¼ˆç”œå‘³ï¼‰é¥®æ–™\n  * [ã€Œæ— ç³–é¥®æ–™ä½¿æ­»äº¡é£é™©å¢åŠ  26 %ã€ï¼Œæ˜¯çœŸçš„å—ï¼Ÿ](https://www.zhihu.com/question/418598272/answer/1450648364)\n    * ç›¸æ¯”äºè½¯é¥®æ–™æ‘„å…¥é‡ï¼œ1æ¯/æœˆçš„å‚ä¸è€…ï¼Œæ··åˆè½¯é¥®æ–™æ‘„å…¥â‰¥1æ¯/å¤©çš„å‚ä¸è€…æ­»äº¡é£é™©å¢åŠ 18%ï¼Œè€Œ**æ‘„å…¥å«ç³–è½¯é¥®æ–™æˆ–æ— ç³–è½¯é¥®æ–™ä¼šä»¤æ­»äº¡é£é™©åˆ†åˆ«å¢åŠ 11%å’Œ27%ã€‚**\n    * ![é¥®æ–™](https://user-images.githubusercontent.com/2707039/163704346-e7d92e7f-eba5-4673-8f15-3a96782c2e32.png)\n  * [Association Between Soft Drink Consumption and Mortality in 10 European Countries](https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2749350)\n* æœ‰ç³–é¥®æ–™\n  * [å¯ä¹å’Œå¥¶èŒ¶ï¼Œå¢åŠ å…¨å› æ­»äº¡ç‡é«˜è¾¾62%ï¼æœæ±é™ä½å…ç–«åŠ›ï¼Œå½±å“è‚ä»£è°¢ï¼å«ç³–é¥®æ–™é‚£äº›äº‹](https://zhuanlan.zhihu.com/p/400746073)\n    * æ¯å¤©1æ¯å«ç³–é¥®æ–™å¢åŠ 7%å…¨å› æ­»äº¡ç‡ï¼Œ2æ¯21%\n    * åœ¨34å¹´çš„éšè®¿ä¸­ï¼Œç ”ç©¶äººå‘˜å‘ç°ï¼Œç›¸æ¯”é‚£äº›ä¸€ä¸ªæœˆå–1æ¯æˆ–è€…æ›´å°‘å«ç³–é¥®æ–™çš„äººï¼Œæ¯å¤©å–2æ¯çš„äººæ€»ä½“æ­»äº¡é£é™©å‡é«˜äº†21%ï¼Œå¿ƒè¡€ç®¡ç–¾ç—…æ­»äº¡é£é™©å‡é«˜äº†31%ï¼Œç™Œç—‡æ­»äº¡é£é™©ä¸Šå‡äº†16%ã€‚\n    * åªè¦æ¯å¤©å¤šå–ä¸€æ¯å«ç³–é¥®æ–™ï¼Œæ€»ä½“æ­»äº¡é£é™©å°†å¢åŠ 7%ï¼Œå¿ƒè¡€ç®¡ç–¾ç—…çš„é£é™©å°†å¢åŠ 10%ï¼Œç™Œç—‡ç›¸å…³çš„æ­»äº¡é£é™©å°†16%ã€‚\n    * å‘è¡¨åœ¨å›½é™…é¡¶çº§æœŸåˆŠã€ŠBMJã€‹ä¸Šçš„ä¸€ç¯‡è®ºæ–‡å°±è¯æ˜äº†å«ç³–é¥®æ–™ä¼šåœ¨å¢åŠ æ‚£ç™Œé£é™©ï¼Œå½“ç„¶è¿™ç¯‡æ–‡ç« éªŒè¯çš„ä¸ä»…ä»…æ˜¯æœæ±ï¼Œå¥¶èŒ¶ä¹Ÿæœ‰ä»½â€”â€”å’Œå«ç³–é¥®æ–™ç›¸å…³çš„æ€»ä½“æ‚£ç™Œé£é™©è¦é«˜å‡ºé€šå¸¸å€¼18%ï¼Œ100%çš„é²œæ¦¨æœæ±ä¹Ÿä¼šä½¿å¾—æ•´ä½“çš„æ‚£ç™Œé£é™©ä¸Šå‡12%ã€‚\n* æœæ±\n  * [JAMAå­åˆŠï¼š100%çº¯æœæ±å¯èƒ½æ¯”å«ç³–é¥®æ–™æ›´å±é™©](https://zhuanlan.zhihu.com/p/66513350)\n    * æ¯å¤©å¤šæ‘„å…¥ä¸€ä»½12ç›å¸çš„å«ç³–é¥®æ–™ï¼Œå…¨å› æ­»äº¡ç‡é£é™©å¢åŠ 11%ï¼›\n    * æ¯å¤©å¤šæ‘„å…¥ä¸€ä»½12ç›å¸çš„æœæ±ï¼Œå…¨å› æ­»äº¡ç‡é£é™©å¢åŠ 24%ã€‚\n* å’–å•¡\n  * [é‡ç£…ï¼å¤šç¯‡ç ”ç©¶è¯å®å–å’–å•¡ä¸äººç¾¤å…¨å› æ­»äº¡ç‡é™ä½ç›´æ¥ç›¸å…³](https://news.bioon.com/article/6725420.html)\n  * [ç§‘æ™® | å–å’–å•¡åˆå¤šäº†ä¸€ä¸ªæ–°ç†ç”±ï¼šé™ä½æ­»äº¡ç‡ï¼ ](https://www.sohu.com/a/439412995_100003595)\n  * [åœ°ä¸­æµ·æˆå¹´äººå’–å•¡æ¶ˆè€—é‡åŠå…¨å› ï¼Œå¿ƒè¡€ç®¡ç–¾ç—…å’Œç™Œç—‡çš„æ­»äº¡ç‡](https://fanyi.pdf365.cn/help/249)\n    * åœ¨æœ€è¿‘çš„èŸèƒåˆ†æä¸­ï¼Œè¯¥ç ”ç©¶åŒ…æ‹¬æ¥è‡ªä¸åŒå›½å®¶çš„40é¡¹ç ”ç©¶å’Œ3,852,651åå—è¯•è€…ã€‚åœ¨è¿™é¡¹èŸèƒåˆ†ææ˜¾ç¤ºï¼Œå’–å•¡æ‘„å…¥é‡ä¸å„ç§åŸå› çš„æ­»äº¡ç‡ï¼ŒCVDå’Œç™Œç—‡æ­»äº¡ç‡ä¹‹é—´å­˜åœ¨éçº¿æ€§å…³ç³»ï¼Œæ¯å¤©æ‘„å…¥ä¸¤æ¯å’–å•¡çš„ç™Œç—‡æ­»äº¡ç‡æœ€ä½(RR = 0.96)ï¼ŒCVDæœ€ä½çš„æ­»äº¡ç‡ï¼Œæ¯å¤©2.5æ¯(RR= 0.83)ï¼Œå…¨å¤©æœ€ä½æ­»äº¡ç‡ä¸ºæ¯å¤©3.5æ¯(RR= 0.85)ï¼Œå¹¶ä¸”éšç€å’–å•¡æ¶ˆè´¹é‡çš„å¢åŠ ï¼Œæ­»äº¡ç‡æ²¡æœ‰è¿›ä¸€æ­¥é™ä½æˆ–å¢åŠ \n* äºšç²¾èƒº\n  * [Scienceï¼šç§‘å­¦èƒŒä¹¦ï¼ä»ç²¾æ¶²ä¸­å‘ç°çš„äºšç²¾èƒºï¼Œç«Ÿç„¶æœ‰ç€æŠ—è¡°è€ã€æŠ—ç™Œã€ä¿æŠ¤å¿ƒè¡€ç®¡å’Œç¥ç»ã€æ”¹å–„è‚¥èƒ–å’Œ2å‹ç³–å°¿ç—…ç­‰é€†å¤©ç¥æ•ˆ](https://www.medsci.cn/article/show_article.do?id=420d12904103)\n  * [é¥®é£Ÿä¸­äºšç²¾èƒºæ‘„å…¥é‡é«˜ä¼šé™ä½æ­»äº¡ç‡](https://zhuanlan.zhihu.com/p/388942219)\n\n##### 6.1.3. æ°”ä½“\n\n* å¸çƒŸ\n  * [å³ä½¿æ˜¯ä½å¼ºåº¦å¸çƒŸï¼Œä¹Ÿå¢åŠ æ­»äº¡é£é™©ï¼](https://www.medsci.cn/article/show_article.do?id=02ca2083319b)\n    * ç ”ç©¶å‘ç°ï¼šåœ¨42 416åç”·æ€§å’Œ86 735åå¥³æ€§ï¼ˆå¹´é¾„åœ¨35-89å²ä¹‹é—´ï¼Œä»¥å‰æ²¡æœ‰æ‚£ç—…ï¼‰ä¸­ï¼Œ18 985åç”·æ€§ï¼ˆ45%ï¼‰å’Œ18 072åå¥³æ€§ï¼ˆ21%ï¼‰ç›®å‰å¸çƒŸï¼Œå…¶ä¸­33%çš„ç”·æ€§å¸çƒŸè€…å’Œ39%çš„å¥³æ€§å¸çƒŸè€…å¹¶ä¸æ¯å¤©å¸çƒŸã€‚8866åç”·æ€§ï¼ˆ21%ï¼‰å’Œ53 912åå¥³æ€§ï¼ˆ62%ï¼‰ä»ä¸å¸çƒŸã€‚åœ¨éšè®¿æœŸé—´ï¼Œä¸ä»ä¸å¸çƒŸç›¸æ¯”ï¼Œæ¯å¤©<10æ”¯çƒŸæˆ–æ¯å¤©â‰¥10æ”¯çƒŸçš„å…¨å› æ­»äº¡ç‡å±é™©æ¯”åˆ†åˆ«ä¸º1.17ï¼ˆ95%ç½®ä¿¡åŒºé—´1.10-1.25ï¼‰å’Œ1.54ï¼ˆ1.42-1.67ï¼‰ã€‚æ— è®ºå¹´é¾„æˆ–æ€§åˆ«ï¼Œå±é™©æ¯”ç›¸ä¼¼ã€‚ä¸æ¯æ—¥å¸çƒŸå…³ç³»æœ€å¯†åˆ‡çš„ç–¾ç—…æ˜¯å‘¼å¸é“ç™Œç—‡ã€æ…¢æ€§é˜»å¡æ€§è‚ºç—…å’Œèƒƒè‚ é“åŠè¡€ç®¡ç–¾ç—…ã€‚åœ¨æ‹›å‹Ÿæ—¶å·²ç»æˆ’çƒŸçš„äººçš„æ­»äº¡ç‡ä½äºç°åœ¨æ¯å¤©å¸çƒŸè€…ã€‚\n    * å¸çƒŸè€…å¹³å‡å‡å°‘å¯¿å‘½11-12å¹´\n  * [å¸çƒŸè®©äººè¿‡ç˜¾æ˜¯ä»€ä¹ˆåŸç†ï¼Ÿæœ‰èŠ‚åˆ¶çš„å¸çƒŸä¾æ—§æœ‰å®³å—ï¼Ÿ](https://www.zhihu.com/question/24846224/answer/1719798177)\n\n##### 6.1.4. å…‰ç…§\n\n* æ™’å¤ªé˜³\n  * [æ™’å¤ªé˜³å’Œæ­»äº¡ç‡çš„å…³ç³»ï¼Œå¦‚ä½•ç§‘å­¦ï¼Œå®‰å…¨çš„æ™’å¤ªé˜³ï¼Ÿ\n](https://zhuanlan.zhihu.com/p/76301306)\n    * ä¸¹éº¦ä¸€é¡¹é•¿è¾¾26å¹´çš„ç ”ç©¶å‘ç°ï¼Œå¤šæ™’å¤ªé˜³èƒ½æ˜¾è‘—å»¶é•¿å¯¿å‘½ï¼Œå³ä½¿æ˜¯ç”±äºè¿‡åº¦æš´æ™’è¯±å‘çš®è‚¤ç™Œçš„æ‚£è€…ï¼Œå¹³å‡å¯¿å‘½ä¹Ÿæ¯”æ™®é€šäººé•¿äº†6å²ã€‚\n\n##### 6.1.5. è¯ç‰©\n\n* NMN\n* äºŒç”²åŒèƒ\n  * [â€œèƒâ€å¹å¿…çœ‹ ä¸¨æˆ‘å°±æ˜¯ç¥è¯â€”â€”äºŒç”²åŒèƒ](https://zhuanlan.zhihu.com/p/419202902)\n    * äºŒç”²åŒèƒä¸ä»…åœ¨å¤šç§è‚¿ç˜¤ã€å¿ƒè¡€ç®¡ç–¾ç—…åŠç³–å°¿ç—…ä¸­å‘æŒ¥ä¿æŠ¤ä½œç”¨ï¼Œè€Œä¸”åœ¨è‚¥èƒ–ã€è‚ç—…ã€è‚¾ç—…åŠè¡°è€æ–¹é¢ä¹Ÿå¤§æ”¾å¼‚å½©ã€‚\n  * [äºŒç”²åŒèƒ2020æœ€å€¼å¾—äº†è§£çš„â€œåƒç“œâ€å¤§æ–°é—»â€”â€”æŠ¤èƒƒã€å¥è„‘ã€æŠ—è¡°ã€é˜²ç™Œè¿˜æ˜¯è‡´ç™Œï¼Ÿ](https://zhuanlan.zhihu.com/p/357807109)\n  * [äºŒç”²åŒèƒçœŸçš„é‚£ä¹ˆç¥å—ï¼Ÿç¾ç ”ç©¶ï¼šçˆ¶äº²æœç”¨äºŒç”²åŒèƒæˆ–è‡´å­å¥³æœ‰ç¼ºé™·](https://baijiahao.baidu.com/s?id=1729999374705305768)\n  * ![äºŒç”²åŒèƒ](https://user-images.githubusercontent.com/2707039/163702325-5d427542-9ae5-4311-8979-d0d326a9832f.jpg)\n  * ä¸è‰¯ååº”\n    * ä½œä¸ºä¸€ç§ä½¿ç”¨è¿‘ç™¾å¹´çš„è¯ç‰©ï¼ŒäºŒç”²åŒèƒçš„ä¸è‰¯ååº”å·²ç»éå¸¸æ˜ç¡®ï¼Œå¸¸è§çš„æœ‰ï¼šç»´ç”Ÿç´ B12ç¼ºä¹ï¼ˆ7%-17.4%ï¼‰ï¼Œèƒƒè‚ é“ä¸è‰¯ååº”ï¼ˆæœ€é«˜53%ï¼‰ï¼Œç–²å€¦ï¼ˆ9%ï¼‰ï¼Œå¤´ç—›ï¼ˆ6%ï¼‰ï¼›ä¸¥é‡ä½†ä¸å¸¸è§çš„ä¸è‰¯ååº”åŒ…æ‹¬ä¹³é…¸é…¸ä¸­æ¯’ã€è‚æŸä¼¤ï¼›ä¹Ÿæœ‰ç ”ç©¶è¡¨æ˜å¯èƒ½å¯¹èƒå„¿è‡´ç•¸\n* å¤åˆç»´ç”Ÿç´ \n  * [æœç”¨å¤åˆç»´ç”Ÿç´ å¯é™ä½ç™Œç—‡å±é™©8%ï¼Œå…¶ä»–æ•ˆæœå¹¶ä¸æ˜¾è‘—](https://health.qq.com/a/20121023/000026.htm)\n* è‘¡è„ç³–èƒº\n  * [ç¥å¥‡ï¼æ°¨ç³–é™ä½å¿ƒè¡€ç®¡æ­»äº¡ç‡65%ï¼Œä¸å®šæœŸè¿åŠ¨æ•ˆæœç›¸å½“](https://www.sohu.com/a/436372221_120873241)\n  * ç¾å›½è¥¿å¼—å‰å°¼äºšå¤§å­¦æœ€æ–°ç ”ç©¶å‘ç° æ°¨ç³–ï¼ˆè½¯éª¨ç´ ï¼‰ å¯ä»¥é™ä½å¿ƒè¡€ç®¡æ­»äº¡ç‡65%ï¼Œé™ä½æ€»ä½“æ­»äº¡ç‡39%ï¼Œæ•ˆæœä¸åšæŒå®šæœŸè¿åŠ¨ç›¸å¯¹\n  * è¯¥ç ”ç©¶ä½¿ç”¨1999å¹´è‡³2010å¹´ï¼Œ16,686åæˆå¹´äººçš„å›½å®¶å¥åº·å’Œè¥å…»æ£€æŸ¥(NHANES)æ•°æ®ï¼Œå‚ä¸è€…çš„ä¸­ä½è¿½è¸ªæ—¶é—´ä¸º107ä¸ªæœˆï¼Œè€Œå…¶ä¸­æœ‰648ä½å‚ä¸è€…å®šæœŸä¸”æ¯æœç”¨æ—¥500-1000æ¯«å…‹çš„è‘¡è„ç³–èƒº/è½¯éª¨ç´ ä¸€å¹´ä»¥ä¸Šã€‚\n* äºšç²¾èƒº\n  * [Scienceï¼šç§‘å­¦èƒŒä¹¦ï¼ä»ç²¾æ¶²ä¸­å‘ç°çš„äºšç²¾èƒºï¼Œç«Ÿç„¶æœ‰ç€æŠ—è¡°è€ã€æŠ—ç™Œã€ä¿æŠ¤å¿ƒè¡€ç®¡å’Œç¥ç»ã€æ”¹å–„è‚¥èƒ–å’Œ2å‹ç³–å°¿ç—…ç­‰é€†å¤©ç¥æ•ˆ](https://www.medsci.cn/article/show_article.do?id=420d12904103)\n  * äºšç²¾èƒºæ˜¯æœ€å®¹æ˜“ä»äººä½“è‚ é“å¸æ”¶çš„å¤šèƒºã€‚è®¸å¤šçš„é£Ÿç‰©ä¸­éƒ½å«æœ‰å¤§é‡çš„äºšç²¾èƒºï¼Œä¾‹å¦‚æ–°é²œçš„é’æ¤’ã€å°éº¦èƒšèŠ½ã€èŠ±æ¤°èœã€è¥¿å…°èŠ±ã€è˜‘è‡å’Œå„ç§å¥¶é…ªï¼Œå°¤å…¶åœ¨çº³è±†ç­‰å¤§è±†åˆ¶å“ã€é¦™è‡å’Œæ¦´è²ä¸­å«é‡æ›´é«˜ã€‚åœ¨æœ¬å®éªŒä¸­ï¼Œç ”ç©¶äººå‘˜é€‰æ‹©äº†829ä½å¹´é¾„åœ¨45-84å²ä¹‹é—´çš„å‚ä¸è€…è¿›è¡Œäº†ä¸ºæœŸ20å¹´çš„éšè®¿ï¼Œåˆ†æäº†é¥®é£Ÿä¸­äºšç²¾èƒºæ‘„å…¥é‡ä¸äººç±»æ­»äº¡ç‡ä¹‹é—´çš„æ½œåœ¨å…³è”ã€‚\n  * ç ”ç©¶å‘ç°ï¼Œå¥³æ€§çš„äºšç²¾èƒºæ‘„å…¥é‡é«˜äºç”·æ€§ï¼Œå¹¶ä¸”æ‘„å…¥é‡éƒ½ä¼šéšç€å¹´é¾„çš„å¢é•¿è€Œä¸‹é™ã€‚äºšç²¾èƒºçš„ä¸»è¦æ¥æºæ˜¯å…¨è°·ç‰©ï¼ˆå 13.4%ï¼‰ã€è‹¹æœå’Œæ¢¨ï¼ˆå 13.3%ï¼‰ã€æ²™æ‹‰ï¼ˆå 9.8%ï¼‰ã€èŠ½èœï¼ˆå 7.3%ï¼‰å’Œé©¬é“ƒè–¯ï¼ˆå 6.4%ï¼‰ã€‚ç ”ç©¶æ ¹æ®äºšç²¾èƒºæ‘„å…¥é‡å°†äººç¾¤åˆ†ä¸ºä¸‰ç»„ï¼Œä½æ‘„å…¥é‡ç»„ï¼ˆ<62.2 Âµmol / dï¼‰ã€ä¸­æ‘„å…¥é‡ç»„ï¼ˆ62.2â€“79.8 Âµmol / dï¼‰å’Œé«˜æ‘„å…¥é‡ç»„ï¼ˆ> 79.8 Âµmol / dï¼‰ã€‚éšè®¿æœŸé—´å…±è®°å½•äº†341ä¾‹æ­»äº¡ï¼Œå…¶ä¸­è¡€ç®¡ç–¾ç—…137ä¾‹ï¼Œç™Œç—‡94ä¾‹ï¼Œå…¶ä»–åŸå› 110ä¾‹ã€‚ç»è®¡ç®—ä½ä¸­é«˜ä¸‰ç»„çš„ç²—ç•¥æ­»äº¡ç‡åˆ†åˆ«ä¸º40.5%ã€23.7%å’Œ15.1%ï¼Œè¿™äº›æ•°æ®è¡¨æ˜äºšç²¾èƒºæ‘„å…¥é‡ä¸å…¨å› æ­»äº¡ç‡ä¹‹é—´çš„è´Ÿç›¸å…³å…³ç³»æ˜¾è‘—ã€‚éšç€é€æ­¥å¯¹å¹´é¾„ã€æ€§åˆ«å’Œçƒ­é‡çš„æ¯”ä¾‹è¿›è¡Œè°ƒæ•´ï¼Œè¿™ç§ç›¸å…³å…³ç³»ä¾ç„¶æ˜¾è‘—ã€‚\n* ç»¼åˆ\n  * [ã€Šè‡ªç„¶ã€‹å­åˆŠæ·±åº¦ç»¼è¿°ï¼šå¦‚ä½•å¼€å‘æŠ—è¡°è€è¯](https://zhuanlan.zhihu.com/p/145495570)\n  * ![å¦‚ä½•å¼€å‘æŠ—è¡°è€è¯](https://user-images.githubusercontent.com/2707039/163702474-205baeec-f0ce-4e8d-96a4-36efe47534de.jpg)\n\n#### 6.2. è¾“å‡º\n\n##### 6.2.1. æŒ¥æ‹è¿åŠ¨\n\n* [å“ªç§è¿åŠ¨æ€§ä»·æ¯”æœ€é«˜ï¼Ÿæƒå¨åŒ»å­¦æ‚å¿—â€œæŸ³å¶åˆ€â€ç»™å‡ºç­”æ¡ˆäº† ](https://www.sohu.com/a/535581770_121124216)\n  * ä¸€å‘¨ä¸‰æ¬¡ï¼Œæ¯æ¬¡45-60åˆ†é’Ÿï¼ŒæŒ¥æ‹è¿åŠ¨ï¼Œé™ä½~47%å…¨å› æ­»äº¡ç‡\n  * ç¾½æ¯›çƒã€ä¹’ä¹“çƒã€ç½‘çƒç­‰éƒ½ç®—æŒ¥æ‹è¿åŠ¨ï¼Œä½†ç”±äºè¥¿åŒ–ç ”ç©¶èƒŒæ™¯ï¼Œå¯èƒ½æŒ‡ç½‘çƒæ›´å¤šã€‚è¿™éšå¼çš„è¡¨è¾¾äº†å…¨èº«é”»ç‚¼æ›´ä¸ºé‡è¦\n\n##### 6.2.2. å‰§çƒˆè¿åŠ¨\n\n* [æ–°ç ”ç©¶ï¼šæ¯å¤©å‰§çƒˆè¿åŠ¨8åˆ†é’Ÿï¼Œå¯é™ä½å…¨å› æ­»äº¡å’Œå¿ƒè„ç—…é£é™©](https://academic.oup.com/eurheartj/advance-article/doi/10.1093/eurheartj/ehac572/6771381)\n  * æ¯å‘¨15-20åˆ†é’Ÿçš„å‰§çƒˆè¿åŠ¨ï¼Œé™ä½16-40%çš„å…¨å› æ­»äº¡ç‡ï¼Œå‰§çƒˆè¿åŠ¨æ—¶é—´è¾¾åˆ°50-57åˆ†é’Ÿ/å‘¨ï¼Œå¯ä»¥è¿›ä¸€æ­¥é™ä½å…¨å› æ­»äº¡ç‡ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œé€šè¿‡åœ¨ä¸€å‘¨çš„çŸ­æ—¶é—´å†…ç´¯ç§¯ç›¸å¯¹å°‘é‡çš„å‰§çƒˆè¿åŠ¨å¯ä»¥é™ä½å¥åº·é£é™©ã€‚\n  \n##### 6.2.3. èµ°è·¯\n\n* [èµ°è·¯é™ä½å…¨å› æ­»äº¡ç‡è¶…è¿‡50%ï¼æ¯å¤©èµ°å¤šå°‘æ­¥æœ€åˆé€‚ï¼Ÿã€ŠJAMAã€‹å­åˆŠè¶…10å¹´ç ”ç©¶å‘Šè¯‰ä½ ç­”æ¡ˆ](http://www.shcell.org/219/3571.html)\n  * ![èµ°è·¯é™ä½å…¨å› æ­»äº¡ç‡](https://user-images.githubusercontent.com/2707039/163704147-afec1c79-799b-4db8-b547-1a2431d504c9.jpg)\n  * æ³¨1ï¼šè¿™é¡¹ç ”ç©¶å‚ä¸è€…çš„å¹³å‡å¹´é¾„ä¸º45.2å²\n  * æ³¨2ï¼šå¹³å‡æ­¥æ•°çš„å¤šå°‘ä¸èŒä¸šæœ‰å…³ï¼Œæ­¤é¡¹ç ”ç©¶ä»…è¡¨æ˜ç›¸å…³æ€§ï¼Œè¿˜æ²¡æœ‰æ›´æ·±åº¦çš„å› æœåˆ†æ\n\n##### 6.2.4. åˆ·ç‰™\n\n* [50ä¸‡å›½äººç ”ç©¶è¯å®ï¼šä¸å¥½å¥½åˆ·ç‰™ï¼Œè‡´ç™Œï¼è¡€ç®¡ç–¾ç—…ä¹Ÿä¼šå¢å¤šï¼](https://www.cn-healthcare.com/articlewm/20211209/content-1293760.html)\n  * ç»å¸¸ä¸åˆ·ç‰™çš„äººï¼šç™Œç—‡ã€æ…¢æ€§é˜»å¡æ€§è‚ºç—…åŠè‚ç¡¬åŒ–é£é™©åˆ†åˆ«å¢åŠ äº†9%ã€12%å’Œ25%ï¼Œè¿‡æ—©æ­»äº¡é£é™©å¢åŠ 25%ã€‚\n\n##### 6.2.5. æ³¡æ¾¡\n\n* [å®šæœŸæ´—æ¾¡é™ä½å¿ƒè¡€ç®¡ç–¾ç—…å‘ä½œé£é™©](https://www.cn-healthcare.com/article/20200326/content-533379.html)\n  * ä¸æ¯å‘¨ä¸€è‡³ä¸¤æ¬¡æ³¡æ¾¡æˆ–æ ¹æœ¬ä¸æ³¡æ¾¡ç›¸æ¯”ï¼Œæ¯å¤©æ´—çƒ­æ°´æ¾¡å¯ä»¥é™ä½28%çš„å¿ƒè¡€ç®¡ç–¾ç—…æ€»é£é™©ï¼Œé™ä½26%çš„ä¸­é£æ€»é£é™©ï¼Œè„‘å‡ºè¡€é£é™©ä¸‹é™46%ã€‚è€Œæµ´ç¼¸æµ´çš„é¢‘ç‡ä¸å¿ƒæºæ€§çŒæ­»çš„é£é™©å¢åŠ æ— å…³ã€‚\n\n##### 6.2.6. åšå®¶åŠ¡ï¼ˆè€å¹´ç”·æ€§ï¼‰\n\n* [Housework Reduces All-Cause and Cancer Mortality in Chinese Men](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061529)\n  * 72å²ä¹‹åç”·æ€§æ¯å‘¨åšé‡å‹å®¶åŠ¡å¯ä»¥å‡å°‘29%å¹³å‡æ­»äº¡ç‡\n  * é‡å‹å®¶åŠ¡ï¼šå¸å°˜ã€æ“¦åœ°æ¿ã€æ‹–åœ°ã€æ“¦æ´—çª—æˆ·ã€æ´—è½¦ã€æ¬åŠ¨å®¶å…·ã€æ¬ç…¤æ°”ç½ç­‰ç­‰ã€‚\n  * è½»å‹å®¶åŠ¡ï¼šæ¸ç°å°˜ã€æ´—ç¢—ã€æ‰‹æ´—è¡£æœã€ç†¨çƒ«ã€æ™¾è¡£æœã€åšé¥­ã€ä¹°æ—¥ç”¨å“ç­‰ç­‰ã€‚\n\n##### 6.2.7. ç¡çœ \n\n* [è¶…30ä¸‡äºšæ´²äººæ•°æ®ï¼šæ¯å¤©ç¡å‡ ä¸ªå°æ—¶æœ€æœ‰ç›Šé•¿å¯¿ï¼Ÿ](https://med.sina.com/article_detail_103_1_105491.html)\n  * åœ¨ç”·æ€§ä¸­ï¼Œä¸ç¡çœ æ—¶é•¿ä¸º7å°æ—¶ç›¸æ¯”ï¼šç¡çœ æŒç»­æ—¶é—´â‰¥10å°æ—¶ä¸å…¨å› æ­»äº¡é£é™©å¢åŠ 34%ç›¸å…³ï¼›\n  * ![ç¡çœ -ç”·](https://user-images.githubusercontent.com/2707039/163704166-226b7ebb-92ce-4753-a3e7-77a87652a104.jpg)\n  * åœ¨å¥³æ€§ä¸­ï¼Œä¸ç¡çœ æŒç»­æ—¶é—´7å°æ—¶ç›¸æ¯”ï¼šç¡çœ æŒç»­æ—¶é—´â‰¥10å°æ—¶ä¸å…¨å› æ­»äº¡é£é™©å¢åŠ 48%ç›¸å…³ï¼›\n  * ![ç¡çœ -å¥³](https://user-images.githubusercontent.com/2707039/163704169-c5c715aa-7130-403b-b0d1-ec34fab094d8.png)\n* [é¢ è¦†è®¤çŸ¥ï¼åŠ æ‹¿å¤§ç ”ç©¶å‘ç°ï¼šæ—©ç¡æ¯”ç†¬å¤œæˆ–è®¸æ›´ä¼¤èº«ï¼Œå‡ ç‚¹ç¡æ‰å¥½ï¼Ÿ](https://www.thepaper.cn/newsDetail_forward_14461799)\n  * å…¶ä¸­ä¸€ä¸ªç»“è®ºä¸ºï¼Œå°±å¯æ—¶é—´ä¸å…¨å› æ­»äº¡ç‡çš„å…³è”æ€§å¼ºï¼Œè¿‡æ—©ç¡è§‰å’Œè¿‡æ™šç¡è§‰éƒ½ä¼šå½±å“å¥åº·ï¼Œä½†æ˜¯æ—©ç¡å¢åŠ çš„å…¨å› æ­»äº¡ç‡æ¯”æ™šç¡å¢åŠ çš„æ­»äº¡ç‡é«˜ï¼Œæ—©ç¡å¢åŠ äº†43%çš„æ­»äº¡é£é™©ï¼Œè€Œæ™šç¡å¢åŠ äº†15%çš„æ­»äº¡é£é™©ã€‚\n  * è¿™é¡¹è°ƒæŸ¥ç ”ç©¶ï¼Œè¿˜å­˜åœ¨å¾ˆå¤šå±€é™æ€§ï¼Œæ¯”å¦‚æ²¡æœ‰ç›´æ¥è¯æ˜å°±å¯æ—¶é—´ä¸æ­»äº¡çš„å…³ç³»ï¼Œä»…ä»…è¯´æ˜ç›¸å…³æ€§ï¼Œé€šè¿‡å‚ä¸äººç¾¤è‡ªæˆ‘æŠ¥å‘Šç»Ÿè®¡ç¡çœ æ—¶é—´ï¼Œæ•°æ®ä¸å¤Ÿå®¢è§‚\n\n##### 6.2.8. ä¹…å\n\n* [ä¸­å›½å±…æ°‘è†³é£ŸæŒ‡å—ç§‘å­¦ç ”ç©¶æŠ¥å‘Šï¼ˆ2021å¹´ï¼‰](https://www.chinanutri.cn/yyjkzxpt/yyjkkpzx/yytsg/zgjm/202103/P020210311486742870527.pdf)\n  * ä¹…åå’Œçœ‹ç”µè§†æ—¶é—´ä¸å…¨å› æ­»äº¡ã€å¿ƒè¡€ç®¡ç–¾ç—…ã€ç™Œç—‡å’Œ2å‹ç³–å°¿ç—…å‘ç—…é«˜é£é™©ç›¸å…³ï¼Œæ˜¯ç‹¬ç«‹é£é™©å› ç´ ã€‚ä¹…åæ—¶é—´æ¯å¤©æ¯å¢åŠ 1å°æ—¶ï¼Œå¿ƒè¡€ç®¡ç–¾ç—…å‘ç”Ÿé£é™©å¢åŠ 4%ï¼Œç™Œç—‡å¢åŠ 1%ï¼Œå…¨å› æ­»äº¡é£é™©å¢åŠ 3%ã€‚å…¨å› æ­»äº¡å’ŒCVDæ­»äº¡é£é™©å¢åŠ çš„ä¹…åæ—¶é—´é˜ˆå€¼æ˜¯6\\~8h/dï¼Œçœ‹ç”µè§†æ—¶é—´é˜ˆå€¼æ˜¯3\\~4h/dã€‚\n* [ä¸–å«ç»„ç»‡å…³äºèº«ä½“æ´»åŠ¨å’Œä¹…åè¡Œä¸ºçš„æŒ‡å—](https://apps.who.int/iris/bitstream/handle/10665/337001/9789240014947-chi.pdf)\n\n#### 6.3. ä¸Šä¸‹æ–‡\n\n##### 6.3.1. æƒ…ç»ª\n\n* [æ‚²è§‚æƒ…ç»ªä¸æ›´é«˜çš„å…¨å› æ­»äº¡ç‡å’Œå¿ƒè¡€ç®¡ç–¾ç—…æ­»äº¡ç‡æœ‰å…³ï¼Œä½†ä¹è§‚æƒ…ç»ªå¹¶ä¸èƒ½èµ·åˆ°ä¿æŠ¤ä½œç”¨](https://www.x-mol.com/paper/1288184397379059712/t?recommendPaper=1263704526086578176)\n* [Pessimism is associated with greater all-cause and cardiovascular mortality, but optimism is not protective](https://www.nature.com/articles/s41598-020-69388-y?utm_source=xmol&utm_medium=affiliate&utm_content=meta&utm_campaign=DDCN_1_GL01_metadata_scirep)\n  * åœ¨1993-1995å¹´é—´ï¼Œä¸€é¡¹é’ˆå¯¹50å²ä»¥ä¸Šæ¾³å¤§åˆ©äºšäººå¥åº·çš„åŒèƒèƒç ”ç©¶ä¸­åŒ…æ‹¬äº†ç”Ÿæ´»å–å‘æµ‹è¯•ï¼ˆLOTï¼‰ï¼Œå…¶ä¸­åŒ…å«ä¹è§‚å’Œæ‚²è§‚çš„é¡¹ç›®ã€‚å¹³å‡20å¹´åï¼Œå‚ä¸è€…ä¸æ¥è‡ªæ¾³å¤§åˆ©äºšå›½å®¶æ­»äº¡æŒ‡æ•°çš„æ­»äº¡ä¿¡æ¯ç›¸åŒ¹é…ã€‚åœ¨2,978åå…·æœ‰å¾ˆå¤šå¯ç”¨åˆ†æ•°çš„å‚ä¸è€…ä¸­ï¼Œæœ‰1,068äººæ­»äº¡ã€‚ç”Ÿå­˜åˆ†ææµ‹è¯•äº†å„ç§ä¹è§‚å› ç´ å’Œæ‚²è§‚æƒ…ç»ªåˆ†æ•°ä¸ä»»ä½•åŸå› ï¼Œç™Œç—‡ï¼Œå¿ƒè¡€ç®¡ç–¾ç—…æˆ–å…¶ä»–å·²çŸ¥åŸå› çš„æ­»äº¡ç‡ä¹‹é—´çš„å…³è”ã€‚å¹´é¾„è°ƒæ•´åçš„æ‚²è§‚é‡è¡¨ä¸Šçš„æ ¸å¿ƒä¸å…¨å› å’Œå¿ƒè¡€ç®¡ç–¾ç—…æ­»äº¡ç‡ç›¸å…³ï¼ˆæ¯1ä¸ªæ ‡å‡†å·®å•ä½çš„å±é™©æ¯”ï¼Œ95ï¼…ç½®ä¿¡åŒºé—´å’Œpå€¼1.134ã€1.065â€“1.207ã€8.85Ã—10 â€“5å’Œ1.196ã€1.045â€“1.368ã€0.0093 ï¼‰ï¼Œä½†ä¸ä¼šå› ç™Œç—‡æ­»äº¡ã€‚ä¹è§‚å¾—åˆ†ä¸æ‚²è§‚å¾—åˆ†ä¹‹é—´çš„ç›¸å…³æ€§å¾ˆå¼±ï¼ˆå¹´é¾„è°ƒæ•´åçš„ç­‰çº§ç›¸å…³ç³»æ•°= âˆ’ 0.176ï¼‰ï¼Œä½†ä¸æ€»æ­»äº¡ç‡æˆ–ç‰¹å®šåŸå› æ­»äº¡ç‡æ²¡æœ‰æ˜¾ç€ç›¸å…³æ€§ã€‚åå‘å› æœå…³ç³»ï¼ˆå¼•èµ·æ‚²è§‚æƒ…ç»ªçš„ç–¾ç—…ï¼‰æ˜¯ä¸å¯èƒ½çš„ï¼Œå› ä¸ºåœ¨é‚£ç§æƒ…å†µä¸‹ï¼Œå¿ƒè¡€ç®¡ç–¾ç—…å’Œç™Œç—‡éƒ½ä¼šå¯¼è‡´æ‚²è§‚æƒ…ç»ªã€‚\n\n##### 6.3.2. è´«å¯Œ\n\n* [JAMAå­åˆŠï¼šè´«å¯Œå·®è·çœŸèƒ½å½±å“å¯¿å‘½ï¼Ÿè¿™å¯èƒ½æ˜¯çœŸçš„ï¼](https://www.cn-healthcare.com/articlewm/20210727/content-1246348.html)\n  * è¯¥ç ”ç©¶ä½¿ç”¨1994-1996å¹´ç¬¬ä¸€æ¬¡æ”¶é›†çš„æ•°æ®ï¼Œå¹¶é€šè¿‡ç”Ÿå­˜æ¨¡å‹æ¥åˆ†æå‡€èµ„äº§å’Œé•¿å¯¿ä¹‹é—´çš„å…³è”ã€‚ç»“æœæ˜¾ç¤ºï¼Œå…±æ”¶çº³5414 åå‚ä¸è€…ï¼Œå¹³å‡å¹´é¾„ä¸º 46.7å²ï¼ŒåŒ…æ‹¬ 2766 åå¥³æ€§ã€‚è¾ƒé«˜çš„å‡€èµ„äº§ä¸è¾ƒä½çš„æ­»äº¡é£é™©ç›¸å…³ã€‚ç‰¹åˆ«æ˜¯åœ¨å…„å¼Ÿå§å¦¹å’ŒåŒèƒèƒä¸­ï¼ˆn = 2490ï¼‰ï¼Œåœ¨è¾ƒé«˜çš„å‡€èµ„äº§å’Œè¾ƒä½çš„æ­»äº¡ç‡ä¹‹é—´è§‚å¯Ÿåˆ°ç±»ä¼¼çš„å…³è”ï¼Œè¡¨æ˜æ‹¥æœ‰æ›´å¤šè´¢å¯Œçš„å…„å¼Ÿå§å¦¹æˆ–åŒèƒèƒæ¯”æ‹¥æœ‰æ›´å°‘è´¢å¯Œçš„å…„å¼Ÿå§å¦¹/åŒèƒèƒæ´»å¾—æ›´ä¹…ã€‚\n\n##### 6.3.3. ä½“é‡\n\n* [JAMAå­åˆŠï¼šå‡è‚¥è¦è¶æ—©ï¼Œæ‰èƒ½æœ‰æ•ˆé™ä½æ­»äº¡ç‡é£é™©](https://www.chinacdc.cn/gwxx/202009/t20200904_218959.html)\n  * å¯¹ä½“é‡å‡è½»çš„æ­»äº¡ç‡é£é™©è¯„ä¼°å‘ç°ï¼Œä½“é‡ä»è‚¥èƒ–å‡è½»åˆ°è¶…é‡çš„æˆå¹´äººä¸ç¨³å®šè‚¥èƒ–äººç¾¤ç›¸æ¯”ï¼Œå…¨å› æ­»äº¡ç‡é™ä½äº†54ï¼…ï¼ˆå±é™©æ¯”ä¸º0.46ï¼‰ï¼Œç„¶è€Œä»æˆå¹´åˆæœŸçš„è¶…é‡å‡è½»åˆ°ä¸­å¹´ä»¥å‰çš„æ­£å¸¸ä½“é‡çš„äººç¾¤çš„æ­»äº¡ç‡é£é™©å¹¶æœªé™ä½ï¼ˆé£é™©æ¯”ä¸º1.12ï¼‰ã€‚\n  * ![Table3](https://raw.githubusercontent.com/qhy040404/Image-Resources-Repo/master/zoi200509t3_1596761185.02415.png)\n\n##### 6.3.4. æ–°å† \n\n* [Magnitude, demographics and dynamics of the effect of the first wave of the COVID-19 pandemic on all-cause mortality in 21 industrialized countries](https://www.nature.com/articles/s41591-020-1112-0.pdf)\n  * ç›®å‰æ¥çœ‹ï¼Œæ–°å† æ­»äº¡ç‡ï¼ˆç¾å›½ï¼‰åœ¨1.5%å·¦å³ï¼Œäººå‡é¢„æœŸå¯¿å‘½å‡å°‘äº†2å¹´\n* [å¦‚ä½•çœ‹å¾…ç¾å›½CDCå®£ç§°æ–°å† æ­»äº¡äººæ•°è¢«é«˜ä¼°ï¼Ÿ](https://www.zhihu.com/question/510943670/answer/2308499719)\n* [NVSS deaths](https://www.cdc.gov/nchs/nvss/deaths.htm)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "WhenMoon-afk--claude-memory-mcp": {
      "owner": "WhenMoon-afk",
      "name": "claude-memory-mcp",
      "url": "https://github.com/WhenMoon-afk/claude-memory-mcp",
      "imageUrl": "https://github.com/WhenMoon-afk.png",
      "description": "Enhances Large Language Models with persistent memory capabilities, allowing for the storage, retrieval, and management of memories across conversations. Integrates with the Claude desktop application, supporting various memory types and semantic search.",
      "stars": 33,
      "forks": 7,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T11:43:08Z",
      "readme_content": "# Claude Memory MCP Server\n\nAn MCP (Model Context Protocol) server implementation that provides persistent memory capabilities for Large Language Models, specifically designed to integrate with the Claude desktop application.\n\n![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)\n\n## Overview\n\nThis project implements optimal memory techniques based on comprehensive research of current approaches in the field. It provides a standardized way for Claude to maintain persistent memory across conversations and sessions.\n\n## Features\n\n- **Tiered Memory Architecture**: Short-term, long-term, and archival memory tiers\n- **Multiple Memory Types**: Support for conversations, knowledge, entities, and reflections\n- **Semantic Search**: Retrieve memories based on semantic similarity\n- **Automatic Memory Management**: Intelligent memory capture without explicit commands\n- **Memory Consolidation**: Automatic consolidation of short-term memories into long-term memory\n- **Memory Management**: Importance-based memory retention and forgetting\n- **Claude Integration**: Ready-to-use integration with Claude desktop application\n- **MCP Protocol Support**: Compatible with the Model Context Protocol\n- **Docker Support**: Easy deployment using Docker containers\n\n## Quick Start\n\n### Option 1: Using Docker (Recommended)\n\n```bash\n# Clone the repository\ngit clone https://github.com/WhenMoon-afk/claude-memory-mcp.git\ncd claude-memory-mcp\n\n# Start with Docker Compose\ndocker-compose up -d\n```\n\nConfigure Claude Desktop to use the containerized MCP server (see [Docker Usage Guide](docs/docker_usage.md) for details).\n\n### Option 2: Standard Installation\n\n1. **Prerequisites**:\n   - Python 3.8-3.12\n   - pip package manager\n\n2. **Installation**:\n   ```bash\n   # Clone the repository\n   git clone https://github.com/WhenMoon-afk/claude-memory-mcp.git\n   cd claude-memory-mcp\n   \n   # Install dependencies\n   pip install -r requirements.txt\n   \n   # Run setup script\n   chmod +x setup.sh\n   ./setup.sh\n   ```\n\n3. **Claude Desktop Integration**:\n\n   Add the following to your Claude configuration file:\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"memory\": {\n         \"command\": \"python\",\n         \"args\": [\"-m\", \"memory_mcp\"],\n         \"env\": {\n           \"MEMORY_FILE_PATH\": \"/path/to/your/memory.json\"\n         }\n       }\n     }\n   }\n   ```\n\n## Using Memory with Claude\n\nThe Memory MCP Server enables Claude to remember information across conversations without requiring explicit commands. \n\n1. **Automatic Memory**: Claude will automatically:\n   - Remember important details you share\n   - Store user preferences and facts\n   - Recall relevant information when needed\n\n2. **Memory Recall**: To see what Claude remembers, simply ask:\n   - \"What do you remember about me?\"\n   - \"What do you know about my preferences?\"\n\n3. **System Prompt**: For optimal memory usage, add this to your Claude system prompt:\n\n   ```\n   This Claude instance has been enhanced with persistent memory capabilities.\n   Claude will automatically remember important details about you across\n   conversations and recall them when relevant, without needing explicit commands.\n   ```\n\nSee the [User Guide](docs/user_guide.md) for detailed usage instructions and examples.\n\n## Documentation\n\n- [User Guide](docs/user_guide.md)\n- [Docker Usage Guide](docs/docker_usage.md)\n- [Compatibility Guide](docs/compatibility.md)\n- [Architecture](docs/architecture.md)\n- [Claude Integration Guide](docs/claude_integration.md)\n\n## Examples\n\nThe `examples` directory contains scripts demonstrating how to interact with the Memory MCP Server:\n\n- `store_memory_example.py`: Example of storing a memory\n- `retrieve_memory_example.py`: Example of retrieving memories\n\n## Troubleshooting\n\nIf you encounter issues:\n\n1. Check the [Compatibility Guide](docs/compatibility.md) for dependency requirements\n2. Ensure your Python version is 3.8-3.12\n3. For NumPy issues, use: `pip install \"numpy>=1.20.0,<2.0.0\"`\n4. Try using Docker for simplified deployment\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.",
      "npm_url": "",
      "npm_downloads": 0
    },
    "WilliamCloudQi--matlab-mcp-server": {
      "owner": "WilliamCloudQi",
      "name": "matlab-mcp-server",
      "url": "https://github.com/WilliamCloudQi/matlab-mcp-server",
      "imageUrl": "https://github.com/WilliamCloudQi.png",
      "description": "Integrates MATLAB with AI to execute MATLAB code, generate scripts from natural language descriptions, and access MATLAB documentation directly through your AI assistant.",
      "stars": 47,
      "forks": 18,
      "license": "Apache License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-10-02T17:05:56Z",
      "readme_content": "# MATLAB MCP Server\n\n\n![GitHub Logo](https://github.com/WilliamCloudQi/matlab-mcp-server/blob/main/-------matlab-mcp-----.png)\n## We welcome contributions from everyone.\n\n## A powerful MCP server that integrates MATLAB with AI, allowing you to execute MATLAB code, generate MATLAB scripts from natural language descriptions, and access MATLAB documentation directly through your AI assistant.\n\n<a href=\"https://glama.ai/mcp/servers/t3mmsdxvmd\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/t3mmsdxvmd/badge\" alt=\"MATLAB Server MCP server\" />\n</a>\n\n## Features\n\n### Resources\n- Access MATLAB documentation via `matlab://documentation/getting-started` URI\n- Get started guide with examples and usage instructions\n\n### Tools\n- `execute_matlab_code` - Execute MATLAB code and get results\n  - Run any MATLAB commands or scripts\n  - Option to save scripts for future reference\n  - View output directly in your conversation\n  \n- `generate_matlab_code` - Generate MATLAB code from natural language\n  - Describe what you want to accomplish in plain language\n  - Get executable MATLAB code in response\n  - Option to save generated scripts\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Requirements\n\n- MATLAB installed on your system\n- Node.js (v14 or higher)\n\n## Installation\n\n### Installing via Smithery\n\nTo install MATLAB MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@WilliamCloudQi/matlab-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @WilliamCloudQi/matlab-mcp-server --client claude\n```\n\n### 1. Install the package\n\n```bash\nnpm install -g matlab-mcp-server\n```\n\nOr clone the repository and build it yourself:\n\n```bash\ngit clone https://github.com/username/matlab-mcp-server.git\ncd matlab-mcp-server\nnpm install\nnpm run build\n```\n\n### 2. Configure cline to use the server\n\nTo use with cline , add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"matlab-server\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/matlab-server/build/index.js\"],\n      \"env\": {\n        \"MATLAB_PATH\": \"/path/to/matlab/executable\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\nReplace `/path/to/matlab/executable` with the path to your MATLAB executable:\n- Windows: Usually `C:\\\\Program Files\\\\MATLAB\\\\R2023b\\\\bin\\\\matlab.exe`\n- macOS: Usually `/Applications/MATLAB_R2023b.app/bin/matlab`\n- Linux: Usually `/usr/local/MATLAB/R2023b/bin/matlab`\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/williamcloudqi-matlab-mcp-server-badge.png)](https://mseep.ai/app/williamcloudqi-matlab-mcp-server)\n\n[![smithery badge](https://smithery.ai/badge/@WilliamCloudQi/matlab-mcp-server)](https://smithery.ai/server/@WilliamCloudQi/matlab-mcp-server)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "wuye-ai--mcp-server-wuye-ai": {
      "owner": "wuye-ai",
      "name": "mcp-server-wuye-ai",
      "url": "https://github.com/wuye-ai/mcp-server-wuye-ai",
      "imageUrl": "https://github.com/wuye-ai.png",
      "description": "Intelligent AI assistant tailored for property management, providing access to industry news, hotspot questions, and knowledge base searches. Integrates with applications using SSE or stdio, secured by token-based authentication.",
      "stars": 1,
      "forks": 2,
      "license": "No License",
      "language": "",
      "updated_at": "2025-09-15T02:13:40Z",
      "readme_content": "# CRICç‰©ä¸šAI MCP Server\n\n--------------\n[![NPM Version](https://img.shields.io/npm/v/%40wuye-ai%2Fmcp-server-wuye-ai)](https://www.npmjs.com/package/@wuye-ai/mcp-server-wuye-ai)\n[![zh-CN](https://img.shields.io/badge/lang-zh--CN-red.svg)](https://github.com/wuye-ai/mcp-server-wuye-ai/blob/master/README.md)\n[![en](https://img.shields.io/badge/lang-en-red.svg)](https://github.com/wuye-ai/mcp-server-wuye-ai/blob/master/README.en.md)\n[![Apply For Access Token](https://img.shields.io/badge/%E7%94%B3%E8%AF%B7%E5%BC%80%E9%80%9A-gray?label=%F0%9F%91%8B)](https://wuye-ai.cricbigdata.com/mcp)\n[![Practical Guide](https://img.shields.io/badge/%E5%AE%9E%E8%B7%B5%E6%8C%87%E5%8D%97-gray?label=%F0%9F%A7%AD)](https://wuye-ai.cricbigdata.com/mcp)\n\nå·²ä¸Šæ¶ | \n[<img src=\"https://static-production.npmjs.com/b0f1a8318363185cc2ea6a40ac23eeb2.png\" width=\"12\" height=\"12\" alt=\"NPM Logo\"> **NPM**](https://www.npmjs.com/package/@wuye-ai/mcp-server-wuye-ai) | \n[<img src=\"https://mcp.so/favicon.ico\" width=\"12\" height=\"12\" alt=\"MCP.so Logo\"> **MCP.so**](https://mcp.so/server/CRIC%E7%89%A9%E4%B8%9AAI/CRIC) |\n[<img src=\"https://mcpservers.org/icon.png\" width=\"12\" height=\"12\" alt=\"MCPServers.org Logo\"> **MCPServers.org**](https://mcpservers.org/servers/wuye-ai/mcp-server-wuye-ai) |\n[<img src=\"https://tcb.cloud.tencent.com/favicon.ico\" width=\"12\" height=\"12\" alt=\"è…¾è®¯äº‘å¼€å‘ Logo\"> **è…¾è®¯äº‘å¼€å‘**](https://tcb.cloud.tencent.com/mcp-server/mcp-server-wuye-ai) |\n[<img src=\"https://g.alicdn.com/sail-web/maas/2.8.5/favicon/128.ico\" width=\"12\" height=\"12\" alt=\"ModelScope Logo\"> **ModelScope**](https://modelscope.cn/mcp/servers/@wuye-ai/mcp-server-wuye-ai) |\n[<img src=\"https://gw.alicdn.com/imgextra/i4/O1CN01vVn7g32134zNZEeAR_!!6000000006928-55-tps-24-24.svg\" width=\"12\" height=\"12\" alt=\"é˜¿é‡Œäº‘ç™¾ç‚¼ Logo\"> **é˜¿é‡Œäº‘ç™¾ç‚¼**](https://bailian.console.aliyun.com/?tab=mcp#/mcp-market/detail/cric-wuye-ai) |\n[<img src=\"https://agi-dev-platform-web.cdn.bcebos.com/ai_apaas/favicon.ico\" width=\"12\" height=\"12\" alt=\"ç™¾åº¦æ™ºèƒ½äº‘ Logo\"> **ç™¾åº¦æ™ºèƒ½äº‘åƒå¸†**](https://console.bce.baidu.com/ai_apaas/mcpServerCenter/mcp_t_cric_ai/detail) |\n[<img src=\"https://gips3.baidu.com/it/u=1551671786,626435656&fm=3028&app=3028&f=PNG&fmt=auto&q=100&size=f300_315\" width=\"12\" height=\"12\" alt=\"ç™¾åº¦æœç´¢å¼€æ”¾å¹³å° Logo\"> **ç™¾åº¦æœç´¢å¼€æ”¾å¹³å°**](https://sai.baidu.com/server/CRIC?id=DZy6eHdoKx2v3gfThymJXf)\n\nï¼ˆæ›´å¤šMCPå¹³å°é™†ç»­ä¸Šæ¶ä¸­â€¦â€¦ï¼‰\n\n--------------\n\n## ç®€ä»‹\n\n**CRICç‰©ä¸šAI** æ˜¯ [å…‹è€Œç‘](http://www.cricchina.com/) ä¸“ä¸ºç‰©ä¸šè¡Œä¸šæ‰“é€ çš„æ™ºèƒ½ AI åŠ©ç†ï¼Œäº2025å¹´4æœˆ25æ—¥ [æ­£å¼å‘å¸ƒ](https://mp.weixin.qq.com/s/GC4V1M6N199Ay2f3kZan_Q)ã€‚\n\n**CRICç‰©ä¸šAI** é€šè¿‡è¡Œä¸šçŸ¥è¯†åº“å»ºè®¾ï¼Œç»“åˆå¤šæ¨¡æ€å¤§æ¨¡å‹ + RAG æŠ€æœ¯ï¼Œé›†æˆäº”å¤§æ ¸å¿ƒèƒ½åŠ›æ¨¡å—ï¼š**è¡Œä¸šç ”ç©¶**ã€**æ³•å¾‹æ³•è§„**ã€**ç¤¾åŒºæ²»ç†**ã€**é¡¹ç›®ç»è¥**ã€**æ–‡æ¡ˆå†™ä½œ**ï¼Œå¹¶åœ¨è¡Œä¸šå‚ç±»çŸ¥è¯†åŸºç¡€ä¸Šï¼Œæ‹“å±•äº† **èµ„è®¯èˆ†æƒ…** å’Œ **äººæ‰åŸ¹è®­** ä¸¤å¤§æ™ºèƒ½ä½“ã€‚\n\n## æ ¸å¿ƒèƒ½åŠ›\n\nå…‹è€Œç‘é€šè¿‡ä¸‰ä¸ªèƒ½åŠ›æ¥æ„å»ºå…¶è‡ªèº«åœ¨ç‰©ä¸šAIåˆä½œé¢†åŸŸä¼˜åŠ¿ï¼š\n\n- **æ•°æ®èµ„äº§è½¬åŒ–èƒ½åŠ›ï¼š** å°†10äº¿å­—è¡Œä¸šè¯­æ–™ã€TBçº§å¤šæ¨¡æ€æ•°æ®è½¬åŒ–ä¸ºç‰©ä¸šè¡Œä¸šçš„é«˜è´¨é‡æ•°æ®é›†ï¼Œå¹¶æ„å»ºäº†ä¸€å¥—è¡Œä¸šæ•°æ®è´¨é‡è¯„ä¼°ä½“ç³»ï¼Œä¿éšœå‡†ç¡®ç‡å’Œå¯ä¿¡åº¦ï¼›\n- **åœºæ™¯ç©¿é€èƒ½åŠ›ï¼š** èšç„¦20+ç‰©ä¸šè¡Œä¸šå‚ç›´ä¸šåŠ¡åœºæ™¯ï¼Œå®šå‘é€‰ç”¨å¯¹åº”é¢†åŸŸçŸ¥è¯†åº“ï¼Œç²¾å‡†åŒ¹é…ï¼›\n- **ç”Ÿæ€è¿›åŒ–èƒ½åŠ›ï¼š** é€šè¿‡æ¯æ—¥å®æ—¶ç›‘æµ‹è¶…è¿‡500+å¯ä¿¡èµ„è®¯å’Œæ•°æ®æ¥æºï¼Œå¤„ç†10ä¸‡+å®æ—¶æ•°æ®çš„è‡ªæ›´æ–°ç³»ç»Ÿï¼Œåœ¨æ”¿ç­–é¢„è­¦ã€å•†æœºæŒ–æ˜å’Œæ‹›æŠ•æ ‡åˆ†æç­‰ç¯èŠ‚å®ç°å‡†ç¡®ç‡çªç ´90%ï¼Œå½¢æˆè¡Œä¸šAIçŸ¥è¯†ä¸­æ¢çš„æŒç»­å‡çº§ã€‚\n\n## MCP Server åŠŸèƒ½\n\n**CRICç‰©ä¸šAI MCP Server** æ˜¯ä¸€ä¸ªåŸºäº [Model Context Protocol](https://modelcontextprotocol.io/) çš„æœåŠ¡ç«¯å®ç°ï¼ŒåŸºäº **CRICç‰©ä¸šAI** å¹³å°çš„éƒ¨åˆ†åŸå­èƒ½åŠ›ï¼Œç›®å‰ç‰ˆæœ¬æä¾›äº†ä»¥ä¸‹ä¸‰å¤§åŠŸèƒ½æ¨¡å—ï¼š\n\n- **èµ„è®¯æ—¥æŠ¥ï¼š** è·å–ç‰©ä¸šè¡Œä¸šèµ„è®¯æ—¥æŠ¥ã€‚\n- **çŸ¥è¯†åº“ï¼š** æœç´¢ç‰©ä¸šè¡Œä¸šä¸“å±çŸ¥è¯†åº“ã€‚\n\nå…·ä½“å·¥å…·ï¼ˆToolï¼‰å®šä¹‰ï¼Œè¯·å‚è€ƒ [å·¥å…·å®šä¹‰é…ç½®](./TOOLS.md) æ–‡æ¡£ã€‚æ›´å¤šèƒ½åŠ›å³å°†æ¨å‡ºï¼Œæ•¬è¯·æœŸå¾…ã€‚\n\n## CRICç‰©ä¸šAI çŸ¥è¯†åº“\n\nä½¿ç”¨ CRIC ç‰©ä¸š AI MCP Serverï¼Œå¯ä»¥æŸ¥è¯¢å…‹è€Œç‘å»ºè®¾çš„ç‰©ä¸šè¡Œä¸šå‚ç±»é«˜è´¨é‡çŸ¥è¯†åº“ï¼Œè·å–ç”¨æˆ·é—®é¢˜ç›¸å…³çš„çŸ¥è¯†æ–‡æœ¬ä¾› AI å‚è€ƒã€‚\n\nç›®å‰å¯ä¾›å¼€é€šçš„çŸ¥è¯†åº“åŒ…æ‹¬ï¼š**æ³•å¾‹æ³•è§„ã€ç‰©ä¸šä¼ä¸šä¿¡æ¯ã€å…‹è€Œç‘æ¦œå•ã€ä¼˜ç§€ç‰©ä¸šé¡¹ç›®æœåŠ¡æ¡ˆä¾‹ã€ç‰©ä¸šè¡Œä¸šç ”ç©¶ã€ç‰©ä¸šé¡¹ç›®åº”æ€¥å“åº”ã€ç‰©ä¸šé¡¹ç›®ç»¼åˆç®¡ç†ã€ç‰©ä¸šé¡¹ç›®å®¢è¯‰å¤„ç†ã€ç‰©ä¸šè¡Œä¸šæ³•å¾‹åˆ¤ä¾‹ã€éä½å®…ç±»ç‰©ä¸šç ”ç©¶ã€ç‰©ä¸šé¡¹ç›®ç®¡ç†æ¡ˆä¾‹** ç­‰ã€‚\n\n## è·å– Access Token\n\næ‚¨éœ€è¦å…ˆè·å– **CRICç‰©ä¸šAI Access Token** æ‰èƒ½ä½¿ç”¨ CRICç‰©ä¸šAI MCP Server çš„åŠŸèƒ½ã€‚è¯·è®¿é—®æˆ‘ä»¬çš„ç½‘ç«™ç”³è¯·ï¼š[ç”³è¯·å¼€é€šä½“éªŒ CRICç‰©ä¸šAI MCP Server](https://wuye-ai.cricbigdata.com/mcp)ã€‚\n\n## å¿«é€Ÿå¼€å§‹\n\n### 1. SSE æ–¹å¼ï¼ˆhttpï¼‰\n\n#### 1.1 è¿è¡Œ\n\næ‚¨å¯ä»¥è‡ªè¡Œè¿è¡Œä¸€ä¸ª MCP Server å¹¶å¯ç”¨ HTTP æ¨¡å¼ï¼Œæˆ–è€…ç›´æ¥ä½¿ç”¨æˆ‘ä»¬æä¾›çš„ URLã€‚\n\n##### A. è‡ªè¡Œè¿è¡Œï¼š\n\n```bash\nMODE=http PORT=3011 npx -y @wuye-ai/mcp-server-wuye-ai\n```\n\nè¿è¡ŒæˆåŠŸåï¼ŒMCP Server URL ä¸º `http://localhost:3011/sse/mcp` ã€‚\n\n##### B. ä½¿ç”¨å®˜æ–¹ï¼š\n\næˆ–è€…æ‚¨ä¹Ÿå¯ä»¥ç›´æ¥ä½¿ç”¨æˆ‘ä»¬çš„å®˜æ–¹çš„ MCP Server URLï¼š\n\n- æµ‹è¯•ç¯å¢ƒï¼š`https://mcp.wuye-ai-staging.cricbigdata.com/sse/mcp`\n- ç”Ÿäº§ç¯å¢ƒï¼š`https://mcp.wuye-ai.cricbigdata.com/sse/mcp`\n\n#### 1.2 æµ‹è¯•\n\næ‚¨å¯ä»¥ä½¿ç”¨ MCP Inspector æˆ–ç¬¬ä¸‰æ–¹å·¥å…·è¿æ¥ SSE æ–¹å¼çš„ MCP Serverã€‚\n\n##### MCP Inspectorï¼š\n\næœåŠ¡è¿è¡ŒæˆåŠŸåï¼Œæ‚¨å¯ä»¥è¿è¡Œ [MCP Inspector](https://github.com/modelcontextprotocol/inspector) æ¥æŸ¥çœ‹å¹¶æµ‹è¯•æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œã€‚\n\n```bash\nnpx @modelcontextprotocol/inspector\n```\n\nMCP Inspector å¯åŠ¨åï¼Œç”¨æµè§ˆå™¨æ‰“å¼€å…¶ Web UIï¼ˆé»˜è®¤ä¸ºï¼šhttp://127.0.0.1:6274/ ï¼‰ã€‚å¹¶æŒ‰ç…§å¦‚ä¸‹æ­¥éª¤é…ç½®è¿æ¥ï¼š\n\n1. åœ¨ç•Œé¢å·¦ä¾§è®¾ç½® Transport Type ä¸º `SSE`ï¼ŒURL ä¸ºä¸Šä¸€æ­¥è·å¾—çš„ MCP Server URLã€‚\n2. å±•å¼€ Authentication é¢æ¿ï¼Œè®¾ç½® Header Name ä¸º `Authorization` ï¼ŒBearer Token ä¸ºæ‚¨çš„ **CRICç‰©ä¸šAI Access Token**ã€‚\n3. ç‚¹å‡» Connect æŒ‰é’®ï¼Œè¿æ¥æˆåŠŸåï¼Œå·¦ä¾§ä¼šæ˜¾ç¤ºå½“å‰è¿æ¥çš„çŠ¶æ€ã€‚\n\næ­¤æ—¶æ‚¨å°±å¯ä»¥æ“ä½œ MCP Inspector æµ‹è¯• CRICç‰©ä¸šAI çš„ MCP Server äº†ã€‚å…·ä½“ä½¿ç”¨æ–¹æ³•æ‚¨å¯ä»¥å‚è€ƒ [MCP Inspector ä¸­æ–‡æ–‡æ¡£](https://mcp-docs.cn/docs/tools/inspector) ã€‚\n\n##### ç¬¬ä¸‰æ–¹å·¥å…·ï¼š\n\né€šè¿‡ç¬¬ä¸‰æ–¹å·¥å…·ä½¿ç”¨ SSE æ–¹å¼æ¥å…¥æ—¶ï¼Œæ‚¨éœ€è¦é€šè¿‡ `Authorization` **HTTP å¤´** æŒ‡å®š Access Tokenã€‚ä¾‹å¦‚ï¼Œ[Cline](https://cline.bot/) è®¾ç½®æ–‡ä»¶ï¼š\n\n```json\n{\n  \"mcpServers\": {\n    \"CRICç‰©ä¸šAI\": {\n      \"transportType\": \"sse\",\n      \"url\": \"https://mcp.wuye-ai.cricbigdata.com/sse/mcp\",\n      \"headers\": {\n        \"Authorization\": \"Bearer {{æ‚¨çš„ CRICç‰©ä¸šAI Access Token}}\"\n      }\n    }\n  }\n}\n```\n\nè¯·æ³¨æ„ï¼Œå½“å‰éƒ¨åˆ†ä½¿ç”¨ [@modelcontextprotocol/typescript-sdk](https://github.com/modelcontextprotocol/typescript-sdk) çš„å·¥å…· [å…¶ ***HTTP å¤´*** è®¾ç½®å¯èƒ½æ— æ³•æ­£ç¡®ç”Ÿæ•ˆ](https://github.com/modelcontextprotocol/typescript-sdk/issues/317)ï¼Œå› æ­¤å»ºè®®ä½¿ç”¨ MCP Inspector æ¥æµ‹è¯•ã€‚æˆ–è€…ï¼Œä½œä¸ºä¸€ç§ä¸´æ—¶æªæ–½ï¼Œæˆ‘ä»¬ä¹Ÿæ”¯æŒåœ¨ URL ä¸­ä½¿ç”¨ Query æ–¹å¼æŒ‡å®š Access Tokenï¼Œä¾‹å¦‚ï¼š\n\n```json\n{\n  \"mcpServers\": {\n    \"CRICç‰©ä¸šAI\": {\n      \"transportType\": \"sse\",\n      \"url\": \"https://mcp.wuye-ai.cricbigdata.com/sse/mcp?token={{æ‚¨çš„ CRICç‰©ä¸šAI Access Token}}\"\n    }\n  }\n}\n```\n\n### 2. Stdio æ–¹å¼\n\n#### 2.1 è¿è¡Œ\n\næˆ‘ä»¬ä¹Ÿæ”¯æŒ stdio æ–¹å¼è¿è¡Œ MCP Serverã€‚å‘½ä»¤å¦‚ä¸‹ï¼š\n\n```bash\nCRIC_WUYE_AI_ACCESS_TOKEN={{æ‚¨çš„ CRICç‰©ä¸šAI Access Token}} npx -y @wuye-ai/mcp-server-wuye-ai\n```\n\n#### 2.2 æµ‹è¯•\n\næ‚¨å¯ä»¥ä½¿ç”¨ç¬¬ä¸‰æ–¹å·¥å…·æˆ–è€… MCP Inspector æ¥è¿æ¥ Stdio æ–¹å¼çš„ MCP Serverã€‚è¯·æ³¨æ„ï¼ŒStdio æ–¹å¼ä¸‹ä¸€èˆ¬æ— éœ€ç”¨æˆ·æ‰‹åŠ¨è¿è¡Œ MCP Serverï¼Œé€šå¸¸æ˜¯ç”±ç¬¬ä¸‰æ–¹å·¥å…·è‡ªåŠ¨è¿è¡Œã€‚\n\n##### MCP Inspector\n\nåœ¨ MCP Inspector ä¸­ï¼Œæ‚¨ä¹Ÿå¯ä»¥é€‰æ‹© Stdio æ–¹å¼æ¥å…¥ã€‚å…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š\n\n1. åœ¨ç•Œé¢å·¦ä¾§è®¾ç½® Transport Type ä¸º `Stdio`ï¼ŒCommand ä¸º `npx`ï¼ŒArguments ä¸º `-y @wuye-ai/mcp-server-wuye-ai`ã€‚\n2. å±•å¼€ Environment Variables é¢æ¿ï¼Œæ·»åŠ æˆ–è®¾ç½® `CRIC_WUYE_AI_ACCESS_TOKEN` ä¸ºæ‚¨çš„ **CRICç‰©ä¸šAI Access Token**ã€‚\n3. ç‚¹å‡» Connect æŒ‰é’®ï¼ŒMCP Inspector ä¼šè‡ªåŠ¨è¿è¡Œå‘½ä»¤å¯åŠ¨ MCP Server å¹¶è¿æ¥ã€‚è¿æ¥æˆåŠŸåï¼Œå·¦ä¾§ä¼šæ˜¾ç¤ºå½“å‰è¿æ¥çš„çŠ¶æ€ã€‚\n\næ­¤æ—¶æ‚¨å°±å¯ä»¥æ“ä½œ MCP Inspector æµ‹è¯• CRICç‰©ä¸šAI çš„ MCP Server äº†ã€‚\n\n##### ç¬¬ä¸‰æ–¹å·¥å…·\n\né€šè¿‡ç¬¬ä¸‰æ–¹å·¥å…·ä½¿ç”¨ Stdio æ–¹å¼æ¥å…¥æ—¶ï¼Œå¦‚æœæ‚¨éœ€è¦æŒ‡å®š Access Tokenï¼Œè¯·é€šè¿‡ç¯å¢ƒå˜é‡ `CRIC_WUYE_AI_ACCESS_TOKEN` æŒ‡å®šã€‚ä¾‹å¦‚ï¼ŒCline è®¾ç½®æ–‡ä»¶ï¼š\n\n```json\n{\n  \"mcpServers\": {\n    \"CRICç‰©ä¸šAI\": {\n      \"transportType\": \"stdio\",\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@wuye-ai/mcp-server-wuye-ai\"\n      ],\n      \"env\": {\n        \"CRIC_WUYE_AI_ACCESS_TOKEN\": \"{{æ‚¨çš„ CRICç‰©ä¸šAI Access Token}}\"\n      }\n    }\n  }\n}\n```\n\n## å®è·µæŒ‡å—\n\nCRICç‰©ä¸šAI MCP Server æ”¯æŒå„ç±»æ™ºèƒ½ä½“å¹³å°æ¥å…¥ï¼Œå¦‚é’‰é’‰AIåŠ©ç†ç­‰ã€‚æ‚¨å¯ä»¥å‚è€ƒ [å®è·µæŒ‡å—](https://alidocs.dingtalk.com/i/p/nb9XJDP07QqPDGyA/docs/mweZ92PV6My4ebxdHdb9oQBYWxEKBD6p) è¿›è¡Œæ“ä½œä½“éªŒã€‚\n\n## å¯é€‰é…ç½®\n\næ‚¨å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡æˆ– URL Queryï¼ˆSSEæ–¹å¼ä¸‹ï¼‰ æ¥é…ç½® CRICç‰©ä¸šAI MCP Server çš„è¿è¡Œæ–¹å¼ã€‚ä»¥ä¸‹æ˜¯å¯ç”¨çš„é…ç½®é¡¹ï¼š\n\n| ç¯å¢ƒå˜é‡å‚æ•°å                          | URL Query å‚æ•°å | é»˜è®¤å€¼                                      | æè¿°                                                                                                                                                                            |\n|----------------------------------|---------------|------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `MODE`                           | *ä¸æ”¯æŒ*         | `stdio`                                  | è¿è¡Œæ¨¡å¼ï¼Œæ”¯æŒ `stdio` å’Œ `http` ä¸¤ç§æ¨¡å¼ã€‚                                                                                                                                                |\n| `HOSTNAME`                       | *ä¸æ”¯æŒ*         | `0.0.0.0`                                | HTTP ç»‘å®šä¸»æœºåï¼Œä»…åœ¨ `http` æ¨¡å¼ä¸‹æœ‰æ•ˆã€‚`0.0.0.0`å³ä¸ºç»‘å®šåˆ°æœ¬æœºæ‰€æœ‰IPåœ°å€ã€‚                                                                                                                            |\n| `PORT`                           | *ä¸æ”¯æŒ*         | `3011`                                   | HTTP ç»‘å®šç«¯å£ï¼Œä»…åœ¨ `http` æ¨¡å¼ä¸‹æœ‰æ•ˆã€‚                                                                                                                                                    |\n| `CRIC_WUYE_AI_ACCESS_TOKEN`      | `token`       | *æ— *                                      | CRICç‰©ä¸šAI Access Tokenã€‚å¦‚æœä¸æä¾›ï¼Œåˆ™ä½¿ç”¨å®é™…è¯·æ±‚ HTTP Authorization Header ä¸­çš„å€¼ã€‚                                                                                                            |\n| `CRIC_WUYE_AI_PROVIDER_API_BASE` | *ä¸æ”¯æŒ*         | `https://export.wuye-ai.cricbigdata.com` | CRICç‰©ä¸šAI åç«¯æ¥å…¥ APIï¼Œè¯·æ³¨æ„ ***æ­¤ URL ä¸æ˜¯ CRICç‰©ä¸šAI MCP Server çš„ URL*** ã€‚å¯é€‰å€¼ä¸º `https://export.wuye-ai-staging.cricbigdata.com` ï¼ˆæµ‹è¯•ç¯å¢ƒï¼‰ã€ `https://export.wuye-ai.cricbigdata.com` ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰ |\n| `CRIC_WUYE_AI_NAME_EN`           | `name_en`     | ç”± CRICç‰©ä¸šAI å·¥ä½œäººå‘˜ä¸ºæ‚¨é»˜è®¤é…ç½®                    | æ˜¯å¦ä½¿ç”¨å·¥å…·è‹±æ–‡åç§°ï¼Œæ”¯æŒ `true` å’Œ `false` ä¸¤ä¸ªå–å€¼ã€‚å¯ç”¨æ—¶ï¼ŒTool åç§°å°†æ”¹ä¸ºä½¿ç”¨è‹±æ–‡ç‰ˆæœ¬ï¼Œä»¥æé«˜å¯¹éƒ¨åˆ†æµ·å¤–æ¨¡å‹çš„å…¼å®¹æ€§ã€‚å¯¹äºæ”¯æŒä¸­æ–‡å·¥å…·åç§°çš„æ¨¡å‹ï¼Œå»ºè®®ä¸å¯ç”¨ï¼Œä»¥è·å¾—æ›´å¥½çš„æ•ˆæœã€‚å¦‚æœé…ç½®è¯¥é€‰é¡¹ï¼Œå°†è¦†ç›–é»˜è®¤é…ç½®ã€‚                                                         |\n| `CRIC_WUYE_AI_FEATURE_SET`       | `feature_set` | ç”± CRICç‰©ä¸šAI å·¥ä½œäººå‘˜ä¸ºæ‚¨é»˜è®¤é…ç½®                    | é¢„é…ç½®çš„å·¥å…·åŠŸèƒ½é›†ï¼Œæ”¯æŒ `base`ã€`detail` ç­‰å–å€¼ã€‚è¯¥å‚æ•°å†³å®šäº†æ‚¨å¯ç”¨çš„ Tool é›†åˆï¼Œ`base` åŠŸèƒ½é›†ä¸­æä¾›äº†â€œè·å–å¯ç”¨çŸ¥è¯†åº“åˆ—è¡¨â€å’Œé€šç”¨çš„â€œæœç´¢çŸ¥è¯†åº“â€å·¥å…·ï¼Œè€Œ `detail` åŠŸèƒ½é›†ä¸­ä¸æä¾›â€œè·å–å¯ç”¨çŸ¥è¯†åº“åˆ—è¡¨â€å·¥å…·ï¼Œä½†ä¸ºæ¯ä¸ªå¯ç”¨çš„çŸ¥è¯†åº“æä¾›äº†å•ç‹¬çš„â€œæœç´¢çŸ¥è¯†åº“â€å·¥å…·ã€‚å¦‚æœé…ç½®è¯¥é€‰é¡¹ï¼Œå°†è¦†ç›–é»˜è®¤é…ç½®ã€‚         |\n| `CRIC_WUYE_AI_OUTPUT_FORMAT`     | `output`      | `raw`                                    | å·¥å…·è°ƒç”¨è¾“å‡ºæ ¼å¼ï¼Œæ”¯æŒ `raw`ï¼ˆä¸è½¬åŒ–ï¼‰ã€`text`ï¼ˆè½¬åŒ–ä¸º Markdown æ–‡æœ¬ï¼‰ç­‰å–å€¼ã€‚                                                                                                                            |\n\n*æ³¨ï¼š* URL Query é…ç½®æ—¶ï¼Œåªéœ€è¦åœ¨ SSE è°ƒç”¨çš„ URL åé¢æ‹¼æ¥å‚æ•°å³å¯ï¼Œä¾‹å¦‚ï¼š\n\n```json\n{\n  \"mcpServers\": {\n    \"CRICç‰©ä¸šAI\": {\n      \"transportType\": \"sse\",\n      \"url\": \"https://mcp.wuye-ai.cricbigdata.com/sse/mcp?token={{æ‚¨çš„ CRICç‰©ä¸šAI Access Token}}&name_en=true\"\n    }\n  }\n}\n```\n\nå…³äº `CRIC_WUYE_AI_NAME_EN` å’Œ `CRIC_WUYE_AI_FEATURE_SET` çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒ [å·¥å…·å®šä¹‰é…ç½®](./TOOLS.md) æ–‡æ¡£ã€‚\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "XPE-7--MCP-Server": {
      "owner": "XPE-7",
      "name": "MCP-Server",
      "url": "https://github.com/XPE-7/MCP-Server",
      "imageUrl": "https://github.com/XPE-7.png",
      "description": "Facilitates intelligent search and retrieval of AI/ML library documentation using Claude's reasoning capabilities, supporting multiple sources and an extendable architecture for adding new documentation easily.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-03-22T10:56:15Z",
      "readme_content": "# ğŸ¤– Claude AI Documentation Assistant ğŸ“š\n\n<div align=\"center\">\n\n![Claude + MCP Integration](https://raw.githubusercontent.com/anthropics/logo/main/claude-badge.png)\n\n*A powerful MCP server that supercharges Claude with documentation search capabilities*\n\n[![Python 3.8+](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)\n\n</div>\n\n## âœ¨ Features\n\n- ğŸ” **Smart Documentation Search** - Search across multiple AI/ML library documentation\n- ğŸ§  **Claude Integration** - Seamless connection with Claude's advanced reasoning capabilities\n- ğŸŒ **Intelligent Web Search** - Leverages Serper API for targeted documentation lookup\n- ğŸ’¨ **Fast Response Times** - Optimized for quick retrieval and processing\n- ğŸ§© **Extendable Architecture** - Easily add more documentation sources\n\n## ğŸ“‹ Prerequisites\n\n- ğŸ Python 3.8 or higher\n- ğŸ”‘ Claude Pro subscription\n- ğŸ” Serper API key ([Get one here](https://serper.dev))\n- ğŸ’» Claude Desktop application\n\n## ğŸš€ Quick Start\n\n### 1ï¸âƒ£ Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/your-username/claude-docs-assistant.git\ncd claude-docs-assistant\n\n# Create a virtual environment (recommended)\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install dependencies\npip install -r requirements.txt\n```\n\n### 2ï¸âƒ£ Configuration\n\nCreate a `.env` file in the project root with your API keys:\n\n```\nSERPER_API_KEY=your_serper_api_key_here\n```\n\n### 3ï¸âƒ£ Start the MCP Server\n\n```bash\npython main.py\n```\n\nYou should see output indicating the server is running and waiting for Claude to connect.\n\n### 4ï¸âƒ£ Connect Claude Desktop App\n\n1. ğŸ“± Open the Claude Desktop App\n2. âš™ï¸ Click on your profile icon and select \"Settings\"\n3. ğŸ§° Navigate to the \"Tools\" section\n4. â• Click \"Add Tool\"\n5. ğŸ”— Select \"Connect to a local tool\"\n6. ğŸ–¥ï¸ Follow the prompts to connect to your running MCP server\n7. âœ… Confirm the connection is successful\n\n## ğŸ® Using Your Claude Documentation Assistant\n\nOnce connected, you can start asking Claude questions that will trigger the documentation search. For example:\n\n```\nCould you explain how to use FAISS with LangChain? Please search the langchain documentation to help me.\n```\n\nClaude will automatically use your MCP server to:\n1. ğŸ” Search for relevant documentation\n2. ğŸ“¥ Retrieve the content\n3. ğŸ§  Process and explain the information\n\n## ğŸ”§ Under the Hood\n\n### ğŸ“„ Code Structure\n\n```\nclaude-docs-assistant/\nâ”œâ”€â”€ main.py           # MCP server implementation\nâ”œâ”€â”€ requirements.txt  # Project dependencies\nâ”œâ”€â”€ .env              # Environment variables (API keys)\nâ””â”€â”€ README.md         # This documentation\n```\n\n### ğŸ”Œ Supported Libraries\n\nThe assistant currently supports searching documentation for:\n\n- ğŸ¦œ **LangChain**: `python.langchain.com/docs`\n- ğŸ¦™ **LlamaIndex**: `docs.llamaindex.ai/en/stable`\n- ğŸ§  **OpenAI**: `platform.openai.com/docs`\n\n### ğŸ§© How It Works\n\n1. ğŸ“¡ The MCP server exposes a `get_docs` tool to Claude\n2. ğŸ” When invoked, the tool searches for documentation using Serper API\n3. ğŸ“š Results are scraped for their content\n4. ğŸ”„ Content is returned to Claude for analysis and explanation\n\n## ğŸ› ï¸ Advanced Configuration\n\n### Adding New Documentation Sources\n\nExtend the `docs_urls` dictionary in `main.py`:\n\n```python\ndocs_urls = {\n    \"langchain\": \"python.langchain.com/docs\",\n    \"llama-index\": \"docs.llamaindex.ai/en/stable\",\n    \"openai\": \"platform.openai.com/docs\",\n    \"huggingface\": \"huggingface.co/docs\",  # Add new documentation sources\n    \"tensorflow\": \"www.tensorflow.org/api_docs\",\n}\n```\n\n### Customizing Search Behavior\n\nModify the `search_web` function to adjust the number of results:\n\n```python\npayload = json.dumps({\"q\": query, \"num\": 5})  # Increase from default 2\n```\n\n## ğŸ” Troubleshooting\n\n### Common Issues\n\n- **ğŸš« \"Connection refused\" error**: Ensure the MCP server is running before connecting Claude\n- **â±ï¸ Timeout errors**: Check your internet connection or increase the timeout value\n- **ğŸ”’ API key issues**: Verify your Serper API key is correct in the `.env` file\n\n### Debugging Tips\n\nAdd more detailed logging by modifying the main.py file:\n\n```python\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n```\n\n## ğŸ“ˆ Performance Optimization\n\n- âš¡ For faster response times, consider caching frequently accessed documentation\n- ğŸ§  Limit the amount of text returned to Claude to avoid token limitations\n- ğŸŒ Use more specific queries to get more relevant documentation\n\n## ğŸ¤ Contributing\n\nContributions are welcome! Here's how you can help:\n\n1. ğŸ´ Fork the repository\n2. ğŸŒ¿ Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. ğŸ’¾ Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. ğŸ“¤ Push to the branch (`git push origin feature/amazing-feature`)\n5. ğŸ” Open a Pull Request\n\n## ğŸ“œ License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## ğŸ™ Acknowledgements\n\n- [Anthropic](https://www.anthropic.com/) for creating Claude\n- [Serper.dev](https://serper.dev) for their search API\n- All the open-source libraries that make this project possible\n\n---\n\n<div align=\"center\">\n  Made with â¤ï¸ for Claude enthusiasts\n</div>\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "xuhuatao--learn-python": {
      "owner": "xuhuatao",
      "name": "learn-python",
      "url": "https://github.com/xuhuatao/learn-python",
      "imageUrl": "https://github.com/xuhuatao.png",
      "description": "Explore Python interactively by modifying and testing code examples across various topics, with built-in assertions and linting tools to enhance code quality and learning.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2021-07-31T08:42:14Z",
      "readme_content": "# Playground and Cheatsheet for Learning Python\n\n[![Build Status](https://travis-ci.org/trekhleb/learn-python.svg?branch=master)](https://travis-ci.org/trekhleb/learn-python)\n\n> This is a collection of Python scripts that are split by [topics](#table-of-contents) and contain \ncode examples with explanations, different use cases and links to further readings.\n\n_Read this in_ [_PortuguÃªs_](README.pt-BR.md).\n\nIt is a **playground** because you may change or add the code to see how it works \nand [test it out](#testing-the-code) using assertions. It also allows you \nto [lint the code](#linting-the-code) you've wrote and check if it fits to Python code style guide.\nAltogether it might make your learning process to be more interactive and it might help you to keep \ncode quality pretty high from very beginning.\n\nIt is a **cheatsheet** because you may get back to these code examples once you want to recap the \nsyntax of [standard Python statements and constructions](#table-of-contents). Also because the \ncode is full of assertions you'll be able to see expected functions/statements output right away\nwithout launching them.\n\n> _You might also be interested in ğŸ¤– [Interactive Machine Learning Experiments](https://github.com/trekhleb/machine-learning-experiments)_\n\n## How to Use This Repository\n\nEach Python script in this repository has the following structure:\n\n```python\n\"\"\"Lists  <--- Name of the topic here\n\n# @see: https://www.learnpython.org/en/Lists  <-- Link to further readings goes here\n\nHere might go more detailed explanation of the current topic (i.e. general info about Lists).\n\"\"\"\n\n\ndef test_list_type():\n    \"\"\"Explanation of sub-topic goes here.\n    \n    Each file contains test functions that illustrate sub-topics (i.e. lists type, lists methods).\n    \"\"\"\n    \n    # Here is an example of how to build a list.  <-- Comments here explain the action\n    squares = [1, 4, 9, 16, 25]\n    \n    # Lists can be indexed and sliced. \n    # Indexing returns the item.\n    assert squares[0] == 1  # <-- Assertions here illustrate the result.\n    # Slicing returns a new list.\n    assert squares[-3:] == [9, 16, 25]  # <-- Assertions here illustrate the result.\n```\n\nSo normally you might want to do the following:\n\n- [Find the topic](#table-of-contents) you want to learn or recap.\n- Read comments and/or documentation that is linked in each script's docstring (as in example above). \n- Look at code examples and assertions to see usage examples and expected output.\n- Change code or add new assertions to see how things work.\n- [Run tests](#testing-the-code) and [lint the code](#linting-the-code) to see if it work and is \nwritten correctly.\n\n## Table of Contents\n\n1. **Getting Started**\n    - [What is Python](src/getting_started/what_is_python.md)\n    - [Python Syntax](src/getting_started/python_syntax.md)\n    - [Variables](src/getting_started/test_variables.py)\n2. **Operators**\n    - [Arithmetic Operators](src/operators/test_arithmetic.py) (`+`, `-`, `*`, `/`, `//`, `%`, `**`)\n    - [Bitwise Operators](src/operators/test_bitwise.py) (`&`, `|`, `^`, `>>`, `<<`, `~`)\n    - [Assignment Operators](src/operators/test_assigment.py) (`=`, `+=`, `-=`, `/=`, `//=` etc.)\n    - [Comparison Operator](src/operators/test_comparison.py) (`==`, `!=`, `>`, `<`, `>=`, `<=`)\n    - [Logical Operators](src/operators/test_logical.py) (`and`, `or`, `not`)\n    - [Identity Operators](src/operators/test_identity.py) (`is`, `is not`)\n    - [Membership Operators](src/operators/test_membership.py) (`in`, `not in`)\n3. **Data Types**\n    - [Numbers](src/data_types/test_numbers.py) (including booleans)\n    - [Strings](src/data_types/test_strings.py) and their methods\n    - [Lists](src/data_types/test_lists.py) and their methods (including list comprehensions)\n    - [Tuples](src/data_types/test_tuples.py)\n    - [Sets](src/data_types/test_sets.py) and their methods\n    - [Dictionaries](src/data_types/test_dictionaries.py)\n    - [Type Casting](src/data_types/test_type_casting.py)\n4. **Control Flow**\n    - [The `if` statement](src/control_flow/test_if.py)\n    - [The `for` statement](src/control_flow/test_for.py) (and `range()` function)\n    - [The `while` statement](src/control_flow/test_while.py)\n    - [The `try` statements](src/control_flow/test_try.py)\n    - [The `break` statement](src/control_flow/test_break.py)\n    - [The `continue` statement](src/control_flow/test_continue.py)\n5. **Functions**\n    - [Function Definition](src/functions/test_function_definition.py) (`def` and `return` statements)\n    - [Scopes of Variables Inside Functions](src/functions/test_function_scopes.py) (`global` and `nonlocal` statements)\n    - [Default Argument Values](src/functions/test_function_default_arguments.py)\n    - [Keyword Arguments](src/functions/test_function_keyword_arguments.py)\n    - [Arbitrary Argument Lists](src/functions/test_function_arbitrary_arguments.py)\n    - [Unpacking Argument Lists](src/functions/test_function_unpacking_arguments.py) (`*` and `**` statements)\n    - [Lambda Expressions](src/functions/test_lambda_expressions.py) (`lambda` statement)\n    - [Documentation Strings](src/functions/test_function_documentation_string.py)\n    - [Function Annotations](src/functions/test_function_annotations.py)\n    - [Function Decorators](src/functions/test_function_decorators.py)\n6. **Classes**\n    - [Class Definition](src/classes/test_class_definition.py) (`class` statement)\n    - [Class Objects](src/classes/test_class_objects.py)\n    - [Instance Objects](src/classes/test_instance_objects.py)\n    - [Method Objects](src/classes/test_method_objects.py)\n    - [Class and Instance Variables](src/classes/test_class_and_instance_variables.py)\n    - [Inheritance](src/classes/test_inheritance.py)\n    - [Multiple Inheritance](src/classes/test_multiple_inheritance.py)\n7. **Modules**\n    - [Modules](src/modules/test_modules.py) (`import` statement)\n    - [Packages](src/modules/test_packages.py)\n8. **Errors and Exceptions**\n    - [Handling Exceptions](src/exceptions/test_handle_exceptions.py) (`try` statement)\n    - [Raising Exceptions](src/exceptions/test_raise_exceptions.py) (`raise` statement) \n9. **Files**\n    - [Reading and Writing](src/files/test_file_reading.py) (`with` statement)\n    - [Methods of File Objects](src/files/test_file_methods.py)\n10. **Additions**\n    - [The `pass` statement](src/additions/test_pass.py)\n    - [Generators](src/additions/test_generators.py) (`yield` statement)\n11. **Brief Tour of the Standard Libraries**\n    - [Serialization](src/standard_libraries/test_json.py) (`json` library)\n    - [File Wildcards](src/standard_libraries/test_glob.py) (`glob` library)\n    - [String Pattern Matching](src/standard_libraries/test_re.py) (`re` library)\n    - [Mathematics](src/standard_libraries/test_math.py) (`math`, `random`, `statistics` libraries)\n    - [Dates and Times](src/standard_libraries/test_datetime.py) (`datetime` library)\n    - [Data Compression](src/standard_libraries/test_zlib.py) (`zlib` library)\n\n## Prerequisites\n\n**Installing Python**\n\nMake sure that you have [Python3 installed](https://realpython.com/installing-python/) on your machine.\n\nYou might want to use [venv](https://docs.python.org/3/library/venv.html) standard Python library\nto create virtual environments and have Python, pip and all dependent packages to be installed and \nserved from the local project directory to avoid messing with system wide packages and their \nversions.\n\nDepending on your installation you might have access to Python3 interpreter either by\nrunning `python` or `python3`. The same goes for pip package manager - it may be accessible either\nby running `pip` or `pip3`.\n\nYou may check your Python version by running:\n\n```bash\npython --version\n```\n\nNote that in this repository whenever you see `python` it will be assumed that it is Python **3**.\n\n**Installing dependencies**\n\nInstall all dependencies that are required for the project by running:\n\n```bash\npip install -r requirements.txt\n```\n\n## Testing the Code\n\nTests are made using [pytest](https://docs.pytest.org/en/latest/) framework.\n\nYou may add new tests for yourself by adding files and functions with `test_` prefix\n(i.e. `test_topic.py` with `def test_sub_topic()` function inside).\n\nTo run all the tests please execute the following command from the project root folder:\n\n```bash\npytest\n```\n\nTo run specific tests please execute:\n\n```bash\npytest ./path/to/the/test_file.py\n```\n\n## Linting the Code\n\nLinting is done using [pylint](http://pylint.pycqa.org/) and [flake8](http://flake8.pycqa.org/en/latest/) libraries.\n\n### PyLint\n\nTo check if the code is written with respect\nto [PEP 8](https://www.python.org/dev/peps/pep-0008/) style guide please run:\n\n```bash\npylint ./src/\n```\n\nIn case if linter will detect error (i.e. `missing-docstring`) you may want to read more about \nspecific error by running:\n\n```bash\npylint --help-msg=missing-docstring\n```\n\n[More about PyLint](http://pylint.pycqa.org/)\n\n### Flake8\n\nTo check if the code is written with respect\nto [PEP 8](https://www.python.org/dev/peps/pep-0008/) style guide please run:\n\n```bash\nflake8 ./src\n```\n\nOr if you want to have more detailed output you may run:\n\n```bash\nflake8 ./src --statistics --show-source --count\n```\n\n[More about Flake8](http://flake8.pycqa.org/en/latest/)\n\n## Supporting the project\n\nYou may support this project via â¤ï¸ï¸ [GitHub](https://github.com/sponsors/trekhleb) or â¤ï¸ï¸ [Patreon](https://www.patreon.com/trekhleb).\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Yash-Kavaiya--introduction-to-llms-nptel": {
      "owner": "Yash-Kavaiya",
      "name": "introduction-to-llms-nptel",
      "url": "https://github.com/Yash-Kavaiya/introduction-to-llms-nptel",
      "imageUrl": "https://github.com/Yash-Kavaiya.png",
      "description": "A structured course on Large Language Models, providing insights into NLP and deep learning, complete with interactive code examples and downloadable materials for enhanced learning.",
      "stars": 2,
      "forks": 1,
      "license": "MIT License",
      "language": "MDX",
      "updated_at": "2025-07-19T08:39:11Z",
      "readme_content": "# Introduction to Large Language Models (LLMs) - NPTEL Course\n\nA comprehensive course on Large Language Models offered by IIT Delhi and IIT Bombay through NPTEL (National Programme on Technology Enhanced Learning).\n\n## Course Overview ğŸ“š\n\n### Instructors\n- Prof. Tanmoy Chakraborty (IIT Delhi)\n- Prof. Soumen Chakrabarti (IIT Bombay)\n\n### Teaching Assistants\n- Anwoy Chatterjee (PhD student, IIT Delhi)\n- Poulami Ghosh (PhD student, IIT Bombay)\n\n## Course Structure ğŸ“\n\n### Weekly Modules\n1. **Week 1: Foundations**\n   - Introduction and Recent Advances\n   - Introduction to Natural Language Processing\n   - Deep Learning Basics\n\n2. **Week 2-8: Core Content**\n   - Transformer Architecture\n   - Language Models & Embeddings\n   - Advanced Learning Paradigms\n   - Knowledge Integration & Retrieval\n   - Ethics & Contemporary Models\n\n## Getting Started ğŸš€\n\n### Prerequisites\n- Python programming knowledge\n- Basic understanding of Machine Learning\n- Data Structures & Algorithms fundamentals\n\n### Local Development\n```bash\n# Install dependencies\npnpm install\n\n# Start development server\npnpm dev\n\n# Visit http://localhost:3000\n```\n\n## Website Features ğŸ’¡\n\n### Technical Features\n- Built with Nextra documentation framework\n- React-based components\n- MDX support for interactive content\n- Dark/light mode theming\n- Full-text search capability\n- Mobile-responsive design\n\n### Content Features\n- Interactive code examples\n- Downloadable lecture materials\n- Progress tracking\n- Embedded diagrams and visualizations\n- Searchable documentation\n\n## Contributing ğŸ¤\n\nWe welcome contributions to improve the course materials:\n1. Fork the repository\n2. Create your feature branch\n3. Commit your changes\n4. Push to the branch\n5. Create a Pull Request\n\n## Resources ğŸ“–\n\n### Additional Reading\n- [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/)\n- [Neural Network Models for NLP](http://u.cs.biu.ac.il/~yogo/nnlp.pdf)\n- Course-specific materials in the `/resources` directory\n\n### Support\nFor technical issues, please open a GitHub issue.\nFor course-related queries, use the NPTEL discussion forum.\n\n## License\n\nThis project is licensed under the MIT License. See [LICENSE](LICENSE) for details.\n\n---\n\nBuilt with [Nextra](https://nextra.site) | Deployed on [Vercel](https://vercel.com)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Yash-Kavaiya--mcp-video-gen": {
      "owner": "Yash-Kavaiya",
      "name": "mcp-video-gen",
      "url": "https://github.com/Yash-Kavaiya/mcp-video-gen",
      "imageUrl": "https://github.com/Yash-Kavaiya.png",
      "description": "Automates the conversion of CSV-formatted multiple-choice questions into professional video presentations with synchronized audio narration, aimed at enhancing educational content. Supports multi-language text-to-speech capabilities for audio generation.",
      "stars": 2,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-16T08:41:37Z",
      "readme_content": "# MCQ Video Generator ğŸ¬ âœ¨\n\n> **Transform your multiple-choice questions into engaging video presentations**\n\n![Python Version](https://img.shields.io/badge/python-3.12-blue.svg)\n![License](https://img.shields.io/badge/license-MIT-green.svg)\n\n## ğŸ“‹ Overview\n\nThe MCQ Video Generator is a powerful tool designed to automatically convert CSV-formatted multiple-choice questions into professional video presentations with synchronized audio narration. Perfect for educators, trainers, and content creators looking to enhance learning materials without the hassle of manual video editing.\n\n## âœ¨ Features\n\n- ğŸ¥ **Automated Video Creation** - Transform CSV files of MCQs into complete videos\n- ğŸ”Š **Text-to-Speech Narration** - Automatic audio generation for all text elements\n- ğŸŒ **Multi-language Support** - Compatible with various languages through gTTS\n- ğŸ¨ **Customizable Styling** - Control colors, fonts, and dimensions\n- ğŸ”„ **Batch Processing** - Process multiple questions in a single run\n\n## ğŸ› ï¸ Installation\n\n### Prerequisites\n\n- Python 3.12 or higher\n- Required font file (default: `HindVadodara-Light.ttf`)\n\n### Setup\n\n1. **Clone the repository**\n\n```bash\ngit clone https://github.com/yourusername/mcp-video-gen.git\ncd mcp-video-gen\n```\n\n2. **Install the required dependencies**\n\n```bash\npip install -e .\n# or\npip install pandas pillow gtts moviepy\n```\n\n3. **Install additional MCP dependencies**\n\n```bash\npip install mcp[cli]>=1.6.0\n```\n\n## ğŸš€ Usage\n\n### Basic Usage\n\n```bash\npython main.py\n```\n\n### As an MCP Tool\n\nThis tool is designed to work within the MCP (Machine Control Protocol) framework:\n\n```python\nfrom mcp.server.fastmcp import FastMCP\nfrom main import create_mcq_video\n\n# Create an MCP server\nmcp = FastMCP(\"mcq_video_generator\")\n\n# Example usage\nresult = await create_mcq_video(\n    csv_file_path=\"your_questions.csv\",\n    output_filename=\"my_quiz_video.mp4\"\n)\n```\n\n## ğŸ“Š Input Format\n\nYour CSV file should contain columns for questions and answer options. Example format:\n\n| Question | A | B | C | D | Answer |\n|----------|---|---|---|---|--------|\n| What is 1+1? | A. 1 | B. 2 | C. 3 | D. 4 | Ans: B. 2 |\n| Capital of France? | A. London | B. Berlin | C. Paris | D. Rome | Ans: C. Paris |\n\n## âš™ï¸ Configuration Options\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `csv_file_path` | Path to input CSV file | *Required* |\n| `output_filename` | Name for final video | \"Gyan_Dariyo_final_video.mp4\" |\n| `language` | Language code for TTS | \"en\" |\n| `font_path` | Path to font file | \"HindVadodara-Light.ttf\" |\n| `font_size` | Text size on slides | 70 |\n| `img_width` | Video width (pixels) | 1920 |\n| `img_height` | Video height (pixels) | 1080 |\n| `bg_color_rgb` | Background color | (0, 127, 215) |\n| `font_color_rgb` | Text color | (255, 255, 255) |\n\n## ğŸ“‹ Process Flow\n\n```mermaid\ngraph TD\n    A[Load CSV Data] --> B[Generate Images]\n    B --> C[Create TTS Audio]\n    C --> D[Combine into Video Clips]\n    D --> E[Concatenate Final Video]\n    E --> F[Output MP4 File]\n```\n\n## ğŸ” Technical Details\n\nThe tool performs the following steps:\n1. ğŸ“‘ Reads MCQ data from a CSV file\n2. ğŸ–¼ï¸ Generates an image for each MCQ with proper text formatting\n3. ğŸ™ï¸ Creates audio narration using Google's Text-to-Speech (gTTS)\n4. ğŸï¸ Combines each image and audio into individual video clips\n5. ğŸ¬ Concatenates all clips into a final video presentation\n\n## âš ï¸ Troubleshooting\n\n### Common Issues\n\n- **Font Not Found Error**: Ensure the specified font file exists in the working directory\n- **Empty CSV Error**: Verify your CSV file contains valid data\n- **Audio Generation Failure**: Check internet connection (required for gTTS)\n\n### Font Requirements\n\nThe default font is set to \"HindVadodara-Light.ttf\". If you use a different font:\n\n```python\nresult = await create_mcq_video(\n    csv_file_path=\"questions.csv\",\n    font_path=\"path/to/your/font.ttf\"\n)\n```\n\n## ğŸ“ License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## ğŸ‘¥ Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n---\n\nMade with â¤ï¸ for educators and content creators",
      "npm_url": "",
      "npm_downloads": 0
    },
    "yueleicool--EnglishGrammar": {
      "owner": "yueleicool",
      "name": "EnglishGrammar",
      "url": "https://github.com/yueleicool/EnglishGrammar",
      "imageUrl": "https://github.com/yueleicool.png",
      "description": "Provides detailed explanations and summaries of English grammar concepts, including parts of speech and sentence components. Aids users in understanding the fundamental elements and structure of English grammar for enhanced language proficiency.",
      "stars": 2,
      "forks": 1,
      "license": "No License",
      "language": "",
      "updated_at": "2025-03-14T17:03:29Z",
      "readme_content": "# EnglishGrammar\nè‹±è¯­è¯­æ³•æ€»ç»“\n\n### ä¸€ã€è¯æ€§ï¼ˆ10ç§ï¼‰\n1.è¿è¯: ç”¨æ¥è¿æ¥è¯ã€çŸ­è¯­æˆ–å¥å­  (ä¸‰å¤§ä»å¥)  \n2.åŠ¨è¯: è¡¨åŠ¨ä½œæˆ–çŠ¶æ€  \n3.å½¢å®¹è¯: è¡¨äººæˆ–äº‹ç‰©çš„æ€§è´¨æˆ–ç‰¹å¾  \n4.å‰¯è¯:  \n  â‘  ä¿®æ”¹åŠ¨è¯ã€å½¢å®¹è¯æˆ–å‰¯è¯  \n  â‘¡ è¯´æ˜æ—¶é—´ã€åœ°ç‚¹ã€ç¨‹åº¦ç­‰  \n5.ä»£è¯: ç”¨æ¥ä»£æ›¿åè¯  \n6.åè¯: è¡¨ç¤ºäººã€äº‹ç‰©ã€åœ°ç‚¹æˆ–æŠ½è±¡æ¦‚å¿µçš„åè¯  \n7.å† è¯: ç”¨åœ¨åè¯å‰ï¼Œå¸®åŠ©è¯´æ˜åè¯  \n8.ä»‹è¯: è¡¨ç¤ºå®ƒåé¢çš„åè¯æˆ–ä»£è¯ä¸å…¶ä»–å¥å­æˆåˆ†çš„å…³ç³»  \n9.æ•°è¯: è¡¨æ•°ç›®æˆ–é¡ºåº  \n10.æ„Ÿå¹è¯: è¡¨ç¤ºå–œã€æ€’ã€å“€ã€ä¹ç­‰æ„Ÿæƒ…  \n\n### äºŒã€å¥å­æˆåˆ† (9ç§)\n1.ä¸»è¯­  \n  â‘  æ˜¯å¥å­æ‰€è¦è¯´çš„äººæˆ–ç‰©ï¼Œå›ç­”æ˜¯\"è°\"æˆ–è€…\"ä»€ä¹ˆ\";  \n  â‘¡ é€šå¸¸ç”¨åè¯æˆ–ä»£è¯æ‹…ä»»  \n2.è°“è¯­  \n  â‘  è¯´æ˜ä¸»è¯­çš„åŠ¨ä½œæˆ–çŠ¶æ€ï¼Œå›ç­”\"åšä»€ä¹ˆ\"  \n  â‘¡ ç”±åŠ¨è¯&åŠ¨è¯çŸ­è¯­æ‹…ä»»  \n3.å®¾è¯­  \n  â‘  è¡¨åŠç‰©åŠ¨è¯çš„å¯¹è±¡æˆ–ç»“æœ  \n  â‘¡ æœ‰åè¯æˆ–ä»£è¯æ‹…ä»»  \n4.è¡¨è¯­  \n  â‘  åœ¨ç³»åŠ¨è¯åï¼Œè¯´æ˜ä¸»è¯­çš„èº«ä»½æˆ–ç‰¹æ€§ï¼Œå›ç­”æ˜¯\"ä»€ä¹ˆ\"æˆ–è€…\"æ€ä¹ˆæ ·\"  \n  â‘¡ ç”±åè¯ã€ä»£è¯æˆ–å½¢å®¹è¯æ‹…ä»»  \n5.åŒå®¾è¯­  \n  â‘  æœ‰äº›åŠç‰©åŠ¨è¯å¸¦ä¸¤ä¸ªå®¾è¯­ï¼Œä¸€ä¸ªæŒ‡ç‰©ï¼Œä¸€ä¸ªæŒ‡äºº  \n  â‘¡ æŒ‡ç‰©çš„å«ç›´æ¥å®¾è¯­ï¼ŒæŒ‡äººçš„å«é—´æ¥å®¾è¯­  \n  â‘¢ ç®€ä»‹å®¾è¯­ä¸€èˆ¬æ”¾åœ¨ç›´æ¥å®¾è¯­çš„å‰é¢  \n  æ³¨æ„:  \n    å¯æŠŠä»‹è¯toæˆ–foråŠ åœ¨é—´æ¥å®¾è¯­å‰æ„æˆçŸ­è¯­ï¼Œæ”¾åœ¨ç›´æ¥å®¾è¯­åé¢ï¼Œæ¥å¼ºè°ƒé—´æ¥å®¾è¯­  \n6.å®šè¯­:  \n  â‘  ä¿®é¥°åè¯æˆ–ä»£è¯  \n7.çŠ¶è¯­  \n  ä¿®é¥°åŠ¨è¯ã€å½¢å®¹è¯ã€å‰¯è¯  \n8.å®¾è¯­è¡¥è¶³è¯­  \n  â‘  ç”¨æ¥è¯´æ˜å®¾è¯­æ€ä¹ˆæ ·æˆ–è€…å¹²ä»€ä¹ˆ  \n  â‘¡ ç”±å½¢å®¹è¯æˆ–åŠ¨è¯å……å½“  \n6.åŒä½è¯­  \n  æ ¹åœ¨åè¯ã€ä»£è¯åé¢ï¼Œè¿›ä¸€æ­¥è¯´æ˜å®ƒçš„æƒ…å†µ  \n\næ¯”è¾ƒ  \n1.å®šè¯­&çŠ¶è¯­  \n  çœ‹æœ‰æ²¡æœ‰è¢«ä¿®é¥°çš„åè¯  \n    æœ‰  å®šè¯­  \n    æ—   çŠ¶è¯­  \n2.å®¾è¯­&è¡¨è¯­  \n  åŠ¨è¯ + å®¾è¯­  \n  be/æ„Ÿå®˜åŠ¨è¯ + è¡¨è¯­  \n3.åŒå®¾&å®¾è¡¥  \n  è¢«åŠ¨è¯­æ€  \n    ä¸¤ä¸ªè¢«åŠ¨å¥-åŒå®¾  \n    ä¸€ä¸ªè¢«åŠ¨å¥-å®¾è¡¥  \n  åŠ¨è¯+1+2  \n\n### ä¸‰ã€æ„è¯æ³• ï¼ˆ3ç§ï¼‰  \n1.åˆæˆæ³•  \n2.æ´¾ç”Ÿå‘  \n  2.1 æ´¾ç”Ÿåè¯  \n     åŠ¨è¯+er/or  \n     åŠ¨è¯+ing \n     åŠ¨è¯+(t)ion  \n     å½¢å®¹è¯+ness  \n     å…¶å®ƒ  \n  2.2 æ´¾ç”Ÿå½¢å®¹è¯\n     åè¯+y   \n     åè¯+ful   \n     åŠ¨è¯+ing/ed    \n     friendly  \n     dangerous   \n     å›½å  \n  2.3 æ´¾ç”Ÿå‰¯è¯  \n     å½¢å®¹è¯+ly   å…¶å®ƒ  \n3.è½¬æ¢æ³•  \n  â‘  å½¢å®¹è¯->åŠ¨è¯  \n  â‘¡ åŠ¨è¯->åè¯  \n  â‘¢ åè¯->åŠ¨è¯  \n  â‘£ å½¢å®¹è¯->å‰¯è¯  \n  â‘¤ å‰¯è¯->è¿è¯  \n  â‘¥ ä»‹è¯->å‰¯è¯  ",
      "npm_url": "",
      "npm_downloads": 0
    },
    "zalab-inc--mcp-sequentialthinking": {
      "owner": "zalab-inc",
      "name": "mcp-sequentialthinking",
      "url": "https://github.com/zalab-inc/mcp-sequentialthinking",
      "imageUrl": "https://github.com/zalab-inc.png",
      "description": "Facilitates dynamic and reflective problem-solving through a structured step-by-step thinking process, enabling users to break down complex problems, revise their thoughts, and branch into alternative reasoning paths.",
      "stars": 3,
      "forks": 3,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-08-19T04:15:22Z",
      "readme_content": "\n# Sequential Thinking MCP Server\n\nAn MCP server implementation that provides a tool for dynamic and reflective problem-solving through a structured thinking process.\n\n## Features\n\n- Break down complex problems into manageable steps\n- Revise and refine thoughts as understanding deepens\n- Branch into alternative paths of reasoning\n- Adjust the total number of thoughts dynamically\n- Generate and verify solution hypotheses\n\n## Tool\n\n### sequential_thinking\n\nFacilitates a detailed, step-by-step thinking process for problem-solving and analysis.\n\n**Inputs:**\n- `thought` (string): The current thinking step\n- `nextThoughtNeeded` (boolean): Whether another thought step is needed\n- `thoughtNumber` (integer): Current thought number\n- `totalThoughts` (integer): Estimated total thoughts needed\n- `isRevision` (boolean, optional): Whether this revises previous thinking\n- `revisesThought` (integer, optional): Which thought is being reconsidered\n- `branchFromThought` (integer, optional): Branching point thought number\n- `branchId` (string, optional): Branch identifier\n- `needsMoreThoughts` (boolean, optional): If more thoughts are needed\n\n## Usage\n\nThe Sequential Thinking tool is designed for:\n- Breaking down complex problems into steps\n- Planning and design with room for revision\n- Analysis that might need course correction\n- Problems where the full scope might not be clear initially\n- Tasks that need to maintain context over multiple steps\n- Situations where irrelevant information needs to be filtered out\n\n## Configuration\n\n### Usage with Claude Desktop\n\nAdd this to your `claude_desktop_config.json`:\n\n#### npx\n\n```json\n{\n  \"mcpServers\": {\n    \"sequential-thinking\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@modelcontextprotocol/server-sequential-thinking\"\n      ]\n    }\n  }\n}\n```\n\n#### docker\n\n```json\n{\n  \"mcpServers\": {\n    \"sequentialthinking\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"mcp/sequentialthinking\"\n      ]\n    }\n  }\n}\n```\n\n## Building\n\nDocker:\n\n```bash\ndocker build -t mcp/sequentialthinking -f src/sequentialthinking/Dockerfile .\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "ZannyTornadoCoding--my-sequential-thinking-mcp-server": {
      "owner": "ZannyTornadoCoding",
      "name": "my-sequential-thinking-mcp-server",
      "url": "https://github.com/ZannyTornadoCoding/my-sequential-thinking-mcp-server",
      "imageUrl": "https://github.com/ZannyTornadoCoding.png",
      "description": "Facilitates structured sequential thinking by breaking down complex problems into logical steps, managing reasoning chains, and visualizing thinking pathways. Integrates with a Memory Bank for storing and retrieving thought processes, while providing tools for reasoning validation and analysis.",
      "stars": 3,
      "forks": 1,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-07-05T01:40:56Z",
      "readme_content": "# Sequential Thinking MCP Server\n\nA Model Context Protocol (MCP) server focused on structured sequential thinking capabilities, designed to integrate with Cline's Memory Bank. This server helps break down complex problems into structured sequential steps, track reasoning chains, and store thinking patterns.\n\n## Features\n\n- Create and manage sequential thinking chains for problem-solving\n- Track chains of thought with validation at each step\n- Store and retrieve reasoning patterns\n- Analyze the quality of reasoning processes\n- Visualize thinking pathways\n- Seamlessly integrate with the Memory Bank system\n\n## Architecture\n\nThe server consists of the following core components:\n\n- **Sequential Thinking Engine**: Manages thinking chains, steps, and reasoning validation\n- **Memory Bank Connector**: Integrates with Cline's Memory Bank\n- **Tag Manager**: Implements a comprehensive tagging system\n- **Visualization Generator**: Creates visual representations of thinking chains\n- **Utilities**: File storage, thinking validation, and other helpers\n\n## Available Tools\n\nThe server provides the following MCP tools:\n\n### create_thinking_chain\nCreate a new sequential thinking process with specified parameters.\n- **Input**: problem description, thinking type, context\n- **Output**: chain_id and initial structure\n\n### add_thinking_step\nAdd a step to an existing thinking chain.\n- **Input**: chain_id, step description, reasoning, evidence\n- **Output**: updated step information\n\n### validate_step\nValidate logical connections between steps.\n- **Input**: chain_id, step_id\n- **Output**: validation results, potential issues\n\n### get_chain\nRetrieve a complete thinking chain.\n- **Input**: chain_id\n- **Output**: full chain with all steps\n\n### generate_visualization\nCreate visual representation of a thinking chain.\n- **Input**: chain_id, format (mermaid, json, text)\n- **Output**: visualization code/data\n\n### save_to_memory\nSave a thinking chain to Memory Bank.\n- **Input**: chain_id, memory_name, tags\n- **Output**: confirmation and memory_id\n\n### load_from_memory\nLoad a thinking chain from Memory Bank.\n- **Input**: memory_id or search parameters\n- **Output**: complete chain\n\n### search_related_thinking\nFind related thinking chains based on parameters.\n- **Input**: keywords, tags, thinking_type\n- **Output**: list of relevant chains\n\n### apply_template\nApply a reasoning template to current thinking.\n- **Input**: template_name, problem_context\n- **Output**: pre-structured thinking chain\n\n## Thinking Types\n\nThe server supports various thinking types, each with specific patterns and structures:\n\n- **Analytical** - Break down, analyze, synthesize\n- **Creative** - Diverge, explore, converge\n- **Critical** - Question, evaluate, conclude\n- **Systems** - Map, analyze, model\n- **First-Principles** - Identify, break down, reassemble\n- **Divergent** - Generate alternatives, explore\n- **Convergent** - Analyze, evaluate, select\n- **Inductive** - Observe, pattern, hypothesize\n- **Deductive** - Premise, logic, conclusion\n\n## Templates\n\nThe server includes ready-to-use reasoning templates to jumpstart the thinking process:\n\n- **First Principles Analysis** - Break down a complex problem into its fundamental principles\n- **Systems Thinking Analysis** - Analyze complex systems holistically\n\n## Installation\n\n1. Ensure Node.js v14+ is installed\n2. Clone the repository\n3. Install dependencies:\n   ```\n   npm install\n   ```\n\n## Usage\n\n1. Start the server:\n   ```\n   node index.js\n   ```\n\n2. The server will be available as an MCP server that you can connect to via Claude/Cline\n\n## Memory Bank Integration\n\nThis server is designed to integrate with Cline's Memory Bank, allowing:\n\n1. Reading from Memory Bank files (projectbrief.md, activeContext.md, etc.)\n2. Storing complete thinking chains as structured memories\n3. Updating activeContext.md with reasoning outcomes\n4. Creating links between reasoning and Memory Bank sections\n\n## Example Tool Usage\n\n```javascript\n// Example: Create a new thinking chain\n{\n  \"problem\": \"How to improve user engagement on our platform\",\n  \"thinking_type\": \"systems\",\n  \"context\": \"Our user engagement metrics have decreased by 15% over the past quarter\"\n}\n\n// Example: Add a thinking step\n{\n  \"chain_id\": \"3a7e4fc0-5c1d-4b9f-9d1a-8b5e7c5a9d3e\",\n  \"description\": \"Identify key components of the engagement system\",\n  \"reasoning\": \"User engagement consists of several interconnected components including onboarding, core user actions, notification systems, and retention mechanisms.\",\n  \"evidence\": \"Analysis of our user journey maps and analytics data\",\n  \"confidence\": 0.8\n}\n\n// Example: Generate a visualization\n{\n  \"chain_id\": \"3a7e4fc0-5c1d-4b9f-9d1a-8b5e7c5a9d3e\",\n  \"format\": \"mermaid\",\n  \"options\": {\n    \"showValidation\": true,\n    \"showConfidence\": true\n  }\n}\n```\n\n## Tag System\n\nThe server implements a comprehensive tagging system with multiple dimensions:\n\n- **Thinking Type** - analytical, creative, critical, systems, etc.\n- **Domain** - business, science, technology, art, etc.\n- **Complexity** - simple, moderate, complex\n- **Status** - draft, validated, complete\n- **Custom** - user-defined tags\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    }
  }
}