{
  "category": "open-source-data",
  "categoryDisplay": "Open Source Data",
  "description": "",
  "totalRepositories": 5,
  "repositories": {
    "OpenDataMCP--OpenDataMCP": {
      "owner": "OpenDataMCP",
      "name": "OpenDataMCP",
      "url": "https://github.com/OpenDataMCP/OpenDataMCP",
      "imageUrl": "/freedevtools/mcp/pfp/OpenDataMCP.webp",
      "description": "Python MCP servers that provide access to Open Data for large language model (LLM) clients, facilitating the integration of various data sources.",
      "stars": 134,
      "forks": 19,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-26T20:00:48Z",
      "readme_content": "# Open Data Model Context Protocol\n\n![vc3598_Hyper-realistic_Swiss_landscape_pristine_SBB_red_train_p_40803c2e-43f5-410e-89aa-f6bdcb4cd089](https://github.com/user-attachments/assets/80c823dd-0b26-4d06-98f9-5c6d7c9103de)\n<p align=\"center\">\n    <em>Connect Open Data to LLMs in minutes!</em>\n</p>\n<p align=\"center\">\n   <a href=\"https://github.com/OpenDataMCP/OpenDataMCP/actions/workflows/ci.yml\" target=\"_blank\">\n    <img src=\"https://github.com/OpenDataMCP/OpenDataMCP/actions/workflows/ci.yml/badge.svg\" alt=\"CI\">\n   </a>\n   <a href=\"https://pypi.org/project/odmcp\" target=\"_blank\">\n       <img src=\"https://img.shields.io/pypi/v/odmcp?color=%2334D058&label=pypi%20package\" alt=\"Package version\">\n   </a>\n   <a href=\"https://github.com/OpenDataMCP/OpenDataMCP/blob/main/LICENSE\" target=\"_blank\">\n      <img src=\"https://img.shields.io/github/license/OpenDataMCP/OpenDataMCP.svg\" alt=\"License\">\n   </a>\n   <a href=\"https://pepy.tech/badge/odmcp\" target=\"_blank\">\n      <img src=\"https://pepy.tech/badge/odmcp?cache-control=no-cache\" alt=\"License\">\n   </a>\n   <a href=\"https://github.com/OpenDataMCP/OpenDataMCP/stargazers\" target=\"_blank\">\n      <img src=\"https://img.shields.io/github/stars/OpenDataMCP/OpenDataMCP.svg?cache-control=no-cache\" alt=\"Stars\">\n   </a>\n</p>\n\n## See it in action\n\nhttps://github.com/user-attachments/assets/760e1a16-add6-49a1-bf71-dfbb335e893e\n\nWe enable 2 things: \n\n* **Open Data Access**: Access to many public datasets right from your LLM application (starting with Claude, more to come).\n* **Publishing**: Get community help and a distribution network to distribute your Open Data. Get everyone to use it!\n\nHow do we do that?\n\n* **Access**: Setup our MCP servers in your LLM application in 2 clicks via our CLI tool (starting with Claude, see Roadmap for next steps).\n* **Publish**: Use provided templates and guidelines to quickly contribute and publish on Open Data MCP. Make your data easily discoverable!\n\n## Usage\n\n### <u>Access</u>: Access Open Data using Open Data MCP CLI Tool\n\n#### Prerequisites\n\nIf you want to use Open Data MCP with Claude Desktop app client you need to install the [Claude Desktop app](https://claude.ai/download).\n\nYou will also need `uv` to easily run our CLI and MCP servers.\n\n##### macOS\n\n```bash\n# you need to install uv through homebrew as using the install shell script \n# will install it locally to your user which make it unavailable in the Claude Desktop app context.\nbrew install uv\n```\n\n##### Windows\n\n```bash\n# (UNTESTED)\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\n#### Open Data MCP - CLI Tool\n\n##### Overview\n\n```bash\n# show available commands\nuvx odmcp \n\n# show available providers\nuvx odmcp list\n\n# show info about a provider\nuvx odmcp info $PROVIDER_NAME\n\n# setup a provider's MCP server on your Claude Desktop app\nuvx odmcp setup $PROVIDER_NAME\n\n# remove a provider's MCP server from your Claude Desktop app\nuvx odmcp remove $PROVIDER_NAME\n```\n\n##### Example\n\nQuickstart for the Switzerland SBB (train company) provider:\n\n```bash\n# make sure claude is installed\nuvx odmcp setup ch_sbb\n```\n\nRestart Claude and you should see a new hammer icon at the bottom right of the chat.\n\nYou can now ask questions to Claude about SBB train network disruption and it will answer based on data collected on `data.sbb.ch`.\n\n### <u>Publish</u>: Contribute by building and publishing public datasets\n\n#### Prerequisites\n\n1. **Install UV Package Manager**\n   ```bash\n   # macOS\n   brew install uv\n\n   # Windows (PowerShell)\n   powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n   # Linux/WSL\n   curl -LsSf https://astral.sh/uv/install.sh | sh\n   ```\n\n2. **Clone & Setup Repository**\n   ```bash\n   # Clone the repository\n   git clone https://github.com/OpenDataMCP/OpenDataMCP.git\n   cd OpenDataMCP\n\n   # Create and activate virtual environment\n   uv venv\n   source .venv/bin/activate  # Unix/macOS\n   # or\n   .venv\\Scripts\\activate     # Windows\n\n   # Install dependencies\n   uv sync\n   ```\n\n3. **Install Pre-commit Hooks**\n   ```bash\n   # Install pre-commit hooks for code quality\n   pre-commit install\n   ```\n\n#### Publishing Instructions\n\n1. **Create a New Provider Module**\n   * Each data source needs its own python module.\n   * Create a new Python module in `src/odmcp/providers/`.\n   * Use a descriptive name following the pattern: `{country_code}_{organization}.py` (e.g., `ch_sbb.py`).\n   * Start with our [template file](https://github.com/OpenDataMCP/OpenDataMCP/blob/main/src/odmcp/providers/__template__.py) as your base.\n\n2. **Implement Required Components**\n   * Define your Tools & Resources following the template structure\n   * Each Tool or Resource should have:\n     - Clear description of its purpose\n     - Well-defined input/output schemas using Pydantic models\n     - Proper error handling\n     - Documentation strings\n\n3. **Tool vs Resource**\n   * Choose **Tool** implementation if your data needs:\n     - Active querying or computation\n     - Parameter-based filtering\n     - Complex transformations\n   * Choose **Resource** implementation if your data is:\n     - Static or rarely changing\n     - Small enough to be loaded into memory\n     - Simple file-based content\n     - Reference documentation or lookup tables\n   * Reference the [MCP documentation](https://github.com/modelcontextprotocol/python-sdk?tab=readme-ov-file#primitives) for guidance\n\n4. **Testing**\n   * Add tests in the `tests/` directory\n   * Follow existing test patterns (see other provider tests)\n   * Required test coverage:\n     - Basic functionality\n     - Edge cases\n     - Error handling\n\n5. **Validation**\n   * Test your MCP server using our experimental client: `uv run src/odmcp/providers/client.py`\n   * Verify all endpoints respond correctly\n   * Ensure error messages are helpful\n   * Check performance with typical query loads\n\nFor other examples, check our existing providers in the `src/odmcp/providers/` directory.\n\n## Contributing\n\nWe have an ambitious roadmap and we want this project to scale with the community. The ultimate goal is to make the millions of datasets publicly available to all LLM applications. \n\nFor that we need your help!\n\n### Discord\n\nWe want to build a helping community around the challenge of bringing open data to LLM's. Join us on discord to start chatting: [https://discord.gg/QPFFZWKW](https://discord.gg/hDg4ZExjGs)\n\n### Our Core Guidelines\n\nBecause of our target scale we want to keep things simple and pragmatic at first. Tackle issues with the community as they come along.\n\n1. **Simplicity and Maintainability**\n   * Minimize abstractions to keep codebase simple and scalable\n   * Focus on clear, straightforward implementations\n   * Avoid unnecessary complexity\n\n2. **Standardization / Templates**\n   * Follow provided templates and guidelines consistently\n   * Maintain uniform structure across providers\n   * Use common patterns for similar functionality\n\n3. **Dependencies**\n   * Keep external dependencies to a minimum\n   * Prioritize single repository/package setup\n   * Carefully evaluate necessity of new dependencies\n\n4. **Code Quality**\n   * Format code using ruff\n   * Maintain comprehensive test coverage with pytest\n   * Follow consistent code style\n\n5. **Type Safety**\n   * Use Python type hints throughout\n   * Leverage Pydantic models for API request/response validation\n   * Ensure type safety in data handling\n\n### Tactical Topics (our current priorities)\n* [x] Initialize repository with guidelines, testing framework, and contribution workflow\n* [x] Implement CI/CD pipeline with automated PyPI releases\n* [x] Develop provider template and first reference implementation\n* [ ] **Integrate additional open datasets (actively seeking contributors)**\n* [ ] Establish clear guidelines for choosing between Resources and Tools\n* [ ] Develop scalable repository architecture for long-term growth\n* [ ] Expand MCP SDK parameter support (authentication, rate limiting, etc.)\n* [ ] Implement additional MCP protocol features (prompts, resource templates)\n* [ ] Add support for alternative transport protocols beyond stdio (SSE)\n* [ ] Deploy hosted MCP servers for improved accessibility\n\n## Roadmap\nLet’s build the open source infrastructure that will allow all LLMs to access all Open Data together!\n\n### Access:\n* Make Open Data available to all LLM applications (beyond Claude)\n* Make Open Data data sources searchable in a scalable way\n* Make Open Data available through MCP remotely (SSE) with publicly sponsored infrastructure\n\n### Publish:\n* Build the many Open Data MCP servers to make all the Open Data truly accessible (we need you!).\n* On our side we are starting to build MCP servers for Switzerland ~12k open dataset! \n* Make it even easier to build Open Data MCP servers\n\nWe are very early, and lack of dataset available is currently the bottleneck. Help yourself! Create your Open Data MCP server and get users to use it as well from their LLMs applications. Let’s connect LLMs to the millions of open datasets from governments, public entities, companies and NGOs!\n\nAs Anthropic's MCP evolves we will adapt and upgrade Open Data MCP.\n\n## Limitations\n\n* All data served by Open Data MCP servers should be Open. \n* Please oblige to the data licenses of the data providers.\n* Our License must be quoted in commercial applications.\n\n## References\n\n* Kudos to [Anthropic's open source MCP](https://spec.modelcontextprotocol.io/) release enabling initiative like this one.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "opendatamcp",
        "mcp",
        "python",
        "opendatamcp python",
        "data opendatamcp",
        "opendatamcp opendatamcp"
      ],
      "category": "open-source-data"
    },
    "doanbactam--code": {
      "owner": "doanbactam",
      "name": "code",
      "url": "https://github.com/doanbactam/code",
      "imageUrl": "/freedevtools/mcp/pfp/doanbactam.webp",
      "description": "Connect to a community-driven directory of open source alternatives to proprietary software. Discover, explore, and contribute to a collection of open source services that facilitate business growth.",
      "stars": 0,
      "forks": 0,
      "license": "GNU General Public License v3.0",
      "language": "TypeScript",
      "updated_at": "2025-04-28T07:21:52Z",
      "readme_content": "![m4v](https://m4v.co/opengraph.png)\n\n<p align=\"center\"></p>\n\n<p align=\"center\">\n  Discover open source alternatives to popular software.\n  <br />\n  <a href=\"https://m4v.co\"><strong>Learn more »</strong></a>\n  <br />\n  <br />\n  <a href=\"https://m4v.co\">Website</a>\n  ·\n  <a href=\"https://github.com/piotrkulpinski/m4v/issues\">Issues</a>\n</p>\n\n<p align=\"center\">\n   <a href=\"https://github.com/piotrkulpinski/m4v/stargazers\"><img src=\"https://img.shields.io/github/stars/piotrkulpinski/m4v\" alt=\"Github Stars\" /></a>\n   <a href=\"https://uptime.betterstack.com/?utm_source=status_badge\"><img src=\"https://uptime.betterstack.com/status-badges/v1/monitor/1lyos.svg\" alt=\"Better Stack\" /></a>\n   <a href=\"https://github.com/piotrkulpinski/m4v/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/piotrkulpinski/m4v\" alt=\"License\" /></a>\n   <a href=\"https://github.com/piotrkulpinski/m4v/pulse\"><img src=\"https://img.shields.io/github/commit-activity/m/piotrkulpinski/m4v\" alt=\"Commits-per-month\" /></a>\n   <a href=\"https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/piotrkulpinski/m4v\">\n   <img alt=\"open in devcontainer\" src=\"https://img.shields.io/static/v1?label=Dev%20Containers&message=Enabled&color=blue&logo=visualstudiocode\" />\n   </a>\n   <a href=\"https://news.ycombinator.com/item?id=39639386\"><img src=\"https://img.shields.io/badge/Hacker%20News-156-%23FF6600\" alt=\"Hacker News\" /></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://www.producthunt.com/posts/m4v?utm_source=badge-top-post-badge&utm_medium=badge&utm_souce=badge-m4v\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=443404&theme=light&period=daily\" alt=\"m4v - Discover open source alternatives to popular software | Product Hunt\" style=\"width: 250px; height: 54px;\" width=\"250\" height=\"54\" /></a>\n  <a href=\"https://www.producthunt.com/posts/m4v?utm_source=badge-featured&utm_medium=badge&utm_souce=badge-m4v\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=443404&theme=light\" alt=\"m4v - Discover open source alternatives to popular software | Product Hunt\" style=\"width: 250px; height: 54px;\" width=\"250\" height=\"54\" /></a>\n</p>\n\n## About this project\n\nm4v is a community driven list of **open source alternatives to proprietary software** and applications.\n\nOur goal is to be your first stop when researching for a new open source service to help you grow your business. We will help you **find alternatives** of the products you already use.\n\nJoin us in creating the biggest **directory of open source software**.\n\n## Sponsoring\n\nm4v is an GPL-3.0-licensed open source project with its ongoing development made possible entirely by the support of these awesome backers. If you'd like to join them, please consider [sponsoring m4v's development](https://github.com/sponsors/piotrkulpinski).\n\nIf you'd like to support the project, you could also consider [buying our Next.js boilerplate](https://dirstarter.com) which is the foundation of creating directory websites, just like this one.\n\n## Services\n\nm4v uses the following third-party services:\n\n- Database: [Neon](https://neon.tech)\n- Analytics: [Plausible](https://plausible.io), [PostHog](https://posthog.com)\n- Newsletter: [Beehiiv](https://go.m4v.co/beehiiv)\n- Background Jobs: [Inngest](https://inngest.com)\n- File Storage: [AWS S3](https://aws.amazon.com/s3)\n- Payments: [Stripe](https://stripe.com)\n- Screenshots: [ScreenshotOne](https://go.m4v.co/screenshotone)\n\nMake sure to set up accounts with these services and add the necessary environment variables to your `.env` file.\n\n## Project Structure\n\nm4v is built as a Turborepo monorepo with multiple packages. The project structure is organized as follows:\n\n- `/apps` - Turborepo apps\n  - `/app` - Main Next.js application using the App Router architecture\n    - `/app` - Application routes and layouts (Next.js App Router)\n    - `/components` - Reusable React components\n    - `/lib` - Core utilities and business logic\n    - `/actions` - Server actions\n    - `/utils` - Helper functions and utilities\n    - `/hooks` - React hooks\n    - `/contexts` - React context providers\n    - `/services` - Service integrations\n    - `/emails` - Email templates\n    - `/server` - Server-side code\n    - `/functions` - Utility functions\n    - `/config` - Configuration files\n    - `/content` - Content management\n    - `/types` - TypeScript type definitions\n    - `/public` - Static assets\n\n  - `/analyzer` - Data analysis tools\n\n- `/packages` - Shared packages\n  - `/db` - Database schema and utilities\n  - `/github` - GitHub integration utilities\n\nThe project uses Turborepo for task orchestration and dependency management across the monorepo.\n\n## Development\n\nThis project uses [Bun](https://bun.sh/) as the package manager and runtime. Make sure you have Bun installed before proceeding.\n\nTo set up the project for development:\n\n1. Clone the repository\n2. Run `bun install` to install all dependencies\n3. Set up the required environment variables (see below)\n4. Run `bun run db:push` to push the Prisma schema to the database\n5. Run `bun run dev` to start the application in development mode\n\n### Environment Variables\n\nRefer to the `.env.example` file for a complete list of required variables.\n\nCopy the `.env.example` file to `.env` and update the variables as needed:\n\n```bash\ncp .env.example .env\n```\n\n## 🧞 Commands\n\nAll commands are run from the root of the project, from a terminal:\n\n| Command           | Action                                           |\n| :---------------- | :----------------------------------------------- |\n| `bun install`     | Installs dependencies                            |\n| `bun run dev`     | Starts local dev server at `localhost:5173`      |\n| `bun run build`   | Build production application                     |\n| `bun run start`   | Preview production build locally                 |\n| `bun run lint`    | Run linter                                       |\n| `bun run format`  | Format code                                      |\n| `bun run typecheck` | Run TypeScript type checking                   |\n| `bun run db:generate` | Generate Prisma client                       |\n| `bun run db:studio` | Start Prisma Studio                           |\n| `bun run db:push` | Push Prisma schema to database                  |\n| `bun run db:pull` | Pull Prisma schema from database                |\n| `bun run db:reset` | Reset Prisma schema                            |\n\n## Deployment\n\nThe project is set up for deployment on Vercel. To deploy manually:\n\n1. Build the project: `bun run build`\n2. Start the production server: `bun run start`\n\nEnsure all environment variables are properly set in your production environment.\n\n## License\n\nm4v is licensed under the [GPL-3.0 License](LICENSE).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "doanbactam",
        "software",
        "data",
        "data doanbactam",
        "doanbactam code",
        "open source"
      ],
      "category": "open-source-data"
    },
    "joaowinderfeldbussolotto--MCP-Websearch-Server": {
      "owner": "joaowinderfeldbussolotto",
      "name": "MCP-Websearch-Server",
      "url": "https://github.com/joaowinderfeldbussolotto/MCP-Websearch-Server",
      "imageUrl": "/freedevtools/mcp/pfp/joaowinderfeldbussolotto.webp",
      "description": "Fetches relevant documentation snippets from Langchain, Llama Index, and OpenAI to enhance search capabilities. Provides a simple tool to retrieve information based on user queries.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-03-28T01:38:25Z",
      "readme_content": "## MPC Docs Server\n\nThis is a simple MCP (Model Context Protocol) server for retrieving information from the official documentation of Langchain, Llama Index, and OpenAI. It provides a tool that can be used by MCP-compatible applications to search and retrieve relevant documentation snippets.\n\n## Features\n\n-   **Documentation Retrieval:** Fetches content from the official documentation of Langchain, Llama Index, and OpenAI.\n-   **MCP Compatibility:** Implements an MCP server, allowing it to be easily integrated with other MCP-compatible applications.\n-   **Simple Tool:** Exposes a `get_docs` tool that accepts a query and library name, returning relevant documentation snippets.\n\n## How It Works\n\n```mermaid\ngraph LR\n    Client[MCP Client] -->|Calls tools| Server[MCP Server]\n    Server -->|Searches web for docs| Serper[Serper API]\n    Serper -->|Returns search results| Server\n    Server -->|Returns documentation| Client\n```\n\n## Getting Started\n\n### Installing uv Package Manager\n\n**On MacOS/Linux:**\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\nMake sure to restart your terminal afterwards to ensure that the `uv` command gets picked up.\n\n### Project Setup\n\nCreate and initialize the project:\n```bash\n# Create a new directory for our project\nuv init mcp-server\ncd mcp-server\n\n# Create virtual environment and activate it\nuv venv\nsource .venv/bin/activate  # On Windows use: .venv\\Scripts\\activate\n\n# Install dependencies\nuv add \"mcp[cli]\" httpx python-dotenv bs4\n```\n\n\n### Environment Variables\n\nCreate a `.env` file in the root directory and add the following:\n\n```\nSERPER_API_KEY=YOUR_SERPER_API_KEY\n```\n\nYou'll need a SERPER API key to use the web search functionality. You can obtain one from [Serper.dev](https://serper.dev/). We are using the Serper API to search the web for relevant documentation.\n\n### Running the Server\n\nStart the MCP server:\n```bash\nuv run main.py\n```\n\nThe server will start and be ready to accept connections.\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "websearch",
        "search",
        "fetches",
        "mcp websearch",
        "websearch server",
        "index openai"
      ],
      "category": "open-source-data"
    },
    "melaodoidao--datagov-mcp-server": {
      "owner": "melaodoidao",
      "name": "datagov-mcp-server",
      "url": "https://github.com/melaodoidao/datagov-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/melaodoidao.webp",
      "description": "Access and retrieve government datasets from Data.gov, enabling interactions with a wide variety of public data resources in real-time.",
      "stars": 17,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-28T16:13:06Z",
      "readme_content": "# Data.gov MCP Server\n\nAn MCP server for accessing data from Data.gov, providing tools and resources for interacting with government datasets.\n\n<a href=\"https://glama.ai/mcp/servers/qi5i2d6sen\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/qi5i2d6sen/badge\" alt=\"Data.gov Server MCP server\" />\n</a>\n\n## Installation\n\n1.  **Install the package globally:**\n\n    ```bash\n    npm install -g @melaodoidao/datagov-mcp-server\n    ```\n\n2. **Configure the MCP Server:**\n\n   - Add the following entry to your `cline_mcp_settings.json` file (usually located in `~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/` on macOS):\n\n     ```json\n      {\n        \"mcpServers\": {\n          \"datagov\": {\n            \"command\": \"datagov-mcp-server\",\n            \"args\": [],\n            \"env\": {}\n          }\n        }\n      }\n     ```\n    - If you are using the Claude Desktop app, add the entry to `~/Library/Application Support/Claude/claude_desktop_config.json` instead.\n\n## Usage\n\nThis server provides the following tools:\n\n*   `package_search`: Search for packages (datasets) on Data.gov.\n*   `package_show`: Get details for a specific package (dataset).\n*   `group_list`: List groups on Data.gov.\n*   `tag_list`: List tags on Data.gov.\n\nIt also provides the following resource template:\n\n*   `datagov://resource/{url}`: Access a Data.gov resource by its URL.\n\nYou can use these tools and resources with Cline by specifying the server name (`datagov-mcp-server`) and the tool/resource name.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit issues or pull requests.\n\n## License\n\nMIT License",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "datasets",
        "datagov",
        "gov",
        "government datasets",
        "data gov",
        "public data"
      ],
      "category": "open-source-data"
    },
    "srobbin--opengov-mcp-server": {
      "owner": "srobbin",
      "name": "opengov-mcp-server",
      "url": "https://github.com/srobbin/opengov-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/srobbin.webp",
      "description": "Enable access to public government datasets from Socrata-powered portals, allowing search, retrieval, and analysis of open data from various government sources without the need for API keys.",
      "stars": 9,
      "forks": 3,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-08-29T07:33:53Z",
      "readme_content": "# OpenGov MCP Server\n\nAn MCP (Model Context Protocol) server that enables MCP clients like Claude Desktop to access Socrata Open Data APIs. This integration allows Claude Desktop to search for, retrieve, and analyze public datasets from government data portals.\n\n## Overview\n\nThis MCP server provides access to open data from any Socrata-powered data portal, including those from cities, states, and federal agencies such as:\n- [Chicago](https://data.cityofchicago.org)\n- [NYC](https://data.cityofnewyork.us)\n- [San Francisco](https://data.sfgov.org)\n- [Los Angeles](https://data.lacity.org)\n- [And other government entities](https://dev.socrata.com/data/)\n\nNo API key is required for basic usage, as the server accesses public data.\n\n## Features\n\nWith this MCP server, clients can:\n- Search and discover datasets by keyword, category, or tags\n- View dataset metadata and column information\n- Run SQL-like queries to retrieve and analyze data\n- Get portal usage statistics\n\n## Installation for Claude Desktop\n\n### Quick Setup with npx (Recommended)\n\nThe easiest way to use this MCP server is with npx, which doesn't require any installation:\n\n1. **Create or edit your Claude Desktop configuration**:\n   \n   Create or edit `claude_desktop_config.json` in your home directory:\n\n   ```json\n   {\n     \"mcpServers\": { \n       \"opengov\": {\n         \"command\": \"npx\",\n         \"args\": [\"-y\", \"opengov-mcp-server@latest\"],\n         \"env\": {\n           \"DATA_PORTAL_URL\": \"https://data.cityofchicago.org\"\n         }\n       }\n     }\n   }\n   ```\n\n   You can replace the DATA_PORTAL_URL with any Socrata-powered data portal.\n\n2. **Restart Claude Desktop** (if it was already running)\n\n3. **Start using the MCP server**:\n   \n   In Claude Desktop, you can now ask questions like:\n   \n   ```\n   How many cars were towed in Chicago this month?\n   ```\n\n   and you can follow up with questions that drill further into detail:\n\n   ```\n   Which make and color were towed the most?\n   Also, were there any interesting vanity plates?\n   ```\n\n   The first time you run a query, npx will automatically download and run the latest version of the server.\n\n### Manual Installation from Source\n\nIf you prefer to run from source (for development or customization):\n\n1. **Clone this repository**:\n   ```bash\n   git clone https://github.com/srobbin/opengov-mcp-server.git\n   cd opengov-mcp-server\n   ```\n\n2. **Install dependencies and build**:\n   ```bash\n   npm install\n   npm run build\n   ```\n\n3. **Create Claude Desktop configuration**:\n   \n   Create or edit `claude_desktop_config.json` in your home directory:\n\n   ```json\n   {\n     \"mcpServers\": { \n       \"opengov\": {\n         \"command\": \"node\",\n         \"args\": [\n           \"/path/to/your/opengov-mcp-server/dist/index.js\"\n         ],\n         \"env\": {\n           \"DATA_PORTAL_URL\": \"https://data.cityofchicago.org\"\n         }\n       }\n     }\n   }\n   ```\n\n   Replace `/path/to/your/opengov-mcp-server` with the actual path where you cloned the repository.\n\n4. **Restart Claude Desktop** (if it was already running)\n\n## Available Tool: get_data\n\nThis MCP server provides a unified `get_data` tool that Claude Desktop uses to access Socrata data.\n\n### Parameters\n\n- `type` (string, required): Operation type\n  - `catalog`: Search and list datasets\n  - `categories`: List dataset categories\n  - `tags`: List dataset tags\n  - `dataset-metadata`: Get dataset details\n  - `column-info`: Get dataset column information\n  - `data-access`: Query and retrieve records\n  - `site-metrics`: Get portal statistics\n\n- `domain` (string, optional): Data portal hostname (without protocol)\n\n- `query` (string, optional): Search query for datasets\n\n- `datasetId` (string): Dataset identifier for specific operations\n\n- `soqlQuery` (string, optional): SoQL query for filtering data\n\n- `limit` (number, optional): Maximum results to return (default: 10)\n\n- `offset` (number, optional): Results to skip for pagination (default: 0)\n\n### Example Queries\n\nThese are examples of how Claude Desktop will format queries to the MCP server:\n\n```javascript\n// Find datasets about budgets\n{\n  \"type\": \"catalog\",\n  \"query\": \"budget\",\n  \"limit\": 5\n}\n\n// Get information about a dataset\n{\n  \"type\": \"dataset-metadata\",\n  \"datasetId\": \"6zsd-86xi\"\n}\n\n// Query dataset records with SQL-like syntax\n{\n  \"type\": \"data-access\",\n  \"datasetId\": \"6zsd-86xi\",\n  \"soqlQuery\": \"SELECT * WHERE amount > 1000 ORDER BY date DESC\",\n  \"limit\": 10\n}\n```\n\n## Configuration Options\n\nThe server requires one environment variable:\n\n- `DATA_PORTAL_URL`: The Socrata data portal URL (e.g., `https://data.cityofchicago.org`)\n\nThis can be set:\n- In the Claude Desktop configuration (recommended)\n- In your environment variables\n- Via command line: `DATA_PORTAL_URL=https://data.cityofchicago.org opengov-mcp-server`\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "datasets",
        "srobbin",
        "data",
        "government datasets",
        "datasets socrata",
        "data srobbin"
      ],
      "category": "open-source-data"
    }
  }
}