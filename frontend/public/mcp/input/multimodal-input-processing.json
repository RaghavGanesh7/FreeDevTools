{
  "category": "multimodal-input-processing",
  "categoryDisplay": "Multimodal Input Processing",
  "description": "",
  "totalRepositories": 3,
  "repositories": {
    "8beeeaaat--touchdesigner-mcp": {
      "owner": "8beeeaaat",
      "name": "touchdesigner-mcp",
      "url": "https://github.com/8beeeaaat/touchdesigner-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/8beeeaaat.webp",
      "description": "The TouchDesigner MCP Server allows AI agents to interact with TouchDesigner projects by creating, modifying, and deleting project elements, as well as executing Python scripts to automate tasks.",
      "stars": 94,
      "forks": 9,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T07:04:27Z",
      "readme_content": "# TouchDesigner MCP\n\nThis is an implementation of an MCP (Model Context Protocol) server for TouchDesigner. Its goal is to enable AI agents to control and operate TouchDesigner projects.\n\n[English](https://github.com/8beeeaaat/touchdesigner-mcp/blob/main/README.md) / [日本語](https://github.com/8beeeaaat/touchdesigner-mcp/blob/main/README.ja.md)\n\n## Overview\n\n[![demo clip](https://github.com/8beeeaaat/touchdesigner-mcp/blob/main/assets/particle_on_youtube.png)](https://youtu.be/V2znaqGU7f4?si=6HDFbcBHCFPdttkM&t=635)\n\nTouchDesigner MCP acts as a bridge between AI models and the TouchDesigner WebServer DAT, enabling AI agents to:\n- Create, modify, and delete nodes\n- Query node properties and project structure\n- Programmatically control TouchDesigner via Python scripts\n\n## Usage\n\n<details>\n  <summary>Method 1: Using Claude Desktop and Desktop Extensions (Recommended)</summary>\n\n### 1. Download Files\nDownload the following from the [releases page](https://github.com/8beeeaaat/touchdesigner-mcp/releases/latest):\n- **TouchDesigner Components**: `touchdesigner-mcp-td.zip`\n- **Desktop Extension (.dxt)**: `touchdesigner-mcp.dxt`\n\n### 2. Set up TouchDesigner Components\n1. Extract the TouchDesigner components from `touchdesigner-mcp-td.zip`.\n2. Import `mcp_webserver_base.tox` into your TouchDesigner project.\n3. Place it at `/project1/mcp_webserver_base`.\n\nhttps://github.com/user-attachments/assets/215fb343-6ed8-421c-b948-2f45fb819ff4\n\n  You can check the startup logs by opening the Textport from the TouchDesigner menu.\n\n  ![import](https://github.com/8beeeaaat/touchdesigner-mcp/blob/main/assets/textport.png)\n\n### 3. Install the Desktop Extension\nDouble-click the `touchdesigner-mcp.dxt` file to install the extension in Claude Desktop.\n\nhttps://github.com/user-attachments/assets/0786d244-8b82-4387-bbe4-9da048212854\n\n### 4. Connect to the Server\nThe extension will automatically handle the connection to the TouchDesigner server.\n\n**⚠️ Important:** The directory structure must be preserved exactly as extracted. The `mcp_webserver_base.tox` component references relative paths to the `modules/` directory and other files.\n\n</details>\n\n<details>\n  <summary>Method 2: Using npx</summary>\n\n*Requires Node.js to be installed.*\n\n### 1. Set up TouchDesigner Components\n1. Download and extract the TouchDesigner components from `touchdesigner-mcp-td.zip` ([releases page](https://github.com/8beeeaaat/touchdesigner-mcp/releases/latest)).\n2. Import `mcp_webserver_base.tox` into your TouchDesigner project.\n3. Place it at `/project1/mcp_webserver_base`.\n\nhttps://github.com/user-attachments/assets/215fb343-6ed8-421c-b948-2f45fb819ff4\n\n  You can check the startup logs by opening the Textport from the TouchDesigner menu.\n\n  ![import](https://github.com/8beeeaaat/touchdesigner-mcp/blob/main/assets/textport.png)\n\n### 2. Set up the MCP Server Configuration\n\n*Example for Claude Desktop:*\n```json\n{\n  \"mcpServers\": {\n    \"touchdesigner\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"touchdesigner-mcp-server@latest\", \"--stdio\"]\n    }\n  }\n}\n```\n\n**Customization:** You can customize the TouchDesigner server connection by adding `--host` and `--port` arguments:\n```json\n\"args\": [\n  \"-y\",\n  \"touchdesigner-mcp-server@latest\",\n  \"--stdio\",\n  \"--host=http://custom_host\",\n  \"--port=9982\"\n]\n```\n</details>\n\n<details>\n  <summary>Method 3: Using a Docker Image</summary>\n\n  [![tutorial](https://github.com/8beeeaaat/touchdesigner-mcp/blob/main/assets/tutorial_docker.png)](https://www.youtube.com/watch?v=BRWoIEVb0TU)\n\n  ### 1. Clone the repository\n  ```bash\n  git clone https://github.com/8beeeaaat/touchdesigner-mcp.git\n  cd touchdesigner-mcp\n  ```\n\n  ### 2. Build the Docker image\n  ```bash\n  make build\n  ```\n\n  ### 3. Install the API Server in Your TouchDesigner Project\n\n  Start TouchDesigner and import the `td/mcp_webserver_base.tox` component into the project you want to control.\n  Example: Place it at `/project1/mcp_webserver_base`.\n\n  Importing the `.tox` file will trigger the `td/import_modules.py` script, which loads the necessary modules for the API server.\n\nhttps://github.com/user-attachments/assets/215fb343-6ed8-421c-b948-2f45fb819ff4\n\n  You can check the startup logs by opening the Textport from the TouchDesigner menu.\n\n  ![import](https://github.com/8beeeaaat/touchdesigner-mcp/blob/main/assets/textport.png)\n\n  ### 4. Start the MCP server container\n\n  ```bash\n  docker-compose up -d\n  ```\n\n  ### 5. Configure your AI agent to use the Docker container\n\n  *Example for Claude Desktop:*\n  ```json\n  {\n    \"mcpServers\": {\n      \"touchdesigner\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"compose\",\n          \"-f\",\n          \"/path/to/your/touchdesigner-mcp/docker-compose.yml\",\n          \"exec\",\n          \"-i\",\n          \"touchdesigner-mcp-server\",\n          \"node\",\n          \"dist/cli.js\",\n          \"--stdio\",\n          \"--host=http://host.docker.internal\"\n        ]\n      }\n    }\n  }\n```\n\n  *On Windows systems, include the drive letter, e.g., `C:\\path\\to\\your\\touchdesigner-mcp\\docker-compose.yml`.*\n\n**Note:** You can customize the TouchDesigner server connection by adding `--host` and `--port` arguments:\n  ```json\n\"args\": [\n  ...,\n  \"--stdio\",\n  \"--host=http://host.docker.internal\",\n  \"--port=9982\"\n]\n  ```\n</details>\n\n\n## Verify Connection\n\nIf the MCP server is recognized, the setup is complete.\nIf it's not recognized, try restarting your AI agent.\nIf you see an error at startup, try launching the agent again after starting TouchDesigner.\nWhen the API server is running properly in TouchDesigner, the agent can use the provided tools to operate it.\n\n### Directory Structure Requirements\n\n**Critical:** When using any method, you must maintain the original directory structure:\n\n```\ntd/\n├── import_modules.py          # Module loader script\n├── mcp_webserver_base.tox     # Main TouchDesigner component\n└── modules/                   # Python modules directory\n    ├── mcp/                   # MCP core logic\n    ├── utils/                 # Shared utilities\n    └── td_server/             # Generated API server code\n```\n\nThe `mcp_webserver_base.tox` component uses relative paths to locate Python modules. Moving or reorganizing these files will cause import errors in TouchDesigner.\n\n![demo](https://github.com/8beeeaaat/touchdesigner-mcp/blob/main/assets/nodes_list.png)\n\n\n## MCP Server Features\n\nThis server enables AI agents to perform operations in TouchDesigner using the Model Context Protocol (MCP).\n\n### Tools\n\nTools allow AI agents to perform actions in TouchDesigner.\n\n| Tool Name                | Description                                                        |\n| :---------------------- | :----------------------------------------------------------------- |\n| `create_td_node`        | Creates a new node.                                                |\n| `delete_td_node`        | Deletes an existing node.                                          |\n| `exec_node_method`      | Calls a Python method on a node.                                   |\n| `execute_python_script` | Executes an arbitrary Python script in TouchDesigner.              |\n| `get_td_class_details`  | Gets details of a TouchDesigner Python class or module.            |\n| `get_td_classes`        | Gets a list of TouchDesigner Python classes.                       |\n| `get_td_info`           | Gets information about the TouchDesigner server environment.       |\n| `get_td_node_parameters`| Gets the parameters of a specific node.                            |\n| `get_td_nodes`          | Gets nodes under a parent path, with optional filtering.           |\n| `update_td_node_parameters` | Updates the parameters of a specific node.                     |\n\n### Prompts\n\nPrompts provide instructions for AI agents to perform specific actions in TouchDesigner.\n\n| Prompt Name         | Description                                                                 |\n| :------------------| :-------------------------------------------------------------------------- |\n| `Search node`      | Fuzzy searches for nodes and retrieves information based on name, family, or type. |\n| `Node connection`  | Provides instructions to connect nodes within TouchDesigner.                |\n| `Check node errors`| Checks for errors on a specified node, and recursively for its children.    |\n\n### Resources\n\nNot implemented.\n\n\n## For Developers\n\n### Quick Start for Development\n\n1. **Set up your environment:**\n   ```bash\n   # Clone and install dependencies\n   git clone https://github.com/8beeeaaat/touchdesigner-mcp.git\n   cd touchdesigner-mcp\n   npm install\n   ```\n\n2. **Build the project:**\n   ```bash\n   make build        # Docker-based build (recommended)\n   # OR\n   npm run build     # Node.js-based build\n   ```\n\n3. **Available commands:**\n   ```bash\n   npm run test      # Run unit and integration tests\n   npm run dev       # Launch the MCP inspector for debugging\n   ```\n\n**Note:** When you update the code, you must restart both the MCP server and TouchDesigner to apply the changes.\n\n### Project Structure Overview\n\n```\n├── src/                       # MCP server source code\n│   ├── api/                  # OpenAPI spec for the TouchDesigner WebServer\n│   ├── core/                 # Core utilities (logger, error handling)\n│   ├── features/             # MCP feature implementations\n│   │   ├── prompts/         # Prompt handlers\n│   │   ├── resources/       # Resource handlers\n│   │   └── tools/           # Tool handlers (e.g., tdTools.ts)\n│   ├── gen/                  # Code generated from the OpenAPI schema for the MCP server\n│   ├── server/               # MCP server logic (connections, main server class)\n│   ├── tdClient/             # TouchDesigner connection API client\n│   ├── index.ts              # Main entry point for the Node.js server\n│   └── ...\n├── td/                        # TouchDesigner-related files\n│   ├── modules/              # Python modules for TouchDesigner\n│   │   ├── mcp/              # Core logic for handling MCP requests in TouchDesigner\n│   │   │   ├── controllers/ # API request controllers (api_controller.py, generated_handlers.py)\n│   │   │   └── services/    # Business logic (api_service.py)\n│   │   ├── td_server/        # Python model code generated from the OpenAPI schema\n│   │   └── utils/            # Shared Python utilities\n│   ├── templates/             # Mustache templates for Python code generation\n│   ├── genHandlers.js         # Node.js script for generating generated_handlers.py\n│   ├── import_modules.py      # Helper script to import API server modules into TouchDesigner\n│   └── mcp_webserver_base.tox # Main TouchDesigner component\n├── tests/                      # Test code\n│   ├── integration/\n│   └── unit/\n└── orval.config.ts             # Orval config (TypeScript client generation)\n```\n\n\n### API Code Generation Workflow\n\nThis project uses OpenAPI-based code generation tools (Orval and openapi-generator-cli).\n\n**API Definition:** The API contract between the Node.js MCP server and the Python server running inside TouchDesigner is defined in `src/api/index.yml`.\n\n1.  **Python server generation (`npm run gen:webserver`):**\n    *   Uses `openapi-generator-cli` via Docker.\n    *   Reads `src/api/index.yml`.\n    *   Generates a Python server skeleton (`td/modules/td_server/`) based on the API definition. This code runs inside TouchDesigner's WebServer DAT.\n    *   **Requires Docker to be installed and running.**\n2.  **Python handler generation (`npm run gen:handlers`):**\n    *   Uses a custom Node.js script (`td/genHandlers.js`) and Mustache templates (`td/templates/`).\n    *   Reads the generated Python server code or OpenAPI spec.\n    *   Generates handler implementations (`td/modules/mcp/controllers/generated_handlers.py`) that connect to the business logic in `td/modules/mcp/services/api_service.py`.\n3.  **TypeScript client generation (`npm run gen:mcp`):**\n    *   Uses `Orval` to generate an API client and Zod schemas for tool validation from the schema YAML, which is bundled by `openapi-generator-cli`.\n    *   Generates a typed TypeScript client (`src/tdClient/`) used by the Node.js server to make requests to the WebServer DAT.\n\nThe build process (`npm run build`) runs all necessary generation steps (`npm run gen`), followed by TypeScript compilation (`tsc`).\n\n## Contributing\n\nWe welcome your contributions!\n\n1. Fork the repository.\n2. Create a feature branch (`git checkout -b feature/amazing-feature`).\n3. Make your changes.\n4. Add tests and ensure everything works (`npm test`).\n5. Commit your changes (`git commit -m 'Add some amazing feature'`).\n6. Push to your branch (`git push origin feature/amazing-feature`).\n7. Open a pull request.\n\nPlease always include appropriate tests when making implementation changes.\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "touchdesigner",
        "multimodal",
        "interact",
        "mcp touchdesigner",
        "touchdesigner mcp",
        "touchdesigner projects"
      ],
      "category": "multimodal-input-processing"
    },
    "stabgan--openrouter-mcp-multimodal": {
      "owner": "stabgan",
      "name": "openrouter-mcp-multimodal",
      "url": "https://github.com/stabgan/openrouter-mcp-multimodal",
      "imageUrl": "/freedevtools/mcp/pfp/stabgan.webp",
      "description": "Combines text chat and image analysis capabilities to conduct multimodal conversations and handle custom queries seamlessly. Optimizes workflows with intelligent model selection and performance improvements.",
      "stars": 10,
      "forks": 4,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-05T07:28:32Z",
      "readme_content": "# OpenRouter MCP Multimodal Server\n\n[![Build Status](https://github.com/stabgan/openrouter-mcp-multimodal/actions/workflows/publish.yml/badge.svg)](https://github.com/stabgan/openrouter-mcp-multimodal/actions/workflows/publish.yml)\n[![npm version](https://img.shields.io/npm/v/@stabgan/openrouter-mcp-multimodal.svg)](https://www.npmjs.com/package/@stabgan/openrouter-mcp-multimodal)\n[![Docker Pulls](https://img.shields.io/docker/pulls/stabgandocker/openrouter-mcp-multimodal.svg)](https://hub.docker.com/r/stabgandocker/openrouter-mcp-multimodal)\n\nAn MCP (Model Context Protocol) server that provides chat and image analysis capabilities through OpenRouter.ai's diverse model ecosystem. This server combines text chat functionality with powerful image analysis capabilities.\n\n## Features\n\n- **Text Chat:**\n  - Direct access to all OpenRouter.ai chat models\n  - Support for simple text and multimodal conversations\n  - Configurable temperature and other parameters\n\n- **Image Analysis:**\n  - Analyze single images with custom questions\n  - Process multiple images simultaneously \n  - Automatic image resizing and optimization\n  - Support for various image sources (local files, URLs, data URLs)\n\n- **Model Selection:**\n  - Search and filter available models\n  - Validate model IDs\n  - Get detailed model information\n  - Support for default model configuration\n\n- **Performance Optimization:**\n  - Smart model information caching\n  - Exponential backoff for retries\n  - Automatic rate limit handling\n\n## What's New in 1.5.0\n\n- **Improved OS Compatibility:**\n  - Enhanced path handling for Windows, macOS, and Linux\n  - Better support for Windows-style paths with drive letters\n  - Normalized path processing for consistent behavior across platforms\n\n- **MCP Configuration Support:**\n  - Cursor MCP integration without requiring environment variables\n  - Direct configuration via MCP parameters\n  - Flexible API key and model specification options\n\n- **Robust Error Handling:**\n  - Improved fallback mechanisms for image processing\n  - Better error reporting with specific diagnostics\n  - Multiple backup strategies for file reading\n\n- **Image Processing Enhancements:**\n  - More reliable base64 encoding for all image types\n  - Fallback options when Sharp module is unavailable\n  - Better handling of large images with automatic optimization\n\n## Installation\n\n### Option 1: Install via npm\n\n```bash\nnpm install -g @stabgan/openrouter-mcp-multimodal\n```\n\n### Option 2: Run via Docker\n\n```bash\ndocker run -i -e OPENROUTER_API_KEY=your-api-key-here stabgandocker/openrouter-mcp-multimodal:latest\n```\n\n## Quick Start Configuration\n\n### Prerequisites\n\n1. Get your OpenRouter API key from [OpenRouter Keys](https://openrouter.ai/keys)\n2. Choose a default model (optional)\n\n### MCP Configuration Options\n\nAdd one of the following configurations to your MCP settings file (e.g., `cline_mcp_settings.json` or `claude_desktop_config.json`):\n\n#### Option 1: Using npx (Node.js)\n\n```json\n{\n  \"mcpServers\": {\n    \"openrouter\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@stabgan/openrouter-mcp-multimodal\"\n      ],\n      \"env\": {\n        \"OPENROUTER_API_KEY\": \"your-api-key-here\",\n        \"DEFAULT_MODEL\": \"qwen/qwen2.5-vl-32b-instruct:free\"\n      }\n    }\n  }\n}\n```\n\n#### Option 2: Using uv (Python Package Manager)\n\n```json\n{\n  \"mcpServers\": {\n    \"openrouter\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"-m\",\n        \"openrouter_mcp_multimodal\"\n      ],\n      \"env\": {\n        \"OPENROUTER_API_KEY\": \"your-api-key-here\",\n        \"DEFAULT_MODEL\": \"qwen/qwen2.5-vl-32b-instruct:free\"\n      }\n    }\n  }\n}\n```\n\n#### Option 3: Using Docker\n\n```json\n{\n  \"mcpServers\": {\n    \"openrouter\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\", \"OPENROUTER_API_KEY=your-api-key-here\",\n        \"-e\", \"DEFAULT_MODEL=qwen/qwen2.5-vl-32b-instruct:free\",\n        \"stabgandocker/openrouter-mcp-multimodal:latest\"\n      ]\n    }\n  }\n}\n```\n\n#### Option 4: Using Smithery (recommended)\n\n```json\n{\n  \"mcpServers\": {\n    \"openrouter\": {\n      \"command\": \"smithery\",\n      \"args\": [\n        \"run\",\n        \"stabgan/openrouter-mcp-multimodal\"\n      ],\n      \"env\": {\n        \"OPENROUTER_API_KEY\": \"your-api-key-here\",\n        \"DEFAULT_MODEL\": \"qwen/qwen2.5-vl-32b-instruct:free\"\n      }\n    }\n  }\n}\n```\n\n## Examples\n\nFor comprehensive examples of how to use this MCP server, check out the [examples directory](./examples/). We provide:\n\n- JavaScript examples for Node.js applications\n- Python examples with interactive chat capabilities\n- Code snippets for integrating with various applications\n\nEach example comes with clear documentation and step-by-step instructions.\n\n## Dependencies\n\nThis project uses the following key dependencies:\n\n- `@modelcontextprotocol/sdk`: ^1.8.0 - Latest MCP SDK for tool implementation\n- `openai`: ^4.89.1 - OpenAI-compatible API client for OpenRouter\n- `sharp`: ^0.33.5 - Fast image processing library\n- `axios`: ^1.8.4 - HTTP client for API requests\n- `node-fetch`: ^3.3.2 - Modern fetch implementation\n\nNode.js 18 or later is required. All dependencies are regularly updated to ensure compatibility and security.\n\n## Available Tools\n\n### mcp_openrouter_chat_completion\n\nSend text or multimodal messages to OpenRouter models:\n\n```javascript\nuse_mcp_tool({\n  server_name: \"openrouter\",\n  tool_name: \"mcp_openrouter_chat_completion\",\n  arguments: {\n    model: \"google/gemini-2.5-pro-exp-03-25:free\", // Optional if default is set\n    messages: [\n      {\n        role: \"system\",\n        content: \"You are a helpful assistant.\"\n      },\n      {\n        role: \"user\",\n        content: \"What is the capital of France?\"\n      }\n    ],\n    temperature: 0.7 // Optional, defaults to 1.0\n  }\n});\n```\n\nFor multimodal messages with images:\n\n```javascript\nuse_mcp_tool({\n  server_name: \"openrouter\",\n  tool_name: \"mcp_openrouter_chat_completion\",\n  arguments: {\n    model: \"anthropic/claude-3.5-sonnet\",\n    messages: [\n      {\n        role: \"user\",\n        content: [\n          {\n            type: \"text\",\n            text: \"What's in this image?\"\n          },\n          {\n            type: \"image_url\",\n            image_url: {\n              url: \"https://example.com/image.jpg\"\n            }\n          }\n        ]\n      }\n    ]\n  }\n});\n```",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "multimodal",
        "conversations",
        "chat",
        "multimodal conversations",
        "mcp multimodal",
        "multimodal input"
      ],
      "category": "multimodal-input-processing"
    },
    "zakahan--vedit-mcp": {
      "owner": "zakahan",
      "name": "vedit-mcp",
      "url": "https://github.com/zakahan/vedit-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/zakahan.webp",
      "description": "Enables video editing through natural language commands for basic editing operations. Integrates with projects to automate video processing tasks using ffmpeg.",
      "stars": 1,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-07-02T16:43:03Z",
      "readme_content": "## Vedit-MCP\nThis is an MCP service for `video editing`, which can achieve basic editing operations with just one sentence.\n\nEnglish | [中文](README_CN.md)\n## Quick Start\n\n### 1. Install Dependencies\n\n#### 1.1 Clone this project or directly download the zip package\n\n#### 1.2 Configure the Python environment\n\n1. It is recommended to use uv for installation\n```bash\ncd vedit-mcp\nuv pip install -r requirements.txt\n```\n2. Or install directly using pip\n```bash\npip install -r requirements.txt\n```\n\n#### 1.3 Configure ffmpeg\n\n`vedit-mcp.py` relies on `ffmpeg` for implementation. Therefore, please configure ffmpeg.\n\n```bash\n# For Mac\nbrew install ffmpeg\n# For Ubuntu\nsudo apt update\nsudo apt install ffmpeg\n``` \n\n### 2. Start the Service\n\n#### 2.1. It is recommended to use `google-adk` to build your own project\n\n- Please refer to [adk-sample](sample/adk_sample.py)\n\n##### Before executing this sample script\n\n1. Please ensure that the path format is at least as follows\n\n> - sample\n>     - kb\n>         - raw/test.mp4   // This is the original video you need to process\n>     - adk_sample.py\n> - vedit_mcp.py\n\n2. Please install the following two dependencies\n```python\n# # adk-sample pip install requirements\n# google-adk==0.3.0\n# litellm==1.67.2\n```\n3. Please set the api-key and api-base\n\nCurrently, this script uses the API of the [`Volcano Ark Platform`](https://www.volcengine.com/product/ark), and you can go there to configure it by yourself.\n\nAfter obtaining the API_KEY, please configure the API_KEY as an environment variable.\n\n```bash\nexport OPENAI_API_KEY=\"your-api-key\"\n```\n\n4. Execute the script\n\n```bash\ncd sample\npython adk_sample.py\n```\n\n5. End of execution\n\nAfter this script is executed correctly and ends, a video result file will be generated in kb/result, and a log file will be generated and the result will be output.\n\nIf you need secondary development, you can choose to add `vedit_mcp.py` to your project for use.\n\n#### 2.2 Or build using `cline`\n\n\nFirstly, please ensure that your Python environment and ffmpeg configuration are correct\nConfigure cline_mcp_settings. json as follows\n```json\n{\n  \"mcpServers\": {\n    \"vedit-mcp\": {\n      \"command\": \"python\",\n      \"args\": [\n        \"vedit_mcp.py\",\n        \"--kb_dir\",\n        \"your-kb-dir-here\"\n      ]\n    }\n  }\n}\n```\n\n#### 2.3. Execute using the stramlit web interface\n\nTo be supplemented \n\n\n### 3. precautions\n\n1. It is recommended to use the `thinking model` to handle this type of task. Currently, it seems that the `thinking model` performs better in handling this type of task? But no further testing has been conducted, it's just an intuitive feeling.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ffmpeg",
        "multimodal",
        "editing",
        "video editing",
        "automate video",
        "multimodal input"
      ],
      "category": "multimodal-input-processing"
    }
  }
}