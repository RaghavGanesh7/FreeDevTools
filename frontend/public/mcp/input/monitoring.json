{
  "category": "monitoring",
  "categoryDisplay": "Monitoring",
  "description": "Access and analyze application monitoring data. Enables AI models to review error reports and performance metrics.",
  "totalRepositories": 10,
  "repositories": {
    "MindscapeHQ--server-raygun": {
      "owner": "MindscapeHQ",
      "name": "server-raygun",
      "url": "https://github.com/MindscapeHQ/mcp-server-raygun",
      "imageUrl": "",
      "description": "Raygun API V3 integration for crash reporting and real user monitoring",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "monitoring",
        "raygun",
        "mindscapehq",
        "raygun api",
        "server raygun",
        "application monitoring"
      ],
      "category": "monitoring"
    },
    "edgedelta--edgedelta-mcp-server": {
      "owner": "edgedelta",
      "name": "edgedelta-mcp-server",
      "url": "https://github.com/edgedelta/edgedelta-mcp-server",
      "imageUrl": "",
      "description": "[grafana/mcp-grafana](https://github.com/grafana/mcp-grafana) 🎖️ 🐍 🏠 ☁️ - Search dashboards, investigate incidents and query datasources in your Grafana instance",
      "stars": 4,
      "forks": 4,
      "license": "MIT License",
      "language": "Go",
      "updated_at": "2025-10-03T14:11:38Z",
      "readme_content": "# Edge Delta MCP Server\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/edgedelta/edgedelta-mcp-server)](https://archestra.ai/mcp-catalog/edgedelta__edgedelta-mcp-server)\n\nThe **Edge Delta MCP Server** is a [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction)\nserver that provides seamless integration with Edge Delta APIs, enabling advanced\nautomation and interaction capabilities for developers and tools.\n\n## Use Cases\n\n- Extract and analyse observability data from Edge Delta.\n- Build AI‑powered tools and applications that interact with Edge Delta’s platform.\n\n## Prerequisites\n\n1. **Docker Engine ≥ 20.10** installed *and running*.\n2. **Docker Buildx plug‑in** available:\n   - **macOS / Windows** – included with Docker Desktop.\n   - **Debian / Ubuntu**\n     ```bash\n     sudo apt-get update && sudo apt-get install -y docker-buildx-plugin\n     ```\n   - **Fedora / RHEL / CentOS**\n     ```bash\n     sudo dnf install -y docker-buildx-plugin   # or yum install …\n     ```\n   - **Other distros (manual fallback)**\n     ```bash\n     mkdir -p ~/.docker/cli-plugins\n     curl -sSL \\\n       https://github.com/docker/buildx/releases/latest/download/buildx-$(uname -s | tr '[:upper:]' '[:lower:]')-amd64 \\\n       -o ~/.docker/cli-plugins/docker-buildx\n     chmod +x ~/.docker/cli-plugins/docker-buildx\n     ```\n3. An **Edge Delta API token** with the required scope – [create one here](https://docs.edgedelta.com/api-tokens/).\n4. Your **Edge Delta organisation ID** – [find it here](https://docs.edgedelta.com/my-organization/).\n\n## Build (container image)\n\nFirst‑time setup (creates a multi‑platform builder and boots it):\n\n```bash\ndocker buildx create --name edgedelta-builder --use\ndocker buildx inspect --bootstrap\n```\n\nBuild the image and load it into the local Docker daemon:\n\n```bash\ndocker buildx build --load -t mcp/edgedelta .\n```\n\n> ℹ️  The `--load` flag streams the image back to your local Docker engine so you can\n> run it directly with `docker run mcp/edgedelta …`.\n\n## Installation\n\n### Usage with Cursor\n\n```json\n{\n  \"mcpServers\": {\n    \"edgedelta\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e ED_ORG_ID\",\n        \"-e ED_API_TOKEN\",\n        \"ghcr.io/edgedelta/edgedelta-mcp-server:latest\"\n      ],\n      \"env\": {\n        \"ED_API_TOKEN\": \"<YOUR_TOKEN>\",\n        \"ED_ORG_ID\": \"<YOUR_ORG_ID>\"\n      }\n    }\n  }\n}\n```\n\n## Library Usage\n\nThe exported Go API of this module is **experimental** and may change without notice.\nIf you rely on it in production, please open an issue describing your use case so we\ncan stabilise the relevant surface.\n\n## License\n\nLicensed under the terms of the **MIT** licence. See [LICENSE](./LICENSE) for full details.\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "monitoring",
        "grafana",
        "edgedelta",
        "datasources grafana",
        "server grafana",
        "application monitoring"
      ],
      "category": "monitoring"
    },
    "getsentry--sentry-mcp": {
      "owner": "getsentry",
      "name": "sentry-mcp",
      "url": "https://github.com/getsentry/sentry-mcp",
      "imageUrl": "",
      "description": "Sentry.io integration for error tracking and performance monitoring",
      "stars": 369,
      "forks": 44,
      "license": "Other",
      "language": "TypeScript",
      "updated_at": "2025-10-04T02:31:09Z",
      "readme_content": "# sentry-mcp\n\n[![codecov](https://codecov.io/gh/getsentry/sentry-mcp/graph/badge.svg?token=khVKvJP5Ig)](https://codecov.io/gh/getsentry/sentry-mcp)\n\nSentry's MCP service is primarily designed for human-in-the-loop coding agents. Our tool selection and priorities are focused on developer workflows and debugging use cases, rather than providing a general-purpose MCP server for all Sentry functionality.\n\nThis remote MCP server acts as middleware to the upstream Sentry API, optimized for coding assistants like Cursor, Claude Code, and similar development tools. It's based on [Cloudflare's work towards remote MCPs](https://blog.cloudflare.com/remote-model-context-protocol-servers-mcp/).\n\n## Getting Started\n\nYou'll find everything you need to know by visiting the deployed service in production:\n\n<https://mcp.sentry.dev>\n\nIf you're looking to contribute, learn how it works, or to run this for self-hosted Sentry, continue below.\n\n### Stdio vs Remote\n\nWhile this repository is focused on acting as an MCP service, we also support a `stdio` transport. This is still a work in progress, but is the easiest way to adapt run the MCP against a self-hosted Sentry install.\n\n**Note:** The AI-powered search tools (`search_events` and `search_issues`) require an OpenAI API key. These tools use natural language processing to translate queries into Sentry's query syntax. Without the API key, these specific tools will be unavailable, but all other tools will function normally.\n\nTo utilize the `stdio` transport, you'll need to create an User Auth Token in Sentry with the necessary scopes. As of writing this is:\n\n```\norg:read\nproject:read\nproject:write\nteam:read\nteam:write\nevent:write\n```\n\nLaunch the transport:\n\n```shell\nnpx @sentry/mcp-server@latest --access-token=sentry-user-token\n```\n\nNeed to connect to a self-hosted deployment? Add <code>--host</code> (hostname\nonly, e.g. <code>--host=sentry.example.com</code>) when you run the command.\n\nNote: You can also use environment variables:\n\n```shell\nSENTRY_ACCESS_TOKEN=\n# Optional overrides for self-hosted deployments\nSENTRY_HOST=\nOPENAI_API_KEY=  # Required for AI-powered search tools (search_events, search_issues)\n```\n\nIf you leave the host variable unset, the CLI automatically targets the Sentry\nSaaS service. Only set the override when you operate self-hosted Sentry.\n\n### MCP Inspector\n\nMCP includes an [Inspector](https://modelcontextprotocol.io/docs/tools/inspector), to easily test the service:\n\n```shell\npnpm inspector\n```\n\nEnter the MCP server URL (<http://localhost:5173>) and hit connect. This should trigger the authentication flow for you.\n\nNote: If you have issues with your OAuth flow when accessing the inspector on `127.0.0.1`, try using `localhost` instead by visiting `http://localhost:6274`.\n\n## Local Development\n\nTo contribute changes, you'll need to set up your local environment:\n\n1. **Set up environment files:**\n\n   ```shell\n   make setup-env  # Creates both .env files from examples\n   ```\n\n2. **Create an OAuth App in Sentry** (Settings => API => [Applications](https://sentry.io/settings/account/api/applications/)):\n\n   - Homepage URL: `http://localhost:5173`\n   - Authorized Redirect URIs: `http://localhost:5173/oauth/callback`\n   - Note your Client ID and generate a Client secret\n\n3. **Configure your credentials:**\n\n   - Edit `.env` in the root directory and add your `OPENAI_API_KEY`\n   - Edit `packages/mcp-cloudflare/.env` and add:\n     - `SENTRY_CLIENT_ID=your_development_sentry_client_id`\n     - `SENTRY_CLIENT_SECRET=your_development_sentry_client_secret`\n     - `COOKIE_SECRET=my-super-secret-cookie`\n\n4. **Start the development server:**\n\n   ```shell\n   pnpm dev\n   ```\n\n### Verify\n\nRun the server locally to make it available at `http://localhost:5173`\n\n```shell\npnpm dev\n```\n\nTo test the local server, enter `http://localhost:5173/mcp` into Inspector and hit connect. Once you follow the prompts, you'll be able to \"List Tools\".\n\n### Tests\n\nThere are two test suites included: basic unit tests, and some evaluations.\n\nUnit tests can be run using:\n\n```shell\npnpm test\n```\n\nEvals will require a `.env` file in the project root with some config:\n\n```shell\n# .env (in project root)\nOPENAI_API_KEY=  # Also required for AI-powered search tools in production\n```\n\nNote: The root `.env` file provides defaults for all packages. Individual packages can have their own `.env` files to override these defaults during development.\n\nOnce that's done you can run them using:\n\n```shell\npnpm eval\n```\n\n## Development Notes\n\n### Automated Code Review\n\nThis repository uses automated code review tools (like Cursor BugBot) to help identify potential issues in pull requests. These tools provide helpful feedback and suggestions, but **we do not recommend making these checks required** as the accuracy is still evolving and can produce false positives.\n\nThe automated reviews should be treated as:\n\n- ✅ **Helpful suggestions** to consider during code review\n- ✅ **Starting points** for discussion and improvement\n- ❌ **Not blocking requirements** for merging PRs\n- ❌ **Not replacements** for human code review\n\nWhen addressing automated feedback, focus on the underlying concerns rather than strictly following every suggestion.\n\n### Contributor Documentation\n\nLooking to contribute or explore the full documentation map? See `CLAUDE.md` (also available as `AGENTS.md`) for contributor workflows and the complete docs index. The `docs/` folder contains the per-topic guides and tool-integrated `.mdc` files.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "monitoring",
        "io",
        "ai",
        "application monitoring",
        "performance monitoring",
        "error tracking"
      ],
      "category": "monitoring"
    },
    "hyperb1iss--lucidity-mcp": {
      "owner": "hyperb1iss",
      "name": "lucidity-mcp",
      "url": "https://github.com/hyperb1iss/lucidity-mcp",
      "imageUrl": "",
      "description": "Enhance AI-generated code quality through intelligent, prompt-based analysis across 10 critical dimensions from complexity to security vulnerabilities",
      "stars": 67,
      "forks": 20,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-25T14:26:10Z",
      "readme_content": "# ✨ Lucidity MCP 🔍\n\n<div align=\"center\">\n\n[![Python 3.13+](https://img.shields.io/badge/python-3.13+-9D00FF.svg?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/downloads/)\n[![License](https://img.shields.io/badge/license-Apache_2.0-FF00FF.svg?style=for-the-badge)](LICENSE)\n[![Status](https://img.shields.io/badge/status-active_development-39FF14.svg?style=for-the-badge)](docs/plan.md)\n[![Code Style](https://img.shields.io/badge/code_style-ruff-00FFFF.svg?style=for-the-badge)](https://github.com/astral-sh/ruff)\n[![Type Check](https://img.shields.io/badge/type_check-mypy-FFBF00.svg?style=for-the-badge)](https://mypy.readthedocs.io/en/stable/)\n\n**Clarity in Code, Confidence in Creation**\n\n</div>\n\nLucidity is a Model Context Protocol (MCP) server designed to enhance the quality of AI-generated code through intelligent, prompt-based analysis. By providing structured guidance to AI coding assistants, Lucidity helps identify and address common quality issues, resulting in cleaner, more maintainable, and more robust code.\n\nBefore you commit, just ask Lucidity to analyze the changes instead of vibe-coding yourself into a nightmare hellscape! 😱 💥 🚫\n\n## 💫 Features\n\n- 🔮 **Comprehensive Issue Detection** - Covers 10 critical quality dimensions from complexity to security vulnerabilities\n- 🔄 **Contextual Analysis** - Compares changes against original code to identify unintended modifications\n- 🌐 **Language Agnostic** - Works with any programming language the AI assistant understands\n- 🎯 **Focused Analysis** - Option to target specific issue types based on project needs\n- 📝 **Structured Outputs** - Guides AI to provide actionable feedback with clear recommendations\n- 🤖 **MCP Integration** - Seamless integration with Claude and other MCP-compatible AI assistants\n- 🪶 **Lightweight Implementation** - Simple server design with minimal dependencies\n- 🧩 **Extensible Framework** - Easy to add new issue types or refine analysis criteria\n- 🔀 **Flexible Transport** - Supports both stdio for terminal-based interaction and SSE for network-based communication\n- 🔄 **Git-Aware Analysis** - Analyzes changes directly from git diff, making it ideal for pre-commit reviews\n\n## 🚀 Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/hyperbliss/lucidity-mcp.git\ncd lucidity-mcp\n\n# Set up a virtual environment with UV\nuv venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Install dependencies with UV\nuv sync\n```\n\n## 📋 Prerequisites\n\n- Python 3.13 or higher\n- Git (for analyzing code changes)\n- UV package manager (recommended for dependency management)\n\n## 🔮 Quick Start\n\n### Run the Lucidity server\n\n```bash\n# Start with stdio transport (for terminal use)\nlucidity-mcp\n\n# Start with SSE transport (for network use)\nlucidity-mcp --transport sse --host 127.0.0.1 --port 6969\n\n# Run with debug logging\nlucidity-mcp --debug\n\n# Run with file logging\nlucidity-mcp --log-file lucidity.log\n```\n\n### Using with AI Assistants\n\n1. Start Lucidity in SSE mode:\n\n   ```bash\n   lucidity-mcp --transport sse\n   ```\n\n2. Connect your AI assistant using the MCP protocol URI:\n\n   ```\n   sse://localhost:6969/sse\n   ```\n\n3. The AI can now invoke the `analyze_changes` tool to get code quality feedback!\n\n## 🧠 Analysis Dimensions\n\nLucidity analyzes code across 10 critical quality dimensions:\n\n1. **Unnecessary Complexity** - Identifies overly complex algorithms, excessive abstractions, and convoluted logic\n2. **Poor Abstractions** - Detects leaky or inappropriate abstractions and unclear separation of concerns\n3. **Unintended Code Deletion** - Catches accidental removal of critical functionality or validation\n4. **Hallucinated Components** - Finds references to non-existent functions, classes, or APIs\n5. **Style Inconsistencies** - Spots deviations from project coding standards and conventions\n6. **Security Vulnerabilities** - Identifies potential security issues in code changes\n7. **Performance Issues** - Detects inefficient algorithms or operations that could impact performance\n8. **Code Duplication** - Finds repeated logic or functionality that should be refactored\n9. **Incomplete Error Handling** - Spots missing or inadequate exception handling\n10. **Test Coverage Gaps** - Identifies missing tests for critical functionality\n\n## 📊 Example AI Assistant Queries\n\nWith an AI assistant connected to Lucidity, try these queries:\n\n- \"Analyze the code quality in my latest git changes\"\n- \"Check for security vulnerabilities in my JavaScript changes\"\n- \"Make sure my Python code follows best practices\"\n- \"Identify any performance issues in my recent code changes\"\n- \"Are there any unintended side effects in my recent refactoring?\"\n- \"Help me improve the abstractions in my code\"\n- \"Check if I've accidentally removed any important validation\"\n- \"Find any hallucinated API calls in my latest commit\"\n- \"Is my error handling complete and robust?\"\n- \"Are there any test coverage gaps in my new feature?\"\n\n## 🛠️ Available MCP Tools\n\n### Tools\n\n- `analyze_changes` - Prepares git changes for analysis through MCP\n  - Parameters:\n    - `workspace_root`: The root directory of the workspace/git repository\n    - `path`: Optional specific file path to analyze\n\n## 💻 Development\n\nLucidity uses UV for dependency management and development workflows. UV is a fast, reliable Python package manager and resolver.\n\n```bash\n# Update dependencies\nuv sync\n\n# Run tests\npytest\n\n# Run linting\nruff check .\n\n# Run type checking\nmypy .\n```\n\n## 🔧 Logging Behavior\n\nLucidity handles logging differently depending on the transport:\n\n- **SSE transport**: Full console logging is enabled\n- **Stdio transport with --log-file**: All logs go to the file, console is disabled\n- **Stdio transport without --log-file**: Only warnings and errors go to stderr, info logs are disabled\n\nThis ensures that stdio communication isn't broken by logs appearing on stdout.\n\n## 🎛️ Command-line Options\n\n```\nusage: lucidity-mcp [-h] [--debug] [--host HOST] [--port PORT] [--transport {stdio,sse}]\n                [--log-level {DEBUG,INFO,WARNING,ERROR,CRITICAL}] [--verbose]\n                [--log-file LOG_FILE]\n\noptions:\n  -h, --help            show this help message and exit\n  --debug               Enable debug logging\n  --host HOST           Host to bind the server to (use 0.0.0.0 for all interfaces)\n  --port PORT           Port to listen on for network connections\n  --transport {stdio,sse}\n                        Transport type to use (stdio for terminal, sse for network)\n  --log-level {DEBUG,INFO,WARNING,ERROR,CRITICAL}\n                        Set the logging level\n  --verbose             Enable verbose logging for HTTP requests\n  --log-file LOG_FILE   Path to log file (required for stdio transport if logs enabled)\n```\n\n## 🤝 Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Set up your development environment with UV\n4. Make your changes\n5. Run tests and linting\n6. Commit your changes (`git commit -m 'Add some amazing feature'`)\n7. Push to the branch (`git push origin feature/amazing-feature`)\n8. Open a Pull Request\n\n## 📝 License\n\nThis project is licensed under the Apache License 2.0 - see the LICENSE file for details.\n\n---\n\n<div align=\"center\">\n\nCreated by [Stefanie Jane 🌠](https://github.com/hyperb1iss)\n\nIf you find Lucidity useful, [buy me a Monster Ultra Violet ⚡️](https://ko-fi.com/hyperb1iss)\n\n</div>\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "hyperb1iss",
        "ai",
        "vulnerabilities",
        "hyperb1iss lucidity",
        "application monitoring",
        "ai generated"
      ],
      "category": "monitoring"
    },
    "inspektor-gadget--ig-mcp-server": {
      "owner": "inspektor-gadget",
      "name": "ig-mcp-server",
      "url": "https://github.com/inspektor-gadget/ig-mcp-server",
      "imageUrl": "",
      "description": "Debug your Container and Kubernetes workloads with an AI interface powered by eBPF.",
      "stars": 15,
      "forks": 1,
      "license": "Apache License 2.0",
      "language": "Go",
      "updated_at": "2025-10-02T09:49:39Z",
      "readme_content": "[![GitHub Release](https://img.shields.io/github/v/release/inspektor-gadget/ig-mcp-server)](https://github.com/inspektor-gadget/ig-mcp-server/releases)\n[![License](https://img.shields.io/github/license/inspektor-gadget/ig-mcp-server)](LICENSE)\n[![Slack](https://img.shields.io/badge/slack-%23inspektor--gadget-brightgreen)](https://kubernetes.slack.com/channels/inspektor-gadget)\n[![Go Report Card](https://goreportcard.com/badge/github.com/inspektor-gadget/ig-mcp-server)](https://goreportcard.com/report/github.com/inspektor-gadget/ig-mcp-server)\n[![Examples](https://img.shields.io/badge/examples-view-orange)](examples/README.md)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/inspektor-gadget/ig-mcp-server)\n\n# Inspektor Gadget MCP Server\n\nAI-powered debugging and inspection for Kubernetes clusters using Inspektor Gadget.\n\nhttps://github.com/user-attachments/assets/86367982-c0aa-455c-ac9e-ca43348899df\n\n## Features\n\n- AI-powered interface for Kubernetes troubleshooting and monitoring\n- One-click Inspektor Gadget deployment and removal\n- Intelligent output summarization and analysis\n- Automatic gadget discovery from Artifact Hub\n\n## Quick Start\n\n1. Ensure you have Docker and a valid `kubeconfig` file\n2. Configure the MCP server in VS Code (see [INSTALL.md](INSTALL.md))\n3. Start using AI commands in VS Code Copilot Chat\n4. Try: \"Show me DNS traffic\" or \"Deploy Inspektor Gadget\"\n5. Head to [examples](examples/README.md) for detailed examples.\n\n## Installation\n\nYou can use the following commands to quickly configure the Inspektor Gadget MCP server using either Docker or a binary in your VS Code settings.\n\n### Docker\n\n<summary>\n  <details>\n    <summary>Install Inspektor Gadget MCP Server - Artifact Hub Discovery</summary>\n    <pre><code>code --add-mcp '{\n  \"name\": \"inspektor-gadget\",\n  \"command\": \"docker\",\n  \"args\": [\n    \"run\",\n    \"-i\",\n    \"--rm\",\n    \"--volume\",\n    \"ig-mcp-cache:/root/.cache/ig-mcp-server\",\n    \"--mount\",\n    \"type=bind,src=${env:HOME}/.kube/config,dst=/kubeconfig\",\n    \"ghcr.io/inspektor-gadget/ig-mcp-server:latest\",\n    \"-gadget-discoverer=artifacthub\"\n  ]\n}'</code></pre>\n  </details>\n<details>\n    <summary>Install Inspektor Gadget MCP Server - Specific Gadgets</summary>\n    <pre><code>code --add-mcp '{\n  \"name\": \"inspektor-gadget\",\n  \"command\": \"docker\",\n  \"args\": [\n    \"run\",\n    \"-i\",\n    \"--rm\",\n    \"--volume\",\n    \"ig-mcp-cache:/root/.cache/ig-mcp-server\",\n    \"--mount\",\n    \"type=bind,src=${env:HOME}/.kube/config,dst=/kubeconfig\",\n    \"ghcr.io/inspektor-gadget/ig-mcp-server:latest\",\n    \"-gadget-images=trace_dns:latest,trace_tcp:latest,snapshot_process:latest,snapshot_socket:latest\"\n  ]\n}'</code></pre>\n  </details>\n</summary>\n\n### Binary\n\nYou can head to the [Releases](https://github.com/inspektor-gadget/ig-mcp-server/releases) page and download the latest binary for your platform:\n\n<summary>\n  <details>\n    <summary>Linux</summary>\n    <pre><code>MCP_VERSION=$(curl -s https://api.github.com/repos/inspektor-gadget/ig-mcp-server/releases/latest | jq -r .tag_name)\nMCP_ARCH=amd64\ncurl -sL https://github.com/inspektor-gadget/ig-mcp-server/releases/download/${MCP_VERSION}/ig-mcp-server-linux-${MCP_ARCH}.tar.gz | sudo tar -C /usr/local/bin -xzf - ig-mcp-server\n</code></pre>\n  </details>\n  <details>\n    <summary>macOS</summary>\n    <pre><code>MCP_VERSION=$(curl -s https://api.github.com/repos/inspektor-gadget/ig-mcp-server/releases/latest | jq -r .tag_name)\nMCP_ARCH=arm64\ncurl -sL https://github.com/inspektor-gadget/ig-mcp-server/releases/download/${MCP_VERSION}/ig-mcp-server-darwin-${MCP_ARCH}.tar.gz | sudo tar -C /usr/local/bin -xzf - ig-mcp-server\n</code></pre>\n  </details>\n  <details>\n    <summary>Windows</summary>\n    <pre><code>$MCP_VERSION = (curl.exe -s https://api.github.com/repos/inspektor-gadget/ig-mcp-server/releases/latest | ConvertFrom-Json).tag_name\n$MCP_ARCH = \"amd64\"\ncurl.exe -L \"https://github.com/inspektor-gadget/ig-mcp-server/releases/download/$MCP_VERSION/ig-mcp-server-windows-$MCP_ARCH.tar.gz\" -o \"ig-mcp-server.tar.gz\"\n$destPath = \"C:\\Program Files\\ig-mcp-server\"\nif (-Not (Test-Path $destPath -PathType Container)) { mkdir $destPath}\ntar.exe -xzf \"ig-mcp-server.tar.gz\" -C \"$destPath\"\nrm ig-mcp-server.tar.gz\nWrite-Host \"✅ Extracted to $destPath\"\nWrite-Host \"👉 Please add '$destPath' to your PATH environment variable manually.\"\n</code></pre>\n  </details>\n</summary>\n\nAfter downloading, you can run the following command to add it to your VS Code MCP configuration.\n\n<summary>\n  <details>\n    <summary>Install Inspektor Gadget MCP Server - Artifact Hub Discovery</summary>\n    <pre><code>code --add-mcp '{\n  \"name\": \"inspektor-gadget\",\n  \"command\": \"ig-mcp-server\",\n  \"args\": [\n    \"-gadget-discoverer=artifacthub\"\n  ]\n}'</code></pre>\n  </details>\n<details>\n    <summary>Install Inspektor Gadget MCP Server - Specific Gadgets</summary>\n    <pre><code>code --add-mcp '{\n    \"name\": \"inspektor-gadget\",\n    \"command\": \"ig-mcp-server\",\n    \"args\": [\n      \"-gadget-images=trace_dns:latest,trace_tcp:latest\"\n    ]\n}'</code></pre>\n    </details>\n</summary>\n\n## Available Tools\n\n### Inspektor Gadget Lifecycle\n\n- **ig_deploy**: Manage deployment of Inspektor Gadget on target Kubernetes cluster\n\n### Gadget Lifecycle\n\n- **ig_gadgets**: Manage the lifecycle of running gadgets (stop/list/get-results)\n\n### Dynamic Tools\n\nEach gadget is registered as its own MCP tool (e.g., `gadget_trace_dns`, `gadget_trace_tcp`, etc.) and supports running gadgets in foreground mode, which is useful for debugging/development and also in background mode for observability.\n\nAlso, You can control which gadgets are available by configuring the MCP server with the `-gadget-discoverer` or `-gadget-images` options, allowing you to limit the tools to only those you need.\n\n#### Gadget Discovery\n\nGadget discovery allows controlling which gadgets are available for use. You can choose between two methods:\n\n- **Automatic**: Uses Artifact Hub (`-gadget-discoverer=artifacthub`)\n- **Manual**: Specify gadgets directly (`-gadget-images=trace_dns:latest`)\n\n![Gadget Tools](media/gadget-tools.png)\n\nSee [INSTALL.md](INSTALL.md) for configuration options.\n\n## Security Notes\n\n- Requires read-only access to your kubeconfig file\n- Needs network access for Artifact Hub discovery\n- See [security guide](SECURITY.md) for setting up server with minimal permissions\n\n## Resources\n\n- 📖 [Documentation](https://inspektor-gadget.io/docs/)\n- 🔍 [Examples](examples/README.md)\n- 🐛 [Issues](https://github.com/inspektor-gadget/ig-mcp-server/issues)\n- 💬 [Slack](https://kubernetes.slack.com/channels/inspektor-gadget)\n- 🌐 [Website](https://inspektor-gadget.io/)\n- 📋 [Troubleshooting](TROUBLESHOOTING.md)\n- 🔒 [Security Guide](SECURITY.md)\n\n## Related Projects\n\n- [Inspektor Gadget](https://github.com/inspektor-gadget/inspektor-gadget) - Kubernetes debugging tool\n- [MCP Specification](https://spec.modelcontextprotocol.io/) - Model Context Protocol\n\n## License\n\nApache License 2.0 - see [LICENSE](LICENSE) for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "kubernetes",
        "monitoring",
        "ai interface",
        "application monitoring",
        "container kubernetes"
      ],
      "category": "monitoring"
    },
    "inventer-dev--mcp-internet-speed-test": {
      "owner": "inventer-dev",
      "name": "mcp-internet-speed-test",
      "url": "https://github.com/inventer-dev/mcp-internet-speed-test",
      "imageUrl": "",
      "description": "Internet speed testing with network performance metrics including download/upload speed, latency, jitter analysis, and CDN server detection with geographic mapping",
      "stars": 10,
      "forks": 6,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-28T17:18:29Z",
      "readme_content": "[![smithery badge](https://smithery.ai/badge/@inventer-dev/mcp-internet-speed-test)](https://smithery.ai/server/@inventer-dev/mcp-internet-speed-test)\n\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/inventer-dev-mcp-internet-speed-test-badge.png)](https://mseep.ai/app/inventer-dev-mcp-internet-speed-test)\n\n<a href=\"https://glama.ai/mcp/servers/@inventer-dev/mcp-internet-speed-test\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@inventer-dev/mcp-internet-speed-test/badge\" alt=\"mcp-internet-speed-test MCP server\" />\n</a>\n\n# MCP Internet Speed Test\n\nAn implementation of a Model Context Protocol (MCP) for internet speed testing. It allows AI models and agents to measure, analyze, and report network performance metrics through a standardized interface.\n\n**📦 Available on PyPI:** https://pypi.org/project/mcp-internet-speed-test/\n\n**🚀 Quick Start:**\n```bash\npip install mcp-internet-speed-test\nmcp-internet-speed-test\n```\n\n## What is MCP?\n\nThe Model Context Protocol (MCP) provides a standardized way for Large Language Models (LLMs) to interact with external tools and data sources. Think of it as the \"USB-C for AI applications\" - a common interface that allows AI systems to access real-world capabilities and information.\n\n## Features\n\n- **Smart Incremental Testing**: Uses SpeedOf.Me methodology with 8-second threshold for optimal accuracy\n- **Download Speed Testing**: Measures bandwidth using files from 128KB to 100MB from GitHub repository\n- **Upload Speed Testing**: Tests upload bandwidth using generated data from 128KB to 100MB\n- **Latency Testing**: Measures network latency with detailed server location information\n- **Jitter Analysis**: Calculates network stability using multiple latency samples (default: 5)\n- **Multi-CDN Support**: Detects and provides info for Fastly, Cloudflare, and AWS CloudFront\n- **Geographic Location**: Maps POP codes to physical locations (50+ locations worldwide)\n- **Cache Analysis**: Detects HIT/MISS status and cache headers\n- **Server Metadata**: Extracts detailed CDN headers including `x-served-by`, `via`, `x-cache`\n- **Comprehensive Testing**: Single function to run all tests with complete metrics\n\n## Installation\n\n### Prerequisites\n\n- Python 3.12 or higher (required for async support)\n- pip or [uv](https://github.com/astral-sh/uv) package manager\n\n### Option 1: Install from PyPI with pip (Recommended)\n\n```bash\n# Install the package globally\npip install mcp-internet-speed-test\n\n# Run the MCP server\nmcp-internet-speed-test\n```\n\n### Option 2: Install from PyPI with uv\n\n```bash\n# Install the package globally\nuv add mcp-internet-speed-test\n\n# Or run directly without installing\nuvx mcp-internet-speed-test\n```\n\n### Option 3: Using docker\n\n```bash\n# Build the Docker image\ndocker build -t mcp-internet-speed-test .\n\n# Run the MCP server in a Docker container\ndocker run -it --rm -v $(pwd):/app -w /app mcp-internet-speed-test\n```\n\n### Option 4: Development/Local Installation\n\nIf you want to contribute or modify the code:\n\n```bash\n# Clone the repository\ngit clone https://github.com/inventer-dev/mcp-internet-speed-test.git\ncd mcp-internet-speed-test\n\n# Install in development mode\npip install -e .\n\n# Or using uv\nuv sync\nuv run python -m mcp_internet_speed_test.main\n```\n\n### Dependencies\n\nThe package automatically installs these dependencies:\n- `mcp[cli]>=1.6.0`: MCP server framework with CLI integration\n- `httpx>=0.27.0`: Async HTTP client for speed tests\n\n\n## Configuration\n\nTo use this MCP server with Claude Desktop or other MCP clients, add it to your MCP configuration file.\n\n### Claude Desktop Configuration\n\nEdit your Claude Desktop MCP configuration file:\n\n#### Option 1: Using pip installed package (Recommended)\n\n```json\n{\n    \"mcpServers\": {\n        \"mcp-internet-speed-test\": {\n            \"command\": \"mcp-internet-speed-test\"\n        }\n    }\n}\n```\n\n#### Option 2: Using uvx\n\n```json\n{\n    \"mcpServers\": {\n        \"mcp-internet-speed-test\": {\n            \"command\": \"uvx\",\n            \"args\": [\"mcp-internet-speed-test\"]\n        }\n    }\n}\n```\n\n## API Tools\n\nThe MCP Internet Speed Test provides the following tools:\n\n### Testing Functions\n1. `measure_download_speed`: Measures download bandwidth (in Mbps) with server location info\n2. `measure_upload_speed`: Measures upload bandwidth (in Mbps) with server location info\n3. `measure_latency`: Measures network latency (in ms) with server location info\n4. `measure_jitter`: Measures network jitter by analyzing latency variations with server info\n5. `get_server_info`: Get detailed CDN server information for any URL without running speed tests\n6. `run_complete_test`: Comprehensive test with all metrics and server metadata\n\n## CDN Server Detection\n\nThis speed test now provides detailed information about the CDN servers serving your tests:\n\n### What You Get\n- **CDN Provider**: Identifies if you're connecting to Fastly, Cloudflare, or Amazon CloudFront\n- **Geographic Location**: Shows the physical location of the server (e.g., \"Mexico City, Mexico\")\n- **POP Code**: Three-letter code identifying the Point of Presence (e.g., \"MEX\", \"QRO\", \"DFW\")\n- **Cache Status**: Whether content is served from cache (HIT) or fetched from origin (MISS)\n- **Server Headers**: Full HTTP headers including `x-served-by`, `via`, and `x-cache`\n\n### Technical Implementation\n\n#### Smart Testing Methodology\n- **Incremental Approach**: Starts with small files (128KB) and progressively increases\n- **Time-Based Optimization**: Uses 8-second base threshold + 4-second additional buffer\n- **Accuracy Focus**: Selects optimal file size that provides reliable measurements\n- **Multi-Provider Support**: Tests against geographically distributed endpoints\n\n#### CDN Detection Capabilities\n- **Fastly**: Detects POP codes and maps to 50+ global locations\n- **Cloudflare**: Identifies data centers and geographic regions\n- **AWS CloudFront**: Recognizes edge locations across continents\n- **Header Analysis**: Parses `x-served-by`, `via`, `x-cache`, and custom CDN headers\n\n### Why This Matters\n- **Network Diagnostics**: Understand which server is actually serving your tests\n- **Performance Analysis**: Correlate speed results with server proximity\n- **CDN Optimization**: Identify if your ISP's routing is optimal\n- **Geographic Awareness**: Know if tests are running from your expected region\n- **Troubleshooting**: Identify routing issues and CDN misconfigurations\n\n### Example Server Info Output\n```json\n{\n  \"cdn_provider\": \"Fastly\",\n  \"pop_code\": \"MEX\",\n  \"pop_location\": \"Mexico City, Mexico\",\n  \"served_by\": \"cache-mex4329-MEX\",\n  \"cache_status\": \"HIT\",\n  \"x_cache\": \"HIT, HIT\"\n}\n```\n\n### Technical Configuration\n\n#### Default Test Files Repository\n```\nGitHub Repository: inventer-dev/speed-test-files\nBranch: main\nFile Sizes: 128KB, 256KB, 512KB, 1MB, 2MB, 5MB, 10MB, 20MB, 40MB, 50MB, 100MB\n```\n\n#### Upload Endpoints Priority\n1. **Cloudflare Workers** (httpi.dev) - Global distribution, highest priority\n2. **HTTPBin** (httpbin.org) - AWS-based, secondary endpoint\n\n#### Supported CDN Locations (150+ POPs)\n\n**Fastly POPs**: MEX, QRO, DFW, LAX, NYC, MIA, LHR, FRA, AMS, CDG, NRT, SIN, SYD, GRU, SCL, BOG, MAD, MIL...\n\n**Cloudflare Centers**: DFW, LAX, SJC, SEA, ORD, MCI, IAD, ATL, MIA, YYZ, LHR, FRA, AMS, CDG, ARN, STO...\n\n**AWS CloudFront**: ATL, BOS, ORD, CMH, DFW, DEN, IAD, LAX, MIA, MSP, JFK, SEA, SJC, AMS, ATH, TXL...\n\n#### Performance Thresholds\n- **Base Test Duration**: 8.0 seconds\n- **Additional Buffer**: 4.0 seconds\n- **Maximum File Size**: Configurable (default: 100MB)\n- **Jitter Samples**: 5 measurements (configurable)\n\n## Troubleshooting\n\n### Common Issues\n\n#### MCP Server Connection\n1. **Path Configuration**: Ensure absolute path is used in MCP configuration\n2. **Directory Permissions**: Verify read/execute permissions for the project directory\n3. **Python Version**: Requires Python 3.12+ with async support\n4. **Dependencies**: Install `fastmcp` and `httpx` packages\n\n#### Speed Test Issues\n1. **GitHub Repository Access**: Ensure `inventer-dev/speed-test-files` is accessible\n2. **Firewall/Proxy**: Check if corporate firewalls block test endpoints\n3. **CDN Routing**: Some ISPs may route differently to CDNs\n4. **Network Stability**: Jitter tests require stable connections\n\n#### Performance Considerations\n- **File Size Limits**: Large files (>50MB) may timeout on slow connections\n- **Upload Endpoints**: If primary endpoint fails, fallback is automatic\n- **Geographic Accuracy**: POP detection depends on CDN header consistency\n\n## Development\n\n### Project Structure\n```\nmcp-internet-speed-test/\n├── mcp_internet_speed_test/  # Main package directory\n│   ├── __init__.py      # Package initialization\n│   └── main.py          # MCP server implementation\n├── README.md           # This documentation\n├── Dockerfile          # Container configuration\n└── pyproject.toml      # Python project configuration\n```\n\n### Key Components\n\n#### Configuration Constants\n- `GITHUB_RAW_URL`: Base URL for test files repository\n- `UPLOAD_ENDPOINTS`: Prioritized list of upload test endpoints\n- `SIZE_PROGRESSION`: Ordered list of file sizes for incremental testing\n- `*_POP_LOCATIONS`: Mappings of CDN codes to geographic locations\n\n#### Core Functions\n- `extract_server_info()`: Parses HTTP headers to identify CDN providers\n- `measure_*()`: Individual test functions for different metrics\n- `run_complete_test()`: Orchestrates comprehensive testing suite\n\n### Configuration Customization\n\nYou can customize the following in `mcp_internet_speed_test/main.py` if you clone the repository:\n```python\n# GitHub repository settings\nGITHUB_USERNAME = \"your-username\"\nGITHUB_REPO = \"your-speed-test-files\"\nGITHUB_BRANCH = \"main\"\n\n# Test duration thresholds\nBASE_TEST_DURATION = 8.0  # seconds\nADDITIONAL_TEST_DURATION = 4.0  # seconds\n\n# Default endpoints\nDEFAULT_UPLOAD_URL = \"your-upload-endpoint\"\nDEFAULT_LATENCY_URL = \"your-latency-endpoint\"\n```\n\n### Contributing\n\nThis is an experimental project and contributions are welcome:\n\n1. **Issues**: Report bugs or request features\n2. **Pull Requests**: Submit code improvements\n3. **Documentation**: Help improve this README\n4. **Testing**: Test with different network conditions and CDNs\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Acknowledgments\n\n- MCP Framework maintainers for standardizing AI tool interactions\n- The Model Context Protocol community for documentation and examples",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "monitoring",
        "latency",
        "ai",
        "test internet",
        "speed testing",
        "application monitoring"
      ],
      "category": "monitoring"
    },
    "mpeirone--zabbix-mcp-server": {
      "owner": "mpeirone",
      "name": "zabbix-mcp-server",
      "url": "https://github.com/mpeirone/zabbix-mcp-server",
      "imageUrl": "",
      "description": "Zabbix integration for hosts, items, triggers, templates, problems, data and more.",
      "stars": 80,
      "forks": 23,
      "license": "GNU General Public License v3.0",
      "language": "Python",
      "updated_at": "2025-10-03T07:32:40Z",
      "readme_content": "# Zabbix MCP Server\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)\n\nA comprehensive Model Context Protocol (MCP) server for Zabbix integration using FastMCP and python-zabbix-utils. This server provides complete access to Zabbix API functionality through MCP-compatible tools.\n\n<a href=\"https://glama.ai/mcp/servers/@mpeirone/zabbix-mcp-server\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@mpeirone/zabbix-mcp-server/badge\" alt=\"zabbix-mcp-server MCP server\" />\n</a>\n\n## Features\n\n### 🏠 Host Management\n- `host_get` - Retrieve hosts with advanced filtering\n- `host_create` - Create new hosts with interfaces and templates\n- `host_update` - Update existing host configurations\n- `host_delete` - Remove hosts from monitoring\n\n### 👥 Host Group Management\n- `hostgroup_get` - Retrieve host groups\n- `hostgroup_create` - Create new host groups\n- `hostgroup_update` - Modify existing host groups\n- `hostgroup_delete` - Remove host groups\n\n### 📊 Item Management\n- `item_get` - Retrieve monitoring items with filtering\n- `item_create` - Create new monitoring items\n- `item_update` - Update existing items\n- `item_delete` - Remove monitoring items\n\n### ⚠️ Trigger Management\n- `trigger_get` - Retrieve triggers and alerts\n- `trigger_create` - Create new triggers\n- `trigger_update` - Modify existing triggers\n- `trigger_delete` - Remove triggers\n\n### 📋 Template Management\n- `template_get` - Retrieve monitoring templates\n- `template_create` - Create new templates\n- `template_update` - Update existing templates\n- `template_delete` - Remove templates\n\n### 🚨 Problem & Event Management\n- `problem_get` - Retrieve current problems and issues\n- `event_get` - Get historical events\n- `event_acknowledge` - Acknowledge events and problems\n\n### 📈 Data Retrieval\n- `history_get` - Access historical monitoring data\n- `trend_get` - Retrieve trend data and statistics\n\n### 👤 User Management\n- `user_get` - Retrieve user accounts\n- `user_create` - Create new users\n- `user_update` - Update user information\n- `user_delete` - Remove user accounts\n\n### 🔧 Maintenance Management\n- `maintenance_get` - Retrieve maintenance periods\n- `maintenance_create` - Schedule maintenance windows\n- `maintenance_update` - Modify maintenance periods\n- `maintenance_delete` - Remove maintenance schedules\n\n### 📊 Additional Features\n- `graph_get` - Retrieve graph configurations\n- `discoveryrule_get` - Get discovery rules\n- `itemprototype_get` - Retrieve item prototypes\n- `configuration_export` - Export Zabbix configurations\n- `configuration_import` - Import configurations\n- `apiinfo_version` - Get API version information\n\n## Installation\n\n### Prerequisites\n\n- Python 3.10 or higher\n- [uv](https://docs.astral.sh/uv/) package manager\n- Access to a Zabbix server with API enabled\n\n### Quick Start\n\n1. **Clone the repository:**\n   ```bash\n   git clone https://github.com/mpeirone/zabbix-mcp-server.git\n   cd zabbix-mcp-server\n   ```\n\n2. **Install dependencies:**\n   ```bash\n   uv sync\n   ```\n\n3. **Configure environment variables:**\n   ```bash\n   cp config/.env.example .env\n   # Edit .env with your Zabbix server details\n   ```\n\n4. **Test the installation:**\n   ```bash\n   uv run python scripts/test_server.py\n   ```\n\n## Configuration\n\n### Required Environment Variables\n\n- `ZABBIX_URL` - Your Zabbix server API endpoint (e.g., `https://zabbix.example.com`)\n\n### Authentication (choose one method)\n\n**Method 1: API Token (Recommended)**\n- `ZABBIX_TOKEN` - Your Zabbix API token\n\n**Method 2: Username/Password**\n- `ZABBIX_USER` - Your Zabbix username\n- `ZABBIX_PASSWORD` - Your Zabbix password\n\n### Optional Configuration\n\n- `READ_ONLY` - Set to `true`, `1`, or `yes` to enable read-only mode (only GET operations allowed)\n\n## Usage\n\n### Running the Server\n\n**With startup script (recommended):**\n```bash\nuv run python scripts/start_server.py\n```\n\n**Direct execution:**\n```bash\nuv run python src/zabbix_mcp_server.py\n```\n\n### Testing\n\n**Run test suite:**\n```bash\nuv run python scripts/test_server.py\n```\n\n### Read-Only Mode\n\nWhen `READ_ONLY=true`, the server will only expose GET operations (retrieve data) and block all create, update, and delete operations. This is useful for:\n\n- 📊 Monitoring dashboards\n- 🔍 Read-only integrations\n- 🔒 Security-conscious environments\n- 🛡️ Preventing accidental modifications\n\n### Example Tool Calls\n\n**Get all hosts:**\n```python\nhost_get()\n```\n\n**Get hosts in specific group:**\n```python\nhost_get(groupids=[\"1\"])\n```\n\n**Create a new host:**\n```python\nhost_create(\n    host=\"server-01\",\n    groups=[{\"groupid\": \"1\"}],\n    interfaces=[{\n        \"type\": 1,\n        \"main\": 1,\n        \"useip\": 1,\n        \"ip\": \"192.168.1.100\",\n        \"dns\": \"\",\n        \"port\": \"10050\"\n    }]\n)\n```\n\n**Get recent problems:**\n```python\nproblem_get(recent=True, limit=10)\n```\n\n**Get history data:**\n```python\nhistory_get(\n    itemids=[\"12345\"],\n    time_from=1640995200,\n    limit=100\n)\n```\n\n## MCP Integration\n\nThis server is designed to work with MCP-compatible clients like Claude Desktop. See [MCP_SETUP.md](MCP_SETUP.md) for detailed integration instructions.\n\n## Docker Support\n\n### Using Docker Compose\n\n1. **Configure environment:**\n   ```bash\n   cp config/.env.example .env\n   # Edit .env with your settings\n   ```\n\n2. **Run with Docker Compose:**\n   ```bash\n   docker compose up -d\n   ```\n\n### Building Docker Image\n\n```bash\ndocker build -t zabbix-mcp-server .\n```\n\n## Development\n\n### Project Structure\n\n```\nzabbix-mcp-server/\n├── src/\n│   └── zabbix_mcp_server.py    # Main server implementation\n├── scripts/\n│   ├── start_server.py         # Startup script with validation\n│   └── test_server.py          # Test script\n├── config/\n│   ├── .env.example           # Environment configuration template\n│   └── mcp.json               # MCP client configuration example\n├── pyproject.toml             # Python project configuration\n├── requirements.txt           # Dependencies\n├── Dockerfile                 # Docker configuration\n├── docker-compose.yml         # Docker Compose setup\n├── README.md                  # This file\n├── MCP_SETUP.md              # MCP integration guide\n├── CONTRIBUTING.md           # Contribution guidelines\n├── CHANGELOG.md              # Version history\n└── LICENSE                   # MIT license\n```\n\n### Contributing\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n### Running Tests\n\n```bash\n# Test server functionality\nuv run python scripts/test_server.py\n\n# Test with Docker\ndocker-compose exec zabbix-mcp python scripts/test_server.py\n```\n\n## Error Handling\n\nThe server includes comprehensive error handling:\n\n- ✅ Authentication errors are clearly reported\n- 🔒 Read-only mode violations are blocked with descriptive messages\n- ✔️ Invalid parameters are validated\n- 🌐 Network and API errors are properly formatted\n- 📝 Detailed logging for troubleshooting\n\n## Security Considerations\n\n- 🔑 Use API tokens instead of username/password when possible\n- 🔒 Enable read-only mode for monitoring-only use cases\n- 🛡️ Secure your environment variables\n- 🔐 Use HTTPS for Zabbix server connections\n- 🔄 Regularly rotate API tokens\n- 📁 Store configuration files securely\n\n## Troubleshooting\n\n### Common Issues\n\n**Connection Failed:**\n- Verify `ZABBIX_URL` is correct and accessible\n- Check authentication credentials\n- Ensure Zabbix API is enabled\n\n**Permission Denied:**\n- Verify user has sufficient Zabbix permissions\n- Check if read-only mode is enabled when trying to modify data\n\n**Tool Not Found:**\n- Ensure all dependencies are installed: `uv sync`\n- Verify Python version compatibility (3.10+)\n\n### Debug Mode\n\nSet environment variable for detailed logging:\n```bash\nexport DEBUG=1\nuv run python scripts/start_server.py\n```\n\n## Dependencies\n\n- [FastMCP](https://github.com/jlowin/fastmcp) - MCP server framework\n- [python-zabbix-utils](https://github.com/zabbix/python-zabbix-utils) - Official Zabbix Python library\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\n- [Zabbix](https://www.zabbix.com/) for the monitoring platform\n- [Model Context Protocol](https://modelcontextprotocol.io/) for the integration standard\n- [FastMCP](https://github.com/jlowin/fastmcp) for the server framework\n\n## Support\n\n- 📖 [Documentation](README.md)\n- 🐛 [Issue Tracker](https://github.com/mpeirone/zabbix-mcp-server/issues)\n- 💬 [Discussions](https://github.com/mpeirone/zabbix-mcp-server/discussions)\n\n---\n\n**Made with ❤️ for the Zabbix and MCP communities**",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "monitoring",
        "zabbix",
        "ai",
        "server zabbix",
        "application monitoring",
        "zabbix integration"
      ],
      "category": "monitoring"
    },
    "netdata--netdata": {
      "owner": "netdata",
      "name": "netdata",
      "url": "https://github.com/netdata/netdata/blob/master/src/web/mcp/README.md",
      "imageUrl": "",
      "description": "Discovery, exploration, reporting and root cause analysis using all observability data, including metrics, logs, systems, containers, processes, and network connections",
      "stars": 76293,
      "forks": 6193,
      "license": "GNU General Public License v3.0",
      "language": "C",
      "updated_at": "2025-10-04T07:00:19Z",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "netdata",
        "monitoring",
        "ai",
        "netdata discovery",
        "netdata netdata",
        "application monitoring"
      ],
      "category": "monitoring"
    },
    "tumf--grafana-loki-mcp": {
      "owner": "tumf",
      "name": "grafana-loki-mcp",
      "url": "https://github.com/tumf/grafana-loki-mcp",
      "imageUrl": "",
      "description": "An MCP server that allows querying Loki logs through the Grafana API.",
      "stars": 17,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T05:23:29Z",
      "readme_content": "# Grafana-Loki MCP Server\n\n[![Test](https://github.com/tumf/grafana-loki-mcp/actions/workflows/test.yml/badge.svg)](https://github.com/tumf/grafana-loki-mcp/actions/workflows/test.yml)\n[![PyPI version](https://badge.fury.io/py/grafana-loki-mcp.svg)](https://badge.fury.io/py/grafana-loki-mcp)\n[![codecov](https://codecov.io/gh/tumf/grafana-loki-mcp/branch/main/graph/badge.svg)](https://codecov.io/gh/tumf/grafana-loki-mcp)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nA [FastMCP](https://github.com/jlowin/fastmcp) server that allows querying Loki logs from Grafana.\n\n## MCP Server Settings\n\n```json\n{\n  \"mcpServers\": {\n    \"loki\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"grafana-loki-mcp\",\n        \"-u\",\n        \"GRAFANA_URL\",\n        \"-k\",\n        \"GRAFANA_API_KEY\"\n      ]\n    }\n  }\n}\n```\n\n- `GRAFANA_URL`: URL of your Grafana instance\n- `GRAFANA_API_KEY`: Grafana API key with appropriate permissions\n\n## Features\n\n- Query Loki logs through Grafana API\n- Get Loki labels and label values\n- Format query results in different formats (text, JSON, markdown)\n- Support for both stdio and SSE transport protocols\n\n## Requirements\n\n- Python 3.10+\n- FastMCP\n- Requests\n\n## Installation\n\n### Using pip\n\n```bash\npip install grafana-loki-mcp\n```\n\n### Development Setup\n\n1. Clone this repository\n2. Install dependencies using uv:\n\n```bash\n# Install uv\npip install uv\n\n# Create and activate virtual environment\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Install dependencies\nuv pip install -e \".[dev]\"\n```\n\n## Usage\n\n### Environment Variables\n\nSet the following environment variables:\n\n- `GRAFANA_URL`: URL of your Grafana instance\n- `GRAFANA_API_KEY`: Grafana API key with appropriate permissions\n\n### Command Line Arguments\n\nYou can also provide these values as command line arguments:\n\n```bash\ngrafana-loki-mcp -u https://your-grafana-instance.com -k your-api-key\n```\n\nAdditional options:\n- `--transport`: Transport protocol to use (`stdio` or `sse`, default: `stdio`)\n\n### Running the Server\n\n```bash\n# Using environment variables\nexport GRAFANA_URL=https://your-grafana-instance.com\nexport GRAFANA_API_KEY=your-api-key\ngrafana-loki-mcp\n\n# Using command line arguments\ngrafana-loki-mcp -u https://your-grafana-instance.com -k your-api-key\n\n# Using SSE transport\ngrafana-loki-mcp --transport sse\n```\n\n## Development\n\n### Testing\n\nRun the test suite:\n\n```bash\npytest\n```\n\nRun with coverage:\n\n```bash\npytest --cov=. --cov-report=term\n```\n\n### Linting and Formatting\n\n```bash\n# Run ruff linter\nruff check .\n\n# Run black formatter\nblack .\n\n# Run type checking\nmypy .\n```\n\n## Available Tools\n\n### query_loki\n\nQuery Loki logs through Grafana.\n\nParameters:\n- `query`: Loki query string\n- `start`: Start time (ISO format, Unix timestamp, or Grafana-style relative time like 'now-1h', default: 1 hour ago)\n- `end`: End time (ISO format, Unix timestamp, or Grafana-style relative time like 'now', default: now)\n- `limit`: Maximum number of log lines to return (default: 100)\n- `direction`: Query direction ('forward' or 'backward', default: 'backward')\n- `max_per_line`: Maximum characters per log line (0 for unlimited, default: 100)\n\n### get_loki_labels\n\nGet all label names from Loki.\n\n### get_loki_label_values\n\nGet values for a specific label from Loki.\n\nParameters:\n- `label`: Label name\n\n### format_loki_results\n\nFormat Loki query results in a more readable format.\n\nParameters:\n- `results`: Loki query results from query_loki\n- `format_type`: Output format ('text', 'json', or 'markdown', default: 'text')\n- `max_per_line`: Maximum characters per log line (0 for unlimited, default: 0)\n\n## Example Usage\n\n```python\n# Example client code\nfrom mcp.client import Client\n\nasync with Client() as client:\n    # Query Loki logs with max_per_line limit\n    results = await client.call_tool(\n        \"query_loki\",\n        {\n            \"query\": '{app=\"my-app\"} |= \"error\"',\n            \"limit\": 50,\n            \"max_per_line\": 100,  # Limit log lines to 100 characters\n            \"start\": \"now-6h\",    # Grafana-style relative time: 6 hours ago\n            \"end\": \"now\"          # Current time\n        }\n    )\n\n    # Format the results\n    formatted = await client.call_tool(\n        \"format_loki_results\",\n        {\n            \"results\": results,\n            \"format_type\": \"markdown\",\n            \"max_per_line\": 100  # Can also limit at formatting time\n        }\n    )\n\n    print(formatted)\n```\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "monitoring",
        "api",
        "logs",
        "application monitoring",
        "grafana api",
        "monitoring access"
      ],
      "category": "monitoring"
    },
    "yshngg--pmcp": {
      "owner": "yshngg",
      "name": "pmcp",
      "url": "https://github.com/yshngg/pmcp",
      "imageUrl": "",
      "description": "A Prometheus Model Context Protocol Server.",
      "stars": 3,
      "forks": 1,
      "license": "Apache License 2.0",
      "language": "Go",
      "updated_at": "2025-09-30T01:59:52Z",
      "readme_content": "# PMCP - Prometheus Model Context Protocol Server\n\n[![codecov](https://codecov.io/gh/yshngg/pmcp/graph/badge.svg?token=C64XY9GFP3)](https://codecov.io/gh/yshngg/pmcp)\n[![Go Report Card](https://goreportcard.com/badge/github.com/yshngg/pmcp)](https://goreportcard.com/report/github.com/yshngg/pmcp)\n\n**🚀 A Golang-based Model Context Protocol (MCP) server implementation for Prometheus that enables natural language interactions with Prometheus metrics and queries.**\n\n**Built with Go**, PMCP provides a robust, type-safe interface that maintains full consistency with the Prometheus HTTP API, allowing you to query and manage your Prometheus instance through natural language conversations with MCP-compatible clients.\n\n---\n\n## Table of Contents\n\n1. [Features](#features)\n2. [Architecture](#architecture)\n3. [Requirements](#requirements)\n4. [Installation](#installation)\n5. [Usage](#usage)\n   * [Command Line Flags](#command-line-flags)\n6. [API Compatibility](#api-compatibility)\n7. [Binding Blocks](#binding-blocks)\n   * [Tools](#tools)\n   * [Prompts](#prompts)\n8. [Contributing](#contributing)\n9. [License](#license)\n10. [Acknowledgments](#acknowledgments)\n\n---\n\n## Features\n\n* **🔥 Golang Implementation**: Built with Go 1.23+ for performance, reliability, and type safety\n* **📊 Complete Prometheus API Coverage**: Full compatibility with Prometheus HTTP API v1\n* **⚡ Instant Query**: Execute Prometheus queries at a specific point in time\n* **📈 Range Query**: Retrieve historical metric data over defined time ranges\n* **🔍 Metadata Query**: Discover time series, label names, and label values\n* **🎯 Target & Rule Management**: Monitor targets, rules, and alerting configurations\n* **🛠️ TSDB Administration**: Advanced database operations including snapshots and series deletion\n* **🌐 Multiple Transport Options**: Support for HTTP, Server-Sent Events (SSE), and stdio\n* **🤖 MCP Integration**: Seamless communication with MCP-compatible clients like Claude Desktop\n\n---\n\n## Architecture\n\nPMCP is designed as a **Golang microservice** that acts as a bridge between MCP clients and Prometheus servers. It provides:\n\n* **Type-safe API bindings** using Go structs that mirror Prometheus API responses\n* **Modular package structure** for maintainability and extensibility  \n* **Comprehensive error handling** with proper Go error propagation\n* **Clean separation of concerns** between transport, API client, and business logic\n\n---\n\n## Requirements\n\n* **Go 1.23.0** or higher\n* A running **Prometheus server** (v2.x)\n* Compatible MCP client (Claude Desktop, custom implementations, etc.)\n\n---\n\n## Installation\n\n### Using Docker (Recommended)\n\nPull the pre-built image from GitHub Container Registry:\n\n```bash\n# Pull the latest image\ndocker pull ghcr.io/yshngg/pmcp:latest\n\n# Run with stdio transport (for desktop clients)\ndocker run --rm ghcr.io/yshngg/pmcp:latest --prom-addr=\"http://host.docker.internal:9090\"\n\n# Run with HTTP transport\ndocker run --rm -p 8080:8080 ghcr.io/yshngg/pmcp:latest --prom-addr=\"http://host.docker.internal:9090\" --transport=http --mcp-addr=\"0.0.0.0:8080\"\n```\n\nAlternatively, build locally:\n\n```bash\ndocker build -t pmcp .\ndocker run -p 8080:8080 pmcp --prom-addr=\"http://prometheus:9090\" --transport=http\n```\n\n### Download Pre-built Binary\n\nDownload the latest release from GitHub:\n\n1. Go to [PMCP Releases](https://github.com/yshngg/pmcp/releases)\n2. Download the appropriate binary for your platform from the **Assets** section\n3. Extract and run:\n\n```bash\n# Linux/macOS example\ntar -xzf pmcp-<version>.linux-amd64.tar.gz\n./pmcp --prom-addr=\"http://localhost:9090\"\n\n# Windows example\nunzip pmcp-<version>.windows-amd64.zip\npmcp.exe --prom-addr=\"http://localhost:9090\"\n```\n\n### Building from Source\n\n```bash\ngit clone https://github.com/yshngg/pmcp.git\ncd pmcp\nmake build\n# Binary will be available as ./pmcp\n```\n\n### Using Go Install\n\nInstall the `pmcp` binary directly from source:\n\n```bash\ngo install github.com/yshngg/pmcp@latest\n```\n\nEnsure `$GOPATH/bin` is in your `$PATH`.\n\n---\n\n## Usage\n\nRun the server by specifying your Prometheus address and preferred transport:\n\n```bash\n# Default (stdio transport) - ideal for desktop clients\npmcp --prom-addr=\"http://localhost:9090\"\n\n# HTTP transport - for web-based integrations\npmcp --prom-addr=\"http://localhost:9090\" --transport=http --mcp-addr=\"localhost:8080\"\n\n# SSE transport - for real-time streaming (deprecated, use HTTP)\npmcp --prom-addr=\"http://localhost:9090\" --transport=sse --mcp-addr=\"localhost:8080\"\n```\n\n### Command Line Flags\n\n| Flag         | Description                                       | Default                 |\n| ------------ | ------------------------------------------------- | ----------------------- |\n| `-help`      | Show help information.                            | N/A                     |\n| `-mcp-addr`  | Address for the MCP server to listen on.          | `localhost:8080`        |\n| `-prom-addr` | Prometheus server URL.                            | `http://localhost:9090` |\n| `-transport` | Communication transport (`stdio`, `http`, `sse`). | `stdio`                 |\n| `-version`   | Print version and exit.                           | N/A                     |\n\n---\n\n## API Compatibility\n\nPMCP maintains **100% compatibility** with the Prometheus HTTP API v1. Every tool and endpoint corresponds directly to the official Prometheus API:\n\n### Query & Data Retrieval\n\n| PMCP Tool | Prometheus Endpoint | HTTP Method | Purpose |\n|-----------|-------------------|-------------|---------|\n| Instant Query | `/api/v1/query` | GET/POST | Execute instant queries |\n| Range Query | `/api/v1/query_range` | GET/POST | Execute range queries |\n\n### Metadata & Discovery\n\n| PMCP Tool | Prometheus Endpoint | HTTP Method | Purpose |\n|-----------|-------------------|-------------|---------|\n| Find Series by Labels | `/api/v1/series` | GET/POST | Find matching time series |\n| List Label Names | `/api/v1/labels` | GET/POST | List all label names |\n| List Label Values | `/api/v1/label/:name/values` | GET | List values for a specific label |\n| Target Discovery | `/api/v1/targets` | GET | Get target information |\n| Target Metadata Query | `/api/v1/targets/metadata` | GET | Get metadata from targets |\n| Metric Metadata Query | `/api/v1/metadata` | GET | Get metric metadata |\n\n### Rules & Alerts\n\n| PMCP Tool | Prometheus Endpoint | HTTP Method | Purpose |\n|-----------|-------------------|-------------|---------|\n| Alert Query | `/api/v1/alerts` | GET | Get all active alerts |\n| Rule Query | `/api/v1/rules` | GET | Get recording/alerting rules |\n| Alertmanager Discovery | `/api/v1/alertmanagers` | GET | Get alertmanager information |\n\n### Status & Configuration\n\n| PMCP Tool | Prometheus Endpoint | HTTP Method | Purpose |\n|-----------|-------------------|-------------|---------|\n| Config | `/api/v1/status/config` | GET | Get current configuration |\n| Flags | `/api/v1/status/flags` | GET | Get runtime flags |\n| Build Information | `/api/v1/status/buildinfo` | GET | Get build information |\n| Runtime Information | `/api/v1/status/runtimeinfo` | GET | Get runtime information |\n| TSDB Stats | `/api/v1/status/tsdb` | GET | Get TSDB statistics |\n| WAL Replay Stats | `/api/v1/status/walreplay` | GET | Get WAL replay status |\n\n### TSDB Administration\n\n| PMCP Tool | Prometheus Endpoint | HTTP Method | Purpose |\n|-----------|-------------------|-------------|---------|\n| TSDB Snapshot | `/api/v1/admin/tsdb/snapshot` | POST/PUT | Create TSDB snapshot |\n| Delete Series | `/api/v1/admin/tsdb/delete_series` | POST/PUT | Delete time series data |\n| Clean Tombstones | `/api/v1/admin/tsdb/clean_tombstones` | POST/PUT | Clean deleted data |\n\n### Management APIs\n\n| PMCP Tool | Prometheus Endpoint | HTTP Method | Purpose |\n|-----------|-------------------|-------------|---------|\n| Health Check | `/-/healthy` | GET/HEAD | Check Prometheus health |\n| Readiness Check | `/-/ready` | GET/HEAD | Check if ready to serve |\n| Reload | `/-/reload` | PUT/POST | Reload configuration |\n| Quit | `/-/quit` | PUT/POST | Graceful shutdown |\n\n**All query parameters, response formats, and error codes match the official Prometheus API specification.**\n\n---\n\n## Binding Blocks\n\n### Tools\n\n**Expression Queries** (Core Prometheus functionality):\n\n* **Instant Query**: Evaluate an instant query at a single point in time\n* **Range Query**: Evaluate an expression query over a range of time\n\n**Metadata Queries** (Series and label discovery):\n\n* **Find Series by Labels**: Return the list of time series that match a certain label set\n* **List Label Names**: Return a list of label names\n* **List Label Values**: Return a list of label values for a provided label name\n* **Target Metadata Query**: Return metadata about metrics currently scraped from targets\n* **Metric Metadata Query**: Return metadata about metrics currently scraped from targets (without target information)\n\n**Discovery & Monitoring**:\n\n* **Target Discovery**: Return an overview of the current state of the Prometheus target discovery\n* **Alert Query**: Return a list of all active alerts\n* **Rule Query**: Return a list of alerting and recording rules that are currently loaded\n* **Alertmanager Discovery**: Return an overview of the current state of the Prometheus alertmanager discovery\n\n**Status & Configuration**:\n\n* **Config**: Return currently loaded configuration file\n* **Flags**: Return flag values that Prometheus was configured with\n* **Runtime Information**: Return various runtime information properties about the Prometheus server\n* **Build Information**: Return various build information properties about the Prometheus server\n* **TSDB Stats**: Return various cardinality statistics about the Prometheus TSDB\n* **WAL Replay Stats**: Return information about the WAL replay\n\n**TSDB Admin APIs** (Advanced operations):\n\n* **TSDB Snapshot**: Create a snapshot of all current data into snapshots/`<datetime>`-`<rand>`\n* **Delete Series**: Delete data for a selection of series in a time range\n* **Clean Tombstones**: Remove the deleted data from disk and cleans up the existing tombstones\n\n**Management APIs**:\n\n* **Health Check**: Check Prometheus health\n* **Readiness Check**: Check if Prometheus is ready to serve traffic (i.e. respond to queries)\n* **Reload**: Trigger a reload of the Prometheus configuration and rule files\n* **Quit**: Trigger a graceful shutdown of Prometheus\n\n### Prompts\n\n* **All Available Metrics**: Return a list of every metric exposed by the Prometheus instance\n\n---\n\n## Contributing\n\nContributions are welcome! This is a **Golang project**, so please ensure:\n\n* Follow Go best practices and conventions\n* Add appropriate tests for new functionality\n* Maintain API compatibility with Prometheus\n* Update documentation as needed\n\nPlease submit a pull request or open an issue to discuss improvements.\n\n### Development Setup\n\n```bash\ngit clone https://github.com/yshngg/pmcp.git\ncd pmcp\ngo mod download\nmake build\n```\n\n---\n\n## License\n\nThis project is licensed under the Apache License 2.0. See the [LICENSE](LICENSE) file for details.\n\n---\n\n## Acknowledgments\n\n* **Built with Go** using the official [Prometheus Go client library](https://github.com/prometheus/client_golang)\n* Powered by [Model Context Protocol Go SDK](https://github.com/modelcontextprotocol/go-sdk)\n* Inspired by [Prometheus](https://prometheus.io/) - the de facto standard for monitoring and alerting\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "monitoring",
        "pmcp",
        "protocol",
        "pmcp prometheus",
        "application monitoring",
        "monitoring access"
      ],
      "category": "monitoring"
    }
  }
}