{
  "category": "aggregators",
  "categoryDisplay": "Aggregators",
  "description": "Servers for accessing many apps and tools through a single MCP server.",
  "totalRepositories": 17,
  "repositories": {
    "1mcp--agent": {
      "owner": "1mcp",
      "name": "agent",
      "url": "https://github.com/1mcp-app/agent",
      "imageUrl": "",
      "description": "A unified Model Context Protocol server implementation that aggregates multiple MCP servers into one.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "aggregators",
        "servers",
        "mcp servers",
        "mcp server",
        "aggregators servers"
      ],
      "category": "aggregators"
    },
    "Data-Everything--mcp-server-templates": {
      "owner": "Data-Everything",
      "name": "mcp-server-templates",
      "url": "https://github.com/Data-Everything/mcp-server-templates",
      "imageUrl": "",
      "description": "One server. All tools. A unified MCP platform that connects many apps, tools, and services behind one powerful interface—ideal for local devs or production agents.",
      "stars": 7,
      "forks": 2,
      "license": "Other",
      "language": "Python",
      "updated_at": "2025-09-30T17:49:33Z",
      "readme_content": "# 🚀 This Project Has Moved!\n\n> ## ⚠️ **IMPORTANT: This repository has been renamed and moved to [MCP Platform](https://github.com/Data-Everything/MCP-Platform)**\n>\n> **What changed:**\n> - **New Repository**: [`Data-Everything/MCP-Platform`](https://github.com/Data-Everything/MCP-Platform)\n> - **New Package**: `pip install mcp-platform` (replaces `mcp-templates`)\n> - **New CLI**: `mcpp` command (replaces `mcpt`)\n> - **Enhanced Features**: Improved architecture and expanded capabilities\n>\n> **Migration is easy:**\n> ```bash\n> # Uninstall old package\n> pip uninstall mcp-templates\n>\n> # Install new package\n> pip install mcp-platform\n>\n> # Use new command (all your configs work the same!)\n> mcpp deploy demo  # instead of mcpt deploy demo\n> ```\n>\n> **📚 [Complete Migration Guide](https://github.com/Data-Everything/MCP-Platform#migration-from-mcp-templates)** | **🆕 [New Documentation](https://data-everything.github.io/MCP-Platform/)**\n\n---\n\n# MCP Server Templates (Legacy)\n\n> **⚠️ This version is in maintenance mode. Please migrate to [MCP Platform](https://github.com/Data-Everything/MCP-Platform) for latest features and updates.**\n\n[![Version](https://img.shields.io/pypi/v/mcp-templates.svg)](https://pypi.org/project/mcp-templates/)\n[![Python Versions](https://img.shields.io/pypi/pyversions/mcp-templates.svg)](https://pypi.org/project/mcp-templates/)\n[![License](https://img.shields.io/badge/License-Elastic%202.0-blue.svg)](LICENSE)\n[![Discord](https://img.shields.io/discord/XXXXX?color=7289da&logo=discord&logoColor=white)](https://discord.gg/55Cfxe9gnr)\n\n<div align=\"center\">\n\n**� [Migrate to MCP Platform](https://github.com/Data-Everything/MCP-Platform)** • **[💬 Discord Community](https://discord.gg/55Cfxe9gnr)** • **[� Legacy Docs](#-quick-start)**\n\n</div>\n\n> **Deploy Model Context Protocol (MCP) servers in seconds, not hours.**\n\nZero-configuration deployment of production-ready MCP servers with Docker containers, comprehensive CLI tools, and intelligent caching. Focus on AI integration, not infrastructure setup.\n\n---\n\n## 🚀 Quick Start\n\n```bash\n# Install MCP Templates\npip install mcp-templates\n\n# List available templates\nmcpt list\n\n# Deploy instantly\nmcpt deploy demo\n\n# View deployment\nmcpt logs demo\n```\n\n**That's it!** Your MCP server is running at `http://localhost:8080`\n\n---\n\n## ⚡ Why MCP Templates?\n\n| Traditional MCP Setup | With MCP Templates |\n|----------------------|-------------------|\n| ❌ Complex configuration | ✅ One-command deployment |\n| ❌ Docker expertise required | ✅ Zero configuration needed |\n| ❌ Manual tool discovery | ✅ Automatic detection |\n| ❌ Environment setup headaches | ✅ Pre-built containers |\n\n**Perfect for:** AI developers, data scientists, DevOps teams building with MCP.\n\n---\n\n## 🌟 Key Features\n\n### 🖱️ **One-Click Deployment**\nDeploy MCP servers instantly with pre-built templates—no Docker knowledge required.\n\n### 🔍 **Smart Tool Discovery**\nAutomatically finds and showcases every tool your server offers.\n\n### 🧠 **Intelligent Caching**\n6-hour template caching with automatic invalidation for lightning-fast operations.\n\n### 💻 **Powerful CLI**\nComprehensive command-line interface for deployment, management, and tool execution.\n\n### 🛠️ **Flexible Configuration**\nConfigure via JSON, YAML, environment variables, CLI options, or override parameters.\n\n### 📦 **Growing Template Library**\nReady-to-use templates for common use cases: filesystem, databases, APIs, and more.\n\n---\n\n## 📚 Installation\n\n### PyPI (Recommended)\n```bash\npip install mcp-templates\n```\n\n### Docker\n```bash\ndocker run --privileged -it dataeverything/mcp-server-templates:latest deploy demo\n```\n\n### From Source\n```bash\ngit clone https://github.com/DataEverything/mcp-server-templates.git\ncd mcp-server-templates\npip install -r requirements.txt\n```\n\n---\n\n## 🎯 Common Use Cases\n\n### Deploy with Custom Configuration\n```bash\n# Basic deployment\nmcpt deploy filesystem --config allowed_dirs=\"/path/to/data\"\n\n# Advanced overrides\nmcpt deploy demo --override metadata__version=2.0 --transport http\n```\n\n### Manage Deployments\n```bash\n# List all deployments\nmcpt list --deployed\n\n# Stop a deployment\nmcpt stop demo\n\n# View logs\nmcpt logs demo --follow\n```\n\n### Template Development\n```bash\n# Create new template\nmcpt create my-template\n\n# Test locally\nmcpt deploy my-template --backend mock\n```\n\n---\n\n## 🏗️ Architecture\n\n```\n┌─────────────┐    ┌───────────────────┐    ┌─────────────────────┐\n│  CLI Tool   │───▶│ DeploymentManager │───▶│ Backend (Docker)    │\n│  (mcpt)     │    │                   │    │                     │\n└─────────────┘    └───────────────────┘    └─────────────────────┘\n       │                      │                        │\n       ▼                      ▼                        ▼\n┌─────────────┐    ┌───────────────────┐    ┌─────────────────────┐\n│ Template    │    │ CacheManager      │    │ Container Instance  │\n│ Discovery   │    │ (6hr TTL)         │    │                     │\n└─────────────┘    └───────────────────┘    └─────────────────────┘\n```\n\n**Configuration Flow:** Template Defaults → Config File → CLI Options → Environment Variables\n\n---\n\n## 📦 Available Templates\n\n| Template | Description | Transport | Use Case |\n|----------|-------------|-----------|----------|\n| **demo** | Hello world MCP server | HTTP, stdio | Testing & learning |\n| **filesystem** | Secure file operations | stdio | File management |\n| **gitlab** | GitLab API integration | stdio | CI/CD workflows |\n| **github** | GitHub API integration | stdio | Development workflows |\n| **zendesk** | Customer support tools | HTTP, stdio | Support automation |\n\n[View all templates →](https://data-everything.github.io/mcp-server-templates/server-templates/)\n\n---\n\n## 🛠️ Configuration Examples\n\n### Basic Configuration\n```bash\nmcpt deploy filesystem --config allowed_dirs=\"/home/user/data\"\n```\n\n### Advanced Configuration\n```bash\nmcpt deploy gitlab \\\n  --config gitlab_token=\"$GITLAB_TOKEN\" \\\n  --config read_only_mode=true \\\n  --override metadata__version=1.2.0 \\\n  --transport stdio\n```\n\n### Configuration File\n```json\n{\n  \"allowed_dirs\": \"/home/user/projects\",\n  \"log_level\": \"DEBUG\",\n  \"security\": {\n    \"read_only\": false,\n    \"max_file_size\": \"100MB\"\n  }\n}\n```\n\n```bash\nmcpt deploy filesystem --config-file myconfig.json\n```\n\n---\n\n## 🔧 Template Development\n\n### Creating Templates\n\n1. **Use the generator**:\n   ```bash\n   mcpt create my-template\n   ```\n\n2. **Define template.json**:\n   ```json\n   {\n     \"name\": \"My Template\",\n     \"description\": \"Custom MCP server\",\n     \"docker_image\": \"my-org/my-mcp-server\",\n     \"transport\": {\n       \"default\": \"stdio\",\n       \"supported\": [\"stdio\", \"http\"]\n     },\n     \"config_schema\": {\n       \"type\": \"object\",\n       \"properties\": {\n         \"api_key\": {\n           \"type\": \"string\",\n           \"env_mapping\": \"API_KEY\",\n           \"sensitive\": true\n         }\n       }\n     }\n   }\n   ```\n\n3. **Test and deploy**:\n   ```bash\n   mcpt deploy my-template --backend mock\n   ```\n\n[Full template development guide →](https://data-everything.github.io/mcp-server-templates/templates/creating/)\n\n---\n\n## � Migration to MCP Platform\n\n**This repository has evolved into MCP Platform with enhanced features and better architecture.**\n\n### Why We Moved\n\n1. **Better Naming**: \"MCP Platform\" better reflects the comprehensive nature of the project\n2. **Enhanced Architecture**: Improved codebase structure and performance\n3. **Expanded Features**: More deployment options, better tooling, enhanced templates\n4. **Future Growth**: Better positioned for upcoming MCP ecosystem developments\n\n### What Stays the Same\n\n- ✅ All your existing configurations work unchanged\n- ✅ Same Docker images and templates\n- ✅ Same deployment workflows\n- ✅ Full backward compatibility during transition\n\n### Migration Steps\n\n1. **Install new package:**\n   ```bash\n   pip uninstall mcp-templates\n   pip install mcp-platform\n   ```\n\n2. **Update commands:**\n   ```bash\n   # Old command\n   mcpt deploy demo\n\n   # New command (everything else identical)\n   mcpp deploy demo\n   ```\n\n3. **Update documentation bookmarks:**\n   - New docs: https://data-everything.github.io/MCP-Platform/\n   - New repository: https://github.com/Data-Everything/MCP-Platform\n\n### Support Timeline\n\n- **Current (Legacy) Package**: Security updates only through 2025\n- **New Platform**: Active development, new features, full support\n- **Migration Support**: Available through Discord and GitHub issues\n\n**🚀 [Start your migration now →](https://github.com/Data-Everything/MCP-Platform)**\n\n---\n\n## �📖 Documentation (Legacy)\n\n- **[Getting Started](https://data-everything.github.io/mcp-server-templates/getting-started/)** - Installation and first deployment\n- **[CLI Reference](https://data-everything.github.io/mcp-server-templates/cli/)** - Complete command documentation\n- **[Template Guide](https://data-everything.github.io/mcp-server-templates/templates/)** - Creating and configuring templates\n- **[User Guide](https://data-everything.github.io/mcp-server-templates/user-guide/)** - Advanced usage and best practices\n\n---\n\n## 🤝 Community\n\n- **[Discord Server](https://discord.gg/55Cfxe9gnr)** - Get help and discuss features\n- **[GitHub Issues](https://github.com/DataEverything/mcp-server-templates/issues)** - Report bugs and request features\n- **[Discussions](https://github.com/DataEverything/mcp-server-templates/discussions)** - Share templates and use cases\n\n---\n\n## 📝 License\n\nThis project is licensed under the [Elastic License 2.0](LICENSE).\n\n---\n\n## 🙏 Acknowledgments\n\nBuilt with ❤️ for the MCP community. Thanks to all contributors and template creators!\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "aggregators",
        "servers",
        "mcp",
        "aggregators servers",
        "mcp server",
        "mcp platform"
      ],
      "category": "aggregators"
    },
    "PipedreamHQ--pipedream": {
      "owner": "PipedreamHQ",
      "name": "pipedream",
      "url": "https://github.com/PipedreamHQ/pipedream/tree/master/modelcontextprotocol",
      "imageUrl": "",
      "description": "Connect with 2,500 APIs with 8,000+ prebuilt tools, and manage servers for your users, in your own app.",
      "stars": 10652,
      "forks": 5504,
      "license": "Other",
      "language": "JavaScript",
      "updated_at": "2025-10-04T11:29:59Z",
      "readme_content": "![pipedream](https://i.ibb.co/LPhXtH1/logo.png)\n\n<p align=\"center\">\n  <a href=\"https://pipedream.com/community\"><img src=\"https://img.shields.io/badge/discourse-forum-brightgreen.svg?style=flat-square&link=https%3A%2F%2Fpipedream.com%2Fcommunity)](https://pipedream.com/community\"></a>\n  <a href=\"https://pipedream.com/support\"><img src=\"https://img.shields.io/badge/-Join%20us%20on%20Slack-green?logo=slack&logoColor=34d28B&labelColor=150d11&color=34d28B&logoWidth=18&link=https%3A%2F%2Fpipedream.com%2Fsupport&link=https%3A%2F%2Fpipedream.com%2Fsupport)](https://pipedream.com/support\"></a>\n  <a href=\"https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fpublish.twitter.com%2F%3FbuttonType%3DFollowButton%26query%3Dhttps%253A%252F%252Ftwitter.com%252Fpipedream%26widget%3DButton&ref_src=twsrc%5Etfw&region=follow_link&screen_name=pipedream&tw_p=followbutton\"><img src=\"https://img.shields.io/twitter/follow/pipedream?label=Follow%20%40pipedream&style=social\"></a>\n  <a href=\"https://wellfound.com/company/pipedreamhq/jobs\"><img src=\"https://img.shields.io/badge/%F0%9F%91%8B%F0%9F%8F%BC%20We're%20hiring!-Join%20us-brightgreen\"></a>\n</p>\n\nPipedream is an integration platform for developers.\n\nPipedream provides a free, hosted platform for connecting apps and developing event-driven automations. The platform has over 1,000 fully-integrated applications, so you can use pre-built components to quickly send messages to Slack, add a new row to Google Sheets, and more. You can also run any Node.js, Python, Golang, or Bash code when you need custom logic. Pipedream has demonstrated SOC 2 compliance and can provide a SOC 2 Type 2 report upon request (please email support@pipedream.com).\n\n<p align=\"center\">\n  <br />\n  <img src=\"./images/hero2.png\" width=\"800px\" alt=\"HTTP trigger + step selection menu\" >\n  <br />\n</p>\n\nThis repo contains:\n\n- [The code for all pre-built integration components](https://github.com/PipedreamHQ/pipedream/tree/master/components)\n- [The product roadmap](https://github.com/PipedreamHQ/pipedream/issues)\n- [The Pipedream docs](https://github.com/PipedreamHQ/pipedream/tree/master/docs)\n- And other source code related to Pipedream.\n\nThis `README` explains the key features of the platform and how to get started.\n\nTo get support, please visit [https://pipedream.com/support](https://pipedream.com/support).\n\n## Key Features\n\n- [Workflows](#workflows) - Workflows run automations. Workflows are sequences of steps - pre-built actions or custom [Node.js](https://pipedream.com/docs/code/nodejs/), [Python](https://pipedream.com/docs/code/python/), [Golang](https://pipedream.com/docs/code/go/), or [Bash](https://pipedream.com/docs/code/bash/) code - triggered by an event (HTTP request, timer, when a new row is added to a Google Sheets, and more).\n- [Event Sources](#event-sources) - Sources trigger workflows. They emit events from services like GitHub, Slack, Airtable, RSS and [more](https://pipedream.com/apps). When you want to run a workflow when an event happens in any third-party app, you're using an event source.\n- [Actions](#actions) - Actions are pre-built code steps that you can use in a workflow to perform common operations across Pipedream's 1,000+ API integrations. For example, you can use actions to send email, add a row to a Google Sheet, [and more](https://pipedream.com/apps).\n- [Custom code](#code) - Most integrations require custom logic. Code is often the best way to express that logic, so Pipedream allows you to run any [Node.js](https://pipedream.com/docs/code/nodejs/), [Python](https://pipedream.com/docs/code/python/), [Golang](https://pipedream.com/docs/code/go/), or [Bash](https://pipedream.com/docs/code/bash/) code. You can import any package from the languages' package managers, connect to any Pipedream connected app, and more. Pipedream is \"low-code\" in the best way: you can use pre-built components when you're performing common actions, but you can write custom code when you need to.\n- [Destinations](#destinations) - Deliver events asynchronously to common destinations like Amazon S3, Snowflake, HTTP and email.\n- [Free](#pricing) - No fees for individual developers (see [limits](https://docs.pipedream.com/limits/))\n\n## Demo\n\nClick the image below to watch a brief demo on YouTube.\n\n<p align=\"center\">\n  <br />\n  <a href=\"https://bit.ly/3ytGgyR\">\n    <img src=\"./images/demo.png\" width=\"800px\" alt=\"Pipedream demo static image\" />\n  </a>\n</p>\n\n### Workflows\n\nWorkflows are sequences of linear [steps](https://pipedream.com/docs/workflows/steps) triggered by an event (like an HTTP request, or when a new row is added to a Google sheet). You can quickly develop complex automations using workflows and connect to any of our 1,000+ integrated apps.\n\n[See our workflow quickstart](https://pipedream.com/docs/quickstart/) to get started.\n\n### Event Sources\n\n[Event Sources](https://pipedream.com/docs/sources/) watch for new data from services like GitHub, Slack, Airtable, RSS and [more](https://pipedream.com/apps). When a source finds a new event, it emits it, triggering any linked workflows.\n\nYou can also consume events emitted by sources using [Pipedream's REST API](https://pipedream.com/docs/api/rest/) or a private, real-time [SSE stream](https://pipedream.com/docs/api/sse/).\n\nWhen a pre-built source doesn't exist for your use case, [you can build your own](https://pipedream.com/docs/components/quickstart/nodejs/sources/). Here is the simplest event source: it exposes an HTTP endpoint you can send any request to, and prints the contents of the request when invoked:\n\n```javascript\nexport default {\n  name: \"http\",\n  version: \"0.0.1\",\n  props: {\n    http: \"$.interface.http\",\n  },\n  run(event) {\n    console.log(event); // event contains the method, payload, etc.\n  },\n};\n```\n\n<a href=\"https://pipedream.com/sources/new?app=http\"><img src=\"https://i.ibb.co/m0bBsSL/deploy-clean.png\" height=\"35\"></a>\n\nYou can find the code for all pre-built sources in [the `components` directory](https://github.com/PipedreamHQ/pipedream/tree/master/components). If you find a bug or want to contribute a feature, [see our contribution guide](https://pipedream.com/docs/components/guidelines/#process).\n\n### Actions\n\n[Actions](https://pipedream.com/docs/components/actions/) are pre-built code steps that you can use in a workflow to perform common operations across Pipedream's 500+ API integrations. For example, you can use actions to send email, add a row to a Google Sheet, [and more](https://pipedream.com/apps).\n\nYou can [create your own actions](https://pipedream.com/docs/components/quickstart/nodejs/actions/), which you can re-use across workflows. You can also [publish actions to the entire Pipedream community](https://pipedream.com/docs/components/guidelines/), making them available for anyone to use.\n\nHere's an action that accepts a `name` as input and prints it to the workflow's logs:\n\n```javascript\nexport default {\n  name: \"Action Demo\",\n  description: \"This is a demo action\",\n  key: \"action_demo\",\n  version: \"0.0.1\",\n  type: \"action\",\n  props: {\n    name: {\n      type: \"string\",\n      label: \"Name\",\n    },\n  },\n  async run() {\n    return `hello ${this.name}!`;\n  },\n};\n```\n\nYou can find the code for all pre-built actions in [the `components` directory](https://github.com/PipedreamHQ/pipedream/tree/master/components). If you find a bug or want to contribute a feature, [see our contribution guide](https://pipedream.com/docs/components/guidelines/#process).\n\n### Custom code\n\nMost integrations require custom logic. Code is often the best way to express that logic, so Pipedream allows you to run custom code in a workflow using:\n\n<table align=\"center\">\n  <tr>\n    <td>\n      <a href=\"https://pipedream.com/docs/code/nodejs/\">\n        <img alt=\"Node.js\" src=\"https://res.cloudinary.com/pipedreamin/image/upload/v1646761316/docs/icons/icons8-nodejs_aax6wn.svg\" width=\"100\">\n      </a>\n    </td>\n    <td>\n      <a href=\"https://pipedream.com/docs/code/python/\">\n        <img alt=\"Python\" src=\"https://res.cloudinary.com/pipedreamin/image/upload/v1647356607/docs/icons/python-logo-generic_k3o5w2.svg\" width=\"100\">\n      </a>\n    </td>\n  </tr>\n  </tr>\n    <td>\n      <a href=\"https://pipedream.com/docs/code/go/\">\n        <img alt=\"Go\" src=\"https://res.cloudinary.com/pipedreamin/image/upload/v1646763751/docs/icons/Go-Logo_Blue_zhkchv.svg\" width=\"100\">\n      </a>\n    </td>\n    <td>\n      <a href=\"https://pipedream.com/docs/code/bash/\">\n        <img alt=\"Bash\" src=\"https://res.cloudinary.com/pipedreamin/image/upload/v1647356698/docs/icons/full_colored_dark_1_-svg_vyfnv7.svg\" width=\"100\">\n      </a>\n    </td>\n  </tr>\n</table>\n\nYou can import any package from the languages' package managers by declaring the imports directly in code. Pipedream will parse and download the necessary dependencies.\n\n```javascript\n// Node.js\nimport axios from \"axios\";\n```\n\n```python\n# Python\nimport pandas as pd\n```\n\n```golang\n// Go\nimport (\n    \"fmt\"\n    pd \"github.com/PipedreamHQ/pipedream-go\"\n)\n```\n\nYou can also [connect to any Pipedream connected app in custom code steps](https://pipedream.com/docs/code/nodejs/auth/). For example, you can connect your Slack account and send a message to a channel:\n\n```javascript\nimport { WebClient } from \"@slack/web-api\";\n\nexport default defineComponent({\n  props: {\n    // This creates a connection called \"slack\" that connects a Slack account.\n    slack: {\n      type: \"app\",\n      app: \"slack\",\n    },\n  },\n  async run({ steps, $ }) {\n    const web = new WebClient(this.slack.$auth.oauth_access_token);\n\n    return await web.chat.postMessage({\n      text: \"Hello, world!\",\n      channel: \"#general\",\n    });\n  },\n});\n```\n\n### Destinations\n\n[Destinations](https://pipedream.com/docs/destinations/), like actions, abstract the connection, batching, and delivery logic required to send events to services like Amazon S3, or targets like HTTP and email.\n\nFor example, sending data to an Amazon S3 bucket is as simple as calling `$send.s3()`:\n\n```javascript\n$send.s3({\n  bucket: \"your-bucket-here\",\n  prefix: \"your-prefix/\",\n  payload: event.body,\n});\n```\n\nPipedream supports the following destinations:\n\n- [Amazon S3](https://docs.pipedream.com/destinations/s3/)\n- [Snowflake](https://docs.pipedream.com/destinations/snowflake/)\n- [HTTP](https://docs.pipedream.com/destinations/http/)\n- [Email](https://docs.pipedream.com/destinations/email/)\n- [SSE](https://docs.pipedream.com/destinations/sse/)\n\n## Contributors\n\nThank you to everyone who has contributed to the Pipedream codebase. We appreciate you!\n\n<a href=\"https://github.com/PipedreamHQ/pipedream/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=PipedreamHQ/pipedream\" />\n</a>\n\n## Pricing\n\nPipedream has a [generous free tier](https://pipedream.com/docs/pricing/#developer-tier). You can run sources and workflows for free within the limits of the free tier. If you hit these limits, you can upgrade to one of our [paid tiers](https://pipedream.com/docs/pricing/).\n\n## Limits\n\nThe Pipedream platform imposes some runtime limits on sources and workflows. [Read more about those in our docs](https://pipedream.com/docs/limits/).\n\n## Found a Bug? Have a Feature to suggest?\n\nBefore adding an issue, please search the [existing issues](https://github.com/PipedreamHQ/pipedream/issues) or [reach out to our team](https://pipedream.com/support/) to see if a similar request already exists.\n\nIf an issue exists, please [add a reaction](https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/about-conversations-on-github) or add a comment detailing your specific use case.\n\nIf an issue _doesn't_ yet exist and you need to create one, please [use the issue templates](https://github.com/PipedreamHQ/pipedream/issues/new/choose).\n\n## Security\n\nYou can read about our platform security and privacy [here](https://pipedream.com/docs/privacy-and-security/).\n\nIf you'd like to report a suspected vulnerability or security issue, or have any questions about the security of the product, please contact our security team at **security@pipedream.com**.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "pipedreamhq",
        "pipedream",
        "aggregators",
        "server pipedreamhq",
        "pipedream connect",
        "pipedreamhq pipedream"
      ],
      "category": "aggregators"
    },
    "TheLunarCompany--lunar": {
      "owner": "TheLunarCompany",
      "name": "lunar",
      "url": "https://github.com/TheLunarCompany/lunar/tree/main/mcpx",
      "imageUrl": "",
      "description": "MCPX is a production-ready, open-source gateway to manage MCP servers at scale—centralize tool discovery, access controls, call prioritization, and usage tracking to simplify agent workflows.",
      "stars": 297,
      "forks": 19,
      "license": "MIT License",
      "language": "Go",
      "updated_at": "2025-10-04T07:29:33Z",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcpx",
        "mcp",
        "aggregators",
        "mcp servers",
        "mcp server",
        "manage mcp"
      ],
      "category": "aggregators"
    },
    "VeriTeknik--pluggedin-mcp-proxy": {
      "owner": "VeriTeknik",
      "name": "pluggedin-mcp-proxy",
      "url": "https://github.com/VeriTeknik/pluggedin-mcp-proxy",
      "imageUrl": "",
      "description": "A comprehensive proxy server that combines multiple MCP servers into a single interface with extensive visibility features. It provides discovery and management of tools, prompts, resources, and templates across servers, plus a playground for debugging when building MCP servers.",
      "stars": 95,
      "forks": 18,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-10-03T04:50:11Z",
      "readme_content": "# plugged.in MCP Proxy Server\n\n<div align=\"center\">\n  <img src=\"https://plugged.in/_next/image?url=%2Fpluggedin-wl.png&w=256&q=75\" alt=\"plugged.in Logo\" width=\"256\" height=\"75\">\n  <h3>The Crossroads for AI Data Exchanges</h3>\n  <p>A unified interface for managing all your MCP servers with built-in playground for testing on any AI model</p>\n\n  [![Version](https://img.shields.io/badge/version-1.9.0-blue?style=for-the-badge)](https://github.com/VeriTeknik/pluggedin-mcp/releases)\n  [![GitHub Stars](https://img.shields.io/github/stars/VeriTeknik/pluggedin-mcp?style=for-the-badge)](https://github.com/VeriTeknik/pluggedin-mcp/stargazers)\n  [![License](https://img.shields.io/github/license/VeriTeknik/pluggedin-mcp?style=for-the-badge)](LICENSE)\n  [![TypeScript](https://img.shields.io/badge/TypeScript-4.9+-blue?style=for-the-badge&logo=typescript)](https://www.typescriptlang.org/)\n  [![MCP](https://img.shields.io/badge/MCP-Compatible-green?style=for-the-badge)](https://modelcontextprotocol.io/)\n</div>\n\n## 📋 Overview\n\nThe plugged.in MCP Proxy Server is a powerful middleware that aggregates multiple Model Context Protocol (MCP) servers into a single unified interface. It fetches tool, prompt, and resource configurations from the [plugged.in App](https://github.com/VeriTeknik/pluggedin-app) and intelligently routes requests to the appropriate underlying MCP servers.\n\nThis proxy enables seamless integration with any MCP client (Claude, Cline, Cursor, etc.) while providing advanced management capabilities through the plugged.in ecosystem.\n\n> ⭐ **If you find this project useful, please consider giving it a star on GitHub!** It helps us reach more developers and motivates us to keep improving.\n\n## ✨ Key Features\n\n### 🚀 Core Capabilities\n- **Built-in AI Playground**: Test your MCPs instantly with Claude, Gemini, OpenAI, and xAI without any client setup\n- **Universal MCP Compatibility**: Works with any MCP client including Claude Desktop, Cline, and Cursor\n- **Multi-Server Support**: Connect to STDIO, SSE, and Streamable HTTP MCP servers\n- **Dual Transport Modes**: Run proxy as STDIO (default) or Streamable HTTP server\n- **Unified Document Search**: Search across all connected servers with built-in RAG capabilities\n- **AI Document Exchange (RAG v2)**: MCP servers can create and manage documents in your library with full attribution\n- **Notifications from Any Model**: Receive real-time notifications with optional email delivery\n- **Multi-Workspace Layer**: Switch between different sets of MCP configurations with one click\n- **API-Driven Proxy**: Fetches capabilities from plugged.in App APIs rather than direct discovery\n- **Full MCP Support**: Handles tools, resources, resource templates, and prompts\n- **Custom Instructions**: Supports server-specific instructions formatted as MCP prompts\n\n### 🎯 New in v1.5.0 (RAG v2 - AI Document Exchange)\n\n- **AI Document Creation**: MCP servers can now create documents directly in your library\n  - Full model attribution tracking (which AI created/updated the document)\n  - Version history with change tracking\n  - Content deduplication via SHA-256 hashing\n  - Support for multiple formats: MD, TXT, JSON, HTML, PDF, and more\n- **Advanced Document Search**: Enhanced RAG queries with AI filtering\n  - Filter by AI model, provider, date range, tags, and source type\n  - Semantic search with relevance scoring\n  - Automatic snippet generation with keyword highlighting\n  - Support for filtering: `ai_generated`, `upload`, or `api` sources\n- **Document Management via MCP**: \n  - Set document visibility: private, workspace, or public\n  - Parent-child relationships for document versions\n  - Profile-based organization alongside project-based scoping\n  - Real-time progress tracking for document processing\n\n### 🎯 Features from v1.4.0 (Registry v2 Support)\n\n- **OAuth Token Management**: Seamless OAuth authentication handling for Streamable HTTP MCP servers\n  - Automatic token retrieval from plugged.in App\n  - Secure token storage and refresh mechanisms\n  - No client-side authentication needed\n- **Enhanced Notification System**: Bidirectional notification support\n  - Send notifications to plugged.in App\n  - Receive notifications from MCP servers\n  - Mark notifications as read/unread\n  - Delete notifications programmatically\n- **Trending Analytics**: Real-time activity tracking\n  - Every tool call is logged and tracked\n  - Contributes to trending server calculations\n  - Usage metrics and popularity insights\n- **Registry Integration**: Full support for Registry v2 features\n  - Automatic server discovery from registry\n  - Installation tracking and metrics\n  - Community server support\n\n### 📦 Features from v1.1.0\n\n- **Streamable HTTP Support**: Full support for downstream MCP servers using Streamable HTTP transport\n- **HTTP Server Mode**: Run the proxy as an HTTP server with configurable ports\n- **Flexible Authentication**: Optional Bearer token authentication for HTTP endpoints\n- **Session Management**: Choose between stateful (session-based) or stateless operation modes\n\n### 🎯 Core Features from v1.0.0\n\n- **Real-Time Notifications**: Track all MCP activities with comprehensive notification support\n- **RAG Integration**: Support for document-enhanced queries through the plugged.in App\n- **Inspector Scripts**: Automated testing tools for debugging and development\n- **Health Monitoring**: Built-in ping endpoint for connection monitoring\n\n## 🔧 Tool Categories\n\nThe proxy provides two distinct categories of tools:\n\n### 🔧 Static Built-in Tools (Always Available)\nThese tools are built into the proxy and work without any server configuration:\n- **`pluggedin_discover_tools`** - Smart discovery with caching for instant results\n- **`pluggedin_rag_query`** - RAG v2 search across your documents with AI filtering capabilities\n- **`pluggedin_send_notification`** - Send notifications with optional email delivery\n- **`pluggedin_create_document`** - (Coming Soon) Create AI-generated documents in your library\n\n### ⚡ Dynamic MCP Tools (From Connected Servers)\nThese tools come from your configured MCP servers and can be turned on/off:\n- Database tools (PostgreSQL, SQLite, etc.)\n- File system tools\n- API integration tools\n- Custom tools from any MCP server\n\nThe discovery tool intelligently shows both categories, giving AI models immediate access to all available capabilities.\n\n### 🚀 Discovery Tool Usage\n\n```bash\n# Quick discovery - returns cached data instantly\npluggedin_discover_tools()\n\n# Force refresh - shows current tools + runs background discovery  \npluggedin_discover_tools({\"force_refresh\": true})\n\n# Discover specific server\npluggedin_discover_tools({\"server_uuid\": \"uuid-here\"})\n```\n\n**Example Response:**\n```\n## 🔧 Static Built-in Tools (Always Available):\n1. **pluggedin_discover_tools** - Smart discovery with caching\n2. **pluggedin_rag_query** - RAG v2 search across documents with AI filtering  \n3. **pluggedin_send_notification** - Send notifications\n4. **pluggedin_create_document** - (Coming Soon) Create AI-generated documents\n\n## ⚡ Dynamic MCP Tools (8) - From Connected Servers:\n1. **query** - Run read-only SQL queries\n2. **generate_random_integer** - Generate secure random integers\n...\n```\n\n### 📚 RAG v2 Usage Examples\n\nThe enhanced RAG v2 system allows MCP servers to create and search documents with full AI attribution:\n\n```bash\n# Search for documents created by specific AI models\npluggedin_rag_query({\n  \"query\": \"system architecture\",\n  \"filters\": {\n    \"modelName\": \"Claude 3 Opus\",\n    \"source\": \"ai_generated\",\n    \"tags\": [\"technical\"]\n  }\n})\n\n# Search across all document sources\npluggedin_rag_query({\n  \"query\": \"deployment guide\",\n  \"filters\": {\n    \"dateFrom\": \"2024-01-01\",\n    \"visibility\": \"workspace\"\n  }\n})\n\n# Future: Create AI-generated documents (Coming Soon)\npluggedin_create_document({\n  \"title\": \"Analysis Report\",\n  \"content\": \"# Market Analysis\\n\\nDetailed findings...\",\n  \"format\": \"md\",\n  \"tags\": [\"analysis\", \"market\"],\n  \"metadata\": {\n    \"model\": {\n      \"name\": \"Claude 3 Opus\",\n      \"provider\": \"Anthropic\"\n    }\n  }\n})\n```\n\n## 🚀 Quick Start\n\n### Prerequisites\n\n- Node.js 18+ (recommended v20+)\n- An API key from the plugged.in App (get one at [plugged.in/api-keys](https://plugged.in/api-keys))\n\n### Installation\n\n```bash\n# Install and run with npx (latest v1.0.0)\nnpx -y @pluggedin/pluggedin-mcp-proxy@latest --pluggedin-api-key YOUR_API_KEY\n```\n\n### 🔄 Upgrading to v1.0.0\n\nFor existing installations, see our [Migration Guide](./MIGRATION_GUIDE_v1.0.0.md) for detailed upgrade instructions.\n\n```bash\n# Quick upgrade\nnpx -y @pluggedin/pluggedin-mcp-proxy@1.0.0 --pluggedin-api-key YOUR_API_KEY\n```\n\n### Configuration for MCP Clients\n\n#### Claude Desktop\n\nAdd the following to your Claude Desktop configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"pluggedin\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@pluggedin/pluggedin-mcp-proxy@latest\"],\n      \"env\": {\n        \"PLUGGEDIN_API_KEY\": \"YOUR_API_KEY\"\n      }\n    }\n  }\n}\n```\n\n#### Cline\n\nAdd the following to your Cline configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"pluggedin\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@pluggedin/pluggedin-mcp-proxy@latest\"],\n      \"env\": {\n        \"PLUGGEDIN_API_KEY\": \"YOUR_API_KEY\"\n      }\n    }\n  }\n}\n```\n\n#### Cursor\n\nFor Cursor, you can use command-line arguments instead of environment variables:\n\n```bash\nnpx -y @pluggedin/pluggedin-mcp-proxy@latest --pluggedin-api-key YOUR_API_KEY\n```\n\n## ⚙️ Configuration Options\n\n### Environment Variables\n\n| Variable | Description | Required | Default |\n|----------|-------------|----------|---------|\n| `PLUGGEDIN_API_KEY` | API key from plugged.in App | Yes | - |\n| `PLUGGEDIN_API_BASE_URL` | Base URL for plugged.in App | No | `https://plugged.in` |\n\n### Command Line Arguments\n\nCommand line arguments take precedence over environment variables:\n\n```bash\nnpx -y @pluggedin/pluggedin-mcp-proxy@latest --pluggedin-api-key YOUR_API_KEY --pluggedin-api-base-url https://your-custom-url.com\n```\n\n#### Transport Options\n\n| Option | Description | Default |\n|--------|-------------|---------|\n| `--transport <type>` | Transport type: `stdio` or `streamable-http` | `stdio` |\n| `--port <number>` | Port for Streamable HTTP server | `12006` |\n| `--stateless` | Enable stateless mode for Streamable HTTP | `false` |\n| `--require-api-auth` | Require API key for Streamable HTTP requests | `false` |\n\nFor a complete list of options:\n\n```bash\nnpx -y @pluggedin/pluggedin-mcp-proxy@latest --help\n```\n\n## 🌐 Streamable HTTP Mode\n\nThe proxy can run as an HTTP server instead of STDIO, enabling web-based access and remote connections.\n\n### Basic Usage\n\n```bash\n# Run as HTTP server on default port (12006)\nnpx -y @pluggedin/pluggedin-mcp-proxy@latest --transport streamable-http --pluggedin-api-key YOUR_API_KEY\n\n# Custom port\nnpx -y @pluggedin/pluggedin-mcp-proxy@latest --transport streamable-http --port 8080 --pluggedin-api-key YOUR_API_KEY\n\n# With authentication required\nnpx -y @pluggedin/pluggedin-mcp-proxy@latest --transport streamable-http --require-api-auth --pluggedin-api-key YOUR_API_KEY\n\n# Stateless mode (new session per request)\nnpx -y @pluggedin/pluggedin-mcp-proxy@latest --transport streamable-http --stateless --pluggedin-api-key YOUR_API_KEY\n```\n\n### HTTP Endpoints\n\n- `POST /mcp` - Send MCP messages\n- `GET /mcp` - Server-sent events stream (optional)\n- `DELETE /mcp` - Terminate session\n- `GET /health` - Health check endpoint\n\n### Session Management\n\nIn stateful mode (default), use the `mcp-session-id` header to maintain sessions:\n\n```bash\n# First request creates a session\ncurl -X POST http://localhost:12006/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Accept: application/json, text/event-stream\" \\\n  -d '{\"jsonrpc\":\"2.0\",\"method\":\"tools/list\",\"id\":1}'\n\n# Subsequent requests use the same session\ncurl -X POST http://localhost:12006/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Accept: application/json, text/event-stream\" \\\n  -H \"mcp-session-id: YOUR_SESSION_ID\" \\\n  -d '{\"jsonrpc\":\"2.0\",\"method\":\"tools/call\",\"params\":{\"name\":\"tool_name\"},\"id\":2}'\n```\n\n### Authentication\n\nWhen using `--require-api-auth`, include your API key as a Bearer token:\n\n```bash\ncurl -X POST http://localhost:12006/mcp \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Accept: application/json, text/event-stream\" \\\n  -d '{\"jsonrpc\":\"2.0\",\"method\":\"ping\",\"id\":1}'\n```\n\n## 🐳 Docker Usage\n\nYou can also build and run the proxy server using Docker.\n\n### Building the Image\n\nEnsure you have Docker installed and running. Navigate to the `pluggedin-mcp` directory and run:\n\n```bash\ndocker build -t pluggedin-mcp-proxy:latest .\n```\n\nA `.dockerignore` file is included to optimize the build context.\n\n### Running the Container\n\n#### STDIO Mode (Default)\n\nRun the container in STDIO mode for MCP Inspector testing:\n\n```bash\ndocker run -it --rm \\\n  -e PLUGGEDIN_API_KEY=\"YOUR_API_KEY\" \\\n  -e PLUGGEDIN_API_BASE_URL=\"YOUR_API_BASE_URL\" \\\n  --name pluggedin-mcp-container \\\n  pluggedin-mcp-proxy:latest\n```\n\n#### Streamable HTTP Mode\n\nRun the container as an HTTP server:\n\n```bash\ndocker run -d --rm \\\n  -e PLUGGEDIN_API_KEY=\"YOUR_API_KEY\" \\\n  -e PLUGGEDIN_API_BASE_URL=\"YOUR_API_BASE_URL\" \\\n  -p 12006:12006 \\\n  --name pluggedin-mcp-http \\\n  pluggedin-mcp-proxy:latest \\\n  --transport streamable-http --port 12006\n```\n\nReplace `YOUR_API_KEY` and `YOUR_API_BASE_URL` (if not using the default `https://plugged.in`).\n\n### Testing with MCP Inspector\n\nWhile the container is running, you can connect to it using the MCP Inspector:\n\n```bash\nnpx @modelcontextprotocol/inspector docker://pluggedin-mcp-container\n```\n\nThis will connect to the standard input/output of the running container.\n\n### Stopping the Container\n\nPress `Ctrl+C` in the terminal where `docker run` is executing. The `--rm` flag ensures the container is removed automatically upon stopping.\n\n## 🏗️ System Architecture\n\nThe plugged.in MCP Proxy Server acts as a bridge between MCP clients and multiple underlying MCP servers:\n\n```mermaid\nsequenceDiagram\n    participant MCPClient as MCP Client (e.g. Claude Desktop)\n    participant PluggedinMCP as plugged.in MCP Proxy\n    participant PluggedinApp as plugged.in App\n    participant MCPServers as Underlying MCP Servers\n\n    MCPClient ->> PluggedinMCP: Request list tools/resources/prompts\n    PluggedinMCP ->> PluggedinApp: Get capabilities via API\n    PluggedinApp ->> PluggedinMCP: Return capabilities (prefixed)\n\n    MCPClient ->> PluggedinMCP: Call tool/read resource/get prompt\n    alt Standard capability\n        PluggedinMCP ->> PluggedinApp: Resolve capability to server\n        PluggedinApp ->> PluggedinMCP: Return server details\n        PluggedinMCP ->> MCPServers: Forward request to target server\n        MCPServers ->> PluggedinMCP: Return response\n    else Custom instruction\n        PluggedinMCP ->> PluggedinApp: Get custom instruction\n        PluggedinApp ->> PluggedinMCP: Return formatted messages\n    end\n    PluggedinMCP ->> MCPClient: Return response\n\n    alt Discovery tool (Smart Caching)\n        MCPClient ->> PluggedinMCP: Call pluggedin_discover_tools\n        alt Cached data available\n            PluggedinMCP ->> PluggedinApp: Check cached capabilities\n            PluggedinApp ->> PluggedinMCP: Return cached tools/resources/prompts\n            PluggedinMCP ->> MCPClient: Return instant results (static + dynamic)\n        else Force refresh or no cache\n            PluggedinMCP ->> PluggedinApp: Trigger background discovery\n            PluggedinMCP ->> MCPClient: Return current tools + \"discovery running\"\n            PluggedinApp ->> MCPServers: Connect and discover capabilities (background)\n            MCPServers ->> PluggedinApp: Return fresh capabilities\n        end\n    end\n```\n\n## 🔄 Workflow\n\n1. **Configuration**: The proxy fetches server configurations from the plugged.in App\n2. **Smart Discovery** (`pluggedin_discover_tools`):\n   - **Cache Check**: First checks for existing cached data (< 1 second)\n   - **Instant Response**: Returns static tools + cached dynamic tools immediately\n   - **Background Refresh**: For `force_refresh=true`, runs discovery in background while showing current tools\n   - **Fresh Discovery**: Only runs full discovery if no cached data exists\n3. **Capability Listing**: The proxy fetches discovered capabilities from plugged.in App APIs\n   - `tools/list`: Fetches from `/api/tools` (includes static + dynamic tools)\n   - `resources/list`: Fetches from `/api/resources`\n   - `resource-templates/list`: Fetches from `/api/resource-templates`\n   - `prompts/list`: Fetches from `/api/prompts` and `/api/custom-instructions`, merges results\n4. **Capability Resolution**: The proxy resolves capabilities to target servers\n   - `tools/call`: Parses prefix from tool name, looks up server in internal map\n   - `resources/read`: Calls `/api/resolve/resource?uri=...` to get server details\n   - `prompts/get`: Checks for custom instruction prefix or calls `/api/resolve/prompt?name=...`\n5. **Request Routing**: Requests are routed to the appropriate underlying MCP server\n6. **Response Handling**: Responses from the underlying servers are returned to the client\n\n## 🔒 Security Features\n\nThe plugged.in MCP Proxy implements comprehensive security measures to protect your system and data:\n\n### Input Validation & Sanitization\n\n- **Command Injection Prevention**: All commands and arguments are validated against allowlists before execution\n- **Environment Variable Security**: Secure parsing of `.env` files with proper handling of quotes and multiline values\n- **Token Validation**: Strong regex patterns for API keys and authentication tokens (32-64 hex characters)\n\n### Network Security\n\n- **SSRF Protection**: URL validation blocks access to:\n  - Localhost and loopback addresses (127.0.0.1, ::1)\n  - Private IP ranges (10.x, 172.16-31.x, 192.168.x)\n  - Link-local addresses (169.254.x)\n  - Multicast and reserved ranges\n  - Common internal service ports (SSH, databases, etc.)\n- **Header Validation**: Protection against header injection with:\n  - Dangerous header blocking\n  - RFC 7230 compliant header name validation\n  - Control character detection\n  - Header size limits (8KB max)\n- **Rate Limiting**: \n  - Tool calls: 60 requests per minute\n  - API calls: 100 requests per minute\n- **Error Sanitization**: Prevents information disclosure by sanitizing error messages\n\n### Process Security\n\n- **Safe Command Execution**: Uses `execFile()` instead of `exec()` to prevent shell injection\n- **Command Allowlist**: Only permits execution of:\n  - `node`, `npx` - Node.js commands\n  - `python`, `python3` - Python commands\n  - `uv`, `uvx`, `uvenv` - UV Python tools\n- **Argument Sanitization**: Removes shell metacharacters and control characters from all arguments\n- **Environment Variable Validation**: Only allows alphanumeric keys with underscores\n\n### Streamable HTTP Security\n\n- **Lazy Authentication**: Tool discovery doesn't require authentication, improving compatibility\n- **Session Security**: Cryptographically secure session ID generation\n- **CORS Protection**: Configurable CORS headers for web access\n- **Request Size Limits**: Prevents DoS through large payloads\n\n### Security Utilities\n\nA dedicated `security-utils.ts` module provides:\n- Bearer token validation\n- URL validation with SSRF protection\n- Command argument sanitization\n- Environment variable validation\n- Rate limiting implementation\n- Error message sanitization\n\nFor detailed security implementation, see [SECURITY.md](SECURITY.md).\n\n## 🧩 Integration with plugged.in App\n\nThe plugged.in MCP Proxy Server is designed to work seamlessly with the [plugged.in App](https://github.com/VeriTeknik/pluggedin-app), which provides:\n\n- A web-based interface for managing MCP server configurations\n- Centralized capability discovery (Tools, Resources, Templates, Prompts)\n- **RAG v2 Document Library**: Upload documents and enable AI-generated content with full attribution\n- Custom instructions management\n- Multi-workspace support for different configuration sets\n- An interactive playground for testing MCP tools with any AI model\n- User authentication and API key management\n- **AI Document Exchange**: Create, search, and manage documents with model attribution tracking\n\n## 📚 Related Resources\n\n- [plugged.in App Repository](https://github.com/VeriTeknik/pluggedin-app)\n- [Model Context Protocol (MCP) Specification](https://modelcontextprotocol.io/)\n- [Claude Desktop Documentation](https://docs.anthropic.com/claude/docs/claude-desktop)\n- [Cline Documentation](https://docs.cline.bot/)\n\n## 🤝 Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## 📝 Recent Updates\n\n### Version 1.9.0 (September 2025) - Security Enhancements\n\n#### 🔒 Enhanced HTML Sanitization\n- **Industry-Standard Sanitization**: Replaced custom regex-based HTML sanitization with `sanitize-html` library\n- **XSS Prevention**: Comprehensive protection against cross-site scripting attacks\n- **HTML Attribute Security**: Enhanced sanitization for HTML attribute contexts (quotes, ampersands)\n- **Format String Injection**: Fixed format string injection vulnerabilities in logging\n- **Security Testing**: Comprehensive test coverage for all sanitization functions\n\n#### 🛡️ Security Improvements\n- **CodeQL Compliance**: Resolved all security vulnerabilities identified by GitHub CodeQL analysis\n- **Input Validation**: Strengthened input validation and sanitization across all functions\n- **Dependency Updates**: Added `sanitize-html` for robust HTML content filtering\n- **Test Coverage**: Enhanced security test suite with XSS attack prevention verification\n\n### Version 1.5.0 (January 2025) - RAG v2\n\n#### 🤖 AI Document Exchange\n- **AI-Generated Documents**: MCP servers can now create documents in your library with full AI attribution\n- **Model Attribution Tracking**: Complete history of which AI models created or updated each document\n- **Advanced Document Search**: Filter by AI model, provider, date, tags, and source type\n- **Document Versioning**: Track changes and maintain version history for AI-generated content\n- **Multi-Source Support**: Documents from uploads, AI generation, or API integrations\n\n#### 🔍 Enhanced RAG Capabilities\n- **Semantic Search**: Improved relevance scoring with PostgreSQL full-text search\n- **Smart Filtering**: Filter results by visibility, model attribution, and document source\n- **Snippet Generation**: Automatic snippet extraction with keyword highlighting\n- **Performance Optimization**: Faster queries with optimized indexing\n\n### Version 1.2.0 (January 2025)\n\n#### 🔒 Security Enhancements\n\n- **URL Validation**: Comprehensive SSRF protection blocking private IPs, localhost, and dangerous ports\n- **Command Allowlisting**: Only approved commands (node, npx, python, etc.) can be executed\n- **Header Sanitization**: Protection against header injection attacks\n- **Lazy Authentication**: Improved Smithery compatibility with auth-free tool discovery\n\n#### 🚀 Performance Improvements\n\n- **Optimized Docker Builds**: Multi-stage builds for minimal container footprint\n- **Production Dependencies Only**: Test files and dev dependencies excluded from Docker images\n- **Resource Efficiency**: Designed for deployment in resource-constrained environments\n\n#### 🔧 Technical Improvements\n\n- Enhanced error handling in Streamable HTTP transport\n- Better session cleanup and memory management\n- Improved TypeScript types and code organization\n\n### Version 1.1.0 (December 2024)\n\n#### 🚀 New Features\n\n- **Streamable HTTP Support**: Connect to downstream MCP servers using the modern Streamable HTTP transport\n- **HTTP Server Mode**: Run the proxy as an HTTP server for web-based access\n- **Flexible Session Management**: Choose between stateless or stateful modes\n- **Authentication Options**: Optional Bearer token authentication for HTTP endpoints\n- **Health Monitoring**: `/health` endpoint for service monitoring\n\n#### 🔧 Technical Improvements\n\n- Updated MCP SDK to v1.13.1 for latest protocol support\n- Added Express.js integration for HTTP server functionality\n- Enhanced TypeScript types for better developer experience\n\n### Version 1.0.0 (June 2025)\n\n#### 🎯 Major Features\n- **Real-Time Notification System**: Track all MCP activities with comprehensive notification support\n- **RAG Integration**: Support for document-enhanced queries through the plugged.in App\n- **Inspector Scripts**: New automated testing tools for debugging and development\n- **Health Monitoring**: Built-in ping endpoint for connection monitoring\n\n#### 🔒 Security Enhancements\n- **Input Validation**: Industry-standard validation and sanitization for all inputs\n- **URL Security**: Enhanced URL validation with SSRF protection\n- **Environment Security**: Secure parsing of environment variables with dotenv\n- **Error Sanitization**: Prevents information disclosure in error responses\n\n#### 🐛 Bug Fixes\n- Fixed JSON-RPC protocol interference (stdout vs stderr separation)\n- Resolved localhost URL validation for development environments\n- Fixed API key handling in inspector scripts\n- Improved connection stability and memory management\n\n#### 🔧 Developer Tools\n- New inspector scripts for automated testing\n- Improved error messages and debugging capabilities\n- Structured logging with proper stderr usage\n- Enhanced TypeScript type safety\n\nSee [Release Notes](./RELEASE_NOTES_v1.0.0.md) for complete details.\n\n## 🧪 Testing and Development\n\n### Local Development\nTests are included for development purposes but are excluded from Docker builds to minimize the container footprint.\n\n```bash\n# Run tests locally\nnpm test\n# or\n./scripts/test-local.sh\n\n# Run tests in watch mode\nnpm run test:watch\n\n# Run tests with UI\nnpm run test:ui\n```\n\n### Lightweight Docker Builds\nThe Docker image is optimized for minimal footprint:\n- Multi-stage build process\n- Only production dependencies in final image\n- Test files and dev dependencies excluded\n- Optimized for resource-constrained environments\n\n```bash\n# Build optimized Docker image\ndocker build -t pluggedin-mcp .\n\n# Check image size\ndocker images pluggedin-mcp\n```\n\n## 📄 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## 🙏 Acknowledgements\n\n- Inspired by the [MCP Proxy Server](https://github.com/adamwattis/mcp-proxy-server/)\n- Built on the [Model Context Protocol](https://modelcontextprotocol.io/)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "proxy",
        "aggregators",
        "servers",
        "mcp proxy",
        "comprehensive proxy",
        "mcp servers"
      ],
      "category": "aggregators"
    },
    "WayStation-ai--mcp": {
      "owner": "WayStation-ai",
      "name": "mcp",
      "url": "https://github.com/waystation-ai/mcp",
      "imageUrl": "",
      "description": "Seamlessly and securely connect Claude Desktop and other MCP hosts to your favorite apps (Notion, Slack, Monday, Airtable, etc.). Takes less than 90 secs.",
      "stars": 32,
      "forks": 7,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-26T16:29:33Z",
      "readme_content": "# What is WayStation\n<img src=\"https://waystation.ai/images/logo.svg\" width=\"50\" align=\"left\"/> [WayStation](https://waystation.ai) connects Claude Desktop, ChatGPT and any MCP host with the productivity tools you use daily such as Notion, Monday, Airtable, Jira etc. through a no-code, secure integration hub. \n\n***The original local WayStation MCP server has been deprecated in favor of the new remote MCP server hosted at https://waystation.ai/mcp. Please refer to the new WayStation MCP server documentation here***\n\n## Overview\nWayStation MCP server is a universal remote MCP server that seamlessly connects Claude (and other clients) to a broad range of productivity tools, including Notion, Monday, AirTable, etc.\n\n- WayStation MCP supports both Streamable HTTPS and SSE transports\n- The default endpoint is https://waystation.ai/mcp. It does transport negotiation and authorization if necessary\n- WayStation also provides preauthenticated individual endpoints like https://waystation.ai/mcp/Iddq66dIdkfARDNb3K. Any registered user can get one in their dashboard at https://waystation.ai/dashboard\n\n## Supported providers\n- WayStation supports the following productivity apps: [Notion](https://waystation.ai/connect/notion), [Monday](https://waystation.ai/connect/monday), [Asana](https://waystation.ai/connect/asana), [Linear](https://waystation.ai/connect/linear), [Atlassian JIRA/Confluence](https://waystation.ai/connect/atlassian), [Slack](https://waystation.ai/connect/slack), [Teams](https://waystation.ai/connect/teams), [Google Drive](https://waystation.ai/connect/gdrive) (including Docs and Sheets), [Office 365](https://waystation.ai/connect/office), [Airtable](https://waystation.ai/connect/airtable), [Miro](https://waystation.ai/connect/miro), [Intercom](https://waystation.ai/connect/intercom), [PayPal](https://waystation.ai/connect/paypal).\n- Users can browse available integrations/providers in the [Integrations Marketplace](https://waystation.ai/marketplace)\n- New integrations are added regularly based on customer requests or community contributions. If you have an integration request, please contact us at support@waystation.ai.\n- Users can connect their apps in the [dashboard](https://waystation.ai/dashboard). The connection process may vary by app but generally involves OAuth2 authentication flow with some additional steps for certain apps.\n\n## Supported AI apps\n- WayStation remote MCP was tested with Claude, Cursor, Cline, WindSurf, and MCP-remote STDIO proxy provider\n- For Claude, user should go into their Settings, then Integrations and click \"Add Integration\". Then enter \"WayStation\" as the Server Name and unique MCP URL from user's dashboard\n- For Cline, user should simply go into the MCP Server screen, switch to the Remote Servers tab, enter \"WayStation\" as the Server Name and unique MCP URL from user's dashboard\n- For Cursor, user should go to the Cursor Settings, MCP tab and click \"Add new global MCP server\". In mcp.json file user should add the entry for WayStation as following:\n```json\n\"WayStation\": {\n      \"url\": \"https://waystation.ai/mcp/<user_unique_id>\"\n}\n```\n\n## Use Cases\nWayStation supports a variety of productivity and automation use cases listed below:\n- [Project Management](https://waystation.ai/ai/project-management)\n- [Task Automation](https://waystation.ai/ai/task-automation)\n- [Meeting Summaries & Action Items](https://waystation.ai/ai/meeting-summaries)\n- [Workflow Automation & Process Optimization](https://waystation.ai/ai/workflow-automation)\n- [Resource & Capacity Planning](https://waystation.ai/ai/resource-capacity-planning)\n- [Risk & Issue Management](https://waystation.ai/ai/risk-issue-management)\n- [Reporting & Insights](https://waystation.ai/ai/reporting-insights)\n- [Portfolio Management](https://waystation.ai/ai/portfolio-management)\n- [Team Collaboration Assistant](https://waystation.ai/ai/team-collaboration-assistant)\n- [Creative Production Management](https://waystation.ai/ai/creative-production-management)\n- [Campaign Management](https://waystation.ai/ai/campaign-management)\n- [Product Management & Roadmapping](https://waystation.ai/ai/product-management-roadmapping)\n- [Product Launch Coordination](https://waystation.ai/ai/product-launch-coordination)\n- [Operations Management](https://waystation.ai/ai/operations-management)\n- [IT Project Coordination](https://waystation.ai/ai/it-project-coordination)\n- [Project Intake & Triage](https://waystation.ai/ai/project-intake-triage)\n- [Knowledge Management Integration](https://waystation.ai/ai/knowledge-management-integration)\n- [Goal Tracking & OKR Alignment](https://waystation.ai/ai/goal-tracking-okr-alignment)\n- [Compliance & Audit Trail Management](https://waystation.ai/ai/compliance-audit-trail)\n- [Timeline & Deadline Optimization](https://waystation.ai/ai/timeline-deadline-optimization)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "servers",
        "aggregators",
        "mcp server",
        "mcp seamlessly",
        "desktop mcp"
      ],
      "category": "aggregators"
    },
    "YangLiangwei--PersonalizationMCP": {
      "owner": "YangLiangwei",
      "name": "PersonalizationMCP",
      "url": "https://github.com/YangLiangwei/PersonalizationMCP",
      "imageUrl": "",
      "description": "Comprehensive personal data aggregation MCP server with Steam, YouTube, Bilibili, Spotify, Reddit and other platforms integrations. Features OAuth2 authentication, automatic token management, and 90+ tools for gaming, music, video, and social platform data access.",
      "stars": 6,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-26T23:38:24Z",
      "readme_content": "# 🎯 PersonalizationMCP\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)\n[![MCP](https://img.shields.io/badge/MCP-Compatible-green.svg)](https://modelcontextprotocol.io/)\n\nA unified personal data hub built on MCP (Model Context Protocol) that allows AI assistants to access your digital life from multiple platforms, providing truly personalized and contextual interactions.\n\n> 📖 **中文文档**: [README_zh.md](README_zh.md)\n\n## 🚀 Quick Start\n\n1. **Clone the repository**\n   ```bash\n   git clone https://github.com/YangLiangwei/PersonalizationMCP.git\n   cd PersonalizationMCP\n   ```\n\n2. **Install dependencies**\n   \n   > 📖 **See detailed installation instructions: [Installation and Setup](#-installation-and-setup)**\n\n3. **Configure your API keys**\n   ```bash\n   cp config.example config\n   # Edit config file with your actual API keys\n   ```\n\n4. **Add to Cursor settings**\n   \n   > 📖 **See detailed MCP configuration: [Cursor Configuration](#-cursor-configuration)**\n\n## 🌟 Features\n\n### 🎮 Steam Integration\n- Get your game library with detailed statistics and playtime\n- View recent gaming activity and currently playing games\n- Get detailed game information and achievements\n- Compare games with friends and get recommendations\n- Analyze gaming habits and preferences\n\n### 🎥 YouTube Integration\n- Search YouTube videos and get detailed video information\n- Get channel information and trending videos\n- Access personal data with OAuth2 (subscriptions, playlists, liked videos)\n- Get personalized recommendations based on your viewing history\n- 🔄 **Smart Token Management** - Automatically detect and refresh expired OAuth2 tokens\n- 🛡️ **Maintenance-Free Configuration** - Prioritize token files, no need to manually update MCP configuration\n\n### 📺 Bilibili Integration\n- Get user profile information and statistics\n- Search videos and get detailed video information\n- Access personal data (watch history, favorites, liked videos, coin history)\n- Get following list and user-uploaded videos\n- Browse \"to view later\" list and personal collections\n\n### 🎵 Spotify Integration\n- Complete OAuth2 authentication with automatic token management\n- Get user profile and music library data\n- Access top artists, tracks, and recently played music\n- Social features: follow/unfollow artists and playlists\n- Library management: saved tracks, albums, shows, episodes, audiobooks\n- Playlist operations: view and manage personal playlists\n\n### 💬 Reddit Integration\n- Complete OAuth2 authentication with automatic token management\n- Access user account information, karma breakdown, and preferences\n- Get submitted posts, comments, and user activity overview\n- View saved content, hidden posts, and voting history\n- Explore subscribed communities and moderation permissions\n- Message system access (inbox, unread, sent messages)\n\n## 📦 Installation and Setup\n\n### 1. Install Dependencies\n\nDue to the complexity of bilibili-api dependencies (especially lxml compilation issues), installation requires specific steps. Choose one of the methods below:\n\n#### **Option A: Using conda (Recommended)**\n```bash\n# 1. Create conda environment\nconda create -n personalhub python=3.12\nconda activate personalhub\n\n# 2. Install lxml via conda (avoids compilation issues)\nconda install lxml\n\n# 3. Install remaining packages\npip install bilibili-api --no-deps\npip install -r requirements.txt\n```\n\n#### **Option B: Using uv**\n```bash\n# 1. Install uv if not already installed\n# Visit: https://docs.astral.sh/uv/getting-started/installation/\n\n# 2. Create environment and install core dependencies\nuv venv\nuv sync\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# 3. Install bilibili-api and its dependencies separately (due to version conflicts)\nuv pip install lxml  # Install lxml first (uses precompiled wheel)\nuv pip install bilibili-api --no-deps  # Install bilibili-api without dependencies\nuv pip install aiohttp beautifulsoup4 colorama PyYAML brotli urllib3  # Install required dependencies\n```\n\n#### **Option C: Using pip (Manual Multi-Step Installation)**\n```bash\n# 1. Create virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# 2. Install packages in specific order to avoid compilation issues\npip install lxml  # Install lxml first (uses precompiled wheel)\npip install bilibili-api --no-deps  # Install bilibili-api without dependencies\npip install -r requirements.txt  # Install all other dependencies\n```\n\n> **⚠️ Important**: The bilibili-api package has complex dependency requirements that can cause compilation failures on some systems. The multi-step installation approach ensures compatibility by installing lxml first, then bilibili-api without its conflicting dependencies, and finally all other required packages.\n\n### 2. Configuration Setup\n\nCopy the example configuration file and fill in your credentials:\n```bash\ncp config.example config\n```\n\nThen edit the `config` file with your actual API keys and tokens.\n\n## 🔧 Platform Configuration\n\n### 🎮 Steam API Setup\n\n> 📖 **Detailed setup guide**: [platforms/steam/README.md](platforms/steam/README.md) | [中文指南](platforms/steam/README_zh.md)\n\n**Quick summary**: Get Steam API key and User ID, then configure:\n```bash\nSTEAM_API_KEY=your_steam_api_key_here\nSTEAM_USER_ID=your_steam_user_id_here\n```\n\n### 🎥 YouTube API Setup\n\n> 📖 **Detailed setup guide**: [platforms/youtube/README.md](platforms/youtube/README.md) | [中文指南](platforms/youtube/README_zh.md)\n\n**Quick summary**: \n1. Get YouTube API key from Google Cloud Console\n2. For personal data access, set up OAuth2 with \"TV and Limited Input device\" type\n3. Use MCP tools for easy authentication\n\n**Configuration:**\n```bash\nYOUTUBE_API_KEY=your_youtube_api_key_here\n# OAuth2 tokens are managed automatically after setup\n```\n\n### 📺 Bilibili Setup\n\n> 📖 **Detailed setup guide**: [platforms/bilibili/README.md](platforms/bilibili/README.md) | [中文指南](platforms/bilibili/README_zh.md)\n\n**Quick summary**: Extract cookies from your browser after logging into Bilibili\n\n**Configuration:**\n```bash\nBILIBILI_SESSDATA=your_bilibili_sessdata_cookie\nBILIBILI_BILI_JCT=your_bilibili_bili_jct_cookie\nBILIBILI_BUVID3=your_bilibili_buvid3_cookie\n```\n\n### 🎵 Spotify API Setup\n\n> 📖 **Detailed setup guide**: [platforms/spotify/README.md](platforms/spotify/README.md) | [中文指南](platforms/spotify/README_zh.md)\n\n**Quick summary**: \n1. Create a Spotify app in [Spotify Developer Dashboard](https://developer.spotify.com/dashboard)\n2. Configure redirect URIs in your app settings\n3. Use MCP tools for OAuth2 authentication with automatic token management\n\n**Configuration:**\n```bash\nSPOTIFY_CLIENT_ID=your_spotify_client_id_here\nSPOTIFY_CLIENT_SECRET=your_spotify_client_secret_here\nSPOTIFY_REDIRECT_URI=https://example.com/callback\n# OAuth2 tokens are managed automatically after authentication\n```\n\n### 💬 Reddit API Setup\n\n> 📖 **Detailed setup guide**: [platforms/reddit/README.md](platforms/reddit/README.md) | [中文指南](platforms/reddit/README_zh.md)\n\n**Quick summary**: \n1. Create a Reddit app in [Reddit Apps](https://www.reddit.com/prefs/apps)\n2. Configure as \"web app\" with redirect URI\n3. Use MCP tools for OAuth2 authentication with automatic token management\n\n**Configuration:**\n```bash\nREDDIT_CLIENT_ID=your_reddit_client_id_here\nREDDIT_CLIENT_SECRET=your_reddit_client_secret_here\nREDDIT_REDIRECT_URI=http://localhost:8888/callback\n# OAuth2 tokens are managed automatically after authentication\n```\n\n## 🖥️ Cursor Configuration\n\nAdd the MCP server to your Cursor settings:\n\n**If using conda:**\n```json\n{\n  \"mcpServers\": {\n    \"personalhub\": {\n      \"command\": \"/path/to/your/conda/envs/personalhub/bin/python\",\n      \"args\": [\"/absolute/path/to/your/project/server.py\"],\n      \"env\": {\n        \"STEAM_API_KEY\": \"your_steam_api_key\",\n        \"STEAM_USER_ID\": \"your_steam_user_id\",\n        \"YOUTUBE_API_KEY\": \"your_youtube_api_key\",\n        \"BILIBILI_SESSDATA\": \"your_bilibili_sessdata\",\n        \"BILIBILI_BILI_JCT\": \"your_bilibili_bili_jct\",\n        \"BILIBILI_BUVID3\": \"your_bilibili_buvid3\",\n        \"REDDIT_CLIENT_ID\": \"your_reddit_client_id\",\n        \"REDDIT_CLIENT_SECRET\": \"your_reddit_client_secret\"\n      }\n    }\n  }\n}\n```\n\n**If using uv:**\n```json\n{\n  \"mcpServers\": {\n    \"personalhub\": {\n      \"command\": \"uv\",\n      \"args\": [\"run\", \"python\", \"/absolute/path/to/your/project/server.py\"],\n      \"env\": {\n        \"STEAM_API_KEY\": \"your_steam_api_key\",\n        \"STEAM_USER_ID\": \"your_steam_user_id\",\n        \"YOUTUBE_API_KEY\": \"your_youtube_api_key\",\n        \"BILIBILI_SESSDATA\": \"your_bilibili_sessdata\",\n        \"BILIBILI_BILI_JCT\": \"your_bilibili_bili_jct\",\n        \"BILIBILI_BUVID3\": \"your_bilibili_buvid3\",\n        \"REDDIT_CLIENT_ID\": \"your_reddit_client_id\",\n        \"REDDIT_CLIENT_SECRET\": \"your_reddit_client_secret\"\n      }\n    }\n  }\n}\n```\n\n**If using pip with virtual environment:**\n```json\n{\n  \"mcpServers\": {\n    \"personalhub\": {\n      \"command\": \"/absolute/path/to/your/project/venv/bin/python\",\n      \"args\": [\"/absolute/path/to/your/project/server.py\"],\n      \"env\": {\n        \"STEAM_API_KEY\": \"your_steam_api_key\",\n        \"STEAM_USER_ID\": \"your_steam_user_id\",\n        \"YOUTUBE_API_KEY\": \"your_youtube_api_key\",\n        \"BILIBILI_SESSDATA\": \"your_bilibili_sessdata\",\n        \"BILIBILI_BILI_JCT\": \"your_bilibili_bili_jct\",\n        \"BILIBILI_BUVID3\": \"your_bilibili_buvid3\",\n        \"REDDIT_CLIENT_ID\": \"your_reddit_client_id\",\n        \"REDDIT_CLIENT_SECRET\": \"your_reddit_client_secret\"\n      }\n    }\n  }\n}\n```\n\n**Note**: For YouTube OAuth2 tokens, we recommend using automatic token management. No need to add `YOUTUBE_ACCESS_TOKEN` in the above configuration. The system will automatically read and refresh tokens from the `youtube_tokens.json` file.\n\n## 🔄 YouTube Smart Token Management\n\nThis system implements intelligent YouTube OAuth2 token management with the following features:\n\n### ✨ Core Features\n- **Automatic Expiration Detection**: System automatically detects tokens expiring within 5 minutes\n- **Auto-Refresh**: No manual intervention needed, system automatically refreshes expired tokens\n- **Smart Priority**: Prioritizes token files, with environment variables as backup\n- **Maintenance-Free Configuration**: No need to manually update tokens in MCP configuration files\n\n### 🔧 Token Priority\n1. **Explicitly passed access_token parameter** (Highest priority)\n2. **Auto-refresh tokens from token file** (Recommended method)\n3. **Tokens from environment variables** (Backup method)\n\n\nThe system automatically handles all token management - no manual maintenance required!\n\n## 🛠️ Available Tools\n\n### 🎮 Steam Tools\n- `get_steam_library()` - Get your game library with statistics\n- `get_steam_recent_activity()` - Get recent gaming activity\n- `get_steam_friends()` - Get your Steam friends list\n- `get_steam_profile()` - Get Steam profile information\n- `get_player_achievements(app_id)` - Get achievements for a specific game\n- `get_user_game_stats(app_id)` - Get detailed game statistics\n- `get_friends_current_games()` - See what games your friends are playing\n- `compare_games_with_friend(friend_steamid)` - Compare game libraries\n- `get_friend_game_recommendations(friend_steamid)` - Get game recommendations\n\n### 🎥 YouTube Tools\n- `search_youtube_videos(query)` - Search for videos\n- `get_video_details(video_id)` - Get detailed video information\n- `get_channel_info(channel_id)` - Get channel information\n- `get_trending_videos()` - Get trending videos\n- `get_youtube_subscriptions()` - Get your subscriptions (OAuth2 required)\n- `get_youtube_playlists()` - Get your playlists (OAuth2 required)\n- `get_youtube_liked_videos()` - Get your liked videos (OAuth2 required)\n- `refresh_youtube_token()` - Manually refresh OAuth2 token\n- `get_youtube_token_status()` - Check OAuth2 token status\n\n### 📺 Bilibili Tools\n- `get_bilibili_user_info(uid)` - Get user profile information\n- `get_my_bilibili_profile()` - Get your own profile\n- `search_bilibili_videos(keyword)` - Search for videos\n- `get_bilibili_video_info(bvid)` - Get detailed video information\n- `get_bilibili_user_videos(uid)` - Get videos uploaded by a user\n- `get_bilibili_following_list()` - Get your following list\n- `get_bilibili_watch_history()` - Get your watch history\n- `get_bilibili_favorites()` - Get your favorite videos\n- `get_bilibili_liked_videos()` - Get your liked videos\n- `get_bilibili_coin_videos()` - Get videos you've given coins to\n- `get_bilibili_toview_list()` - Get your \"to view later\" list\n\n### 🎵 Spotify Tools (17 Total)\n\n**Authentication & Configuration (7 tools):**\n- `test_spotify_credentials()` - Test API credentials\n- `setup_spotify_oauth()` - Initialize OAuth flow\n- `complete_spotify_oauth()` - Complete OAuth authentication\n- `get_spotify_token_status()` - Get token status\n- `refresh_spotify_token()` - Manual token refresh\n\n**Music Discovery & Social (9 tools):**\n- `get_current_user_profile()` - Get your Spotify profile\n- `get_user_top_items()` - Get top artists/tracks\n- `get_user_recently_played()` - Get recently played music\n- `get_followed_artists()` - Get followed artists\n- `follow_artists_or_users()` / `unfollow_artists_or_users()` - Social features\n\n**Library & Playlists (6 tools):**\n- `get_user_saved_tracks()` / `get_user_saved_albums()` - Library management\n- `get_user_saved_shows()` / `get_user_saved_episodes()` - Podcast content\n- `get_current_user_playlists()` / `get_playlist_items()` - Playlist operations\n\n### 💬 Reddit Tools (25 Total)\n\n**Authentication & Configuration (6 tools):**\n- `test_reddit_credentials()` - Test API credentials\n- `setup_reddit_oauth()` - Initialize OAuth flow\n- `complete_reddit_oauth()` - Complete OAuth authentication\n- `get_reddit_token_status()` - Get token status\n- `refresh_reddit_token()` - Manual token refresh\n- `auto_refresh_reddit_token_if_needed()` - Auto token management\n\n**Account Information (6 tools):**\n- `get_user_subreddits()` - Get subscribed communities\n- `get_user_trophies()` - Get Reddit trophies and achievements\n- `get_user_preferences()` - Get account settings\n- `get_user_karma_breakdown()` - Get karma distribution\n- `get_moderated_subreddits()` - Get moderated communities\n- `get_contributor_subreddits()` - Get contributor permissions\n\n**Content & Activity (10 tools):**\n- `get_user_submitted_posts()` - Get submitted posts\n- `get_user_comments()` - Get comment history\n- `get_user_overview()` - Get mixed activity timeline\n- `get_saved_content()` - Get saved posts/comments\n- `get_hidden_posts()` - Get hidden content\n- `get_upvoted_content()` - Get upvoted content\n- `get_downvoted_content()` - Get downvoted content\n\n**Messaging (3 tools):**\n- `get_inbox_messages()` - Get inbox messages\n- `get_unread_messages()` - Get unread messages\n- `get_sent_messages()` - Get sent messages\n\n### 🔧 System Tools\n- `test_connection()` - Test if MCP server is working\n- `get_personalization_status()` - Get overall platform status\n- `test_steam_credentials()` - Test Steam API configuration\n- `test_youtube_credentials()` - Test YouTube API configuration\n- `test_bilibili_credentials()` - Test Bilibili configuration\n- `test_spotify_credentials()` - Test Spotify API configuration\n- `test_reddit_credentials()` - Test Reddit API configuration\n\n## 💬 Usage Examples\n\n### Gaming Analysis\n- \"What games have I been playing recently?\"\n- \"Show me my most played Steam games\"\n- \"What games do my friends recommend?\"\n- \"Compare my game library with my friend's\"\n\n### Video Content Discovery\n- \"Find YouTube videos about machine learning\"\n- \"What are the trending videos on YouTube today?\"\n- \"Show me my YouTube liked videos\"\n- \"Find popular Bilibili videos about programming\"\n\n### Personal Data Insights\n- \"Analyze my gaming habits and preferences\"\n- \"What type of YouTube content do I watch most?\"\n- \"Show me my Bilibili favorites and liked videos\"\n\n### Music & Audio Analysis\n- \"What artists have I been listening to most lately on Spotify?\"\n- \"Show me my recently played music and find patterns\"\n- \"What are my top tracks from the past month?\"\n- \"Find new music recommendations based on my Spotify data\"\n\n### Reddit Activity Analysis\n- \"What communities am I most active in on Reddit?\"\n- \"Show me my recent Reddit posts and comments\"\n- \"What's my karma breakdown across different subreddits?\"\n- \"Find my saved Reddit content and analyze my interests\"\n\n## 🚀 Development\n\n### Running the Server\n\n**If using conda:**\n```bash\nconda activate personalhub\npython server.py\n```\n\n**If using uv:**\n```bash\nuv run python server.py\n```\n\n**If using pip with virtual environment:**\n```bash\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\npython server.py\n```\n\n### Testing Configuration\nUse these tools to test your setup:\n```python\n# Test individual platforms\ntest_steam_credentials()\ntest_youtube_credentials()\ntest_bilibili_credentials()\ntest_reddit_credentials()\n\n# Check overall status\nget_personalization_status()\n```\n\n### Adding New Platforms\n1. Create a new `platform_mcp.py` file\n2. Implement the platform-specific tools using `@mcp.tool()` decorator\n3. Add setup function to `server.py`\n4. Update configuration files and documentation\n\n## 🔒 Privacy and Security\n\n- **Local Storage**: All API keys and tokens are stored locally on your machine\n- **No Data Transmission**: Your personal data is never transmitted to third parties\n- **Direct API Calls**: All API calls are made directly from your machine to the respective platforms\n- **Secure Configuration**: Use environment variables or local config files\n- **Regular Updates**: Rotate API keys and tokens regularly for security\n\n### Security Best Practices\n1. **Don't commit sensitive files**: Ensure `config`, `.env`, `myinfo.json`, and `youtube_tokens.json` are in `.gitignore`\n2. **Update cookies regularly**: Bilibili cookies expire and need periodic updates\n3. **Use environment variables**: In production, use system environment variables\n4. **File permissions**: Ensure config files are only readable by you\n5. **YouTube token security**: The system automatically manages OAuth2 tokens securely in local files\n6. **Gradual configuration**: You can configure platforms incrementally - missing credentials won't cause errors\n\n## 🆘 Troubleshooting\n\n### Common Issues\n\n**Q: Bilibili cookies not working?**\nA: Cookies expire regularly. Re-extract them from your browser and update your config.\n\n**Q: Steam API rate limits?**\nA: Steam API has rate limits. Avoid frequent calls and implement reasonable delays.\n\n**Q: YouTube API quota exceeded?**\nA: YouTube API has daily quotas. You can request quota increases or optimize your usage.\n\n**Q: YouTube OAuth2 token expired?**\nA: The system automatically refreshes expired tokens. If manual refresh is needed, use `refresh_youtube_token()`.\n\n**Q: Can I use only some platforms?**\nA: Yes! You can configure only the platforms you want to use. Missing credentials won't cause errors.\n\n**Q: How to verify my configuration?**\nA: Use the test tools or call `get_personalization_status()` to check all platforms.\n\n### Getting Help\n1. Check configuration file format\n2. Verify API keys and cookies are valid\n3. Review MCP server logs\n4. Use test tools to validate each platform configuration\n\n## 🤝 Contributing\n\nContributions are welcome! Here's how you can help:\n\n1. **Fork the repository**\n2. **Create a feature branch**: `git checkout -b feature/amazing-feature`\n3. **Make your changes** and add tests if applicable\n4. **Commit your changes**: `git commit -m 'Add amazing feature'`\n5. **Push to the branch**: `git push origin feature/amazing-feature`\n6. **Open a Pull Request**\n\n### Adding New Platforms\n\nWant to add support for a new platform? Follow these steps:\n\n1. Create a new `platform_mcp.py` file (e.g., `spotify_mcp.py`)\n2. Implement platform-specific tools using the `@mcp.tool()` decorator\n3. Add a setup function and integrate it in `server.py`\n4. Update configuration files and documentation\n5. Add tests and examples\n\n## 📄 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## 🙏 Acknowledgments\n\n- [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) for the amazing protocol\n- [Anthropic](https://www.anthropic.com/) for Claude and MCP development\n- All the platform APIs that make this integration possible\n\n## ⭐ Star History\n\nIf you find this project useful, please consider giving it a star on GitHub!\n\n---\n\n**Made with ❤️ for connecting your digital life with AI**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "aggregators",
        "personalizationmcp",
        "servers",
        "aggregators servers",
        "yangliangwei personalizationmcp",
        "mcp server"
      ],
      "category": "aggregators"
    },
    "duaraghav8--MCPJungle": {
      "owner": "duaraghav8",
      "name": "MCPJungle",
      "url": "https://github.com/duaraghav8/MCPJungle",
      "imageUrl": "",
      "description": "Self-hosted MCP Server registry for enterprise AI Agents",
      "stars": 571,
      "forks": 72,
      "license": "Mozilla Public License 2.0",
      "language": "Go",
      "updated_at": "2025-10-04T09:50:29Z",
      "readme_content": "<h1 align=\"center\">\n  :deciduous_tree: MCPJungle :deciduous_tree:\n</h1>\n<p align=\"center\">\n  Self-hosted MCP Gateway for your private AI agents\n</p>\n<p align=\"center\">\n  <a href=\"https://discord.gg/CapV4Z3krk\" style=\"text-decoration: none;\">\n    <img src=\"https://img.shields.io/badge/Discord-MCPJungle-5865F2?style=flat-square&logo=discord&logoColor=white\" alt=\"Discord\" style=\"max-width: 100%;\">\n  </a>\n</p>\n\nMCPJungle is a single source-of-truth registry for all [Model Context Protocol](https://modelcontextprotocol.io/introduction) Servers running in your Organisation.\n\n🧑‍💻 Developers use it to register & manage MCP servers and the tools they provide from a central place.\n\n🤖 MCP Clients use it to discover and consume all these tools from a single \"Gateway\" MCP Server.\n\n![diagram](./assets/mcpjungle-diagram/mcpjungle-diagram.png)\n\n<p align=\"center\">MCPJungle is the only MCP Server your AI agents need to connect to!</p>\n\n# Who should use MCPJungle?\n1. **Developers** using MCP Clients like Claude & Cursor that need to access MCP servers for tool-calling\n2. **Developers** building production-grade AI Agents that need to access MCP servers with built-in security, privacy and Access Control.\n3. **Organisations** wanting to view & manage all MCP client-server interactions from a central place. Hosted in their own datacenter 🔒\n\n# 📋 Table of Contents\n\n- [Quick Start guide](#quickstart-guide)\n- [Installation](#installation)\n- [Usage](#usage)\n  - [Server](#server)\n    - [Running mcpjungle server inside Docker](#running-inside-docker)\n    - [Running mcpjungle server directly on the host machine](#running-directly-on-host)\n  - [Client](#client)\n    - [Adding Streamable HTTP-based MCP servers](#registering-streamable-http-based-servers)\n    - [Adding STDIO-based MCP servers](#registering-stdio-based-servers)\n    - [Removing MCP servers](#deregistering-mcp-servers)\n  - [Connect to mcpjungle from Claude](#claude)\n  - [Connect to mcpjungle from Cursor](#cursor)\n  - [Enabling/Disabling Tools globally](#enablingdisabling-tools)\n  - [Tool Groups](#tool-groups)\n  - [Authentication](#authentication)\n  - [Enterprise features](#enterprise-features-)\n    - [Access Control](#access-control)\n    - [OpenTelemetry](#opentelemetry)\n- [Limitations](#current-limitations-)\n- [Contributing](#contributing-)\n\n# Quickstart guide\nThis quickstart guide will show you how to:\n1. Start the MCPJungle server locally using `docker compose`\n2. Register a simple MCP server in mcpjungle\n3. Connect your Claude to mcpjungle to access your MCP tools\n\n## Start the server\n```bash\ncurl -O https://raw.githubusercontent.com/mcpjungle/MCPJungle/refs/heads/main/docker-compose.yaml\ndocker compose up -d\n```\n\n## Register MCP servers\nDownload the `mcpjungle` CLI on your local machine either using brew or directly from the [Releases Page](https://github.com/mcpjungle/MCPJungle/releases).\n```bash\nbrew install mcpjungle/mcpjungle/mcpjungle\n```\n\nThe CLI lets you manage everything in mcpjungle.\n\nNext, lets add an MCP server to mcpjungle using the CLI. For this example, we'll use [context7](https://context7.com/).\n```bash\nmcpjungle register --name context7 --url https://mcp.context7.com/mcp\n```\n\n## Connect to mcpjungle\n\nUse the following configuration for your Claude MCP servers config:\n```json\n{\n  \"mcpServers\": {\n    \"mcpjungle\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-remote\",\n        \"http://localhost:8080/mcp\",\n        \"--allow-http\"\n      ]\n    }\n  }\n}\n```\n\nOnce mcpjungle is added as an MCP to your Claude, try asking it the following:\n```text\nUse context7 to get the documentation for `/lodash/lodash`\n```\n\nClaude will then attempt to call the `context7__get-library-docs` tool via MCPJungle, which will return the documentation for the Lodash library.\n\n<p align=\"center\">\n  <img src=\"./assets/quickstart-claude-call-tool.png\" alt=\"claude calls context7 tool via mcpjungle\" height=\"400\">\n</p>\n\nCongratulations! 🎉\n\nYou have successfully registered a remote MCP server in MCPJungle and called one of its tools via Claude\n\nYou can now proceed to play around with the mcpjungle and explore the documentation & CLI for more details.\n\n# Installation\nMCPJungle is shipped as a stand-alone binary.\n\nYou can either download it from the [Releases](https://github.com/mcpjungle/MCPJungle/releases) Page or use [Homebrew](https://brew.sh/) to install it:\n\n```bash\nbrew install mcpjungle/mcpjungle/mcpjungle\n```\n\nVerify your installation by running\n\n```bash\nmcpjungle version\n```\n\n> [!IMPORTANT]\n> On MacOS, you will have to use homebrew because the compiled binary is not [Notarized](https://developer.apple.com/documentation/security/notarizing-macos-software-before-distribution) yet.\n\nMCPJungle provides a Docker image which is useful for running the registry server (more about it later).\n\n```bash\ndocker pull mcpjungle/mcpjungle\n```\n\n# Usage\nMCPJungle has a Client-Server architecture and the binary lets you run both the Server and the Client.\n\n## Server\nThe MCPJungle server is responsible for managing all the MCP servers registered in it and providing a unified MCP gateway for AI Agents to discover and call tools provided by these registered servers.\n\nThe gateway itself runs over streamable http transport and is accessible at the `/mcp` endpoint.\n\n### Running inside Docker\nFor running the MCPJungle server locally, docker compose is the recommended way:\n```shell\n# docker-compose.yaml is optimized for individuals running mcpjungle on their local machines for personal use.\n# mcpjungle will run in `development` mode by default.\ncurl -O https://raw.githubusercontent.com/mcpjungle/MCPJungle/refs/heads/main/docker-compose.yaml\n\ndocker compose up -d\n\n# docker-compose.prod.yaml is optimized for orgs deploying mcpjungle on a remote server for multiple users.\n# mcpjungle will run in `enterprise` mode by default, which enables enterprise features.\ncurl -O https://raw.githubusercontent.com/mcpjungle/MCPJungle/refs/heads/main/docker-compose.prod.yaml\n\ndocker compose -f docker-compose.prod.yaml up -d\n```\n\n> [!NOTE]\n> The `enterprise` mode used to be called `production` mode.\n> The mode has now been renamed for clarity. Everything else remains the same.\n\nThis will start the MCPJungle server along with a persistent Postgres database container.\n\nYou can quickly verify that the server is running:\n```bash\ncurl http://localhost:8080/health\n```\n\nIf you plan on registering stdio-based MCP servers that rely on `npx` or `uvx`, use mcpjungle's `stdio` tagged docker image instead.\n```bash\nMCPJUNGLE_IMAGE_TAG=latest-stdio docker compose up -d\n```\n\n> [!NOTE]\n> If you're using `docker-compose.yaml`, this is already the default image tag.\n> You only need to specify the stdio image tag if you're using `docker-compose.prod.yaml`.\n\nThis image is significantly larger. But it is very convenient and recommended for running locally when you rely on stdio-based MCP servers.\n\nFor example, if you only want to register remote mcp servers like context7 and deepwiki, you can use the standard (minimal) image.\n\nBut if you also want to use stdio-based servers like `filesystem`, `time`, `github`, etc., you should use the `stdio`-tagged image instead.\n\n> [!NOTE]\n> If your stdio servers rely on tools other than `npx` or `uvx`, you will have to create a custom docker image that includes those dependencies along with the mcpjungle binary.\n\n**Production Deployment**\n\nThe default [MCPJungle Docker image](https://hub.docker.com/r/mcpjungle/mcpjungle) is very lightweight - it only contains a minimal base image and the `mcpjungle` binary.\n\nIt is therefore suitable and recommended for production deployments.\n\nFor the database, we recommend you deploy a separate Postgres DB cluster and supply its endpoint to mcpjungle (see [Database](#database) section below).\n\nYou can see the definitions of the [standard Docker image](./Dockerfile) and the [stdio Docker image](./stdio.Dockerfile).\n\n### Running directly on host\nYou can also run the server directly on your host machine using the binary:\n\n```bash\nmcpjungle start\n```\n\nThis starts the main registry server and MCP gateway, accessible on port `8080` by default.\n\n\n\n### Database\nThe mcpjungle server relies on a database and by default, creates a SQLite DB in the current working directory.\n\nThis is okay when you're just testing things out locally.\n\nAlternatively, you can supply a DSN for a Postgresql database to the server:\n\n```bash\nexport DATABASE_URL=postgres://admin:root@localhost:5432/mcpjungle_db\n\n#run as container\ndocker run mcpjungle/mcpjungle:latest\n\n# or run directly\nmcpjungle start\n```\n\n## Client\nOnce the server is up, you can use the mcpjungle CLI to interact with it.\n\nMCPJungle currently supports MCP servers using [stdio](https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#stdio) and [Streamable HTTP](https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#streamable-http) Transports.\n\nLet's see how to register them in mcpjungle.\n\n### Registering streamable HTTP-based servers\nLet's say you're already running a streamable http MCP server locally at `http://127.0.0.1:8000/mcp` which provides basic math tools like `add`, `subtract`, etc.\n\nYou can register this MCP server with MCPJungle:\n```bash\nmcpjungle register --name calculator --description \"Provides some basic math tools\" --url http://127.0.0.1:8000/mcp\n```\n\nIf you used docker compose to run the server, and you're not on Linux, you will have to use `host.docker.internal` instead of your local loopback address.\n```bash\nmcpjungle register --name calculator --description \"Provides some basic math tools\" --url http://host.docker.internal:8000/mcp\n```\n\nThe registry will now start tracking this MCP server and load its tools.\n\n![register a MCP server in MCPJungle](./assets/register-mcp-server.png)\n\nYou can also provide a configuration file to register the MCP server:\n```bash\ncat ./calculator.json\n{\n  \"name\": \"calculator\",\n  \"transport\": \"streamable_http\",\n  \"description\": \"Provides some basic math tools\",\n  \"url\": \"http://127.0.0.1:8000/mcp\"\n}\n\nmcpjungle register -c ./calculator.json\n```\n\nAll tools provided by this server are now accessible via MCPJungle:\n\n```bash\nmcpjungle list tools\n\n# Check tool usage\nmcpjungle usage calculator__multiply\n\n# Call a tool\nmcpjungle invoke calculator__multiply --input '{\"a\": 100, \"b\": 50}'\n```\n\n![Call a tool via MCPJungle Proxy MCP server](./assets/tool-call.png)\n\n> [!NOTE]\n> A tool in MCPJungle must be referred to by its canonical name which follows the pattern `<mcp-server-name>__<tool-name>`.\n> Server name and tool name are separated by a double underscore `__`.\n>\n> eg- If you register a MCP server `github` which provides a tool called `git_commit`, you can invoke it in MCPJungle using the name `github__git_commit`.\n> \n> Your MCP client must also use this canonical name to call the tool via MCPJungle.\n\nThe config file format for registering a Streamable HTTP-based MCP server is:\n```json\n{\n  \"name\": \"<name of your mcp server>\",\n  \"transport\": \"streamable_http\",\n  \"description\": \"<description>\",\n  \"url\": \"<url of the mcp server>\",\n  \"bearer_token\": \"<optional bearer token for authentication>\"\n}\n```\n\n### Registering STDIO-based servers\n\nHere's an example configuration file (let's call it `filesystem.json`) for a MCP server that uses the STDIO transport:\n\n```json\n{\n  \"name\": \"filesystem\",\n  \"transport\": \"stdio\",\n  \"description\": \"filesystem mcp server\",\n  \"command\": \"npx\",\n  \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \".\"]\n}\n```\n\nYou can register this MCP server in MCPJungle by providing the configuration file:\n```bash\n# Save the JSON configuration to a file (e.g., filesystem.json)\nmcpjungle register -c ./filesystem.json\n```\n\nThe config file format for registering a STDIO-based MCP server is:\n\n```json\n{\n  \"name\": \"<name of your mcp server>\",\n  \"transport\": \"stdio\",\n  \"description\": \"<description>\",\n  \"command\": \"<command to run the mcp server, eg- 'npx', 'uvx'>\",\n  \"args\": [\"arguments\", \"to\", \"pass\", \"to\", \"the\", \"command\"],\n  \"env\": {\n    \"KEY\": \"value\"\n  }\n}\n```\n\nYou can also watch a quick video on [How to register a STDIO-based MCP server](https://youtu.be/YqHiuexR5fw).\n\n> [!TIP]\n> If your STDIO server fails or throws errors for some reason, check the mcpjungle server's logs to view its `stderr` output.\n\n**Limitation** 🚧\n\nMCPJungle creates a new connection when a tool is called. This means a new sub-process for a STDIO mcp server is started for every tool call.\n\nThis has some performance overhead but ensures that there are no memory leaks.\n\nBut it also means that currently MCPJungle doesn't support stateful connections with your MCP server.\n\nWe want to hear your feedback to improve this mechanism, feel free to create an issue, start a discussion or just reach out on Discord.\n\n\n**Caveat** ⚠️\n\nWhen running mcpjungle inside Docker, you need some extra configuration to run the `filesystem` mcp server.\n\nBy default, mcpjungle inside container does not have access to your host filesystem.\n\nSo you must:\n- mount the host directory you want to access as a volume in the container\n- specify the mount path as the directory in the filesystem mcp server command args\n\nThe `docker-compose.yaml` provided by mcpjungle mounts the current working directory as `/host` in the container.\n\nSo you can use the following configuration for the filesystem mcp server:\n\n```json\n{\n  \"name\": \"filesystem\",\n  \"transport\": \"stdio\",\n  \"command\": \"npx\",\n  \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/host\"]\n}\n```\n\nThen, the mcp has access to `/host`, ie, the current working directory on your host machine.\n\nSee [DEVELOPMENT.md](./DEVELOPMENT.md#docker-filesystem-access) for more details.\n\n\n### Deregistering MCP servers\nYou can remove a MCP server from mcpjungle.\n\n```bash\nmcpjungle deregister calculator\nmcpjungle deregister filesystem\n```\n\nOnce removed, this mcp server and its tools are no longer available to you or your MCP clients.\n\n## Integration with other MCP Clients\nAssuming that MCPJungle is running on `http://localhost:8080`, use the following configurations to connect to it:\n\n### Claude\n```json\n{\n  \"mcpServers\": {\n    \"mcpjungle\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-remote\",\n        \"http://localhost:8080/mcp\",\n        \"--allow-http\"\n      ]\n    }\n  }\n}\n```\n\n### Cursor\n```json\n{\n  \"mcpServers\": {\n    \"mcpjungle\": {\n      \"url\": \"http://localhost:8080/mcp\"\n    }\n  }\n}\n```\n\nYou can watch a quick video on [How to connect Cursor to MCPJungle](https://youtu.be/SaUqj-eLPnw).\n\n## Enabling/Disabling Tools\nYou can enable or disable a specific tool or all the tools provided by an MCP Server.\n\nIf a tool is disabled, it is not available via the MCPJungle Proxy, so no MCP clients can view or call it.\n\n```bash\n# disable the `get-library-docs` tool provided by the `context7` MCP server\nmcpjungle disable context7__get-library-docs\n\n# re-enable the tool\nmcpjungle enable context7__get-library-docs\n\n# disable all tools provided by the `context7` MCP server\nmcpjungle disable context7\n\n# re-enable all tools of `context7`\nmcpjungle enable context7\n```\n\nA disabled tool is still accessible via mcpjungle's HTTP API, so humans can still manage it from the CLI (or any other HTTP client).\n\n> [!NOTE]\n> When a new server is registered in MCPJungle, all its tools are **enabled** by default.\n\n## Tool Groups\nAs you add more MCP servers to MCPJungle, the number of tools available through the Gateway can grow significantly.\n\nIf your MCP client is exposed to hundreds of tools through the gateway MCP, its performance may degrade.\n\nMCPJungle allows you to **expose only a subset of all available tools to your MCP clients using Tool Groups**.\n\nYou can create a new group and only include specific tools that you wish to expose.\n\nOnce a group is created, mcpjungle returns a unique endpoint for it.\n\nYou can then configure your MCP client to use this group-specific endpoint instead of the main gateway endpoint.\n\n### Creating a Tool Group\nYou can create a new tool group by providing a JSON configuration file to the `create group` command.\n\nYou must specify a unique `name` for the group and define which tools to include using one or more of the following fields:\n- **`included_tools`**: List specific tool names to include (e.g., `[\"filesystem__read_file\", \"time__get_current_time\"]`)\n- **`included_servers`**: Include ALL tools from specific MCP servers (e.g., `[\"time\", \"deepwiki\"]`)\n- **`excluded_tools`**: Exclude specific tools (useful when including entire servers)\n\n#### Example 1: Cherry-picking specific tools\nHere is an example of a tool group configuration file (`claude-tools-group.json`):\n```json\n{\n  \"name\": \"claude-tools\",\n  \"description\": \"This group only contains tools for Claude Desktop to use\",\n  \"included_tools\": [\n    \"filesystem__read_file\",\n    \"deepwiki__read_wiki_contents\",\n    \"time__get_current_time\"\n  ]\n}\n```\n\nThis group exposes only 3 handpicked tools instead of all available tools.\n\n#### Example 2: Including entire servers with exclusions\nYou can also include all tools from specific servers and optionally exclude some:\n```json\n{\n  \"name\": \"claude-tools\",\n  \"description\": \"All tools from time and deepwiki servers except time__convert_time\",\n  \"included_servers\": [\"time\", \"deepwiki\"],\n  \"excluded_tools\": [\"time__convert_time\"]\n}\n```\n\nThis includes ALL tools from the `time` and `deepwiki` servers except `time__convert_time`.\n\n#### Example 3: Mixing approaches\nYou can combine all three fields for maximum flexibility:\n```json\n{\n  \"name\": \"comprehensive-tools\",\n  \"description\": \"Mix of manual tools, server inclusion, and exclusions\",\n  \"included_tools\": [\"filesystem__read_file\"],\n  \"included_servers\": [\"time\"],\n  \"excluded_tools\": [\"time__convert_time\"]\n}\n```\n\nThis includes `filesystem__read_file` plus all tools from the `time` server except `time__convert_time`.\n\nYou can create this group in mcpjungle:\n```bash\n$ mcpjungle create group -c ./claude-tools-group.json\n\nTool Group claude-tools created successfully\nIt is now accessible at the following streamable http endpoint:\n\n    http://127.0.0.1:8080/v0/groups/claude-tools/mcp\n\n```\n\nYou can then configure Claude (or any other MCP client) to use this group-specific endpoint to access the MCP server.\n\nThe client will then ONLY see and be able to use these 3 tools and will not be aware of any other tools registered in MCPJungle.\n\n> [!TIP]\n> You can run `mcpjungle list tools` to view all available tools and pick the ones you want to include in your group.\n\nYou can also watch a [Video on using Tool Groups](https://youtu.be/A21rfGgo38A).\n\n> [!NOTE]\n> The exclusion is always applied at the end.\n> So if you add a tool to `included_tools` and also list it in `excluded_tools`, it will be excluded from the final group.\n\n### Managing tool groups\nYou can currently perform operations like listing all groups, viewing details of a specific group and deleting a group.\n\n```bash\n# list all tool groups\nmcpjungle list groups\n\n# view details of a specific group\nmcpjungle get group claude-tools\n\n# delete a group\nmcpjungle delete group claude-tools\n```\n\n### Working with tools in groups\nYou can list and invoke tools within specific groups using the `--group` flag:\n\n```bash\n# list tools in a specific group\nmcpjungle list tools --group claude-tools\n\n# invoke a tool from a specific group context\nmcpjungle invoke filesystem__read_file --group claude-tools --input '{\"path\": \"README.md\"}'\n```\n\nThese commands provide group-scoped operations, making it easier to work with tools within specific contexts and validate that tools are available in your groups.\n\n> [!NOTE]\n> If a tool is included in a group but is later disabled globally or deleted, then it will not be available via the group's MCP endpoint.\n>\n> But if the tool is re-enabled or added again later, it will automatically become available in the group again.\n\n**Limitations** 🚧\n1. Currently, you cannot update an existing tool group. You must delete the group and create a new one with the modified configuration file.\n2. In `enterprise` mode, currently only an admin can create a Tool Group. We're working on allowing standard Users to create their own groups as well.\n\n## Authentication\nMCPJungle currently supports authentication if your Streamable HTTP MCP Server accepts static tokens for auth.\n\nThis is useful when using SaaS-provided MCP Servers like HuggingFace, Stripe, etc. which require your API token for authentication.\n\nYou can supply your token while registering the MCP server:\n```bash\n# If you specify the `--bearer-token` flag, MCPJungle will add the `Authorization: Bearer <token>` header to all requests made to this MCP server.\nmcpjungle register --name huggingface --description \"HuggingFace MCP Server\" --url https://huggingface.co/mcp --bearer-token <your-hf-api-token>\n```\n\nOr from your configuration file\n```bash\n{\n  \"name\": \"huggingface\",\n  \"transport\": \"streamable_http\",\n  \"url\": \"https://huggingface.co/mcp\",\n  \"description\": \"hugging face mcp server\",\n  \"bearer_token\": \"<your-hf-api-token>\"\n}\n```\n\nSupport for Oauth flow is coming soon!\n\n## Enterprise Features 🔒\n\nIf you're running MCPJungle in your organisation, we recommend running the Server in the `enterprise` mode:\n```bash\n# enable enterprise features by running in enterprise mode\nmcpjungle start --enterprise\n\n# you can also specify the server mode as environment variable (valid values are `development` and `enterprise`)\nexport SERVER_MODE=enterprise\nmcpjungle start\n\n# Or use the enterprise-mode docker compose file as described above\ndocker compose -f docker-compose.prod.yaml up -d\n```\n\nBy default, mcpjungle server runs in `development` mode which is ideal for individuals running it locally.\n\nIn Enterprise mode, the server enforces stricter security policies and will provide additional features like Authentication, ACLs, observability and more.\n\nAfter starting the server in enterprise mode, you must initialize it by running the following command on your client machine:\n```bash\nmcpjungle init-server\n```\n\nThis will create an admin user in the server and store its API access token in your home directory (`~/.mcpjungle.conf`).\n\nYou can then use the mcpjungle cli to make authenticated requests to the server.\n\n### Access Control\n\nIn `development` mode, all MCP clients have full access to all the MCP servers registered in MCPJungle Proxy.\n\n`enterprise` mode lets you control which MCP clients can access which MCP servers.\n\nSuppose you have registered 2 MCP servers `calculator` and `github` in MCPJungle in enterprise mode.\n\nBy default, no MCP client can access these servers. **You must create an MCP Client in mcpjungle and explicitly allow it to access the MCP servers.**\n\n```bash\n# Create a new MCP client for your Cursor IDE to use. It can access the calculator and github MCP servers\nmcpjungle create mcp-client cursor-local --allow \"calculator, github\"\n\nMCP client 'cursor-local' created successfully!\nServers accessible: calculator,github\n\nAccess token: 1YHf2LwE1LXtp5lW_vM-gmdYHlPHdqwnILitBhXE4Aw\nSend this token in the `Authorization: Bearer {token}` HTTP header.\n```\n\nMcpjungle creates an access token for your client.\nConfigure your client or agent to send this token in the `Authorization` header when making requests to the mcpjungle proxy.\n\nFor example, you can add the following configuration in Cursor to connect to MCPJungle:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcpjungle\": {\n      \"url\": \"http://localhost:8080/mcp\",\n      \"headers\": {\n        \"Authorization\": \"Bearer 1YHf2LwE1LXtp5lW_vM-gmdYHlPHdqwnILitBhXE4Aw\"\n      }\n    }\n  }\n}\n```\n\nA client that has access to a particular server this way can view and call all the tools provided by that server.\n\n> [!NOTE]\n> If you don't specify the `--allow` flag, the MCP client will not be able to access any MCP servers.\n\n### OpenTelemetry\nMCPJungle supports Prometheus-compatible OpenTelemetry Metrics for observability.\n\n- In `enterprise` mode, OpenTelemetry is enabled by default.\n- In `development` mode, telemetry is disabled by default. You can enable it by setting the `OTEL_ENABLED` environment variable to `true` before starting the server:\n\n```bash\n# enable OpenTelemetry metrics\nexport OTEL_ENABLED=true\n\n# optionally, set additional attributes to be added to all metrics\nexport OTEL_RESOURCE_ATTRIBUTES=deployment.environment.name=enterprise\n\n# start the server\nmcpjungle start\n```\n\nOnce the mcpjungle server is started, metrics are available at the `/metrics` endpoint.\n\n# Current limitations 🚧\nWe're not perfect yet, but we're working hard to get there!\n\n### 1. MCPJungle doesn't maintain any long-running connections to the registered MCP Servers\nWhen you call a tool in a Streamable HTTP server, mcpjungle creates a new connection to the server to serve the request.\n\nWhen you call a tool in a STDIO server, mcpjungle creates a new connection and starts a new sub-process to run this server.\n\nAfter servicing your request, it terminates this sub-process.\n\nSo a new stdio server process is started for every tool call.\n\nThis has some performance overhead but ensures that there are no memory leaks.\n\nIt also means that if you rely on stateful connections with your MCP server, mcpjungle can currently not provide that.\n\nWe plan on improving this mechanism in future releases and are open to ideas from the community!\n\n### 2. MCPJungle does not support OAuth flow for authentication.\nThis is a work in progress.\n\nWe're collecting more feedback on how people use OAuth with MCP servers, so feel free to start a Discussion or open an issue to share your use case.\n\n# Contributing 💻\n\nWe welcome contributions from the community! \n\n- **For contribution guidelines and standards**, see [CONTRIBUTION.md](./CONTRIBUTION.md)\n- **For development setup and technical details**, see [DEVELOPMENT.md](./DEVELOPMENT.md)\n\nJoin our [Discord community](https://discord.gg/CapV4Z3krk) to connect with other contributors and maintainers.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "aggregators",
        "agents",
        "enterprise",
        "aggregators servers",
        "enterprise ai",
        "mcp server"
      ],
      "category": "aggregators"
    },
    "glenngillen--mcpmcp-server": {
      "owner": "glenngillen",
      "name": "mcpmcp-server",
      "url": "https://github.com/glenngillen/mcpmcp-server",
      "imageUrl": "",
      "description": "A list of MCP servers so you can ask your client which servers you can use to improve your daily workflow.",
      "stars": 20,
      "forks": 8,
      "license": "Apache License 2.0",
      "language": "",
      "updated_at": "2025-09-30T09:22:38Z",
      "readme_content": "# mcpmcp-server\n\nDiscover, setup, and integrate MCP servers with your favorite clients. Unlock the full potential of AI in your daily workflow.\n\n## Installation/usage:\n\nUpdate the configuration of your MCP client to the following: \n\n```json\n{\n  \"mcpServers\": {\n    \"mcpmcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-remote@latest\", \"https://mcpmcp.io/mcp\"]\n    }\n  }\n}\n```\n\n(**note:** this config definitely works for Claude Desktop on macOS. If you need variations for other apps or platforms check the [homepage](https://mcpmcp.io/#install)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcpmcp",
        "mcp",
        "servers",
        "mcp servers",
        "mcpmcp server",
        "mcp server"
      ],
      "category": "aggregators"
    },
    "julien040--anyquery": {
      "owner": "julien040",
      "name": "anyquery",
      "url": "https://github.com/julien040/anyquery",
      "imageUrl": "",
      "description": "Query more than 40 apps with one binary using SQL. It can also connect to your PostgreSQL, MySQL, or SQLite compatible database. Local-first and private by design.",
      "stars": 1360,
      "forks": 82,
      "license": "Other",
      "language": "Go",
      "updated_at": "2025-10-04T11:11:01Z",
      "readme_content": "# Anyquery\n\n<img src=\"https://anyquery.dev/images/logo-shadow.png\" alt=\"Anyquery logo\" width=\"96\"></img>\n\n![GitHub Downloads (all assets, all releases)](https://img.shields.io/github/downloads/julien040/anyquery/total)\n![GitHub commit activity](https://img.shields.io/github/commit-activity/m/julien040/anyquery)\n[![Documentation](https://img.shields.io/badge/documentation-blue)](https://anyquery.dev)\n[![GitHub issues](https://img.shields.io/github/issues/julien040/anyquery)](https://github.com/julien040/anyquery/issues)\n[![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fregistry.anyquery.dev%2Fv0%2Fregistry%2F&query=%24.plugins_count&label=Integrations%20count&cacheSeconds=3600)](https://anyquery.dev/integrations/)\n[![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fregistry.anyquery.dev%2Fv0%2Fquery%2F&query=%24.queries_count&style=flat&label=Queries%20from%20the%20hub&cacheSeconds=3600&link=https%3A%2F%2Fanyquery.dev%2Fqueries)](https://anyquery.dev/queries)\n[![Go Reference](https://pkg.go.dev/badge/github.com/julien040/anyquery@v0.1.3/namespace.svg)](https://pkg.go.dev/github.com/julien040/anyquery/namespace)\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/julien040/anyquery)](https://archestra.ai/mcp-catalog/julien040__anyquery)\n\nAnyquery is a SQL query engine that allows you to run SQL queries on pretty much anything. It supports querying [files](https://anyquery.dev/docs/usage/querying-files/), [databases](https://anyquery.dev/docs/database), and [apps](https://anyquery.dev/integrations) (e.g. Apple Notes, Notion, Chrome, Todoist, etc.). It's built on top of [SQLite](https://www.sqlite.org) and uses [plugins](https://anyquery.dev/integrations) to extend its functionality.\n\nIt can also connect to [LLMs](https://anyquery.dev/llm) (e.g. ChatGPT, Claude, Cursor, TypingMind, etc.) to allow them to access your data.\n\nFinally, it can act as a [MySQL server](https://anyquery.dev/docs/usage/mysql-server/), allowing you to run SQL queries from your favorite MySQL-compatible client (e.g. [TablePlus](https://anyquery.dev/connection-guide/tableplus/), [Metabase](https://anyquery.dev/connection-guide/metabase/), etc.).\n\n![Anyquery header](https://anyquery.dev/images/release-header.png)\n\n## Usage\n\n### Connecting LLM\n\nLLMs can connect to Anyquery using the [Model Context Protocol (MCP)](https://anyquery.dev/docs/reference/commands/anyquery_mcp). This protocol provides context for LLMs that support it. You can start the MCP server with the following command:\n\n```bash\n# To be started by the LLM client\nanyquery mcp --stdio\n# To connect using an HTTP and SSE tunnel\nanyquery mcp --host 127.0.0.1 --port 8070\n```\n\nYou can also connect to clients that supports function calling (e.g. ChatGPT, TypingMind). Refer to each [connection guide](https://anyquery.dev/integrations#llm) in the documentation for more information.\n\n```bash\n# Copy the ID returned by the command, and paste it in the LLM client (e.g. ChatGPT, TypingMind)\nanyquery gpt\n```\n\n![5ire example](https://anyquery.dev/images/docs/llm/5ire-final.png)\n\n### Running SQL queries\n\nThe [documentation](https://anyquery.dev/docs/usage/running-queries) provides detailed instructions on how to run queries with Anyquery.\nBut let's see a quick example. Type `anyquery` in your terminal to open the shell mode. Then, run the following query:\n\n![Anyquery SQL examples](https://anyquery.dev/images/anyquery_examples.sql.png)\n\nYou can also launch the MySQL server with `anyquery server` and connect to it with your favorite MySQL-compatible client.\n\n```bash\nanyquery server &\nmysql -u root -h 127.0.0.1 -P 8070\n```\n\n## Installation\n\nThe [documentation](https://anyquery.dev/docs/#installation) provides detailed instructions on how to install Anyquery on your system. You can install anyquery from Homebrew, APT, YUM/DNF, Scoop, Winget and Chocolatey. You can also download the binary from the [releases page](https://github.com/julien040/anyquery/releases).\n\n### Homebrew\n\n```zsh\nbrew install anyquery\n```\n<!-- \n### Snap\n\n```bash\nsudo snap install anyquery\n``` -->\n\n### APT\n\n```bash\necho \"deb [trusted=yes] https://apt.julienc.me/ /\" | sudo tee /etc/apt/sources.list.d/anyquery.list\nsudo apt update\nsudo apt install anyquery\n```\n\n### YUM/DNF\n\n```bash\necho \"[anyquery]\nname=Anyquery\nbaseurl=https://yum.julienc.me/\nenabled=1\ngpgcheck=0\" | sudo tee /etc/yum.repos.d/anyquery.repo\nsudo dnf install anyquery\n```\n\n### Scoop\n\n```powershell\nscoop bucket add anyquery https://github.com/julien040/anyquery-scoop\nscoop install anyquery\n```\n\n### Winget\n\n```powershell\nwinget install JulienCagniart.anyquery\n```\n\n### Chocolatey\n\n```powershell\nchoco install anyquery\n```\n\n## Plugins\n\nAnyquery is plugin-based, and you can install plugins to extend its functionality. You can install plugins from the [official registry](https://anyquery.dev/integrations) or create your own. Anyquery can also [load any SQLite extension](https://anyquery.dev/docs/usage/plugins#using-sqlite-extensions).\n\n![Integrations](https://anyquery.dev/images/integrations_logo.png)\n\n## License\n\nAnyquery is licensed under the AGPLv3 license for the core engine. The RPC library is licensed under the MIT license so that anyone can reuse plugins in different projects.\n\nThe plugins are not subject to the AGPL license. Each plugins has its own license and the copyright is owned by the plugin author.\nSee the [LICENSE](https://github.com/julien040/anquery/blob/main/LICENSE.md) file for more information.\n\n## Contributing\n\nIf you want to contribute to Anyquery, please read the [contributing guidelines](https://anyquery.dev/docs/developers/project/contributing). I currently only accept minor contributions, but I'm open to any suggestions or feedback.\n\nYou can have a brief overview of the project in the [architecture](https://anyquery.dev/docs/developers/project/architecture/) documentation.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "anyquery",
        "aggregators",
        "servers",
        "aggregators servers",
        "anyquery query",
        "mcp server"
      ],
      "category": "aggregators"
    },
    "metatool-ai--metatool-app": {
      "owner": "metatool-ai",
      "name": "metatool-app",
      "url": "https://github.com/metatool-ai/metatool-app",
      "imageUrl": "",
      "description": "MetaMCP is the one unified middleware MCP server that manages your MCP connections with GUI.",
      "stars": 1416,
      "forks": 200,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-04T03:33:25Z",
      "readme_content": "# 🚀 MetaMCP (MCP Aggregator, Orchestrator, Middleware, Gateway in one docker)\n\n<div align=\"center\">\n\n<div align=\"center\">\n  <a href=\"https://discord.gg/mNsyat7mFX\" style=\"text-decoration: none;\">\n    <img src=\"https://img.shields.io/badge/Discord-MetaMCP-5865F2?style=flat-square&logo=discord&logoColor=white\" alt=\"Discord\" style=\"max-width: 100%;\">\n  </a>\n  <a href=\"https://docs.metamcp.com\" style=\"text-decoration: none;\">\n    <img src=\"https://img.shields.io/badge/Documentation-docs.metamcp.com-blue?style=flat-square&logo=book\" alt=\"Documentation\" style=\"max-width: 100%;\">\n  </a>\n  <a href=\"https://opensource.org/licenses/MIT\" style=\"text-decoration: none;\">\n    <img src=\"https://img.shields.io/badge/License-MIT-yellow.svg?style=flat-square\" alt=\"MIT License\" style=\"max-width: 100%;\">\n  </a>\n  <a href=\"https://github.com/metatool-ai/metamcp/pkgs/container/metamcp\" style=\"text-decoration: none;\">\n    <img src=\"https://img.shields.io/badge/GHCR-available-green.svg?style=flat-square&logo=github\" alt=\"GHCR\" style=\"max-width: 100%;\">\n  </a>\n  <a href=\"https://deepwiki.com/metatool-ai/metamcp\"><img src=\"https://img.shields.io/badge/DeepWiki-metatool--ai%2Fmetamcp-blue.svg?style=flat-square&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McDcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==\" alt=\"DeepWiki: MetaMCP\"></a>\n</div>\n\n</div>\n\n**MetaMCP** is a MCP proxy that lets you dynamically aggregate MCP servers into a unified MCP server, and apply middlewares. MetaMCP itself is a MCP server so it can be easily plugged into **ANY** MCP clients.\n\n![MetaMCP Diagram](metamcp.svg)\n\n---\n\nFor more details, consider visiting our documentation site: https://docs.metamcp.com\n\nEnglish | [中文](./README_cn.md)\n\n## 📋 Table of Contents\n\n- [🎯 Use Cases](#-use-cases)\n- [📖 Concepts](#-concepts)\n  - [🖥️ MCP Server](#️-mcp-server)\n  - [🏷️ MetaMCP Namespace](#️-metamcp-namespace)\n  - [🌐 MetaMCP Endpoint](#-metamcp-endpoint)\n  - [⚙️ Middleware](#️-middleware)\n  - [🔍 Inspector](#-inspector)\n- [🚀 Quick Start](#-quick-start)\n  - [🐳 Run with Docker Compose (Recommended)](#-run-with-docker-compose-recommended)\n  - [💻 Local Development](#-local-development)\n- [🔌 MCP Protocol Compatibility](#-mcp-protocol-compatibility)\n- [🔗 Connect to MetaMCP](#-connect-to-metamcp)\n  - [📝 E.g., Cursor via mcp.json](#-eg-cursor-via-mcpjson)\n  - [🖥️ Connecting Claude Desktop and Other STDIO-only Clients](#️-connecting-claude-desktop-and-other-stdio-only-clients)\n  - [🔧 API Key Auth Troubleshooting](#-api-key-auth-troubleshooting)\n- [❄️ Cold Start Problem and Custom Dockerfile](#️-cold-start-problem-and-custom-dockerfile)\n- [🔐 Authentication](#-authentication)\n- [🔗 OpenID Connect (OIDC) Provider Support](#-openid-connect-oidc-provider-support)\n  - [🛠️ Configuration](#️-configuration)\n  - [🏢 Supported Providers](#-supported-providers)\n  - [🔒 Security Features](#-security-features)\n  - [📱 Usage](#-usage)\n- [🌐 Custom Deployment and SSE conf for Nginx](#-custom-deployment-and-sse-conf-for-nginx)\n- [🏗️ Architecture](#️-architecture)\n  - [📊 Sequence Diagram](#-sequence-diagram)\n- [🗺️ Roadmap](#️-roadmap)\n- [🌐 i18n](#-i18n)\n- [🤝 Contributing](#-contributing)\n- [📄 License](#-license)\n- [🙏 Credits](#-credits)\n\n\n## 🎯 Use Cases\n- 🏷️ **Group MCP servers into namespaces, host them as meta-MCPs, and assign public endpoints** (SSE or Streamable HTTP), with auth. One-click to switch a namespace for an endpoint.\n-  🎯 **Pick tools you only need when remixing MCP servers.** Apply other **pluggable middleware** around observability, security, etc. (coming soon)\n-  🔍 **Use as enhanced MCP inspector** with saved server configs, and inspect your MetaMCP endpoints in house to see if it works or not.\n-  🔍 **Use as Elasticsearch for MCP tool selection** (coming soon)\n\nGenerally developers can use MetaMCP as **infrastructure** to host dynamically composed MCP servers through a unified endpoint, and build agents on top of it.\n\nQuick demo video: https://youtu.be/Cf6jVd2saAs\n\n![MetaMCP Screenshot](metamcp_screenshot.png)\n\n## 📖 Concepts\n\n### 🖥️ **MCP Server**\nA MCP server configuration that tells MetaMCP how to start a MCP server.\n\n```json\n\"HackerNews\": {\n  \"type\": \"STDIO\",\n  \"command\": \"uvx\",\n  \"args\": [\"mcp-hn\"]\n}\n```\n\n#### 🔐 **Environment Variables & Secrets (STDIO MCP Servers)**\n\nFor **STDIO MCP servers**, MetaMCP supports three ways to handle environment variables and secrets:\n\n**1. Raw Values** - Direct string values (not recommended for secrets):\n```\nAPI_KEY=your-actual-api-key-here\nDEBUG=true\n```\n\n**2. Environment Variable References** - Use `${ENV_VAR_NAME}` syntax:\n```\nAPI_KEY=${OPENAI_API_KEY}\nDATABASE_URL=${DB_CONNECTION_STRING}\n```\n\n**3. Auto-matching** - If the expected environment variable name in your tool matches the container's environment variable, you can omit it entirely. MetaMCP will automatically pass through matching environment variables.\n\n> **🔒 Security Note**: Environment variable references (`${VAR_NAME}`) are resolved from the MetaMCP container's environment at runtime. This keeps actual secret values out of your configuration and git repository.\n\n> **⚙️ Development Note**: For local development with `pnpm run dev:docker`, ensure your environment variables are listed in `turbo.json` under `globalEnv` to be passed to the development processes. This is not required for production Docker deployments.\n\n### 🏷️ **MetaMCP Namespace**\n- Group one or more MCP servers into a namespace\n- Enable/disable MCP servers or at tool level\n- Apply middlewares to MCP requests and responses\n\n### 🌐 **MetaMCP Endpoint**\n- Create endpoints and assign namespace to endpoints\n- Multiple MCP servers in the namespace will be aggregated and emitted as a MetaMCP endpoint\n- Choose between API-Key Auth (in header or query param) or standard OAuth in MCP Spec 2025-06-18\n- Host through **SSE** or **Streamable HTTP** transports in MCP and **OpenAPI** endpoints for clients like [Open WebUI](https://github.com/open-webui/open-webui)\n\n### ⚙️ **Middleware**\n- Intercepts and transforms MCP requests and responses at namespace level\n- **Built-in example**: \"Filter inactive tools\" - optimizes tool context for LLMs\n- **Future ideas**: tool logging, error traces, validation, scanning\n\n### 🔍 **Inspector**\nSimilar to the official MCP inspector, but with **saved server configs** - MetaMCP automatically creates configurations so you can debug MetaMCP endpoints immediately.\n\n## 🚀 Quick Start\n\n### **🐳 Run with Docker Compose (Recommended)**\n\nClone repo, prepare `.env`, and start with docker compose:\n\n```bash\ngit clone https://github.com/metatool-ai/metamcp.git\ncd metamcp\ncp example.env .env\ndocker compose up -d\n```\n\nIf you modify APP_URL env vars, make sure you only access from the APP_URL, because MetaMCP enforces CORS policy on the URL, so no other URL is accessible.\n\nNote that the pg volume name may collide with your other pg dockers, which is global, consider rename it in `docker-compose.yml`:\n\n```\nvolumes:\n  metamcp_postgres_data:\n    driver: local\n```\n\n### **💻 Local Development**\n\nStill recommend running postgres through docker for easy setup:\n\n```bash\npnpm install\npnpm dev\n```\n\n## 🔌 MCP Protocol Compatibility\n\n- ✅ **Tools, Resources, and Prompts** supported\n- ✅ **OAuth-enabled MCP servers** tested for 03-26 version\n\nIf you have questions, feel free to leave **GitHub issues** or **PRs**.\n\n## 🔗 Connect to MetaMCP\n\n### 📝 E.g., Cursor via mcp.json\n\nExample `mcp.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"MetaMCP\": {\n      \"url\": \"http://localhost:12008/metamcp/<YOUR_ENDPOINT_NAME>/sse\"\n    }\n  }\n}\n```\n\n### 🖥️ Connecting Claude Desktop and Other STDIO-only Clients\n\nSince MetaMCP endpoints are remote only (SSE, Streamable HTTP, OpenAPI), clients that only support stdio servers (like Claude Desktop) need a local proxy to connect.\n\n**Note:** While `mcp-remote` is sometimes suggested for this purpose, it's designed for OAuth-based authentication and doesn't work with MetaMCP's API key authentication. Based on testing, `mcp-proxy` is the recommended solution.\n\nHere's a working configuration for Claude Desktop using `mcp-proxy`:\n\nUsing Streamable HTTP\n\n```json\n{\n  \"mcpServers\": {\n    \"MetaMCP\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"mcp-proxy\",\n        \"--transport\",\n        \"streamablehttp\",\n        \"http://localhost:12008/metamcp/<YOUR_ENDPOINT_NAME>/mcp\"\n      ],\n      \"env\": {\n        \"API_ACCESS_TOKEN\": \"<YOUR_API_KEY_HERE>\"\n      }\n    }\n  }\n}\n```\n\nUsing SSE\n\n```json\n{\n  \"mcpServers\": {\n    \"ehn\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"mcp-proxy\",\n        \"http://localhost:12008/metamcp/<YOUR_ENDPOINT_NAME>/sse\"\n      ],\n      \"env\": {\n        \"API_ACCESS_TOKEN\": \"<YOUR_API_KEY_HERE>\"\n      }\n    }\n  }\n}\n```\n\n**Important notes:**\n- Replace `<YOUR_ENDPOINT_NAME>` with your actual endpoint name\n- Replace `<YOUR_API_KEY_HERE>` with your MetaMCP API key (format: `sk_mt_...`)\n\nFor more details and alternative approaches, see [issue #76](https://github.com/metatool-ai/metamcp/issues/76#issuecomment-3046707532).\n\n### 🔧 API Key Auth Troubleshooting\n\n- `?api_key=` param api key auth doesn't work for SSE. It only works for Streamable HTTP and OpenAPI.\n- Best practice is to use the API key in `Authorization: Bearer <API_KEY>` header.\n- Try disable auth temporarily when you face connection issues to see if it is an auth issue.\n\n## ❄️ Cold Start Problem and Custom Dockerfile\n\n- MetaMCP pre-allocate idle sessions for each configured MCP servers and MetaMCPs. The default idle session for each is 1 and that can help reduce cold start time.\n- If your MCP requires dependencies other than `uvx` or `npx`, you need to customize the Dockerfile to install dependencies on your own.\n- Check [invalidation.md](invalidation.md) for a seq diagram about how idle session invalidates during updates.\n\n🛠️ **Solution**: Customize the Dockerfile to add dependencies or pre-install packages to reduce cold start time.\n\n## 🔐 Authentication\n\n- 🛡️ **Better Auth** for frontend & backend (TRPC procedures)\n- 🍪 **Session cookies** enforce secure internal MCP proxy connections\n- 🔑 **API key authentication** for external access via `Authorization: Bearer <api-key>` header\n- 🪪 **MCP OAuth**: Exposed endpoints have options to use standard OAuth in MCP Spec 2025-06-18, easy to connect.\n- 🏢 **Multi-tenancy**: Designed for organizations to deploy on their own machines. Supports both private and public access scopes. Users can create MCPs, namespaces, endpoints, and API keys for themselves or for everyone. Public API keys cannot access private MetaMCPs.\n- ⚙️ **Separate Registration Controls**: Administrators can independently control UI registration and SSO/OAuth registration through the settings page, allowing for flexible enterprise deployment scenarios.\n\n## 🔗 OpenID Connect (OIDC) Provider Support\n\nMetaMCP supports **OpenID Connect authentication** for enterprise SSO integration. This allows organizations to use their existing identity providers (Auth0, Keycloak, Azure AD, etc.) for authentication.\n\n### 🛠️ **Configuration**\n\nAdd the following environment variables to your `.env` file:\n\n```bash\n# Required\nOIDC_CLIENT_ID=your-oidc-client-id\nOIDC_CLIENT_SECRET=your-oidc-client-secret\nOIDC_DISCOVERY_URL=https://your-provider.com/.well-known/openid-configuration\n\n# Optional customization\nOIDC_PROVIDER_ID=oidc\nOIDC_SCOPES=openid email profile\nOIDC_PKCE=true\n```\n\n### 🏢 **Supported Providers**\n\nMetaMCP has been tested with popular OIDC providers:\n\n- **Auth0**: `https://your-domain.auth0.com/.well-known/openid-configuration`\n- **Keycloak**: `https://your-keycloak.com/realms/your-realm/.well-known/openid-configuration`\n- **Azure AD**: `https://login.microsoftonline.com/your-tenant-id/v2.0/.well-known/openid-configuration`\n- **Google**: `https://accounts.google.com/.well-known/openid-configuration`\n- **Okta**: `https://your-domain.okta.com/.well-known/openid-configuration`\n\n### 🔒 **Security Features**\n\n- 🔐 **PKCE (Proof Key for Code Exchange)** enabled by default\n- 🛡️ **Authorization Code Flow** with automatic user creation\n- 🔄 **Auto-discovery** of OIDC endpoints\n- 🍪 **Seamless session management** with existing auth system\n\n### 📱 **Usage**\n\nOnce configured, users will see a **\"Sign in with OIDC\"** button on the login page alongside the email/password form. The authentication flow automatically creates new users on first login.\n\nFor more detailed configuration examples and troubleshooting, see **[CONTRIBUTING.md](CONTRIBUTING.md#openid-connect-oidc-provider-setup)**.\n\n## ⚙️ Registration Controls\n\nMetaMCP provides **separate controls** for different registration methods, allowing administrators to fine-tune user access policies for enterprise deployments.\n\n### 🎛️ **Available Controls**\n\n- **UI Registration**: Controls whether users can create accounts via the registration form\n- **SSO Registration**: Controls whether users can create accounts via SSO/OAuth providers (OIDC, etc.)\n\n### 🏢 **Enterprise Use Cases**\n\nThis separation enables common enterprise scenarios:\n\n- **Block UI registration, allow SSO**: Prevent manual signups while allowing corporate SSO users\n- **Block SSO registration, allow UI**: Allow manual signups while restricting SSO access\n- **Block both**: Completely disable new user registration\n- **Allow both**: Default behavior for open deployments\n\n### 🛠️ **Configuration**\n\nAccess the **Settings** page in the MetaMCP admin interface to configure these controls:\n\n1. Navigate to **Settings** → **Authentication Settings**\n2. Toggle **\"Disable UI Registration\"** to control form-based signups\n3. Toggle **\"Disable SSO Registration\"** to control OAuth/OIDC signups\n\nBoth controls work independently, giving you full flexibility over your registration policy.\n\n## 🌐 Custom Deployment and SSE conf for Nginx\n\nIf you want to deploy it to a online service or a VPS, a instance of at least 2GB-4GB of memory is required. And the larger size, the better performance.\n\nSince MCP leverages SSE for long connection, if you are using reverse proxy like nginx, please refer to an example setup [nginx.conf.example](nginx.conf.example)\n\n## 🏗️ Architecture\n\n- **Frontend**: Next.js\n- **Backend**: Express.js with tRPC, hosting MCPs through TS SDK and internal proxy\n- **Auth**: Better Auth\n- **Structure**: Standalone monorepo with Turborepo and Docker publishing\n\n### 📊 Sequence Diagram\n\n*Note: Prompts and resources follow similar patterns to tools.*\n\n```mermaid\nsequenceDiagram\n    participant MCPClient as MCP Client (e.g., Claude Desktop)\n    participant MetaMCP as MetaMCP Server\n    participant MCPServers as Installed MCP Servers\n\n    MCPClient ->> MetaMCP: Request list tools\n\n    loop For each listed MCP Server\n        MetaMCP ->> MCPServers: Request list_tools\n        MCPServers ->> MetaMCP: Return list of tools\n    end\n\n    MetaMCP ->> MetaMCP: Aggregate tool lists & apply middleware\n    MetaMCP ->> MCPClient: Return aggregated list of tools\n\n    MCPClient ->> MetaMCP: Call tool\n    MetaMCP ->> MCPServers: call_tool to target MCP Server\n    MCPServers ->> MetaMCP: Return tool response\n    MetaMCP ->> MCPClient: Return tool response\n```\n\n## 🗺️ Roadmap\n\n**Potential next steps:**\n\n- [ ] 🔌 Headless Admin API access\n- [ ] 🔍 Dynamically apply search rules on MetaMCP endpoints\n- [ ] 🛠️ More middlewares\n- [ ] 💬 Chat/Agent Playground\n- [ ] 🧪 Testing & Evaluation for MCP tool selection optimization\n- [ ] ⚡ Dynamically generate MCP servers\n\n## 🌐 i18n\n\nSee [README-i18n.md](README-i18n.md)\n\nCurrently en and zh locale are supported, but welcome contributions.\n\n## 🤝 Contributing\n\nWe welcome contributions! See details at **[CONTRIBUTING.md](CONTRIBUTING.md)**\n\n## 📄 License\n\n**MIT**\n\nWould appreciate if you mentioned with back links if your projects use the code.\n\n## 🙏 Credits\n\nSome code inspired by:\n- [MCP Inspector](https://github.com/modelcontextprotocol/inspector)\n- [MCP Proxy Server](https://github.com/adamwattis/mcp-proxy-server)\n\nNot directly used the code by took ideas from\n- https://github.com/open-webui/openapi-servers\n- https://github.com/open-webui/mcpo\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "metamcp",
        "middleware",
        "mcp",
        "middleware mcp",
        "mcp server",
        "server metatool"
      ],
      "category": "aggregators"
    },
    "mindsdb--mindsdb": {
      "owner": "mindsdb",
      "name": "mindsdb",
      "url": "https://github.com/mindsdb/mindsdb",
      "imageUrl": "",
      "description": "Connect and unify data across various platforms and databases with [MindsDB as a single MCP server](https://docs.mindsdb.com/mcp/overview).",
      "stars": 36251,
      "forks": 5823,
      "license": "Other",
      "language": "Python",
      "updated_at": "2025-10-04T12:39:17Z",
      "readme_content": "\n\n<a name=\"readme-top\"></a>\n\n<div align=\"center\">\n\t<a href=\"https://pypi.org/project/MindsDB/\" target=\"_blank\"><img src=\"https://badge.fury.io/py/MindsDB.svg\" alt=\"MindsDB Release\"></a>\n\t<a href=\"https://www.python.org/downloads/\" target=\"_blank\"><img src=\"https://img.shields.io/badge/python-3.10.x%7C%203.11.x-brightgreen.svg\" alt=\"Python supported\"></a>\n\t<a href=\"https://hub.docker.com/u/mindsdb\" target=\"_blank\"><img src=\"https://img.shields.io/docker/pulls/mindsdb/mindsdb\" alt=\"Docker pulls\"></a>\n\n  <br />\n  <br />\n\n  <a href=\"https://trendshift.io/repositories/3068\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/3068\" alt=\"mindsdb%2Fmindsdb | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n  <a href=\"https://github.com/mindsdb/mindsdb\">\n    <img src=\"/docs/assets/mindsdb_logo.png\" alt=\"MindsDB\" width=\"300\">\n  </a>\n\n  <p align=\"center\">\n    <br />\n    <a href=\"https://www.mindsdb.com?utm_medium=community&utm_source=github&utm_campaign=mindsdb%20repo\">Website</a>\n    ·\n    <a href=\"https://docs.mindsdb.com?utm_medium=community&utm_source=github&utm_campaign=mindsdb%20repo\">Docs</a>\n    ·\n    <a href=\"https://mindsdb.com/contact\">Contact us for a Demo</a>\n    ·\n    <a href=\"https://mindsdb.com/joincommunity?utm_medium=community&utm_source=github&utm_campaign=mindsdb%20repo\">Community Slack</a>\n  </p>\n</div>\n\n----------------------------------------\n\n\nMindsDB enables humans, AI, agents, and applications to get highly accurate answers across large scale data sources.\n\n<a href=\"https://www.youtube.com/watch?v=MX3OKpnsoLM\" target=\"_blank\">\n  <img src=\"https://github.com/user-attachments/assets/119e7b82-f901-4214-a26f-ff7c5ad86064\" alt=\"MindsDB Demo\">\n\t\n</a>\n\n\n## Install MindsDB Server \n\nMindsDB is an open-source server that can be deployed anywhere - from your laptop to the cloud, and everywhere in between. And yes, you can customize it to your heart's content.\n\n  * [Using Docker Desktop](https://docs.mindsdb.com/setup/self-hosted/docker-desktop). This is the fastest and recommended way to get started and have it all running.\n  * [Using Docker](https://docs.mindsdb.com/setup/self-hosted/docker). This is also simple, but gives you more flexibility on how to further customize your server.\n\n[MindsDB has an MCP server built in](https://docs.mindsdb.com/mcp/overview) that enables your MCP applications to connect, unify and respond to questions over large-scale federated data—spanning databases, data warehouses, and SaaS applications.\n \n----------------------------------------\n\n# Core Philosophy: Connect, Unify, Respond\n\nMindsDB's architecture is built around three fundamental capabilities:\n\n## [Connect](https://docs.mindsdb.com/integrations/data-overview) Your Data\n\nYou can connect to hundreds of enterprise [data sources (learn more)](https://docs.mindsdb.com/integrations/data-overview). These integrations allow MindsDB to access data wherever it resides, forming the foundation for all other capabilities.\n\n## [Unify](https://docs.mindsdb.com/mindsdb_sql/overview) Your Data\n\n\nIn many situations, it’s important to be able to prepare and unify data before generating responses from it. MindsDB SQL offers knowledge bases and views that allow indexing and organizing structured and unstructured data as if it were unified in a single system.\n\n* [**KNOWLEDGE BASES**](https://docs.mindsdb.com/mindsdb_sql/knowledge-bases) – Index and organize unstructured data for efficient Q&A.\n* [**VIEWS**](https://docs.mindsdb.com/mindsdb_sql/sql/create/view) – Simplify data access by creating unified views across different sources (no-ETL).\n\n\nUnification of data can be automated using JOBs\n\n* [**JOBS**](https://docs.mindsdb.com/mindsdb_sql/sql/create/jobs) – Schedule synchronization and transformation tasks for real-time processing.\n\n\n## [Respond](https://docs.mindsdb.com/mindsdb_sql/agents/agent) From Your Data\n\nChat with Your Data\n\n* [**AGENTS**](https://docs.mindsdb.com/mindsdb_sql/agents/agent) – Configure built-in agents specialized in answering questions over your connected and unified data.\n* [**MCP**](https://docs.mindsdb.com/mcp/overview) – Connect to MindsDB through the MCP (Model Context Protocol) for seamless interaction.\n\n----------------------------------------\n\n## 🤝 Contribute\n\nInterested in contributing to MindsDB? Follow our [installation guide for development](https://docs.mindsdb.com/contribute/install?utm_medium=community&utm_source=github&utm_campaign=mindsdb%20repo).\n\nYou can find our [contribution guide here](https://docs.mindsdb.com/contribute/contribute?utm_medium=community&utm_source=github&utm_campaign=mindsdb%20repo).\n\nWe welcome suggestions! Feel free to open new issues with your ideas, and we’ll guide you.\n\nThis project adheres to a [Contributor Code of Conduct](https://github.com/mindsdb/mindsdb/blob/main/CODE_OF_CONDUCT.md). By participating, you agree to follow its terms.\n\nAlso, check out our [community rewards and programs](https://mindsdb.com/community?utm_medium=community&utm_source=github&utm_campaign=mindsdb%20repo).\n\n## 🤍 Support\n\nIf you find a bug, please submit an [issue on GitHub](https://github.com/mindsdb/mindsdb/issues/new/choose).\n\nHere’s how you can get community support:\n\n* Ask a question in our [Slack Community](https://mindsdb.com/joincommunity?utm_medium=community&utm_source=github&utm_campaign=mindsdb%20repo).\n* Join our [GitHub Discussions](https://github.com/mindsdb/mindsdb/discussions).\n* Post on [Stack Overflow](https://stackoverflow.com/questions/tagged/mindsdb) with the MindsDB tag.\n\nFor commercial support, please [contact the MindsDB team](https://mindsdb.com/contact?utm_medium=community&utm_source=github&utm_campaign=mindsdb%20repo).\n\n## 💚 Current Contributors\n\n<a href=\"https://github.com/mindsdb/mindsdb/graphs/contributors\">\n  <img src=\"https://contributors-img.web.app/image?repo=mindsdb/mindsdb\" />\n</a>\n\nGenerated with [contributors-img](https://contributors-img.web.app).\n\n## 🔔 Subscribe for Updates\n\nJoin our [Slack community](https://mindsdb.com/joincommunity)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mindsdb",
        "databases",
        "servers",
        "server mindsdb",
        "mindsdb connect",
        "databases mindsdb"
      ],
      "category": "aggregators"
    },
    "particlefuture--MCPDiscovery": {
      "owner": "particlefuture",
      "name": "MCPDiscovery",
      "url": "https://github.com/particlefuture/MCPDiscovery",
      "imageUrl": "",
      "description": "MCP of MCPs. A central hub for MCP servers. Helps you discover available MCP servers and learn how to install and use them.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcps",
        "mcp",
        "aggregators",
        "mcp servers",
        "mcp server",
        "server particlefuture"
      ],
      "category": "aggregators"
    },
    "sitbon--magg": {
      "owner": "sitbon",
      "name": "magg",
      "url": "https://github.com/sitbon/magg",
      "imageUrl": "",
      "description": "Magg: A meta-MCP server that acts as a universal hub, allowing LLMs to autonomously discover, install, and orchestrate multiple MCP servers - essentially giving AI assistants the power to extend their own capabilities on-demand.",
      "stars": 84,
      "forks": 16,
      "license": "GNU Affero General Public License v3.0",
      "language": "Python",
      "updated_at": "2025-10-03T22:32:49Z",
      "readme_content": "# 🧲 **Magg** - *The MCP Aggregator*\n\n[//]: # ([![Tests]&#40;https://img.shields.io/github/actions/workflow/status/sitbon/magg/test.yml?style=flat-square&label=tests&#41;]&#40;https://github.com/sitbon/magg/actions/workflows/test.yml&#41;)\n[![Python Version](https://img.shields.io/pypi/pyversions/magg?style=flat-square&logo=python&logoColor=white)](https://pypi.org/project/magg/)\n[![PyPI Version](https://img.shields.io/pypi/v/magg?style=flat-square&logo=pypi&logoColor=white)](https://pypi.org/project/magg/)\n[![GitHub Release](https://img.shields.io/github/v/release/sitbon/magg?style=flat-square&logo=github)](https://github.com/sitbon/magg/releases)\n[![DeepWiki](https://img.shields.io/badge/DeepWiki-sitbon%2Fmagg-blue.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McDcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==)](https://deepwiki.com/sitbon/magg)\n[![Downloads](https://img.shields.io/pypi/dm/magg?style=flat-square)](https://pypistats.org/packages/magg)\n<!-- DeepWiki badge generated by https://deepwiki.ryoppippi.com/ -->\n\n[![Tests](https://github.com/sitbon/magg/actions/workflows/test.yml/badge.svg)](https://github.com/sitbon/magg/actions/workflows/test.yml)\n[![Docker](https://github.com/sitbon/magg/actions/workflows/docker-publish.yml/badge.svg)](https://github.com/sitbon/magg/actions/workflows/docker-publish.yml)\n\nA *[Model Context Protocol](https://modelcontextprotocol.io/)* server that manages, aggregates, and proxies other MCP servers, enabling LLMs to dynamically extend their own capabilities.\n\n## What is Magg?\n\nMagg is a meta-MCP server that acts as a central hub for managing multiple MCP servers. It provides tools that allow LLMs to:\n\n- Search for new MCP servers and discover setup instructions\n- Add and configure MCP servers dynamically\n- Enable/disable servers on demand\n- Aggregate tools from multiple servers under unified prefixes\n- Persist configurations across sessions\n\nThink of Magg as a \"package manager for LLM tools\" - it lets AI assistants install and manage their own capabilities at runtime.\n\n## Features\n\n- **Self-Service Tool Management**: LLMs can search for and add new MCP servers without human intervention.\n- **Dynamic Configuration Reloading**: Automatically detects and applies config changes without restarting.\n- **Automatic Tool Proxying**: Tools from added servers are automatically exposed with configurable prefixes.\n- **ProxyMCP Tool**: A built-in tool that proxies the MCP protocol to itself, for clients that don't support notifications or dynamic tool updates (which is most of them currently).\n- **Smart Configuration**: Uses MCP sampling to intelligently configure servers from just a URL.\n- **Persistent Configuration**: Maintains server configurations in `.magg/config.json`.\n- **Multiple Transport Support**: Works with stdio, HTTP, and in-memory transports.\n- **Bearer Token Authentication**: Optional RSA-based JWT authentication for secure HTTP access.\n- **Docker Support**: Pre-built images for production, staging, and development workflows.\n- **Health Monitoring**: Built-in `magg_status` and `magg_check` tools for server health checks.\n- **Real-time Messaging**: Full support for MCP notifications and messages - receive tool/resource updates and progress notifications from backend servers.\n- **Python 3.12+ Support**: Fully compatible with Python 3.12 and 3.13.\n- **Kit Management**: Bundle related MCP servers into kits for easy loading/unloading as a group.\n- **MBro CLI**: Included [MCP Browser](docs/mbro.md) for interactive exploration and management of MCP servers, with script support for automation.\n\n## Installation\n\n### Prerequisites\n\n- Python 3.12 or higher (3.13+ recommended)\n- `uv` (recommended) - Install from [astral.sh/uv](https://astral.sh/uv)\n\n### Quick Install (Recommended)\n\nThe easiest way to install Magg is as a tool using `uv`:\n\n```bash\n# Install Magg as a tool\nuv tool install magg\n\n# Run with stdio transport (for Claude Desktop, Cline, etc.)\nmagg serve\n\n# Run with HTTP transport (for system-wide access)\nmagg serve --http\n```\n\n### Alternative: Run Directly from GitHub\n\nYou can also run Magg directly from GitHub without installing:\n\n```bash\n# Run with stdio transport\nuvx --from git+https://github.com/sitbon/magg.git magg\n\n# Run with HTTP transport\nuvx --from git+https://github.com/sitbon/magg.git magg serve --http\n```\n\n### Local Development\n\nFor development, clone the repository and install in editable mode:\n\n```bash\n# Clone the repository\ngit clone https://github.com/sitbon/magg.git\ncd magg\n\n# Install in development mode with dev dependencies\nuv sync --dev\n\n# Or with poetry\npoetry install --with dev\n\n# Run the CLI\nmagg --help\n```\n\n### Docker\n\nMagg is available as pre-built Docker images from GitHub Container Registry:\n\n```bash\n# Run production image (WARNING log level)\ndocker run -p 8000:8000 ghcr.io/sitbon/magg:latest\n\n# Run with authentication (mount or set private key)\ndocker run -p 8000:8000 \\\n  -v ~/.ssh/magg:/home/magg/.ssh/magg:ro \\\n  ghcr.io/sitbon/magg:latest\n\n# Or with environment variable\ndocker run -p 8000:8000 \\\n  -e MAGG_PRIVATE_KEY=\"$(cat ~/.ssh/magg/magg.key)\" \\\n  ghcr.io/sitbon/magg:latest\n\n# Run beta image (INFO log level)\ndocker run -p 8000:8000 ghcr.io/sitbon/magg:beta\n\n# Run with custom config directory\ndocker run -p 8000:8000 \\\n  -v /path/to/config:/home/magg/.magg \\\n  ghcr.io/sitbon/magg:latest\n```\n\n#### Docker Image Strategy\n\nMagg uses a multi-stage Docker build with three target stages:\n\n- **`pro` (Production)**: Minimal image with WARNING log level, suitable for production deployments\n- **`pre` (Pre-production)**: Same as production but with INFO log level for staging/testing (available but not published)\n- **`dev` (Development)**: Includes development dependencies and DEBUG logging for troubleshooting\n\nImages are automatically published to GitHub Container Registry with the following tags:\n\n- **Version tags** (from main branch): `1.2.3`, `1.2`, `dev`, `1.2-dev`, `1.2-dev-py3.12`, etc.\n- **Branch tags** (from beta branch): `beta`, `beta-dev`\n- **Python-specific dev tags**: `beta-dev-py3.12`, `beta-dev-py3.13`, etc.\n\n#### Docker Compose\n\nFor easier management, use Docker Compose:\n\n```bash\n# Clone the repository\ngit clone https://github.com/sitbon/magg.git\ncd magg\n\n# Run production version\ndocker compose up magg\n\n# Run staging version (on port 8001)\ndocker compose up magg-beta\n\n# Run development version (on port 8008)\n# This uses ./.magg/config.json for configuration\ndocker compose up magg-dev\n\n# Build and run with custom registry\nREGISTRY=my.registry.com docker compose build\nREGISTRY=my.registry.com docker compose push\n```\n\nSee `compose.yaml` and `.env.example` for configuration options.\n\n## Usage\n\n### Running Magg\n\nMagg can run in three modes:\n\n1. **Stdio Mode** (default) - For integration with Claude Desktop, Cline, Cursor, etc.:\n   ```bash\n   magg serve\n   ```\n\n2. **HTTP Mode** - For system-wide access or web integrations:\n   ```bash\n   magg serve --http --port 8000\n   ```\n\n3. **Hybrid Mode** - Both stdio and HTTP simultaneously:\n   ```bash\n   magg serve --hybrid\n   magg serve --hybrid --port 8080  # Custom port\n   ```\n   \n   This is particularly useful when you want to use Magg through an MCP client while also allowing HTTP access. For example:\n   \n   **With Claude Code:**\n   ```bash\n   # Configure Claude Code to use Magg in hybrid mode\n   claude mcp add magg -- magg serve --hybrid --port 42000\n   ```\n   \n   **With mbro:**\n   ```bash\n   # mbro hosts Magg and connects via stdio\n   mbro connect magg \"magg serve --hybrid --port 8080\"\n   \n   # Other mbro instances can connect via HTTP\n   mbro connect magg http://localhost:8080\n   ```\n\n### Available Tools\n\nOnce Magg is running, it exposes the following tools to LLMs:\n\n- `magg_list_servers` - List all configured MCP servers\n- `magg_add_server` - Add a new MCP server\n- `magg_remove_server` - Remove a server\n- `magg_enable_server` / `magg_disable_server` - Toggle server availability\n- `magg_search_servers` - Search for MCP servers online\n- `magg_list_tools` - List all available tools from all servers\n- `magg_smart_configure` - Intelligently configure a server from a URL\n- `magg_analyze_servers` - Analyze configured servers and suggest improvements\n- `magg_status` - Get server and tool statistics\n- `magg_check` - Health check servers with repair actions (report/remount/unmount/disable)\n- `magg_reload_config` - Reload configuration from disk and apply changes\n- `magg_load_kit` - Load a kit and its servers into the configuration\n- `magg_unload_kit` - Unload a kit and optionally its servers from the configuration\n- `magg_list_kits` - List all available kits with their status\n- `magg_kit_info` - Get detailed information about a specific kit\n\n### Quick Inspection with MBro\n\nMagg includes the `mbro` (MCP Browser) CLI tool for interactive exploration. A unique feature is the ability to connect to Magg in stdio mode for quick inspection:\n\n```bash\n# Connect mbro to a Magg instance via stdio (no HTTP server needed)\nmbro connect local-magg magg serve\n\n# Now inspect your Magg setup from the MCP client perspective\nmbro:local-magg> call magg_status\nmbro:local-magg> call magg_list_servers\n```\n\nMBro also supports:\n- **Scripts**: Create `.mbro` files with commands for automation\n- **Shell-style arguments**: Use `key=value` syntax instead of JSON\n- **Tab completion**: Rich parameter hints after connecting\n\nSee the [MBro Documentation](docs/mbro.md) for details.\n\n### Authentication\n\nMagg supports optional bearer token authentication to secure access:\n\n#### Quick Start\n\n1. **Initialize authentication** (creates RSA keypair):\n   ```bash\n   magg auth init\n   ```\n\n2. **Generate a JWT token** for clients:\n   ```bash\n   # Generate token (displays on screen)\n   magg auth token\n   \n   # Export as environment variable\n   export MAGG_JWT=$(magg auth token -q)\n   ```\n\n3. **Connect with authentication**:\n   - Using `MaggClient` (auto-loads from MAGG_JWT):\n     ```python\n     from magg.client import MaggClient\n     \n     async def main():\n         async with MaggClient(\"http://localhost:8000/mcp\") as client:\n             tools = await client.list_tools()\n     ```\n   - Using FastMCP with explicit token:\n     ```python\n     from fastmcp import Client\n     from fastmcp.client import BearerAuth\n     \n     jwt_token = \"your-jwt-token-here\"\n     async with Client(\"http://localhost:8000/mcp\", auth=BearerAuth(jwt_token)) as client:\n         tools = await client.list_tools()\n     ```\n\n#### Key Management\n\n- Keys are stored in `~/.ssh/magg/` by default\n- Private key can be set via `MAGG_PRIVATE_KEY` environment variable\n- To disable auth, remove keys or set non-existent `key_path` in `.magg/auth.json`\n\n#### Authentication Commands\n\n- `magg auth init` - Initialize authentication (generates RSA keypair)\n- `magg auth status` - Check authentication configuration\n- `magg auth token` - Generate JWT token\n- `magg auth public-key` - Display public key (for verification)\n- `magg auth private-key` - Display private key (for backup)\n\nSee [examples/authentication.py](examples/authentication.py) for more usage patterns.\n\n### Configuration\n\nMagg stores its configuration in `.magg/config.json` in your current working directory. This allows for project-specific tool configurations.\n\n#### Dynamic Configuration Reloading\n\nMagg supports automatic configuration reloading without requiring a restart:\n\n- **Automatic file watching**: Detects changes to `config.json` and reloads automatically (uses watchdog when available)\n- **SIGHUP signal**: Send `kill -HUP <pid>` to trigger immediate reload (Unix-like systems)\n- **MCP tool**: Use `magg_reload_config` tool from any MCP client\n- **Smart transitions**: Only affected servers are restarted during reload\n\nConfiguration reload is enabled by default. You can control it with:\n- `MAGG_AUTO_RELOAD=false` - Disable automatic reloading\n- `MAGG_RELOAD_POLL_INTERVAL=5.0` - Set polling interval in seconds (when watchdog unavailable)\n\nSee [Configuration Reload Documentation](docs/config-reload.md) for detailed information.\n\n#### Environment Variables\n\nMagg supports several environment variables for configuration:\n- `MAGG_CONFIG_PATH` - Path to config file (default: `.magg/config.json`)\n- `MAGG_LOG_LEVEL` - Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL (default: INFO)\n- `MAGG_STDERR_SHOW=1` - Show stderr output from subprocess MCP servers (default: suppressed)\n- `MAGG_AUTO_RELOAD` - Enable/disable config auto-reload (default: true)\n- `MAGG_RELOAD_POLL_INTERVAL` - Config polling interval in seconds (default: 1.0)\n- `MAGG_READ_ONLY=true` - Run in read-only mode\n- `MAGG_SELF_PREFIX` - Prefix for Magg tools (default: \"magg\"). Tools will be named as `{prefix}{sep}{tool}` (e.g., `magg_list_servers`)\n- `MAGG_PREFIX_SEP` - Separator between prefix and tool name (default: \"_\")\n\nExample configuration:\n```json\n{\n  \"servers\": {\n    \"calculator\": {\n      \"name\": \"calculator\",\n      \"source\": \"https://github.com/executeautomation/calculator-mcp\",\n      \"command\": \"npx @executeautomation/calculator-mcp\",\n      \"prefix\": \"calc\",\n      \"enabled\": true\n    }\n  }\n}\n```\n\n### Adding Servers\n\nServers can be added in several ways:\n\n1. **Using the LLM** (recommended):\n   ```\n   \"Add the Playwright MCP server\"\n   \"Search for and add a calculator tool\"\n   ```\n\n2. **Manual configuration** via `magg_add_server`:\n   ```\n   name: playwright\n   url: https://github.com/microsoft/playwright-mcp\n   command: npx @playwright/mcp@latest\n   prefix: pw\n   ```\n\n3. **Direct config editing**: Edit `.magg/config.json` directly\n\n### Real-time Notifications with MaggClient\n\nThe `MaggClient` now supports real-time notifications from backend MCP servers:\n\n```python\nfrom magg import MaggClient, MaggMessageHandler\n\n# Using callbacks\nhandler = MaggMessageHandler(\n    on_tool_list_changed=lambda n: print(\"Tools changed!\"),\n    on_progress=lambda n: print(f\"Progress: {n.params.progress}\")\n)\n\nasync with MaggClient(\"http://localhost:8000/mcp\", message_handler=handler) as client:\n    # Client will receive notifications while connected\n    tools = await client.list_tools()\n```\n\nSee [Messaging Documentation](docs/messaging.md) for advanced usage including custom message handlers.\n\n### Kit Management\n\nMagg supports organizing related MCP servers into \"kits\" - bundles that can be loaded and unloaded as a group:\n\n```bash\n# List available kits\nmagg kit list\n\n# Load a kit (adds all its servers)\nmagg kit load web-tools\n\n# Unload a kit (removes servers only in that kit)\nmagg kit unload web-tools\n\n# Get information about a kit\nmagg kit info web-tools\n```\n\nYou can also manage kits programmatically through Magg's tools when connected via an MCP client:\n- `magg_list_kits` - List all available kits\n- `magg_load_kit` - Load a kit and its servers\n- `magg_unload_kit` - Unload a kit\n- `magg_kit_info` - Get detailed kit information\n\nKits are JSON files stored in `~/.magg/kit.d/` or `.magg/kit.d/` that define a collection of related servers. See [Kit Documentation](docs/kits.md) for details on creating and managing kits.\n\n### MBro Scripts\n\nAutomate common workflows with MBro scripts:\n\n```bash\n# Create a setup script\ncat > setup.mbro <<EOF\n# Connect to Magg and check status\nconnect magg magg serve\ncall magg_status\ncall magg_list_servers\n\n# Add a new server if needed\ncall magg_add_server name=calculator source=\"npx -y @modelcontextprotocol/server-calculator\"\nEOF\n\n# Run the script\nmbro -x setup.mbro\n```\n\n## Documentation\n\nFor more documentation, see [docs/](docs/index.md).\n\n## Appearances\n\nMagg appears in multiple locations. Please feel free to submit a PR to add more appearances below in alphabetical order.\n\n### Listing, Index, and other MCP Sites\n\n* [DeepWiki](https://deepwiki.com/sitbon/magg) - AI-generated documentation\n* [Glama.ai](https://glama.ai/mcp/servers/@sitbon/magg) - MCP server listing and hosting\n\n### Awesome GitHub MCP Lists\n\n* [@modelcontextprotocol/servers](https://github.com/modelcontextprotocol/servers)\n* [@punkpeye/awesome-mcp-servers](https://github.com/punkpeye/awesome-mcp-servers)\n* [@wong2/awesome-mcp-servers](https://github.com/wong2/awesome-mcp-servers)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "magg",
        "aggregators",
        "mcp",
        "mcp servers",
        "mcp server",
        "magg meta"
      ],
      "category": "aggregators"
    },
    "sxhxliang--mcp-access-point": {
      "owner": "sxhxliang",
      "name": "mcp-access-point",
      "url": "https://github.com/sxhxliang/mcp-access-point",
      "imageUrl": "",
      "description": "Turn a web service into an MCP server in one click without making any code changes.",
      "stars": 130,
      "forks": 24,
      "license": "MIT License",
      "language": "Rust",
      "updated_at": "2025-10-01T15:37:24Z",
      "readme_content": "# MCP Access Point  \r\n\r\n`MCP Access Point` is a lightweight protocol conversion gateway tool designed to establish a communication bridge between traditional `HTTP` services and `MCP` (Model Context Protocol) clients. It enables MCP clients to interact directly with existing HTTP services without requiring any server-side interface modifications.  \r\n<p align=\"center\">\r\n  <a href=\"./README.md\"><img alt=\"README in English\" src=\"https://img.shields.io/badge/English-4578DA\"></a>\r\n  <a href=\"./README_CN.md\"><img alt=\"简体中文版\" src=\"https://img.shields.io/badge/简体中文-F40002\"></a>\r\n  <a href=\"https://deepwiki.com/sxhxliang/mcp-access-point\"><img src=\"https://deepwiki.com/badge.svg\" alt=\"Ask DeepWiki\"></a>\r\n  <a href=\"https://zread.ai/sxhxliang/mcp-access-point\"><img alt=\"中文文档\" src=\"https://img.shields.io/badge/中文文档-4578DA\"></a>\r\n</p>\r\n\r\n![Admin Dashboard](assets/admin_dashboard.png)\r\n\r\n## Introduction  \r\nThis project is built on `Pingora` - an ultra-high performance gateway proxy library capable of supporting massive-scale request proxy services. Pingora has been used to build services that handle core traffic for the Cloudflare platform, consistently serving over 40 million requests per second across the internet for years. It has become the technical cornerstone supporting a significant proportion of traffic on the Cloudflare platform.\r\n\r\n## HTTP to MCP  \r\nThis mode allows clients like `Cursor Desktop` to communicate with remote HTTP servers through `SSE`, even when the servers themselves don't support the SSE protocol.\r\n\r\n- Example setup includes two services:  \r\n  - Service 1 runs locally at `127.0.0.1:8090`  \r\n  - Service 2 runs remotely at `api.example.com`  \r\n- Through the `MCP Access Point`, both services can be converted to MCP services without any code modifications.  \r\n- Clients communicate with `Service 1` and `Service 2` via the MCP protocol. The MCP Access Point automatically distinguishes MCP requests and forwards them to the appropriate backend services.\r\n\r\n```mermaid\r\ngraph LR\r\n   A[\"Cursor Desktop\"] <--> |SSE| B[\"MCP Access Point\"]\r\n   A2[\"Other Desktop\"] <--> |Streamable Http| B[\"MCP Access Point\"]\r\n   B <--> |http 127.0.0.1:8090| C1[\"Existing API Server\"]\r\n   B <--> |https//api.example.com| C2[\"Existing API Server\"]\r\n  \r\n   style A2 fill:#ffe6f9,stroke:#333,color:black,stroke-width:2px\r\n   style A fill:#ffe6f9,stroke:#333,color:black,stroke-width:2px\r\n   style B fill:#e6e6af,stroke:#333,color:black,stroke-width:2px\r\n   style C1 fill:#e6ffe6,stroke:#333,color:black,stroke-width:2px\r\n   style C2 fill:#e6ffd6,stroke:#333,color:black,stroke-width:2px\r\n```\r\n\r\n### Transport Type (Specification)\r\nCurrently supports `SSE` and `Streamable HTTP` protocols:\r\n- ✅ Streamable HTTP (stateless) 2025-03-26\r\n  - All services: `ip:port/mcp`\r\n  - Single service: `ip:port/api/{service_id}/mcp`\r\n  \r\n- ✅ SSE 2024-11-05\r\n  - All services: `ip:port/sse`\r\n  - Single service: `ip:port/api/{service_id}/sse`\r\n\r\nuse `IP:PORT/sse` for `SSE` \r\nuse `IP:PORT/mcp` for `Streamable HTTP` \r\n\r\n### Supported MCP clients\r\n- ✅ [MCP Inspector](https://github.com/modelcontextprotocol/inspector)\r\n- ✅ [Cursor Desktop](https://docs.cursor.com/context/model-context-protocol)\r\n- ✅ [Windsurf](https://docs.windsurf.com/plugins/cascade/mcp#model-context-protocol-mcp)\r\n- ✅ [VS Code](https://code.visualstudio.com/docs/copilot/chat/mcp-servers)\r\n- ✅ [Trae](https://docs.trae.ai/ide/model-context-protocol)\r\n\r\n## Core Features\r\n- **Protocol Conversion**: Seamless conversion between HTTP and MCP protocols\r\n- **Zero-Intrusive Integration**: Full compatibility with existing HTTP services\r\n- **Client Empowerment**: Enables MCP clients to directly call standard HTTP services\r\n- **Lightweight Proxy**: Minimalist architecture with efficient protocol conversion\r\n- **Multi-tenancy**: Independent configuration and endpoints for each tenant\r\n- **Runtime Configuration Management**: Dynamic configuration updates without service restart\r\n- **Admin API**: RESTful API for real-time configuration management\r\n\r\n## Quick Start  \r\n\r\n### Installation  \r\n```bash\r\n# Install from source\r\ngit clone https://github.com/sxhxliang/mcp-access-point.git\r\ncd mcp-access-point\r\ncargo run -- -c config.yaml\r\n\r\n# Use inspector for debugging (start service first)\r\nnpx @modelcontextprotocol/inspector node build/index.js\r\n# Access http://127.0.0.1:6274/\r\n# Select \"SSE\" and enter 0.0.0.0:8080/sse, then click connect\r\n# or select \"Streamable HTTP\" and enter 0.0.0.0:8080/mcp\r\n```\r\n\r\n### Multi-tenancy Support\r\nThe MCP Access Gateway supports multi-tenancy, where each tenant can configure multiple MCP services accessible via:\r\n- `/api/{mcp-service-id}/sse` (for SSE)\r\n- `/api/{mcp-service-id}/mcp` (for Streamable HTTP)\r\n\r\nExample configuration:\r\n```yaml\r\n# config.yaml example (supports multiple services)\r\n\r\nmcps:\r\n  - id: service-1 # Access via /api/service-1/sse or /api/service-1/mcp\r\n    ... # Service configuration\r\n  - id: service-2 # Access via /api/service-2/sse or /api/service-2/mcp\r\n    ... # Service configuration\r\n  - id: service-3 # Access via /api/service-3/sse or /api/service-3/mcp\r\n    ... # Service configuration\r\n```\r\n\r\nTo access all services simultaneously, use:\r\n- `0.0.0.0:8080/mcp` (Streamable HTTP)\r\n- `0.0.0.0:8080/sse` (SSE)\r\n\r\n### Configuration Details\r\n1. **`-c config.yaml`**\r\n   - `-c` (or `--config`) specifies the configuration file path (`config.yaml`).\r\n   - This file defines the APIs that the MCP Access Point will proxy and convert.\r\n\r\n### config.yaml Example\r\nThe configuration file supports multi-tenancy, allowing independent configuration of upstream services and routing rules for each MCP service. Key configuration items include:\r\n\r\n1. **mcps** - MCP service list\r\n   - `id`: Unique service identifier used to generate access paths\r\n   - `upstream_id`: Associated upstream service ID\r\n   - `path`: OpenAPI specification file path. Supports local files (e.g., `config/openapi.json`) and remote HTTP/HTTPS URLs (e.g., `https://petstore.swagger.io/v2/swagger.json`). Both JSON and YAML formats are supported.\r\n   - `routes`: Custom routing configuration (optional)\r\n   - `upstream`: Upstream service specific configuration (optional)\r\n\r\n2. **upstreams** - Upstream service configuration\r\n   - `id`: Upstream service ID\r\n   - `nodes`: Backend node addresses and weights\r\n   - `type`: Load balancing algorithm (roundrobin/random/ip_hash)\r\n   - `scheme`: Upstream protocol (http/https)\r\n   - `pass_host`: HTTP Host header handling\r\n   - `upstream_host`: Override Host header value\r\n\r\nComplete configuration example:\r\n```yaml\r\n# config.yaml example (supports multiple services)\r\nmcps:\r\n  - id: service-1 # Unique identifier, accessible via /api/service-1/sse or /api/service-1/mcp\r\n    upstream_id: 1\r\n    path: config/openapi_for_demo_patch1.json # Local OpenAPI spec path\r\n\r\n  - id: service-2 # Unique identifier\r\n    upstream_id: 2\r\n    path: https://petstore.swagger.io/v2/swagger.json # Remote OpenAPI spec\r\n\r\n  - id: service-3 \r\n    upstream_id: 3\r\n    routes: # Custom routing\r\n      - id: 1\r\n        operation_id: get_weather\r\n        uri: /points/{latitude},{longitude}\r\n        method: GET\r\n        meta:\r\n          name: Get Weather\r\n          description: Retrieve weather information by coordinates\r\n          inputSchema: # Optional input validation\r\n            type: object\r\n            required:\r\n              - latitude\r\n              - longitude\r\n            properties:\r\n              latitude:\r\n                type: number\r\n                minimum: -90\r\n                maximum: 90\r\n              longitude:\r\n                type: number\r\n                minimum: -180\r\n                maximum: 180\r\n\r\nupstreams: # Required upstream configuration\r\n  - id: 1\r\n    headers: # Headers to send to upstream service\r\n      X-API-Key: \"12345-abcdef\"        # API key\r\n      Authorization: \"Bearer token123\" # Bearer token\r\n      User-Agent: \"MyApp/1.0\"          # User agent\r\n      Accept: \"application/json\"       # Accept header\r\n    nodes: # Backend nodes (IP or domain)\r\n      \"127.0.0.1:8090\": 1 # Format: address:weight\r\n\r\n  - id: 2 \r\n    nodes:\r\n      \"127.0.0.1:8091\": 1\r\n\r\n  - id: 3 \r\n    nodes:\r\n      \"api.weather.gov\": 1\r\n    type: roundrobin # Load balancing algorithm\r\n    scheme: https # Protocol\r\n    pass_host: rewrite # Host header handling\r\n    upstream_host: api.weather.gov # Override Host\r\n```\r\n\r\nTo run the MCP Access Gateway with config file:\r\n```bash\r\ncargo run -- -c config.yaml\r\n```\r\n\r\n## Running via Docker  \r\n\r\n### Run Locally for quick start\r\n\r\n```bash\r\n# Note: Replace /path/to/your/config.yaml with actual path\r\ndocker run -d --name mcp-access-point --rm \\\r\n  -p 8080:8080 \\\r\n  -e port=8080 \\\r\n  -v /path/to/your/config.yaml:/app/config/config.yaml \\\r\n  ghcr.io/sxhxliang/mcp-access-point:main\r\n```\r\n\r\n\r\n### Build Docker Image (Optional)  \r\n- install docker\r\n- clone repository and build image\r\n```bash\r\n# Clone repository\r\ngit clone https://github.com/sxhxliang/mcp-access-point.git\r\ncd mcp-access-point\r\n\r\n# Build image\r\ndocker build -t liangshihua/mcp-access-point:latest .\r\n```\r\n\r\n- Run Docker Container\r\n```bash\r\n# Using environment variables (service running on host)\r\n# Note: Replace /path/to/your/config.yaml with actual path\r\n\r\ndocker run -d --name mcp-access-point --rm \\\r\n  -p 8080:8080 \\\r\n  -e port=8080 \\\r\n  -v /path/to/your/config.yaml:/app/config/config.yaml \\\r\n  liangshihua/mcp-access-point:latest\r\n```\r\n\r\n### Environment Variables  \r\n- `port`: MCP Access Point listening port (default: 8080)\r\n\r\n## Typical Use Cases  \r\n\r\n- **Progressive Architecture Migration**: Facilitate gradual transition from HTTP to MCP  \r\n- **Hybrid Architecture Support**: Reuse existing HTTP infrastructure within MCP ecosystem  \r\n- **Protocol Compatibility**: Build hybrid systems supporting both protocols  \r\n\r\n**Example Scenario**:  \r\nWhen MCP-based AI clients need to interface with legacy HTTP microservices, the MCP Access Gateway acts as a middleware layer enabling seamless protocol conversion.\r\n\r\nMany thanks to [@limcheekin](https://github.com/limcheekin) for writing an article with a practical example: https://limcheekin.medium.com/building-your-first-no-code-mcp-server-the-fabric-integration-story-90da58cdbe1f\r\n\r\n## Runtime Configuration Management\r\n\r\nThe MCP Access Point now supports dynamic configuration management through a RESTful Admin API, allowing you to update configurations without restarting the service.\r\n\r\n### Admin API Features\r\n\r\n- **Real-time Configuration Updates**: Modify upstreams, services, routes, and other resources on-the-fly\r\n- **Dependency Validation**: Automatic validation of resource dependencies before changes\r\n- **Batch Operations**: Execute multiple configuration changes atomically\r\n- **Configuration Validation**: Dry-run mode to validate changes before applying\r\n- **Resource Statistics**: Monitor and track configuration state\r\n\r\n### Admin API Configuration\r\n\r\nAdd the following to your `config.yaml` to enable the Admin API:\r\n\r\n```yaml\r\naccess_point:\r\n  admin:\r\n    address: \"127.0.0.1:8081\"  # Admin API listening address\r\n    api_key: \"your-api-key\"    # Optional API key for authentication\r\n```\r\n\r\n### Admin API Endpoints\r\n\r\n#### Resource Management\r\n- `GET /admin/resources` - Get resource summary and statistics\r\n- `GET /admin/resources/{type}` - List all resources of a specific type\r\n- `GET /admin/resources/{type}/{id}` - Get a specific resource\r\n- `POST /admin/resources/{type}/{id}` - Create a new resource\r\n- `PUT /admin/resources/{type}/{id}` - Update an existing resource\r\n- `DELETE /admin/resources/{type}/{id}` - Delete a resource\r\n\r\n#### Advanced Operations\r\n- `POST /admin/validate/{type}/{id}` - Validate resource configuration\r\n- `POST /admin/batch` - Execute batch operations\r\n- `POST /admin/reload/{type}` - Reload a specific resource type\r\n- `POST /admin/reload/config` - Reload full configuration from file (defaults to `config.yaml`). Optional JSON body: `{ \"config_path\": \"path/to/config.yaml\" }`\r\n\r\n#### Supported Resource Types\r\n- `upstreams` - Backend server configurations\r\n- `services` - Service definitions\r\n- `routes` - Routing rules\r\n- `global_rules` - Global plugin rules\r\n- `mcp_services` - MCP service configurations\r\n- `ssls` - SSL certificate configurations\r\n\r\n### Admin API Examples\r\n\r\n#### Create a new upstream\r\n```bash\r\ncurl -X POST http://localhost:8081/admin/resources/upstreams/my-upstream \\\r\n  -H \"Content-Type: application/json\" \\\r\n  -d '{\r\n    \"id\": \"my-upstream\",\r\n    \"type\": \"RoundRobin\",\r\n    \"nodes\": [\"127.0.0.1:8001\", \"127.0.0.1:8002\"],\r\n    \"timeout\": {\r\n      \"connect\": 5,\r\n      \"read\": 10,\r\n      \"send\": 10\r\n    }\r\n  }'\r\n```\r\n\r\n#### Create a service\r\n```bash\r\ncurl -X POST http://localhost:8081/admin/resources/services/my-service \\\r\n  -H \"Content-Type: application/json\" \\\r\n  -d '{\r\n    \"id\": \"my-service\",\r\n    \"upstream_id\": \"my-upstream\",\r\n    \"hosts\": [\"api.example.com\"]\r\n  }'\r\n```\r\n\r\n#### Batch operations\r\n```bash\r\ncurl -X POST http://localhost:8081/admin/batch \\\r\n  -H \"Content-Type: application/json\" \\\r\n  -d '{\r\n    \"dry_run\": false,\r\n    \"operations\": [\r\n      {\r\n        \"operation_type\": \"create\",\r\n        \"resource_type\": \"upstreams\",\r\n        \"resource_id\": \"batch-upstream\",\r\n        \"data\": {\r\n          \"id\": \"batch-upstream\",\r\n          \"type\": \"Random\",\r\n          \"nodes\": [\"192.168.1.10:8080\"]\r\n        }\r\n      },\r\n      {\r\n        \"operation_type\": \"create\",\r\n        \"resource_type\": \"services\",\r\n        \"resource_id\": \"batch-service\",\r\n        \"data\": {\r\n          \"id\": \"batch-service\",\r\n          \"upstream_id\": \"batch-upstream\"\r\n        }\r\n      }\r\n    ]\r\n  }'\r\n```\r\n\r\n#### Get resource statistics\r\n```bash\r\ncurl http://localhost:8081/admin/resources\r\n```\r\n\r\n### Admin Dashboard UI\r\n\r\n- Route: `GET /admin` serves a built-in dashboard (`static/admin_dashboard.html`).\r\n  1) `mcp_services`, 2) `ssls`, 3) `global_rules`, 4) `routes`, 5) `upstreams`, 6) `services`.\r\n- Each card shows `count` and a formatted `last_updated` derived from the API response.\r\n\r\n#### Reload configuration from file\r\n```bash\r\n# Uses default config.yaml\r\ncurl -X POST http://localhost:8081/admin/reload/config \\\r\n  -H \"Content-Type: application/json\" \\\r\n  -H \"x-api-key: your-api-key\"\r\n\r\n# Or specify a different config path\r\ncurl -X POST http://localhost:8081/admin/reload/config \\\r\n  -H \"Content-Type: application/json\" \\\r\n  -H \"x-api-key: your-api-key\" \\\r\n  -d '{\"config_path\": \"./config.yaml\"}'\r\n```\r\n\r\n### Testing the Admin API\r\n\r\nUse the provided test script to verify Admin API functionality:\r\n\r\n```bash\r\n# Make the test script executable\r\nchmod +x test-admin-api.sh\r\n\r\n# Run comprehensive API tests\r\n./test-admin-api.sh\r\n```\r\n\r\nFor detailed Admin API documentation, see [RUNTIME_CONFIG_API.md](./RUNTIME_CONFIG_API.md).\r\n\r\n## Contribution Guidelines\r\n1. Fork this repository.\r\n2. Create a branch and commit your changes.\r\n3. Create a pull request and wait for it to be merged.\r\n4. Make sure your code follows the Rust coding standards.\r\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp",
        "aggregators",
        "servers",
        "mcp server",
        "mcp access",
        "service mcp"
      ],
      "category": "aggregators"
    },
    "tigranbs--mcgravity": {
      "owner": "tigranbs",
      "name": "mcgravity",
      "url": "https://github.com/tigranbs/mcgravity",
      "imageUrl": "",
      "description": "A proxy tool for composing multiple MCP servers into one unified endpoint. Scale your AI tools by load balancing requests across multiple MCP servers, similar to how Nginx works for web servers.",
      "stars": 71,
      "forks": 4,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-09-30T02:46:46Z",
      "readme_content": "# McGravity\n\n<div align=\"center\">\n  <img src=\"./assets/thumbnail.png\" alt=\"McGravity Thumbnail\" width=\"400\">\n</div>\n\n## About\n\nMcGravity is a tool that connects multiple MCP (Model Context Protocol) servers into one unified service. It lets you reuse the same MCP server and scale underlying MCP server connections almost infinitely.\n\nThe current version works as a basic CLI tool, but McGravity will grow to become a full-featured proxy for MCP servers - like Nginx but for modern Gen AI tools and servers.\n\n## Why McGravity?\n\n```\nWithout McGravity:\n┌─────────┐     ┌─────────┐\n│ Client  │────▶│MCP      │\n│         │     │Server 1 │\n└─────────┘     └─────────┘\n    │\n    │           ┌─────────┐\n    └──────────▶│MCP      │\n                │Server 2 │\n                └─────────┘\n```\n\n```\nWith McGravity:\n┌─────────┐     ┌─────────┐     ┌─────────┐\n│ Client  │────▶│McGravity│────▶│MCP      │\n│         │     │         │     │Server 1 │\n└─────────┘     └─────────┘     └─────────┘\n                     │\n                     │          ┌─────────┐\n                     └─────────▶│MCP      │\n                                │Server 2 │\n                                └─────────┘\n```\n\nMcGravity solves these problems:\n\n- Connect to multiple MCP servers through one endpoint\n- Balance load between MCP servers\n- Provide a single point of access for your applications\n\n## Installation\n\n```bash\n# Install dependencies\nbun install\n\n# Build the project into a single executable\nbun build src/index.ts --compile --outfile mcgravity\n```\n\n## Docker\n\nMcGravity is available on Docker Hub: [tigranbs/mcgravity](https://hub.docker.com/r/tigranbs/mcgravity).\n\n```bash\ndocker pull tigranbs/mcgravity\n\n# Basic usage\ndocker run -p 3001:3001 tigranbs/mcgravity http://mcp1.example.com http://mcp2.example.com\n\n# With custom host and port\ndocker run -p 4000:4000 tigranbs/mcgravity --host 0.0.0.0 --port 4000 http://mcp1.example.com\n```\n\n## Usage\n\nBasic command:\n\n```bash\n./mcgravity <mcp-server-address1> <mcp-server-address2> ...\n```\n\nWith options:\n\n```bash\n./mcgravity --host localhost --port 3001 http://mcp1.example.com http://mcp2.example.com\n```\n\nUsing configuration file:\n\n```bash\n./mcgravity --config config.yaml\n```\n\n### Options\n\n- `--host <host>`: Host to bind the server to (default: localhost)\n- `--port <port>`: Port to bind the server to (default: 3001)\n- `--config <path>`: Path to the config file (default: config.yaml)\n- `--mcp-version <version>`: Version of the MCP server (default: 1.0.0)\n- `--mcp-name <name>`: Name of the MCP server (default: mcgravity)\n- `--help`: Show help information\n\n### Configuration\n\nMcGravity can be configured using a YAML file. See `config.example.yaml` for a sample configuration:\n\n```yaml\nname: mcgravity\nversion: 1.0.0\ndescription: A simple MCP server\n\nservers:\n  echo-server:\n    url: http://localhost:3000/sse\n    name: echo-server\n    version: 1.0.0\n    description: A simple echo server\n    tags:\n      - echo\n```\n\nYou can run the included echo server example for testing:\n\n```bash\n# Start the echo server first\nbun examples/echo-server.ts\n\n# Then start McGravity pointing to the echo server\n./mcgravity --config config.yaml\n```\n\n## Examples\n\nStart McGravity with default settings:\n\n```bash\n./mcgravity http://mcp1.example.com http://mcp2.example.com\n```\n\nSpecify host and port:\n\n```bash\n./mcgravity --host 0.0.0.0 --port 4000 http://mcp1.example.com http://mcp2.example.com\n```\n\n## Running Tests\n\nTo run all tests:\n\n```bash\nbun test\n```\n\nTo run integration tests only:\n\n```bash\nbun run test:integration\n```\n\n### Integration Tests\n\nThe integration tests verify that McGravity can:\n\n1. Connect to an MCP server (the example echo server)\n2. Correctly proxy capabilities from the target MCP server\n3. Pass requests from clients to the target MCP server and return responses\n\nFor more details about the test suite, see the [test README](test/README.md).\n\nThe tests are automatically run in GitHub Actions CI on push and PR events.\n\n## Future Plans\n\nMcGravity will expand to include:\n\n- Web interface for monitoring\n- Advanced load balancing\n- MCP server health checks\n- Authentication and access control\n- Plugin system for custom integrations\n\n## Development\n\n### TypeScript and Code Style\n\nThis project uses:\n\n- TypeScript with Bun runtime\n- ESLint for code linting with TypeScript-specific rules\n- Prettier for code formatting\n\nThe configuration is optimized for Bun with appropriate TypeScript settings for the runtime environment.\n\nRun the following commands:\n\n```bash\n# Format code with Prettier\nbun run format\n\n# Check if code is properly formatted\nbun run format:check\n\n# Lint code with ESLint\nbun run lint\n\n# Fix auto-fixable linting issues\nbun run lint:fix\n```\n\nVS Code is configured to format code on save and provide linting information when the recommended extensions are installed.\n\n## Contributing\n\nContributions are welcome! Feel free to open issues or submit pull requests.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "aggregators",
        "mcp",
        "mcgravity",
        "mcp servers",
        "mcgravity proxy",
        "mcp server"
      ],
      "category": "aggregators"
    },
    "wegotdocs--open-mcp": {
      "owner": "wegotdocs",
      "name": "open-mcp",
      "url": "https://github.com/wegotdocs/open-mcp",
      "imageUrl": "",
      "description": "Turn a web API into an MCP server in 10 seconds and add it to the open source registry: https://open-mcp.org",
      "stars": 267,
      "forks": 30,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-10-02T06:44:03Z",
      "readme_content": "# OpenMCP\n\nhttps://www.open-mcp.org\n\nOpenMCP is both:\n\n1. a standard for converting web APIs into MCP servers\n2. an open source registry of servers which follow the standard\n\nEach OpenMCP server gives MCP clients the ability to make requests to a particular web API in a token-efficient way. Together the servers in the registry represent a broad range of services, empowering the underlying client LLMs to fetch data and perform actions on behalf of their users across many domains.\n\n## Contents\n\n- [Creating a server](#creating-a-server)\n- [Adding OpenMCP servers to MCP clients](#adding-openmcp-servers-to-mcp-clients)\n- [Converting web API -> OpenMCP](#converting-web-api---openmcp)\n\n## Creating a server\n\nhttps://www.open-mcp.org/servers/creating-a-server\n\n## Adding OpenMCP servers to MCP clients\n\n### Remote hosting\n\n...\n\n### Local hosting\n\n<div>\n  <a href=\"https://www.loom.com/share/aa26fed41f084ff1bd115436f9d799dd\">\n    <p>Local hosting demo - watch video</p>\n  </a>\n  <a href=\"https://www.loom.com/share/aa26fed41f084ff1bd115436f9d799dd\">\n    <img style=\"max-width:300px;\" src=\"https://cdn.loom.com/sessions/thumbnails/aa26fed41f084ff1bd115436f9d799dd-9815ccb91b155b9d-full-play.gif\">\n  </a>\n</div>\n\n#### Requirements:\n\n- Node.js v18 or later (includes npx and npm)\n\n#### Claude desktop\n\n```bash\nnpx @open-mcp/config add {server-id} \\\n  ~/Library/Application\\ Support/Claude/claude_desktop_config.json \\\n  --ENV_VAR=abc123\n```\n\nNow restart Claude desktop to load the tools.\n\n#### Cursor\n\nRun this from the root of your project directory or, to add to all cursor projects, run it from your home directory `~`.\n\n```bash\nnpx @open-mcp/config add {server-id} \\\n  .cursor/mcp.json \\\n  --ENV_VAR=abc123\n```\n\nNow go to `Cursor > Settings > Cursor Settings` then click `MCP` to ensure the server is enabled.\n\n#### Other clients\n\n```bash\nnpx @open-mcp/config add {server-id} \\\n  /path/to/config.json \\\n  --ENV_VAR=abc123\n```\n\n#### Alternatives\n\nIf you don't want to use the CLI you can use `npm` to install the package manually, then add a `node` command to your client config with an absolute path to `dist/index.js`. See the individual server READMEs for more details.\n\n## Converting web API -> OpenMCP\n\n### REST `openapi.yaml` / `openapi.json`\n\n...\n\n### gRPC `service.proto`\n\n...\n\n### JSON-RPC `openrpc.json`\n\n...\n\n### GraphQL `schema.gql`\n\n...\n\n### SOAP `service.wsdl`\n\n...\n\n### PostgREST `schema.sql`\n\n...\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "aggregators",
        "mcp",
        "api",
        "mcp server",
        "api mcp",
        "aggregators servers"
      ],
      "category": "aggregators"
    }
  }
}