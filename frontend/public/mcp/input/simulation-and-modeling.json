{
  "category": "simulation-and-modeling",
  "categoryDisplay": "Simulation and Modeling",
  "description": "",
  "totalRepositories": 9,
  "repositories": {
    "3a3--fujitsu-sdt-mcp": {
      "owner": "3a3",
      "name": "fujitsu-sdt-mcp",
      "url": "https://github.com/3a3/fujitsu-sdt-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/3a3.webp",
      "description": "The Fujitsu Social Digital Twin Server allows users to interact with a simulation of social and traffic scenarios through natural language commands. It enables running simulations, analyzing results, and retrieving simulation data easily.",
      "stars": 2,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-27T17:38:46Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/3a3-fujitsu-sdt-mcp-badge.png)](https://mseep.ai/app/3a3-fujitsu-sdt-mcp)\n\n# Fujitsu Social Digital Twin MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@3a3/fujitsu-sdt-mcp)](https://smithery.ai/server/@3a3/fujitsu-sdt-mcp)\n\nThis project integrates [Fujitsu's Social Digital Twin and Digital Rehearsal API](https://portal.research.global.fujitsu.com/converging-technology/) with the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/), allowing Large Language Models (LLMs) to access Fujitsu's Digital Rehearsal API through natural language.\n\n<a href=\"https://glama.ai/mcp/servers/@3a3/fujitsu-sdt-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@3a3/fujitsu-sdt-mcp/badge\" alt=\"Fujitsu Social Digital Twin Server MCP server\" />\n</a>\n\n## Overview\n\nFujitsu's Social Digital Twin recreates not only the state of people and objects in the digital space based on real-world data, but also entire economic and social activities. Its core function, \"Digital Rehearsal,\" enables users to simulate human and social behavior in a digital space before implementing measures in the real world, allowing for advance verification of their effects and impacts.\n\nThis project uses MCP to bridge the gap between LLMs and the Digital Rehearsal API, enabling users to run simulations and analyze results using natural language.\n\n## Key Features\n\n- Retrieve and display simulation lists\n- Start simulations\n- Retrieve and analyze simulation results\n- Manage simulation data\n- Analyze traffic simulations\n- Compare scenarios\n- Generate simulation configurations from natural language\n\n## Prerequisites\n\n- Python 3.13 or higher\n- Access to Fujitsu API Gateway (API Key)\n- MCP-compatible LLM client (e.g., Claude Desktop)\n\n## Installation\n\n### Installing via Smithery\n\nTo install Fujitsu Social Digital Twin Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@3a3/fujitsu-sdt-mcp):\n\n```bash\nnpx -y @smithery/cli install @3a3/fujitsu-sdt-mcp --client claude\n```\n\n### 1. Clone the Repository\n\n```bash\ngit clone https://github.com/3a3/fujitsu-sdt-mcp.git\ncd fujitsu-sdt-mcp\n```\n\n### 2. Set Up Environment\n\n**Using uv (recommended)**:\n\nFirst, install uv:\n\n```bash\n# Install uv using pip\npip install uv\n\n# Or using curl (Linux/macOS)\ncurl -sSf https://astral.sh/uv/install.sh | sh\n```\n\nThen, set up your environment with uv:\n\n```bash\n# Create virtual environment\nuv venv\n\n# Activate virtual environment\n# Windows:\n.venv\\Scripts\\activate\n# Unix/MacOS:\nsource .venv/bin/activate\n\n# Install dependencies\nuv pip install -r requirements.txt\n```\n\nAlternatively, you can use the provided setup script:\n\n```bash\n# Make the script executable\nchmod +x setup.sh\n\n# Run setup\n./setup.sh\n```\n\n### 3. Set Environment Variables\n\n```bash\n# Windows:\nset FUJITSU_API_BASE_URL=https://apigateway.research.global.fujitsu.com/sdtp\nset FUJITSU_API_KEY=your_api_key_here\n\n# Unix/MacOS:\nexport FUJITSU_API_BASE_URL=https://apigateway.research.global.fujitsu.com/sdtp\nexport FUJITSU_API_KEY=your_api_key_here\n```\n\nAlternatively, you can create a `.env` file with the following settings:\n\n```\nFUJITSU_API_BASE_URL=https://apigateway.research.global.fujitsu.com/sdtp\nFUJITSU_API_KEY=your_api_key_here\n```\n\n## Usage\n\n### Starting the MCP Server\n\n```bash\npython -m fujitsu_sdt_mcp\n```\n\nThe server communicates using standard I/O with MCP clients.\n\n### Using the Interactive Client\n\nA simple client is also provided for direct interaction with the MCP server:\n\n```bash\npython client.py\n```\n\nWhen you start the client, a list of available resources and tools will be displayed, and you can call them from the command line.\n\n### Setup with Claude Desktop\n\nTo use the server with MCP-compatible LLM clients such as Claude Desktop:\n\n1. Open Claude Desktop\n2. Go to Settings > Developer Settings > Edit Config File\n3. Add the following settings:\n\n```json\n\"command\": \"uvx\",\n\"args\": [\n    \"fujitsu-sdt-mcp\"\n],\n\"env\": {\n    \"FUJITSU_API_BASE_URL\": \"https://apigateway.research.global.fujitsu.com/sdtp\",\n    \"FUJITSU_API_KEY\": \"your_api_key_here\"\n}\n```\n\n4. Restart Claude Desktop\n\n## Resources and Tools\n\n### Resources\n\n- `resource://digital_rehearsal_overview`: Overview of Digital Rehearsal technology\n- `resource://simulation_metrics_explanation`: Explanation of simulation metrics\n- `resource://scenario_examples`: Example scenarios\n\n### Tools\n\n- `list_simulations`: Retrieve a list of simulations\n- `start_simulation`: Start a simulation\n- `get_simulation_result`: Retrieve simulation results\n- `get_metrics`: Retrieve simulation metrics\n- `list_simdata`: Retrieve a list of simulation data\n- `get_simdata`: Retrieve simulation data\n- `analyze_traffic_simulation`: Analyze traffic simulation\n- `compare_scenarios`: Compare scenarios\n- `create_natural_language_simulation_config`: Generate simulation settings from natural language\n\n## Usage Examples\n\n### Retrieving a List of Simulations\n\n```\ntool list_simulations\n```\n\n### Starting a Simulation\n\n```\ntool start_simulation {\"simdataId\": \"your_simdata_id\"}\n```\n\n### Analyzing Traffic Simulation\n\n```\ntool analyze_traffic_simulation {\"simulationId\": \"your_simulation_id\", \"region\": \"Tokyo\", \"timeRange\": \"morning rush hour\", \"scenario\": \"traffic optimization\"}\n```\n\n### Generating Simulation Settings from Natural Language\n\n```\ntool create_natural_language_simulation_config {\"description\": \"I want to run a traffic optimization simulation during morning rush hour in Tokyo\"}\n```\n\n## Example LLM Interaction\n\n```\nUser: I want to run a traffic simulation during morning rush hour in Tokyo\n\nClaude: I can help you run a traffic simulation for Tokyo's morning rush hour. Here's how we can set it up.\n\nFirst, let's generate simulation settings from your natural language description:\n[Tool execution: create_natural_language_simulation_config]\n\nGenerated settings:\n{\n  \"simulationType\": \"traffic\",\n  \"parameters\": {\n    \"region\": \"Tokyo\",\n    \"timeRange\": \"morning_rush\"\n  },\n  \"name\": \"traffic_20250416_123045\"\n}\n\nNext, let's check available simulation data:\n[Tool execution: list_simdata]\n\nFrom this data, I can start a simulation using Tokyo's morning traffic data.\nI've selected the appropriate simulation data ID and will start the simulation:\n[Tool execution: start_simulation]\n\nThe simulation has started. The simulation ID is \"sim_12345\".\nIt will take some time for the results to be available. Once complete, I'll analyze them.\n\n(After simulation completes)\nLet's analyze the simulation results:\n[Tool execution: analyze_traffic_simulation]\n\nAnalysis results:\n- CO2 emissions: 1,250kg\n- Average travel time: 42 minutes\n- Total traffic volume: 15,700 vehicles\n\nFrom these results, I can see that the Shibuya-Shinjuku route experiences particularly severe congestion.\nHere are some potential improvements:\n1. Optimize traffic signal control\n2. Implement one-way traffic on certain roads during specific times\n3. Increase public transportation frequency\n\nWould you like to see a more detailed analysis?\n```\n\n## Contributing\n\nPlease report bugs or feature requests via GitHub Issues. Pull requests are welcome.\n\n## License\n\nThis project is released under the MIT License. See the LICENSE file for details.\n\n## Acknowledgments\n\n- Fujitsu Corporation - Development of Social Digital Twin technology\n- Model Context Protocol (MCP) - Enabling seamless integration with LLMs\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "simulations",
        "fujitsu",
        "simulation",
        "simulation social",
        "fujitsu social",
        "fujitsu sdt"
      ],
      "category": "simulation-and-modeling"
    },
    "BearNetwork-BRNKC--SketchUp-MCP": {
      "owner": "BearNetwork-BRNKC",
      "name": "SketchUp-MCP",
      "url": "https://github.com/BearNetwork-BRNKC/SketchUp-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/BearNetwork-BRNKC.webp",
      "description": "Integrates Sketchup with Claude AI for real-time interaction and control of 3D modeling tasks. Facilitate the creation, modification, and manipulation of components and materials through direct Ruby code execution and fetch details from the current Sketchup scene.",
      "stars": 11,
      "forks": 1,
      "license": "MIT License",
      "language": "Ruby",
      "updated_at": "2025-08-28T16:17:32Z",
      "readme_content": "# SketchupMCP - Sketchup 模型上下文協議（MCP）整合\n[![smithery badge](https://smithery.ai/badge/@BearNetwork-BRNKC/SketchUp-MCP)](https://smithery.ai/server/@BearNetwork-BRNKC/SketchUp-MCP)\n\nSketchupMCP 透過模型上下文協議（MCP）將 Sketchup 連接到 Claude AI，使 Claude 能夠直接與 Sketchup 互動和控制。這項整合允許使用提示輔助 3D 建模、場景創建和操作 Sketchup。\n\n特別感謝 [mhyrr/sketchup-mcp](https://github.com/mhyrr/sketchup-mcp) 提供的架構。\n我們對其原生版本(mhyrr/sketchup-mcp)進行了繁體中文化及部份功能優化與調整。\n\n## 功能\n\n* **雙向通信**：透過 TCP 套接字連接 Claude AI 與 Sketchup\n* **組件操作**：在 Sketchup 中創建、修改、刪除和變換組件\n* **材質控制**：應用和修改材質與顏色\n* **場景檢查**：獲取當前 Sketchup 場景的詳細資訊\n* **選取處理**：獲取並操作已選取的組件\n* **Ruby 代碼執行**：在 Sketchup 中直接執行任意 Ruby 代碼，以進行高級操作\n\n## 組件\n\n該系統由兩個主要組件組成：\n\n1. **Sketchup 擴展**：在 Sketchup 內部創建 TCP 伺服器來接收並執行命令的擴展\n2. **MCP 伺服器（`sketchup_mcp/server.py`）**：實作模型上下文協議並連接到 Sketchup 擴展的 Python 伺服器\n\n## 安裝\n\n### 安裝 Sketchup 擴展\n\n1. 下載或自行構建最新的 `.rbz` 檔案\n2. 在 Sketchup 中，前往 **Window > Extension Manager**\n3. 點擊 **Install Extension**，然後選擇下載的 `.rbz` 檔案\n4. 重新啟動 Sketchup\n\n### Python 套件安裝\n\n我們使用 `uv` 來管理 Python 環境，因此需要先安裝 `uv`：\n\n```sh\npip install uv\n```\n\n### Installing via Smithery\n\n要使用  [Smithery](https://smithery.ai/server/@BearNetwork-BRNKC/SketchUp-MCP) 安裝 Sketchup MCP：\n\n```bash\nnpx -y @smithery/cli install @BearNetwork-BRNKC/SketchUp-MCP --client claude\n```\n\n### 安裝 Sketchup 擴展\n\n1. 下載或自行構建最新的 `.rbz` 檔案\n2. 在 Sketchup 中，前往 **Window > Extension Manager**\n3. 點擊 **Install Extension**，然後選擇下載的 `.rbz` 檔案\n4. 重新啟動 Sketchup\n\n## 使用方式\n\n### 啟動連線\n\n1. 在 Sketchup 中，前往 **Extensions > SketchupMCP > Start Server**\n2. 伺服器將預設啟動在 **9876** 端口\n3. 確保 MCP 伺服器已在終端執行\n\n### 與 Claude 配合使用\n\n在 Claude 配置中加入以下內容，以使用 MCP 伺服器：\n\n```json\n\"mcpServers\": {\n    \"sketchup\": {\n        \"command\": \"uvx\",\n        \"args\": [\n            \"sketchup-mcp\"\n        ]\n    }\n}\n```\n\n這將自動從 [PyPI](https://pypi.org/project/sketchup-mcp/) 下載最新版本。\n\n成功連接後，Claude 將能夠透過以下功能與 Sketchup 互動：\n\n#### 工具\n\n* `get_scene_info` - 獲取當前 Sketchup 場景資訊\n* `get_selected_components` - 獲取當前選取的組件資訊\n* `create_component` - 創建新組件並指定參數\n* `delete_component` - 從場景中刪除組件\n* `transform_component` - 移動、旋轉或縮放組件\n* `set_material` - 為組件應用材質\n* `export_scene` - 將當前場景匯出為多種格式\n* `eval_ruby` - 在 Sketchup 中執行任意 Ruby 代碼以進行高級操作\n\n### 指令示例\n\n以下是一些可以要求 Claude 執行的操作示例：\n\n* \"創建一個帶有屋頂和窗戶的簡單房屋模型\"\n* \"選取所有組件並獲取它們的資訊\"\n* \"將選取的組件變成紅色\"\n* \"將選取的組件向上移動 10 個單位\"\n* \"將當前場景匯出為 3D 模型\"\n* \"使用 Ruby 代碼創建一個複雜的藝術與工藝櫃\"\n\n## 疑難排解\n\n* **連線問題**：確保 Sketchup 擴展伺服器和 MCP 伺服器都在運行\n* **命令執行失敗**：檢查 Sketchup 的 Ruby 控制台以查看錯誤訊息\n* **超時錯誤**：嘗試簡化請求或將操作拆分為較小的步驟\n\n## 技術細節\n\n### 通信協議\n\n該系統使用基於 TCP 套接字的簡單 JSON 協議：\n\n* **命令** 以 JSON 物件的形式發送，包含 `type` 和可選的 `params`\n* **回應** 以 JSON 物件的形式返回，包含 `status` 及 `result` 或 `message`\n\n## 授權\n\nMIT 授權許可證\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "sketchup",
        "modeling",
        "brnkc",
        "brnkc sketchup",
        "sketchup mcp",
        "integrates sketchup"
      ],
      "category": "simulation-and-modeling"
    },
    "InditexTech--mcp-server-simulator-ios-idb": {
      "owner": "InditexTech",
      "name": "mcp-server-simulator-ios-idb",
      "url": "https://github.com/InditexTech/mcp-server-simulator-ios-idb",
      "imageUrl": "/freedevtools/mcp/pfp/InditexTech.webp",
      "description": "Control iOS simulators using natural language commands to automate app management, UI interactions, and debugging tasks, streamlining the development workflow.",
      "stars": 261,
      "forks": 18,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-10-02T18:22:07Z",
      "readme_content": "# 📱 MCP Server for iOS Simulator\n\n[![MCP Server](https://glama.ai/mcp/servers/@InditexTech/mcp-server-simulator-ios-idb/badge)](https://glama.ai/mcp/servers/@InditexTech/mcp-server-simulator-ios-idb)\n\nA Model Context Protocol (MCP) server that enables LLMs to interact with iOS simulators through natural language commands.\n\n## ℹ️ Overview\n\nThis MCP server provides a bridge between Large Language Models (LLMs) and iOS simulators, offering comprehensive control through natural language commands. Here's what it can do:\n\nFor detailed usage, see the Installation guide and Supported Commands sections. You can use this server either through direct MCP integration or as a standalone library.\n\nCheck out the Architecture section to understand how the components work together to enable natural language control of iOS simulators.\n\n\n\n### 🎮 Simulator Control\n- Create and manage simulator sessions\n- Boot, shutdown, and monitor simulator states\n- List available and running simulators\n- Focus simulator windows\n\n### 📱 Application Management\n- Install and manage iOS applications\n- Launch, terminate, and uninstall apps\n- Monitor app states and verify installations\n- Handle app permissions and configurations\n\n### 🖱️ UI Interaction & Testing\n- Interact with the simulator UI\n- Execute tap, swipe, and button press actions\n- Input text and key sequences\n- Access accessibility elements for UI testing\n- Record videos of UI interactions\n\n### 🛠️ Development & Debugging\n- Capture screenshots and system logs\n- Debug applications in real-time\n- Monitor and analyze crash logs\n- Install dynamic libraries and manage app data\n\n### ⚡ Advanced Features\n- Additional functionality includes:\n  - Location simulation\n  - Media injection\n  - URL scheme handling\n  - Contact database management\n  - Keychain operations\n\nFor detailed usage, see the Installation guide and Supported Commands sections. You can use this server either through direct MCP integration or as a standalone library.\n\nCheck out the Architecture section to understand how the components work together to enable natural language control of iOS simulators.\n\n## 📋 Requirements\n\n- **macOS**: Required for iOS simulator support\n- **Node.js**: v14.0.0 or higher\n- **Homebrew**: Required for installing dependencies\n- **XCode**: With iOS simulators installed\n\n## 🚀 Installation\n\nThe easiest way to install this server is through Cline:\n\n1. Simply ask Cline:\n```\nAdd this mcp to cline https://github.com/InditexTech/mcp-server-simulator-ios-idb\n```\n\n2. Cline will handle the installation process automatically, including dependency management and configuration.\n\nAlternatively, you can install it manually:\n\n```bash\n# Clone the repository\ngit clone https://github.com/InditexTech/mcp-server-simulator-ios-idb.git\ncd mcp-server-simulator-ios-idb\n\n# Create and activate Python virtual environment\npython3 -m venv venv\nsource venv/bin/activate  # On Unix/macOS\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n\n# Start the project\nnpm start\n\n# Run tests\nnpm test\n```\n\nThe installation process will automatically:\n1. Check if you're running macOS\n2. Install idb-companion via Homebrew\n3. Install fb-idb via pip in the virtual environment\n\nNote: Make sure to keep the virtual environment activated while using the server. If you close your terminal and come back later, you'll need to reactivate the virtual environment with the `source venv/bin/activate` command before running `npm start`.\n\n## 🔌 MCP Integration\n\nTo use this server with Claude or other LLM assistants:\n\n1. Add the server to your MCP settings in Claude Desktop:\n\n```json\n{\n  \"mcpServers\": {\n    \"ios-simulator\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-server-simulator-ios-idb/dist/index.js\"],\n      \"env\": {}\n    }\n  }\n}\n```\n\n2. The LLM can now use natural language commands to control iOS simulators:\n\n```\ncreate a simulator session with iPhone 14\ninstall app /path/to/my-app.ipa\nlaunch app com.example.myapp\ntap at 100, 200\ntake a screenshot\n```\n\n## 📚 Usage as a Library\n\nYou can also use this package as a library in your own projects:\n\n### 🔰 Basic Usage\n\n```typescript\nimport { createMCPServer } from 'mcp-server-simulator-ios-idb';\n\nasync function main() {\n  // Create an instance of the MCP server\n  const { orchestrator } = createMCPServer();\n  \n  // Process natural language commands\n  \n  // Create a simulator session\n  const sessionResult = await orchestrator.processInstruction('create session');\n  console.log(`Session created: ${sessionResult.data}`);\n  \n  // Interact with the simulator\n  await orchestrator.processInstruction('tap at 100, 200');\n  \n  // Capture a screenshot\n  const screenshotResult = await orchestrator.processInstruction('take screenshot');\n  console.log(`Screenshot saved at: ${screenshotResult.data}`);\n}\n\nmain().catch(console.error);\n```\n\n### 🚀 Advanced Usage\n\nYou can also use the individual components directly:\n\n```typescript\nimport { \n  IDBManager, \n  NLParser, \n  MCPOrchestrator,\n  ParserToOrchestrator,\n  OrchestratorToIDB\n} from 'mcp-server-simulator-ios-idb';\n\n// Create instances\nconst idbManager = new IDBManager();\nconst parser = new NLParser();\nconst orchestrator = new MCPOrchestrator(parser, idbManager);\n\n// Use the components directly\nconst sessionId = await idbManager.createSimulatorSession({\n  deviceName: 'iPhone 12',\n  platformVersion: '15.0'\n});\n\nawait idbManager.tap(sessionId, 100, 200);\n```\n\n## 🏗️ Project Structure\n\n```\nmcp-server-simulator-ios-idb/\n├── src/                      # Source code\n│   ├── adapters/             # Adapter components\n│   ├── idb/                  # IDB manager implementation\n│   ├── mcp/                  # MCP server implementation\n│   ├── orchestrator/         # Command orchestrator\n│   ├── parser/              # Natural language parser\n│   └── index.ts             # Main entry point\n├── types/                   # TypeScript type definitions\n├── scripts/                 # Installation scripts\n├── package.json            # Project configuration\n└── tsconfig.json          # TypeScript configuration\n```\n\n## 🎯 Supported Commands\n\nThe NLParser supports the following natural language commands:\n\n### 🎮 Simulator Management\n| Command | Description | Example |\n|---------|-------------|---------|\n| Create session | Creates a new simulator session | \"create session\", \"create simulator iPhone 12\" |\n| Terminate session | Terminates the current session | \"terminate session\", \"close simulator\" |\n| List simulators | Lists available simulators | \"list simulators\", \"show simulators\" |\n| List booted simulators | Lists running simulators | \"list booted simulators\", \"show running simulators\" |\n| Boot simulator | Boots a simulator by UDID | \"boot simulator 5A321B8F-4D85-4267-9F79-2F5C91D142C2\" |\n| Shutdown simulator | Shuts down a simulator | \"shutdown simulator 5A321B8F-4D85-4267-9F79-2F5C91D142C2\" |\n| Focus simulator | Brings simulator window to front | \"focus simulator\", \"bring simulator to front\" |\n| List simulator sessions | Lists active simulator sessions | \"list simulator sessions\", \"show active sessions\" |\n\n### 📱 App Management\n| Command | Description | Example |\n|---------|-------------|---------|\n| Install app | Installs an app on the simulator | \"install app /path/to/app.ipa\" |\n| Launch app | Launches an app on the simulator | \"launch app com.example.app\" |\n| Terminate app | Terminates a running app | \"terminate app com.example.app\" |\n| Uninstall app | Uninstalls an app | \"uninstall app com.example.app\" |\n| List apps | Lists installed applications | \"list apps\", \"show installed apps\" |\n| Check if app installed | Checks if an app is installed | \"is app com.example.app installed\" |\n\n### 🖱️ UI Interaction\n| Command | Description | Example |\n|---------|-------------|---------|\n| Tap | Taps at specific coordinates | \"tap at 100, 200\" |\n| Swipe | Performs a swipe gesture | \"swipe from 100, 200 to 300, 400\" |\n| Press button | Presses a device button | \"press button HOME\", \"press button SIRI\" |\n| Input text | Types text | \"input text Hello World\" |\n| Press key | Presses a key by code | \"press key 4\" |\n| Press key sequence | Presses a sequence of keys | \"press key sequence 4 5 6\" |\n\n### ♿ Accessibility\n| Command | Description | Example |\n|---------|-------------|---------|\n| Describe elements | Lists all accessibility elements | \"describe all elements\", \"show accessibility elements\" |\n| Describe point | Describes element at coordinates | \"describe point 100, 200\", \"what's at 150, 300\" |\n\n### 📸 Capture and Logs\n| Command | Description | Example |\n|---------|-------------|---------|\n| Take screenshot | Captures a screenshot | \"take screenshot\", \"capture screen\" |\n| Record video | Records screen activity | \"record video /path/output.mp4\" |\n| Stop recording | Stops video recording | \"stop recording\", \"stop video recording\" |\n| Get logs | Retrieves system or app logs | \"get logs\", \"get logs for com.example.app\" |\n\n### 🐛 Debug\n| Command | Description | Example |\n|---------|-------------|---------|\n| Start debug | Starts a debug session | \"debug app com.example.app\", \"start debug com.example.app\" |\n| Stop debug | Stops a debug session | \"stop debug\", \"terminate debug session\" |\n| Debug status | Gets debug session status | \"debug status\", \"show debug info\" |\n\n### 💥 Crash Logs\n| Command | Description | Example |\n|---------|-------------|---------|\n| List crash logs | Lists available crash logs | \"list crash logs\", \"show crash logs\" |\n| Show crash log | Shows content of a crash log | \"show crash log crash_2023-01-01\" |\n| Delete crash logs | Deletes crash logs | \"delete crash logs\", \"clear crash logs\" |\n\n### 🔧 Additional Commands\n| Command | Description | Example |\n|---------|-------------|---------|\n| Install dylib | Installs a dynamic library | \"install dylib /path/to/library.dylib\" |\n| Open URL | Opens a URL in the simulator | \"open url https://example.com\" |\n| Clear keychain | Clears the simulator's keychain | \"clear keychain\" |\n| Set location | Sets the simulator's location | \"set location 37.7749, -122.4194\" |\n| Add media | Adds media to the camera roll | \"add media /path/to/image.jpg\" |\n| Approve permissions | Approves app permissions | \"approve permissions com.example.app photos camera\" |\n| Update contacts | Updates contacts database | \"update contacts /path/to/contacts.sqlite\" |\n\nThe interface supports all commands available in the idb CLI tool, providing a comprehensive set of operations for iOS simulator automation.\n\n## 🔍 Architecture\n\nThe server consists of three main components:\n\n1. **IDBManager**: Low-level component that interacts directly with iOS simulators through idb.\n2. **NLParser**: Component that interprets natural language instructions and converts them into structured commands.\n3. **MCPOrchestrator**: Central component that coordinates interactions between the parser and the IDBManager.\n\nThese components are connected through adapters:\n- **ParserToOrchestrator**: Converts parser results into orchestrator commands.\n- **OrchestratorToIDB**: Translates orchestrator commands into IDBManager calls.\n\n## 🔌 MCP Integration\n\nTo use this server with the Model Context Protocol:\n\n1. Add the server to your MCP settings:\n\n```json\n{\n  \"mcpServers\": {\n    \"ios-simulator\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-server-simulator-ios-idb/dist/index.js\"],\n      \"env\": {}\n    }\n  }\n}\n```\n\n2. Connect to the server in your LLM application:\n\n```typescript\nconst result = await useMcpTool({\n  serverName: \"ios-simulator\",\n  toolName: \"process-instruction\",\n  arguments: {\n    instruction: \"create simulator session\"\n  }\n});\n```\n\n## 🙏 Acknowledgments\n\nThis project would not be possible without [facebook/idb](https://github.com/facebook/idb), which provides the underlying iOS simulator control capabilities. We extend our sincere gratitude to the Facebook/Meta team and all contributors to the idb project for creating and maintaining such a powerful and reliable tool.\n\n## 📄 License\n\nThis tool is available as open source under the terms of the Apache-2.0.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "simulators",
        "simulator",
        "ios",
        "ios simulators",
        "simulator ios",
        "simulators using"
      ],
      "category": "simulation-and-modeling"
    },
    "JotaDeRodriguez--Bonsai_mcp": {
      "owner": "JotaDeRodriguez",
      "name": "Bonsai_mcp",
      "url": "https://github.com/JotaDeRodriguez/Bonsai_mcp",
      "imageUrl": "/freedevtools/mcp/pfp/JotaDeRodriguez.webp",
      "description": "Connects Blender with Claude to analyze and manipulate IFC models, enabling querying of project information, exploration of spatial structures, and execution of Python code within Blender.",
      "stars": 26,
      "forks": 6,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T21:36:13Z",
      "readme_content": "\n# Bonsai-mcp - Model Context Protocol Integration for IFC through IfcOpenShell and Blender\n\nBonsai-mcp is a fork of [BlenderMCP](https://github.com/ahujasid/blender-mcp) that extends the original functionality with dedicated support for IFC (Industry Foundation Classes) models through Bonsai. This integration is a platform to let LLMs read and modify IFC files.\n\n## Features\n\n- **IFC-specific functionality**: Query IFC models, analyze spatial structures, examine building elements and extract quantities\n\n- **Eleven IFC tools included**: Inspect project info, list entities, examine properties, explore spatial structure, analyze relationships and more\n\n- **Sequential Thinking**: Includes the sequential thinking tool from [modelcontextprotocol/servers](https://github.com/modelcontextprotocol/servers/tree/main/src/sequentialthinking) for structured problem solving\n\n- **Execute Code tool from the original BlenderMCP implementation**: Create and modify objects, apply materials, and execute Python code in Blender\n\n## Components\n\nThe system consists of two main components:\n\n1. **Blender Addon (`addon.py`)**: A Blender addon that creates a socket server within Blender to receive and execute commands, including IFC-specific operations\n\n2. **MCP Server (`tools.py`)**: A Python server that implements the Model Context Protocol and connects to the Blender addon\n\n## Installation - Through MCP Client Settings\n\n### Prerequisites\n\n- Blender 4.0 or newer\n\n- Python 3.12 or newer\n\n- uv package manager\n\n- Bonsai BIM addon for Blender (for IFC functionality)\n\n**Installing uv:**\n\n**Mac:**\n\n```bash\n\nbrew  install  uv\n\n```\n\n**Windows:**\n\n```bash\n\npowershell  -c  \"irm https://astral.sh/uv/install.ps1 | iex\"\n\nset  Path=C:\\Users\\[username]\\.local\\bin;%Path%\n\n```\n\nFor other platforms, see the [uv installation guide](https://docs.astral.sh/uv/getting-started/installation/).\n\n### Clone the repository\n\n```bash\n\ngit  clone  https://github.com/JotaDeRodriguez/Bonsai_mcp\n\n```\n\n### Claude for Desktop Integration\n\nEdit your `claude_desktop_config.json` file (Claude > Settings > Developer > Edit Config) to include:\n\n```json\n{\n    \"mcpServers\": {\n        \"Bonsai-mcp\": {\n            \"command\": \"uv\",\n            \"args\": [\n              \"--directory\",\n              \"\\\\your\\\\path\\\\to\\\\Bonsai_mcp\",\n              \"run\",\n              \"tools.py\"\n          ]\n        }\n    }\n}\n\n```\n\n## Installation via Docker\n\nThe repository comes with a Dockerfile that makes deployment simple and consistent across different environments.\n\n## Quick Start\n\n```bash\n# Clone the repository\ngit clone https://github.com/JotaDeRodriguez/Bonsai_mcp\ncd Bonsai_mcp\n\n# Build the Docker image\ndocker build -t bonsai_mcp .\n\n# Run the container\ndocker run -p 8000:8000 --name bonsai_mcp bonsai_mcp\n```\n\nOnce running, the container will expose the MCP tools as REST/OpenAPI APIs at `http://localhost:8000`.\n\n- To verify youtr installation, open your browser and navigate to\n- `http://localhost:8000/docs`\n- You'll see the Swagger UI with all available endpoints\n- Test an endpoint by clicking on it, then click \"Try it out\" and \"Execute\"\n\n### Connecting to Open WebUI or Other API Clients\n\nTo connect this API to Open WebUI:\n\n1. In Open WebUI, go to Settings > Manage Tool Servers\n2. Add a new connection with:\n\n- URL: `http://localhost:8000`\n- Path to OpenAPI spec: `/openapi.json`\n- Authentication: None (unless configured otherwise)\n\n### Environment Variables\n\nThe Docker container accepts several environment variables to customize its behavior:\n\n```bash\n# Example with custom settings\ndocker run -p 8000:8000 \\\n  -e BLENDER_HOST=host.docker.internal \\\n  -e BLENDER_PORT=9876 \\\n  -e MCP_HOST=0.0.0.0 \\\n  -e MCP_PORT=8000 \\\n  --name bonsai_mcp bonsai_mcp\n```\n\n## Installing the Blender Addon\n\n1. Download the `addon.py` file from this repo\n\n2. Open Blender\n\n3. Go to Edit > Preferences > Add-ons\n\n4. Click \"Install...\" and select the `addon.py` file\n\n5. Enable the addon by checking the box next to \"Interface: Blender MCP - IFC\"\n\n## Usage\n\n### Starting the Connection\n\n1. In Blender, go to the 3D View sidebar (press N if not visible)\n\n2. Find the \"Blender MCP - IFC\" tab\n\n3. Click \"Connect to Claude\"\n\n4. Make sure the MCP server is running\n\n### Using with Claude\n\nOnce connected, you'll see a hammer icon in Claude's interface with tools for the Blender MCP IFC integration.\n\n## IFC Tools\n\nThis repo includes multiple IFC-specific tools that enable comprehensive querying and manipulation of IFC models:\n\n**get_ifc_project_info**: Retrieves basic information about the IFC project, including name, description, and counts of different entity types. Example: \"What is the basic information about this IFC project?\"\n\n**list_ifc_entities**: Lists IFC entities of a specific type (walls, doors, spaces, etc.) with options to limit results and filter by selection. Example: \"List all the walls in this IFC model\" or \"Show me the windows in this building\"\n\n**get_ifc_properties**: Retrieves all properties of a specific IFC entity by its GlobalId or from currently selected objects. Example: \"What are the properties of this wall with ID 1Dvrgv7Tf5IfTEapMkwDQY?\"\n\n**get_ifc_spatial_structure**: Gets the spatial hierarchy of the IFC model (site, building, storeys, spaces). Example: \"Show me the spatial structure of this building\"\n\n**get_ifc_relationships**: Retrieves all relationships for a specific IFC entity. Example: \"What are the relationships of the entrance door?\"\n\n**get_selected_ifc_entities**: Gets information about IFC entities corresponding to objects currently selected in the Blender UI. Example: \"Tell me about the elements I've selected in Blender\"\n\n**get_user_view**: Captures the current Blender viewport as an image, allowing visualization of the model from the user's perspective. Example: \"Show me what the user is currently seeing in Blender\"\n\n**export_ifc_data**: Exports IFC data to a structured JSON or CSV file, with options to filter by entity type or building level. Example: \"Export all wall data to a CSV file\"\n\n**place_ifc_object**: Creates and positions an IFC element in the model at specified coordinates with optional rotation. Example: \"Place a door at coordinates X:10, Y:5, Z:0 with 90 degrees rotation\"\n\n**get_ifc_quantities**: Calculate and get quantities (m2, m3, etc.) for IFC elements, with options to filter by entity type or selected ones. Example: \"Give me the area of all the walls in the building using the tool get_ifc_quantities\"\n\n**export_drawing_png**: Exports 2D and 3D drawings as high-resolution PNG images with customizable resolution and view parameters. Creates orthographic plan views from above at specified height offsets. Example: \"Generate a floor plan PNG for the ground floor at 1920x1080 resolution\"\n\n**get_ifc_georeferencing_info**: Retrieves comprehensive georeferencing information from IFC files including coordinate reference systems (CRS), map conversions, world coordinate systems, true north direction, and site geographic coordinates. Example: \"What georeferencing information is available in this IFC model?\"\n\n**georeference_ifc_model**: Creates or updates georeferencing information in IFC models, allowing you to set coordinate reference systems using EPSG codes or custom CRS definitions, establish map conversions with eastings/northings coordinates, and configure site geographic positioning. Example: \"Georeference this IFC model using EPSG:4326 with coordinates at latitude 40.7589, longitude -73.9851\"\n\n## MCP Resources\n\nThis integration provides access to structured documentation through MCP resources:\n\n**file://table_of_contents.md**: Contains the complete technical report structure template for generating comprehensive building reports. This resource provides a standardized table of contents that can be used as a reference when creating technical documentation from IFC models.\n\n## MCP Prompts\n\nThe server includes specialized MCP Prompts for automated report generation:\n\n**Technical_building_report**: Generates comprehensive technical building reports based on IFC models loaded in Blender. This prompt provides a structured workflow for creating professional architectural documentation in multiple languages (English, Spanish, French, German, Italian, Portuguese). The prompt guides the analysis through systematic data extraction from the IFC model, including spatial structure, quantities, materials, and building systems, culminating in a complete technical report with drawings and 3D visualizations.\n\n## Execute Blender Code\n\nLegacy feature from the original MCP implementation. Allows Claude to execute arbitrary Python code in Blender. Use with caution.\n\n## Sequential Thinking Tool\n\nThis integration includes the Sequential Thinking tool for structured problem-solving and analysis. It facilitates a step-by-step thinking process that can branch, revise, and adapt as understanding deepens - perfect for complex IFC model analysis or planning tasks.\n\nExample: \"Use sequential thinking to analyze this building's energy efficiency based on the IFC model\"\n\n## Example Commands\n\nHere are some examples of what you can ask Claude to do with IFC models:\n\n- \"Analyze this IFC model and tell me how many walls, doors and windows it has\"\n\n- \"Show me the spatial structure of this building model\"\n\n- \"List all spaces in this IFC model and their properties\"\n\n- \"Identify all structural elements in this building\"\n\n- \"What are the relationships between this wall and other elements?\"\n\n- \"Generate a report of the measurements from the IFC model opened in Blender\"\n\n- \"Use sequential thinking to create a maintenance plan for this building based on the IFC model\"\n\n## Troubleshooting\n\n- **Connection issues**: Make sure the Blender addon server is running, and the MCP server is configured in Claude\n- **IFC model not loading**: Verify that you have the Bonsai BIM addon installed and that an IFC file is loaded\n- **Timeout errors**: Try simplifying your requests or breaking them into smaller steps\n\n**Docker:**\n\n- **\"Connection refused\" errors**: Make sure Blender is running and the addon is enabled with the server started\n- **CORS issues**: The API has CORS enabled by default for all origins. If you encounter issues, check your client's CORS settings\n- **Performance concerns**: For large IFC models, the API responses might be slower. Consider adjusting timeouts in your client\n\n## Technical Details\n\nThe IFC integration uses the Bonsai BIM module to access ifcopenshell functionality within Blender. The communication follows the same JSON-based protocol over TCP sockets as the original BlenderMCP.\n\n## Limitations & Security Considerations\n\n- The `execute_blender_code` tool from the original project is still available, allowing running arbitrary Python code in Blender. Use with caution and always save your work.\n\n- Complex IFC models may require breaking down operations into smaller steps.\n\n- IFC query performance depends on model size and complexity.\n\n- Get User View tool returns a base64 encoded image. Please ensure the client supports it.\n\n## Contributions\n\nThis MIT licensed repo is open to be forked, modified and used in any way. I'm open to ideas and collaborations, so don't hesitate to get in contact with me for contributions.\n\n## Credits\n\n- Original BlenderMCP by [Siddharth Ahuja](https://github.com/ahujasid/blender-mcp)\n\n- Sequential Thinking tool from [modelcontextprotocol/servers](https://github.com/modelcontextprotocol/servers/tree/main/src/sequentialthinking)\n\n- IFC integration built upon the Bonsai BIM addon for Blender\n\n## TO DO\n\nIntegration and testing with more MCP Clients\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "python",
        "modeling",
        "simulation",
        "ifc models",
        "simulation modeling",
        "code blender"
      ],
      "category": "simulation-and-modeling"
    },
    "PatrickPalmer--MayaMCP": {
      "owner": "PatrickPalmer",
      "name": "MayaMCP",
      "url": "https://github.com/PatrickPalmer/MayaMCP",
      "imageUrl": "/freedevtools/mcp/pfp/PatrickPalmer.webp",
      "description": "Control Autodesk Maya using natural language commands via the Model Context Protocol, enabling the creation, modification, and querying of Maya scenes without requiring installation inside Maya.",
      "stars": 26,
      "forks": 10,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-17T20:52:14Z",
      "readme_content": "# Maya MCP\r\nModel Context Protocol (MCP) server implementation for Autodesk Maya\r\n\r\nTested with Maya 2023, 2025.\r\n\r\nv0.2.0\r\n\r\nThis project enables AI assistant clients like Claude Desktop to control Autodesk Maya through natural language using the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/). \r\n\r\nThis is early days for Maya MCP server and has a minimal set of functionality. It's really the architecture design and simplicity that has been the initial focus.\r\n\r\nHere is a list of some of the tools registered with Maya MCP.\r\n\r\n## Basic Tools\r\n\r\n| Tool | Description |\r\n|------|-------------|\r\n| list_objects_by_type | Get a list of objects in the scene. Use filter_by to filter for certain objects such as \"cameras\", \"lights\", \"materials\", or \"shapes\". |\r\n| create_object | Create an object in the Maya scene. Object types available are cube, cone, sphere, cylinder, camera, spotLight, pointLight, directionalLight. |\r\n| get_object_attributes | Get a list of attributes on a Maya object. | \r\n| set_object_attributes | Set an object's attribute with a specific value. |\r\n| scene_new | Create a new scene in Maya. Use the force argument to force a new scene when an existing scene is loaded and has been modified. |\r\n| scene_open | Load in a scene into Maya. | \r\n| scene_save | Save the current scene. If the filename is not specified, it will save it as its current name. |\r\n| select_object | Select an object in the scene. |\r\n\r\n## Advanced Modeling Tools\r\n\r\n| Tool | Description |\r\n|------|-------------|\r\n| create_advanced_model | Create complex 3D models like cars, trees, buildings, cups, and chairs with detailed parameters. |\r\n| mesh_operations | Perform modeling operations such as extrude, bevel, subdivide, boolean, combine, bridge, and split. |\r\n| create_material | Create and assign materials with various types (lambert, phong, wood, marble, chrome, glass, etc.) |\r\n| create_curve | Generate NURBS curves for various shapes (line, circle, spiral, helix, star, gear, etc.) |\r\n| curve_modeling | Create geometry using curve-based modeling techniques (extrude, loft, revolve, sweep, etc.) |\r\n| organize_objects | Organize objects through grouping, parenting, layout, alignment, and distribution. |\r\n| generate_scene | Generate complete 3D scenes with multiple objects (city, forest, living room, office, park) |\r\n\r\n## Installation\r\n\r\nMaya MCP server is designed so there is only an MCP server and doesn't require anything to be installed within Maya. This is helpful since you can easily use different versions of Maya and not have to worry about coordinating version changes. This is done by taking advantage of the default Command Port Maya opens up for MEL scripting. \r\n\r\nMCP requires Python 3.10 or greater. Currently using pip as the package requirements are minimal. To install the virtual environment:\r\n\r\n1. download this project\r\n2. Create a virtual env using Python 3.10+ in the project directory. ```python -m venv .venv```\r\n3. activate the virtual environment\r\n   * Windows: ```.venv\\Scripts\\activate.bat```\r\n   * Mac/Linux: ```source .venv\\bin\\activate.sh```\r\n4. ```pip install -r requirements.txt```\r\n\r\nAs stated, there is nothing to install for Maya.\r\n\r\n### MCP Client Configuration\r\n\r\nDepending on which MCP Client you're using, the configuration file location differs. For [Anthopic Claude Desktop](https://claude.ai/download), go to File -> Settings -> Developer Tab and press the Edit Config button. This will bring up the file finder in the directory location of the JSON config file.\r\n\r\nNext you need to edit the config JSON file by hand using a text editor.  Make sure to use full file paths.\r\n\r\n```\r\n{\r\n  \"mcpServers\": {\r\n    \"MayaMCP\": {\r\n      \"command\": \"[FULL PATH TO MayaMCP PROJECT]/.venv/Scripts/python.exe\",\r\n      \"args\": [\r\n        \"[FULL PATH TO MayaMCP PROJECT]/src/maya_mcp_server.py\"\r\n      ]\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nOnce the changes have been made, restart Claude Desktop (use Exit menu item instead of just closing the window). In the Developers Tab, you will now see the Maya MCP server listed.\r\n\r\nIn Claude Desktop, you can verify the Maya MCP tools are available. Press the  button and a detailed popup will appear.\r\n\r\n\r\n\r\n\r\n### Maya Communications\r\n\r\nWhen the Maya MCP server first attempts to communicate with Maya, you will get this popup within Maya. Please click \"Allow All\" to allow for ongoing communication between the MCP server and Maya. This will need to be done each Maya session.\r\n\r\n\r\n\r\n\r\n## Developer Notes\r\n\r\nThe Maya MCP Server module was designed to be easily modified in a non-intrusive way. This is done by having the Maya Python code reside in the MCP server and sent to Maya's command port for execution. The results are sent back to the server and processed.\r\n\r\nThe default Maya command port runs MEL so the Python code is modified to run within MEL function call to the Python interpreter. There is also some limits such as multi-line Python code can't have any returned results. So, each command creates two connections to Maya. First to run the operation and save the results. The second connection then to read back the results. \r\n\r\nTo help minimize populating the namespace in the Maya global Python interpreter, functions and variables sent to Maya will be scoped to start with _mcp_maya_*. Each of the Maya tools are scoped into a function named _mcp_maya_scope(). The results are assigned to the variable _mcp_maya_results. This way should significantly reduce the possibility of name collisions. \r\n\r\nThere is a bit of elegance to this design. You basically can just add the Python file, restart the MCP Client and Maya MCP server and go. You don't need to integrate the operations on both the Maya MCP server and Maya itself. The code you add is only Maya specific Python and doesn't need to add any MCP decorators. This is a much better design to grow and adapt to different installations instead of having a fixed set of tools.\r\n\r\nThe Maya MCP server was built using the low-level Python MCP module. This was necessary to allow for dynamically defining all of the tools at run time. The tool function signatures are captured dynamically at the start of the server. \r\n\r\n### Adding New Tools\r\n\r\nIt is easy to add new tools to Maya MCP. You don't need to change any of the existing code. All you need to do is add a single tool command Python file to the mayatools/thirdparty directory. The tool itself will run in Maya so it will have access to all of the Maya Python modules. There are a few programmer notes in the design of the tool.\r\n\r\n* The name of the Python file and the function name must be the same. Make sure it is unique.\r\n* The Python function will be loaded by both the server and Maya. Any code outside of the function must be able to be loaded into standalone Python. Meaning any imports such as maya.cmds should be done in the scope of the function. The MCP server loads the function so it can inspect the function signature to send the information to MCP Client via JSON-RPC.\r\n* The function signature will be parsed and must include any types in the function argument annotation.\r\n* When your function is sent to Maya, it will be scoped within am _mcp_maya_scope function. This provides a number of benefits. The functions sent to Maya will not polute the Python global space too much running in Maya. Plus, any exceptions thrown will be caught and returned back to the MCP Client as errors.\r\n* Generally, you want to return either a list or dictionary or throw an exception when there is an error.\r\n* Name your function and arguments appropriately so the LLM can understand the operation. Include a function doc string.\r\n* Default arguments are good. \r\n* Error checking is good so error messages can provide better failed explanations.\r\n\r\nI recommend looking at the existing Maya tools in this project as examples.\r\n\r\n## Testing\r\n\r\nCurrently Maya MCP has only been tested on Windows. Should work on both Linux and Mac as everything is using standard Python.\r\n\r\n## Future Ideas\r\n\r\nIt's early days for MCP and there is a lot to improve. Here are some ideas.\r\n\r\n* Expose more functionality.\r\n* Improve using prompt engineering, particularly describing Maya's usage and data relationships.\r\n* Everything is registered as tools, allow for resources and prompts.\r\n* It could be possible to find any plugins within Maya that has MCP tools. Maybe something like looking at the PYTHONPATH within Maya with any directory named MCP. All of those could be inspected and then provided back to the MCP Client.\r\n\r\n## License\r\n\r\nMIT\r\n\r\n## Links\r\n\r\n* [Model Context Protocol (MCP)](https://modelcontextprotocol.io/)\r\n* [Anthopic Claude Desktop](https://claude.ai/download)\r\n* [MCP Python SDK](https://github.com/modelcontextprotocol/python-sdk)\r\n* [Unreal MCP](https://github.com/chongdashu/unreal-mcp)\r\n\r\n\r\n## Important Note\r\n\r\nThis project was done on my personal time and equipment to learn about MCP. The project is not affiliated with my current employer and does not represent their work or interests.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mayamcp",
        "maya",
        "autodesk",
        "mayamcp control",
        "autodesk maya",
        "maya using"
      ],
      "category": "simulation-and-modeling"
    },
    "lobstercare--geofs-mcp": {
      "owner": "lobstercare",
      "name": "geofs-mcp",
      "url": "https://github.com/lobstercare/geofs-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/lobstercare.webp",
      "description": "Control and interact with aircraft in the GeoFS flight simulator. Access real-time flight data, execute maneuvers, and navigate between waypoints using AI models.",
      "stars": 4,
      "forks": 1,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-08-09T15:17:30Z",
      "readme_content": "# GeoFS MCP Server\n\nA Model Context Protocol (MCP) server for the GeoFS flight simulator, allowing AI models to control and interact with aircraft in the GeoFS browser-based flight simulator.\n![image](https://github.com/user-attachments/assets/9b9f8c68-10c1-43b5-b040-f9b7740c04cd)\n![image](https://github.com/user-attachments/assets/611c64f4-1b88-4e86-b289-adfcb12dc97d)\n![image](https://github.com/user-attachments/assets/c713ff6d-7188-4a22-99a6-4673fc9d25f0)\n\n## Features\n\n- 🛫 Control aircraft flight parameters (throttle, heading, etc.)\n- 📊 Access real-time flight data (position, speed, attitude)\n- 🗺️ Navigate between waypoints and airports\n- ✈️ Select different aircraft models\n- 🔄 Execute flight maneuvers (takeoff, landing)\n\n## Prerequisites\n\n- Node.js (v14 or higher)\n- npm or yarn\n- A modern web browser (Chrome recommended)\n\n## Installation\n\n1. Clone this repository:\n   ```\n   git clone https://github.com/yourusername/geofs-mcp-server.git\n   cd geofs-mcp-server\n   ```\n\n2. Install dependencies:\n   ```\n   npm install\n   ```\n\n3. Build the project:\n   ```\n   npm run build\n   ```\n\n## Usage\n\n### Starting the Server\n\n1. Start the MCP server:\n   ```\n   npm start\n   ```\n\n2. The server will launch a browser window that navigates to GeoFS\n   - You may need to log in to GeoFS if required\n   - The server will wait for GeoFS to fully load before accepting commands\n\n3. The MCP server will be available at:\n   - HTTP: `http://localhost:3000`\n   - WebSocket: `ws://localhost:3000`\n\n### Using with AI Models\n\nThis MCP server can be used with AI models that support the Model Context Protocol, allowing them to:\n\n1. Control aircraft in the simulator\n2. Retrieve flight data and simulator state\n3. Execute complex flight maneuvers\n4. Plan and follow flight routes\n\n### API Endpoints\n\n- `GET /mcp` - Get server capabilities and available endpoints\n- `GET /mcp/aircraft` - Get current aircraft data\n- `POST /mcp/aircraft` - Control aircraft parameters\n- `GET /mcp/flight-data` - Get comprehensive flight data\n- `POST /mcp/navigation` - Set navigation parameters\n- `GET /mcp/simulation` - Get simulation status\n- `POST /mcp/simulation` - Control simulation parameters\n\n### WebSocket Commands\n\nThe server also supports WebSocket for real-time communication:\n\n```javascript\n// Example WebSocket message\n{\n  \"id\": 1,\n  \"type\": \"command\",\n  \"command\": \"setThrottle\",\n  \"params\": {\n    \"value\": 0.75\n  }\n}\n```\n\nAvailable commands:\n- `setThrottle` - Set engine throttle (0-1)\n- `setHeading` - Set target heading in degrees\n- `getPosition` - Get current aircraft position\n- `selectAircraft` - Change to a different aircraft\n- `takeOff` - Execute takeoff procedure\n- `land` - Execute landing procedure\n- `getFlightData` - Get comprehensive flight data\n\n## Example Client\n\nSee the `examples/simple-client.js` file for a basic example of how to connect to and use the GeoFS MCP server.\n\nTo run the example:\n```\nnode examples/simple-client.js\n```\n\n## How It Works\n\nThe GeoFS MCP server uses Puppeteer to control a browser instance running GeoFS. It provides a standardized MCP interface that allows AI models to interact with the flight simulator through HTTP and WebSocket APIs.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Acknowledgements\n\n- [GeoFS](https://www.geo-fs.com/) - The browser-based flight simulator\n- [Model Context Protocol](https://github.com/modelcontextprotocol/mcp) - Protocol specification for AI model context\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "simulator",
        "flight",
        "maneuvers",
        "flight simulator",
        "geofs flight",
        "aircraft geofs"
      ],
      "category": "simulation-and-modeling"
    },
    "neka-nat--freecad-mcp": {
      "owner": "neka-nat",
      "name": "freecad-mcp",
      "url": "https://github.com/neka-nat/freecad-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/neka-nat.webp",
      "description": "Control FreeCAD directly from the desktop, enabling integration with Claude Desktop for enhanced design workflows and automation. Supports various design tasks including creating flanges, toy cars, and converting 2D drawings into 3D models.",
      "stars": 319,
      "forks": 56,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T09:14:17Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/neka-nat-freecad-mcp-badge.png)](https://mseep.ai/app/neka-nat-freecad-mcp)\n\n# FreeCAD MCP\n\nThis repository is a FreeCAD MCP that allows you to control FreeCAD from Claude Desktop.\n\n## Demo\n\n### Design a flange\n\n\n\n### Design a toy car\n\n\n\n### Design a part from 2D drawing\n\n#### Input 2D drawing\n\n\n\n#### Demo\n\n\n\nThis is the conversation history.\nhttps://claude.ai/share/7b48fd60-68ba-46fb-bb21-2fbb17399b48\n\n## Install addon\n\nFreeCAD Addon directory is\n* Windows: `%APPDATA%\\FreeCAD\\Mod\\`\n* Mac: `~/Library/Application\\ Support/FreeCAD/Mod/`\n* Linux:\n  * Ubuntu: `~/.FreeCAD/Mod/` or `~/snap/freecad/common/Mod/` (if you install FreeCAD from snap)\n  * Debian: `~/.local/share/FreeCAD/Mod`\n\nPlease put `addon/FreeCADMCP` directory to the addon directory.\n\n```bash\ngit clone https://github.com/neka-nat/freecad-mcp.git\ncd freecad-mcp\ncp -r addon/FreeCADMCP ~/.FreeCAD/Mod/\n```\n\nWhen you install addon, you need to restart FreeCAD.\nYou can select \"MCP Addon\" from Workbench list and use it.\n\n\n\nAnd you can start RPC server by \"Start RPC Server\" command in \"FreeCAD MCP\" toolbar.\n\n\n\n## Setting up Claude Desktop\n\nPre-installation of the [uvx](https://docs.astral.sh/uv/guides/tools/) is required.\n\nAnd you need to edit Claude Desktop config file, `claude_desktop_config.json`.\n\nFor user.\n\n```json\n{\n  \"mcpServers\": {\n    \"freecad\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"freecad-mcp\"\n      ]\n    }\n  }\n}\n```\n\nIf you want to save token, you can set `only_text_feedback` to `true` and use only text feedback.\n\n```json\n{\n  \"mcpServers\": {\n    \"freecad\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"freecad-mcp\",\n        \"--only-text-feedback\"\n      ]\n    }\n  }\n}\n```\n\n\nFor developer.\nFirst, you need clone this repository.\n\n```bash\ngit clone https://github.com/neka-nat/freecad-mcp.git\n```\n\n```json\n{\n  \"mcpServers\": {\n    \"freecad\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/freecad-mcp/\",\n        \"run\",\n        \"freecad-mcp\"\n      ]\n    }\n  }\n}\n```\n\n## Tools\n\n* `create_document`: Create a new document in FreeCAD.\n* `create_object`: Create a new object in FreeCAD.\n* `edit_object`: Edit an object in FreeCAD.\n* `delete_object`: Delete an object in FreeCAD.\n* `execute_code`: Execute arbitrary Python code in FreeCAD.\n* `insert_part_from_library`: Insert a part from the [parts library](https://github.com/FreeCAD/FreeCAD-library).\n* `get_view`: Get a screenshot of the active view.\n* `get_objects`: Get all objects in a document.\n* `get_object`: Get an object in a document.\n* `get_parts_list`: Get the list of parts in the [parts library](https://github.com/FreeCAD/FreeCAD-library).\n\n## Contributors\n\n<a href=\"https://github.com/neka-nat/freecad-mcp/graphs/contributors\">\n  <img alt=\"freecad_mcp\" src=\"https://contrib.rocks/image?repo=neka-nat/freecad-mcp\" />\n</a>\n\nMade with [contrib.rocks](https://contrib.rocks).",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "freecad",
        "3d",
        "modeling",
        "freecad directly",
        "control freecad",
        "freecad mcp"
      ],
      "category": "simulation-and-modeling"
    },
    "radial-hks--MCP-Unreal-Server": {
      "owner": "radial-hks",
      "name": "MCP-Unreal-Server",
      "url": "https://github.com/radial-hks/MCP-Unreal-Server",
      "imageUrl": "/freedevtools/mcp/pfp/radial-hks.webp",
      "description": "Manage and execute Python code in Unreal Engine environments, with automatic discovery of Unreal instances and real-time monitoring of their status. Provides robust logging capabilities and support for remote execution in both attended and unattended modes.",
      "stars": 4,
      "forks": 5,
      "license": "No License",
      "language": "HTML",
      "updated_at": "2025-07-25T07:11:11Z",
      "readme_content": "# MCP Unreal Server\n\nA server implementation for interacting with Unreal Engine instances through remote Python execution.\n\n## Features\n\n- 🚀 **Unreal Instance Management**\n  - Automatic discovery of Unreal nodes via multicast\n  - Real-time node status monitoring\n  - Resource listing through LSP-compatible clients\n\n- 💻 **Remote Execution**\n  - Execute Python code in Unreal Engine environments\n  - Support for both attended and unattended execution modes\n  - File execution and statement evaluation modes\n\n- 📊 **Logging & Monitoring**\n  - Detailed logging to file (`mcp_unreal.log`)\n  - Console logging with different verbosity levels\n  - Node connection health monitoring\n\n## Installation\n\n```bash\n# Clone repository\ngit clone https://github.com/your-org/mcp-unreal-server.git\ncd mcp-unreal-server\n\n# Install dependencies\npip install -r requirements.txt\n```\n\n## Configuration\n\n### Network Settings\nConfigure multicast parameters in `RemoteExecutionConfig`:\n```python\n# Default multicast settings (modify in server.py)\nconfig.multicast_group_endpoint = (\"239.0.0.1\", 6766)\n```\n\n### Logging\nModify logging configuration in `server.py`:\n```python\n# Adjust log levels\nfile_handler.setLevel(logging.DEBUG)  # File logging\nconsole_handler.setLevel(logging.INFO)  # Console logging\n```\n\n## Usage\n\n### Starting the Server\n```bash\npython -m src.mcp_server_unreal.server\n```\n\n### Supported Tools\n\n1. **Connect to Unreal Instance**\n```json\n{\n  \"host\": \"239.0.0.1\",\n  \"port\": 6766\n}\n```\n\n2. **Execute Python Code**\n```json\n{\n  \"node_id\": \"<unreal-node-id>\",\n  \"code\": \"print('Hello Unreal')\",\n  \"unattended\": true\n}\n```\n\n## API Documentation\n\n### Resource Format\n```python\ntypes.Resource(\n    uri=\"unreal://<node_id>\",\n    name=f\"Unreal Instance: {node_id}\",\n    description=\"Unreal Engine instance\",\n    mimeType=\"application/x-unreal\"\n)\n```\n\n### Execution Modes\n| Mode                 | Description                     |\n|----------------------|---------------------------------|\n| MODE_EXEC_FILE       | Execute Python file             |\n| MODE_EXEC_STATEMENT  | Execute Python statement        |\n| MODE_EVAL_STATEMENT  | Evaluate Python expression      |\n\n## Troubleshooting\n\n**Common Issues:**\n- No nodes discovered: Verify Unreal instances are running with MCP plugin\n- Execution timeout: Check firewall settings for multicast traffic\n- Connection drops: Monitor `mcp_unreal.log` for node status changes\n\n## License\nApache-2.0 License",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "logging",
        "python",
        "hks",
        "unreal server",
        "unreal instances",
        "remote execution"
      ],
      "category": "simulation-and-modeling"
    },
    "team-plask--3d-mcp": {
      "owner": "team-plask",
      "name": "3d-mcp",
      "url": "https://github.com/team-plask/3d-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/team-plask.webp",
      "description": "Creates a unified TypeScript interface for interacting with multiple 3D software applications such as Blender, Maya, and Unreal Engine through a single API. Facilitates operations like creating keyframes and managing 3D object properties with streamlined code generation.",
      "stars": 14,
      "forks": 1,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-21T17:08:44Z",
      "readme_content": "# 3D MCP\n\n![Plugin Tests](https://github.com/team-plask/3d-mcp/workflows/Plugin%20Code%20Generation%20Tests/badge.svg) ![TypeScript](https://img.shields.io/badge/TypeScript-5.0%2B-blue) ![License](https://img.shields.io/badge/License-Apache_2.0-green)\n\n## Overview\n\n3D-MCP is a universal implementation of the [Model Context Protocol](https://modelcontextprotocol.io/introduction) for 3D software. It creates a unified TypeScript interface for LLMs to interact with Blender, Maya, Unreal Engine, and other 3D applications through a single coherent API.\n\n```typescript\n// LLMs use the same interface regardless of underlying 3D software\nawait tools.animation.createKeyframe({\n  objectId: \"cube_1\",\n  property: \"rotation.x\",\n  time: 30,\n  value: Math.PI/2\n});\n```\n\n## Core Philosophy & Design Decisions\n\n3D-MCP is built on four interconnected architectural principles that together create a unified system for 3D content creation:\n\n1. **Entity-First Design**: Well-defined domain entities form the foundation of all operations, enabling consistent data modeling across platforms\n2. **Type-Safe CRUD Operations**: Automated generation of create, read, update, delete operations with complete type validation\n3. **Atomic Operation Layer**: A minimal set of platform-specific implementations that handle fundamental operations\n4. **Composable Tool Architecture**: Complex functionality built by combining atomic operations in a platform-agnostic way\n\nThis architecture creates a **dependency inversion** where platform-specific implementation details are isolated to atomic operations, while the majority of the codebase remains platform-independent.\n\n```\n┌─────────────────────────────────────────────────────────────────────────┐\n│                             LLM / User API                              │\n└───────────────────────────────────┬─────────────────────────────────────┘\n                                    │ MCP Tool API\n                                    ▼\n┌─────────────────────────────────────────────────────────────────────────┐\n│                          Compound Operations                            │\n│                                                                         │\n│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────────────┐  │\n│  │ Modeling Tools  │  │ Animation Tools │  │ Rigging Tools           │  │\n│  └─────────────────┘  └─────────────────┘  └─────────────────────────┘  │\n└───────────────────────────────────┬─────────────────────────────────────┘\n                                    │ Implemented by\n                                    ▼\n┌─────────────────────────────────────────────────────────────────────────┐\n│                           Atomic Operations                             │\n│                                                                         │\n│  ┌─────────── Entity CRUD ────────────┐ ┌────────── Non-CRUD ─────────┐ │ \n│  │ create{Entity}s update{Entity}s ...│ │  select, undo, redo, etc.   │ │  \n│  └────────────────────────────────────┘ └─────────────────────────────┘ │\n└───────────────────────────────────┬─────────────────────────────────────┘\n                                    │ Plug-in Server Request\n                                    ▼\n┌─────────────────────────────────────────────────────────────────────────┐\n│                       Platform-Specific Adapters                        │\n│                                                                         │\n│  ┌──── Blender ────┐  ┌────── Maya ─────┐  ┌─── Unreal Engine ────┐     │\n│  │ createKeyframes │  │ createKeyframes │  │ createKeyframes      │     │    \n│  └─────────────────┘  └─────────────────┘  └──────────────────────┘     │\n└─────────────────────────────────────────────────────────────────────────┘\n```\n\n## Why These Design Decisions?\n\n**Entity-First Design** was chosen because:\n- 3D applications use different object models but share core concepts (meshes, materials, animations)\n- Zod schemas provide single-source-of-truth for validation, typing, and documentation\n- Strong typing catches errors at compile time rather than runtime\n- Rich metadata enables better AI understanding of domain objects\n\n**CRUD Operations as Foundation** because:\n- They map cleanly to what 3D applications need to do with entities\n- Standardized patterns reduce cognitive overhead\n- Auto-generation eliminates repetitive code using `createCrudOperations`\n- Every entity automatically gets the same consistent interface\n\n**Atomic and Compound Tool Separation** because:\n- Only atomic tools need platform-specific implementation (~20% of codebase)\n- Compound tools work across all platforms without modification (~80% of codebase)\n- New platforms only need to implement atomic operations to gain all functionality\n- Maintainable architecture with clear separation of concerns\n\n## Technical Architecture\n\n### 1. Entity-Centric CRUD Architecture\n\nThe system's foundation is a rich type system of domain entities that generates CRUD operations:\n\n```typescript\n// Define entities with rich metadata using Zod\nexport const Mesh = NodeBase.extend({\n  vertices: z.array(Tensor.VEC3).describe(\"Array of vertex positions [x, y, z]\"),\n  normals: z.array(Tensor.VEC3).optional().describe(\"Array of normal vectors\"),\n  // ... other properties\n});\n\n// CRUD operations generated automatically from entity schemas\nconst entityCruds = createCrudOperations(ModelEntities);\n// => Creates createMeshs, getMeshs, updateMeshs, deleteMeshs, listMeshs\n\n// All operations preserve complete type information\nawait tool.createRigControls.execute({\n  name: \"arm_ctrl\",          \n  shape: \"cube\",            // TypeScript error if not a valid enum value\n  targetJointIds: [\"joint1\"], // Must be string array\n  color: [0.2, 0.4, 1],     // Must match Color schema format\n  // IDE autocomplete shows all required/optional fields\n});\n```\n\nEntity schemas provide:\n- **Schema Validation**: Runtime parameter checking with detailed error messages\n- **Type Information**: Complete TypeScript types for IDE assistance\n- **Documentation**: Self-documenting API with descriptions\n- **Code Generation**: Templates for platform-specific implementations\n\n#### Entity Architecture Diagram\n\n```\n┌──────────────────────────────────────────────────────────────┐\n│                Core Entity Definitions                       │\n│                                                              │\n│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐   │\n│  │ BaseEntity  │  │ NodeBase    │  │ Other Core Entities │   │\n│  └─────────────┘  └─────────────┘  └─────────────────────┘   │\n└──────────────────────────────────────────────────────────────┘\n                           ▲\n                           │ extends\n                           │\n┌──────────────────────────────────────────────────────────────┐\n│                Domain-Specific Entities                      │\n│                                                              │\n│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐   │\n│  │ Model       │  │ Animation   │  │ Rigging             │   │\n│  │ Entities    │  │ Entities    │  │ Entities            │   │\n│  └─────────────┘  └─────────────┘  └─────────────────────┘   │\n└──────────────────────────────────────────────────────────────┘\n                           │\n                           │ input to\n                           ▼\n┌──────────────────────────────────────────────────────────────┐\n│                Automatic CRUD Generation                     │\n│                                                              │\n│  ┌─────────────────────────────────────────────────────────┐ │\n│  │ createCrudOperations(Entities)                          │ │\n│  └─────────────────────────────────────────────────────────┘ │\n└──────────────────────────────────────────────────────────────┘\n                           │\n                           │ generates\n                           ▼\n┌──────────────────────────────────────────────────────────────┐\n│                     Atomic Operations                        │\n│                                                              │\n│  ┌─────────────────┐ ┌──────────────┐ ┌─────────────────┐    │\n│  │ create{Entity}s │ │ get{Entity}s │ │ update{Entity}s │ .. │\n│  └─────────────────┘ └──────────────┘ └─────────────────┘    │\n└──────────────────────────────────────────────────────────────┘\n                           │\n                           │ foundation for\n                           ▼\n┌──────────────────────────────────────────────────────────────┐\n│                    Compound Operations                       │\n│                                                              │\n│  ┌─────────────────────────────────────────────────────────┐ │\n│  │ No need for platform-specific code. Use atomic ops only.│ │\n│  └─────────────────────────────────────────────────────────┘ │\n└──────────────────────────────────────────────────────────────┘\n```\n\n\n### 2. Compound Tool Architecture\n\nThe system creates a clear separation between atomic and compound operations:\n\n```typescript\n// From compounded.ts - Higher level operations composed from atomic operations\ncreateIKFKSwitch: defineCompoundTool({\n  // ...parameter and return definitions...\n  execute: async (params) => {\n    // Create IK chain using atomic operations\n    const ikChainResult = await tool.createIKChains.execute({/*...*/});\n    \n    // Create control with full type-checking\n    const ikControlResult = await tool.createRigControls.execute({\n      name: `${switchName}_IK_CTRL`,\n      shape: ikControlShape,  // Type-checked against schema\n      targetJointIds: [jointIds[jointIds.length - 1]],\n      color: ikColor,\n      // ...other parameters\n    });\n    \n    // Position the control at the end effector\n    await tool.batchTransform.execute({/*...*/});\n    \n    // Create constraints to connect the system\n    await tool.createConstraint.execute({/*...*/});\n    \n    // Return standardized response with created IDs\n    return {\n      success: true,\n      switchControlId: switchControlResult.id,\n      ikControlId: ikControlResult.id,\n      fkControlIds,\n      poleVectorId: poleVectorId || undefined,\n    };\n  }\n})\n```\n\nThis architecture provides several technical advantages:\n\n1. **Atomic Operations** (~20% of the system):\n   - Directly interact with platform APIs\n   - Need platform-specific implementations\n   - Focus on single entity operations (create, read, update, delete)\n   - Form minimal implementation required for new platforms\n\n2. **Compound Operations** (~80% of the system):\n   - Built entirely from atomic operations\n   - Zero platform-specific code\n   - Implement higher-level domain concepts\n   - Work on any platform without modification\n\n#### Tool Composition Flow\n\n```\n┌─────────────────────────────────────────────────────────────────────────┐\n│                        High-Level Tool Definition                       │\n└──────────────────────────────────────┬──────────────────────────────────┘\n                                       │\n                                       ▼\n┌─────────────────────────────────────────────────────────────────────────┐\n│                         Compound Tool Pattern                           │\n│                                                                         │\n│  ┌──────────────────────────────────────────────────────────────────┐   │\n│  │ defineCompoundTool({                                             │   │\n│  │   description: string,                                           │   │\n│  │   parameters: zod.Schema,                                        │   │\n│  │   returns: zod.Schema,                                           │   │\n│  │   execute: async (params) => {                                   │   │\n│  │     // Composed entirely from atomic operations                  │   │\n│  │     await tool.atomicOperation1.execute({...});                  │   │\n│  │     await tool.atomicOperation2.execute({...});                  │   │\n│  │     return { success: true, ...results };                        │   │\n│  │   }                                                              │   │\n│  │ })                                                               │   │\n│  └──────────────────────────────────────────────────────────────────┘   │\n└───────────────────────────────────┬─────────────────────────────────────┘\n                                    │ Plug-in Server Request\n                                    ▼\n┌─────────────────────────────────────────────────────────────────────────┐\n│                         Platform Adaptation                             │\n│                                                                         │\n│  ┌──────────────────────────┐  ┌─────────────────────────────────────┐  │\n│  │ Blender Implementation   │  │ Maya Implementation                 │  │\n│  │ of Atomic Operations     │  │ of Atomic Operations                │  │\n│  └──────────────────────────┘  └─────────────────────────────────────┘  │\n└─────────────────────────────────────────────────────────────────────────┘\n```\n\nKey files for the compound tool architecture:\n- compounded.ts: Compound modeling tools\n- compounded.ts: Compound animation tools\n- compounded.ts: Compound rigging tools\n\n### 3. Code Generation Pipeline\n\nThe system automatically generates platform-specific implementations from TypeScript definitions:\n\n```\n┌─────────────────┐     ┌────────────────────┐     ┌─────────────────────────┐\n│ Entity Schemas  │     │ Schema             │     │ Platform-Specific Code  │\n│ & Tools (TS)    │ ──> │ Extraction (TS)    │ ──> │ (Python/C++/etc.)       │\n└─────────────────┘     └────────────────────┘     └─────────────────────────┘\n      │                        │                             │\n      │                        │                             │\n      ▼                        ▼                             ▼\n┌─────────────────┐     ┌────────────────────┐     ┌─────────────────────────┐\n│ Type            │     │ Parameter          │     │ Implementation          │\n│ Definitions     │     │ Validation         │     │ Templates               │\n└─────────────────┘     └────────────────────┘     └─────────────────────────┘\n```\n\nKey aspects of the generation system:\n- **Entity Extraction**: Analyzes Zod schemas to understand entity structure\n- **Parameter Mapping**: Converts TypeScript types to platform-native types\n- **Validation Generation**: Creates parameter validation in target languages\n- **Implementation Templates**: Provides platform-specific code patterns\n\nThe codegen system is implemented in:\n- [plugin-codegen.ts](./packages/scripts/plugin-codegen.ts): Main code generation script\n- [extract-schemas.ts](./packages/scripts/extract-schemas.ts): Extracts Zod schemas from TypeScript files into temporary JSON files.\n\n### 4. Domain Organization\n\nThe system is organized into domains that mirror 3D content creation workflows:\n\n- **Core**: Base entities and operations used across all domains\n- **Modeling**: Mesh creation, editing, and topology operations\n- **Animation**: Keyframes, curves, clips, and animation control\n- **Rigging**: Skeletal systems, controls, and deformation\n- **Rendering**: Materials, lights, and render settings\n\nEach domain follows the same organizational pattern:\n- [`entity.ts`](./packages/src/tool/animation/entity.ts): Domain-specific entity definitions\n- [`atomic.ts`](./packages/src/tool/animation/atomic.ts): Atomic operations for domain entities\n- [`compounded.ts`](./packages/src/tool/animation/compounded.ts): Higher-level operations built from atomic tools\n\n#### Domain Structure Diagram\n\n```\npackages/src/tool/\n│\n├── core/                  # Core shared components\n│   ├── entity.ts          # Base entities all domains use\n│   ├── utils.ts           # Shared utilities including CRUD generation\n│   └── ...\n│\n├── model/                 # Modeling domain\n│   ├── entity.ts          # Mesh, Vertex, Face, etc.\n│   ├── atomic.ts          # Atomic modeling operations\n│   ├── compounded.ts      # Higher-level modeling tools\n│   └── ...\n│\n├── animation/             # Animation domain\n│   ├── entity.ts          # Keyframe, AnimCurve, Clip, etc.\n│   ├── atomic.ts          # Atomic animation operations\n│   ├── compounded.ts      # Higher-level animation tools\n│   └── ...\n│\n├── rig/                   # Rigging domain\n│   ├── entity.ts          # Joint, IKChain, Control, etc.\n│   ├── atomic.ts          # Atomic rigging operations\n│   ├── compounded.ts      # Higher-level rigging tools\n│   └── ...\n│\n└── rendering/             # Rendering domain\n    ├── entity.ts          # Camera, Light, RenderSettings, etc.\n    ├── atomic.ts          # Atomic rendering operations\n    ├── compounded.ts      # Higher-level rendering tools\n    └── ...\n```\n\n### 5. Entity-Centric CRUD Architecture\n\nThe system implements a sophisticated entity-centric approach where:\n\n1. **Entities as Domain Models**: Each domain (modeling, animation, rigging) defines its core entities that represent its fundamental concepts. These are implemented as Zod schemas with rich type information.\n\n2. **CRUD as Foundation**: Every entity automatically receives a complete set of CRUD operations (Create, Read, Update, Delete) through the `createCrudOperations` utility:\n\n```typescript\n// Each domain starts with CRUD operations for all its entities\nconst entityCruds = createCrudOperations(ModelEntities);\n\nconst modelAtomicTools = {\n  ...entityCruds,  // Foundation of all atomic tools\n  // Domain-specific operations build on this foundation\n}\n```\n\n3. **Entity Reuse and Inheritance**: Core entities defined in `core/entity.ts` are extended by domain-specific entities, promoting code reuse and consistent design across domains.\n\n4. **DDD-Inspired Architecture**: The system follows Domain-Driven Design principles by organizing code around domain entities and aggregates rather than technical concerns.\n\nThis architecture provides several key benefits:\n\n- **Consistency**: All entities have the same patterns for basic operations\n- **Reduced Boilerplate**: CRUD operations are generated automatically  \n- **Clear Organization**: Tools are organized around domain entities\n- **Separation of Concerns**: Each domain manages its own entities while sharing common patterns\n\nThe combination of rich entity models with automatic CRUD operations creates a robust foundation that simplifies development while maintaining flexibility for domain-specific operations.\n\n## Getting Started\n\n```bash\n# Install dependencies\nbun install\n\n# Run the server\nbun run index.ts\n\n# Extract schemas and generate plugins\nbun run packages/scripts/plugin-codegen.ts\n```\n\n## Development Workflow\n\n1. **Define Entities**: Create or extend entity schemas in `src/tool/<domain>/entity.ts`\n2. **Generate CRUD**: Use `createCrudOperations` to generate atomic operations\n3. **Create Compound Tools**: Build higher-level operations from atomic tools\n4. **Generate Plugins**: Run the code generator to create platform-specific implementations\n\n## Contributing\n\nThe architectural decisions in 3D-MCP make it uniquely extensible:\n\n1. **Add New Entities**: Define new entities and automatically get CRUD operations\n2. **Add New Compound Tools**: Combine existing atomic operations to create new functionality\n3. **Add New Platforms**: Implement the atomic tool interfaces in a new plugin\n\nSee our contributing guide for more details on how to contribute.\n\n---\n\n*3D-MCP: One API to rule all 3D software*",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "3d",
        "plask",
        "typescript",
        "plask 3d",
        "3d mcp",
        "3d software"
      ],
      "category": "simulation-and-modeling"
    }
  }
}