{
  "category": "virtual-assistants",
  "categoryDisplay": "Virtual Assistants",
  "description": "",
  "totalRepositories": 23,
  "repositories": {
    "AI-QL--chat-mcp": {
      "owner": "AI-QL",
      "name": "chat-mcp",
      "url": "https://github.com/AI-QL/chat-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/AI-QL.webp",
      "description": "A cross-platform desktop application that connects and interacts with various Large Language Models (LLMs) via the Model Context Protocol (MCP). It provides a clean and minimalistic codebase for testing and understanding MCP functionalities.",
      "stars": 238,
      "forks": 33,
      "license": "Apache License 2.0",
      "language": "HTML",
      "updated_at": "2025-10-04T06:18:14Z",
      "readme_content": "# MCP Chat Desktop App\n## A Cross-Platform Interface for LLMs\n\nThis desktop application utilizes the MCP (Model Context Protocol) to seamlessly connect and interact with various Large Language Models (LLMs). Built on Electron, the app ensures full cross-platform compatibility, enabling smooth operation across different operating systems.\n\nThe primary objective of this project is to deliver a clean, minimalistic codebase that simplifies understanding the core principles of MCP. Additionally, it provides a quick and efficient way to test multiple servers and LLMs, making it an ideal tool for developers and researchers alike.\n\n## News\n\nThis project originated as a modified version of Chat-UI, initially adopting a minimalist code approach to implement core MCP functionality for educational purposes. \n\nThrough iterative updates to MCP, I received community feedback advocating for a completely new architecture - one that eliminates third-party CDN dependencies and establishes clearer modular structure to better support derivative development and debugging workflows. \n\nThis led to the creation of [Tool Unitary User Interface](https://github.com/AI-QL/tuui),  a restructured desktop application optimized for AI-powered development. Building upon the original foundation, TUUI serves as a practical AI-assisted development paradigm, if you're interested, you can also leverage AI to develop new features for TUUI. The platform employs a strict linting and formatting system to ensure AI-generated code adheres to coding standards.\n\n> **ğŸ“¢ Update: June 2025**  \n> The current project refactoring has been largely completed, and a pre-release version is now available. Please refer to the following documentation for details:\n> - [TUUI GitHub Repository](https://github.com/AI-QL/tuui)\n> - [TUUI Architecture](https://deepwiki.com/AI-QL/tuui)\n> - [TUUI Official Website](https://www.tuui.com/)\n\n## Features\n\n- Cross-Platform Compatibility: Supports Linux, macOS, and Windows.\n\n- Flexible Apache-2.0 License: Allows easy modification and building of your own desktop applications.\n\n- Dynamic LLM Configuration: Compatible with all OpenAI SDK-supported LLMs, enabling quick testing of multiple backends through manual or preset configurations.\n\n- Multi-Client Management: Configure and manage multiple clients to connect to multiple servers using MCP config.\n\n- UI Adaptability: The UI can be directly extracted for web use, ensuring consistent ecosystem and interaction logic across web and desktop versions.\n\n\n## Architecture\n\nAdopted a straightforward architecture consistent with the MCP documentation to facilitate a clear understanding of MCP principles by:\n\n[DeepWiki](https://deepwiki.com/AI-QL/chat-mcp)\n\n## How to use\n\nAfter cloning or downloading this repository:\n\n1. Please modify the `config.json` file located in [src/main](src/main).  \n   Ensure that the `command` and `path` specified in the `args` are valid.\n\n2. Please ensure that [Node.js](https://nodejs.org/) is installed on your system.  \n   You can verify this by running `node -v` and `npm -v` in your terminal to check their respective versions.\n\n3. `npm install`\n\n4. `npm start`\n\n## Configuration\n\nCreate a `.json` file and paste the following content into it. This file can then be provided as the interface configuration for the Chat UI.\n\n- `gtp-api.json`\n\n    ```json\n    {\n        \"chatbotStore\": {\n            \"apiKey\": \"\",\n            \"url\": \"https://api.aiql.com\",\n            \"path\": \"/v1/chat/completions\",\n            \"model\": \"gpt-4o-mini\",\n            \"max_tokens_value\": \"\",\n            \"mcp\": true\n        },\n        \"defaultChoiceStore\": {\n            \"model\": [\n                \"gpt-4o-mini\",\n                \"gpt-4o\",\n                \"gpt-4\",\n                \"gpt-4-turbo\"\n            ]\n        }\n    }\n    ```\n\nYou can replace the 'url' if you have direct access to the OpenAI API.\n\nAlternatively, you can also use another API endpoint that supports function calls: \n\n- `qwen-api.json`\n\n    ```json\n    {\n        \"chatbotStore\": {\n            \"apiKey\": \"\",\n            \"url\": \"https://dashscope.aliyuncs.com/compatible-mode\",\n            \"path\": \"/v1/chat/completions\",\n            \"model\": \"qwen-turbo\",\n            \"max_tokens_value\": \"\",\n            \"mcp\": true\n        },\n        \"defaultChoiceStore\": {\n            \"model\": [\n                \"qwen-turbo\",\n                \"qwen-plus\",\n                \"qwen-max\"\n            ]\n        }\n    }\n    ```\n\n- `deepinfra.json`\n\n    ```json\n    {\n        \"chatbotStore\": {\n            \"apiKey\": \"\",\n            \"url\": \"https://api.deepinfra.com\",\n            \"path\": \"/v1/openai/chat/completions\",\n            \"model\": \"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n            \"max_tokens_value\": \"32000\",\n            \"mcp\": true\n        },\n        \"defaultChoiceStore\": {\n            \"model\": [\n                \"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n                \"meta-llama/Meta-Llama-3.1-405B-Instruct\",\n                \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n            ]\n        }\n    }\n    ```\n\n## Build Application\n\nYou can build your own desktop application by:\n\n```bash\nnpm run build-app\n```\n\nThis CLI helps you build and package your application for your current OS, with artifacts stored in the /artifacts directory.\n\nFor Debian/Ubuntu users experiencing RPM build issues, try one of the following solutions: \n\n- Edit `package.json` to skip the RPM build step. Or \n\n- Install `rpm` using `sudo apt-get install rpm` (You may need to run `sudo apt update` to ensure your package list is up-to-date)\n\n\n# Troubleshooting\n\n## Error: spawn npx ENOENT - [ISSUE 40](https://github.com/modelcontextprotocol/servers/issues/40)\n\nModify the `config.json` in [src/main](src/main)\n\nOn windows, npx may not work, please refer my workaround: [ISSUE 101](https://github.com/modelcontextprotocol/typescript-sdk/issues/101)\n\n- Or you can use `node` in config.json: \n    ```json\n    {\n        \"mcpServers\": {\n            \"filesystem\": {\n            \"command\": \"node\",\n            \"args\": [\n                \"node_modules/@modelcontextprotocol/server-filesystem/dist/index.js\",\n                \"D:/Github/mcp-test\"\n            ]\n            }\n        }\n    }\n    ```\n\nPlease ensure that the provided path is valid, especially if you are using a relative path. It is highly recommended to provide an absolute path for better clarity and accuracy.\n\nBy default, I will install `server-everything`, `server-filesystem`, and `server-puppeteer` for test purposes. However, you can install additional server libraries or use `npx` to utilize other server libraries as needed.\n\n## Installation timeout\n\nGenerally, after executing `npm install` for the entire project, the total size of files in the `node_modules` directory typically exceeds 500MB. \n\nIf the installation process stalls at less than 300MB and the progress bar remains static, it is likely due to a timeout during the installation of the latter part, specifically Electron.\n\nThis issue often arises because the download speed from Electron's default server is excessively slow or even inaccessible in certain regions. To resolve this, you can modify the environment or global variable `ELECTRON_MIRROR` to switch to an Electron mirror site that is accessible from your location.\n\n## Electron builder timeout\n\nWhen using electron-builder to package files, it automatically downloads several large release packages from GitHub. If the network connection is unstable, this process may be interrupted or timeout.\n\nOn Windows, you may need to clear the cache located under the `electron` and `electron-builder` directories within `C:\\Users\\YOURUSERNAME\\AppData\\Local` before attempting to retry.\n\nDue to potential terminal permission issues, it is recommended to use the default shell terminal instead of VSCode's built-in terminal.\n\n## Demo\n\n### Multimodal Support\n![demo_multimodal](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-multimodal.png)\n\n### Reasoning and Latex Support\n![demo_latex](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-latex.png)\n\n### MCP Tools Visualization\n![demo_tools](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-tools.png)\n\n### MCP Toolcall Process Overview\n![demo_toolcall](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-toolcall.png)\n\n### MCP Prompts Template\n![demo_prompts](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-prompts.png)\n\n### Dynamic LLM Config\n![demo_llms](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-llms.png)\n\n### DevTool Troubleshooting\n![demo_devtool](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-devtool.png)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ql",
        "assistants",
        "chat",
        "virtual assistants",
        "ql chat",
        "chat mcp"
      ],
      "category": "virtual-assistants"
    },
    "AlexKissiJr--UnrealMCP": {
      "owner": "AlexKissiJr",
      "name": "UnrealMCP",
      "url": "https://github.com/AlexKissiJr/UnrealMCP",
      "imageUrl": "/freedevtools/mcp/pfp/AlexKissiJr.webp",
      "description": "Control and manipulate the Unreal Engine environment programmatically using AI tools through a Machine Control Protocol (MCP). Facilitate scene manipulation and automation to enhance the game development workflow.",
      "stars": 6,
      "forks": 1,
      "license": "No License",
      "language": "C++",
      "updated_at": "2025-06-11T11:25:27Z",
      "readme_content": "# UnrealMCP Plugin\n\n# VERY WIP REPO\nI'm working on adding more tools now and cleaning up the codebase, \nI plan to allow for easy tool extension outside the main plugin\n\nThis is very much a work in progress, and I need to clean up a lot of stuff!!!!!\n\nAlso, I only use windows, so I don't know how this would be setup for mac/unix\n\n## Overview\nUnrealMCP is an Unofficial Unreal Engine plugin designed to control Unreal Engine with AI tools. It implements a Machine Control Protocol (MCP) within Unreal Engine, allowing external AI systems to interact with and manipulate the Unreal environment programmatically.\n\nI only just learned about MCP a few days ago, so I'm not that familiar with it, I'm still learning so things might be initially pretty rough.\nI've implemented this using https://github.com/ahujasid/blender-mcp as a reference, which relies on Claude for Desktop. It now works with both Claude for Desktop and Cursor. If you experiment with other models, please let me know!\n\n## âš ï¸ DISCLAIMER\nThis plugin allows AI agents to directly modify your Unreal Engine project. While it can be a powerful tool, it also comes with risks:\n\n- AI agents may make unexpected changes to your project\n- Files could be accidentally deleted or modified\n- Project settings could be altered\n- Assets could be overwritten\n\n**IMPORTANT SAFETY MEASURES:**\n1. Always use source control (like Git or Perforce) with your project\n2. Make regular backups of your project\n3. Test the plugin in a separate project first\n4. Review changes before committing them\n\nBy using this plugin, you acknowledge that:\n- You are solely responsible for any changes made to your project\n- The plugin author is not responsible for any damage, data loss, or issues caused by AI agents\n- You use this plugin at your own risk\n\n## Features\n- TCP server implementation for remote control of Unreal Engine\n- JSON-based command protocol for AI tools integration\n- Editor UI integration for easy access to MCP functionality\n- Comprehensive scene manipulation capabilities\n- Python companion scripts for client-side interaction\n\n## Roadmap\nThese are what I have in mind for development as of 3/14/2025\nI'm not sure what's possible yet, in theory anything, but it depends on how\ngood the integrated LLM is at utilizing these tools.\n- [X] Basic operations working\n- [X] Python working\n- [X] Materials\n- [ ] User Extensions (in progress)\n- [ ] Asset tools\n- [ ] Blueprints\n- [ ] Niagara VFX\n- [ ] Metasound\n- [ ] Landscape (I might hold off on this because Epic has mentioned they are going to be updating the landscape tools)\n- [ ] Modeling Tools\n- [ ] PCG\n\n## Requirements\n- Unreal Engine 5.5 (I have only tested on this version, may work with earlier, but no official support)\n- C++ development environment configured for Unreal Engine\n- Python 3.7+ for client-side scripting\n- Model to run the commands, in testing I've been using Claude for Desktop https://claude.ai/download\n\n## Prerequisites to run\n- Unreal Editor Installation (Tested with 5.3, but should work on 5.0+)\n- Python 3.7+ (This can run with your existing python install)\n- MCP compatible LLM (Claude for Desktop, Cursor, etc.)\n- Setup: run setup_unreal_mcp.bat in MCP folder as per instructions in MCP/README_MCP_SETUP.md\n\n## Quick Start for Cursor Users\nIf you want to use UnrealMCP with Cursor, follow these simple steps:\n\n1. Clone or download this repository as a zip\n2. Create a new Unreal Project, or open an existing one\n3. Create a \"Plugins\" folder in your project directory if it doesn't exist\n4. Unzip or copy this repository into the Plugins folder\n5. Run `setup_cursor_mcp.bat` in the MCP folder\n6. Open your Unreal project and enable the plugin in Edit > Plugins (if not already enabled)\n7. Start Cursor and ask it to work with your Unreal project\n\nThat's it! The setup script will automatically configure everything needed for Cursor integration.\n\n## Installation\n\n1. Clone or download this repository as a zip\n2. Create a new Unreal Project, or open an existing one\n3. Create a \"Plugins\" folder in your project directory if it doesn't exist\n4. Unzip or copy this repository into the Plugins folder\n5. Setup MCP \n    - Run the `setup_unreal_mcp.bat` script in the MCP folder (see `MCP/README_MCP_SETUP.md` for details)\n    - This will configure Python and your AI assistant (Claude for Desktop or Cursor)\n6. Open your Unreal project, the plugin should be available in the Plugins menu\n7. If not, enable the plugin in Edit > Plugins\n8. Choose your preferred AI assistant:\n    - For Claude for Desktop: follow the instructions in the \"With Claude for Desktop\" section below\n    - For Cursor: follow the instructions in the \"With Cursor\" section below\n\n## With Claude for Desktop\nYou will need to find your installation directory for Claude for Desktop. Find claude_desktop_config.json and add an entry and make it look like so:\n\n**Windows:** `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n```json\n{\n    \"mcpServers\": {\n        \"unreal\": {\n            \"command\": \"C:/path/to/your/project/Plugins/UnrealMCP/MCP/run_unreal_mcp.bat\",\n            \"args\": []\n        }\n    }\n}\n```\n\nAlternatively the unreal_mcp_setup.bat script should do this for you.\n\nTo find the path to your claude for desktop install you can go into settings and click 'Edit Config'\nThis is usually in \n```\nC:\\Users\\USERNAME\\AppData\\Roaming\\Claude\n```\n\n## With Cursor\nCursor should be automatically configured if you've run the setup script with the Cursor option. If you need to manually configure it:\n\n**Windows:** `%APPDATA%\\Cursor\\User\\settings.json`\n\nAdd or update the settings with:\n```json\n{\n    \"mcp\": {\n        \"enabled\": true,\n        \"servers\": {\n            \"unreal\": {\n                \"command\": \"C:/path/to/your/project/Plugins/UnrealMCP/MCP/run_unreal_mcp.bat\",\n                \"args\": []\n            }\n        }\n    }\n}\n```\n\n## Testing\nOnce everything is setup you need to launch the unreal editor.\nNote: Nothing else has to be started or set up to run the mcp bridge, it will run when needed.\n\nOpen Claude for Desktop or Cursor, ensure that the tools have successfully enabled, ask your AI assistant to work in Unreal.\n\nHere are some example prompts to try:\n- \"What actors are in the current level?\" \n- \"Create a cube at position (0, 0, 100)\"\n- \"List available commands I can use with Unreal Engine\"\n\n## Usage\n### In Unreal Editor\nOnce the plugin is enabled, you'll find MCP controls in the editor toolbar button. \n![image](https://github.com/user-attachments/assets/68338e7a-090d-4fd9-acc9-37c0c1b63227)\n\n![image](https://github.com/user-attachments/assets/34f734ee-65a4-448a-a6db-9e941a588e93)\n\nThe TCP server can be started/stopped from here.\nCheck the output log under log filter LogMCP for extra information.\n\nOnce the server is confirmed up and running from the editor.\nOpen Claude for Desktop, ensure that the tools have successfully enabled, ask Claude to work in unreal.\n\nCurrently only basic operations are supported, creating objects, modfiying their transforms, getting scene info, and running python scripts.\nClaude makes a lot of errors with unreal python as I believe there aren't a ton of examples for it, but let it run and it will usually figure things out.\nI would really like to improve this aspect of how it works but it's low hanging fruit for adding functionality into unreal.\n\n### Client-Side Integration\nUse the provided Python scripts in the `MCP` directory to connect to and control your Unreal Engine instance:\n\n```python\nfrom unreal_mcp_client import UnrealMCPClient\n\n# Connect to the Unreal MCP server\nclient = UnrealMCPClient(\"localhost\", 13377)\n\n# Example: Create a cube in the scene\nclient.create_object(\n    class_name=\"StaticMeshActor\",\n    asset_path=\"/Engine/BasicShapes/Cube.Cube\",\n    location=(0, 0, 100),\n    rotation=(0, 0, 0),\n    scale=(1, 1, 1),\n    name=\"MCP_Cube\"\n)\n```\n\n## Command Reference\nThe plugin supports various commands for scene manipulation:\n- `get_scene_info`: Retrieve information about the current scene\n- `create_object`: Spawn a new object in the scene\n- `delete_object`: Remove an object from the scene\n- `modify_object`: Change properties of an existing object\n- `execute_python`: Run Python commands in Unreal's Python environment\n- And more to come...\n\nRefer to the documentation in the `Docs` directory for a complete command reference.\n\n## Security Considerations\n- The MCP server accepts connections from any client by default\n- Limit server exposure to localhost for development\n- Validate all incoming commands to prevent injection attacks\n\n## Troubleshooting\n- Ensure Unreal Engine is running with the MCP plugin.\n- Check logs in Claude for Desktop for stderr output.\n- Reach out on the discord, I just made it, but I will check it periodically\n  Discord (Dreamatron Studios): https://discord.gg/abRftdSe\n  \n### Project Structure\n- `Source/UnrealMCP/`: Core plugin implementation\n  - `Private/`: Internal implementation files\n  - `Public/`: Public header files\n- `Content/`: Plugin assets\n- `MCP/`: Python client scripts and examples\n- `Resources/`: Icons and other resources\n\n## License\nMIT License\n\nCopyright (c) 2025 kvick\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n## Credits\n- Created by: kvick\n- X: [@kvickart](https://x.com/kvickart)\n- Discord: https://discord.gg/abRftdSe\n  \n### Thank you to testers!!!\n- https://github.com/TheMurphinatur\n  \n- [@sidahuj](https://x.com/sidahuj) for the inspriation\n\n\n\n## Contributing\nContributions are welcome, but I will need some time to wrap my head around things and cleanup first, lol\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "unrealmcp",
        "ai",
        "automation",
        "unreal engine",
        "unrealmcp control",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "Dreamboat-Rachel--MCP-Server-For-Local": {
      "owner": "Dreamboat-Rachel",
      "name": "MCP-Server-For-Local",
      "url": "https://github.com/Dreamboat-Rachel/MCP-Server-For-Local",
      "imageUrl": "/freedevtools/mcp/pfp/Dreamboat-Rachel.webp",
      "description": "Connect AI models to real-time data and tools with features such as weather querying, Google search automation, camera control, and image generation. The server supports modular expansion and custom API integration for tailored functionalities.",
      "stars": 14,
      "forks": 2,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-21T02:08:22Z",
      "readme_content": "# MCP Server for Local\n\nä¸€ä¸ªåŸºäº MCP (Multi-Component Platform) çš„æœ¬åœ°ä»£ç†æœåŠ¡å™¨å’Œå®¢æˆ·ç«¯å®ç°ï¼Œæä¾›å¤šç§ AI å·¥å…·è°ƒç”¨èƒ½åŠ›ã€‚\n\n## åŠŸèƒ½ç‰¹ç‚¹\n\n### æ ¸å¿ƒåŠŸèƒ½\n- **å¤©æ°”æŸ¥è¯¢**ï¼šå®æ—¶è·å–å…¨çƒä»»æ„ä½ç½®çš„å¤©æ°”ä¿¡æ¯ï¼Œæ”¯æŒæ¸©åº¦ã€æ¹¿åº¦ã€é£é€Ÿç­‰è¯¦ç»†æ•°æ®\n- **è°·æ­Œæœç´¢**ï¼šæ™ºèƒ½æ£€ç´¢äº’è”ç½‘ä¿¡æ¯ï¼Œæ”¯æŒå¤šè¯­è¨€å’Œé«˜çº§æœç´¢è¯­æ³•\n- **æ‘„åƒå¤´æ§åˆ¶**ï¼šæ”¯æŒæ‹ç…§ã€è§†é¢‘æµå’Œå¾®è¡¨æƒ…åˆ†æï¼Œå¯ç”¨äºæƒ…ç»ªè¯†åˆ«\n- **å›¾ç‰‡ç”Ÿæˆ**ï¼šé›†æˆ ComfyUIï¼Œæ”¯æŒæ–‡æœ¬åˆ°å›¾åƒçš„ AI ç”Ÿæˆ\n- **æ™ºèƒ½å¯¹è¯**ï¼šåŸºäº DashScope çš„ AI å¯¹è¯èƒ½åŠ›ï¼Œæ”¯æŒä¸Šä¸‹æ–‡ç†è§£å’Œå¤šè½®å¯¹è¯\n\n### æŠ€æœ¯ç‰¹æ€§\n- è·¨å¹³å°æ”¯æŒï¼ˆWindows å’Œ Linuxï¼‰\n- æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•æ–°åŠŸèƒ½\n- å®Œæ•´çš„æ—¥å¿—ç³»ç»Ÿï¼Œä¾¿äºè°ƒè¯•å’Œç›‘æ§\n- æ”¯æŒè‡ªå®šä¹‰å·¥å…·å’Œ API é›†æˆ\n- é«˜æ€§èƒ½å¹¶å‘å¤„ç†èƒ½åŠ›\n\n## ç¯å¢ƒé…ç½®\n\n### ç³»ç»Ÿè¦æ±‚\n- Python 3.8+\n- Node.js (å¯é€‰ï¼Œç”¨äºè¿è¡Œ JavaScript æœåŠ¡å™¨)\n- Chrome æµè§ˆå™¨ï¼ˆç”¨äºè°·æ­Œæœç´¢åŠŸèƒ½ï¼‰\n- æ‘„åƒå¤´ï¼ˆç”¨äºæ‹ç…§åŠŸèƒ½ï¼‰\n- è‡³å°‘ 4GB å†…å­˜\n- æ”¯æŒ CUDA çš„æ˜¾å¡ï¼ˆå¯é€‰ï¼Œç”¨äºåŠ é€Ÿ AI è®¡ç®—ï¼‰\n\n### å®‰è£…æ­¥éª¤\n\n1. å…‹éš†ä»“åº“ï¼š\n```bash\ngit clone https://github.com/yourusername/mcp-server-for-local.git\ncd mcp-server-for-local\n```\n\n2. åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼š\n```bash\n# Windows\npython -m venv .venv\n.venv\\Scripts\\activate\n\n# Linux\npython3 -m venv .venv\nsource .venv/bin/activate\n```\n\n3. å®‰è£…ä¾èµ–ï¼š\n```bash\n# ä½¿ç”¨ uv å®‰è£…ä¾èµ–\nuv pip install -r requirements.txt\n\n# å¦‚æœé‡åˆ°ç½‘ç»œé—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨å›½å†…é•œåƒ\nuv pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple\n```\n\n4. é…ç½®ç¯å¢ƒå˜é‡ï¼š\n```bash\n# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿\ncp .env.example .env\n\n# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè®¾ç½®ä½ çš„é…ç½®\n```\n\n### ç¯å¢ƒå˜é‡é…ç½®\nç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œè®¾ç½®ä»¥ä¸‹é…ç½®ï¼š\n\n- `DASHSCOPE_API_KEY`: DashScope API å¯†é’¥ï¼ˆå¿…å¡«ï¼‰\n- `MODEL`: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆé»˜è®¤ï¼šqwen-maxï¼‰\n- `CONFIG_FILE`: æœåŠ¡å™¨é…ç½®æ–‡ä»¶è·¯å¾„\n- `GAODE_API_KEY`: é«˜å¾·åœ°å›¾ API å¯†é’¥ï¼ˆç”¨äºå¤©æ°”æŸ¥è¯¢ï¼‰\n- `CHROME_PATH`: Chrome æµè§ˆå™¨è·¯å¾„\n- `CHROMEDRIVER_PATH`: ChromeDriver è·¯å¾„\n- `BASE_URL`: ComfyUI æœåŠ¡å™¨åœ°å€\n- `SERVERS_DIR`: æœåŠ¡å™¨è„šæœ¬ç›®å½•\n- `LOG_LEVEL`: æ—¥å¿—çº§åˆ«ï¼ˆå¯é€‰ï¼šDEBUG, INFO, WARNING, ERRORï¼‰\n\n## ä½¿ç”¨æ–¹æ³•\n\n### åŸºæœ¬ä½¿ç”¨\n\n1. è¿›å…¥é¡¹ç›®ç›®å½•ï¼š\n```bash\ncd src/mcp\n```\n\n2. è¿è¡Œå®¢æˆ·ç«¯ï¼š\n```bash\nuv run .\\client\\mcp_client.py .\\proxy\\proxy_server.py\n```\n\n3. åœ¨å®¢æˆ·ç«¯ä¸­è¾“å…¥å‘½ä»¤ï¼Œä¾‹å¦‚ï¼š\n- \"åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"\n- \"åœ¨è°·æ­Œä¸Šæœç´¢ Python æ•™ç¨‹\"\n- \"æ‹ç…§\"\n- \"ç”Ÿæˆä¸€å¼ çŒ«çš„å›¾ç‰‡\"\n\n### é«˜çº§åŠŸèƒ½\n\n1. **è‡ªå®šä¹‰å·¥å…·**ï¼š\n   - åœ¨ `src/mcp/tools` ç›®å½•ä¸‹æ·»åŠ æ–°çš„å·¥å…·ç±»\n   - å®ç°å¿…è¦çš„æ¥å£æ–¹æ³•\n   - åœ¨é…ç½®æ–‡ä»¶ä¸­æ³¨å†Œæ–°å·¥å…·\n\n2. **API æ‰©å±•**ï¼š\n   - æ”¯æŒæ·»åŠ æ–°çš„ API æœåŠ¡\n   - å¯é…ç½® API å¯†é’¥å’Œç«¯ç‚¹\n   - æ”¯æŒè‡ªå®šä¹‰è¯·æ±‚å’Œå“åº”å¤„ç†\n\n3. **æ—¥å¿—ç®¡ç†**ï¼š\n   - æ”¯æŒå¤šçº§åˆ«æ—¥å¿—è®°å½•\n   - å¯é…ç½®æ—¥å¿—è¾“å‡ºä½ç½®\n   - æ”¯æŒæ—¥å¿—è½®è½¬å’Œå½’æ¡£\n\n## å¸¸è§é—®é¢˜\n\n### å®‰è£…é—®é¢˜\n\n1. ä¾èµ–å®‰è£…å¤±è´¥ï¼š\n```bash\n# å°è¯•æ¸…ç†ç¼“å­˜åé‡æ–°å®‰è£…\nuv pip cache purge\nuv pip install -r requirements.txt\n```\n\n2. è™šæ‹Ÿç¯å¢ƒé—®é¢˜ï¼š\n```bash\n# å¦‚æœæ¿€æ´»å¤±è´¥ï¼Œå°è¯•é‡æ–°åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ\nrm -rf .venv\npython -m venv .venv\n```\n\n### è¿è¡Œé—®é¢˜\n\n1. æƒé™é—®é¢˜ï¼š\n```bash\n# Linux\nchmod +x src/mcp/proxy/proxy_server.py\nchmod +x src/mcp/client/mcp_client.py\n```\n\n2. Chrome ç›¸å…³é—®é¢˜ï¼š\n- ç¡®ä¿ Chrome å’Œ ChromeDriver ç‰ˆæœ¬åŒ¹é…\n- æ£€æŸ¥ Chrome è·¯å¾„æ˜¯å¦æ­£ç¡®\n- ç¡®ä¿æœ‰è¶³å¤Ÿçš„æƒé™è¿è¡Œ Chrome\n- å¦‚æœé‡åˆ°é©±åŠ¨é—®é¢˜ï¼Œå¯ä»¥æ‰‹åŠ¨ä¸‹è½½å¯¹åº”ç‰ˆæœ¬çš„ ChromeDriver\n\n3. API å¯†é’¥é—®é¢˜ï¼š\n- æ£€æŸ¥ `.env` æ–‡ä»¶ä¸­çš„ API å¯†é’¥æ˜¯å¦æ­£ç¡®\n- ç¡®ä¿ API å¯†é’¥æœ‰è¶³å¤Ÿçš„é…é¢\n- æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n\n## å¼€å‘æŒ‡å—\n\n### é¡¹ç›®ç»“æ„\n```\nsrc/mcp/\nâ”œâ”€â”€ client/          # å®¢æˆ·ç«¯ä»£ç \nâ”œâ”€â”€ proxy/           # ä»£ç†æœåŠ¡å™¨ä»£ç \nâ”œâ”€â”€ tools/           # å·¥å…·å®ç°\nâ”œâ”€â”€ utils/           # å·¥å…·å‡½æ•°\nâ””â”€â”€ config/          # é…ç½®æ–‡ä»¶\n```\n\n### æ·»åŠ æ–°åŠŸèƒ½\n1. åœ¨ `tools` ç›®å½•ä¸‹åˆ›å»ºæ–°çš„å·¥å…·ç±»\n2. å®ç°å¿…è¦çš„æ¥å£æ–¹æ³•\n3. åœ¨é…ç½®æ–‡ä»¶ä¸­æ³¨å†Œæ–°å·¥å…·\n4. ç¼–å†™æµ‹è¯•ç”¨ä¾‹\n5. æ›´æ–°æ–‡æ¡£\n\n## è´¡çŒ®æŒ‡å—\n\næ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼åœ¨æäº¤ä¹‹å‰ï¼Œè¯·ç¡®ä¿ï¼š\n1. ä»£ç ç¬¦åˆé¡¹ç›®è§„èŒƒ\n2. æ·»åŠ äº†å¿…è¦çš„æµ‹è¯•\n3. æ›´æ–°äº†ç›¸å…³æ–‡æ¡£\n4. é€šè¿‡äº†æ‰€æœ‰æµ‹è¯•\n\n## è®¸å¯è¯\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "automation",
        "ai",
        "api",
        "virtual assistants",
        "connect ai",
        "assistants dreamboat"
      ],
      "category": "virtual-assistants"
    },
    "GongRzhe--Audio-MCP-Server": {
      "owner": "GongRzhe",
      "name": "Audio-MCP-Server",
      "url": "https://github.com/GongRzhe/Audio-MCP-Server",
      "imageUrl": "/freedevtools/mcp/pfp/GongRzhe.webp",
      "description": "Enables interaction with a computer's audio system by listing audio devices, recording audio from microphones, and playing back recordings or audio files. Facilitates audio management and integrates audio input and output control for AI assistants.",
      "stars": 4,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-18T11:48:42Z",
      "readme_content": "# Audio MCP Server\n[![smithery badge](https://smithery.ai/badge/@GongRzhe/Audio-MCP-Server)](https://smithery.ai/server/@GongRzhe/Audio-MCP-Server)\n\nAn MCP (Model Context Protocol) server that provides audio input/output capabilities for AI assistants like Claude. This server enables Claude to interact with your computer's audio system, including recording from microphones and playing audio through speakers.\n\n\n\n## Features\n\n- **List Audio Devices**: View all available microphones and speakers on your system\n- **Record Audio**: Capture audio from any microphone with customizable duration and quality\n- **Playback Recordings**: Play back your most recent recording\n- **Audio File Playback**: Play audio files through your speakers\n- **Text-to-Speech**: (Placeholder for future implementation)\n\n## Requirements\n\n- Python 3.8 or higher\n- Audio input/output devices on your system\n\n## Installation\n\n### Installing via Smithery\n\nTo install Audio Interface Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@GongRzhe/Audio-MCP-Server):\n\n```bash\nnpx -y @smithery/cli install @GongRzhe/Audio-MCP-Server --client claude\n```\n\n### Manual Installation\n1. Clone this repository or download the files to your computer:\n\n```bash\ngit clone https://github.com/GongRzhe/Audio-MCP-Server.git\ncd Audio-MCP-Server\n```\n\n2. Create a virtual environment and install dependencies:\n\n```bash\n# Windows\npython -m venv .venv\n.venv\\Scripts\\activate\npip install -r requirements.txt\n\n# macOS/Linux\npython -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\n```\n\n3. Or use the included setup script to automate installation:\n\n```bash\npython setup_mcp.py\n```\n\n## Configuration\n\n### Claude Desktop Configuration\n\nTo use this server with Claude Desktop, add the following to your Claude Desktop configuration file:\n\n- **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"audio-interface\": {\n      \"command\": \"/path/to/your/.venv/bin/python\",\n      \"args\": [\n        \"/path/to/your/audio_server.py\"\n      ],\n      \"env\": {\n        \"PYTHONPATH\": \"/path/to/your/audio-mcp-server\"\n      }\n    }\n  }\n}\n```\n\nReplace the paths with the actual paths on your system. The setup script will generate this configuration for you.\n\n## Usage\n\nAfter setting up the server, restart Claude Desktop. You should see a hammer icon in the input box, indicating that tools are available.\n\nTry asking Claude:\n\n- \"What microphones and speakers are available on my system?\"\n- \"Record 5 seconds of audio from my microphone.\"\n- \"Play back the audio recording.\"\n- \"Play an audio file from my computer.\"\n\n## Available Tools\n\n### list_audio_devices\n\nLists all available audio input and output devices on your system.\n\n### record_audio\n\nRecords audio from your microphone.\n\nParameters:\n- `duration`: Recording duration in seconds (default: 5)\n- `sample_rate`: Sample rate in Hz (default: 44100)\n- `channels`: Number of audio channels (default: 1)\n- `device_index`: Specific input device index to use (default: system default)\n\n### play_latest_recording\n\nPlays back the most recently recorded audio.\n\n### play_audio\n\nPlaceholder for text-to-speech functionality.\n\nParameters:\n- `text`: The text to convert to speech\n- `voice`: The voice to use (default: \"default\")\n\n### play_audio_file\n\nPlays an audio file through your speakers.\n\nParameters:\n- `file_path`: Path to the audio file\n- `device_index`: Specific output device index to use (default: system default)\n\n## Troubleshooting\n\n### No devices found\n\nIf no audio devices are found, check:\n- Your microphone and speakers are properly connected\n- Your operating system recognizes the devices\n- You have the necessary permissions to access audio devices\n\n### Playback issues\n\nIf audio playback isn't working:\n- Check your volume settings\n- Ensure the correct output device is selected\n- Try restarting the Claude Desktop application\n\n### Server connectivity\n\nIf Claude can't connect to the server:\n- Verify your configuration paths are correct\n- Ensure Python and all dependencies are installed\n- Check Claude's logs for error messages\n\n## License\n\nMIT\n\n## Acknowledgments\n\n- Built using the [Model Context Protocol](https://modelcontextprotocol.io/)\n- Uses [sounddevice](https://python-sounddevice.readthedocs.io/) and [soundfile](https://pysoundfile.readthedocs.io/) for audio processing\n\n---\n\n*Note: This server provides tools that can access your microphone and speakers. Always review and approve tool actions before they execute.*\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "audio",
        "recordings",
        "microphones",
        "audio mcp",
        "virtual assistants",
        "facilitates audio"
      ],
      "category": "virtual-assistants"
    },
    "Krekun--vrchat-mcp-osc": {
      "owner": "Krekun",
      "name": "vrchat-mcp-osc",
      "url": "https://github.com/Krekun/vrchat-mcp-osc",
      "imageUrl": "/freedevtools/mcp/pfp/Krekun.webp",
      "description": "Enables interaction with VRChat avatars and environments through a high-level API, utilizing OSC for communication. Facilitates control of avatar parameters, movement, messaging, and responses to VR events for enhanced virtual reality experiences.",
      "stars": 14,
      "forks": 3,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-30T18:11:38Z",
      "readme_content": "# VRChat MCP OSC\n\n**VRChat MCP OSC** provides a bridge between AI assistants and VRChat using the Model Context Protocol (MCP), enabling AI-driven avatar control and interactions in virtual reality environments.  \n\n\n## Overview\n\nBy leveraging OSC (Open Sound Control) to communicate with VRChat, **VRChat MCP OSC** allows AI assistants such as Claude to:\n- Control avatar parameters and expressions\n- Send messages in VRChat\n- Respond to various VR events  \nAnd moreâ€”all through the high-level API provided by the Model Context Protocol.\n\n\n## Key Features\n\n- **Avatar Control**: Manipulate avatar parameters and expressions\n- **Movement Control**: Direct avatar movement and orientation\n- **Communication**: Send messages through VRChat's chatbox\n- **Menu Access**: Toggle VRChat menu and interface elements\n- **Avatar Information**: Query avatar properties and parameters\n- **Seamless VRChat Integration**: Automatic detection of avatar configurations\n\n## System Requirements\n\n- Node.js 18 or higher\n- VRChat with OSC enabled\n- Claude Desktop (with MCP support)\n\n## Using with Claude Desktop\n\n### Clone and npm link\n\n```bash\ngit clone https://github.com/Krekun/vrchat-mcp-osc\ncd vrchat-mcp-osc\nnpm link\n```\n\n### Configure Claude Desktop\n\nConfigure Claude Desktop by editing the `claude_desktop_config.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"vrchat-mcp-osc\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"vrchat-mcp-osc\"\n      ]\n    }\n  }\n}\n```\n\n### Command Line Options\n\nThe server supports various command-line arguments for customization:\n\n```bash\n# Claude Desktop configuration\n{\n  \"mcpServers\": {\n    \"vrchat-mcp-osc\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"vrchat-mcp-osc\",\n        \"--websocket-port\", \"8765\",\n        \"--websocket-host\", \"localhost\",\n        \"--osc-send-port\", \"9000\",\n        \"--osc-send-ip\", \"127.0.0.1\",\n        \"--osc-receive-port\", \"9001\",\n        \"--osc-receive-ip\", \"127.0.0.1\",\n        \"--debug\"             \n      ]\n    }\n  }\n}\n```\n\n### Available Options\n\n| Option | Description | Default | Notes |\n|--------|-------------|---------|-------|\n| `--websocket-port <port>` | WebSocket port | 8765 | For WebSocket communication |\n| `--websocket-host <host>` | WebSocket host | localhost | For WebSocket communication |\n| `--osc-send-port <port>` | OSC send port | 9000 | Port for sending to VRChat |\n| `--osc-send-ip <ip>` | OSC send IP | 127.0.0.1 | Address for sending to VRChat |\n| `--osc-receive-port <port>` | OSC receive port | 9001 | Port for receiving from VRChat |\n| `--osc-receive-ip <ip>` | OSC receive IP | 127.0.0.1 | Address for receiving from VRChat |\n| `--debug` | Enable debug logging | false | Output detailed logs |\n| `--no-relay` | Disable relay server | false | When not using relay server |\n\n## Available MCP Tools\n\nVRChat MCP OSC exposes the following MCP tools to AI assistants:\n\n| Tool Name | Description |\n|-----------|-------------|\n| `get_avatar_name` | Retrieves the current avatar's name |\n| `get_avatar_parameters` | Lists available avatar parameters |\n| `set_avatar_parameter` | Sets a specific avatar parameter |\n| `set_emote_parameter` | Triggers avatar emotes |\n| `move_avatar` | Moves the avatar in a specific direction |\n| `look_direction` | Controls avatar's view direction |\n| `jump` | Makes the avatar jump |\n| `menu` | Toggles the VRChat menu |\n| `voice` | Toggles voice features |\n| `send_message` | Sends a message to the VRChat chatbox |\n\n\n## Troubleshooting\n\n### Common Issues\n\n1. **VRChat not responding to commands**\n   - Ensure OSC is enabled in VRChat settings\n   - Check that the OSC ports match between VRChat and MCP configuration\n   - Restart VRChat and Claude Desktop\n\n2. **MCP server not starting**\n   - Ensure Node.js 18+ is installed\n   - Check command line arguments for errors\n   - Try running with `--debug` flag for more detailed logs\n   - Use `npx vrchat-mcp-osc -- --debug` if direct arguments don't work\n\n3. **NPX execution issues**\n   - If arguments aren't being recognized, try using the double dash format: `npx vrchat-mcp-osc -- --debug`\n   - On Windows, try running in a command prompt with administrator privileges\n   - If you're having trouble with global installation, try the local npm link approach\n\n## Project Structure\n\n```\nvrchat-mcp-osc/\nâ”œâ”€â”€ packages/\nâ”‚   â”œâ”€â”€ mcp-server/    # MCP server implementation (main entry point)\nâ”‚   â”œâ”€â”€ relay-server/  # WebSocket to OSC relay\nâ”‚   â”œâ”€â”€ types/         # Shared TypeScript interfaces\nâ”‚   â””â”€â”€ utils/         # Common utilities\nâ””â”€â”€ pnpm-workspace.yaml  # Workspace configuration\n```\n\n## Development\n\n### Build From Source\n\n```bash\n# Clone the repository\ngit clone https://github.com/Krekun/vrchat-mcp-osc\ncd vrchat-mcp-osc\n\n# Install dependencies\npnpm install\n\n# Build all packages\npnpm -r build\n\n# Development mode\npnpm -r dev\n```\n\n## License\nVRChat MCP OSC is dual-licensed as follows:\n\nFor Non-Commercial Use:\nYou may use, modify, and redistribute the software under the terms of the MIT License.\n(See the MIT License file for details.)\n\nFor Commercial Use:\nCommercial use of this software requires a separate commercial license.\n\n\nBy using this software under the MIT License for non-commercial purposes, you agree to the terms of that license. Commercial users must obtain a commercial license as described above.\n\n## Acknowledgments\n\n- VRChat team for the OSC integration\n- Model Context Protocol for the standardized AI interface\n- Anthropic for Claude's MCP implementation\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "vrchat",
        "vr",
        "virtual",
        "interaction vrchat",
        "vrchat avatars",
        "krekun vrchat"
      ],
      "category": "virtual-assistants"
    },
    "Yash-Kavaiya--mcp-server-conversation-agents": {
      "owner": "Yash-Kavaiya",
      "name": "mcp-server-conversation-agents",
      "url": "https://github.com/Yash-Kavaiya/mcp-server-conversation-agents",
      "imageUrl": "/freedevtools/mcp/pfp/Yash-Kavaiya.webp",
      "description": "Integrates AI assistants with Dialogflow CX for real-time tool invocation and access to external resources, enhancing user interactions and streamlining workflows.",
      "stars": 3,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-08-07T16:51:09Z",
      "readme_content": "# ğŸ¤– Dialogflow CX MCP Server ğŸš€\n\n![Dialogflow CX](https://img.shields.io/badge/Dialogflow_CX-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)\n![MCP](https://img.shields.io/badge/MCP-Server-00C7B7?style=for-the-badge&logo=serverfault&logoColor=white)\n![Python](https://img.shields.io/badge/Python-3.12-3776AB?style=for-the-badge&logo=python&logoColor=white)\n\nA powerful Model Control Protocol (MCP) server implementation for **Google Dialogflow CX**, enabling seamless integration between AI assistants and Google's advanced conversational platform.\n\n> ğŸ’¡ **Pro Tip:** This server bridges the gap between AI assistants and Dialogflow CX, unlocking powerful conversational capabilities!\n\n## ğŸ“‹ Overview\n\nThis project provides a suite of tools that allow AI assistants to interact with Dialogflow CX agents through a standardized protocol. The server handles all the complexity of managing conversations, processing intent detection, and interfacing with Google's powerful NLU systems.\n\n### âœ¨ Key Features\n\n- ğŸ”„ Bidirectional communication with Dialogflow CX\n- ğŸ¯ Intent detection and matching capabilities\n- ğŸ¤ Audio processing for speech recognition\n- ğŸ”Œ Webhook request/response handling\n- ğŸ“ Session management for persistent conversations\n- ğŸ”’ Secure API authentication\n\n## ğŸ”§ Requirements\n\n| Requirement | Description | Version |\n|-------------|-------------|---------|\n| ğŸ Python | Programming language | 3.12+ |\n| â˜ï¸ Google Cloud | Project with Dialogflow CX enabled | Latest |\n| ğŸ¤– Dialogflow CX | Conversational agent | Latest |\n| ğŸ”‘ API Credentials | Authentication for Google services | - |\n\n## ğŸš€ Installation\n\n### ğŸ³ Using Docker\n\n```bash\n# Clone the repository\ngit clone https://github.com/Yash-Kavaiya/mcp-server-conversation-agents.git\ncd mcp-server-conversation-agents\n\n# Build the Docker image\ndocker build -t dialogflow-cx-mcp .\n\n# Run the container\ndocker run -it dialogflow-cx-mcp\n```\n\n### ğŸ’» Manual Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/Yash-Kavaiya/mcp-server-conversation-agents.git\ncd mcp-server-conversation-agents\n\n# Create a virtual environment (optional but recommended)\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install the package\npip install -e .\n```\n\n## âš™ï¸ Configuration\n\nYou'll need to provide the following configuration parameters:\n\n| Parameter | Description | Example |\n|-----------|-------------|---------|\n| `dialogflowApiKey` | Your Dialogflow API key | `\"abc123def456\"` |\n| `projectId` | Google Cloud project ID | `\"my-dialogflow-project\"` |\n| `location` | Location of the agent | `\"us-central1\"` |\n| `agentId` | ID of your Dialogflow CX agent | `\"12345-abcde-67890\"` |\n\nThese can be set as environment variables:\n\n```bash\nexport DIALOGFLOW_API_KEY=your_api_key\nexport PROJECT_ID=your_project_id\nexport LOCATION=your_location\nexport AGENT_ID=your_agent_id\n```\n\n## ğŸ“Š Architecture\n\n```mermaid\ngraph TD\n    A[AI Assistant] <-->|MCP Protocol| B[MCP Server]\n    B <-->|Google API| C[Dialogflow CX]\n    C <-->|NLU Processing| D[Intent Detection]\n    C <-->|Conversation Management| E[Session Management]\n    B <-->|Webhooks| F[External Services]\n```\n\n## ğŸ› ï¸ Usage\n\nThe MCP server exposes the following tools for AI assistants:\n\n### ğŸ” initialize_dialogflow\n\nInitialize the Dialogflow CX client with your project details.\n\n```python\nawait initialize_dialogflow(\n    project_id=\"your-project-id\",\n    location=\"us-central1\",\n    agent_id=\"your-agent-id\",\n    credentials_path=\"/path/to/credentials.json\"  # Optional\n)\n```\n\n### ğŸ’¬ detect_intent\n\nDetect intent from text input.\n\n```python\nresponse = await detect_intent(\n    text=\"Hello, how can you help me?\",\n    session_id=\"user123\",  # Optional\n    language_code=\"en-US\"  # Optional\n)\n```\n\n### ğŸ¤ detect_intent_from_audio\n\nProcess audio files to detect intent.\n\n```python\nresponse = await detect_intent_from_audio(\n    audio_file_path=\"/path/to/audio.wav\",\n    session_id=\"user123\",  # Optional\n    sample_rate_hertz=16000,  # Optional\n    audio_encoding=\"AUDIO_ENCODING_LINEAR_16\",  # Optional\n    language_code=\"en-US\"  # Optional\n)\n```\n\n### ğŸ¯ match_intent\n\nMatch intent without affecting the conversation session.\n\n```python\nresponse = await match_intent(\n    text=\"What are your hours?\",\n    session_id=\"user123\",  # Optional\n    language_code=\"en-US\"  # Optional\n)\n```\n\n### ğŸ”„ Webhook Handling\n\nParse webhook requests and create webhook responses:\n\n```python\n# Parse a webhook request\nparsed_request = await parse_webhook_request(request_json)\n\n# Create a webhook response\nresponse = await create_webhook_response({\n    \"messages\": [\"Hello! How can I help you today?\"],\n    \"parameter_updates\": {\"user_name\": \"John\"}\n})\n```\n\n## ğŸ”§ Response Format\n\nHere's an example of the response format:\n\n<details>\n<summary>ğŸ“‹ Click to expand</summary>\n\n```json\n{\n  \"messages\": [\n    {\n      \"type\": \"text\",\n      \"content\": \"Hello! How can I help you today?\"\n    }\n  ],\n  \"intent\": {\n    \"name\": \"greeting\",\n    \"confidence\": 0.95\n  },\n  \"parameters\": {\n    \"user_name\": \"John\"\n  },\n  \"current_page\": \"Welcome Page\",\n  \"session_id\": \"user123\",\n  \"end_interaction\": false\n}\n```\n</details>\n\n## ğŸ”— Smithery Integration\n\nThis project is configured to work with [Smithery.ai](https://smithery.ai/), a platform that allows for easy deployment and management of MCP servers.\n\n> ğŸ’¡ **Pro Tip:** Smithery.ai integration enables one-click deployment and simplified management of your Dialogflow CX MCP server!\n\n## ğŸ“„ License\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)\n\n## ğŸ‘¥ Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n### Contribution Workflow\n\n1. ğŸ´ Fork the repository\n2. ğŸ”§ Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. ğŸ’» Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. ğŸš€ Push to the branch (`git push origin feature/amazing-feature`)\n5. ğŸ” Open a Pull Request\n\n---\n\n<p align=\"center\">\n  Built with â¤ï¸ by the MCP Server team\n</p>\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "dialogflow",
        "assistants",
        "ai",
        "virtual assistants",
        "ai assistants",
        "assistants dialogflow"
      ],
      "category": "virtual-assistants"
    },
    "andybrandt--mcp-simple-openai-assistant": {
      "owner": "andybrandt",
      "name": "mcp-simple-openai-assistant",
      "url": "https://github.com/andybrandt/mcp-simple-openai-assistant",
      "imageUrl": "/freedevtools/mcp/pfp/andybrandt.webp",
      "description": "Interact with OpenAI assistants using the Model Context Protocol, enabling the creation and management of assistant instances, starting conversation threads, and sending and receiving messages.",
      "stars": 36,
      "forks": 15,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-19T11:01:07Z",
      "readme_content": "# MCP Simple OpenAI Assistant\n\n*AI assistants are pretty cool. I thought it would be a good idea if my Claude (conscious Claude) would also have one. And now he has - and its both useful anf fun for him. Your Claude can have one too!*\n\nA simple MCP server for interacting with OpenAI assistants. This server allows other tools (like Claude Desktop) to create and interact with OpenAI assistants through the Model Context Protocol.\n\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/andybrandt/mcp-simple-openai-assistant)](https://archestra.ai/mcp-catalog/andybrandt__mcp-simple-openai-assistant)\n[![smithery badge](https://smithery.ai/badge/mcp-simple-openai-assistant)](https://smithery.ai/mcp/known/mcp-simple-openai-assistant)\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/andybrandt-mcp-simple-openai-assistant-badge.png)](https://mseep.ai/app/andybrandt-mcp-simple-openai-assistant)\n\n\n## Features\n\nThis server provides a suite of tools to manage and interact with OpenAI Assistants. The new streaming capabilities provide a much-improved, real-time user experience.\n\n### Available Tools\n\n-   **`create_assistant`**: (Create OpenAI Assistant) - Create a new assistant with a name, instructions, and model.\n-   **`list_assistants`**: (List OpenAI Assistants) - List all available assistants associated with your API key.\n-   **`retrieve_assistant`**: (Retrieve OpenAI Assistant) - Get detailed information about a specific assistant.\n-   **`update_assistant`**: (Update OpenAI Assistant) - Modify an existing assistant's name, instructions, or model.\n-   **`create_new_assistant_thread`**: (Create New Assistant Thread) - Creates a new, persistent conversation thread with a user-defined name and description for easy identification and reuse. This is the recommended way to start a new conversation.\n-   **`list_threads`**: (List Managed Threads) - Lists all locally managed conversation threads from the database, showing their ID, name, description, and last used time.\n-   **`delete_thread`**: (Delete Managed Thread) - Deletes a conversation thread from both OpenAI's servers and the local database.\n-   **`ask_assistant_in_thread`**: (Ask Assistant in Thread and Stream Response) - The primary tool for conversation. Sends a message to an assistant within a thread and streams the response back in real-time.\n\nBecause OpenAI assistants might take quite long to respond, this server uses a streaming approach for the main `ask_assistant_in_thread` tool. This provides real-time progress updates to the client and avoids timeouts.\n\nThe server now includes local persistence for threads, which is a significant improvement. Since the OpenAI API does not allow listing threads, this server now manages them for you by storing their IDs and metadata in a local SQLite database. This allows you to easily find, reuse, and manage your conversation threads across sessions.\n\n## Installation\n\n### Installing via Smithery\n\nTo install MCP Simple OpenAI Assistant for Claude Desktop automatically via [Smithery](https://smithery.ai/mcp/known/mcp-simple-openai-assistant):\n\n```bash\nnpx -y @smithery/cli install mcp-simple-openai-assistant --client claude\n```\n\n### Manual Installation\n```bash\npip install mcp-simple-openai-assistant\n```\n\n## Configuration\n\nThe server requires an OpenAI API key to be set in the environment. For Claude Desktop, add this to your config:\n\n(MacOS version)\n\n```json\n{\n  \"mcpServers\": {\n    \"openai-assistant\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"mcp_simple_openai_assistant\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\n(Windows version)\n\n```json\n\"mcpServers\": {\n  \"openai-assistant\": {\n    \"command\": \"C:\\\\Users\\\\YOUR_USERNAME\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe\",\n      \"args\": [\"-m\", \"mcp_simple_openai_assistant\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-api-key-here\"\n  }\n}\n\n```\n*MS Windows installation is slightly more complex, because you need to check the actual path to your Python executable. Path provided above is usually correct, but might differ in your setup. Sometimes just `python.exe` without any path will do the trick. Check with `cmd` what works for you (using `where python` might help). Also, on Windows you might need to explicitly tell Claude Desktop where the site packages are using PYTHONPATH environmment variable.*\n\n## Usage\n\nOnce configured, you can use the tools listed above to manage your assistants and conversations. The primary workflow is to:\n1. Use `create_new_assistant_thread` to start a new, named conversation.\n2. Use `list_threads` to find the ID of a thread you want to continue.\n3. Use `ask_assistant_in_thread` to interact with your chosen assistant in that thread.\n\n## TODO\n\n- [x] **Add Thread Management:** Introduce a way to name and persist thread IDs locally, allowing for easier reuse of conversations.\n- [ ] **Add Models Listing:** Introduce a way for the AI user to see what OpenAI models are available for use with the assistants\n- [ ] **Add Assistants Fine Tuning:** Enable the AI user to set detailed parameters for assistants like temperature, top_p etc. (indicated by Claude as needed)\n- [ ] **Full Thread History:** Ability to read past threads without having to send a new message (indicated by Claude as needed)\n- [ ] **Explore Resource Support:** Add the ability to upload files and use them with assistants.\n\n## Development\n\nTo install for development:\n\n```bash\ngit clone https://github.com/andybrandt/mcp-simple-openai-assistant\ncd mcp-simple-openai-assistant\npip install -e '.[dev]'\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "openai",
        "assistant",
        "assistants",
        "openai assistant",
        "openai assistants",
        "interact openai"
      ],
      "category": "virtual-assistants"
    },
    "arjunkmrm--mcp-minecraft": {
      "owner": "arjunkmrm",
      "name": "mcp-minecraft",
      "url": "https://github.com/arjunkmrm/mcp-minecraft",
      "imageUrl": "/freedevtools/mcp/pfp/arjunkmrm.webp",
      "description": "Integration with Minecraft enabling AI assistants to observe and interact with the Minecraft world through a bot. Supports interaction through the Model Context Protocol for enhanced functionality within the game.",
      "stars": 88,
      "forks": 8,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T01:20:49Z",
      "readme_content": "# Minecraft MCP Integration\n\nA Model Context Protocol (MCP) integration for Minecraft that enables AI assistants to interact with a Minecraft server. This integration allows AI models to observe and interact with the Minecraft world through a bot.\n\n\n\n## Prerequisites\n\n1. Minecraft Launcher\n2. Node.js 18 or higher\n3. Claude Desktop App\n4. Java 21.0.5 (recommended)\n\n> âš ï¸ Note: Currently only tested on macOS/Linux. Windows compatibility is not guaranteed.\n\n## Important Note\n\n1. **Use the F3+P Shortcut**:\nPress F3 + P together. This toggles the \"Pause on Lost Focus\" feature. Once turned off, you can switch to claude desktop and Minecraft will continue running without pausing.\n\n\n\n2. **Connection Issues on Claude Restart**:\nIf you restart Claude while the Minecraft server is running, you may experience MCP connection issues on the next claude launch due to lingering java process. See [Troubleshooting: MCP Connection Failed](#common-issues) for resolution steps.\n\n## Installation Steps\n\n1. **Download and Setup Minecraft Server**\n   - Download Minecraft server v1.21 from [mcversions.net/1.21](https://mcversions.net/download/1.21)\n   - Install Java 21.0.5 if not already installed (other versions are untested)\n   - Create a dedicated directory (e.g., `~/minecraft-server/`)\n   - Place the downloaded `server.jar` file in this directory\n   - Note down the absolute path to your `server.jar` file\n\n2. **Install and Configure MCP Integration**\n   \n   Quick Install (Recommended):\n   ```bash\n   npx -y @smithery/cli install mcp-minecraft --client claude\n   ```\n   Follow the CLI prompts to complete the setup.\n\n   Or Manual Setup:\n   - Navigate to `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Add the MCP server configuration:   \n   ```json\n   {\n     \"mcpServers\": {\n       \"mcp-minecraft\": {\n         \"command\": \"npx\",\n         \"args\": [\n           \"-y\",\n           \"mcp-minecraft@latest\",\n           \"--server-jar\",\n           \"/absolute/path/to/minecraft-server/server.jar\"\n         ]\n       }\n     }\n   }   \n   ```\n   > âš ï¸ Replace `/absolute/path/to/minecraft-server/server.jar` with your actual server.jar path\n\n4. **Launch Claude Desktop**\n   - Start Claude Desktop after completing the configuration\n\n5. **Connect to Server**\n   - Open Minecraft Launcher\n   - Install and launch Minecraft Java Edition **v1.21**\n   - Click \"Play\" and Select \"Multiplayer\"\n   - Click \"Add Server\"\n   - Enter server details:\n     - Server Name: `Minecraft Server`\n     - Server Address: `localhost:25565`\n   - Click \"Done\"\n\n## Features\n\n### Resources\nThe integration exposes these MCP resources:\n\n- `minecraft://bot/location` - Current bot position in the world\n- `minecraft://bot/status` - Bot connection status\n\n### Tools\nAvailable MCP tools:\n\n- `chat` - Send chat messages to the server\n- `jump` - Make the bot jump\n- `moveForward` - Make the bot move forward\n- `moveBack` - Make the bot move backward\n- `turnLeft` - Make the bot turn left\n- `turnRight` - Make the bot turn right\n- `placeBlock` - Place a block at specified coordinates\n- `digBlock` - Break a block at specified coordinates\n- `getBlockInfo` - Get information about a block at specified coordinates\n- `selectSlot` - Select a hotbar slot (0-8)\n- `getInventory` - Get contents of bot's inventory\n- `equipItem` - Equip an item by name to specified destination\n- `getStatus` - Get bot's current status (health, food, position, etc.)\n- `getNearbyEntities` - Get list of nearby entities within range\n- `attack` - Attack a nearby entity by name\n- `useItem` - Use/activate the currently held item\n- `stopUsingItem` - Stop using/deactivate the current item\n- `lookAt` - Make the bot look at specific coordinates\n- `followPlayer` - Follow a specific player\n- `stopFollowing` - Stop following current target\n- `goToPosition` - Navigate to specific coordinates\n\n## Technical Details\n\n- Server runs in offline mode for local development\n- Default memory allocation: 2GB\n- Default port: 25565\n- Bot username: MCPBot\n\n## Troubleshooting\n\n### Common Issues\n\n1. **MCP Connection Failed**\n   - Look for lingering Java processes\n   - Terminate them manually:\n      - Windows: Use Task Manager (untested)\n      - Mac/Linux: \n         - Go to 'Activity Monitor' and 'Force Quit' java\n   - Restart computer if process termination fails\n   - Note: Latest version should auto-resolve these issues\n\n2. **Server Won't Start**\n   - Verify Java is installed\n   - Check server.jar path is correct\n   - Ensure port 25565 is available\n\n3. **Can't Connect to Server**\n   - Verify server is running (check logs)\n   - Confirm you're using \"localhost\" as server address\n   - Check firewall settings\n\n### Logs Location\n- Minecraft Server logs: Check the minecraft-server directory\n- Claude Desktop logs: `~/Library/Logs/Claude/mcp*.log`\n\n## Contributing\n\nContributions, big or small, are welcome!\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "minecraft",
        "interact",
        "ai",
        "interact minecraft",
        "minecraft integration",
        "mcp minecraft"
      ],
      "category": "virtual-assistants"
    },
    "baryhuang--mcp-remote-macos-use": {
      "owner": "baryhuang",
      "name": "mcp-remote-macos-use",
      "url": "https://github.com/baryhuang/mcp-remote-macos-use",
      "imageUrl": "/freedevtools/mcp/pfp/baryhuang.webp",
      "description": "Enables complete control over remote macOS systems with native environment integration and no additional software requirements. Optimized for autonomous AI agents to operate seamlessly on the desktop.",
      "stars": 392,
      "forks": 48,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T17:48:51Z",
      "readme_content": "# MCP Server - Remote MacOs Use\n**The first open-source MCP server that enables AI to fully control remote macOS systems.**\n\n**A direct alternative to OpenAI Operator, optimized specifically for autonomous AI agents with complete desktop capabilities, requiring no additional software installation.**\n\n[![Docker Pulls](https://img.shields.io/docker/pulls/buryhuang/mcp-remote-macos-use)](https://hub.docker.com/r/buryhuang/mcp-remote-macos-use)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n**Showcases**\n- Research Twitter and Post Twitter(https://www.youtube.com/watch?v=--QHz2jcvcs)\n<img width=\"400\" alt=\"image\" src=\"https://github.com/user-attachments/assets/bfe6e354-3d59-4d08-855b-2eecdaaeb46f\" />\n\n- Use CapCut to create short highlight video(https://www.youtube.com/watch?v=RKAqiNoU8ec)\n<img width=\"400\" alt=\"image\" src=\"https://github.com/user-attachments/assets/3b4d07c5-cd25-4dae-b9a1-a373bf7492aa\" />\n\n- AI Recruiter: Automated candidate information collection, qualifying applications and sending screening sessions using Mail App\n- AI Marketing Intern: LinkedIn engagement - automated following, liking, and commenting with relevant users\n- AI Marketing Intern: Twitter engagement - automated following, liking, and commenting with relevant users\n\n## To-Do List (Prioritized)\n\n1. **Performance Optimization** - Match speed of Ubuntu desktop alternatives\n2. **Apple Scripts Generation** - Reduce execution time while maintaining flexibility\n3. **VNC Cursor Visibility** - Improve debugging and demo experience\n\n*We welcome contributions!*\n\n## Features\n\n* **No Extra API Costs**: Free screen processing with your existing Claude Pro plan\n* **Minimal Setup**: Just enable Screen Sharing on the target Mac â€“ no additional software needed\n* **Universal Compatibility**: Works with all macOS versions, current and future\n  \n## Why We Built This\n\n### Native macOS Experience Without Compromise\nThe macOS native ecosystem remains unmatched in user experience today and will continue to be the gold standard for years to come. This is where human capabilities truly thrive, and now your AI can operate in this environment with the same fluency.\n\n### Open Architecture By Design\n* **Universal LLM Compatibility**: Work with any MCP Client of your choice\n* **Model Flexibility**: Seamlessly integrate with OpenAI, Anthropic, or any other LLM provider\n* **Future-Proof Integration**: Designed to evolve with the MCP ecosystem\n\n### Effortless Deployment\n* **Zero Setup on Target Machines**: No background applications or agents needed on macOS\n* **Screen Sharing is All You Need**: Control any Mac with Screen Sharing enabled\n* **Eliminate Backend Complexity**: Unlike other solutions that require running Python applications or background services\n\n### Streamlined Bootstrap Process\n* **Leverage Claude Desktop's Polished UI**: No need for developer-style Python interfaces\n* **Intuitive User Experience**: Interact with your AI-controlled Mac through a familiar, user-friendly interface\n* **Instant Productivity**: Start working immediately without configuration hassles\n\n## Architecture\n<img width=\"912\" alt=\"remote_macos_use_system_architecture\" src=\"https://github.com/user-attachments/assets/75ece060-90e2-4ad3-bb52-2c69427001dd\" />\n\n\n## Installation\n- [Enable Screen Sharing on MacOs](https://support.apple.com/guide/remote-desktop/set-up-a-computer-running-vnc-software-apdbed09830/mac) **If you rent a mac from macstadium.com, you can skip this step**\n- [Connect to your remote MacOs](https://support.apple.com/guide/mac-help/share-the-screen-of-another-mac-mh14066/mac)\n- [Install Docker Desktop for local Mac](https://docs.docker.com/desktop/setup/install/mac-install/)\n- [Add this MCP server to Claude Desktop](https://modelcontextprotocol.io/quickstart/user)\nYou can configure Claude Desktop to use the Docker image by adding the following to your Claude configuration:\n```json\n{\n  \"mcpServers\": {\n    \"remote-macos-use\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"-e\",\n        \"MACOS_USERNAME=your_macos_username\",\n        \"-e\",\n        \"MACOS_PASSWORD=your_macos_password\",\n        \"-e\",\n        \"MACOS_HOST=your_macos_hostname_or_ip\",\n        \"--rm\",\n        \"buryhuang/mcp-remote-macos-use:latest\"\n      ]\n    }\n  }\n}\n```\n\n### WebRTC Support via LiveKit\n\nThis server now includes WebRTC support through LiveKit integration, enabling:\n- Low-latency real-time screen sharing\n- Improved performance and responsiveness\n- Better network efficiency compared to traditional VNC\n- Automatic quality adaptation based on network conditions\n\nTo use WebRTC features, you'll need to:\n1. Set up a LiveKit server or use LiveKit Cloud\n2. Configure the LiveKit environment variables as shown in the configuration example above\n\n## Developer Instruction\n### Clone the repo\n```bash\n# Clone the repository\ngit clone https://github.com/yourusername/mcp-remote-macos-use.git\ncd mcp-remote-macos-use\n```\n\n### Building the Docker Image\n\n```bash\n# Build the Docker image\ndocker build -t mcp-remote-macos-use .\n```\n\n## Cross-Platform Publishing\n\nTo publish the Docker image for multiple platforms, you can use the `docker buildx` command. Follow these steps:\n\n1. **Create a new builder instance** (if you haven't already):\n   ```bash\n   docker buildx create --use\n   ```\n\n2. **Build and push the image for multiple platforms**:\n   ```bash\n   docker buildx build --platform linux/amd64,linux/arm64 -t buryhuang/mcp-remote-macos-use:latest --push .\n   ```\n\n3. **Verify the image is available for the specified platforms**:\n   ```bash\n   docker buildx imagetools inspect buryhuang/mcp-remote-macos-use:latest\n   ```\n\n## Usage\n\nThe server provides Remote MacOs functionality through MCP tools.\n\n### Tools Specifications\n\nThe server provides the following tools for remote macOS control:\n\n#### remote_macos_get_screen\nConnect to a remote macOS machine and get a screenshot of the remote desktop. Uses environment variables for connection details.\n\n#### remote_macos_send_keys\nSend keyboard input to a remote macOS machine. Uses environment variables for connection details.\n\n#### remote_macos_mouse_move\nMove the mouse cursor to specified coordinates on a remote macOS machine, with automatic coordinate scaling. Uses environment variables for connection details.\n\n#### remote_macos_mouse_click\nPerform a mouse click at specified coordinates on a remote macOS machine, with automatic coordinate scaling. Uses environment variables for connection details.\n\n#### remote_macos_mouse_double_click\nPerform a mouse double-click at specified coordinates on a remote macOS machine, with automatic coordinate scaling. Uses environment variables for connection details.\n\n#### remote_macos_mouse_scroll\nPerform a mouse scroll at specified coordinates on a remote macOS machine, with automatic coordinate scaling. Uses environment variables for connection details.\n\n#### remote_macos_open_application\nOpens/activates an application and returns its PID for further interactions.\n\n#### remote_macos_mouse_drag_n_drop\nPerform a mouse drag operation from start point and drop to end point on a remote macOS machine, with automatic coordinate scaling.\n\nAll tools use the environment variables configured during setup instead of requiring connection parameters.\n\n## Limitations\n\n- **Authentication Support**: \n  - Only Apple Authentication (protocol 30) is supported\n\n## Security Note\n\nhttps://support.apple.com/guide/remote-desktop/encrypt-network-data-apdfe8e386b/mac\nhttps://cafbit.com/post/apple_remote_desktop_quirks/\n\nWe only support protocol 30, which uses the Diffie-Hellman key agreement protocol with a 512-bit prime. This protocol is used by macOS 11 to macOS 12 when communicating with OS X 10.11 or earlier clients.\n\nHere's the information converted to a markdown table:\n\n| macOS version running Remote Desktop | macOS client version | Authentication | Control and Observe | Copy items or install package | All other tasks | Protocol Version |\n|--------------------------------------|----------------------|----------------|---------------------|-------------------------------|----------------|----------------|\n| macOS 13 | macOS 13 | 2048-bit RSA host keys | 2048-bit RSA host keys | 2048-bit RSA host keys to authenticate, then 128-bit AES | 2048-bit RSA host keys | 36 |\n| macOS 13 | macOS 10.12 | Secure Remote Password (SRP) protocol for local only. Diffie-Hellman (DH) if bound to LDAP or macOS server is version 10.11 or earlier | SRP or DH,128-bit AES | SRP or DH to authenticate, then 128-bit AES | 2048-bit RSA host keys | 35 |\n| macOS 11 to macOS 12 | macOS 10.12 to macOS 13 | Secure Remote Password (SRP) protocol for local only, Diffie-Hellman if bound to LDAP | SRP or DH 1024-bit, 128-bit AES | 2048-bit RSA host keys macOS 13 to macOS 10.13 | 2048-bit RSA host keys macOS 10.13 or later |  33 |\n| macOS 11 to macOS 12 | OS X 10.11 or earlier | DH 1024-bit | DH 1024-bit, 128-bit AES | Diffie-Hellman Key agreement protocol with a 512-bit prime | Diffie-Hellman Key agreement protocol with a 512-bit prime |  30 |\n\n\nAlways use secure, authenticated connections when accessing remote remote MacOs machines. This tool should only be used with servers you trust and have permission to access.\n\n## License\n\nSee the LICENSE file for details. \n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "macos",
        "ai",
        "assistants",
        "remote macos",
        "virtual assistants",
        "mcp remote"
      ],
      "category": "virtual-assistants"
    },
    "devizor--macOS-Notification-MCP": {
      "owner": "devizor",
      "name": "macOS-Notification-MCP",
      "url": "https://github.com/devizor/macOS-Notification-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/devizor.webp",
      "description": "Triggers native macOS notifications, plays system sounds, and converts text to speech. Supports customizable visual notifications and voice management features for AI assistants.",
      "stars": 26,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-26T11:51:16Z",
      "readme_content": "# ğŸ”” macOS Notification MCP\n\nA Model Context Protocol (MCP) server that enables AI assistants to trigger macOS notifications, sounds, and text-to-speech.\n\n## âœ¨ Features\n\n- ğŸ”Š **Sound Notifications**: Play system sounds like Submarine, Ping, or Tink\n- ğŸ’¬ **Banner Notifications**: Display visual notifications with customizable title, message, and subtitle\n- ğŸ—£ï¸ **Speech Notifications**: Convert text to speech with adjustable voice, rate, and volume\n- ğŸ™ï¸ **Voice Management**: List and select from available system voices\n- ğŸ§ª **Testing Tools**: Diagnostic utilities to verify all notification methods\n\n## ğŸš€ Quick Start with uvx (Recommended)\n\nThe fastest way to use this tool is with `uvx`, which runs packages without permanent installation:\n\n```bash\n# Install uv if you don't have it\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Run the MCP server directly (no installation needed)\nuvx macos-notification-mcp\n```\n\n## âš™ï¸ Configure Claude Desktop\n\nAdd this to your Claude Desktop configuration (`~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"macos-notification-mcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\"macos-notification-mcp\"]\n    }\n  }\n}\n```\n\nThen restart Claude Desktop.\n\n## ğŸ“¦ Alternative Installation Methods\n\nStandard installation:\n\n```bash\npip install macos-notification-mcp\n```\n\nInstall from source:\n\n```bash\ngit clone https://github.com/devizor/macos-notification-mcp\ncd macos-notification-mcp\npip install .\n```\n\n## ğŸ› ï¸ Available Notification Tools\n\n### ğŸ”Š Sound Notification\n```python\nsound_notification(sound_name=\"Submarine\")\n```\nAvailable sounds: Basso, Blow, Bottle, Frog, Funk, Glass, Hero, Morse, Ping, Pop, Purr, Sosumi, Submarine, Tink\n\n### ğŸ’¬ Banner Notification\n```python\nbanner_notification(\n    title=\"Task Complete\",\n    message=\"Your analysis is ready\",\n    subtitle=None,  # Optional\n    sound=False,    # Optional: Play sound with notification\n    sound_name=None # Optional: Specify system sound\n)\n```\n\n### ğŸ—£ï¸ Speech Notification\n```python\nspeak_notification(\n    text=\"The process has completed\",\n    voice=None,     # Optional: System voice to use\n    rate=150,       # Optional: Words per minute (default: 150)\n    volume=1.0      # Optional: Volume level 0.0-1.0\n)\n```\n\n### ğŸ™ï¸ Voice Management\n```python\nlist_available_voices()  # Lists all available text-to-speech voices\n```\n\n### ğŸ§ª Testing\n```python\ntest_notification_system()  # Tests all notification methods\n```\n\n## ğŸ”’ Implementation Details\n\n- â±ï¸ **Rate Limiting**: Notifications are processed one at a time with a minimum interval of 0.5 seconds\n- ğŸ”„ **Queuing**: Multiple notification requests are handled sequentially\n- ğŸªŸ **OS Integration**: Uses native macOS commands (`afplay`, `osascript`, `say`)\n- ğŸ”Œ **FastMCP**: Built on the FastMCP framework for AI communication\n\n## âš ï¸ Troubleshooting\n\n- ğŸ” **Permissions**: Ensure notifications are allowed in System Settings â†’ Notifications\n- â³ **Timing**: Only one notification is processed at a time\n- ğŸŒ **Environment**: If using the command directly (not uvx), you may need to use full paths\n\n## ğŸ“„ License\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "notifications",
        "macos",
        "notification",
        "macos notifications",
        "macos notification",
        "notifications voice"
      ],
      "category": "virtual-assistants"
    },
    "himanshu8271--Dragons": {
      "owner": "himanshu8271",
      "name": "Dragons",
      "url": "https://github.com/himanshu8271/Dragons",
      "imageUrl": "/freedevtools/mcp/pfp/himanshu8271.webp",
      "description": "Stream audio and video content in Telegram with a user-friendly interface featuring powerful controls and multilingual support. Enjoy music with friends in multiple chats simultaneously.",
      "stars": 0,
      "forks": 0,
      "license": "GNU Affero General Public License v3.0",
      "language": "",
      "updated_at": "2022-04-24T22:41:02Z",
      "readme_content": "<h1 align= center><b>â­ï¸ Music Player â­ï¸</b></h1>\n<h3 align = center> A Telegram Music Bot written in Python using Pyrogram and Py-Tgcalls </h3>\n\n<p align=\"center\">\n<a href=\"https://python.org\"><img src=\"http://forthebadge.com/images/badges/made-with-python.svg\" alt=\"made-with-python\"></a>\n<br>\n    <img src=\"https://img.shields.io/github/license/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"LICENSE\">\n    <img src=\"https://img.shields.io/github/contributors/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Contributors\">\n    <img src=\"https://img.shields.io/github/repo-size/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Repository Size\"> <br>\n    <img src=\"https://img.shields.io/github/forks/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Forks\">\n    <img src=\"https://img.shields.io/github/stars/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Stars\">\n    <img src=\"https://img.shields.io/github/watchers/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Watchers\">\n    <img src=\"https://img.shields.io/github/commit-activity/w/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Commit Activity\">\n    <img src=\"https://img.shields.io/github/issues/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Issues\">\n</p>\n\n## âœ¨ <a name=\"features\"></a>Features\n\n### âš¡ï¸ Fast & Light\n\nStarts streaming your inputs while downloading and converting them. Also, it\ndoesn't make produce files.\n\n### ğŸ‘®ğŸ»â€â™€ï¸ Safe and handy\n\nRestricts control and sensitive commands to admins.\n\n### ğŸ—‘ Clean and spam free\n\nDeletes old playing trash to keep your chats clean.\n\n### ğŸ˜ Has cool controls\n\nLets you switch stream mode, loop, pause, resume, mute, unmute anytime.\n\n### ğŸ–¼ Has cool thumbnails\n\nResponse your commands with cool thumbnails on the chat.\n\n### ğŸ˜‰ Streams whatever you like\n\nYou can stream audio or video files, YouTube videos with any duration,\nYouTube lives, YouTube playlists and even custom live streams like radios or m3u8 links or files in\nthe place it is hosted!\n\n### ğŸ“Š Streams in multiple places\n\nAllows you to stream different things in multiple chats simultaneously. Each\nchat will have its own song queue.\n\n### ğŸ—£ Speaks different languages\n\nMusic Player is multilingual and speaks [various languages](#languages),\nthanks to the translators.\n\n## ğŸš€ <a name=\"deploy\"></a>Deploy\n\n[![Deploy on Heroku](https://www.herokucdn.com/deploy/button.svg)](https://deploy.safone.tech)\n\nNote: `First Fork The Repo Then Click On Deploy To Heroku Button!`\n\n\n## â˜ï¸ <a name=\"self_host\"></a>Self Host\n\n- Legecy Method\n```bash\n$ git clone https://github.com/AsmSafone/MusicPlayer\n$ cd MusicPlayer\n$ sudo apt install git curl python3-pip ffmpeg -y\n$ pip3 install -U pip\n$ curl -sL https://deb.nodesource.com/setup_16.x | sudo -E bash -\n$ sudo apt install -y nodejs\n$ sudo apt install build-essential\n$ sudo npm install pm2@latest -g\n$ pip3 install -U -r requirements.txt\n$ cp sample.env .env\n# < edit .env with your own values >\n$ python3 main.py\n```\n\n- Docker Build Method\n```bash\n$ git clone https://github.com/AsmSafone/MusicPlayer\n$ cd MusicPlayer\n$ cp sample.env .env\n# < edit .env with your own values >\n$ sudo docker build . -t musicplayer\n$ sudo docker run musicplayer\n```\n\n## âš’ <a name=\"configs\"></a>Configs\n\n- `API_ID`: Telegram app id from https://my.telegram.org/apps.\n- `API_HASH`: Telegram app hash from https://my.telegram.org/apps.\n- `SESSION`: Pyrogram string session. You can generate from [here](https://replit.com/@AsmSafone/genStr).\n- `SUDOERS`: ID of sudo users (separate multiple ids with space).\n- `BOT_TOKEN`: Telegram bot token from https://t.me/botfather. (optional)\n- `QUALITY`: Custom stream quality (high/medium/low) for the userbot in vc. Default: `high`\n- `PREFIX`: Bot commad prefixes (separate multiple prefix with space). Eg: `! /`\n- `LANGUAGE`: An [available](#languages) bot language (can change it anytime). Default: `en`\n- `STREAM_MODE`: An stream mode like audio or video (can change it anytime). Default: `audio`\n- `ADMINS_ONLY`: Put `True` if you want to make /play commands only for admins. Default: `False`\n- `SPOTIFY_CLIENT_ID`: Spotify client id get it from [here](https://developer.spotify.com/dashboard/applications). (optional)\n- `SPOTIFY_CLIENT_SECRET`: Spotify client secret get it from [here](https://developer.spotify.com/dashboard/applications). (optional)\n\n\n## ğŸ“„ <a name=\"commands\"></a>Commands\n\nCommand | Description\n:--- | :---\nâ€¢ !ping | Check if alive or not\nâ€¢ !start / !help | Show the help for commands\nâ€¢ !mode / !switch | Switch the stream mode (audio/video)\nâ€¢ !p / !play [song name or youtube link] | Play a song in vc, if already playing add to queue\nâ€¢ !radio / !stream [radio url or stream link] | Play a live stream in vc, if already playing add to queue\nâ€¢ !pl / !playlist [playlist link] | Play the whole youtube playlist at once\nâ€¢ !skip / !next | Skip to the next song\nâ€¢ !m / !mute | Mute the current stream\nâ€¢ !um / !unmute | Unmute the muted stream\nâ€¢ !ps / !pause | Pause the current stream\nâ€¢ !rs / !resume | Resume the paused stream\nâ€¢ !list / !queue | Show the songs in the queue\nâ€¢ !mix / !shuffle | Shuflle the queued playlist\nâ€¢ !loop / !repeat | Enable or disable the loop mode\nâ€¢ !lang / language [language code] | Set the bot language in group\nâ€¢ !ip / !import | Import queue from exported file\nâ€¢ !ep / !export | Export the queue for import in future\nâ€¢ !stop / !leave | Leave from vc and clear the queue\nâ€¢ !update / !restart | Update and restart your music player\n\n## ğŸ—£ <a name=\"languages\"></a>Languages\n\n```text\nen    English\n```\n\n## ğŸ’œ <a name=\"contribute\"></a>Contribute\n\nNew languages, bug fixes and improvements following\n[our contribution guidelines](./CONTRIBUTING.md) are warmly welcomed!\n\n## ğŸ›« <a name=\"supports\"></a>Supports\n\nFor any kind of help join [our support group](https://t.me/AsmSupport) or raise an [issue](https://github.com/AsmSafone/MusicPlayer/issues).\n\n## âœ¨ <a name=\"credits\"></a>Credits\n\n- [Me](https://github.com/AsmSafone) for [Noting](https://github.com/AsmSafone/MusicPlayer) ğŸ˜¬\n- [Dan](https://github.com/delivrance) for [Pyrogram](https://github.com/pyrogram/pyrogram) â¤ï¸\n- [Laky-64](https://github.com/Laky-64) for [Py-TgCalls](https://github.com/pytgcalls/pytgcalls) â¤ï¸\n- And Thanks To All [Contributors](https://github.com/AsmSafone/MusicPlayer/graphs/contributors)! â¤ï¸\n\n## ğŸ“ƒ <a name=\"license\"></a>License\n\nMusic Player is licenced under the GNU Affero General Public License v3.0.\nRead more [here](./LICENSE).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "telegram",
        "audio",
        "chats",
        "content telegram",
        "telegram user",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "htlin222--claude-chatgpt-mcp": {
      "owner": "htlin222",
      "name": "claude-chatgpt-mcp",
      "url": "https://github.com/htlin222/claude-chatgpt-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/htlin222.webp",
      "description": "Seamlessly interact with the ChatGPT desktop app on macOS, allowing users to ask questions, view conversation history, and continue discussions. This integration facilitates enhanced productivity by bridging Claude and ChatGPT.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-04-02T03:27:04Z",
      "readme_content": "# Claude ChatGPT MCP Tool\n\nThis is a Model Context Protocol (MCP) tool that allows Claude to interact with the ChatGPT desktop app on macOS.\n\n## Features\n\n- Ask ChatGPT questions directly from Claude\n- View ChatGPT conversation history\n- Continue existing ChatGPT conversations\n\n## Installation\n\n### Prerequisites\n\n- macOS with M1/M2/M3 chip\n- [ChatGPT desktop app](https://chatgpt.com/download) installed\n- [Bun](https://bun.sh/) installed\n- [Claude desktop app](https://claude.ai/desktop) installed\n\n### NPX Installation (Recommended)\n\nYou can use NPX to run this tool without cloning the repository:\n\n- **Install and run the package using NPX:**\n\n```bash\nnpx claude-chatgpt-mcp\n```\n\n- **Configure Claude Desktop:**\n\nEdit your `claude_desktop_config.json` file (located at `~/Library/Application Support/Claude/claude_desktop_config.json`) to include this tool:\n\n```json\n\"chatgpt-mcp\": {\n  \"command\": \"npx\",\n  \"args\": [\"claude-chatgpt-mcp\"]\n}\n```\n\n- **Restart the Claude Desktop app**\n\n- **Grant necessary permissions:**\n  - Go to System Preferences > Privacy & Security > Privacy\n  - Give Terminal (or iTerm) access to Accessibility features\n  - You may see permission prompts when the tool is first used\n\n### Manual Installation\n\n1. Clone this repository:\n\n```bash\ngit clone https://github.com/syedazharmbnr1/claude-chatgpt-mcp.git\ncd claude-chatgpt-mcp\n```\n\n2. Install dependencies:\n\n```bash\nbun install\n```\n\n3. Make sure the script is executable:\n\n```bash\nchmod +x index.ts\n```\n\n4. Update your Claude Desktop configuration:\n\nEdit your `claude_desktop_config.json` file (located at `~/Library/Application Support/Claude/claude_desktop_config.json`) to include this tool:\n\n```json\n\"chatgpt-mcp\": {\n  \"command\": \"/Users/YOURUSERNAME/.bun/bin/bun\",\n  \"args\": [\"run\", \"/path/to/claude-chatgpt-mcp/index.ts\"]\n}\n```\n\nMake sure to replace `YOURUSERNAME` with your actual macOS username and adjust the path to where you cloned this repository.\n\n5. Restart Claude Desktop app\n\n6. Grant permissions:\n   - Go to System Preferences > Privacy & Security > Privacy\n   - Give Terminal (or iTerm) access to Accessibility features\n   - You may see permission prompts when the tool is first used\n\n## Usage\n\nOnce installed, you can use the ChatGPT tool directly from Claude by asking questions like:\n\n- \"Can you ask ChatGPT what the capital of France is?\"\n- \"Show me my recent ChatGPT conversations\"\n- \"Ask ChatGPT to explain quantum computing\"\n\n## Troubleshooting\n\nIf the tool isn't working properly:\n\n1. Make sure ChatGPT app is installed and you're logged in\n2. Verify the path to bun in your claude_desktop_config.json is correct\n3. Check that you've granted all necessary permissions\n4. Try restarting both Claude and ChatGPT apps\n\n## Optimizations\n\nThis fork includes several significant improvements to the original implementation:\n\n### Enhanced AppleScript Robustness\n\n#### Conversation Retrieval\n- Added multiple UI element targeting approaches to handle ChatGPT UI changes\n- Implemented better error detection with specific error messages\n- Added fallback mechanisms using accessibility attributes\n- Improved timeout handling with appropriate delays\n\n#### Response Handling\n- Replaced fixed waiting times with dynamic response detection\n- Added intelligent completion detection that recognizes when ChatGPT has finished typing\n- Implemented text stability detection (waits until text stops changing)\n- Added response extraction logic to isolate just the relevant response text\n- Improved error handling with detailed error messages\n- Added post-processing to clean up UI elements from responses\n- Implemented incomplete response detection to warn about potential cutoffs\n\nThese optimizations make the integration more reliable across different scenarios, more resilient to UI changes in the ChatGPT application, and better at handling longer response times without message cutoff issues.\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "chatgpt",
        "conversation",
        "interact",
        "interact chatgpt",
        "chatgpt mcp",
        "chatgpt desktop"
      ],
      "category": "virtual-assistants"
    },
    "hyy0612--chatbot": {
      "owner": "hyy0612",
      "name": "chatbot",
      "url": "https://github.com/hyy0612/chatbot",
      "imageUrl": "/freedevtools/mcp/pfp/hyy0612.webp",
      "description": "Provides a conversational AI interface for applications, enabling automated responses and interactive dialogue to enhance user engagement. It supports easy deployment of chat-based AI solutions for various use cases.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-07T09:52:24Z",
      "readme_content": "# chatbot",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "chatbot",
        "ai",
        "dialogue",
        "hyy0612 chatbot",
        "chatbot provides",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "imgompanda--AutoGPT123": {
      "owner": "imgompanda",
      "name": "AutoGPT123",
      "url": "https://github.com/imgompanda/AutoGPT123",
      "imageUrl": "/freedevtools/mcp/pfp/imgompanda.webp",
      "description": "AutoGPT enables users to build, test, and deploy AI agents, facilitating the automation of various tasks and the realization of innovative ideas in AI development.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2024-04-09T13:17:37Z",
      "readme_content": "# AutoGPT: build & use AI agents\n\n[](https://discord.gg/autogpt) &ensp;\n[![Twitter Follow](https://img.shields.io/twitter/follow/Auto_GPT?style=social)](https://twitter.com/Auto_GPT) &ensp;\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n**AutoGPT** is the vision of the power of AI accessible to everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters:\n\n- ğŸ—ï¸ **Building** - Lay the foundation for something amazing.\n- ğŸ§ª **Testing** - Fine-tune your agent to perfection.\n- ğŸ¤ **Delegating** - Let AI work for you, and have your ideas come to life.\n\nBe part of the revolution! **AutoGPT** is here to stay, at the forefront of AI innovation.\n\n**ğŸ“– [Documentation](https://docs.agpt.co)**\n&ensp;|&ensp;\n**ğŸš€ [Contributing](CONTRIBUTING.md)**\n&ensp;|&ensp;\n**ğŸ› ï¸ [Build your own Agent - Quickstart](QUICKSTART.md)**\n\n## ğŸ¥‡ Current Best Agent: evo.ninja\n[Current Best Agent]: #-current-best-agent-evoninja\n\nThe AutoGPT Arena Hackathon saw [**evo.ninja**](https://github.com/polywrap/evo.ninja) earn the top spot on our Arena Leaderboard, proving itself as the best open-source generalist agent. Try it now at https://evo.ninja!\n\nğŸ“ˆ To challenge evo.ninja, AutoGPT, and others, submit your benchmark run to the [Leaderboard](#-leaderboard), and maybe your agent will be up here next!\n\n## ğŸ§± Building blocks\n\n### ğŸ—ï¸ Forge\n\n**Forge your own agent!** &ndash; Forge is a ready-to-go template for your agent application. All the boilerplate code is already handled, letting you channel all your creativity into the things that set *your* agent apart. All tutorials are located [here](https://medium.com/@aiedge/autogpt-forge-e3de53cc58ec). Components from the [`forge.sdk`](/autogpts/forge/forge/sdk) can also be used individually to speed up development and reduce boilerplate in your agent project.\n\nğŸš€ [**Getting Started with Forge**](https://github.com/Significant-Gravitas/AutoGPT/blob/master/autogpts/forge/tutorials/001_getting_started.md) &ndash;\nThis guide will walk you through the process of creating your own agent and using the benchmark and user interface.\n\nğŸ“˜ [Learn More](https://github.com/Significant-Gravitas/AutoGPT/tree/master/autogpts/forge) about Forge\n\n### ğŸ¯ Benchmark\n\n**Measure your agent's performance!** The `agbenchmark` can be used with any agent that supports the agent protocol, and the integration with the project's [CLI] makes it even easier to use with AutoGPT and forge-based agents. The benchmark offers a stringent testing environment. Our framework allows for autonomous, objective performance evaluations, ensuring your agents are primed for real-world action.\n\n<!-- TODO: insert visual demonstrating the benchmark -->\n\nğŸ“¦ [`agbenchmark`](https://pypi.org/project/agbenchmark/) on Pypi\n&ensp;|&ensp;\nğŸ“˜ [Learn More](https://github.com/Significant-Gravitas/AutoGPT/blob/master/benchmark) about the Benchmark\n\n#### ğŸ† [Leaderboard][leaderboard]\n[leaderboard]: https://leaderboard.agpt.co\n\nSubmit your benchmark run through the UI and claim your place on the AutoGPT Arena Leaderboard! The best scoring general agent earns the title of **[Current Best Agent]**, and will be adopted into our repo so people can easily run it through the [CLI].\n\n[![Screenshot of the AutoGPT Arena leaderboard](https://github.com/Significant-Gravitas/AutoGPT/assets/12185583/60813392-9ddb-4cca-bb44-b477dbae225d)][leaderboard]\n\n### ğŸ’» UI\n\n**Makes agents easy to use!** The `frontend` gives you a user-friendly interface to control and monitor your agents. It connects to agents through the [agent protocol](#-agent-protocol), ensuring compatibility with many agents from both inside and outside of our ecosystem.\n\n<!-- TODO: instert screenshot of front end -->\n\nThe frontend works out-of-the-box with all agents in the repo. Just use the [CLI] to run your agent of choice!\n\nğŸ“˜ [Learn More](https://github.com/Significant-Gravitas/AutoGPT/tree/master/frontend) about the Frontend\n\n### âŒ¨ï¸ CLI\n\n[CLI]: #-cli\n\nTo make it as easy as possible to use all of the tools offered by the repository, a CLI is included at the root of the repo:\n\n```shell\n$ ./run\nUsage: cli.py [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  agent      Commands to create, start and stop agents\n  arena      Commands to enter the arena\n  benchmark  Commands to start the benchmark and list tests and categories\n  setup      Installs dependencies needed for your system.\n```\n\nJust clone the repo, install dependencies with `./run setup`, and you should be good to go!\n\n## ğŸ¤” Questions? Problems? Suggestions?\n\n### Get help - [Discord ğŸ’¬](https://discord.gg/autogpt)\n\n[![Join us on Discord](https://invidget.switchblade.xyz/autogpt)](https://discord.gg/autogpt)\n\nTo report a bug or request a feature, create a [GitHub Issue](https://github.com/Significant-Gravitas/AutoGPT/issues/new/choose). Please ensure someone else hasnâ€™t created an issue for the same topic.\n\n## ğŸ¤ Sister projects\n\n### ğŸ”„ Agent Protocol\n\nTo maintain a uniform standard and ensure seamless compatibility with many current and future applications, AutoGPT employs the [agent protocol](https://agentprotocol.ai/) standard by the AI Engineer Foundation. This standardizes the communication pathways from your agent to the frontend and benchmark.\n\n---\n\n<p align=\"center\">\n<a href=\"https://star-history.com/#Significant-Gravitas/AutoGPT\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=Significant-Gravitas/AutoGPT&type=Date&theme=dark\" />\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=Significant-Gravitas/AutoGPT&type=Date\" />\n    <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=Significant-Gravitas/AutoGPT&type=Date\" />\n  </picture>\n</a>\n</p>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "autogpt",
        "automation",
        "autogpt123",
        "virtual assistants",
        "imgompanda autogpt123",
        "ai agents"
      ],
      "category": "virtual-assistants"
    },
    "logos-42--ANPtest": {
      "owner": "logos-42",
      "name": "ANPtest",
      "url": "https://github.com/logos-42/ANPtest",
      "imageUrl": "/freedevtools/mcp/pfp/logos-42.webp",
      "description": "Connects to AI agents using self-compressed decentralized identifiers (DIDs). Facilitates interactive conversations with an AI assistant in a talk show style, featuring functionalities for DID generation and QR code display.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-04-01T07:36:48Z",
      "readme_content": "# è„±å£ç§€AIæ™ºèƒ½ä½“\r\n\r\nåŸºäºè‡ªå‹ç¼©DIDæŠ€æœ¯ï¼Œä½¿ç”¨ç¡…åŸºæµåŠ¨APIå®ç°çš„è„±å£ç§€AIåŠ©æ‰‹ã€‚\r\n\r\n## é¡¹ç›®ç‰¹ç‚¹\r\n\r\n- å®ç°è‡ªå‹ç¼©DIDï¼Œæ— éœ€é¢å¤–æŸ¥è¯¢å³å¯è¿æ¥æ™ºèƒ½ä½“\r\n- ä½¿ç”¨ç¡…åŸºæµåŠ¨çš„DeepSeek-R1-Distill-Qwen-32Bå¤§æ¨¡å‹\r\n- æä¾›ç”ŸæˆDIDã€äºŒç»´ç å±•ç¤ºå’ŒèŠå¤©åŠŸèƒ½\r\n- æ”¯æŒæ™ºèƒ½ä½“é—´çš„é€šä¿¡ä¸è¿æ¥\r\n\r\n## æŠ€æœ¯æ ˆ\r\n\r\n- Next.js: Reactæ¡†æ¶\r\n- è‡ªå‹ç¼©DID: å»ä¸­å¿ƒåŒ–èº«ä»½è¯†åˆ«\r\n- ç¡…åŸºæµåŠ¨API: AIå¤§æ¨¡å‹æœåŠ¡\r\n- Vercel: éƒ¨ç½²æœåŠ¡\r\n\r\n## å¿«é€Ÿå¼€å§‹\r\n\r\n### æœ¬åœ°å¼€å‘\r\n\r\n1. å…‹éš†é¡¹ç›®å¹¶å®‰è£…ä¾èµ–:\r\n\r\n```bash\r\ngit clone <repository-url>\r\ncd comedyagent\r\nnpm install\r\n```\r\n\r\n2. é…ç½®APIå¯†é’¥:\r\n\r\nå¦‚éœ€ä½¿ç”¨ä¸åŒçš„APIå¯†é’¥ï¼Œè¯·ä¿®æ”¹`lib/ai.js`æ–‡ä»¶ä¸­çš„`API_KEY`å˜é‡ã€‚\r\n\r\n3. å¯åŠ¨å¼€å‘æœåŠ¡å™¨:\r\n\r\n```bash\r\nnpm run dev\r\n```\r\n\r\n4. è®¿é—® http://localhost:3000 æŸ¥çœ‹åº”ç”¨ã€‚\r\n\r\n### Verceléƒ¨ç½²\r\n\r\n1. Forkæ­¤ä»“åº“åˆ°æ‚¨çš„GitHubè´¦æˆ·ã€‚\r\n\r\n2. åœ¨Vercelä¸Šåˆ›å»ºæ–°é¡¹ç›®ï¼Œå¹¶è¿æ¥æ‚¨çš„GitHubä»“åº“ã€‚\r\n\r\n3. éƒ¨ç½²å®Œæˆåï¼Œå³å¯é€šè¿‡Vercelæä¾›çš„URLè®¿é—®åº”ç”¨ã€‚\r\n\r\n## ä½¿ç”¨è¯´æ˜\r\n\r\n### ç”ŸæˆDID\r\n\r\n1. åœ¨é¦–é¡µç‚¹å‡»\"ç”ŸæˆDID\"æŒ‰é’®ã€‚\r\n2. ç³»ç»Ÿä¼šç”Ÿæˆä¸€ä¸ªè‡ªåŒ…å«DIDï¼Œå¹¶ä»¥æ–‡æœ¬å’ŒäºŒç»´ç å½¢å¼æ˜¾ç¤ºã€‚\r\n3. æ‚¨å¯ä»¥å¤åˆ¶DIDæˆ–åˆ†äº«äºŒç»´ç ã€‚\r\n\r\n### æµ‹è¯•æ™ºèƒ½ä½“\r\n\r\n1. åœ¨é¦–é¡µçš„èŠå¤©æ¡†ä¸­è¾“å…¥æ¶ˆæ¯ã€‚\r\n2. ç‚¹å‡»\"å‘é€\"æŒ‰é’®æˆ–æŒ‰Enteré”®ã€‚\r\n3. æ™ºèƒ½ä½“ä¼šä»¥è„±å£ç§€æ¼”å‘˜çš„é£æ ¼å›å¤æ‚¨çš„æ¶ˆæ¯ã€‚\r\n\r\n### è¿æ¥å…¶ä»–æ™ºèƒ½ä½“\r\n\r\n1. å‰å¾€\"/connect\"é¡µé¢ã€‚\r\n2. è¾“å…¥å…¶ä»–æ™ºèƒ½ä½“çš„DIDã€‚\r\n3. ç‚¹å‡»\"è¿æ¥\"æŒ‰é’®ã€‚\r\n4. è¿æ¥æˆåŠŸåï¼Œæ‚¨å¯ä»¥å‘è¯¥æ™ºèƒ½ä½“å‘é€æ¶ˆæ¯ã€‚\r\n\r\næ‚¨è¿˜å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è¿æ¥æ™ºèƒ½ä½“:\r\n\r\n- åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€`{æ‚¨çš„åŸŸå}/connect?did={DIDå­—ç¬¦ä¸²}`\r\n- æˆ–è€…åˆ›å»ºä¸€ä¸ª`did://`åè®®é“¾æ¥: `did://{DIDå­—ç¬¦ä¸²}`\r\n\r\n## é¡¹ç›®ç»“æ„\r\n\r\n```\r\ncomedyagent/\r\nâ”œâ”€â”€ api/                  # APIè·¯ç”±\r\nâ”‚   â”œâ”€â”€ generate-did.js   # DIDç”ŸæˆAPI\r\nâ”‚   â””â”€â”€ message.js        # æ¶ˆæ¯å¤„ç†API\r\nâ”œâ”€â”€ components/           # Reactç»„ä»¶\r\nâ”œâ”€â”€ lib/                  # å·¥å…·åº“\r\nâ”‚   â”œâ”€â”€ ai.js             # AIæœåŠ¡\r\nâ”‚   â””â”€â”€ did.js            # DIDåŠŸèƒ½\r\nâ”œâ”€â”€ pages/                # é¡µé¢\r\nâ”‚   â”œâ”€â”€ index.js          # é¦–é¡µ\r\nâ”‚   â””â”€â”€ connect.js        # è¿æ¥é¡µé¢\r\nâ”œâ”€â”€ public/               # é™æ€èµ„æº\r\nâ”œâ”€â”€ styles/               # æ ·å¼æ–‡ä»¶\r\nâ”‚   â”œâ”€â”€ Home.module.css   # é¦–é¡µæ ·å¼\r\nâ”‚   â””â”€â”€ Connect.module.css# è¿æ¥é¡µé¢æ ·å¼\r\nâ”œâ”€â”€ package.json          # é¡¹ç›®é…ç½®\r\nâ””â”€â”€ vercel.json           # Vercelé…ç½®\r\n```\r\n\r\n## è‡ªå‹ç¼©DIDè¯¦è§£\r\n\r\næœ¬é¡¹ç›®ä¸­çš„è‡ªå‹ç¼©DIDæ˜¯ä¸€ç§åˆ›æ–°çš„æ•°å­—èº«ä»½è¡¨ç¤ºæ–¹å¼ï¼ŒåŒ…å«äº†ä»¥ä¸‹ä¿¡æ¯:\r\n\r\n- èº«ä»½æ ‡è¯†\r\n- å…¬é’¥\r\n- æœåŠ¡ç«¯ç‚¹\r\n- å…ƒæ•°æ®\r\n- æ•°å­—ç­¾å\r\n\r\nä¸ä¼ ç»ŸDIDä¸åŒï¼Œè‡ªå‹ç¼©DIDå°†æ‰€æœ‰å¿…è¦ä¿¡æ¯ç¼–ç åœ¨ä¸€ä¸ªå­—ç¬¦ä¸²ä¸­ï¼Œæ— éœ€æŸ¥è¯¢é¢å¤–æœåŠ¡å™¨å³å¯è·å–èº«ä»½ä¿¡æ¯å’Œé€šä¿¡æ–¹å¼ã€‚\r\n\r\n## è®¸å¯è¯\r\n\r\nMIT ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "agents",
        "assistant",
        "ai assistant",
        "ai agents",
        "connects ai"
      ],
      "category": "virtual-assistants"
    },
    "mrexodia--user-feedback-mcp": {
      "owner": "mrexodia",
      "name": "user-feedback-mcp",
      "url": "https://github.com/mrexodia/user-feedback-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/mrexodia.webp",
      "description": "Facilitates a feedback loop in tools for desktop application development by collecting user insights during complex interactions. Enhances testing processes by prompting users for feedback before task completion.",
      "stars": 47,
      "forks": 8,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-04T14:06:32Z",
      "readme_content": "# User Feedback MCP\r\n\r\nSimple [MCP Server](https://modelcontextprotocol.io/introduction) to enable a human-in-the-loop workflow in tools like [Cline](https://cline.bot) and [Cursor](https://www.cursor.com). This is especially useful for developing desktop applications that require complex user interactions to test.\r\n\r\n![Screenshot showing the feedback UI](https://github.com/mrexodia/user-feedback-mcp/blob/main/.github/feedback-ui.png?raw=true)\r\n\r\n## Prompt Engineering\r\n\r\nFor the best results, add the following to your custom prompt:\r\n\r\n> Before completing the task, use the user_feedback MCP tool to ask the user for feedback.\r\n\r\nThis will ensure Cline uses this MCP server to request user feedback before marking the task as completed.\r\n\r\n## `.user-feedback.json`\r\n\r\nHitting _Save Configuration_ creates a `.user-feedback.json` file in your project directory that looks like this:\r\n\r\n```json\r\n{\r\n  \"command\": \"npm run dev\",\r\n  \"execute_automatically\": false\r\n}\r\n```\r\n\r\nThis configuration will be loaded on startup and if `execute_automatically` is enabled your `command` will be instantly executed (you will not have to click _Run_ manually). For multi-step commands you should use something like [Task](https://taskfile.dev).\r\n\r\n## Installation (Cline)\r\n\r\nTo install the MCP server in Cline, follow these steps (see screenshot):\r\n\r\n![Screenshot showing installation steps](https://github.com/mrexodia/user-feedback-mcp/blob/main/.github/cline-installation.png?raw=true)\r\n\r\n1. Install [uv](https://github.com/astral-sh/uv) globally:\r\n   - Windows: `pip install uv`\r\n   - Linux/Mac: `curl -LsSf https://astral.sh/uv/install.sh | sh`\r\n2. Clone this repository, for this example `C:\\MCP\\user-feedback-mcp`.\r\n3. Navigate to the Cline _MCP Servers_ configuration (see screenshot).\r\n4. Click on the _Installed_ tab.\r\n5. Click on _Configure MCP Servers_, which will open `cline_mcp_settings.json`.\r\n6. Add the `user-feedback-mcp` server:\r\n\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"github.com/mrexodia/user-feedback-mcp\": {\r\n      \"command\": \"uv\",\r\n      \"args\": [\r\n        \"--directory\",\r\n        \"c:\\\\MCP\\\\user-feedback-mcp\",\r\n        \"run\",\r\n        \"server.py\"\r\n      ],\r\n      \"timeout\": 600,\r\n      \"autoApprove\": [\r\n        \"user_feedback\"\r\n      ]\r\n    }\r\n  }\r\n}\r\n\r\n```\r\n\r\n## Development\r\n\r\n```sh\r\nuv run fastmcp dev server.py\r\n```\r\n\r\nThis will open a web interface at http://localhost:5173 and allow you to interact with the MCP tools for testing.\r\n\r\n## Available tools\r\n\r\n```\r\n<use_mcp_tool>\r\n<server_name>github.com/mrexodia/user-feedback-mcp</server_name>\r\n<tool_name>user_feedback</tool_name>\r\n<arguments>\r\n{\r\n  \"project_directory\": \"C:/MCP/user-feedback-mcp\",\r\n  \"summary\": \"I've implemented the changes you requested.\"\r\n}\r\n</arguments>\r\n</use_mcp_tool>\r\n```",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mrexodia",
        "feedback",
        "assistants",
        "virtual assistants",
        "assistants mrexodia",
        "facilitates feedback"
      ],
      "category": "virtual-assistants"
    },
    "mrgeeko--vapi-mcp": {
      "owner": "mrgeeko",
      "name": "vapi-mcp",
      "url": "https://github.com/mrgeeko/vapi-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/mrgeeko.webp",
      "description": "Integrate voice AI capabilities into applications for managing voice assistants and conducting outbound calls. Provides advanced features for enhancing user interactions through voice conversations.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2025-04-07T08:10:10Z",
      "readme_content": "# Vapi MCP for Cursor\n\nThis project implements a Model Context Protocol (MCP) server for integrating Vapi's voice AI capabilities with Cursor.\n\n## Setup Instructions\n\n### 1. Project Structure\n\nThe Vapi MCP server is structured as follows:\n- `vapi-mcp-server/` - Main server code\n  - `src/` - TypeScript source files\n  - `dist/` - Compiled JavaScript output\n  - `.env` - Environment variables for API keys\n\n### 2. Environment Configuration\n\nCreate a `.env` file in the `vapi-mcp-server` directory with the following variables:\n\n```\n# Vapi API Keys\nVAPI_ORG_ID=your-org-id\nVAPI_PRIVATE_KEY=your-private-key\nVAPI_KNOWLEDGE_ID=your-knowledge-id\nVAPI_JWT_PRIVATE=your-jwt-private\n\n# Environment\nNODE_ENV=development\n```\n\n### 3. Building the Server\n\nTo build the server:\n\n```bash\ncd vapi-mcp/vapi-mcp-server\nnpm install\nnpm run build\n```\n\n### 4. Configuration in Cursor\n\n#### Important: Avoiding \"Client Closed\" Errors\n\nWhen configuring the Vapi MCP server in Cursor's MCP settings, pay attention to the following crucial details:\n\n1. **Working Directory**: The `cwd` parameter is required to ensure the server runs in the correct directory and can access the `.env` file properly.\n\n2. **Environment Variables**: Must be explicitly provided in the configuration, even if they exist in the `.env` file.\n\n3. **Module Type**: The server uses ES modules, so the `package.json` must include `\"type\": \"module\"`.\n\nHere's the correct configuration for `.cursor/mcp.json`:\n\n```json\n\"Vapi Voice AI Tools\": {\n  \"command\": \"node\",\n  \"type\": \"stdio\",\n  \"args\": [\n    \"/Users/matthewcage/Documents/AA-GitHub/MCP/vapi-mcp/vapi-mcp-server/dist/index.js\"\n  ],\n  \"cwd\": \"/Users/matthewcage/Documents/AA-GitHub/MCP/vapi-mcp/vapi-mcp-server\",\n  \"env\": {\n    \"VAPI_ORG_ID\": \"your-org-id\",\n    \"VAPI_PRIVATE_KEY\": \"your-private-key\",\n    \"VAPI_KNOWLEDGE_ID\": \"your-knowledge-id\",\n    \"VAPI_JWT_PRIVATE\": \"your-jwt-private\",\n    \"NODE_ENV\": \"development\"\n  }\n}\n```\n\n## Troubleshooting\n\n### \"Client Closed\" Error in Cursor\n\nIf you see \"Client Closed\" in the Cursor MCP Tools panel:\n\n1. **Check Working Directory**: Ensure the `cwd` parameter is set correctly in your mcp.json\n2. **Verify Environment Variables**: Make sure all required environment variables are passed in the configuration\n3. **Check Module Type**: Ensure `package.json` has `\"type\": \"module\"`\n4. **Inspect Permissions**: Make sure the dist/index.js file is executable (`chmod +x dist/index.js`)\n5. **Test Server Directly**: Run the server manually to check for errors:\n   ```bash\n   cd vapi-mcp/vapi-mcp-server\n   node --trace-warnings dist/index.js\n   ```\n\n### Module Not Found Errors\n\nIf you get \"Error: Cannot find module\" when running:\n\n1. **Check Working Directory**: Are you running from the correct directory?\n2. **Rebuild**: Try rebuilding the project with `npm run build`\n3. **Dependencies**: Ensure all dependencies are installed with `npm install`\n\n## Available Tools\n\nThe Vapi MCP server provides the following tools:\n\n1. **vapi_call** - Make outbound calls using Vapi's voice AI\n2. **vapi_assistant** - Manage voice assistants (create, get, list, update, delete)\n3. **vapi_conversation** - Retrieve conversation details from calls\n\n## Lessons Learned\n\n1. When integrating with Cursor's MCP:\n   - Always specify the `cwd` parameter to ensure the server runs in the correct directory\n   - Pass all required environment variables directly in the MCP configuration\n   - For ES modules, ensure package.json has `\"type\": \"module\"` and tsconfig.json uses appropriate module settings\n   - Test the server directly before configuring in Cursor\n\n2. The server command path must be absolute and correctly formed in the Cursor MCP config\n\n3. Using stdio transport type is required for proper integration with Cursor ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "voice",
        "vapi",
        "assistants",
        "voice assistants",
        "voice ai",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "popcornspace--voice-call-mcp-server": {
      "owner": "popcornspace",
      "name": "voice-call-mcp-server",
      "url": "https://github.com/popcornspace/voice-call-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/popcornspace.webp",
      "description": "Facilitates voice call management through Twilio and OpenAI, enabling real-time audio processing for interactive conversations with AI assistants. Offers pre-built prompts for common scenarios to streamline call initiation and handling.",
      "stars": 49,
      "forks": 9,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-18T23:39:26Z",
      "readme_content": "# Voice Call MCP Server\n\nA Model Context Protocol (MCP) server that enables Claude and other AI assistants to initiate and manage voice calls using Twilio and OpenAI (GPT-4o Realtime model).\n\nUse this as a base to kick-start your AI-powered voice calling explorations, save time and develop additional functionality on top of it.\n\n\n\n\n## Sequence Diagram\n\n```mermaid\nsequenceDiagram\n    participant AI as AI Assistant (e.g., Claude)\n    participant MCP as MCP Server\n    participant Twilio as Twilio\n    participant Phone as Destination Phone\n    participant OpenAI as OpenAI\n    \n    AI->>MCP: 1) Initiate outbound call request <br>(POST /calls)\n    MCP->>Twilio: 2) Place outbound call via Twilio API\n    Twilio->>Phone: 3) Ring the destination phone\n    Twilio->>MCP: 4) Call status updates & audio callbacks (webhooks)\n    MCP->>OpenAI: 5) Forward real-time audio to OpenaAI's realtime model\n    OpenAI->>MCP: 6) Return voice stream\n    MCP->>Twilio: 7) Send voice stream\n    Twilio->>Phone: 8) Forward voice stream\n    Note over Phone: Two-way conversation continues <br>until the call ends\n```\n\n\n## Features\n\n- Make outbound phone calls via Twilio ğŸ“\n- Process call audio in real-time with GPT-4o Realtime model ğŸ™ï¸\n- Real-time language switching during calls ğŸŒ\n- Pre-built prompts for common calling scenarios (like restaurant reservations) ğŸ½ï¸\n- Automatic public URL tunneling with ngrok ğŸ”„\n- Secure handling of credentials ğŸ”’\n\n## Why MCP?\n\nThe Model Context Protocol (MCP) bridges the gap between AI assistants and real-world actions. By implementing MCP, this server allows AI models like Claude to:\n\n1. Initiate actual phone calls on behalf of users\n2. Process and respond to real-time audio conversations\n3. Execute complex tasks requiring voice communication\n\nThis open-source implementation provides transparency and customizability, allowing developers to extend functionality while maintaining control over their data and privacy.\n\n## Requirements\n\n- Node.js >= 22\n  - If you need to update Node.js, we recommend using `nvm` (Node Version Manager):\n    ```bash\n    nvm install 22\n    nvm use 22\n    ```\n- Twilio account with API credentials\n- OpenAI API key\n- Ngrok Authtoken\n\n## Installation\n\n### Manual Installation\n\n1. Clone the repository\n   ```bash\n   git clone https://github.com/lukaskai/voice-call-mcp-server.git\n   cd voice-call-mcp-server\n   ```\n\n2. Install dependencies and build\n   ```bash\n   npm install\n   npm run build\n   ```\n\n## Configuration\n\nThe server requires several environment variables:\n\n- `TWILIO_ACCOUNT_SID`: Your Twilio account SID\n- `TWILIO_AUTH_TOKEN`: Your Twilio auth token\n- `TWILIO_NUMBER`: Your Twilio number\n- `OPENAI_API_KEY`: Your OpenAI API key\n- `NGROK_AUTHTOKEN`: Your ngrok authtoken\n- `RECORD_CALLS`: Set to \"true\" to record calls (optional)\n\n### Claude Desktop Configuration\n\nTo use this server with Claude Desktop, add the following to your configuration file:\n\n**macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n\n**Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"voice-call\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/your/mcp-new/dist/start-all.cjs\"],\n      \"env\": {\n        \"TWILIO_ACCOUNT_SID\": \"your_account_sid\",\n        \"TWILIO_AUTH_TOKEN\": \"your_auth_token\",\n        \"TWILIO_NUMBER\": \"your_e.164_format_number\",\n        \"OPENAI_API_KEY\": \"your_openai_api_key\",\n        \"NGROK_AUTHTOKEN\": \"your_ngrok_authtoken\"\n      }\n    }\n  }\n}\n```\n\nAfter that, restart Claude Desktop to reload the configuration. \nIf connected, you should see Voice Call under the ğŸ”¨ menu.\n\n## Example Interactions with Claude\n\nHere are some natural ways to interact with the server through Claude:\n\n1. Simple call:\n```\nCan you call +1-123-456-7890 and let them know I'll be 15 minutes late for our meeting?\n```\n\n2. Restaurant reservation:\n```\nPlease call Delicious Restaurant at +1-123-456-7890 and make a reservation for 4 people tonight at 7:30 PM. Please speak in German.\n```\n\n3. Appointment scheduling:\n```\nPlease call Expert Dental NYC (+1-123-456-7899) and reschedule my Monday appointment to next Friday between 4â€“6pm.\n```\n\n## Important Notes\n\n1. **Phone Number Format**: All phone numbers must be in E.164 format (e.g., +11234567890)\n2. **Rate Limits**: Be aware of your Twilio and OpenAI account's rate limits and pricing\n3. **Voice Conversations**: The AI will handle natural conversations in real-time\n4. **Call Duration**: Be mindful of call durations as they affect OpenAI API and Twilio costs\n5. **Public Exposure**: Be aware that the ngrok tunnel exposes your server publicly for Twilio to reach it (though with a random URL and protected by a random secret)\n\n## Troubleshooting\n\nCommon error messages and solutions:\n\n1. \"Phone number must be in E.164 format\"\n   - Make sure the phone number starts with \"+\" and the country code\n\n2. \"Invalid credentials\"\n   - Double-check your TWILIO_ACCOUNT_SID and TWILIO_AUTH_TOKEN. You can copy them from the [Twilio Console](https://console.twilio.com)\n\n3. \"OpenAI API error\"\n   - Verify your OPENAI_API_KEY is correct and has sufficient credits\n\n4. \"Ngrok tunnel failed to start\"\n   - Ensure your NGROK_AUTHTOKEN is valid and not expired\n\n5. \"OpenAI Realtime does not detect the end of voice input, or is lagging.\"\n   - Sometimes, there might be voice encoding issues between Twilio and the receiver's network operator. Try using a different receiver.\n\n## Contributing\n\nContributions are welcome! Here are some areas we're looking to improve:\n\n- Implement support for multiple AI models beyond the current implementation\n- Add database integration to store conversation history locally and make it accessible for AI context\n- Improve latency and response times to enhance call experiences\n- Enhance error handling and recovery mechanisms\n- Add more pre-built conversation templates for common scenarios\n- Implement improved call monitoring and analytics\n\nIf you'd like to contribute, please open an issue to discuss your ideas before submitting a pull request.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Security\n\nPlease do not include any sensitive information (like phone numbers or API credentials) in GitHub issues or pull requests. This server handles sensitive communications; deploy it responsibly and ensure all credentials are kept secure.\n\n\n## Time For a New Mission?\n\nWeâ€™re hiring engineers to build at the frontier of voice AI â€” and bake it into a next-gen telco.\n\nCurious? Head to [careers.popcorn.space](https://careers.popcorn.space/apply) ğŸ¿Â !",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "twilio",
        "voice",
        "audio",
        "virtual assistants",
        "voice mcp",
        "twilio openai"
      ],
      "category": "virtual-assistants"
    },
    "rsagacom--chatgpt-on-wechat": {
      "owner": "rsagacom",
      "name": "chatgpt-on-wechat",
      "url": "https://github.com/rsagacom/chatgpt-on-wechat",
      "imageUrl": "/freedevtools/mcp/pfp/rsagacom.webp",
      "description": "A multi-platform intelligent dialogue service that supports text, voice, and image interactions. It can connect to various AI models and allows for custom enterprise AI applications through plugin extensions.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2024-01-28T14:00:49Z",
      "readme_content": "# ç®€ä»‹\n\n> æœ¬é¡¹ç›®æ˜¯åŸºäºå¤§æ¨¡å‹çš„æ™ºèƒ½å¯¹è¯æœºå™¨äººï¼Œæ”¯æŒå¾®ä¿¡ã€ä¼ä¸šå¾®ä¿¡ã€å…¬ä¼—å·ã€é£ä¹¦ã€é’‰é’‰æ¥å…¥ï¼Œå¯é€‰æ‹©GPT3.5/GPT4.0/Claude/æ–‡å¿ƒä¸€è¨€/è®¯é£æ˜Ÿç«/é€šä¹‰åƒé—®/Gemini/LinkAIï¼Œèƒ½å¤„ç†æ–‡æœ¬ã€è¯­éŸ³å’Œå›¾ç‰‡ï¼Œé€šè¿‡æ’ä»¶è®¿é—®æ“ä½œç³»ç»Ÿå’Œäº’è”ç½‘ç­‰å¤–éƒ¨èµ„æºï¼Œæ”¯æŒåŸºäºè‡ªæœ‰çŸ¥è¯†åº“å®šåˆ¶ä¼ä¸šAIåº”ç”¨ã€‚\n\næœ€æ–°ç‰ˆæœ¬æ”¯æŒçš„åŠŸèƒ½å¦‚ä¸‹ï¼š\n\n- [x] **å¤šç«¯éƒ¨ç½²ï¼š** æœ‰å¤šç§éƒ¨ç½²æ–¹å¼å¯é€‰æ‹©ä¸”åŠŸèƒ½å®Œå¤‡ï¼Œç›®å‰å·²æ”¯æŒä¸ªäººå¾®ä¿¡ã€å¾®ä¿¡å…¬ä¼—å·å’Œã€ä¼ä¸šå¾®ä¿¡ã€é£ä¹¦ã€é’‰é’‰ç­‰éƒ¨ç½²æ–¹å¼\n- [x] **åŸºç¡€å¯¹è¯ï¼š** ç§èŠåŠç¾¤èŠçš„æ¶ˆæ¯æ™ºèƒ½å›å¤ï¼Œæ”¯æŒå¤šè½®ä¼šè¯ä¸Šä¸‹æ–‡è®°å¿†ï¼Œæ”¯æŒ GPT-3.5, GPT-4, claude, Gemini, æ–‡å¿ƒä¸€è¨€, è®¯é£æ˜Ÿç«, é€šä¹‰åƒé—®\n- [x] **è¯­éŸ³èƒ½åŠ›ï¼š** å¯è¯†åˆ«è¯­éŸ³æ¶ˆæ¯ï¼Œé€šè¿‡æ–‡å­—æˆ–è¯­éŸ³å›å¤ï¼Œæ”¯æŒ azure, baidu, google, openai(whisper/tts) ç­‰å¤šç§è¯­éŸ³æ¨¡å‹\n- [x] **å›¾åƒèƒ½åŠ›ï¼š** æ”¯æŒå›¾ç‰‡ç”Ÿæˆã€å›¾ç‰‡è¯†åˆ«ã€å›¾ç”Ÿå›¾ï¼ˆå¦‚ç…§ç‰‡ä¿®å¤ï¼‰ï¼Œå¯é€‰æ‹© Dall-E-3, stable diffusion, replicate, midjourney, visionæ¨¡å‹\n- [x] **ä¸°å¯Œæ’ä»¶ï¼š** æ”¯æŒä¸ªæ€§åŒ–æ’ä»¶æ‰©å±•ï¼Œå·²å®ç°å¤šè§’è‰²åˆ‡æ¢ã€æ–‡å­—å†’é™©ã€æ•æ„Ÿè¯è¿‡æ»¤ã€èŠå¤©è®°å½•æ€»ç»“ã€æ–‡æ¡£æ€»ç»“å’Œå¯¹è¯ã€è”ç½‘æœç´¢ç­‰æ’ä»¶\n- [x] **çŸ¥è¯†åº“ï¼š** é€šè¿‡ä¸Šä¼ çŸ¥è¯†åº“æ–‡ä»¶è‡ªå®šä¹‰ä¸“å±æœºå™¨äººï¼Œå¯ä½œä¸ºæ•°å­—åˆ†èº«ã€æ™ºèƒ½å®¢æœã€ç§åŸŸåŠ©æ‰‹ä½¿ç”¨ï¼ŒåŸºäº [LinkAI](https://link-ai.tech) å®ç°\n\n# æ¼”ç¤º\n\nhttps://github.com/zhayujie/chatgpt-on-wechat/assets/26161723/d5154020-36e3-41db-8706-40ce9f3f1b1e\n\nDemo made by [Visionn](https://www.wangpc.cc/)\n\n# å•†ä¸šæ”¯æŒ\n\n> æˆ‘ä»¬è¿˜æä¾›ä¼ä¸šçº§çš„ **AIåº”ç”¨å¹³å°**ï¼ŒåŒ…å«çŸ¥è¯†åº“ã€Agentæ’ä»¶ã€åº”ç”¨ç®¡ç†ç­‰èƒ½åŠ›ï¼Œæ”¯æŒå¤šå¹³å°èšåˆçš„åº”ç”¨æ¥å…¥ã€å®¢æˆ·ç«¯ç®¡ç†ã€å¯¹è¯ç®¡ç†ï¼Œä»¥åŠæä¾›\nSaaSæœåŠ¡ã€ç§æœ‰åŒ–éƒ¨ç½²ã€ç¨³å®šæ‰˜ç®¡æ¥å…¥ ç­‰å¤šç§æ¨¡å¼ã€‚\n>\n> ç›®å‰å·²åœ¨ç§åŸŸè¿è¥ã€æ™ºèƒ½å®¢æœã€ä¼ä¸šæ•ˆç‡åŠ©æ‰‹ç­‰åœºæ™¯ç§¯ç´¯äº†ä¸°å¯Œçš„ AI è§£å†³æ–¹æ¡ˆï¼Œ åœ¨ç”µå•†ã€æ–‡æ•™ã€å¥åº·ã€æ–°æ¶ˆè´¹ç­‰å„è¡Œä¸šæ²‰æ·€äº† AI è½åœ°çš„æœ€ä½³å®è·µï¼Œè‡´åŠ›äºæ‰“é€ åŠ©åŠ›ä¸­å°ä¼ä¸šæ‹¥æŠ± AI çš„ä¸€ç«™å¼å¹³å°ã€‚\n\nä¼ä¸šæœåŠ¡å’Œå•†ç”¨å’¨è¯¢å¯è”ç³»äº§å“é¡¾é—®ï¼š\n\n<img alt=\"product_manager_qrcode\" width=\"240\" src=\"https://img-1317903499.cos.ap-guangzhou.myqcloud.com/docs/product-manager-qrcode.jpg\">\n\n# å¼€æºç¤¾åŒº\n\næ·»åŠ å°åŠ©æ‰‹å¾®ä¿¡åŠ å…¥å¼€æºé¡¹ç›®äº¤æµç¾¤ï¼š\n\n\n\n# æ›´æ–°æ—¥å¿—\n\n>**2023.11.11ï¼š** [1.5.3ç‰ˆæœ¬](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.3) å’Œ [1.5.4ç‰ˆæœ¬](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.4)ï¼Œæ–°å¢Google Geminiã€é€šä¹‰åƒé—®æ¨¡å‹\n\n>**2023.11.10ï¼š** [1.5.2ç‰ˆæœ¬](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.2)ï¼Œæ–°å¢é£ä¹¦é€šé“ã€å›¾åƒè¯†åˆ«å¯¹è¯ã€é»‘åå•é…ç½®\n\n>**2023.11.10ï¼š** [1.5.0ç‰ˆæœ¬](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.0)ï¼Œæ–°å¢ `gpt-4-turbo`, `dall-e-3`, `tts` æ¨¡å‹æ¥å…¥ï¼Œå®Œå–„å›¾åƒç†è§£&ç”Ÿæˆã€è¯­éŸ³è¯†åˆ«&ç”Ÿæˆçš„å¤šæ¨¡æ€èƒ½åŠ›\n\n>**2023.10.16ï¼š** æ”¯æŒé€šè¿‡æ„å›¾è¯†åˆ«ä½¿ç”¨LinkAIè”ç½‘æœç´¢ã€æ•°å­¦è®¡ç®—ã€ç½‘é¡µè®¿é—®ç­‰æ’ä»¶ï¼Œå‚è€ƒ[æ’ä»¶æ–‡æ¡£](https://docs.link-ai.tech/platform/plugins)\n\n>**2023.09.26ï¼š** æ’ä»¶å¢åŠ  æ–‡ä»¶/æ–‡ç« é“¾æ¥ ä¸€é”®æ€»ç»“å’Œå¯¹è¯çš„åŠŸèƒ½ï¼Œä½¿ç”¨å‚è€ƒï¼š[æ’ä»¶è¯´æ˜](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins/linkai#3%E6%96%87%E6%A1%A3%E6%80%BB%E7%BB%93%E5%AF%B9%E8%AF%9D%E5%8A%9F%E8%83%BD)\n\n>**2023.08.08ï¼š** æ¥å…¥ç™¾åº¦æ–‡å¿ƒä¸€è¨€æ¨¡å‹ï¼Œé€šè¿‡ [æ’ä»¶](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins/linkai) æ”¯æŒ Midjourney ç»˜å›¾\n\n>**2023.06.12ï¼š** æ¥å…¥ [LinkAI](https://link-ai.tech/console) å¹³å°ï¼Œå¯åœ¨çº¿åˆ›å»ºé¢†åŸŸçŸ¥è¯†åº“ï¼Œå¹¶æ¥å…¥å¾®ä¿¡ã€å…¬ä¼—å·åŠä¼ä¸šå¾®ä¿¡ä¸­ï¼Œæ‰“é€ ä¸“å±å®¢æœæœºå™¨äººã€‚ä½¿ç”¨å‚è€ƒ [æ¥å…¥æ–‡æ¡£](https://link-ai.tech/platform/link-app/wechat)ã€‚\n\n>**2023.04.26ï¼š** æ”¯æŒä¼ä¸šå¾®ä¿¡åº”ç”¨å·éƒ¨ç½²ï¼Œå…¼å®¹æ’ä»¶ï¼Œå¹¶æ”¯æŒè¯­éŸ³å›¾ç‰‡äº¤äº’ï¼Œç§äººåŠ©ç†ç†æƒ³é€‰æ‹©ï¼Œ[ä½¿ç”¨æ–‡æ¡£](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/wechatcom/README.md)ã€‚(contributed by [@lanvent](https://github.com/lanvent) in [#944](https://github.com/zhayujie/chatgpt-on-wechat/pull/944))\n\n>**2023.04.05ï¼š** æ”¯æŒå¾®ä¿¡å…¬ä¼—å·éƒ¨ç½²ï¼Œå…¼å®¹æ’ä»¶ï¼Œå¹¶æ”¯æŒè¯­éŸ³å›¾ç‰‡äº¤äº’ï¼Œ[ä½¿ç”¨æ–‡æ¡£](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/wechatmp/README.md)ã€‚(contributed by [@JS00000](https://github.com/JS00000) in [#686](https://github.com/zhayujie/chatgpt-on-wechat/pull/686))\n\n>**2023.04.05ï¼š** å¢åŠ èƒ½è®©ChatGPTä½¿ç”¨å·¥å…·çš„`tool`æ’ä»¶ï¼Œ[ä½¿ç”¨æ–‡æ¡£](https://github.com/goldfishh/chatgpt-on-wechat/blob/master/plugins/tool/README.md)ã€‚å·¥å…·ç›¸å…³issueå¯åé¦ˆè‡³[chatgpt-tool-hub](https://github.com/goldfishh/chatgpt-tool-hub)ã€‚(contributed by [@goldfishh](https://github.com/goldfishh) in [#663](https://github.com/zhayujie/chatgpt-on-wechat/pull/663))\n\n>**2023.03.25ï¼š** æ”¯æŒæ’ä»¶åŒ–å¼€å‘ï¼Œç›®å‰å·²å®ç° å¤šè§’è‰²åˆ‡æ¢ã€æ–‡å­—å†’é™©æ¸¸æˆã€ç®¡ç†å‘˜æŒ‡ä»¤ã€Stable Diffusionç­‰æ’ä»¶ï¼Œä½¿ç”¨å‚è€ƒ [#578](https://github.com/zhayujie/chatgpt-on-wechat/issues/578)ã€‚(contributed by [@lanvent](https://github.com/lanvent) in [#565](https://github.com/zhayujie/chatgpt-on-wechat/pull/565))\n\n>**2023.03.09ï¼š** åŸºäº `whisper API`(åç»­å·²æ¥å…¥æ›´å¤šçš„è¯­éŸ³`API`æœåŠ¡) å®ç°å¯¹å¾®ä¿¡è¯­éŸ³æ¶ˆæ¯çš„è§£æå’Œå›å¤ï¼Œæ·»åŠ é…ç½®é¡¹ `\"speech_recognition\":true` å³å¯å¯ç”¨ï¼Œä½¿ç”¨å‚è€ƒ [#415](https://github.com/zhayujie/chatgpt-on-wechat/issues/415)ã€‚(contributed by [wanggang1987](https://github.com/wanggang1987) in [#385](https://github.com/zhayujie/chatgpt-on-wechat/pull/385))\n\n>**2023.02.09ï¼š** æ‰«ç ç™»å½•å­˜åœ¨è´¦å·é™åˆ¶é£é™©ï¼Œè¯·è°¨æ…ä½¿ç”¨ï¼Œå‚è€ƒ[#58](https://github.com/AutumnWhj/ChatGPT-wechat-bot/issues/158)\n\n# å¿«é€Ÿå¼€å§‹\n\nå¿«é€Ÿå¼€å§‹æ–‡æ¡£ï¼š[é¡¹ç›®æ­å»ºæ–‡æ¡£](https://docs.link-ai.tech/cow/quick-start)\n\n## å‡†å¤‡\n\n### 1. è´¦å·æ³¨å†Œ\n\né¡¹ç›®é»˜è®¤ä½¿ç”¨OpenAIæ¥å£ï¼Œéœ€å‰å¾€ [OpenAIæ³¨å†Œé¡µé¢](https://beta.openai.com/signup) åˆ›å»ºè´¦å·ï¼Œåˆ›å»ºå®Œè´¦å·åˆ™å‰å¾€ [APIç®¡ç†é¡µé¢](https://beta.openai.com/account/api-keys) åˆ›å»ºä¸€ä¸ª API Key å¹¶ä¿å­˜ä¸‹æ¥ï¼Œåé¢éœ€è¦åœ¨é¡¹ç›®ä¸­é…ç½®è¿™ä¸ªkeyã€‚æ¥å£éœ€è¦æµ·å¤–ç½‘ç»œè®¿é—®åŠç»‘å®šä¿¡ç”¨å¡æ”¯ä»˜ã€‚\n\n> é»˜è®¤å¯¹è¯æ¨¡å‹æ˜¯ openai çš„ gpt-3.5-turboï¼Œè®¡è´¹æ–¹å¼æ˜¯çº¦æ¯ 1000tokens (çº¦750ä¸ªè‹±æ–‡å•è¯ æˆ– 500æ±‰å­—ï¼ŒåŒ…å«è¯·æ±‚å’Œå›å¤) æ¶ˆè€— $0.002ï¼Œå›¾ç‰‡ç”Ÿæˆæ˜¯Dell Eæ¨¡å‹ï¼Œæ¯å¼ æ¶ˆè€— $0.016ã€‚\n\né¡¹ç›®åŒæ—¶ä¹Ÿæ”¯æŒä½¿ç”¨ LinkAI æ¥å£ï¼Œæ— éœ€ä»£ç†ï¼Œå¯ä½¿ç”¨ æ–‡å¿ƒã€è®¯é£ã€GPT-3ã€GPT-4 ç­‰æ¨¡å‹ï¼Œæ”¯æŒ å®šåˆ¶åŒ–çŸ¥è¯†åº“ã€è”ç½‘æœç´¢ã€MJç»˜å›¾ã€æ–‡æ¡£æ€»ç»“å’Œå¯¹è¯ç­‰èƒ½åŠ›ã€‚ä¿®æ”¹é…ç½®å³å¯ä¸€é”®åˆ‡æ¢ï¼Œå‚è€ƒ [æ¥å…¥æ–‡æ¡£](https://link-ai.tech/platform/link-app/wechat)ã€‚\n\n### 2.è¿è¡Œç¯å¢ƒ\n\næ”¯æŒ Linuxã€MacOSã€Windows ç³»ç»Ÿï¼ˆå¯åœ¨LinuxæœåŠ¡å™¨ä¸Šé•¿æœŸè¿è¡Œ)ï¼ŒåŒæ—¶éœ€å®‰è£… `Python`ã€‚\n> å»ºè®®Pythonç‰ˆæœ¬åœ¨ 3.7.1~3.9.X ä¹‹é—´ï¼Œæ¨è3.8ç‰ˆæœ¬ï¼Œ3.10åŠä»¥ä¸Šç‰ˆæœ¬åœ¨ MacOS å¯ç”¨ï¼Œå…¶ä»–ç³»ç»Ÿä¸Šä¸ç¡®å®šèƒ½å¦æ­£å¸¸è¿è¡Œã€‚\n\n> æ³¨æ„ï¼šDocker æˆ– Railway éƒ¨ç½²æ— éœ€å®‰è£…pythonç¯å¢ƒå’Œä¸‹è½½æºç ï¼Œå¯ç›´æ¥å¿«è¿›åˆ°ä¸‹ä¸€èŠ‚ã€‚\n\n**(1) å…‹éš†é¡¹ç›®ä»£ç ï¼š**\n\n```bash\ngit clone https://github.com/zhayujie/chatgpt-on-wechat\ncd chatgpt-on-wechat/\n```\n\næ³¨: å¦‚é‡åˆ°ç½‘ç»œé—®é¢˜å¯é€‰æ‹©å›½å†…é•œåƒ https://gitee.com/zhayujie/chatgpt-on-wechat\n\n**(2) å®‰è£…æ ¸å¿ƒä¾èµ– (å¿…é€‰)ï¼š**\n> èƒ½å¤Ÿä½¿ç”¨`itchat`åˆ›å»ºæœºå™¨äººï¼Œå¹¶å…·æœ‰æ–‡å­—äº¤æµåŠŸèƒ½æ‰€éœ€çš„æœ€å°ä¾èµ–é›†åˆã€‚\n```bash\npip3 install -r requirements.txt\n```\n\n**(3) æ‹“å±•ä¾èµ– (å¯é€‰ï¼Œå»ºè®®å®‰è£…)ï¼š**\n\n```bash\npip3 install -r requirements-optional.txt\n```\n> å¦‚æœæŸé¡¹ä¾èµ–å®‰è£…å¤±è´¥å¯æ³¨é‡Šæ‰å¯¹åº”çš„è¡Œå†ç»§ç»­\n\n## é…ç½®\n\né…ç½®æ–‡ä»¶çš„æ¨¡æ¿åœ¨æ ¹ç›®å½•çš„`config-template.json`ä¸­ï¼Œéœ€å¤åˆ¶è¯¥æ¨¡æ¿åˆ›å»ºæœ€ç»ˆç”Ÿæ•ˆçš„ `config.json` æ–‡ä»¶ï¼š\n\n```bash\n  cp config-template.json config.json\n```\n\nç„¶ååœ¨`config.json`ä¸­å¡«å…¥é…ç½®ï¼Œä»¥ä¸‹æ˜¯å¯¹é»˜è®¤é…ç½®çš„è¯´æ˜ï¼Œå¯æ ¹æ®éœ€è¦è¿›è¡Œè‡ªå®šä¹‰ä¿®æ”¹ï¼ˆè¯·å»æ‰æ³¨é‡Šï¼‰ï¼š\n\n```bash\n# config.jsonæ–‡ä»¶å†…å®¹ç¤ºä¾‹\n{\n  \"open_ai_api_key\": \"YOUR API KEY\",                          # å¡«å…¥ä¸Šé¢åˆ›å»ºçš„ OpenAI API KEY\n  \"model\": \"gpt-3.5-turbo\",                                   # æ¨¡å‹åç§°, æ”¯æŒ gpt-3.5-turbo, gpt-3.5-turbo-16k, gpt-4, wenxin, xunfei\n  \"proxy\": \"\",                                                # ä»£ç†å®¢æˆ·ç«¯çš„ipå’Œç«¯å£ï¼Œå›½å†…ç¯å¢ƒå¼€å¯ä»£ç†çš„éœ€è¦å¡«å†™è¯¥é¡¹ï¼Œå¦‚ \"127.0.0.1:7890\"\n  \"single_chat_prefix\": [\"bot\", \"@bot\"],                      # ç§èŠæ—¶æ–‡æœ¬éœ€è¦åŒ…å«è¯¥å‰ç¼€æ‰èƒ½è§¦å‘æœºå™¨äººå›å¤\n  \"single_chat_reply_prefix\": \"[bot] \",                       # ç§èŠæ—¶è‡ªåŠ¨å›å¤çš„å‰ç¼€ï¼Œç”¨äºåŒºåˆ†çœŸäºº\n  \"group_chat_prefix\": [\"@bot\"],                              # ç¾¤èŠæ—¶åŒ…å«è¯¥å‰ç¼€åˆ™ä¼šè§¦å‘æœºå™¨äººå›å¤\n  \"group_name_white_list\": [\"ChatGPTæµ‹è¯•ç¾¤\", \"ChatGPTæµ‹è¯•ç¾¤2\"], # å¼€å¯è‡ªåŠ¨å›å¤çš„ç¾¤åç§°åˆ—è¡¨\n  \"group_chat_in_one_session\": [\"ChatGPTæµ‹è¯•ç¾¤\"],              # æ”¯æŒä¼šè¯ä¸Šä¸‹æ–‡å…±äº«çš„ç¾¤åç§°  \n  \"image_create_prefix\": [\"ç”»\", \"çœ‹\", \"æ‰¾\"],                   # å¼€å¯å›¾ç‰‡å›å¤çš„å‰ç¼€\n  \"conversation_max_tokens\": 1000,                            # æ”¯æŒä¸Šä¸‹æ–‡è®°å¿†çš„æœ€å¤šå­—ç¬¦æ•°\n  \"speech_recognition\": false,                                # æ˜¯å¦å¼€å¯è¯­éŸ³è¯†åˆ«\n  \"group_speech_recognition\": false,                          # æ˜¯å¦å¼€å¯ç¾¤ç»„è¯­éŸ³è¯†åˆ«\n  \"use_azure_chatgpt\": false,                                 # æ˜¯å¦ä½¿ç”¨Azure ChatGPT serviceä»£æ›¿openai ChatGPT service. å½“è®¾ç½®ä¸ºtrueæ—¶éœ€è¦è®¾ç½® open_ai_api_baseï¼Œå¦‚ https://xxx.openai.azure.com/\n  \"azure_deployment_id\": \"\",                                  # é‡‡ç”¨Azure ChatGPTæ—¶ï¼Œæ¨¡å‹éƒ¨ç½²åç§°\n  \"azure_api_version\": \"\",                                    # é‡‡ç”¨Azure ChatGPTæ—¶ï¼ŒAPIç‰ˆæœ¬\n  \"character_desc\": \"ä½ æ˜¯ChatGPT, ä¸€ä¸ªç”±OpenAIè®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹, ä½ æ—¨åœ¨å›ç­”å¹¶è§£å†³äººä»¬çš„ä»»ä½•é—®é¢˜ï¼Œå¹¶ä¸”å¯ä»¥ä½¿ç”¨å¤šç§è¯­è¨€ä¸äººäº¤æµã€‚\",  # äººæ ¼æè¿°\n  # è®¢é˜…æ¶ˆæ¯ï¼Œå…¬ä¼—å·å’Œä¼ä¸šå¾®ä¿¡channelä¸­è¯·å¡«å†™ï¼Œå½“è¢«è®¢é˜…æ—¶ä¼šè‡ªåŠ¨å›å¤ï¼Œå¯ä½¿ç”¨ç‰¹æ®Šå ä½ç¬¦ã€‚ç›®å‰æ”¯æŒçš„å ä½ç¬¦æœ‰{trigger_prefix}ï¼Œåœ¨ç¨‹åºä¸­å®ƒä¼šè‡ªåŠ¨æ›¿æ¢æˆbotçš„è§¦å‘è¯ã€‚\n  \"subscribe_msg\": \"æ„Ÿè°¢æ‚¨çš„å…³æ³¨ï¼\\nè¿™é‡Œæ˜¯ChatGPTï¼Œå¯ä»¥è‡ªç”±å¯¹è¯ã€‚\\næ”¯æŒè¯­éŸ³å¯¹è¯ã€‚\\næ”¯æŒå›¾ç‰‡è¾“å‡ºï¼Œç”»å­—å¼€å¤´çš„æ¶ˆæ¯å°†æŒ‰è¦æ±‚åˆ›ä½œå›¾ç‰‡ã€‚\\næ”¯æŒè§’è‰²æ‰®æ¼”å’Œæ–‡å­—å†’é™©ç­‰ä¸°å¯Œæ’ä»¶ã€‚\\nè¾“å…¥{trigger_prefix}#help æŸ¥çœ‹è¯¦ç»†æŒ‡ä»¤ã€‚\",\n  \"use_linkai\": false,                                        # æ˜¯å¦ä½¿ç”¨LinkAIæ¥å£ï¼Œé»˜è®¤å…³é—­ï¼Œå¼€å¯åå¯å›½å†…è®¿é—®ï¼Œä½¿ç”¨çŸ¥è¯†åº“å’ŒMJ\n  \"linkai_api_key\": \"\",                                       # LinkAI Api Key\n  \"linkai_app_code\": \"\"                                       # LinkAI åº”ç”¨code\n}\n```\n**é…ç½®è¯´æ˜ï¼š**\n\n**1.ä¸ªäººèŠå¤©**\n\n+ ä¸ªäººèŠå¤©ä¸­ï¼Œéœ€è¦ä»¥ \"bot\"æˆ–\"@bot\" ä¸ºå¼€å¤´çš„å†…å®¹è§¦å‘æœºå™¨äººï¼Œå¯¹åº”é…ç½®é¡¹ `single_chat_prefix` (å¦‚æœä¸éœ€è¦ä»¥å‰ç¼€è§¦å‘å¯ä»¥å¡«å†™  `\"single_chat_prefix\": [\"\"]`)\n+ æœºå™¨äººå›å¤çš„å†…å®¹ä¼šä»¥ \"[bot] \" ä½œä¸ºå‰ç¼€ï¼Œ ä»¥åŒºåˆ†çœŸäººï¼Œå¯¹åº”çš„é…ç½®é¡¹ä¸º `single_chat_reply_prefix` (å¦‚æœä¸éœ€è¦å‰ç¼€å¯ä»¥å¡«å†™ `\"single_chat_reply_prefix\": \"\"`)\n\n**2.ç¾¤ç»„èŠå¤©**\n\n+ ç¾¤ç»„èŠå¤©ä¸­ï¼Œç¾¤åç§°éœ€é…ç½®åœ¨ `group_name_white_list ` ä¸­æ‰èƒ½å¼€å¯ç¾¤èŠè‡ªåŠ¨å›å¤ã€‚å¦‚æœæƒ³å¯¹æ‰€æœ‰ç¾¤èŠç”Ÿæ•ˆï¼Œå¯ä»¥ç›´æ¥å¡«å†™ `\"group_name_white_list\": [\"ALL_GROUP\"]`\n+ é»˜è®¤åªè¦è¢«äºº @ å°±ä¼šè§¦å‘æœºå™¨äººè‡ªåŠ¨å›å¤ï¼›å¦å¤–ç¾¤èŠå¤©ä¸­åªè¦æ£€æµ‹åˆ°ä»¥ \"@bot\" å¼€å¤´çš„å†…å®¹ï¼ŒåŒæ ·ä¼šè‡ªåŠ¨å›å¤ï¼ˆæ–¹ä¾¿è‡ªå·±è§¦å‘ï¼‰ï¼Œè¿™å¯¹åº”é…ç½®é¡¹ `group_chat_prefix`\n+ å¯é€‰é…ç½®: `group_name_keyword_white_list`é…ç½®é¡¹æ”¯æŒæ¨¡ç³ŠåŒ¹é…ç¾¤åç§°ï¼Œ`group_chat_keyword`é…ç½®é¡¹åˆ™æ”¯æŒæ¨¡ç³ŠåŒ¹é…ç¾¤æ¶ˆæ¯å†…å®¹ï¼Œç”¨æ³•ä¸ä¸Šè¿°ä¸¤ä¸ªé…ç½®é¡¹ç›¸åŒã€‚ï¼ˆContributed by [evolay](https://github.com/evolay))\n+ `group_chat_in_one_session`ï¼šä½¿ç¾¤èŠå…±äº«ä¸€ä¸ªä¼šè¯ä¸Šä¸‹æ–‡ï¼Œé…ç½® `[\"ALL_GROUP\"]` åˆ™ä½œç”¨äºæ‰€æœ‰ç¾¤èŠ\n\n**3.è¯­éŸ³è¯†åˆ«**\n\n+ æ·»åŠ  `\"speech_recognition\": true` å°†å¼€å¯è¯­éŸ³è¯†åˆ«ï¼Œé»˜è®¤ä½¿ç”¨openaiçš„whisperæ¨¡å‹è¯†åˆ«ä¸ºæ–‡å­—ï¼ŒåŒæ—¶ä»¥æ–‡å­—å›å¤ï¼Œè¯¥å‚æ•°ä»…æ”¯æŒç§èŠ (æ³¨æ„ç”±äºè¯­éŸ³æ¶ˆæ¯æ— æ³•åŒ¹é…å‰ç¼€ï¼Œä¸€æ—¦å¼€å¯å°†å¯¹æ‰€æœ‰è¯­éŸ³è‡ªåŠ¨å›å¤ï¼Œæ”¯æŒè¯­éŸ³è§¦å‘ç”»å›¾)ï¼›\n+ æ·»åŠ  `\"group_speech_recognition\": true` å°†å¼€å¯ç¾¤ç»„è¯­éŸ³è¯†åˆ«ï¼Œé»˜è®¤ä½¿ç”¨openaiçš„whisperæ¨¡å‹è¯†åˆ«ä¸ºæ–‡å­—ï¼ŒåŒæ—¶ä»¥æ–‡å­—å›å¤ï¼Œå‚æ•°ä»…æ”¯æŒç¾¤èŠ (ä¼šåŒ¹é…group_chat_prefixå’Œgroup_chat_keyword, æ”¯æŒè¯­éŸ³è§¦å‘ç”»å›¾)ï¼›\n+ æ·»åŠ  `\"voice_reply_voice\": true` å°†å¼€å¯è¯­éŸ³å›å¤è¯­éŸ³ï¼ˆåŒæ—¶ä½œç”¨äºç§èŠå’Œç¾¤èŠï¼‰ï¼Œä½†æ˜¯éœ€è¦é…ç½®å¯¹åº”è¯­éŸ³åˆæˆå¹³å°çš„keyï¼Œç”±äºitchatåè®®çš„é™åˆ¶ï¼Œåªèƒ½å‘é€è¯­éŸ³mp3æ–‡ä»¶ï¼Œè‹¥ä½¿ç”¨wechatyåˆ™å›å¤çš„æ˜¯å¾®ä¿¡è¯­éŸ³ã€‚\n\n**4.å…¶ä»–é…ç½®**\n\n+ `model`: æ¨¡å‹åç§°ï¼Œç›®å‰æ”¯æŒ `gpt-3.5-turbo`, `text-davinci-003`, `gpt-4`, `gpt-4-32k`, `wenxin` , `claude` ,  `xunfei`(å…¶ä¸­gpt-4 apiæš‚æœªå®Œå…¨å¼€æ”¾ï¼Œç”³è¯·é€šè¿‡åå¯ä½¿ç”¨)\n+ `temperature`,`frequency_penalty`,`presence_penalty`: Chat APIæ¥å£å‚æ•°ï¼Œè¯¦æƒ…å‚è€ƒ[OpenAIå®˜æ–¹æ–‡æ¡£ã€‚](https://platform.openai.com/docs/api-reference/chat)\n+ `proxy`ï¼šç”±äºç›®å‰ `openai` æ¥å£å›½å†…æ— æ³•è®¿é—®ï¼Œéœ€é…ç½®ä»£ç†å®¢æˆ·ç«¯çš„åœ°å€ï¼Œè¯¦æƒ…å‚è€ƒ  [#351](https://github.com/zhayujie/chatgpt-on-wechat/issues/351)\n+ å¯¹äºå›¾åƒç”Ÿæˆï¼Œåœ¨æ»¡è¶³ä¸ªäººæˆ–ç¾¤ç»„è§¦å‘æ¡ä»¶å¤–ï¼Œè¿˜éœ€è¦é¢å¤–çš„å…³é”®è¯å‰ç¼€æ¥è§¦å‘ï¼Œå¯¹åº”é…ç½® `image_create_prefix `\n+ å…³äºOpenAIå¯¹è¯åŠå›¾ç‰‡æ¥å£çš„å‚æ•°é…ç½®ï¼ˆå†…å®¹è‡ªç”±åº¦ã€å›å¤å­—æ•°é™åˆ¶ã€å›¾ç‰‡å¤§å°ç­‰ï¼‰ï¼Œå¯ä»¥å‚è€ƒ [å¯¹è¯æ¥å£](https://beta.openai.com/docs/api-reference/completions) å’Œ [å›¾åƒæ¥å£](https://beta.openai.com/docs/api-reference/completions)  æ–‡æ¡£ï¼Œåœ¨[`config.py`](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/config.py)ä¸­æ£€æŸ¥å“ªäº›å‚æ•°åœ¨æœ¬é¡¹ç›®ä¸­æ˜¯å¯é…ç½®çš„ã€‚\n+ `conversation_max_tokens`ï¼šè¡¨ç¤ºèƒ½å¤Ÿè®°å¿†çš„ä¸Šä¸‹æ–‡æœ€å¤§å­—æ•°ï¼ˆä¸€é—®ä¸€ç­”ä¸ºä¸€ç»„å¯¹è¯ï¼Œå¦‚æœç´¯ç§¯çš„å¯¹è¯å­—æ•°è¶…å‡ºé™åˆ¶ï¼Œå°±ä¼šä¼˜å…ˆç§»é™¤æœ€æ—©çš„ä¸€ç»„å¯¹è¯ï¼‰\n+ `rate_limit_chatgpt`ï¼Œ`rate_limit_dalle`ï¼šæ¯åˆ†é’Ÿæœ€é«˜é—®ç­”é€Ÿç‡ã€ç”»å›¾é€Ÿç‡ï¼Œè¶…é€Ÿåæ’é˜ŸæŒ‰åºå¤„ç†ã€‚\n+ `clear_memory_commands`: å¯¹è¯å†…æŒ‡ä»¤ï¼Œä¸»åŠ¨æ¸…ç©ºå‰æ–‡è®°å¿†ï¼Œå­—ç¬¦ä¸²æ•°ç»„å¯è‡ªå®šä¹‰æŒ‡ä»¤åˆ«åã€‚\n+ `hot_reload`: ç¨‹åºé€€å‡ºåï¼Œæš‚å­˜å¾®ä¿¡æ‰«ç çŠ¶æ€ï¼Œé»˜è®¤å…³é—­ã€‚\n+ `character_desc` é…ç½®ä¸­ä¿å­˜ç€ä½ å¯¹æœºå™¨äººè¯´çš„ä¸€æ®µè¯ï¼Œä»–ä¼šè®°ä½è¿™æ®µè¯å¹¶ä½œä¸ºä»–çš„è®¾å®šï¼Œä½ å¯ä»¥ä¸ºä»–å®šåˆ¶ä»»ä½•äººæ ¼      (å…³äºä¼šè¯ä¸Šä¸‹æ–‡çš„æ›´å¤šå†…å®¹å‚è€ƒè¯¥ [issue](https://github.com/zhayujie/chatgpt-on-wechat/issues/43))\n+ `subscribe_msg`ï¼šè®¢é˜…æ¶ˆæ¯ï¼Œå…¬ä¼—å·å’Œä¼ä¸šå¾®ä¿¡channelä¸­è¯·å¡«å†™ï¼Œå½“è¢«è®¢é˜…æ—¶ä¼šè‡ªåŠ¨å›å¤ï¼Œ å¯ä½¿ç”¨ç‰¹æ®Šå ä½ç¬¦ã€‚ç›®å‰æ”¯æŒçš„å ä½ç¬¦æœ‰{trigger_prefix}ï¼Œåœ¨ç¨‹åºä¸­å®ƒä¼šè‡ªåŠ¨æ›¿æ¢æˆbotçš„è§¦å‘è¯ã€‚\n\n**5.LinkAIé…ç½® (å¯é€‰)**\n\n+ `use_linkai`: æ˜¯å¦ä½¿ç”¨LinkAIæ¥å£ï¼Œå¼€å¯åå¯å›½å†…è®¿é—®ï¼Œä½¿ç”¨çŸ¥è¯†åº“å’Œ `Midjourney` ç»˜ç”», å‚è€ƒ [æ–‡æ¡£](https://link-ai.tech/platform/link-app/wechat)\n+ `linkai_api_key`: LinkAI Api Keyï¼Œå¯åœ¨ [æ§åˆ¶å°](https://link-ai.tech/console/interface) åˆ›å»º\n+ `linkai_app_code`: LinkAI åº”ç”¨codeï¼Œé€‰å¡«\n\n**æœ¬è¯´æ˜æ–‡æ¡£å¯èƒ½ä¼šæœªåŠæ—¶æ›´æ–°ï¼Œå½“å‰æ‰€æœ‰å¯é€‰çš„é…ç½®é¡¹å‡åœ¨è¯¥[`config.py`](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/config.py)ä¸­åˆ—å‡ºã€‚**\n\n## è¿è¡Œ\n\n### 1.æœ¬åœ°è¿è¡Œ\n\nå¦‚æœæ˜¯å¼€å‘æœº **æœ¬åœ°è¿è¡Œ**ï¼Œç›´æ¥åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹æ‰§è¡Œï¼š\n\n```bash\npython3 app.py                                    # windowsç¯å¢ƒä¸‹è¯¥å‘½ä»¤é€šå¸¸ä¸º python app.py\n```\n\nç»ˆç«¯è¾“å‡ºäºŒç»´ç åï¼Œä½¿ç”¨å¾®ä¿¡è¿›è¡Œæ‰«ç ï¼Œå½“è¾“å‡º \"Start auto replying\" æ—¶è¡¨ç¤ºè‡ªåŠ¨å›å¤ç¨‹åºå·²ç»æˆåŠŸè¿è¡Œäº†ï¼ˆæ³¨æ„ï¼šç”¨äºç™»å½•çš„å¾®ä¿¡éœ€è¦åœ¨æ”¯ä»˜å¤„å·²å®Œæˆå®åè®¤è¯ï¼‰ã€‚æ‰«ç ç™»å½•åä½ çš„è´¦å·å°±æˆä¸ºæœºå™¨äººäº†ï¼Œå¯ä»¥åœ¨å¾®ä¿¡æ‰‹æœºç«¯é€šè¿‡é…ç½®çš„å…³é”®è¯è§¦å‘è‡ªåŠ¨å›å¤ (ä»»æ„å¥½å‹å‘é€æ¶ˆæ¯ç»™ä½ ï¼Œæˆ–æ˜¯è‡ªå·±å‘æ¶ˆæ¯ç»™å¥½å‹)ï¼Œå‚è€ƒ[#142](https://github.com/zhayujie/chatgpt-on-wechat/issues/142)ã€‚\n\n### 2.æœåŠ¡å™¨éƒ¨ç½²\n\nä½¿ç”¨nohupå‘½ä»¤åœ¨åå°è¿è¡Œç¨‹åºï¼š\n\n```bash\nnohup python3 app.py & tail -f nohup.out          # åœ¨åå°è¿è¡Œç¨‹åºå¹¶é€šè¿‡æ—¥å¿—è¾“å‡ºäºŒç»´ç \n```\næ‰«ç ç™»å½•åç¨‹åºå³å¯è¿è¡ŒäºæœåŠ¡å™¨åå°ï¼Œæ­¤æ—¶å¯é€šè¿‡ `ctrl+c` å…³é—­æ—¥å¿—ï¼Œä¸ä¼šå½±å“åå°ç¨‹åºçš„è¿è¡Œã€‚ä½¿ç”¨ `ps -ef | grep app.py | grep -v grep` å‘½ä»¤å¯æŸ¥çœ‹è¿è¡Œäºåå°çš„è¿›ç¨‹ï¼Œå¦‚æœæƒ³è¦é‡æ–°å¯åŠ¨ç¨‹åºå¯ä»¥å…ˆ `kill` æ‰å¯¹åº”çš„è¿›ç¨‹ã€‚æ—¥å¿—å…³é—­åå¦‚æœæƒ³è¦å†æ¬¡æ‰“å¼€åªéœ€è¾“å…¥Â `tail -f nohup.out`ã€‚æ­¤å¤–ï¼Œ`scripts` ç›®å½•ä¸‹æœ‰ä¸€é”®è¿è¡Œã€å…³é—­ç¨‹åºçš„è„šæœ¬ä¾›ä½¿ç”¨ã€‚\n\n> **å¤šè´¦å·æ”¯æŒï¼š** å°†é¡¹ç›®å¤åˆ¶å¤šä»½ï¼Œåˆ†åˆ«å¯åŠ¨ç¨‹åºï¼Œç”¨ä¸åŒè´¦å·æ‰«ç ç™»å½•å³å¯å®ç°åŒæ—¶è¿è¡Œã€‚\n\n> **ç‰¹æ®ŠæŒ‡ä»¤ï¼š** ç”¨æˆ·å‘æœºå™¨äººå‘é€ **#reset** å³å¯æ¸…ç©ºè¯¥ç”¨æˆ·çš„ä¸Šä¸‹æ–‡è®°å¿†ã€‚\n\n\n### 3.Dockeréƒ¨ç½²\n\n> ä½¿ç”¨dockeréƒ¨ç½²æ— éœ€ä¸‹è½½æºç å’Œå®‰è£…ä¾èµ–ï¼Œåªéœ€è¦è·å– docker-compose.yml é…ç½®æ–‡ä»¶å¹¶å¯åŠ¨å®¹å™¨å³å¯ã€‚\n\n> å‰ææ˜¯éœ€è¦å®‰è£…å¥½ `docker` åŠ `docker-compose`ï¼Œå®‰è£…æˆåŠŸçš„è¡¨ç°æ˜¯æ‰§è¡Œ `docker -v` å’Œ `docker-compose version` (æˆ– docker compose version) å¯ä»¥æŸ¥çœ‹åˆ°ç‰ˆæœ¬å·ï¼Œå¯å‰å¾€ [dockerå®˜ç½‘](https://docs.docker.com/engine/install/) è¿›è¡Œä¸‹è½½ã€‚\n\n#### (1) ä¸‹è½½ docker-compose.yml æ–‡ä»¶\n\n```bash\nwget https://open-1317903499.cos.ap-guangzhou.myqcloud.com/docker-compose.yml\n```\n\nä¸‹è½½å®Œæˆåæ‰“å¼€ `docker-compose.yml` ä¿®æ”¹æ‰€éœ€é…ç½®ï¼Œå¦‚ `OPEN_AI_API_KEY` å’Œ `GROUP_NAME_WHITE_LIST` ç­‰ã€‚\n\n#### (2) å¯åŠ¨å®¹å™¨\n\nåœ¨ `docker-compose.yml` æ‰€åœ¨ç›®å½•ä¸‹æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨å®¹å™¨ï¼š\n\n```bash\nsudo docker compose up -d\n```\n\nè¿è¡Œ `sudo docker ps` èƒ½æŸ¥çœ‹åˆ° NAMES ä¸º chatgpt-on-wechat çš„å®¹å™¨å³è¡¨ç¤ºè¿è¡ŒæˆåŠŸã€‚\n\næ³¨æ„ï¼š\n\n - å¦‚æœ `docker-compose` æ˜¯ 1.X ç‰ˆæœ¬ åˆ™éœ€è¦æ‰§è¡Œ `sudo  docker-compose up -d` æ¥å¯åŠ¨å®¹å™¨\n - è¯¥å‘½ä»¤ä¼šè‡ªåŠ¨å» [docker hub](https://hub.docker.com/r/zhayujie/chatgpt-on-wechat) æ‹‰å– latest ç‰ˆæœ¬çš„é•œåƒï¼Œlatest é•œåƒä¼šåœ¨æ¯æ¬¡é¡¹ç›® release æ–°çš„ç‰ˆæœ¬æ—¶ç”Ÿæˆ\n\næœ€åè¿è¡Œä»¥ä¸‹å‘½ä»¤å¯æŸ¥çœ‹å®¹å™¨è¿è¡Œæ—¥å¿—ï¼Œæ‰«ææ—¥å¿—ä¸­çš„äºŒç»´ç å³å¯å®Œæˆç™»å½•ï¼š\n\n```bash\nsudo docker logs -f chatgpt-on-wechat\n```\n\n#### (3) æ’ä»¶ä½¿ç”¨\n\nå¦‚æœéœ€è¦åœ¨dockerå®¹å™¨ä¸­ä¿®æ”¹æ’ä»¶é…ç½®ï¼Œå¯é€šè¿‡æŒ‚è½½çš„æ–¹å¼å®Œæˆï¼Œå°† [æ’ä»¶é…ç½®æ–‡ä»¶](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/plugins/config.json.template)\né‡å‘½åä¸º `config.json`ï¼Œæ”¾ç½®äº `docker-compose.yml` ç›¸åŒç›®å½•ä¸‹ï¼Œå¹¶åœ¨ `docker-compose.yml` ä¸­çš„ `chatgpt-on-wechat` éƒ¨åˆ†ä¸‹æ·»åŠ  `volumes` æ˜ å°„:\n\n```\nvolumes:\n  - ./config.json:/app/plugins/config.json\n```\n\n### 4. Railwayéƒ¨ç½²\n\n> Railway æ¯æœˆæä¾›5åˆ€å’Œæœ€å¤š500å°æ—¶çš„å…è´¹é¢åº¦ã€‚ (07.11æ›´æ–°: ç›®å‰å¤§éƒ¨åˆ†è´¦å·å·²æ— æ³•å…è´¹éƒ¨ç½²)\n\n1. è¿›å…¥ [Railway](https://railway.app/template/qApznZ?referralCode=RC3znh)\n2. ç‚¹å‡» `Deploy Now` æŒ‰é’®ã€‚\n3. è®¾ç½®ç¯å¢ƒå˜é‡æ¥é‡è½½ç¨‹åºè¿è¡Œçš„å‚æ•°ï¼Œä¾‹å¦‚`open_ai_api_key`, `character_desc`ã€‚\n\n**ä¸€é”®éƒ¨ç½²:**\n  \n  [![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/template/qApznZ?referralCode=RC3znh)\n\n## å¸¸è§é—®é¢˜\n\nFAQsï¼š <https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs>\n\næˆ–ç›´æ¥åœ¨çº¿å’¨è¯¢ [é¡¹ç›®å°åŠ©æ‰‹](https://link-ai.tech/app/Kv2fXJcH)  (betaç‰ˆæœ¬ï¼Œè¯­æ–™å®Œå–„ä¸­ï¼Œå›å¤ä»…ä¾›å‚è€ƒ)\n\n## å¼€å‘\n\næ¬¢è¿æ¥å…¥æ›´å¤šåº”ç”¨ï¼Œå‚è€ƒ [Terminalä»£ç ](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/terminal/terminal_channel.py) å®ç°æ¥æ”¶å’Œå‘é€æ¶ˆæ¯é€»è¾‘å³å¯æ¥å…¥ã€‚ åŒæ—¶æ¬¢è¿å¢åŠ æ–°çš„æ’ä»¶ï¼Œå‚è€ƒ [æ’ä»¶è¯´æ˜æ–‡æ¡£](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins)ã€‚\n\n## è”ç³»\n\næ¬¢è¿æäº¤PRã€Issuesï¼Œä»¥åŠStaræ”¯æŒä¸€ä¸‹ã€‚ç¨‹åºè¿è¡Œé‡åˆ°é—®é¢˜å¯ä»¥æŸ¥çœ‹ [å¸¸è§é—®é¢˜åˆ—è¡¨](https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs) ï¼Œå…¶æ¬¡å‰å¾€ [Issues](https://github.com/zhayujie/chatgpt-on-wechat/issues) ä¸­æœç´¢ã€‚ä¸ªäººå¼€å‘è€…å¯åŠ å…¥å¼€æºäº¤æµç¾¤å‚ä¸æ›´å¤šè®¨è®ºï¼Œä¼ä¸šç”¨æˆ·å¯è”ç³»[äº§å“é¡¾é—®](https://img-1317903499.cos.ap-guangzhou.myqcloud.com/docs/product-manager-qrcode.jpg)å’¨è¯¢ã€‚",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "chatgpt",
        "dialogue",
        "wechat",
        "dialogue service",
        "chatgpt wechat",
        "rsagacom chatgpt"
      ],
      "category": "virtual-assistants"
    },
    "scarletlabs-ai--Votars-MCP": {
      "owner": "scarletlabs-ai",
      "name": "Votars-MCP",
      "url": "https://github.com/scarletlabs-ai/Votars-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/scarletlabs-ai.webp",
      "description": "Integrate advanced AI functionalities for processing complex tasks through robust APIs. Supports voice recording, transcription, and intelligent AI processing for meetings.",
      "stars": 27,
      "forks": 2,
      "license": "No License",
      "language": "Go",
      "updated_at": "2025-07-07T07:12:32Z",
      "readme_content": "![Votars Logo](https://votars.ai/_next/static/media/logo.e7b6bff6.svg) \n# Votars MCP \n[![smithery badge](https://smithery.ai/badge/@scarletlabs-ai/votars-mcp)](https://smithery.ai/server/@scarletlabs-ai/votars-mcp)\n\n\n## Overview\n\nVotars-MCP is a tool that supports multiple language implementations of the **Votars MCP server**. Currently, only the Go version is available, with other languages to be added in future releases. It supports two interaction modes: `sse` (Server-Sent Events) and `stdio` (Standard Input/Output). It is designed to provide seamless integration with the Votars AI platform for processing various tasks.\n\n## About Votars\n\n[Votars](https://votars.ai/en/) is the world's smartest multilingual meeting assistant, designed for voice recording, transcription, and advanced AI processing. It features real-time translation, intelligent error correction, AI summarization, smart content generation, and AI discussions. The Votars app is available on [Web](https://votars.ai/en/), [iOS](https://apps.apple.com/us/app/votars-ai-transcribe-organize/id6737496290), and [Android](https://play.google.com/store/apps/details?id=com.votars.transcribe).\n\nAdditionally, Votars is an AI-powered platform that enables developers to integrate advanced AI functionalities into their applications. By leveraging Votars, you can process complex tasks efficiently with robust APIs designed for high performance and scalability.\n\n## Features\n- **Easy Integration with Votars**\n- **Modular Design:** Ready to be extended with additional functionalities.\n- **Supported MCP Tools:**\n  - `Votars_fetch_recent_transcripts`: Allows users to read recent transcripts from their workspace, providing convenient access to the latest recorded sessions.\n  - `Votars_fetch_a_specific_transcript`: Enables users to retrieve specific transcripts by providing a transcript ID, allowing targeted retrieval of stored data.\n  \n  More functionalities will be added soon. Stay tuned!\n\n## Installation (Go MCP)\n\n### Installing via Smithery\n\nTo install votars-mcp for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@scarletlabs-ai/votars-mcp):\n\n```bash\nnpx -y @smithery/cli install @scarletlabs-ai/votars-mcp --client claude\n```\n\n### Manual Installation\nTo install the Go version of Votars MCP from the GitHub repository, use:\n\n```bash\n go install github.com/scarletlabs-ai/Votars-MCP/go/votars-mcp@latest\n```\n\n## Usage (Go MCP)\n\n### Run MCP Service\nBefore using the `sse` mode, you need to run the MCP server. Open a terminal and run:\n\n```bash\nvotars-mcp -t sse -p 8080\n```\n\nThis command starts the MCP service on port 8080, ready to accept `sse` requests.\n\n\n### 1. SSE Mode\n\nFor `sse` mode, you need to provide the API key via request headers in the configuration file.\n\nConfiguration file example (`mcp.config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"Votars MCP\": {\n      \"type\": \"sse\",\n      \"url\": \"http://0.0.0.0:8080/sse\",\n      \"headers\": {\n        \"Authorization\": \"Bearer <your-api-key>\"\n      }\n    }\n  }\n}\n```\n\n### 2. Stdio Mode\n\nFor `stdio` mode, set the API key as an environment variable.\n\n\nConfiguration file example (`mcp.config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"Votars MCP Stdio\": {\n      \"type\": \"stdio\",\n      \"command\": \"votars-mcp\",\n      \"args\": [\"-t\", \"stdio\"],\n      \"env\": {\n        \"VOTARS_API_KEY\": \"<your-api-key>\"\n      }\n    }\n  }\n}\n```\n\n## Obtaining Your API Key\n\n1. Go to [Votars.AI](https://votars.ai/en/) and register.\n2. Navigate to your workspace's `Settings`.\n3. Create an API Key under the API Key management section.\n\n\n\n## Roadmap\n\n- **Current Support:** Go\n- **Planned Support:** Python, JavaScript, Rust, etc.\n\n## License\n\nMIT License",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "voice",
        "assistants",
        "virtual assistants",
        "scarletlabs ai",
        "transcription intelligent"
      ],
      "category": "virtual-assistants"
    },
    "suryawanshishantanu6--time-mcp": {
      "owner": "suryawanshishantanu6",
      "name": "time-mcp",
      "url": "https://github.com/suryawanshishantanu6/time-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/suryawanshishantanu6.webp",
      "description": "Integrates a tool-augmented LLM pipeline to provide answers to time-related and general inquiries. Utilizes a Flask API for current timestamps and employs an MCP Agent for intent detection and interaction with an LLM via OpenRouter.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-08T03:55:06Z",
      "readme_content": "# time-mcp\n\nA minimal agentic AI system that answers time-related and general questions using a tool-augmented LLM pipeline.\n\n## Features\n- **Flask API**: Provides the current timestamp.\n- **MCP Agent Server**: Reasoning agent that detects user intent, calls tools (like the time API), engineers prompts, and interacts with an LLM via OpenRouter (OpenAI-compatible API).\n- **Streamlit UI**: Simple chat interface to talk to the AI agent.\n\n---\n\n## Setup\n\n### 1. Clone and Install Dependencies\n```bash\npip install -r requirements.txt\n```\n\n### 2. Environment Variable\nSet your OpenRouter API key (get one from https://openrouter.ai):\n```bash\nexport OPENROUTER_API_KEY=sk-...your-key...\n```\n\n### 3. Run the Servers\nOpen three terminals (or use background processes):\n\n#### Terminal 1: Flask Time API\n```bash\npython flask_api.py\n```\n\n#### Terminal 2: MCP Agent Server\n```bash\npython mcp_server.py\n```\n\n#### Terminal 3: Streamlit UI\n```bash\nstreamlit run streamlit_ui.py\n```\n\nThe Streamlit UI will open in your browser (default: http://localhost:8501)\n\n---\n\n## Usage\n- Ask the agent any question in the Streamlit UI.\n- If you ask about the time (e.g., \"What is the time?\"), the agent will call the Flask API, fetch the current time, and craft a beautiful, natural response using the LLM.\n- For other questions, the agent will answer using the LLM only.\n\n---\n\n## Architecture\n```\n[Streamlit UI] â†’ [MCP Agent Server] â†’ [Tools (e.g., Time API)]\n                            â†“\n                        [LLM via OpenRouter]\n```\n- The MCP agent detects intent, calls tools as needed, engineers prompts, and sends them to the LLM.\n- Easily extensible to add more tools (just add to the MCPAgent class).\n\n---\n\n## Customization\n- **Add more tools**: Implement new methods in `MCPAgent` and update `self.tools`.\n- **Improve intent detection**: Extend `detect_intent()` in `MCPAgent`.\n- **Change LLM model**: Update the `model` field in `call_llm()`.\n\n---\n\n## Requirements\n- Python 3.7+\n- See `requirements.txt` for dependencies.\n\n---\n\n## Credits\n- Built using Flask, Streamlit, OpenRouter, and Python.\n- Inspired by agentic LLM design patterns.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llm",
        "timestamps",
        "api",
        "virtual assistants",
        "augmented llm",
        "llm pipeline"
      ],
      "category": "virtual-assistants"
    },
    "tijs--py-sound-mcp": {
      "owner": "tijs",
      "name": "py-sound-mcp",
      "url": "https://github.com/tijs/py-sound-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/tijs.webp",
      "description": "Plays customizable sound effects for coding events such as completions and errors, providing audio feedback in MCP-compatible environments. Integrates seamlessly with tools like Cursor to enhance the interactive development experience.",
      "stars": 1,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-12T09:02:31Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/tijs-py-sound-mcp-badge.png)](https://mseep.ai/app/tijs-py-sound-mcp)\n\n# MCP Sound Tool\n\nA Model Context Protocol (MCP) implementation that plays sound effects for Cursor AI and other MCP-compatible environments. This Python implementation provides audio feedback for a more interactive coding experience.\n\n## Features\n\n* Plays sound effects for various events (completion, error, notification)\n* Uses the Model Context Protocol (MCP) for standardized integration with Cursor and other IDEs\n* Cross-platform support (Windows, macOS, Linux)\n* Configurable sound effects\n\n## Installation\n\n### Python Version Compatibility\n\nThis package is tested with Python 3.8-3.11. If you encounter errors with Python 3.12+ (particularly `BrokenResourceError` or `TaskGroup` exceptions), please try using an earlier Python version.\n\n### Recommended: Install with pipx\n\nThe recommended way to install mcp-sound-tool is with [pipx](https://pypa.github.io/pipx/), which installs the package in an isolated environment while making the commands available globally:\n\n```bash\n# Install pipx if you don't have it\npython -m pip install --user pipx\npython -m pipx ensurepath\n\n# Install mcp-sound-tool\npipx install mcp-sound-tool\n```\n\nThis method ensures that the tool has its own isolated environment, avoiding conflicts with other packages.\n\n### Alternative: Install with pip\n\nYou can also install directly with pip:\n\n```bash\npip install mcp-sound-tool\n```\n\n### From Source\n\n1. Clone this repository:\n\n   ```bash\n   git clone https://github.com/yourusername/mcp-sound-tool\n   cd mcp-sound-tool\n   ```\n\n2. Install with pipx directly from the source directory:\n\n   ```bash\n   pipx install .\n   ```\n\n   Or with pip:\n\n   ```bash\n   pip install -e .\n   ```\n\n## Usage\n\n### Adding Sound Files\n\nPlace your sound files in the `sounds` directory. The following sound files are expected:\n\n* `completion.mp3` - Played after code generation\n* `error.mp3` - Played when an error occurs\n* `notification.mp3` - Used for general notifications\n\nYou can find free sound effects on websites like freesound.org.\n\n### Running the MCP Server\n\nRun the MCP server:\n\n```bash\nmcp-sound-tool\n```\n\nThe server will start and listen for events from Cursor or other MCP-compatible clients through the stdio transport.\n\n### Configuration in Cursor\n\nTo use this server with Cursor, add it to your MCP configuration file:\n\nOn macOS:\n\n```json\n// ~/Library/Application Support/Cursor/mcp.json\n{\n  \"mcpServers\": {\n    \"sound\": {\n      \"command\": \"mcp-sound-tool\",\n      \"args\": [],\n      \"type\": \"stdio\",\n      \"pollingInterval\": 5000,\n      \"startupTimeout\": 10000,\n      \"restartOnFailure\": true\n    }\n  }\n}\n```\n\nOn Windows:\n\n```json\n// %APPDATA%/Cursor/mcp.json\n{\n  \"mcpServers\": {\n    \"sound\": {\n      \"command\": \"mcp-sound-tool\",\n      \"args\": [],\n      \"type\": \"stdio\",\n      \"pollingInterval\": 5000,\n      \"startupTimeout\": 10000,\n      \"restartOnFailure\": true\n    }\n  }\n}\n```\n\nWhen installed with `pipx`, the `mcp-sound-tool` command will be available in your PATH, so Cursor will be able to find and execute it without specifying the full path.\n\n## Sound MCP Usage Guidelines for AI Models\n\nThis MCP server provides audio feedback capabilities for AI interactions. It's designed to enhance the user experience by providing clear audio cues that indicate the status of operations without requiring the user to read text.\n\n### When to Use Sound Feedback\n\nAI agents should use the sound tools proactively at appropriate moments:\n\n1. **Success Sounds (`completion`)**:\n   * After a task or command has successfully completed\n   * When a significant operation has finished successfully\n   * When confirming a user's request has been fulfilled\n\n2. **Error Sounds (`error`)**:\n   * When a command has failed or encountered an error\n   * When warning the user about a problem\n   * When an operation couldn't be completed as requested\n\n3. **Notification Sounds (`notification`)**:\n   * When alerting the user to important information\n   * When prompting for user attention or input\n   * For status updates on long-running operations\n\n### Example Usage\n\n```python\n# When a command completes successfully\n@mcp.tool()\ndef execute_command(command):\n    result = run_command(command)\n    if result.success:\n        play_sound(\"completion\")  # Indicate success with audio\n        return \"Command executed successfully\"\n    else:\n        play_sound(\"error\")  # Indicate failure with audio\n        return f\"Error: {result.error_message}\"\n```\n\n### Available Tools\n\n1. `play_sound(sound_type=\"completion\", custom_sound_path=None)`: Play a sound effect\n2. `list_available_sounds()`: List all available sound files\n3. `install_to_user_dir()`: Install sound files to user's config directory\n\nFor more details, connect to the MCP server and check the tool descriptions.\n\n## Development\n\nFor development:\n\n```bash\n# Install development dependencies\npip install -e \".[dev]\"\n\n# Run tests\npytest\n```\n\n## Acknowledgments\n\n* [SIAM-TheLegend](https://github.com/SIAM-TheLegend) for creating the original [sound-mcp](https://github.com/SIAM-TheLegend/sound-mcp) JavaScript implementation that inspired this Python version\n* The MCP protocol developers for creating a powerful standard for AI tool interactions\n* Contributors to the testing and documentation\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "interactive",
        "sound",
        "audio",
        "py sound",
        "sound mcp",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "veenastudio--flstudio-mcp": {
      "owner": "veenastudio",
      "name": "flstudio-mcp",
      "url": "https://github.com/veenastudio/flstudio-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/veenastudio.webp",
      "description": "Connects AI model Claude to FL Studio for seamless integration of melodies, chords, and drum patterns into music projects. Facilitates real-time music production by allowing interaction between AI and the FL Studio environment.",
      "stars": 59,
      "forks": 4,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-30T19:37:52Z",
      "readme_content": "# flstudio MCP\n\n# This is an MCP server that connects Claude to FL Studio.\nMade this in 3 days. We're open sourcing it to see what we can actually get out of it. The possibilities are endless.\n\n## If you're running to any issues, join our discord and we can setup it for you.\n(also join if you interested in the future of music and AI or want to request features. we're building this with you)\n\nhttps://discord.gg/ZjG9TaEhvy\n\nCheck out our AI-Powered DAW for musicians at www.veena.studio\n\nAll in browser. All for free.\n\n\n## Step 1: Download the Files\nYou should see two main items.\n\n- A folder called Test Controller\n- A python file called trigger.py\nThe Test Controller folder has a file called device_test.py that receives information from the MCP server.\ntrigger.py is the MCP server.\n\nPlace the Test Controller folder in Image-Line/FL Studio/Settings/Hardware (Don't change the name of this file or folder)\n\n## Step 2: Set up MCP for Claude\nFollow this tutorial to see how to setup MCP servers in Claude by edyting the claude_desktop_config files.\n\nhttps://modelcontextprotocol.io/quickstart/server\n\nIf you followed this process, make sure to change whatever mentions of weather.py to trigger.py\n\nIf the Hammer icon doesn't show up, open Task Manager and force close the Claude process.\n\nIt should then show up.\n\nThis is what my config file looks like\n\n![mcp](https://github.com/user-attachments/assets/e8e609f7-eaa4-469b-9140-c05b5a9bf242)\n\n## Step 3: Set Up Virtual MIDI Ports\n\n### For Windows\nFor Windows, download LoopMIDI from here.\n\nhttps://www.tobias-erichsen.de/software/loopmidi.html\n\nInstall LoopMIDI and add a port using the + button.\n\nThis is what mine looks like:\n![loopmidi2](https://github.com/user-attachments/assets/fdc2770f-e07a-4b19-824b-56de8a4aa2c3)\n\n### For Mac\nYour MIDI Ports would be automatically setup to receive data.\n\n## Step 4: Setup MIDI Controller\nOpen FL Studio.\n\nGo To Options > MIDI Settings.\n\nIn the Input Tab, click the MIDI Input you just created with LoopMIDI.\n\nChange controller type from (generic controller) to Test Controller.\n\n## Step 5: Download Packages\nGo to the folder with the trigger.py file. (This is the MCP Server file)\n\nActivate the conda environment (like you learned in the Claude MCP Setup Tutorial)\n\nRun this command to download the necessary packages: uv pip install httpx mido python-rtmidi typing fastmcp FL-Studio-API-Stubs\n(uv should be installed from the Claude MCP setup)\n\n## Step 6: Verify MCP Connection\nTell Claude to get available MIDI ports.\n\nThis should use the MCP to get the ports from FL Studio.\n\nIf Windows, copy the port you created with LoopMIDI and the number in front of it.\n\nIf Mac, copy the default port.\n\n![loopmidi](https://github.com/user-attachments/assets/a14b0aaa-5127-47c9-b041-fcb5a70339d9)\n\nIn my case, I copy loopMIDI Port 2\n\nOpen trigger.py in a text editor and replace the default port with the name of the port you just copied.\noutput_port = mido.open_output('loopMIDI Port 2') \n\n\n## Step 7: Make Music\nUse the MCP to send melodies, chords, drums, etc.\n\nClick on the instrument you want to record to and it will live record to the piano roll of that instrument.\n\nI tend to use this prompt when I start a new chat: Here is format for notes: note(0-127),velocity(0-100),length in beats(decimal),position in beats(decimal)\n\n## Step 8: Share what you made\nShare what you made on our Discord: https://discord.gg/ZjG9TaEhvy\n\n## Credits\nFL Studio API Stubs: https://github.com/IL-Group/FL-Studio-API-Stubs\nAbleton MCP: https://github.com/ahujasid/ableton-mcp\n\n## Nerd Stuff\nIf you want to contribute please go ahead. \n\nThe way this works is that device_test.py behaves as a virtual MIDI Controller.\nThe MCP server (trigger.py) communicates with this MIDI Controller by opening a Virtual Port and sending MIDI messages through a library called MIDO.\n\nThe issue with MIDI messages is that its only 7 bits so we can only send in number from 0-127.\n\nSo we encrypt all of our MIDI data like note position, etc in multiple MIDI notes that the device knows how to read.\n\nHopefully, Image Line can give us more access to their DAW via their API so we don't have to do this MIDI nonsense.\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "flstudio",
        "studio",
        "ai",
        "fl studio",
        "flstudio mcp",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    }
  }
}