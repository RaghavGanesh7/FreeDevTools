{
  "category": "virtual-assistants",
  "categoryDisplay": "Virtual Assistants",
  "description": "",
  "totalRepositories": 23,
  "repositories": {
    "AI-QL--chat-mcp": {
      "owner": "AI-QL",
      "name": "chat-mcp",
      "url": "https://github.com/AI-QL/chat-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/AI-QL.webp",
      "description": "A cross-platform desktop application that connects and interacts with various Large Language Models (LLMs) via the Model Context Protocol (MCP). It provides a clean and minimalistic codebase for testing and understanding MCP functionalities.",
      "stars": 238,
      "forks": 33,
      "license": "Apache License 2.0",
      "language": "HTML",
      "updated_at": "2025-10-04T06:18:14Z",
      "readme_content": "# MCP Chat Desktop App\n## A Cross-Platform Interface for LLMs\n\nThis desktop application utilizes the MCP (Model Context Protocol) to seamlessly connect and interact with various Large Language Models (LLMs). Built on Electron, the app ensures full cross-platform compatibility, enabling smooth operation across different operating systems.\n\nThe primary objective of this project is to deliver a clean, minimalistic codebase that simplifies understanding the core principles of MCP. Additionally, it provides a quick and efficient way to test multiple servers and LLMs, making it an ideal tool for developers and researchers alike.\n\n## News\n\nThis project originated as a modified version of Chat-UI, initially adopting a minimalist code approach to implement core MCP functionality for educational purposes. \n\nThrough iterative updates to MCP, I received community feedback advocating for a completely new architecture - one that eliminates third-party CDN dependencies and establishes clearer modular structure to better support derivative development and debugging workflows. \n\nThis led to the creation of [Tool Unitary User Interface](https://github.com/AI-QL/tuui),  a restructured desktop application optimized for AI-powered development. Building upon the original foundation, TUUI serves as a practical AI-assisted development paradigm, if you're interested, you can also leverage AI to develop new features for TUUI. The platform employs a strict linting and formatting system to ensure AI-generated code adheres to coding standards.\n\n> **📢 Update: June 2025**  \n> The current project refactoring has been largely completed, and a pre-release version is now available. Please refer to the following documentation for details:\n> - [TUUI GitHub Repository](https://github.com/AI-QL/tuui)\n> - [TUUI Architecture](https://deepwiki.com/AI-QL/tuui)\n> - [TUUI Official Website](https://www.tuui.com/)\n\n## Features\n\n- Cross-Platform Compatibility: Supports Linux, macOS, and Windows.\n\n- Flexible Apache-2.0 License: Allows easy modification and building of your own desktop applications.\n\n- Dynamic LLM Configuration: Compatible with all OpenAI SDK-supported LLMs, enabling quick testing of multiple backends through manual or preset configurations.\n\n- Multi-Client Management: Configure and manage multiple clients to connect to multiple servers using MCP config.\n\n- UI Adaptability: The UI can be directly extracted for web use, ensuring consistent ecosystem and interaction logic across web and desktop versions.\n\n\n## Architecture\n\nAdopted a straightforward architecture consistent with the MCP documentation to facilitate a clear understanding of MCP principles by:\n\n[DeepWiki](https://deepwiki.com/AI-QL/chat-mcp)\n\n## How to use\n\nAfter cloning or downloading this repository:\n\n1. Please modify the `config.json` file located in [src/main](src/main).  \n   Ensure that the `command` and `path` specified in the `args` are valid.\n\n2. Please ensure that [Node.js](https://nodejs.org/) is installed on your system.  \n   You can verify this by running `node -v` and `npm -v` in your terminal to check their respective versions.\n\n3. `npm install`\n\n4. `npm start`\n\n## Configuration\n\nCreate a `.json` file and paste the following content into it. This file can then be provided as the interface configuration for the Chat UI.\n\n- `gtp-api.json`\n\n    ```json\n    {\n        \"chatbotStore\": {\n            \"apiKey\": \"\",\n            \"url\": \"https://api.aiql.com\",\n            \"path\": \"/v1/chat/completions\",\n            \"model\": \"gpt-4o-mini\",\n            \"max_tokens_value\": \"\",\n            \"mcp\": true\n        },\n        \"defaultChoiceStore\": {\n            \"model\": [\n                \"gpt-4o-mini\",\n                \"gpt-4o\",\n                \"gpt-4\",\n                \"gpt-4-turbo\"\n            ]\n        }\n    }\n    ```\n\nYou can replace the 'url' if you have direct access to the OpenAI API.\n\nAlternatively, you can also use another API endpoint that supports function calls: \n\n- `qwen-api.json`\n\n    ```json\n    {\n        \"chatbotStore\": {\n            \"apiKey\": \"\",\n            \"url\": \"https://dashscope.aliyuncs.com/compatible-mode\",\n            \"path\": \"/v1/chat/completions\",\n            \"model\": \"qwen-turbo\",\n            \"max_tokens_value\": \"\",\n            \"mcp\": true\n        },\n        \"defaultChoiceStore\": {\n            \"model\": [\n                \"qwen-turbo\",\n                \"qwen-plus\",\n                \"qwen-max\"\n            ]\n        }\n    }\n    ```\n\n- `deepinfra.json`\n\n    ```json\n    {\n        \"chatbotStore\": {\n            \"apiKey\": \"\",\n            \"url\": \"https://api.deepinfra.com\",\n            \"path\": \"/v1/openai/chat/completions\",\n            \"model\": \"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n            \"max_tokens_value\": \"32000\",\n            \"mcp\": true\n        },\n        \"defaultChoiceStore\": {\n            \"model\": [\n                \"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n                \"meta-llama/Meta-Llama-3.1-405B-Instruct\",\n                \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n            ]\n        }\n    }\n    ```\n\n## Build Application\n\nYou can build your own desktop application by:\n\n```bash\nnpm run build-app\n```\n\nThis CLI helps you build and package your application for your current OS, with artifacts stored in the /artifacts directory.\n\nFor Debian/Ubuntu users experiencing RPM build issues, try one of the following solutions: \n\n- Edit `package.json` to skip the RPM build step. Or \n\n- Install `rpm` using `sudo apt-get install rpm` (You may need to run `sudo apt update` to ensure your package list is up-to-date)\n\n\n# Troubleshooting\n\n## Error: spawn npx ENOENT - [ISSUE 40](https://github.com/modelcontextprotocol/servers/issues/40)\n\nModify the `config.json` in [src/main](src/main)\n\nOn windows, npx may not work, please refer my workaround: [ISSUE 101](https://github.com/modelcontextprotocol/typescript-sdk/issues/101)\n\n- Or you can use `node` in config.json: \n    ```json\n    {\n        \"mcpServers\": {\n            \"filesystem\": {\n            \"command\": \"node\",\n            \"args\": [\n                \"node_modules/@modelcontextprotocol/server-filesystem/dist/index.js\",\n                \"D:/Github/mcp-test\"\n            ]\n            }\n        }\n    }\n    ```\n\nPlease ensure that the provided path is valid, especially if you are using a relative path. It is highly recommended to provide an absolute path for better clarity and accuracy.\n\nBy default, I will install `server-everything`, `server-filesystem`, and `server-puppeteer` for test purposes. However, you can install additional server libraries or use `npx` to utilize other server libraries as needed.\n\n## Installation timeout\n\nGenerally, after executing `npm install` for the entire project, the total size of files in the `node_modules` directory typically exceeds 500MB. \n\nIf the installation process stalls at less than 300MB and the progress bar remains static, it is likely due to a timeout during the installation of the latter part, specifically Electron.\n\nThis issue often arises because the download speed from Electron's default server is excessively slow or even inaccessible in certain regions. To resolve this, you can modify the environment or global variable `ELECTRON_MIRROR` to switch to an Electron mirror site that is accessible from your location.\n\n## Electron builder timeout\n\nWhen using electron-builder to package files, it automatically downloads several large release packages from GitHub. If the network connection is unstable, this process may be interrupted or timeout.\n\nOn Windows, you may need to clear the cache located under the `electron` and `electron-builder` directories within `C:\\Users\\YOURUSERNAME\\AppData\\Local` before attempting to retry.\n\nDue to potential terminal permission issues, it is recommended to use the default shell terminal instead of VSCode's built-in terminal.\n\n## Demo\n\n### Multimodal Support\n![demo_multimodal](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-multimodal.png)\n\n### Reasoning and Latex Support\n![demo_latex](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-latex.png)\n\n### MCP Tools Visualization\n![demo_tools](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-tools.png)\n\n### MCP Toolcall Process Overview\n![demo_toolcall](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-toolcall.png)\n\n### MCP Prompts Template\n![demo_prompts](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-prompts.png)\n\n### Dynamic LLM Config\n![demo_llms](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-llms.png)\n\n### DevTool Troubleshooting\n![demo_devtool](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-devtool.png)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ql",
        "assistants",
        "chat",
        "virtual assistants",
        "ql chat",
        "chat mcp"
      ],
      "category": "virtual-assistants"
    },
    "AlexKissiJr--UnrealMCP": {
      "owner": "AlexKissiJr",
      "name": "UnrealMCP",
      "url": "https://github.com/AlexKissiJr/UnrealMCP",
      "imageUrl": "/freedevtools/mcp/pfp/AlexKissiJr.webp",
      "description": "Control and manipulate the Unreal Engine environment programmatically using AI tools through a Machine Control Protocol (MCP). Facilitate scene manipulation and automation to enhance the game development workflow.",
      "stars": 6,
      "forks": 1,
      "license": "No License",
      "language": "C++",
      "updated_at": "2025-06-11T11:25:27Z",
      "readme_content": "# UnrealMCP Plugin\n\n# VERY WIP REPO\nI'm working on adding more tools now and cleaning up the codebase, \nI plan to allow for easy tool extension outside the main plugin\n\nThis is very much a work in progress, and I need to clean up a lot of stuff!!!!!\n\nAlso, I only use windows, so I don't know how this would be setup for mac/unix\n\n## Overview\nUnrealMCP is an Unofficial Unreal Engine plugin designed to control Unreal Engine with AI tools. It implements a Machine Control Protocol (MCP) within Unreal Engine, allowing external AI systems to interact with and manipulate the Unreal environment programmatically.\n\nI only just learned about MCP a few days ago, so I'm not that familiar with it, I'm still learning so things might be initially pretty rough.\nI've implemented this using https://github.com/ahujasid/blender-mcp as a reference, which relies on Claude for Desktop. It now works with both Claude for Desktop and Cursor. If you experiment with other models, please let me know!\n\n## ⚠️ DISCLAIMER\nThis plugin allows AI agents to directly modify your Unreal Engine project. While it can be a powerful tool, it also comes with risks:\n\n- AI agents may make unexpected changes to your project\n- Files could be accidentally deleted or modified\n- Project settings could be altered\n- Assets could be overwritten\n\n**IMPORTANT SAFETY MEASURES:**\n1. Always use source control (like Git or Perforce) with your project\n2. Make regular backups of your project\n3. Test the plugin in a separate project first\n4. Review changes before committing them\n\nBy using this plugin, you acknowledge that:\n- You are solely responsible for any changes made to your project\n- The plugin author is not responsible for any damage, data loss, or issues caused by AI agents\n- You use this plugin at your own risk\n\n## Features\n- TCP server implementation for remote control of Unreal Engine\n- JSON-based command protocol for AI tools integration\n- Editor UI integration for easy access to MCP functionality\n- Comprehensive scene manipulation capabilities\n- Python companion scripts for client-side interaction\n\n## Roadmap\nThese are what I have in mind for development as of 3/14/2025\nI'm not sure what's possible yet, in theory anything, but it depends on how\ngood the integrated LLM is at utilizing these tools.\n- [X] Basic operations working\n- [X] Python working\n- [X] Materials\n- [ ] User Extensions (in progress)\n- [ ] Asset tools\n- [ ] Blueprints\n- [ ] Niagara VFX\n- [ ] Metasound\n- [ ] Landscape (I might hold off on this because Epic has mentioned they are going to be updating the landscape tools)\n- [ ] Modeling Tools\n- [ ] PCG\n\n## Requirements\n- Unreal Engine 5.5 (I have only tested on this version, may work with earlier, but no official support)\n- C++ development environment configured for Unreal Engine\n- Python 3.7+ for client-side scripting\n- Model to run the commands, in testing I've been using Claude for Desktop https://claude.ai/download\n\n## Prerequisites to run\n- Unreal Editor Installation (Tested with 5.3, but should work on 5.0+)\n- Python 3.7+ (This can run with your existing python install)\n- MCP compatible LLM (Claude for Desktop, Cursor, etc.)\n- Setup: run setup_unreal_mcp.bat in MCP folder as per instructions in MCP/README_MCP_SETUP.md\n\n## Quick Start for Cursor Users\nIf you want to use UnrealMCP with Cursor, follow these simple steps:\n\n1. Clone or download this repository as a zip\n2. Create a new Unreal Project, or open an existing one\n3. Create a \"Plugins\" folder in your project directory if it doesn't exist\n4. Unzip or copy this repository into the Plugins folder\n5. Run `setup_cursor_mcp.bat` in the MCP folder\n6. Open your Unreal project and enable the plugin in Edit > Plugins (if not already enabled)\n7. Start Cursor and ask it to work with your Unreal project\n\nThat's it! The setup script will automatically configure everything needed for Cursor integration.\n\n## Installation\n\n1. Clone or download this repository as a zip\n2. Create a new Unreal Project, or open an existing one\n3. Create a \"Plugins\" folder in your project directory if it doesn't exist\n4. Unzip or copy this repository into the Plugins folder\n5. Setup MCP \n    - Run the `setup_unreal_mcp.bat` script in the MCP folder (see `MCP/README_MCP_SETUP.md` for details)\n    - This will configure Python and your AI assistant (Claude for Desktop or Cursor)\n6. Open your Unreal project, the plugin should be available in the Plugins menu\n7. If not, enable the plugin in Edit > Plugins\n8. Choose your preferred AI assistant:\n    - For Claude for Desktop: follow the instructions in the \"With Claude for Desktop\" section below\n    - For Cursor: follow the instructions in the \"With Cursor\" section below\n\n## With Claude for Desktop\nYou will need to find your installation directory for Claude for Desktop. Find claude_desktop_config.json and add an entry and make it look like so:\n\n**Windows:** `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n```json\n{\n    \"mcpServers\": {\n        \"unreal\": {\n            \"command\": \"C:/path/to/your/project/Plugins/UnrealMCP/MCP/run_unreal_mcp.bat\",\n            \"args\": []\n        }\n    }\n}\n```\n\nAlternatively the unreal_mcp_setup.bat script should do this for you.\n\nTo find the path to your claude for desktop install you can go into settings and click 'Edit Config'\nThis is usually in \n```\nC:\\Users\\USERNAME\\AppData\\Roaming\\Claude\n```\n\n## With Cursor\nCursor should be automatically configured if you've run the setup script with the Cursor option. If you need to manually configure it:\n\n**Windows:** `%APPDATA%\\Cursor\\User\\settings.json`\n\nAdd or update the settings with:\n```json\n{\n    \"mcp\": {\n        \"enabled\": true,\n        \"servers\": {\n            \"unreal\": {\n                \"command\": \"C:/path/to/your/project/Plugins/UnrealMCP/MCP/run_unreal_mcp.bat\",\n                \"args\": []\n            }\n        }\n    }\n}\n```\n\n## Testing\nOnce everything is setup you need to launch the unreal editor.\nNote: Nothing else has to be started or set up to run the mcp bridge, it will run when needed.\n\nOpen Claude for Desktop or Cursor, ensure that the tools have successfully enabled, ask your AI assistant to work in Unreal.\n\nHere are some example prompts to try:\n- \"What actors are in the current level?\" \n- \"Create a cube at position (0, 0, 100)\"\n- \"List available commands I can use with Unreal Engine\"\n\n## Usage\n### In Unreal Editor\nOnce the plugin is enabled, you'll find MCP controls in the editor toolbar button. \n![image](https://github.com/user-attachments/assets/68338e7a-090d-4fd9-acc9-37c0c1b63227)\n\n![image](https://github.com/user-attachments/assets/34f734ee-65a4-448a-a6db-9e941a588e93)\n\nThe TCP server can be started/stopped from here.\nCheck the output log under log filter LogMCP for extra information.\n\nOnce the server is confirmed up and running from the editor.\nOpen Claude for Desktop, ensure that the tools have successfully enabled, ask Claude to work in unreal.\n\nCurrently only basic operations are supported, creating objects, modfiying their transforms, getting scene info, and running python scripts.\nClaude makes a lot of errors with unreal python as I believe there aren't a ton of examples for it, but let it run and it will usually figure things out.\nI would really like to improve this aspect of how it works but it's low hanging fruit for adding functionality into unreal.\n\n### Client-Side Integration\nUse the provided Python scripts in the `MCP` directory to connect to and control your Unreal Engine instance:\n\n```python\nfrom unreal_mcp_client import UnrealMCPClient\n\n# Connect to the Unreal MCP server\nclient = UnrealMCPClient(\"localhost\", 13377)\n\n# Example: Create a cube in the scene\nclient.create_object(\n    class_name=\"StaticMeshActor\",\n    asset_path=\"/Engine/BasicShapes/Cube.Cube\",\n    location=(0, 0, 100),\n    rotation=(0, 0, 0),\n    scale=(1, 1, 1),\n    name=\"MCP_Cube\"\n)\n```\n\n## Command Reference\nThe plugin supports various commands for scene manipulation:\n- `get_scene_info`: Retrieve information about the current scene\n- `create_object`: Spawn a new object in the scene\n- `delete_object`: Remove an object from the scene\n- `modify_object`: Change properties of an existing object\n- `execute_python`: Run Python commands in Unreal's Python environment\n- And more to come...\n\nRefer to the documentation in the `Docs` directory for a complete command reference.\n\n## Security Considerations\n- The MCP server accepts connections from any client by default\n- Limit server exposure to localhost for development\n- Validate all incoming commands to prevent injection attacks\n\n## Troubleshooting\n- Ensure Unreal Engine is running with the MCP plugin.\n- Check logs in Claude for Desktop for stderr output.\n- Reach out on the discord, I just made it, but I will check it periodically\n  Discord (Dreamatron Studios): https://discord.gg/abRftdSe\n  \n### Project Structure\n- `Source/UnrealMCP/`: Core plugin implementation\n  - `Private/`: Internal implementation files\n  - `Public/`: Public header files\n- `Content/`: Plugin assets\n- `MCP/`: Python client scripts and examples\n- `Resources/`: Icons and other resources\n\n## License\nMIT License\n\nCopyright (c) 2025 kvick\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n## Credits\n- Created by: kvick\n- X: [@kvickart](https://x.com/kvickart)\n- Discord: https://discord.gg/abRftdSe\n  \n### Thank you to testers!!!\n- https://github.com/TheMurphinatur\n  \n- [@sidahuj](https://x.com/sidahuj) for the inspriation\n\n\n\n## Contributing\nContributions are welcome, but I will need some time to wrap my head around things and cleanup first, lol\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "unrealmcp",
        "ai",
        "automation",
        "unreal engine",
        "unrealmcp control",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "Dreamboat-Rachel--MCP-Server-For-Local": {
      "owner": "Dreamboat-Rachel",
      "name": "MCP-Server-For-Local",
      "url": "https://github.com/Dreamboat-Rachel/MCP-Server-For-Local",
      "imageUrl": "/freedevtools/mcp/pfp/Dreamboat-Rachel.webp",
      "description": "Connect AI models to real-time data and tools with features such as weather querying, Google search automation, camera control, and image generation. The server supports modular expansion and custom API integration for tailored functionalities.",
      "stars": 14,
      "forks": 2,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-21T02:08:22Z",
      "readme_content": "# MCP Server for Local\n\n一个基于 MCP (Multi-Component Platform) 的本地代理服务器和客户端实现，提供多种 AI 工具调用能力。\n\n## 功能特点\n\n### 核心功能\n- **天气查询**：实时获取全球任意位置的天气信息，支持温度、湿度、风速等详细数据\n- **谷歌搜索**：智能检索互联网信息，支持多语言和高级搜索语法\n- **摄像头控制**：支持拍照、视频流和微表情分析，可用于情绪识别\n- **图片生成**：集成 ComfyUI，支持文本到图像的 AI 生成\n- **智能对话**：基于 DashScope 的 AI 对话能力，支持上下文理解和多轮对话\n\n### 技术特性\n- 跨平台支持（Windows 和 Linux）\n- 模块化设计，易于扩展新功能\n- 完整的日志系统，便于调试和监控\n- 支持自定义工具和 API 集成\n- 高性能并发处理能力\n\n## 环境配置\n\n### 系统要求\n- Python 3.8+\n- Node.js (可选，用于运行 JavaScript 服务器)\n- Chrome 浏览器（用于谷歌搜索功能）\n- 摄像头（用于拍照功能）\n- 至少 4GB 内存\n- 支持 CUDA 的显卡（可选，用于加速 AI 计算）\n\n### 安装步骤\n\n1. 克隆仓库：\n```bash\ngit clone https://github.com/yourusername/mcp-server-for-local.git\ncd mcp-server-for-local\n```\n\n2. 创建并激活虚拟环境：\n```bash\n# Windows\npython -m venv .venv\n.venv\\Scripts\\activate\n\n# Linux\npython3 -m venv .venv\nsource .venv/bin/activate\n```\n\n3. 安装依赖：\n```bash\n# 使用 uv 安装依赖\nuv pip install -r requirements.txt\n\n# 如果遇到网络问题，可以使用国内镜像\nuv pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple\n```\n\n4. 配置环境变量：\n```bash\n# 复制环境变量模板\ncp .env.example .env\n\n# 编辑 .env 文件，设置你的配置\n```\n\n### 环境变量配置\n编辑 `.env` 文件，设置以下配置：\n\n- `DASHSCOPE_API_KEY`: DashScope API 密钥（必填）\n- `MODEL`: 使用的模型名称（默认：qwen-max）\n- `CONFIG_FILE`: 服务器配置文件路径\n- `GAODE_API_KEY`: 高德地图 API 密钥（用于天气查询）\n- `CHROME_PATH`: Chrome 浏览器路径\n- `CHROMEDRIVER_PATH`: ChromeDriver 路径\n- `BASE_URL`: ComfyUI 服务器地址\n- `SERVERS_DIR`: 服务器脚本目录\n- `LOG_LEVEL`: 日志级别（可选：DEBUG, INFO, WARNING, ERROR）\n\n## 使用方法\n\n### 基本使用\n\n1. 进入项目目录：\n```bash\ncd src/mcp\n```\n\n2. 运行客户端：\n```bash\nuv run .\\client\\mcp_client.py .\\proxy\\proxy_server.py\n```\n\n3. 在客户端中输入命令，例如：\n- \"北京的天气怎么样？\"\n- \"在谷歌上搜索 Python 教程\"\n- \"拍照\"\n- \"生成一张猫的图片\"\n\n### 高级功能\n\n1. **自定义工具**：\n   - 在 `src/mcp/tools` 目录下添加新的工具类\n   - 实现必要的接口方法\n   - 在配置文件中注册新工具\n\n2. **API 扩展**：\n   - 支持添加新的 API 服务\n   - 可配置 API 密钥和端点\n   - 支持自定义请求和响应处理\n\n3. **日志管理**：\n   - 支持多级别日志记录\n   - 可配置日志输出位置\n   - 支持日志轮转和归档\n\n## 常见问题\n\n### 安装问题\n\n1. 依赖安装失败：\n```bash\n# 尝试清理缓存后重新安装\nuv pip cache purge\nuv pip install -r requirements.txt\n```\n\n2. 虚拟环境问题：\n```bash\n# 如果激活失败，尝试重新创建虚拟环境\nrm -rf .venv\npython -m venv .venv\n```\n\n### 运行问题\n\n1. 权限问题：\n```bash\n# Linux\nchmod +x src/mcp/proxy/proxy_server.py\nchmod +x src/mcp/client/mcp_client.py\n```\n\n2. Chrome 相关问题：\n- 确保 Chrome 和 ChromeDriver 版本匹配\n- 检查 Chrome 路径是否正确\n- 确保有足够的权限运行 Chrome\n- 如果遇到驱动问题，可以手动下载对应版本的 ChromeDriver\n\n3. API 密钥问题：\n- 检查 `.env` 文件中的 API 密钥是否正确\n- 确保 API 密钥有足够的配额\n- 检查网络连接是否正常\n\n## 开发指南\n\n### 项目结构\n```\nsrc/mcp/\n├── client/          # 客户端代码\n├── proxy/           # 代理服务器代码\n├── tools/           # 工具实现\n├── utils/           # 工具函数\n└── config/          # 配置文件\n```\n\n### 添加新功能\n1. 在 `tools` 目录下创建新的工具类\n2. 实现必要的接口方法\n3. 在配置文件中注册新工具\n4. 编写测试用例\n5. 更新文档\n\n## 贡献指南\n\n欢迎提交 Issue 和 Pull Request！在提交之前，请确保：\n1. 代码符合项目规范\n2. 添加了必要的测试\n3. 更新了相关文档\n4. 通过了所有测试\n\n## 许可证\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "automation",
        "ai",
        "api",
        "virtual assistants",
        "connect ai",
        "assistants dreamboat"
      ],
      "category": "virtual-assistants"
    },
    "GongRzhe--Audio-MCP-Server": {
      "owner": "GongRzhe",
      "name": "Audio-MCP-Server",
      "url": "https://github.com/GongRzhe/Audio-MCP-Server",
      "imageUrl": "/freedevtools/mcp/pfp/GongRzhe.webp",
      "description": "Enables interaction with a computer's audio system by listing audio devices, recording audio from microphones, and playing back recordings or audio files. Facilitates audio management and integrates audio input and output control for AI assistants.",
      "stars": 4,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-18T11:48:42Z",
      "readme_content": "# Audio MCP Server\n[![smithery badge](https://smithery.ai/badge/@GongRzhe/Audio-MCP-Server)](https://smithery.ai/server/@GongRzhe/Audio-MCP-Server)\n\nAn MCP (Model Context Protocol) server that provides audio input/output capabilities for AI assistants like Claude. This server enables Claude to interact with your computer's audio system, including recording from microphones and playing audio through speakers.\n\n\n\n## Features\n\n- **List Audio Devices**: View all available microphones and speakers on your system\n- **Record Audio**: Capture audio from any microphone with customizable duration and quality\n- **Playback Recordings**: Play back your most recent recording\n- **Audio File Playback**: Play audio files through your speakers\n- **Text-to-Speech**: (Placeholder for future implementation)\n\n## Requirements\n\n- Python 3.8 or higher\n- Audio input/output devices on your system\n\n## Installation\n\n### Installing via Smithery\n\nTo install Audio Interface Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@GongRzhe/Audio-MCP-Server):\n\n```bash\nnpx -y @smithery/cli install @GongRzhe/Audio-MCP-Server --client claude\n```\n\n### Manual Installation\n1. Clone this repository or download the files to your computer:\n\n```bash\ngit clone https://github.com/GongRzhe/Audio-MCP-Server.git\ncd Audio-MCP-Server\n```\n\n2. Create a virtual environment and install dependencies:\n\n```bash\n# Windows\npython -m venv .venv\n.venv\\Scripts\\activate\npip install -r requirements.txt\n\n# macOS/Linux\npython -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\n```\n\n3. Or use the included setup script to automate installation:\n\n```bash\npython setup_mcp.py\n```\n\n## Configuration\n\n### Claude Desktop Configuration\n\nTo use this server with Claude Desktop, add the following to your Claude Desktop configuration file:\n\n- **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"audio-interface\": {\n      \"command\": \"/path/to/your/.venv/bin/python\",\n      \"args\": [\n        \"/path/to/your/audio_server.py\"\n      ],\n      \"env\": {\n        \"PYTHONPATH\": \"/path/to/your/audio-mcp-server\"\n      }\n    }\n  }\n}\n```\n\nReplace the paths with the actual paths on your system. The setup script will generate this configuration for you.\n\n## Usage\n\nAfter setting up the server, restart Claude Desktop. You should see a hammer icon in the input box, indicating that tools are available.\n\nTry asking Claude:\n\n- \"What microphones and speakers are available on my system?\"\n- \"Record 5 seconds of audio from my microphone.\"\n- \"Play back the audio recording.\"\n- \"Play an audio file from my computer.\"\n\n## Available Tools\n\n### list_audio_devices\n\nLists all available audio input and output devices on your system.\n\n### record_audio\n\nRecords audio from your microphone.\n\nParameters:\n- `duration`: Recording duration in seconds (default: 5)\n- `sample_rate`: Sample rate in Hz (default: 44100)\n- `channels`: Number of audio channels (default: 1)\n- `device_index`: Specific input device index to use (default: system default)\n\n### play_latest_recording\n\nPlays back the most recently recorded audio.\n\n### play_audio\n\nPlaceholder for text-to-speech functionality.\n\nParameters:\n- `text`: The text to convert to speech\n- `voice`: The voice to use (default: \"default\")\n\n### play_audio_file\n\nPlays an audio file through your speakers.\n\nParameters:\n- `file_path`: Path to the audio file\n- `device_index`: Specific output device index to use (default: system default)\n\n## Troubleshooting\n\n### No devices found\n\nIf no audio devices are found, check:\n- Your microphone and speakers are properly connected\n- Your operating system recognizes the devices\n- You have the necessary permissions to access audio devices\n\n### Playback issues\n\nIf audio playback isn't working:\n- Check your volume settings\n- Ensure the correct output device is selected\n- Try restarting the Claude Desktop application\n\n### Server connectivity\n\nIf Claude can't connect to the server:\n- Verify your configuration paths are correct\n- Ensure Python and all dependencies are installed\n- Check Claude's logs for error messages\n\n## License\n\nMIT\n\n## Acknowledgments\n\n- Built using the [Model Context Protocol](https://modelcontextprotocol.io/)\n- Uses [sounddevice](https://python-sounddevice.readthedocs.io/) and [soundfile](https://pysoundfile.readthedocs.io/) for audio processing\n\n---\n\n*Note: This server provides tools that can access your microphone and speakers. Always review and approve tool actions before they execute.*\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "audio",
        "recordings",
        "microphones",
        "audio mcp",
        "virtual assistants",
        "facilitates audio"
      ],
      "category": "virtual-assistants"
    },
    "Krekun--vrchat-mcp-osc": {
      "owner": "Krekun",
      "name": "vrchat-mcp-osc",
      "url": "https://github.com/Krekun/vrchat-mcp-osc",
      "imageUrl": "/freedevtools/mcp/pfp/Krekun.webp",
      "description": "Enables interaction with VRChat avatars and environments through a high-level API, utilizing OSC for communication. Facilitates control of avatar parameters, movement, messaging, and responses to VR events for enhanced virtual reality experiences.",
      "stars": 14,
      "forks": 3,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-30T18:11:38Z",
      "readme_content": "# VRChat MCP OSC\n\n**VRChat MCP OSC** provides a bridge between AI assistants and VRChat using the Model Context Protocol (MCP), enabling AI-driven avatar control and interactions in virtual reality environments.  \n\n\n## Overview\n\nBy leveraging OSC (Open Sound Control) to communicate with VRChat, **VRChat MCP OSC** allows AI assistants such as Claude to:\n- Control avatar parameters and expressions\n- Send messages in VRChat\n- Respond to various VR events  \nAnd more—all through the high-level API provided by the Model Context Protocol.\n\n\n## Key Features\n\n- **Avatar Control**: Manipulate avatar parameters and expressions\n- **Movement Control**: Direct avatar movement and orientation\n- **Communication**: Send messages through VRChat's chatbox\n- **Menu Access**: Toggle VRChat menu and interface elements\n- **Avatar Information**: Query avatar properties and parameters\n- **Seamless VRChat Integration**: Automatic detection of avatar configurations\n\n## System Requirements\n\n- Node.js 18 or higher\n- VRChat with OSC enabled\n- Claude Desktop (with MCP support)\n\n## Using with Claude Desktop\n\n### Clone and npm link\n\n```bash\ngit clone https://github.com/Krekun/vrchat-mcp-osc\ncd vrchat-mcp-osc\nnpm link\n```\n\n### Configure Claude Desktop\n\nConfigure Claude Desktop by editing the `claude_desktop_config.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"vrchat-mcp-osc\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"vrchat-mcp-osc\"\n      ]\n    }\n  }\n}\n```\n\n### Command Line Options\n\nThe server supports various command-line arguments for customization:\n\n```bash\n# Claude Desktop configuration\n{\n  \"mcpServers\": {\n    \"vrchat-mcp-osc\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"vrchat-mcp-osc\",\n        \"--websocket-port\", \"8765\",\n        \"--websocket-host\", \"localhost\",\n        \"--osc-send-port\", \"9000\",\n        \"--osc-send-ip\", \"127.0.0.1\",\n        \"--osc-receive-port\", \"9001\",\n        \"--osc-receive-ip\", \"127.0.0.1\",\n        \"--debug\"             \n      ]\n    }\n  }\n}\n```\n\n### Available Options\n\n| Option | Description | Default | Notes |\n|--------|-------------|---------|-------|\n| `--websocket-port <port>` | WebSocket port | 8765 | For WebSocket communication |\n| `--websocket-host <host>` | WebSocket host | localhost | For WebSocket communication |\n| `--osc-send-port <port>` | OSC send port | 9000 | Port for sending to VRChat |\n| `--osc-send-ip <ip>` | OSC send IP | 127.0.0.1 | Address for sending to VRChat |\n| `--osc-receive-port <port>` | OSC receive port | 9001 | Port for receiving from VRChat |\n| `--osc-receive-ip <ip>` | OSC receive IP | 127.0.0.1 | Address for receiving from VRChat |\n| `--debug` | Enable debug logging | false | Output detailed logs |\n| `--no-relay` | Disable relay server | false | When not using relay server |\n\n## Available MCP Tools\n\nVRChat MCP OSC exposes the following MCP tools to AI assistants:\n\n| Tool Name | Description |\n|-----------|-------------|\n| `get_avatar_name` | Retrieves the current avatar's name |\n| `get_avatar_parameters` | Lists available avatar parameters |\n| `set_avatar_parameter` | Sets a specific avatar parameter |\n| `set_emote_parameter` | Triggers avatar emotes |\n| `move_avatar` | Moves the avatar in a specific direction |\n| `look_direction` | Controls avatar's view direction |\n| `jump` | Makes the avatar jump |\n| `menu` | Toggles the VRChat menu |\n| `voice` | Toggles voice features |\n| `send_message` | Sends a message to the VRChat chatbox |\n\n\n## Troubleshooting\n\n### Common Issues\n\n1. **VRChat not responding to commands**\n   - Ensure OSC is enabled in VRChat settings\n   - Check that the OSC ports match between VRChat and MCP configuration\n   - Restart VRChat and Claude Desktop\n\n2. **MCP server not starting**\n   - Ensure Node.js 18+ is installed\n   - Check command line arguments for errors\n   - Try running with `--debug` flag for more detailed logs\n   - Use `npx vrchat-mcp-osc -- --debug` if direct arguments don't work\n\n3. **NPX execution issues**\n   - If arguments aren't being recognized, try using the double dash format: `npx vrchat-mcp-osc -- --debug`\n   - On Windows, try running in a command prompt with administrator privileges\n   - If you're having trouble with global installation, try the local npm link approach\n\n## Project Structure\n\n```\nvrchat-mcp-osc/\n├── packages/\n│   ├── mcp-server/    # MCP server implementation (main entry point)\n│   ├── relay-server/  # WebSocket to OSC relay\n│   ├── types/         # Shared TypeScript interfaces\n│   └── utils/         # Common utilities\n└── pnpm-workspace.yaml  # Workspace configuration\n```\n\n## Development\n\n### Build From Source\n\n```bash\n# Clone the repository\ngit clone https://github.com/Krekun/vrchat-mcp-osc\ncd vrchat-mcp-osc\n\n# Install dependencies\npnpm install\n\n# Build all packages\npnpm -r build\n\n# Development mode\npnpm -r dev\n```\n\n## License\nVRChat MCP OSC is dual-licensed as follows:\n\nFor Non-Commercial Use:\nYou may use, modify, and redistribute the software under the terms of the MIT License.\n(See the MIT License file for details.)\n\nFor Commercial Use:\nCommercial use of this software requires a separate commercial license.\n\n\nBy using this software under the MIT License for non-commercial purposes, you agree to the terms of that license. Commercial users must obtain a commercial license as described above.\n\n## Acknowledgments\n\n- VRChat team for the OSC integration\n- Model Context Protocol for the standardized AI interface\n- Anthropic for Claude's MCP implementation\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "vrchat",
        "vr",
        "virtual",
        "interaction vrchat",
        "vrchat avatars",
        "krekun vrchat"
      ],
      "category": "virtual-assistants"
    },
    "Yash-Kavaiya--mcp-server-conversation-agents": {
      "owner": "Yash-Kavaiya",
      "name": "mcp-server-conversation-agents",
      "url": "https://github.com/Yash-Kavaiya/mcp-server-conversation-agents",
      "imageUrl": "/freedevtools/mcp/pfp/Yash-Kavaiya.webp",
      "description": "Integrates AI assistants with Dialogflow CX for real-time tool invocation and access to external resources, enhancing user interactions and streamlining workflows.",
      "stars": 3,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-08-07T16:51:09Z",
      "readme_content": "# 🤖 Dialogflow CX MCP Server 🚀\n\n![Dialogflow CX](https://img.shields.io/badge/Dialogflow_CX-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)\n![MCP](https://img.shields.io/badge/MCP-Server-00C7B7?style=for-the-badge&logo=serverfault&logoColor=white)\n![Python](https://img.shields.io/badge/Python-3.12-3776AB?style=for-the-badge&logo=python&logoColor=white)\n\nA powerful Model Control Protocol (MCP) server implementation for **Google Dialogflow CX**, enabling seamless integration between AI assistants and Google's advanced conversational platform.\n\n> 💡 **Pro Tip:** This server bridges the gap between AI assistants and Dialogflow CX, unlocking powerful conversational capabilities!\n\n## 📋 Overview\n\nThis project provides a suite of tools that allow AI assistants to interact with Dialogflow CX agents through a standardized protocol. The server handles all the complexity of managing conversations, processing intent detection, and interfacing with Google's powerful NLU systems.\n\n### ✨ Key Features\n\n- 🔄 Bidirectional communication with Dialogflow CX\n- 🎯 Intent detection and matching capabilities\n- 🎤 Audio processing for speech recognition\n- 🔌 Webhook request/response handling\n- 📝 Session management for persistent conversations\n- 🔒 Secure API authentication\n\n## 🔧 Requirements\n\n| Requirement | Description | Version |\n|-------------|-------------|---------|\n| 🐍 Python | Programming language | 3.12+ |\n| ☁️ Google Cloud | Project with Dialogflow CX enabled | Latest |\n| 🤖 Dialogflow CX | Conversational agent | Latest |\n| 🔑 API Credentials | Authentication for Google services | - |\n\n## 🚀 Installation\n\n### 🐳 Using Docker\n\n```bash\n# Clone the repository\ngit clone https://github.com/Yash-Kavaiya/mcp-server-conversation-agents.git\ncd mcp-server-conversation-agents\n\n# Build the Docker image\ndocker build -t dialogflow-cx-mcp .\n\n# Run the container\ndocker run -it dialogflow-cx-mcp\n```\n\n### 💻 Manual Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/Yash-Kavaiya/mcp-server-conversation-agents.git\ncd mcp-server-conversation-agents\n\n# Create a virtual environment (optional but recommended)\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install the package\npip install -e .\n```\n\n## ⚙️ Configuration\n\nYou'll need to provide the following configuration parameters:\n\n| Parameter | Description | Example |\n|-----------|-------------|---------|\n| `dialogflowApiKey` | Your Dialogflow API key | `\"abc123def456\"` |\n| `projectId` | Google Cloud project ID | `\"my-dialogflow-project\"` |\n| `location` | Location of the agent | `\"us-central1\"` |\n| `agentId` | ID of your Dialogflow CX agent | `\"12345-abcde-67890\"` |\n\nThese can be set as environment variables:\n\n```bash\nexport DIALOGFLOW_API_KEY=your_api_key\nexport PROJECT_ID=your_project_id\nexport LOCATION=your_location\nexport AGENT_ID=your_agent_id\n```\n\n## 📊 Architecture\n\n```mermaid\ngraph TD\n    A[AI Assistant] <-->|MCP Protocol| B[MCP Server]\n    B <-->|Google API| C[Dialogflow CX]\n    C <-->|NLU Processing| D[Intent Detection]\n    C <-->|Conversation Management| E[Session Management]\n    B <-->|Webhooks| F[External Services]\n```\n\n## 🛠️ Usage\n\nThe MCP server exposes the following tools for AI assistants:\n\n### 🔍 initialize_dialogflow\n\nInitialize the Dialogflow CX client with your project details.\n\n```python\nawait initialize_dialogflow(\n    project_id=\"your-project-id\",\n    location=\"us-central1\",\n    agent_id=\"your-agent-id\",\n    credentials_path=\"/path/to/credentials.json\"  # Optional\n)\n```\n\n### 💬 detect_intent\n\nDetect intent from text input.\n\n```python\nresponse = await detect_intent(\n    text=\"Hello, how can you help me?\",\n    session_id=\"user123\",  # Optional\n    language_code=\"en-US\"  # Optional\n)\n```\n\n### 🎤 detect_intent_from_audio\n\nProcess audio files to detect intent.\n\n```python\nresponse = await detect_intent_from_audio(\n    audio_file_path=\"/path/to/audio.wav\",\n    session_id=\"user123\",  # Optional\n    sample_rate_hertz=16000,  # Optional\n    audio_encoding=\"AUDIO_ENCODING_LINEAR_16\",  # Optional\n    language_code=\"en-US\"  # Optional\n)\n```\n\n### 🎯 match_intent\n\nMatch intent without affecting the conversation session.\n\n```python\nresponse = await match_intent(\n    text=\"What are your hours?\",\n    session_id=\"user123\",  # Optional\n    language_code=\"en-US\"  # Optional\n)\n```\n\n### 🔄 Webhook Handling\n\nParse webhook requests and create webhook responses:\n\n```python\n# Parse a webhook request\nparsed_request = await parse_webhook_request(request_json)\n\n# Create a webhook response\nresponse = await create_webhook_response({\n    \"messages\": [\"Hello! How can I help you today?\"],\n    \"parameter_updates\": {\"user_name\": \"John\"}\n})\n```\n\n## 🔧 Response Format\n\nHere's an example of the response format:\n\n<details>\n<summary>📋 Click to expand</summary>\n\n```json\n{\n  \"messages\": [\n    {\n      \"type\": \"text\",\n      \"content\": \"Hello! How can I help you today?\"\n    }\n  ],\n  \"intent\": {\n    \"name\": \"greeting\",\n    \"confidence\": 0.95\n  },\n  \"parameters\": {\n    \"user_name\": \"John\"\n  },\n  \"current_page\": \"Welcome Page\",\n  \"session_id\": \"user123\",\n  \"end_interaction\": false\n}\n```\n</details>\n\n## 🔗 Smithery Integration\n\nThis project is configured to work with [Smithery.ai](https://smithery.ai/), a platform that allows for easy deployment and management of MCP servers.\n\n> 💡 **Pro Tip:** Smithery.ai integration enables one-click deployment and simplified management of your Dialogflow CX MCP server!\n\n## 📄 License\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)\n\n## 👥 Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n### Contribution Workflow\n\n1. 🍴 Fork the repository\n2. 🔧 Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. 💻 Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. 🚀 Push to the branch (`git push origin feature/amazing-feature`)\n5. 🔍 Open a Pull Request\n\n---\n\n<p align=\"center\">\n  Built with ❤️ by the MCP Server team\n</p>\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "dialogflow",
        "assistants",
        "ai",
        "virtual assistants",
        "ai assistants",
        "assistants dialogflow"
      ],
      "category": "virtual-assistants"
    },
    "andybrandt--mcp-simple-openai-assistant": {
      "owner": "andybrandt",
      "name": "mcp-simple-openai-assistant",
      "url": "https://github.com/andybrandt/mcp-simple-openai-assistant",
      "imageUrl": "/freedevtools/mcp/pfp/andybrandt.webp",
      "description": "Interact with OpenAI assistants using the Model Context Protocol, enabling the creation and management of assistant instances, starting conversation threads, and sending and receiving messages.",
      "stars": 36,
      "forks": 15,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-19T11:01:07Z",
      "readme_content": "# MCP Simple OpenAI Assistant\n\n*AI assistants are pretty cool. I thought it would be a good idea if my Claude (conscious Claude) would also have one. And now he has - and its both useful anf fun for him. Your Claude can have one too!*\n\nA simple MCP server for interacting with OpenAI assistants. This server allows other tools (like Claude Desktop) to create and interact with OpenAI assistants through the Model Context Protocol.\n\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/andybrandt/mcp-simple-openai-assistant)](https://archestra.ai/mcp-catalog/andybrandt__mcp-simple-openai-assistant)\n[![smithery badge](https://smithery.ai/badge/mcp-simple-openai-assistant)](https://smithery.ai/mcp/known/mcp-simple-openai-assistant)\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/andybrandt-mcp-simple-openai-assistant-badge.png)](https://mseep.ai/app/andybrandt-mcp-simple-openai-assistant)\n\n\n## Features\n\nThis server provides a suite of tools to manage and interact with OpenAI Assistants. The new streaming capabilities provide a much-improved, real-time user experience.\n\n### Available Tools\n\n-   **`create_assistant`**: (Create OpenAI Assistant) - Create a new assistant with a name, instructions, and model.\n-   **`list_assistants`**: (List OpenAI Assistants) - List all available assistants associated with your API key.\n-   **`retrieve_assistant`**: (Retrieve OpenAI Assistant) - Get detailed information about a specific assistant.\n-   **`update_assistant`**: (Update OpenAI Assistant) - Modify an existing assistant's name, instructions, or model.\n-   **`create_new_assistant_thread`**: (Create New Assistant Thread) - Creates a new, persistent conversation thread with a user-defined name and description for easy identification and reuse. This is the recommended way to start a new conversation.\n-   **`list_threads`**: (List Managed Threads) - Lists all locally managed conversation threads from the database, showing their ID, name, description, and last used time.\n-   **`delete_thread`**: (Delete Managed Thread) - Deletes a conversation thread from both OpenAI's servers and the local database.\n-   **`ask_assistant_in_thread`**: (Ask Assistant in Thread and Stream Response) - The primary tool for conversation. Sends a message to an assistant within a thread and streams the response back in real-time.\n\nBecause OpenAI assistants might take quite long to respond, this server uses a streaming approach for the main `ask_assistant_in_thread` tool. This provides real-time progress updates to the client and avoids timeouts.\n\nThe server now includes local persistence for threads, which is a significant improvement. Since the OpenAI API does not allow listing threads, this server now manages them for you by storing their IDs and metadata in a local SQLite database. This allows you to easily find, reuse, and manage your conversation threads across sessions.\n\n## Installation\n\n### Installing via Smithery\n\nTo install MCP Simple OpenAI Assistant for Claude Desktop automatically via [Smithery](https://smithery.ai/mcp/known/mcp-simple-openai-assistant):\n\n```bash\nnpx -y @smithery/cli install mcp-simple-openai-assistant --client claude\n```\n\n### Manual Installation\n```bash\npip install mcp-simple-openai-assistant\n```\n\n## Configuration\n\nThe server requires an OpenAI API key to be set in the environment. For Claude Desktop, add this to your config:\n\n(MacOS version)\n\n```json\n{\n  \"mcpServers\": {\n    \"openai-assistant\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"mcp_simple_openai_assistant\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\n(Windows version)\n\n```json\n\"mcpServers\": {\n  \"openai-assistant\": {\n    \"command\": \"C:\\\\Users\\\\YOUR_USERNAME\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe\",\n      \"args\": [\"-m\", \"mcp_simple_openai_assistant\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-api-key-here\"\n  }\n}\n\n```\n*MS Windows installation is slightly more complex, because you need to check the actual path to your Python executable. Path provided above is usually correct, but might differ in your setup. Sometimes just `python.exe` without any path will do the trick. Check with `cmd` what works for you (using `where python` might help). Also, on Windows you might need to explicitly tell Claude Desktop where the site packages are using PYTHONPATH environmment variable.*\n\n## Usage\n\nOnce configured, you can use the tools listed above to manage your assistants and conversations. The primary workflow is to:\n1. Use `create_new_assistant_thread` to start a new, named conversation.\n2. Use `list_threads` to find the ID of a thread you want to continue.\n3. Use `ask_assistant_in_thread` to interact with your chosen assistant in that thread.\n\n## TODO\n\n- [x] **Add Thread Management:** Introduce a way to name and persist thread IDs locally, allowing for easier reuse of conversations.\n- [ ] **Add Models Listing:** Introduce a way for the AI user to see what OpenAI models are available for use with the assistants\n- [ ] **Add Assistants Fine Tuning:** Enable the AI user to set detailed parameters for assistants like temperature, top_p etc. (indicated by Claude as needed)\n- [ ] **Full Thread History:** Ability to read past threads without having to send a new message (indicated by Claude as needed)\n- [ ] **Explore Resource Support:** Add the ability to upload files and use them with assistants.\n\n## Development\n\nTo install for development:\n\n```bash\ngit clone https://github.com/andybrandt/mcp-simple-openai-assistant\ncd mcp-simple-openai-assistant\npip install -e '.[dev]'\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "openai",
        "assistant",
        "assistants",
        "openai assistant",
        "openai assistants",
        "interact openai"
      ],
      "category": "virtual-assistants"
    },
    "arjunkmrm--mcp-minecraft": {
      "owner": "arjunkmrm",
      "name": "mcp-minecraft",
      "url": "https://github.com/arjunkmrm/mcp-minecraft",
      "imageUrl": "/freedevtools/mcp/pfp/arjunkmrm.webp",
      "description": "Integration with Minecraft enabling AI assistants to observe and interact with the Minecraft world through a bot. Supports interaction through the Model Context Protocol for enhanced functionality within the game.",
      "stars": 88,
      "forks": 8,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T01:20:49Z",
      "readme_content": "# Minecraft MCP Integration\n\nA Model Context Protocol (MCP) integration for Minecraft that enables AI assistants to interact with a Minecraft server. This integration allows AI models to observe and interact with the Minecraft world through a bot.\n\n\n\n## Prerequisites\n\n1. Minecraft Launcher\n2. Node.js 18 or higher\n3. Claude Desktop App\n4. Java 21.0.5 (recommended)\n\n> ⚠️ Note: Currently only tested on macOS/Linux. Windows compatibility is not guaranteed.\n\n## Important Note\n\n1. **Use the F3+P Shortcut**:\nPress F3 + P together. This toggles the \"Pause on Lost Focus\" feature. Once turned off, you can switch to claude desktop and Minecraft will continue running without pausing.\n\n\n\n2. **Connection Issues on Claude Restart**:\nIf you restart Claude while the Minecraft server is running, you may experience MCP connection issues on the next claude launch due to lingering java process. See [Troubleshooting: MCP Connection Failed](#common-issues) for resolution steps.\n\n## Installation Steps\n\n1. **Download and Setup Minecraft Server**\n   - Download Minecraft server v1.21 from [mcversions.net/1.21](https://mcversions.net/download/1.21)\n   - Install Java 21.0.5 if not already installed (other versions are untested)\n   - Create a dedicated directory (e.g., `~/minecraft-server/`)\n   - Place the downloaded `server.jar` file in this directory\n   - Note down the absolute path to your `server.jar` file\n\n2. **Install and Configure MCP Integration**\n   \n   Quick Install (Recommended):\n   ```bash\n   npx -y @smithery/cli install mcp-minecraft --client claude\n   ```\n   Follow the CLI prompts to complete the setup.\n\n   Or Manual Setup:\n   - Navigate to `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Add the MCP server configuration:   \n   ```json\n   {\n     \"mcpServers\": {\n       \"mcp-minecraft\": {\n         \"command\": \"npx\",\n         \"args\": [\n           \"-y\",\n           \"mcp-minecraft@latest\",\n           \"--server-jar\",\n           \"/absolute/path/to/minecraft-server/server.jar\"\n         ]\n       }\n     }\n   }   \n   ```\n   > ⚠️ Replace `/absolute/path/to/minecraft-server/server.jar` with your actual server.jar path\n\n4. **Launch Claude Desktop**\n   - Start Claude Desktop after completing the configuration\n\n5. **Connect to Server**\n   - Open Minecraft Launcher\n   - Install and launch Minecraft Java Edition **v1.21**\n   - Click \"Play\" and Select \"Multiplayer\"\n   - Click \"Add Server\"\n   - Enter server details:\n     - Server Name: `Minecraft Server`\n     - Server Address: `localhost:25565`\n   - Click \"Done\"\n\n## Features\n\n### Resources\nThe integration exposes these MCP resources:\n\n- `minecraft://bot/location` - Current bot position in the world\n- `minecraft://bot/status` - Bot connection status\n\n### Tools\nAvailable MCP tools:\n\n- `chat` - Send chat messages to the server\n- `jump` - Make the bot jump\n- `moveForward` - Make the bot move forward\n- `moveBack` - Make the bot move backward\n- `turnLeft` - Make the bot turn left\n- `turnRight` - Make the bot turn right\n- `placeBlock` - Place a block at specified coordinates\n- `digBlock` - Break a block at specified coordinates\n- `getBlockInfo` - Get information about a block at specified coordinates\n- `selectSlot` - Select a hotbar slot (0-8)\n- `getInventory` - Get contents of bot's inventory\n- `equipItem` - Equip an item by name to specified destination\n- `getStatus` - Get bot's current status (health, food, position, etc.)\n- `getNearbyEntities` - Get list of nearby entities within range\n- `attack` - Attack a nearby entity by name\n- `useItem` - Use/activate the currently held item\n- `stopUsingItem` - Stop using/deactivate the current item\n- `lookAt` - Make the bot look at specific coordinates\n- `followPlayer` - Follow a specific player\n- `stopFollowing` - Stop following current target\n- `goToPosition` - Navigate to specific coordinates\n\n## Technical Details\n\n- Server runs in offline mode for local development\n- Default memory allocation: 2GB\n- Default port: 25565\n- Bot username: MCPBot\n\n## Troubleshooting\n\n### Common Issues\n\n1. **MCP Connection Failed**\n   - Look for lingering Java processes\n   - Terminate them manually:\n      - Windows: Use Task Manager (untested)\n      - Mac/Linux: \n         - Go to 'Activity Monitor' and 'Force Quit' java\n   - Restart computer if process termination fails\n   - Note: Latest version should auto-resolve these issues\n\n2. **Server Won't Start**\n   - Verify Java is installed\n   - Check server.jar path is correct\n   - Ensure port 25565 is available\n\n3. **Can't Connect to Server**\n   - Verify server is running (check logs)\n   - Confirm you're using \"localhost\" as server address\n   - Check firewall settings\n\n### Logs Location\n- Minecraft Server logs: Check the minecraft-server directory\n- Claude Desktop logs: `~/Library/Logs/Claude/mcp*.log`\n\n## Contributing\n\nContributions, big or small, are welcome!\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "minecraft",
        "interact",
        "ai",
        "interact minecraft",
        "minecraft integration",
        "mcp minecraft"
      ],
      "category": "virtual-assistants"
    },
    "baryhuang--mcp-remote-macos-use": {
      "owner": "baryhuang",
      "name": "mcp-remote-macos-use",
      "url": "https://github.com/baryhuang/mcp-remote-macos-use",
      "imageUrl": "/freedevtools/mcp/pfp/baryhuang.webp",
      "description": "Enables complete control over remote macOS systems with native environment integration and no additional software requirements. Optimized for autonomous AI agents to operate seamlessly on the desktop.",
      "stars": 392,
      "forks": 48,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T17:48:51Z",
      "readme_content": "# MCP Server - Remote MacOs Use\n**The first open-source MCP server that enables AI to fully control remote macOS systems.**\n\n**A direct alternative to OpenAI Operator, optimized specifically for autonomous AI agents with complete desktop capabilities, requiring no additional software installation.**\n\n[![Docker Pulls](https://img.shields.io/docker/pulls/buryhuang/mcp-remote-macos-use)](https://hub.docker.com/r/buryhuang/mcp-remote-macos-use)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n**Showcases**\n- Research Twitter and Post Twitter(https://www.youtube.com/watch?v=--QHz2jcvcs)\n<img width=\"400\" alt=\"image\" src=\"https://github.com/user-attachments/assets/bfe6e354-3d59-4d08-855b-2eecdaaeb46f\" />\n\n- Use CapCut to create short highlight video(https://www.youtube.com/watch?v=RKAqiNoU8ec)\n<img width=\"400\" alt=\"image\" src=\"https://github.com/user-attachments/assets/3b4d07c5-cd25-4dae-b9a1-a373bf7492aa\" />\n\n- AI Recruiter: Automated candidate information collection, qualifying applications and sending screening sessions using Mail App\n- AI Marketing Intern: LinkedIn engagement - automated following, liking, and commenting with relevant users\n- AI Marketing Intern: Twitter engagement - automated following, liking, and commenting with relevant users\n\n## To-Do List (Prioritized)\n\n1. **Performance Optimization** - Match speed of Ubuntu desktop alternatives\n2. **Apple Scripts Generation** - Reduce execution time while maintaining flexibility\n3. **VNC Cursor Visibility** - Improve debugging and demo experience\n\n*We welcome contributions!*\n\n## Features\n\n* **No Extra API Costs**: Free screen processing with your existing Claude Pro plan\n* **Minimal Setup**: Just enable Screen Sharing on the target Mac – no additional software needed\n* **Universal Compatibility**: Works with all macOS versions, current and future\n  \n## Why We Built This\n\n### Native macOS Experience Without Compromise\nThe macOS native ecosystem remains unmatched in user experience today and will continue to be the gold standard for years to come. This is where human capabilities truly thrive, and now your AI can operate in this environment with the same fluency.\n\n### Open Architecture By Design\n* **Universal LLM Compatibility**: Work with any MCP Client of your choice\n* **Model Flexibility**: Seamlessly integrate with OpenAI, Anthropic, or any other LLM provider\n* **Future-Proof Integration**: Designed to evolve with the MCP ecosystem\n\n### Effortless Deployment\n* **Zero Setup on Target Machines**: No background applications or agents needed on macOS\n* **Screen Sharing is All You Need**: Control any Mac with Screen Sharing enabled\n* **Eliminate Backend Complexity**: Unlike other solutions that require running Python applications or background services\n\n### Streamlined Bootstrap Process\n* **Leverage Claude Desktop's Polished UI**: No need for developer-style Python interfaces\n* **Intuitive User Experience**: Interact with your AI-controlled Mac through a familiar, user-friendly interface\n* **Instant Productivity**: Start working immediately without configuration hassles\n\n## Architecture\n<img width=\"912\" alt=\"remote_macos_use_system_architecture\" src=\"https://github.com/user-attachments/assets/75ece060-90e2-4ad3-bb52-2c69427001dd\" />\n\n\n## Installation\n- [Enable Screen Sharing on MacOs](https://support.apple.com/guide/remote-desktop/set-up-a-computer-running-vnc-software-apdbed09830/mac) **If you rent a mac from macstadium.com, you can skip this step**\n- [Connect to your remote MacOs](https://support.apple.com/guide/mac-help/share-the-screen-of-another-mac-mh14066/mac)\n- [Install Docker Desktop for local Mac](https://docs.docker.com/desktop/setup/install/mac-install/)\n- [Add this MCP server to Claude Desktop](https://modelcontextprotocol.io/quickstart/user)\nYou can configure Claude Desktop to use the Docker image by adding the following to your Claude configuration:\n```json\n{\n  \"mcpServers\": {\n    \"remote-macos-use\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"-e\",\n        \"MACOS_USERNAME=your_macos_username\",\n        \"-e\",\n        \"MACOS_PASSWORD=your_macos_password\",\n        \"-e\",\n        \"MACOS_HOST=your_macos_hostname_or_ip\",\n        \"--rm\",\n        \"buryhuang/mcp-remote-macos-use:latest\"\n      ]\n    }\n  }\n}\n```\n\n### WebRTC Support via LiveKit\n\nThis server now includes WebRTC support through LiveKit integration, enabling:\n- Low-latency real-time screen sharing\n- Improved performance and responsiveness\n- Better network efficiency compared to traditional VNC\n- Automatic quality adaptation based on network conditions\n\nTo use WebRTC features, you'll need to:\n1. Set up a LiveKit server or use LiveKit Cloud\n2. Configure the LiveKit environment variables as shown in the configuration example above\n\n## Developer Instruction\n### Clone the repo\n```bash\n# Clone the repository\ngit clone https://github.com/yourusername/mcp-remote-macos-use.git\ncd mcp-remote-macos-use\n```\n\n### Building the Docker Image\n\n```bash\n# Build the Docker image\ndocker build -t mcp-remote-macos-use .\n```\n\n## Cross-Platform Publishing\n\nTo publish the Docker image for multiple platforms, you can use the `docker buildx` command. Follow these steps:\n\n1. **Create a new builder instance** (if you haven't already):\n   ```bash\n   docker buildx create --use\n   ```\n\n2. **Build and push the image for multiple platforms**:\n   ```bash\n   docker buildx build --platform linux/amd64,linux/arm64 -t buryhuang/mcp-remote-macos-use:latest --push .\n   ```\n\n3. **Verify the image is available for the specified platforms**:\n   ```bash\n   docker buildx imagetools inspect buryhuang/mcp-remote-macos-use:latest\n   ```\n\n## Usage\n\nThe server provides Remote MacOs functionality through MCP tools.\n\n### Tools Specifications\n\nThe server provides the following tools for remote macOS control:\n\n#### remote_macos_get_screen\nConnect to a remote macOS machine and get a screenshot of the remote desktop. Uses environment variables for connection details.\n\n#### remote_macos_send_keys\nSend keyboard input to a remote macOS machine. Uses environment variables for connection details.\n\n#### remote_macos_mouse_move\nMove the mouse cursor to specified coordinates on a remote macOS machine, with automatic coordinate scaling. Uses environment variables for connection details.\n\n#### remote_macos_mouse_click\nPerform a mouse click at specified coordinates on a remote macOS machine, with automatic coordinate scaling. Uses environment variables for connection details.\n\n#### remote_macos_mouse_double_click\nPerform a mouse double-click at specified coordinates on a remote macOS machine, with automatic coordinate scaling. Uses environment variables for connection details.\n\n#### remote_macos_mouse_scroll\nPerform a mouse scroll at specified coordinates on a remote macOS machine, with automatic coordinate scaling. Uses environment variables for connection details.\n\n#### remote_macos_open_application\nOpens/activates an application and returns its PID for further interactions.\n\n#### remote_macos_mouse_drag_n_drop\nPerform a mouse drag operation from start point and drop to end point on a remote macOS machine, with automatic coordinate scaling.\n\nAll tools use the environment variables configured during setup instead of requiring connection parameters.\n\n## Limitations\n\n- **Authentication Support**: \n  - Only Apple Authentication (protocol 30) is supported\n\n## Security Note\n\nhttps://support.apple.com/guide/remote-desktop/encrypt-network-data-apdfe8e386b/mac\nhttps://cafbit.com/post/apple_remote_desktop_quirks/\n\nWe only support protocol 30, which uses the Diffie-Hellman key agreement protocol with a 512-bit prime. This protocol is used by macOS 11 to macOS 12 when communicating with OS X 10.11 or earlier clients.\n\nHere's the information converted to a markdown table:\n\n| macOS version running Remote Desktop | macOS client version | Authentication | Control and Observe | Copy items or install package | All other tasks | Protocol Version |\n|--------------------------------------|----------------------|----------------|---------------------|-------------------------------|----------------|----------------|\n| macOS 13 | macOS 13 | 2048-bit RSA host keys | 2048-bit RSA host keys | 2048-bit RSA host keys to authenticate, then 128-bit AES | 2048-bit RSA host keys | 36 |\n| macOS 13 | macOS 10.12 | Secure Remote Password (SRP) protocol for local only. Diffie-Hellman (DH) if bound to LDAP or macOS server is version 10.11 or earlier | SRP or DH,128-bit AES | SRP or DH to authenticate, then 128-bit AES | 2048-bit RSA host keys | 35 |\n| macOS 11 to macOS 12 | macOS 10.12 to macOS 13 | Secure Remote Password (SRP) protocol for local only, Diffie-Hellman if bound to LDAP | SRP or DH 1024-bit, 128-bit AES | 2048-bit RSA host keys macOS 13 to macOS 10.13 | 2048-bit RSA host keys macOS 10.13 or later |  33 |\n| macOS 11 to macOS 12 | OS X 10.11 or earlier | DH 1024-bit | DH 1024-bit, 128-bit AES | Diffie-Hellman Key agreement protocol with a 512-bit prime | Diffie-Hellman Key agreement protocol with a 512-bit prime |  30 |\n\n\nAlways use secure, authenticated connections when accessing remote remote MacOs machines. This tool should only be used with servers you trust and have permission to access.\n\n## License\n\nSee the LICENSE file for details. \n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "macos",
        "ai",
        "assistants",
        "remote macos",
        "virtual assistants",
        "mcp remote"
      ],
      "category": "virtual-assistants"
    },
    "devizor--macOS-Notification-MCP": {
      "owner": "devizor",
      "name": "macOS-Notification-MCP",
      "url": "https://github.com/devizor/macOS-Notification-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/devizor.webp",
      "description": "Triggers native macOS notifications, plays system sounds, and converts text to speech. Supports customizable visual notifications and voice management features for AI assistants.",
      "stars": 26,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-26T11:51:16Z",
      "readme_content": "# 🔔 macOS Notification MCP\n\nA Model Context Protocol (MCP) server that enables AI assistants to trigger macOS notifications, sounds, and text-to-speech.\n\n## ✨ Features\n\n- 🔊 **Sound Notifications**: Play system sounds like Submarine, Ping, or Tink\n- 💬 **Banner Notifications**: Display visual notifications with customizable title, message, and subtitle\n- 🗣️ **Speech Notifications**: Convert text to speech with adjustable voice, rate, and volume\n- 🎙️ **Voice Management**: List and select from available system voices\n- 🧪 **Testing Tools**: Diagnostic utilities to verify all notification methods\n\n## 🚀 Quick Start with uvx (Recommended)\n\nThe fastest way to use this tool is with `uvx`, which runs packages without permanent installation:\n\n```bash\n# Install uv if you don't have it\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Run the MCP server directly (no installation needed)\nuvx macos-notification-mcp\n```\n\n## ⚙️ Configure Claude Desktop\n\nAdd this to your Claude Desktop configuration (`~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"macos-notification-mcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\"macos-notification-mcp\"]\n    }\n  }\n}\n```\n\nThen restart Claude Desktop.\n\n## 📦 Alternative Installation Methods\n\nStandard installation:\n\n```bash\npip install macos-notification-mcp\n```\n\nInstall from source:\n\n```bash\ngit clone https://github.com/devizor/macos-notification-mcp\ncd macos-notification-mcp\npip install .\n```\n\n## 🛠️ Available Notification Tools\n\n### 🔊 Sound Notification\n```python\nsound_notification(sound_name=\"Submarine\")\n```\nAvailable sounds: Basso, Blow, Bottle, Frog, Funk, Glass, Hero, Morse, Ping, Pop, Purr, Sosumi, Submarine, Tink\n\n### 💬 Banner Notification\n```python\nbanner_notification(\n    title=\"Task Complete\",\n    message=\"Your analysis is ready\",\n    subtitle=None,  # Optional\n    sound=False,    # Optional: Play sound with notification\n    sound_name=None # Optional: Specify system sound\n)\n```\n\n### 🗣️ Speech Notification\n```python\nspeak_notification(\n    text=\"The process has completed\",\n    voice=None,     # Optional: System voice to use\n    rate=150,       # Optional: Words per minute (default: 150)\n    volume=1.0      # Optional: Volume level 0.0-1.0\n)\n```\n\n### 🎙️ Voice Management\n```python\nlist_available_voices()  # Lists all available text-to-speech voices\n```\n\n### 🧪 Testing\n```python\ntest_notification_system()  # Tests all notification methods\n```\n\n## 🔒 Implementation Details\n\n- ⏱️ **Rate Limiting**: Notifications are processed one at a time with a minimum interval of 0.5 seconds\n- 🔄 **Queuing**: Multiple notification requests are handled sequentially\n- 🪟 **OS Integration**: Uses native macOS commands (`afplay`, `osascript`, `say`)\n- 🔌 **FastMCP**: Built on the FastMCP framework for AI communication\n\n## ⚠️ Troubleshooting\n\n- 🔐 **Permissions**: Ensure notifications are allowed in System Settings → Notifications\n- ⏳ **Timing**: Only one notification is processed at a time\n- 🌐 **Environment**: If using the command directly (not uvx), you may need to use full paths\n\n## 📄 License\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "notifications",
        "macos",
        "notification",
        "macos notifications",
        "macos notification",
        "notifications voice"
      ],
      "category": "virtual-assistants"
    },
    "himanshu8271--Dragons": {
      "owner": "himanshu8271",
      "name": "Dragons",
      "url": "https://github.com/himanshu8271/Dragons",
      "imageUrl": "/freedevtools/mcp/pfp/himanshu8271.webp",
      "description": "Stream audio and video content in Telegram with a user-friendly interface featuring powerful controls and multilingual support. Enjoy music with friends in multiple chats simultaneously.",
      "stars": 0,
      "forks": 0,
      "license": "GNU Affero General Public License v3.0",
      "language": "",
      "updated_at": "2022-04-24T22:41:02Z",
      "readme_content": "<h1 align= center><b>⭐️ Music Player ⭐️</b></h1>\n<h3 align = center> A Telegram Music Bot written in Python using Pyrogram and Py-Tgcalls </h3>\n\n<p align=\"center\">\n<a href=\"https://python.org\"><img src=\"http://forthebadge.com/images/badges/made-with-python.svg\" alt=\"made-with-python\"></a>\n<br>\n    <img src=\"https://img.shields.io/github/license/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"LICENSE\">\n    <img src=\"https://img.shields.io/github/contributors/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Contributors\">\n    <img src=\"https://img.shields.io/github/repo-size/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Repository Size\"> <br>\n    <img src=\"https://img.shields.io/github/forks/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Forks\">\n    <img src=\"https://img.shields.io/github/stars/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Stars\">\n    <img src=\"https://img.shields.io/github/watchers/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Watchers\">\n    <img src=\"https://img.shields.io/github/commit-activity/w/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Commit Activity\">\n    <img src=\"https://img.shields.io/github/issues/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Issues\">\n</p>\n\n## ✨ <a name=\"features\"></a>Features\n\n### ⚡️ Fast & Light\n\nStarts streaming your inputs while downloading and converting them. Also, it\ndoesn't make produce files.\n\n### 👮🏻‍♀️ Safe and handy\n\nRestricts control and sensitive commands to admins.\n\n### 🗑 Clean and spam free\n\nDeletes old playing trash to keep your chats clean.\n\n### 😎 Has cool controls\n\nLets you switch stream mode, loop, pause, resume, mute, unmute anytime.\n\n### 🖼 Has cool thumbnails\n\nResponse your commands with cool thumbnails on the chat.\n\n### 😉 Streams whatever you like\n\nYou can stream audio or video files, YouTube videos with any duration,\nYouTube lives, YouTube playlists and even custom live streams like radios or m3u8 links or files in\nthe place it is hosted!\n\n### 📊 Streams in multiple places\n\nAllows you to stream different things in multiple chats simultaneously. Each\nchat will have its own song queue.\n\n### 🗣 Speaks different languages\n\nMusic Player is multilingual and speaks [various languages](#languages),\nthanks to the translators.\n\n## 🚀 <a name=\"deploy\"></a>Deploy\n\n[![Deploy on Heroku](https://www.herokucdn.com/deploy/button.svg)](https://deploy.safone.tech)\n\nNote: `First Fork The Repo Then Click On Deploy To Heroku Button!`\n\n\n## ☁️ <a name=\"self_host\"></a>Self Host\n\n- Legecy Method\n```bash\n$ git clone https://github.com/AsmSafone/MusicPlayer\n$ cd MusicPlayer\n$ sudo apt install git curl python3-pip ffmpeg -y\n$ pip3 install -U pip\n$ curl -sL https://deb.nodesource.com/setup_16.x | sudo -E bash -\n$ sudo apt install -y nodejs\n$ sudo apt install build-essential\n$ sudo npm install pm2@latest -g\n$ pip3 install -U -r requirements.txt\n$ cp sample.env .env\n# < edit .env with your own values >\n$ python3 main.py\n```\n\n- Docker Build Method\n```bash\n$ git clone https://github.com/AsmSafone/MusicPlayer\n$ cd MusicPlayer\n$ cp sample.env .env\n# < edit .env with your own values >\n$ sudo docker build . -t musicplayer\n$ sudo docker run musicplayer\n```\n\n## ⚒ <a name=\"configs\"></a>Configs\n\n- `API_ID`: Telegram app id from https://my.telegram.org/apps.\n- `API_HASH`: Telegram app hash from https://my.telegram.org/apps.\n- `SESSION`: Pyrogram string session. You can generate from [here](https://replit.com/@AsmSafone/genStr).\n- `SUDOERS`: ID of sudo users (separate multiple ids with space).\n- `BOT_TOKEN`: Telegram bot token from https://t.me/botfather. (optional)\n- `QUALITY`: Custom stream quality (high/medium/low) for the userbot in vc. Default: `high`\n- `PREFIX`: Bot commad prefixes (separate multiple prefix with space). Eg: `! /`\n- `LANGUAGE`: An [available](#languages) bot language (can change it anytime). Default: `en`\n- `STREAM_MODE`: An stream mode like audio or video (can change it anytime). Default: `audio`\n- `ADMINS_ONLY`: Put `True` if you want to make /play commands only for admins. Default: `False`\n- `SPOTIFY_CLIENT_ID`: Spotify client id get it from [here](https://developer.spotify.com/dashboard/applications). (optional)\n- `SPOTIFY_CLIENT_SECRET`: Spotify client secret get it from [here](https://developer.spotify.com/dashboard/applications). (optional)\n\n\n## 📄 <a name=\"commands\"></a>Commands\n\nCommand | Description\n:--- | :---\n• !ping | Check if alive or not\n• !start / !help | Show the help for commands\n• !mode / !switch | Switch the stream mode (audio/video)\n• !p / !play [song name or youtube link] | Play a song in vc, if already playing add to queue\n• !radio / !stream [radio url or stream link] | Play a live stream in vc, if already playing add to queue\n• !pl / !playlist [playlist link] | Play the whole youtube playlist at once\n• !skip / !next | Skip to the next song\n• !m / !mute | Mute the current stream\n• !um / !unmute | Unmute the muted stream\n• !ps / !pause | Pause the current stream\n• !rs / !resume | Resume the paused stream\n• !list / !queue | Show the songs in the queue\n• !mix / !shuffle | Shuflle the queued playlist\n• !loop / !repeat | Enable or disable the loop mode\n• !lang / language [language code] | Set the bot language in group\n• !ip / !import | Import queue from exported file\n• !ep / !export | Export the queue for import in future\n• !stop / !leave | Leave from vc and clear the queue\n• !update / !restart | Update and restart your music player\n\n## 🗣 <a name=\"languages\"></a>Languages\n\n```text\nen    English\n```\n\n## 💜 <a name=\"contribute\"></a>Contribute\n\nNew languages, bug fixes and improvements following\n[our contribution guidelines](./CONTRIBUTING.md) are warmly welcomed!\n\n## 🛫 <a name=\"supports\"></a>Supports\n\nFor any kind of help join [our support group](https://t.me/AsmSupport) or raise an [issue](https://github.com/AsmSafone/MusicPlayer/issues).\n\n## ✨ <a name=\"credits\"></a>Credits\n\n- [Me](https://github.com/AsmSafone) for [Noting](https://github.com/AsmSafone/MusicPlayer) 😬\n- [Dan](https://github.com/delivrance) for [Pyrogram](https://github.com/pyrogram/pyrogram) ❤️\n- [Laky-64](https://github.com/Laky-64) for [Py-TgCalls](https://github.com/pytgcalls/pytgcalls) ❤️\n- And Thanks To All [Contributors](https://github.com/AsmSafone/MusicPlayer/graphs/contributors)! ❤️\n\n## 📃 <a name=\"license\"></a>License\n\nMusic Player is licenced under the GNU Affero General Public License v3.0.\nRead more [here](./LICENSE).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "telegram",
        "audio",
        "chats",
        "content telegram",
        "telegram user",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "htlin222--claude-chatgpt-mcp": {
      "owner": "htlin222",
      "name": "claude-chatgpt-mcp",
      "url": "https://github.com/htlin222/claude-chatgpt-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/htlin222.webp",
      "description": "Seamlessly interact with the ChatGPT desktop app on macOS, allowing users to ask questions, view conversation history, and continue discussions. This integration facilitates enhanced productivity by bridging Claude and ChatGPT.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-04-02T03:27:04Z",
      "readme_content": "# Claude ChatGPT MCP Tool\n\nThis is a Model Context Protocol (MCP) tool that allows Claude to interact with the ChatGPT desktop app on macOS.\n\n## Features\n\n- Ask ChatGPT questions directly from Claude\n- View ChatGPT conversation history\n- Continue existing ChatGPT conversations\n\n## Installation\n\n### Prerequisites\n\n- macOS with M1/M2/M3 chip\n- [ChatGPT desktop app](https://chatgpt.com/download) installed\n- [Bun](https://bun.sh/) installed\n- [Claude desktop app](https://claude.ai/desktop) installed\n\n### NPX Installation (Recommended)\n\nYou can use NPX to run this tool without cloning the repository:\n\n- **Install and run the package using NPX:**\n\n```bash\nnpx claude-chatgpt-mcp\n```\n\n- **Configure Claude Desktop:**\n\nEdit your `claude_desktop_config.json` file (located at `~/Library/Application Support/Claude/claude_desktop_config.json`) to include this tool:\n\n```json\n\"chatgpt-mcp\": {\n  \"command\": \"npx\",\n  \"args\": [\"claude-chatgpt-mcp\"]\n}\n```\n\n- **Restart the Claude Desktop app**\n\n- **Grant necessary permissions:**\n  - Go to System Preferences > Privacy & Security > Privacy\n  - Give Terminal (or iTerm) access to Accessibility features\n  - You may see permission prompts when the tool is first used\n\n### Manual Installation\n\n1. Clone this repository:\n\n```bash\ngit clone https://github.com/syedazharmbnr1/claude-chatgpt-mcp.git\ncd claude-chatgpt-mcp\n```\n\n2. Install dependencies:\n\n```bash\nbun install\n```\n\n3. Make sure the script is executable:\n\n```bash\nchmod +x index.ts\n```\n\n4. Update your Claude Desktop configuration:\n\nEdit your `claude_desktop_config.json` file (located at `~/Library/Application Support/Claude/claude_desktop_config.json`) to include this tool:\n\n```json\n\"chatgpt-mcp\": {\n  \"command\": \"/Users/YOURUSERNAME/.bun/bin/bun\",\n  \"args\": [\"run\", \"/path/to/claude-chatgpt-mcp/index.ts\"]\n}\n```\n\nMake sure to replace `YOURUSERNAME` with your actual macOS username and adjust the path to where you cloned this repository.\n\n5. Restart Claude Desktop app\n\n6. Grant permissions:\n   - Go to System Preferences > Privacy & Security > Privacy\n   - Give Terminal (or iTerm) access to Accessibility features\n   - You may see permission prompts when the tool is first used\n\n## Usage\n\nOnce installed, you can use the ChatGPT tool directly from Claude by asking questions like:\n\n- \"Can you ask ChatGPT what the capital of France is?\"\n- \"Show me my recent ChatGPT conversations\"\n- \"Ask ChatGPT to explain quantum computing\"\n\n## Troubleshooting\n\nIf the tool isn't working properly:\n\n1. Make sure ChatGPT app is installed and you're logged in\n2. Verify the path to bun in your claude_desktop_config.json is correct\n3. Check that you've granted all necessary permissions\n4. Try restarting both Claude and ChatGPT apps\n\n## Optimizations\n\nThis fork includes several significant improvements to the original implementation:\n\n### Enhanced AppleScript Robustness\n\n#### Conversation Retrieval\n- Added multiple UI element targeting approaches to handle ChatGPT UI changes\n- Implemented better error detection with specific error messages\n- Added fallback mechanisms using accessibility attributes\n- Improved timeout handling with appropriate delays\n\n#### Response Handling\n- Replaced fixed waiting times with dynamic response detection\n- Added intelligent completion detection that recognizes when ChatGPT has finished typing\n- Implemented text stability detection (waits until text stops changing)\n- Added response extraction logic to isolate just the relevant response text\n- Improved error handling with detailed error messages\n- Added post-processing to clean up UI elements from responses\n- Implemented incomplete response detection to warn about potential cutoffs\n\nThese optimizations make the integration more reliable across different scenarios, more resilient to UI changes in the ChatGPT application, and better at handling longer response times without message cutoff issues.\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "chatgpt",
        "conversation",
        "interact",
        "interact chatgpt",
        "chatgpt mcp",
        "chatgpt desktop"
      ],
      "category": "virtual-assistants"
    },
    "hyy0612--chatbot": {
      "owner": "hyy0612",
      "name": "chatbot",
      "url": "https://github.com/hyy0612/chatbot",
      "imageUrl": "/freedevtools/mcp/pfp/hyy0612.webp",
      "description": "Provides a conversational AI interface for applications, enabling automated responses and interactive dialogue to enhance user engagement. It supports easy deployment of chat-based AI solutions for various use cases.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-07T09:52:24Z",
      "readme_content": "# chatbot",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "chatbot",
        "ai",
        "dialogue",
        "hyy0612 chatbot",
        "chatbot provides",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "imgompanda--AutoGPT123": {
      "owner": "imgompanda",
      "name": "AutoGPT123",
      "url": "https://github.com/imgompanda/AutoGPT123",
      "imageUrl": "/freedevtools/mcp/pfp/imgompanda.webp",
      "description": "AutoGPT enables users to build, test, and deploy AI agents, facilitating the automation of various tasks and the realization of innovative ideas in AI development.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2024-04-09T13:17:37Z",
      "readme_content": "# AutoGPT: build & use AI agents\n\n[](https://discord.gg/autogpt) &ensp;\n[![Twitter Follow](https://img.shields.io/twitter/follow/Auto_GPT?style=social)](https://twitter.com/Auto_GPT) &ensp;\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n**AutoGPT** is the vision of the power of AI accessible to everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters:\n\n- 🏗️ **Building** - Lay the foundation for something amazing.\n- 🧪 **Testing** - Fine-tune your agent to perfection.\n- 🤝 **Delegating** - Let AI work for you, and have your ideas come to life.\n\nBe part of the revolution! **AutoGPT** is here to stay, at the forefront of AI innovation.\n\n**📖 [Documentation](https://docs.agpt.co)**\n&ensp;|&ensp;\n**🚀 [Contributing](CONTRIBUTING.md)**\n&ensp;|&ensp;\n**🛠️ [Build your own Agent - Quickstart](QUICKSTART.md)**\n\n## 🥇 Current Best Agent: evo.ninja\n[Current Best Agent]: #-current-best-agent-evoninja\n\nThe AutoGPT Arena Hackathon saw [**evo.ninja**](https://github.com/polywrap/evo.ninja) earn the top spot on our Arena Leaderboard, proving itself as the best open-source generalist agent. Try it now at https://evo.ninja!\n\n📈 To challenge evo.ninja, AutoGPT, and others, submit your benchmark run to the [Leaderboard](#-leaderboard), and maybe your agent will be up here next!\n\n## 🧱 Building blocks\n\n### 🏗️ Forge\n\n**Forge your own agent!** &ndash; Forge is a ready-to-go template for your agent application. All the boilerplate code is already handled, letting you channel all your creativity into the things that set *your* agent apart. All tutorials are located [here](https://medium.com/@aiedge/autogpt-forge-e3de53cc58ec). Components from the [`forge.sdk`](/autogpts/forge/forge/sdk) can also be used individually to speed up development and reduce boilerplate in your agent project.\n\n🚀 [**Getting Started with Forge**](https://github.com/Significant-Gravitas/AutoGPT/blob/master/autogpts/forge/tutorials/001_getting_started.md) &ndash;\nThis guide will walk you through the process of creating your own agent and using the benchmark and user interface.\n\n📘 [Learn More](https://github.com/Significant-Gravitas/AutoGPT/tree/master/autogpts/forge) about Forge\n\n### 🎯 Benchmark\n\n**Measure your agent's performance!** The `agbenchmark` can be used with any agent that supports the agent protocol, and the integration with the project's [CLI] makes it even easier to use with AutoGPT and forge-based agents. The benchmark offers a stringent testing environment. Our framework allows for autonomous, objective performance evaluations, ensuring your agents are primed for real-world action.\n\n<!-- TODO: insert visual demonstrating the benchmark -->\n\n📦 [`agbenchmark`](https://pypi.org/project/agbenchmark/) on Pypi\n&ensp;|&ensp;\n📘 [Learn More](https://github.com/Significant-Gravitas/AutoGPT/blob/master/benchmark) about the Benchmark\n\n#### 🏆 [Leaderboard][leaderboard]\n[leaderboard]: https://leaderboard.agpt.co\n\nSubmit your benchmark run through the UI and claim your place on the AutoGPT Arena Leaderboard! The best scoring general agent earns the title of **[Current Best Agent]**, and will be adopted into our repo so people can easily run it through the [CLI].\n\n[![Screenshot of the AutoGPT Arena leaderboard](https://github.com/Significant-Gravitas/AutoGPT/assets/12185583/60813392-9ddb-4cca-bb44-b477dbae225d)][leaderboard]\n\n### 💻 UI\n\n**Makes agents easy to use!** The `frontend` gives you a user-friendly interface to control and monitor your agents. It connects to agents through the [agent protocol](#-agent-protocol), ensuring compatibility with many agents from both inside and outside of our ecosystem.\n\n<!-- TODO: instert screenshot of front end -->\n\nThe frontend works out-of-the-box with all agents in the repo. Just use the [CLI] to run your agent of choice!\n\n📘 [Learn More](https://github.com/Significant-Gravitas/AutoGPT/tree/master/frontend) about the Frontend\n\n### ⌨️ CLI\n\n[CLI]: #-cli\n\nTo make it as easy as possible to use all of the tools offered by the repository, a CLI is included at the root of the repo:\n\n```shell\n$ ./run\nUsage: cli.py [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  agent      Commands to create, start and stop agents\n  arena      Commands to enter the arena\n  benchmark  Commands to start the benchmark and list tests and categories\n  setup      Installs dependencies needed for your system.\n```\n\nJust clone the repo, install dependencies with `./run setup`, and you should be good to go!\n\n## 🤔 Questions? Problems? Suggestions?\n\n### Get help - [Discord 💬](https://discord.gg/autogpt)\n\n[![Join us on Discord](https://invidget.switchblade.xyz/autogpt)](https://discord.gg/autogpt)\n\nTo report a bug or request a feature, create a [GitHub Issue](https://github.com/Significant-Gravitas/AutoGPT/issues/new/choose). Please ensure someone else hasn’t created an issue for the same topic.\n\n## 🤝 Sister projects\n\n### 🔄 Agent Protocol\n\nTo maintain a uniform standard and ensure seamless compatibility with many current and future applications, AutoGPT employs the [agent protocol](https://agentprotocol.ai/) standard by the AI Engineer Foundation. This standardizes the communication pathways from your agent to the frontend and benchmark.\n\n---\n\n<p align=\"center\">\n<a href=\"https://star-history.com/#Significant-Gravitas/AutoGPT\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=Significant-Gravitas/AutoGPT&type=Date&theme=dark\" />\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=Significant-Gravitas/AutoGPT&type=Date\" />\n    <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=Significant-Gravitas/AutoGPT&type=Date\" />\n  </picture>\n</a>\n</p>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "autogpt",
        "automation",
        "autogpt123",
        "virtual assistants",
        "imgompanda autogpt123",
        "ai agents"
      ],
      "category": "virtual-assistants"
    },
    "logos-42--ANPtest": {
      "owner": "logos-42",
      "name": "ANPtest",
      "url": "https://github.com/logos-42/ANPtest",
      "imageUrl": "/freedevtools/mcp/pfp/logos-42.webp",
      "description": "Connects to AI agents using self-compressed decentralized identifiers (DIDs). Facilitates interactive conversations with an AI assistant in a talk show style, featuring functionalities for DID generation and QR code display.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-04-01T07:36:48Z",
      "readme_content": "# 脱口秀AI智能体\r\n\r\n基于自压缩DID技术，使用硅基流动API实现的脱口秀AI助手。\r\n\r\n## 项目特点\r\n\r\n- 实现自压缩DID，无需额外查询即可连接智能体\r\n- 使用硅基流动的DeepSeek-R1-Distill-Qwen-32B大模型\r\n- 提供生成DID、二维码展示和聊天功能\r\n- 支持智能体间的通信与连接\r\n\r\n## 技术栈\r\n\r\n- Next.js: React框架\r\n- 自压缩DID: 去中心化身份识别\r\n- 硅基流动API: AI大模型服务\r\n- Vercel: 部署服务\r\n\r\n## 快速开始\r\n\r\n### 本地开发\r\n\r\n1. 克隆项目并安装依赖:\r\n\r\n```bash\r\ngit clone <repository-url>\r\ncd comedyagent\r\nnpm install\r\n```\r\n\r\n2. 配置API密钥:\r\n\r\n如需使用不同的API密钥，请修改`lib/ai.js`文件中的`API_KEY`变量。\r\n\r\n3. 启动开发服务器:\r\n\r\n```bash\r\nnpm run dev\r\n```\r\n\r\n4. 访问 http://localhost:3000 查看应用。\r\n\r\n### Vercel部署\r\n\r\n1. Fork此仓库到您的GitHub账户。\r\n\r\n2. 在Vercel上创建新项目，并连接您的GitHub仓库。\r\n\r\n3. 部署完成后，即可通过Vercel提供的URL访问应用。\r\n\r\n## 使用说明\r\n\r\n### 生成DID\r\n\r\n1. 在首页点击\"生成DID\"按钮。\r\n2. 系统会生成一个自包含DID，并以文本和二维码形式显示。\r\n3. 您可以复制DID或分享二维码。\r\n\r\n### 测试智能体\r\n\r\n1. 在首页的聊天框中输入消息。\r\n2. 点击\"发送\"按钮或按Enter键。\r\n3. 智能体会以脱口秀演员的风格回复您的消息。\r\n\r\n### 连接其他智能体\r\n\r\n1. 前往\"/connect\"页面。\r\n2. 输入其他智能体的DID。\r\n3. 点击\"连接\"按钮。\r\n4. 连接成功后，您可以向该智能体发送消息。\r\n\r\n您还可以通过以下方式连接智能体:\r\n\r\n- 在浏览器中打开`{您的域名}/connect?did={DID字符串}`\r\n- 或者创建一个`did://`协议链接: `did://{DID字符串}`\r\n\r\n## 项目结构\r\n\r\n```\r\ncomedyagent/\r\n├── api/                  # API路由\r\n│   ├── generate-did.js   # DID生成API\r\n│   └── message.js        # 消息处理API\r\n├── components/           # React组件\r\n├── lib/                  # 工具库\r\n│   ├── ai.js             # AI服务\r\n│   └── did.js            # DID功能\r\n├── pages/                # 页面\r\n│   ├── index.js          # 首页\r\n│   └── connect.js        # 连接页面\r\n├── public/               # 静态资源\r\n├── styles/               # 样式文件\r\n│   ├── Home.module.css   # 首页样式\r\n│   └── Connect.module.css# 连接页面样式\r\n├── package.json          # 项目配置\r\n└── vercel.json           # Vercel配置\r\n```\r\n\r\n## 自压缩DID详解\r\n\r\n本项目中的自压缩DID是一种创新的数字身份表示方式，包含了以下信息:\r\n\r\n- 身份标识\r\n- 公钥\r\n- 服务端点\r\n- 元数据\r\n- 数字签名\r\n\r\n与传统DID不同，自压缩DID将所有必要信息编码在一个字符串中，无需查询额外服务器即可获取身份信息和通信方式。\r\n\r\n## 许可证\r\n\r\nMIT ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "agents",
        "assistant",
        "ai assistant",
        "ai agents",
        "connects ai"
      ],
      "category": "virtual-assistants"
    },
    "mrexodia--user-feedback-mcp": {
      "owner": "mrexodia",
      "name": "user-feedback-mcp",
      "url": "https://github.com/mrexodia/user-feedback-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/mrexodia.webp",
      "description": "Facilitates a feedback loop in tools for desktop application development by collecting user insights during complex interactions. Enhances testing processes by prompting users for feedback before task completion.",
      "stars": 47,
      "forks": 8,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-04T14:06:32Z",
      "readme_content": "# User Feedback MCP\r\n\r\nSimple [MCP Server](https://modelcontextprotocol.io/introduction) to enable a human-in-the-loop workflow in tools like [Cline](https://cline.bot) and [Cursor](https://www.cursor.com). This is especially useful for developing desktop applications that require complex user interactions to test.\r\n\r\n![Screenshot showing the feedback UI](https://github.com/mrexodia/user-feedback-mcp/blob/main/.github/feedback-ui.png?raw=true)\r\n\r\n## Prompt Engineering\r\n\r\nFor the best results, add the following to your custom prompt:\r\n\r\n> Before completing the task, use the user_feedback MCP tool to ask the user for feedback.\r\n\r\nThis will ensure Cline uses this MCP server to request user feedback before marking the task as completed.\r\n\r\n## `.user-feedback.json`\r\n\r\nHitting _Save Configuration_ creates a `.user-feedback.json` file in your project directory that looks like this:\r\n\r\n```json\r\n{\r\n  \"command\": \"npm run dev\",\r\n  \"execute_automatically\": false\r\n}\r\n```\r\n\r\nThis configuration will be loaded on startup and if `execute_automatically` is enabled your `command` will be instantly executed (you will not have to click _Run_ manually). For multi-step commands you should use something like [Task](https://taskfile.dev).\r\n\r\n## Installation (Cline)\r\n\r\nTo install the MCP server in Cline, follow these steps (see screenshot):\r\n\r\n![Screenshot showing installation steps](https://github.com/mrexodia/user-feedback-mcp/blob/main/.github/cline-installation.png?raw=true)\r\n\r\n1. Install [uv](https://github.com/astral-sh/uv) globally:\r\n   - Windows: `pip install uv`\r\n   - Linux/Mac: `curl -LsSf https://astral.sh/uv/install.sh | sh`\r\n2. Clone this repository, for this example `C:\\MCP\\user-feedback-mcp`.\r\n3. Navigate to the Cline _MCP Servers_ configuration (see screenshot).\r\n4. Click on the _Installed_ tab.\r\n5. Click on _Configure MCP Servers_, which will open `cline_mcp_settings.json`.\r\n6. Add the `user-feedback-mcp` server:\r\n\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"github.com/mrexodia/user-feedback-mcp\": {\r\n      \"command\": \"uv\",\r\n      \"args\": [\r\n        \"--directory\",\r\n        \"c:\\\\MCP\\\\user-feedback-mcp\",\r\n        \"run\",\r\n        \"server.py\"\r\n      ],\r\n      \"timeout\": 600,\r\n      \"autoApprove\": [\r\n        \"user_feedback\"\r\n      ]\r\n    }\r\n  }\r\n}\r\n\r\n```\r\n\r\n## Development\r\n\r\n```sh\r\nuv run fastmcp dev server.py\r\n```\r\n\r\nThis will open a web interface at http://localhost:5173 and allow you to interact with the MCP tools for testing.\r\n\r\n## Available tools\r\n\r\n```\r\n<use_mcp_tool>\r\n<server_name>github.com/mrexodia/user-feedback-mcp</server_name>\r\n<tool_name>user_feedback</tool_name>\r\n<arguments>\r\n{\r\n  \"project_directory\": \"C:/MCP/user-feedback-mcp\",\r\n  \"summary\": \"I've implemented the changes you requested.\"\r\n}\r\n</arguments>\r\n</use_mcp_tool>\r\n```",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mrexodia",
        "feedback",
        "assistants",
        "virtual assistants",
        "assistants mrexodia",
        "facilitates feedback"
      ],
      "category": "virtual-assistants"
    },
    "mrgeeko--vapi-mcp": {
      "owner": "mrgeeko",
      "name": "vapi-mcp",
      "url": "https://github.com/mrgeeko/vapi-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/mrgeeko.webp",
      "description": "Integrate voice AI capabilities into applications for managing voice assistants and conducting outbound calls. Provides advanced features for enhancing user interactions through voice conversations.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2025-04-07T08:10:10Z",
      "readme_content": "# Vapi MCP for Cursor\n\nThis project implements a Model Context Protocol (MCP) server for integrating Vapi's voice AI capabilities with Cursor.\n\n## Setup Instructions\n\n### 1. Project Structure\n\nThe Vapi MCP server is structured as follows:\n- `vapi-mcp-server/` - Main server code\n  - `src/` - TypeScript source files\n  - `dist/` - Compiled JavaScript output\n  - `.env` - Environment variables for API keys\n\n### 2. Environment Configuration\n\nCreate a `.env` file in the `vapi-mcp-server` directory with the following variables:\n\n```\n# Vapi API Keys\nVAPI_ORG_ID=your-org-id\nVAPI_PRIVATE_KEY=your-private-key\nVAPI_KNOWLEDGE_ID=your-knowledge-id\nVAPI_JWT_PRIVATE=your-jwt-private\n\n# Environment\nNODE_ENV=development\n```\n\n### 3. Building the Server\n\nTo build the server:\n\n```bash\ncd vapi-mcp/vapi-mcp-server\nnpm install\nnpm run build\n```\n\n### 4. Configuration in Cursor\n\n#### Important: Avoiding \"Client Closed\" Errors\n\nWhen configuring the Vapi MCP server in Cursor's MCP settings, pay attention to the following crucial details:\n\n1. **Working Directory**: The `cwd` parameter is required to ensure the server runs in the correct directory and can access the `.env` file properly.\n\n2. **Environment Variables**: Must be explicitly provided in the configuration, even if they exist in the `.env` file.\n\n3. **Module Type**: The server uses ES modules, so the `package.json` must include `\"type\": \"module\"`.\n\nHere's the correct configuration for `.cursor/mcp.json`:\n\n```json\n\"Vapi Voice AI Tools\": {\n  \"command\": \"node\",\n  \"type\": \"stdio\",\n  \"args\": [\n    \"/Users/matthewcage/Documents/AA-GitHub/MCP/vapi-mcp/vapi-mcp-server/dist/index.js\"\n  ],\n  \"cwd\": \"/Users/matthewcage/Documents/AA-GitHub/MCP/vapi-mcp/vapi-mcp-server\",\n  \"env\": {\n    \"VAPI_ORG_ID\": \"your-org-id\",\n    \"VAPI_PRIVATE_KEY\": \"your-private-key\",\n    \"VAPI_KNOWLEDGE_ID\": \"your-knowledge-id\",\n    \"VAPI_JWT_PRIVATE\": \"your-jwt-private\",\n    \"NODE_ENV\": \"development\"\n  }\n}\n```\n\n## Troubleshooting\n\n### \"Client Closed\" Error in Cursor\n\nIf you see \"Client Closed\" in the Cursor MCP Tools panel:\n\n1. **Check Working Directory**: Ensure the `cwd` parameter is set correctly in your mcp.json\n2. **Verify Environment Variables**: Make sure all required environment variables are passed in the configuration\n3. **Check Module Type**: Ensure `package.json` has `\"type\": \"module\"`\n4. **Inspect Permissions**: Make sure the dist/index.js file is executable (`chmod +x dist/index.js`)\n5. **Test Server Directly**: Run the server manually to check for errors:\n   ```bash\n   cd vapi-mcp/vapi-mcp-server\n   node --trace-warnings dist/index.js\n   ```\n\n### Module Not Found Errors\n\nIf you get \"Error: Cannot find module\" when running:\n\n1. **Check Working Directory**: Are you running from the correct directory?\n2. **Rebuild**: Try rebuilding the project with `npm run build`\n3. **Dependencies**: Ensure all dependencies are installed with `npm install`\n\n## Available Tools\n\nThe Vapi MCP server provides the following tools:\n\n1. **vapi_call** - Make outbound calls using Vapi's voice AI\n2. **vapi_assistant** - Manage voice assistants (create, get, list, update, delete)\n3. **vapi_conversation** - Retrieve conversation details from calls\n\n## Lessons Learned\n\n1. When integrating with Cursor's MCP:\n   - Always specify the `cwd` parameter to ensure the server runs in the correct directory\n   - Pass all required environment variables directly in the MCP configuration\n   - For ES modules, ensure package.json has `\"type\": \"module\"` and tsconfig.json uses appropriate module settings\n   - Test the server directly before configuring in Cursor\n\n2. The server command path must be absolute and correctly formed in the Cursor MCP config\n\n3. Using stdio transport type is required for proper integration with Cursor ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "voice",
        "vapi",
        "assistants",
        "voice assistants",
        "voice ai",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "popcornspace--voice-call-mcp-server": {
      "owner": "popcornspace",
      "name": "voice-call-mcp-server",
      "url": "https://github.com/popcornspace/voice-call-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/popcornspace.webp",
      "description": "Facilitates voice call management through Twilio and OpenAI, enabling real-time audio processing for interactive conversations with AI assistants. Offers pre-built prompts for common scenarios to streamline call initiation and handling.",
      "stars": 49,
      "forks": 9,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-18T23:39:26Z",
      "readme_content": "# Voice Call MCP Server\n\nA Model Context Protocol (MCP) server that enables Claude and other AI assistants to initiate and manage voice calls using Twilio and OpenAI (GPT-4o Realtime model).\n\nUse this as a base to kick-start your AI-powered voice calling explorations, save time and develop additional functionality on top of it.\n\n\n\n\n## Sequence Diagram\n\n```mermaid\nsequenceDiagram\n    participant AI as AI Assistant (e.g., Claude)\n    participant MCP as MCP Server\n    participant Twilio as Twilio\n    participant Phone as Destination Phone\n    participant OpenAI as OpenAI\n    \n    AI->>MCP: 1) Initiate outbound call request <br>(POST /calls)\n    MCP->>Twilio: 2) Place outbound call via Twilio API\n    Twilio->>Phone: 3) Ring the destination phone\n    Twilio->>MCP: 4) Call status updates & audio callbacks (webhooks)\n    MCP->>OpenAI: 5) Forward real-time audio to OpenaAI's realtime model\n    OpenAI->>MCP: 6) Return voice stream\n    MCP->>Twilio: 7) Send voice stream\n    Twilio->>Phone: 8) Forward voice stream\n    Note over Phone: Two-way conversation continues <br>until the call ends\n```\n\n\n## Features\n\n- Make outbound phone calls via Twilio 📞\n- Process call audio in real-time with GPT-4o Realtime model 🎙️\n- Real-time language switching during calls 🌐\n- Pre-built prompts for common calling scenarios (like restaurant reservations) 🍽️\n- Automatic public URL tunneling with ngrok 🔄\n- Secure handling of credentials 🔒\n\n## Why MCP?\n\nThe Model Context Protocol (MCP) bridges the gap between AI assistants and real-world actions. By implementing MCP, this server allows AI models like Claude to:\n\n1. Initiate actual phone calls on behalf of users\n2. Process and respond to real-time audio conversations\n3. Execute complex tasks requiring voice communication\n\nThis open-source implementation provides transparency and customizability, allowing developers to extend functionality while maintaining control over their data and privacy.\n\n## Requirements\n\n- Node.js >= 22\n  - If you need to update Node.js, we recommend using `nvm` (Node Version Manager):\n    ```bash\n    nvm install 22\n    nvm use 22\n    ```\n- Twilio account with API credentials\n- OpenAI API key\n- Ngrok Authtoken\n\n## Installation\n\n### Manual Installation\n\n1. Clone the repository\n   ```bash\n   git clone https://github.com/lukaskai/voice-call-mcp-server.git\n   cd voice-call-mcp-server\n   ```\n\n2. Install dependencies and build\n   ```bash\n   npm install\n   npm run build\n   ```\n\n## Configuration\n\nThe server requires several environment variables:\n\n- `TWILIO_ACCOUNT_SID`: Your Twilio account SID\n- `TWILIO_AUTH_TOKEN`: Your Twilio auth token\n- `TWILIO_NUMBER`: Your Twilio number\n- `OPENAI_API_KEY`: Your OpenAI API key\n- `NGROK_AUTHTOKEN`: Your ngrok authtoken\n- `RECORD_CALLS`: Set to \"true\" to record calls (optional)\n\n### Claude Desktop Configuration\n\nTo use this server with Claude Desktop, add the following to your configuration file:\n\n**macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n\n**Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"voice-call\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/your/mcp-new/dist/start-all.cjs\"],\n      \"env\": {\n        \"TWILIO_ACCOUNT_SID\": \"your_account_sid\",\n        \"TWILIO_AUTH_TOKEN\": \"your_auth_token\",\n        \"TWILIO_NUMBER\": \"your_e.164_format_number\",\n        \"OPENAI_API_KEY\": \"your_openai_api_key\",\n        \"NGROK_AUTHTOKEN\": \"your_ngrok_authtoken\"\n      }\n    }\n  }\n}\n```\n\nAfter that, restart Claude Desktop to reload the configuration. \nIf connected, you should see Voice Call under the 🔨 menu.\n\n## Example Interactions with Claude\n\nHere are some natural ways to interact with the server through Claude:\n\n1. Simple call:\n```\nCan you call +1-123-456-7890 and let them know I'll be 15 minutes late for our meeting?\n```\n\n2. Restaurant reservation:\n```\nPlease call Delicious Restaurant at +1-123-456-7890 and make a reservation for 4 people tonight at 7:30 PM. Please speak in German.\n```\n\n3. Appointment scheduling:\n```\nPlease call Expert Dental NYC (+1-123-456-7899) and reschedule my Monday appointment to next Friday between 4–6pm.\n```\n\n## Important Notes\n\n1. **Phone Number Format**: All phone numbers must be in E.164 format (e.g., +11234567890)\n2. **Rate Limits**: Be aware of your Twilio and OpenAI account's rate limits and pricing\n3. **Voice Conversations**: The AI will handle natural conversations in real-time\n4. **Call Duration**: Be mindful of call durations as they affect OpenAI API and Twilio costs\n5. **Public Exposure**: Be aware that the ngrok tunnel exposes your server publicly for Twilio to reach it (though with a random URL and protected by a random secret)\n\n## Troubleshooting\n\nCommon error messages and solutions:\n\n1. \"Phone number must be in E.164 format\"\n   - Make sure the phone number starts with \"+\" and the country code\n\n2. \"Invalid credentials\"\n   - Double-check your TWILIO_ACCOUNT_SID and TWILIO_AUTH_TOKEN. You can copy them from the [Twilio Console](https://console.twilio.com)\n\n3. \"OpenAI API error\"\n   - Verify your OPENAI_API_KEY is correct and has sufficient credits\n\n4. \"Ngrok tunnel failed to start\"\n   - Ensure your NGROK_AUTHTOKEN is valid and not expired\n\n5. \"OpenAI Realtime does not detect the end of voice input, or is lagging.\"\n   - Sometimes, there might be voice encoding issues between Twilio and the receiver's network operator. Try using a different receiver.\n\n## Contributing\n\nContributions are welcome! Here are some areas we're looking to improve:\n\n- Implement support for multiple AI models beyond the current implementation\n- Add database integration to store conversation history locally and make it accessible for AI context\n- Improve latency and response times to enhance call experiences\n- Enhance error handling and recovery mechanisms\n- Add more pre-built conversation templates for common scenarios\n- Implement improved call monitoring and analytics\n\nIf you'd like to contribute, please open an issue to discuss your ideas before submitting a pull request.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Security\n\nPlease do not include any sensitive information (like phone numbers or API credentials) in GitHub issues or pull requests. This server handles sensitive communications; deploy it responsibly and ensure all credentials are kept secure.\n\n\n## Time For a New Mission?\n\nWe’re hiring engineers to build at the frontier of voice AI — and bake it into a next-gen telco.\n\nCurious? Head to [careers.popcorn.space](https://careers.popcorn.space/apply) 🍿 !",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "twilio",
        "voice",
        "audio",
        "virtual assistants",
        "voice mcp",
        "twilio openai"
      ],
      "category": "virtual-assistants"
    },
    "rsagacom--chatgpt-on-wechat": {
      "owner": "rsagacom",
      "name": "chatgpt-on-wechat",
      "url": "https://github.com/rsagacom/chatgpt-on-wechat",
      "imageUrl": "/freedevtools/mcp/pfp/rsagacom.webp",
      "description": "A multi-platform intelligent dialogue service that supports text, voice, and image interactions. It can connect to various AI models and allows for custom enterprise AI applications through plugin extensions.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2024-01-28T14:00:49Z",
      "readme_content": "# 简介\n\n> 本项目是基于大模型的智能对话机器人，支持微信、企业微信、公众号、飞书、钉钉接入，可选择GPT3.5/GPT4.0/Claude/文心一言/讯飞星火/通义千问/Gemini/LinkAI，能处理文本、语音和图片，通过插件访问操作系统和互联网等外部资源，支持基于自有知识库定制企业AI应用。\n\n最新版本支持的功能如下：\n\n- [x] **多端部署：** 有多种部署方式可选择且功能完备，目前已支持个人微信、微信公众号和、企业微信、飞书、钉钉等部署方式\n- [x] **基础对话：** 私聊及群聊的消息智能回复，支持多轮会话上下文记忆，支持 GPT-3.5, GPT-4, claude, Gemini, 文心一言, 讯飞星火, 通义千问\n- [x] **语音能力：** 可识别语音消息，通过文字或语音回复，支持 azure, baidu, google, openai(whisper/tts) 等多种语音模型\n- [x] **图像能力：** 支持图片生成、图片识别、图生图（如照片修复），可选择 Dall-E-3, stable diffusion, replicate, midjourney, vision模型\n- [x] **丰富插件：** 支持个性化插件扩展，已实现多角色切换、文字冒险、敏感词过滤、聊天记录总结、文档总结和对话、联网搜索等插件\n- [x] **知识库：** 通过上传知识库文件自定义专属机器人，可作为数字分身、智能客服、私域助手使用，基于 [LinkAI](https://link-ai.tech) 实现\n\n# 演示\n\nhttps://github.com/zhayujie/chatgpt-on-wechat/assets/26161723/d5154020-36e3-41db-8706-40ce9f3f1b1e\n\nDemo made by [Visionn](https://www.wangpc.cc/)\n\n# 商业支持\n\n> 我们还提供企业级的 **AI应用平台**，包含知识库、Agent插件、应用管理等能力，支持多平台聚合的应用接入、客户端管理、对话管理，以及提供\nSaaS服务、私有化部署、稳定托管接入 等多种模式。\n>\n> 目前已在私域运营、智能客服、企业效率助手等场景积累了丰富的 AI 解决方案， 在电商、文教、健康、新消费等各行业沉淀了 AI 落地的最佳实践，致力于打造助力中小企业拥抱 AI 的一站式平台。\n\n企业服务和商用咨询可联系产品顾问：\n\n<img alt=\"product_manager_qrcode\" width=\"240\" src=\"https://img-1317903499.cos.ap-guangzhou.myqcloud.com/docs/product-manager-qrcode.jpg\">\n\n# 开源社区\n\n添加小助手微信加入开源项目交流群：\n\n\n\n# 更新日志\n\n>**2023.11.11：** [1.5.3版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.3) 和 [1.5.4版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.4)，新增Google Gemini、通义千问模型\n\n>**2023.11.10：** [1.5.2版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.2)，新增飞书通道、图像识别对话、黑名单配置\n\n>**2023.11.10：** [1.5.0版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.0)，新增 `gpt-4-turbo`, `dall-e-3`, `tts` 模型接入，完善图像理解&生成、语音识别&生成的多模态能力\n\n>**2023.10.16：** 支持通过意图识别使用LinkAI联网搜索、数学计算、网页访问等插件，参考[插件文档](https://docs.link-ai.tech/platform/plugins)\n\n>**2023.09.26：** 插件增加 文件/文章链接 一键总结和对话的功能，使用参考：[插件说明](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins/linkai#3%E6%96%87%E6%A1%A3%E6%80%BB%E7%BB%93%E5%AF%B9%E8%AF%9D%E5%8A%9F%E8%83%BD)\n\n>**2023.08.08：** 接入百度文心一言模型，通过 [插件](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins/linkai) 支持 Midjourney 绘图\n\n>**2023.06.12：** 接入 [LinkAI](https://link-ai.tech/console) 平台，可在线创建领域知识库，并接入微信、公众号及企业微信中，打造专属客服机器人。使用参考 [接入文档](https://link-ai.tech/platform/link-app/wechat)。\n\n>**2023.04.26：** 支持企业微信应用号部署，兼容插件，并支持语音图片交互，私人助理理想选择，[使用文档](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/wechatcom/README.md)。(contributed by [@lanvent](https://github.com/lanvent) in [#944](https://github.com/zhayujie/chatgpt-on-wechat/pull/944))\n\n>**2023.04.05：** 支持微信公众号部署，兼容插件，并支持语音图片交互，[使用文档](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/wechatmp/README.md)。(contributed by [@JS00000](https://github.com/JS00000) in [#686](https://github.com/zhayujie/chatgpt-on-wechat/pull/686))\n\n>**2023.04.05：** 增加能让ChatGPT使用工具的`tool`插件，[使用文档](https://github.com/goldfishh/chatgpt-on-wechat/blob/master/plugins/tool/README.md)。工具相关issue可反馈至[chatgpt-tool-hub](https://github.com/goldfishh/chatgpt-tool-hub)。(contributed by [@goldfishh](https://github.com/goldfishh) in [#663](https://github.com/zhayujie/chatgpt-on-wechat/pull/663))\n\n>**2023.03.25：** 支持插件化开发，目前已实现 多角色切换、文字冒险游戏、管理员指令、Stable Diffusion等插件，使用参考 [#578](https://github.com/zhayujie/chatgpt-on-wechat/issues/578)。(contributed by [@lanvent](https://github.com/lanvent) in [#565](https://github.com/zhayujie/chatgpt-on-wechat/pull/565))\n\n>**2023.03.09：** 基于 `whisper API`(后续已接入更多的语音`API`服务) 实现对微信语音消息的解析和回复，添加配置项 `\"speech_recognition\":true` 即可启用，使用参考 [#415](https://github.com/zhayujie/chatgpt-on-wechat/issues/415)。(contributed by [wanggang1987](https://github.com/wanggang1987) in [#385](https://github.com/zhayujie/chatgpt-on-wechat/pull/385))\n\n>**2023.02.09：** 扫码登录存在账号限制风险，请谨慎使用，参考[#58](https://github.com/AutumnWhj/ChatGPT-wechat-bot/issues/158)\n\n# 快速开始\n\n快速开始文档：[项目搭建文档](https://docs.link-ai.tech/cow/quick-start)\n\n## 准备\n\n### 1. 账号注册\n\n项目默认使用OpenAI接口，需前往 [OpenAI注册页面](https://beta.openai.com/signup) 创建账号，创建完账号则前往 [API管理页面](https://beta.openai.com/account/api-keys) 创建一个 API Key 并保存下来，后面需要在项目中配置这个key。接口需要海外网络访问及绑定信用卡支付。\n\n> 默认对话模型是 openai 的 gpt-3.5-turbo，计费方式是约每 1000tokens (约750个英文单词 或 500汉字，包含请求和回复) 消耗 $0.002，图片生成是Dell E模型，每张消耗 $0.016。\n\n项目同时也支持使用 LinkAI 接口，无需代理，可使用 文心、讯飞、GPT-3、GPT-4 等模型，支持 定制化知识库、联网搜索、MJ绘图、文档总结和对话等能力。修改配置即可一键切换，参考 [接入文档](https://link-ai.tech/platform/link-app/wechat)。\n\n### 2.运行环境\n\n支持 Linux、MacOS、Windows 系统（可在Linux服务器上长期运行)，同时需安装 `Python`。\n> 建议Python版本在 3.7.1~3.9.X 之间，推荐3.8版本，3.10及以上版本在 MacOS 可用，其他系统上不确定能否正常运行。\n\n> 注意：Docker 或 Railway 部署无需安装python环境和下载源码，可直接快进到下一节。\n\n**(1) 克隆项目代码：**\n\n```bash\ngit clone https://github.com/zhayujie/chatgpt-on-wechat\ncd chatgpt-on-wechat/\n```\n\n注: 如遇到网络问题可选择国内镜像 https://gitee.com/zhayujie/chatgpt-on-wechat\n\n**(2) 安装核心依赖 (必选)：**\n> 能够使用`itchat`创建机器人，并具有文字交流功能所需的最小依赖集合。\n```bash\npip3 install -r requirements.txt\n```\n\n**(3) 拓展依赖 (可选，建议安装)：**\n\n```bash\npip3 install -r requirements-optional.txt\n```\n> 如果某项依赖安装失败可注释掉对应的行再继续\n\n## 配置\n\n配置文件的模板在根目录的`config-template.json`中，需复制该模板创建最终生效的 `config.json` 文件：\n\n```bash\n  cp config-template.json config.json\n```\n\n然后在`config.json`中填入配置，以下是对默认配置的说明，可根据需要进行自定义修改（请去掉注释）：\n\n```bash\n# config.json文件内容示例\n{\n  \"open_ai_api_key\": \"YOUR API KEY\",                          # 填入上面创建的 OpenAI API KEY\n  \"model\": \"gpt-3.5-turbo\",                                   # 模型名称, 支持 gpt-3.5-turbo, gpt-3.5-turbo-16k, gpt-4, wenxin, xunfei\n  \"proxy\": \"\",                                                # 代理客户端的ip和端口，国内环境开启代理的需要填写该项，如 \"127.0.0.1:7890\"\n  \"single_chat_prefix\": [\"bot\", \"@bot\"],                      # 私聊时文本需要包含该前缀才能触发机器人回复\n  \"single_chat_reply_prefix\": \"[bot] \",                       # 私聊时自动回复的前缀，用于区分真人\n  \"group_chat_prefix\": [\"@bot\"],                              # 群聊时包含该前缀则会触发机器人回复\n  \"group_name_white_list\": [\"ChatGPT测试群\", \"ChatGPT测试群2\"], # 开启自动回复的群名称列表\n  \"group_chat_in_one_session\": [\"ChatGPT测试群\"],              # 支持会话上下文共享的群名称  \n  \"image_create_prefix\": [\"画\", \"看\", \"找\"],                   # 开启图片回复的前缀\n  \"conversation_max_tokens\": 1000,                            # 支持上下文记忆的最多字符数\n  \"speech_recognition\": false,                                # 是否开启语音识别\n  \"group_speech_recognition\": false,                          # 是否开启群组语音识别\n  \"use_azure_chatgpt\": false,                                 # 是否使用Azure ChatGPT service代替openai ChatGPT service. 当设置为true时需要设置 open_ai_api_base，如 https://xxx.openai.azure.com/\n  \"azure_deployment_id\": \"\",                                  # 采用Azure ChatGPT时，模型部署名称\n  \"azure_api_version\": \"\",                                    # 采用Azure ChatGPT时，API版本\n  \"character_desc\": \"你是ChatGPT, 一个由OpenAI训练的大型语言模型, 你旨在回答并解决人们的任何问题，并且可以使用多种语言与人交流。\",  # 人格描述\n  # 订阅消息，公众号和企业微信channel中请填写，当被订阅时会自动回复，可使用特殊占位符。目前支持的占位符有{trigger_prefix}，在程序中它会自动替换成bot的触发词。\n  \"subscribe_msg\": \"感谢您的关注！\\n这里是ChatGPT，可以自由对话。\\n支持语音对话。\\n支持图片输出，画字开头的消息将按要求创作图片。\\n支持角色扮演和文字冒险等丰富插件。\\n输入{trigger_prefix}#help 查看详细指令。\",\n  \"use_linkai\": false,                                        # 是否使用LinkAI接口，默认关闭，开启后可国内访问，使用知识库和MJ\n  \"linkai_api_key\": \"\",                                       # LinkAI Api Key\n  \"linkai_app_code\": \"\"                                       # LinkAI 应用code\n}\n```\n**配置说明：**\n\n**1.个人聊天**\n\n+ 个人聊天中，需要以 \"bot\"或\"@bot\" 为开头的内容触发机器人，对应配置项 `single_chat_prefix` (如果不需要以前缀触发可以填写  `\"single_chat_prefix\": [\"\"]`)\n+ 机器人回复的内容会以 \"[bot] \" 作为前缀， 以区分真人，对应的配置项为 `single_chat_reply_prefix` (如果不需要前缀可以填写 `\"single_chat_reply_prefix\": \"\"`)\n\n**2.群组聊天**\n\n+ 群组聊天中，群名称需配置在 `group_name_white_list ` 中才能开启群聊自动回复。如果想对所有群聊生效，可以直接填写 `\"group_name_white_list\": [\"ALL_GROUP\"]`\n+ 默认只要被人 @ 就会触发机器人自动回复；另外群聊天中只要检测到以 \"@bot\" 开头的内容，同样会自动回复（方便自己触发），这对应配置项 `group_chat_prefix`\n+ 可选配置: `group_name_keyword_white_list`配置项支持模糊匹配群名称，`group_chat_keyword`配置项则支持模糊匹配群消息内容，用法与上述两个配置项相同。（Contributed by [evolay](https://github.com/evolay))\n+ `group_chat_in_one_session`：使群聊共享一个会话上下文，配置 `[\"ALL_GROUP\"]` 则作用于所有群聊\n\n**3.语音识别**\n\n+ 添加 `\"speech_recognition\": true` 将开启语音识别，默认使用openai的whisper模型识别为文字，同时以文字回复，该参数仅支持私聊 (注意由于语音消息无法匹配前缀，一旦开启将对所有语音自动回复，支持语音触发画图)；\n+ 添加 `\"group_speech_recognition\": true` 将开启群组语音识别，默认使用openai的whisper模型识别为文字，同时以文字回复，参数仅支持群聊 (会匹配group_chat_prefix和group_chat_keyword, 支持语音触发画图)；\n+ 添加 `\"voice_reply_voice\": true` 将开启语音回复语音（同时作用于私聊和群聊），但是需要配置对应语音合成平台的key，由于itchat协议的限制，只能发送语音mp3文件，若使用wechaty则回复的是微信语音。\n\n**4.其他配置**\n\n+ `model`: 模型名称，目前支持 `gpt-3.5-turbo`, `text-davinci-003`, `gpt-4`, `gpt-4-32k`, `wenxin` , `claude` ,  `xunfei`(其中gpt-4 api暂未完全开放，申请通过后可使用)\n+ `temperature`,`frequency_penalty`,`presence_penalty`: Chat API接口参数，详情参考[OpenAI官方文档。](https://platform.openai.com/docs/api-reference/chat)\n+ `proxy`：由于目前 `openai` 接口国内无法访问，需配置代理客户端的地址，详情参考  [#351](https://github.com/zhayujie/chatgpt-on-wechat/issues/351)\n+ 对于图像生成，在满足个人或群组触发条件外，还需要额外的关键词前缀来触发，对应配置 `image_create_prefix `\n+ 关于OpenAI对话及图片接口的参数配置（内容自由度、回复字数限制、图片大小等），可以参考 [对话接口](https://beta.openai.com/docs/api-reference/completions) 和 [图像接口](https://beta.openai.com/docs/api-reference/completions)  文档，在[`config.py`](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/config.py)中检查哪些参数在本项目中是可配置的。\n+ `conversation_max_tokens`：表示能够记忆的上下文最大字数（一问一答为一组对话，如果累积的对话字数超出限制，就会优先移除最早的一组对话）\n+ `rate_limit_chatgpt`，`rate_limit_dalle`：每分钟最高问答速率、画图速率，超速后排队按序处理。\n+ `clear_memory_commands`: 对话内指令，主动清空前文记忆，字符串数组可自定义指令别名。\n+ `hot_reload`: 程序退出后，暂存微信扫码状态，默认关闭。\n+ `character_desc` 配置中保存着你对机器人说的一段话，他会记住这段话并作为他的设定，你可以为他定制任何人格      (关于会话上下文的更多内容参考该 [issue](https://github.com/zhayujie/chatgpt-on-wechat/issues/43))\n+ `subscribe_msg`：订阅消息，公众号和企业微信channel中请填写，当被订阅时会自动回复， 可使用特殊占位符。目前支持的占位符有{trigger_prefix}，在程序中它会自动替换成bot的触发词。\n\n**5.LinkAI配置 (可选)**\n\n+ `use_linkai`: 是否使用LinkAI接口，开启后可国内访问，使用知识库和 `Midjourney` 绘画, 参考 [文档](https://link-ai.tech/platform/link-app/wechat)\n+ `linkai_api_key`: LinkAI Api Key，可在 [控制台](https://link-ai.tech/console/interface) 创建\n+ `linkai_app_code`: LinkAI 应用code，选填\n\n**本说明文档可能会未及时更新，当前所有可选的配置项均在该[`config.py`](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/config.py)中列出。**\n\n## 运行\n\n### 1.本地运行\n\n如果是开发机 **本地运行**，直接在项目根目录下执行：\n\n```bash\npython3 app.py                                    # windows环境下该命令通常为 python app.py\n```\n\n终端输出二维码后，使用微信进行扫码，当输出 \"Start auto replying\" 时表示自动回复程序已经成功运行了（注意：用于登录的微信需要在支付处已完成实名认证）。扫码登录后你的账号就成为机器人了，可以在微信手机端通过配置的关键词触发自动回复 (任意好友发送消息给你，或是自己发消息给好友)，参考[#142](https://github.com/zhayujie/chatgpt-on-wechat/issues/142)。\n\n### 2.服务器部署\n\n使用nohup命令在后台运行程序：\n\n```bash\nnohup python3 app.py & tail -f nohup.out          # 在后台运行程序并通过日志输出二维码\n```\n扫码登录后程序即可运行于服务器后台，此时可通过 `ctrl+c` 关闭日志，不会影响后台程序的运行。使用 `ps -ef | grep app.py | grep -v grep` 命令可查看运行于后台的进程，如果想要重新启动程序可以先 `kill` 掉对应的进程。日志关闭后如果想要再次打开只需输入 `tail -f nohup.out`。此外，`scripts` 目录下有一键运行、关闭程序的脚本供使用。\n\n> **多账号支持：** 将项目复制多份，分别启动程序，用不同账号扫码登录即可实现同时运行。\n\n> **特殊指令：** 用户向机器人发送 **#reset** 即可清空该用户的上下文记忆。\n\n\n### 3.Docker部署\n\n> 使用docker部署无需下载源码和安装依赖，只需要获取 docker-compose.yml 配置文件并启动容器即可。\n\n> 前提是需要安装好 `docker` 及 `docker-compose`，安装成功的表现是执行 `docker -v` 和 `docker-compose version` (或 docker compose version) 可以查看到版本号，可前往 [docker官网](https://docs.docker.com/engine/install/) 进行下载。\n\n#### (1) 下载 docker-compose.yml 文件\n\n```bash\nwget https://open-1317903499.cos.ap-guangzhou.myqcloud.com/docker-compose.yml\n```\n\n下载完成后打开 `docker-compose.yml` 修改所需配置，如 `OPEN_AI_API_KEY` 和 `GROUP_NAME_WHITE_LIST` 等。\n\n#### (2) 启动容器\n\n在 `docker-compose.yml` 所在目录下执行以下命令启动容器：\n\n```bash\nsudo docker compose up -d\n```\n\n运行 `sudo docker ps` 能查看到 NAMES 为 chatgpt-on-wechat 的容器即表示运行成功。\n\n注意：\n\n - 如果 `docker-compose` 是 1.X 版本 则需要执行 `sudo  docker-compose up -d` 来启动容器\n - 该命令会自动去 [docker hub](https://hub.docker.com/r/zhayujie/chatgpt-on-wechat) 拉取 latest 版本的镜像，latest 镜像会在每次项目 release 新的版本时生成\n\n最后运行以下命令可查看容器运行日志，扫描日志中的二维码即可完成登录：\n\n```bash\nsudo docker logs -f chatgpt-on-wechat\n```\n\n#### (3) 插件使用\n\n如果需要在docker容器中修改插件配置，可通过挂载的方式完成，将 [插件配置文件](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/plugins/config.json.template)\n重命名为 `config.json`，放置于 `docker-compose.yml` 相同目录下，并在 `docker-compose.yml` 中的 `chatgpt-on-wechat` 部分下添加 `volumes` 映射:\n\n```\nvolumes:\n  - ./config.json:/app/plugins/config.json\n```\n\n### 4. Railway部署\n\n> Railway 每月提供5刀和最多500小时的免费额度。 (07.11更新: 目前大部分账号已无法免费部署)\n\n1. 进入 [Railway](https://railway.app/template/qApznZ?referralCode=RC3znh)\n2. 点击 `Deploy Now` 按钮。\n3. 设置环境变量来重载程序运行的参数，例如`open_ai_api_key`, `character_desc`。\n\n**一键部署:**\n  \n  [![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/template/qApznZ?referralCode=RC3znh)\n\n## 常见问题\n\nFAQs： <https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs>\n\n或直接在线咨询 [项目小助手](https://link-ai.tech/app/Kv2fXJcH)  (beta版本，语料完善中，回复仅供参考)\n\n## 开发\n\n欢迎接入更多应用，参考 [Terminal代码](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/terminal/terminal_channel.py) 实现接收和发送消息逻辑即可接入。 同时欢迎增加新的插件，参考 [插件说明文档](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins)。\n\n## 联系\n\n欢迎提交PR、Issues，以及Star支持一下。程序运行遇到问题可以查看 [常见问题列表](https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs) ，其次前往 [Issues](https://github.com/zhayujie/chatgpt-on-wechat/issues) 中搜索。个人开发者可加入开源交流群参与更多讨论，企业用户可联系[产品顾问](https://img-1317903499.cos.ap-guangzhou.myqcloud.com/docs/product-manager-qrcode.jpg)咨询。",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "chatgpt",
        "dialogue",
        "wechat",
        "dialogue service",
        "chatgpt wechat",
        "rsagacom chatgpt"
      ],
      "category": "virtual-assistants"
    },
    "scarletlabs-ai--Votars-MCP": {
      "owner": "scarletlabs-ai",
      "name": "Votars-MCP",
      "url": "https://github.com/scarletlabs-ai/Votars-MCP",
      "imageUrl": "/freedevtools/mcp/pfp/scarletlabs-ai.webp",
      "description": "Integrate advanced AI functionalities for processing complex tasks through robust APIs. Supports voice recording, transcription, and intelligent AI processing for meetings.",
      "stars": 27,
      "forks": 2,
      "license": "No License",
      "language": "Go",
      "updated_at": "2025-07-07T07:12:32Z",
      "readme_content": "![Votars Logo](https://votars.ai/_next/static/media/logo.e7b6bff6.svg) \n# Votars MCP \n[![smithery badge](https://smithery.ai/badge/@scarletlabs-ai/votars-mcp)](https://smithery.ai/server/@scarletlabs-ai/votars-mcp)\n\n\n## Overview\n\nVotars-MCP is a tool that supports multiple language implementations of the **Votars MCP server**. Currently, only the Go version is available, with other languages to be added in future releases. It supports two interaction modes: `sse` (Server-Sent Events) and `stdio` (Standard Input/Output). It is designed to provide seamless integration with the Votars AI platform for processing various tasks.\n\n## About Votars\n\n[Votars](https://votars.ai/en/) is the world's smartest multilingual meeting assistant, designed for voice recording, transcription, and advanced AI processing. It features real-time translation, intelligent error correction, AI summarization, smart content generation, and AI discussions. The Votars app is available on [Web](https://votars.ai/en/), [iOS](https://apps.apple.com/us/app/votars-ai-transcribe-organize/id6737496290), and [Android](https://play.google.com/store/apps/details?id=com.votars.transcribe).\n\nAdditionally, Votars is an AI-powered platform that enables developers to integrate advanced AI functionalities into their applications. By leveraging Votars, you can process complex tasks efficiently with robust APIs designed for high performance and scalability.\n\n## Features\n- **Easy Integration with Votars**\n- **Modular Design:** Ready to be extended with additional functionalities.\n- **Supported MCP Tools:**\n  - `Votars_fetch_recent_transcripts`: Allows users to read recent transcripts from their workspace, providing convenient access to the latest recorded sessions.\n  - `Votars_fetch_a_specific_transcript`: Enables users to retrieve specific transcripts by providing a transcript ID, allowing targeted retrieval of stored data.\n  \n  More functionalities will be added soon. Stay tuned!\n\n## Installation (Go MCP)\n\n### Installing via Smithery\n\nTo install votars-mcp for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@scarletlabs-ai/votars-mcp):\n\n```bash\nnpx -y @smithery/cli install @scarletlabs-ai/votars-mcp --client claude\n```\n\n### Manual Installation\nTo install the Go version of Votars MCP from the GitHub repository, use:\n\n```bash\n go install github.com/scarletlabs-ai/Votars-MCP/go/votars-mcp@latest\n```\n\n## Usage (Go MCP)\n\n### Run MCP Service\nBefore using the `sse` mode, you need to run the MCP server. Open a terminal and run:\n\n```bash\nvotars-mcp -t sse -p 8080\n```\n\nThis command starts the MCP service on port 8080, ready to accept `sse` requests.\n\n\n### 1. SSE Mode\n\nFor `sse` mode, you need to provide the API key via request headers in the configuration file.\n\nConfiguration file example (`mcp.config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"Votars MCP\": {\n      \"type\": \"sse\",\n      \"url\": \"http://0.0.0.0:8080/sse\",\n      \"headers\": {\n        \"Authorization\": \"Bearer <your-api-key>\"\n      }\n    }\n  }\n}\n```\n\n### 2. Stdio Mode\n\nFor `stdio` mode, set the API key as an environment variable.\n\n\nConfiguration file example (`mcp.config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"Votars MCP Stdio\": {\n      \"type\": \"stdio\",\n      \"command\": \"votars-mcp\",\n      \"args\": [\"-t\", \"stdio\"],\n      \"env\": {\n        \"VOTARS_API_KEY\": \"<your-api-key>\"\n      }\n    }\n  }\n}\n```\n\n## Obtaining Your API Key\n\n1. Go to [Votars.AI](https://votars.ai/en/) and register.\n2. Navigate to your workspace's `Settings`.\n3. Create an API Key under the API Key management section.\n\n\n\n## Roadmap\n\n- **Current Support:** Go\n- **Planned Support:** Python, JavaScript, Rust, etc.\n\n## License\n\nMIT License",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "voice",
        "assistants",
        "virtual assistants",
        "scarletlabs ai",
        "transcription intelligent"
      ],
      "category": "virtual-assistants"
    },
    "suryawanshishantanu6--time-mcp": {
      "owner": "suryawanshishantanu6",
      "name": "time-mcp",
      "url": "https://github.com/suryawanshishantanu6/time-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/suryawanshishantanu6.webp",
      "description": "Integrates a tool-augmented LLM pipeline to provide answers to time-related and general inquiries. Utilizes a Flask API for current timestamps and employs an MCP Agent for intent detection and interaction with an LLM via OpenRouter.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-08T03:55:06Z",
      "readme_content": "# time-mcp\n\nA minimal agentic AI system that answers time-related and general questions using a tool-augmented LLM pipeline.\n\n## Features\n- **Flask API**: Provides the current timestamp.\n- **MCP Agent Server**: Reasoning agent that detects user intent, calls tools (like the time API), engineers prompts, and interacts with an LLM via OpenRouter (OpenAI-compatible API).\n- **Streamlit UI**: Simple chat interface to talk to the AI agent.\n\n---\n\n## Setup\n\n### 1. Clone and Install Dependencies\n```bash\npip install -r requirements.txt\n```\n\n### 2. Environment Variable\nSet your OpenRouter API key (get one from https://openrouter.ai):\n```bash\nexport OPENROUTER_API_KEY=sk-...your-key...\n```\n\n### 3. Run the Servers\nOpen three terminals (or use background processes):\n\n#### Terminal 1: Flask Time API\n```bash\npython flask_api.py\n```\n\n#### Terminal 2: MCP Agent Server\n```bash\npython mcp_server.py\n```\n\n#### Terminal 3: Streamlit UI\n```bash\nstreamlit run streamlit_ui.py\n```\n\nThe Streamlit UI will open in your browser (default: http://localhost:8501)\n\n---\n\n## Usage\n- Ask the agent any question in the Streamlit UI.\n- If you ask about the time (e.g., \"What is the time?\"), the agent will call the Flask API, fetch the current time, and craft a beautiful, natural response using the LLM.\n- For other questions, the agent will answer using the LLM only.\n\n---\n\n## Architecture\n```\n[Streamlit UI] → [MCP Agent Server] → [Tools (e.g., Time API)]\n                            ↓\n                        [LLM via OpenRouter]\n```\n- The MCP agent detects intent, calls tools as needed, engineers prompts, and sends them to the LLM.\n- Easily extensible to add more tools (just add to the MCPAgent class).\n\n---\n\n## Customization\n- **Add more tools**: Implement new methods in `MCPAgent` and update `self.tools`.\n- **Improve intent detection**: Extend `detect_intent()` in `MCPAgent`.\n- **Change LLM model**: Update the `model` field in `call_llm()`.\n\n---\n\n## Requirements\n- Python 3.7+\n- See `requirements.txt` for dependencies.\n\n---\n\n## Credits\n- Built using Flask, Streamlit, OpenRouter, and Python.\n- Inspired by agentic LLM design patterns.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llm",
        "timestamps",
        "api",
        "virtual assistants",
        "augmented llm",
        "llm pipeline"
      ],
      "category": "virtual-assistants"
    },
    "tijs--py-sound-mcp": {
      "owner": "tijs",
      "name": "py-sound-mcp",
      "url": "https://github.com/tijs/py-sound-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/tijs.webp",
      "description": "Plays customizable sound effects for coding events such as completions and errors, providing audio feedback in MCP-compatible environments. Integrates seamlessly with tools like Cursor to enhance the interactive development experience.",
      "stars": 1,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-12T09:02:31Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/tijs-py-sound-mcp-badge.png)](https://mseep.ai/app/tijs-py-sound-mcp)\n\n# MCP Sound Tool\n\nA Model Context Protocol (MCP) implementation that plays sound effects for Cursor AI and other MCP-compatible environments. This Python implementation provides audio feedback for a more interactive coding experience.\n\n## Features\n\n* Plays sound effects for various events (completion, error, notification)\n* Uses the Model Context Protocol (MCP) for standardized integration with Cursor and other IDEs\n* Cross-platform support (Windows, macOS, Linux)\n* Configurable sound effects\n\n## Installation\n\n### Python Version Compatibility\n\nThis package is tested with Python 3.8-3.11. If you encounter errors with Python 3.12+ (particularly `BrokenResourceError` or `TaskGroup` exceptions), please try using an earlier Python version.\n\n### Recommended: Install with pipx\n\nThe recommended way to install mcp-sound-tool is with [pipx](https://pypa.github.io/pipx/), which installs the package in an isolated environment while making the commands available globally:\n\n```bash\n# Install pipx if you don't have it\npython -m pip install --user pipx\npython -m pipx ensurepath\n\n# Install mcp-sound-tool\npipx install mcp-sound-tool\n```\n\nThis method ensures that the tool has its own isolated environment, avoiding conflicts with other packages.\n\n### Alternative: Install with pip\n\nYou can also install directly with pip:\n\n```bash\npip install mcp-sound-tool\n```\n\n### From Source\n\n1. Clone this repository:\n\n   ```bash\n   git clone https://github.com/yourusername/mcp-sound-tool\n   cd mcp-sound-tool\n   ```\n\n2. Install with pipx directly from the source directory:\n\n   ```bash\n   pipx install .\n   ```\n\n   Or with pip:\n\n   ```bash\n   pip install -e .\n   ```\n\n## Usage\n\n### Adding Sound Files\n\nPlace your sound files in the `sounds` directory. The following sound files are expected:\n\n* `completion.mp3` - Played after code generation\n* `error.mp3` - Played when an error occurs\n* `notification.mp3` - Used for general notifications\n\nYou can find free sound effects on websites like freesound.org.\n\n### Running the MCP Server\n\nRun the MCP server:\n\n```bash\nmcp-sound-tool\n```\n\nThe server will start and listen for events from Cursor or other MCP-compatible clients through the stdio transport.\n\n### Configuration in Cursor\n\nTo use this server with Cursor, add it to your MCP configuration file:\n\nOn macOS:\n\n```json\n// ~/Library/Application Support/Cursor/mcp.json\n{\n  \"mcpServers\": {\n    \"sound\": {\n      \"command\": \"mcp-sound-tool\",\n      \"args\": [],\n      \"type\": \"stdio\",\n      \"pollingInterval\": 5000,\n      \"startupTimeout\": 10000,\n      \"restartOnFailure\": true\n    }\n  }\n}\n```\n\nOn Windows:\n\n```json\n// %APPDATA%/Cursor/mcp.json\n{\n  \"mcpServers\": {\n    \"sound\": {\n      \"command\": \"mcp-sound-tool\",\n      \"args\": [],\n      \"type\": \"stdio\",\n      \"pollingInterval\": 5000,\n      \"startupTimeout\": 10000,\n      \"restartOnFailure\": true\n    }\n  }\n}\n```\n\nWhen installed with `pipx`, the `mcp-sound-tool` command will be available in your PATH, so Cursor will be able to find and execute it without specifying the full path.\n\n## Sound MCP Usage Guidelines for AI Models\n\nThis MCP server provides audio feedback capabilities for AI interactions. It's designed to enhance the user experience by providing clear audio cues that indicate the status of operations without requiring the user to read text.\n\n### When to Use Sound Feedback\n\nAI agents should use the sound tools proactively at appropriate moments:\n\n1. **Success Sounds (`completion`)**:\n   * After a task or command has successfully completed\n   * When a significant operation has finished successfully\n   * When confirming a user's request has been fulfilled\n\n2. **Error Sounds (`error`)**:\n   * When a command has failed or encountered an error\n   * When warning the user about a problem\n   * When an operation couldn't be completed as requested\n\n3. **Notification Sounds (`notification`)**:\n   * When alerting the user to important information\n   * When prompting for user attention or input\n   * For status updates on long-running operations\n\n### Example Usage\n\n```python\n# When a command completes successfully\n@mcp.tool()\ndef execute_command(command):\n    result = run_command(command)\n    if result.success:\n        play_sound(\"completion\")  # Indicate success with audio\n        return \"Command executed successfully\"\n    else:\n        play_sound(\"error\")  # Indicate failure with audio\n        return f\"Error: {result.error_message}\"\n```\n\n### Available Tools\n\n1. `play_sound(sound_type=\"completion\", custom_sound_path=None)`: Play a sound effect\n2. `list_available_sounds()`: List all available sound files\n3. `install_to_user_dir()`: Install sound files to user's config directory\n\nFor more details, connect to the MCP server and check the tool descriptions.\n\n## Development\n\nFor development:\n\n```bash\n# Install development dependencies\npip install -e \".[dev]\"\n\n# Run tests\npytest\n```\n\n## Acknowledgments\n\n* [SIAM-TheLegend](https://github.com/SIAM-TheLegend) for creating the original [sound-mcp](https://github.com/SIAM-TheLegend/sound-mcp) JavaScript implementation that inspired this Python version\n* The MCP protocol developers for creating a powerful standard for AI tool interactions\n* Contributors to the testing and documentation\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "interactive",
        "sound",
        "audio",
        "py sound",
        "sound mcp",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "veenastudio--flstudio-mcp": {
      "owner": "veenastudio",
      "name": "flstudio-mcp",
      "url": "https://github.com/veenastudio/flstudio-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/veenastudio.webp",
      "description": "Connects AI model Claude to FL Studio for seamless integration of melodies, chords, and drum patterns into music projects. Facilitates real-time music production by allowing interaction between AI and the FL Studio environment.",
      "stars": 59,
      "forks": 4,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-30T19:37:52Z",
      "readme_content": "# flstudio MCP\n\n# This is an MCP server that connects Claude to FL Studio.\nMade this in 3 days. We're open sourcing it to see what we can actually get out of it. The possibilities are endless.\n\n## If you're running to any issues, join our discord and we can setup it for you.\n(also join if you interested in the future of music and AI or want to request features. we're building this with you)\n\nhttps://discord.gg/ZjG9TaEhvy\n\nCheck out our AI-Powered DAW for musicians at www.veena.studio\n\nAll in browser. All for free.\n\n\n## Step 1: Download the Files\nYou should see two main items.\n\n- A folder called Test Controller\n- A python file called trigger.py\nThe Test Controller folder has a file called device_test.py that receives information from the MCP server.\ntrigger.py is the MCP server.\n\nPlace the Test Controller folder in Image-Line/FL Studio/Settings/Hardware (Don't change the name of this file or folder)\n\n## Step 2: Set up MCP for Claude\nFollow this tutorial to see how to setup MCP servers in Claude by edyting the claude_desktop_config files.\n\nhttps://modelcontextprotocol.io/quickstart/server\n\nIf you followed this process, make sure to change whatever mentions of weather.py to trigger.py\n\nIf the Hammer icon doesn't show up, open Task Manager and force close the Claude process.\n\nIt should then show up.\n\nThis is what my config file looks like\n\n![mcp](https://github.com/user-attachments/assets/e8e609f7-eaa4-469b-9140-c05b5a9bf242)\n\n## Step 3: Set Up Virtual MIDI Ports\n\n### For Windows\nFor Windows, download LoopMIDI from here.\n\nhttps://www.tobias-erichsen.de/software/loopmidi.html\n\nInstall LoopMIDI and add a port using the + button.\n\nThis is what mine looks like:\n![loopmidi2](https://github.com/user-attachments/assets/fdc2770f-e07a-4b19-824b-56de8a4aa2c3)\n\n### For Mac\nYour MIDI Ports would be automatically setup to receive data.\n\n## Step 4: Setup MIDI Controller\nOpen FL Studio.\n\nGo To Options > MIDI Settings.\n\nIn the Input Tab, click the MIDI Input you just created with LoopMIDI.\n\nChange controller type from (generic controller) to Test Controller.\n\n## Step 5: Download Packages\nGo to the folder with the trigger.py file. (This is the MCP Server file)\n\nActivate the conda environment (like you learned in the Claude MCP Setup Tutorial)\n\nRun this command to download the necessary packages: uv pip install httpx mido python-rtmidi typing fastmcp FL-Studio-API-Stubs\n(uv should be installed from the Claude MCP setup)\n\n## Step 6: Verify MCP Connection\nTell Claude to get available MIDI ports.\n\nThis should use the MCP to get the ports from FL Studio.\n\nIf Windows, copy the port you created with LoopMIDI and the number in front of it.\n\nIf Mac, copy the default port.\n\n![loopmidi](https://github.com/user-attachments/assets/a14b0aaa-5127-47c9-b041-fcb5a70339d9)\n\nIn my case, I copy loopMIDI Port 2\n\nOpen trigger.py in a text editor and replace the default port with the name of the port you just copied.\noutput_port = mido.open_output('loopMIDI Port 2') \n\n\n## Step 7: Make Music\nUse the MCP to send melodies, chords, drums, etc.\n\nClick on the instrument you want to record to and it will live record to the piano roll of that instrument.\n\nI tend to use this prompt when I start a new chat: Here is format for notes: note(0-127),velocity(0-100),length in beats(decimal),position in beats(decimal)\n\n## Step 8: Share what you made\nShare what you made on our Discord: https://discord.gg/ZjG9TaEhvy\n\n## Credits\nFL Studio API Stubs: https://github.com/IL-Group/FL-Studio-API-Stubs\nAbleton MCP: https://github.com/ahujasid/ableton-mcp\n\n## Nerd Stuff\nIf you want to contribute please go ahead. \n\nThe way this works is that device_test.py behaves as a virtual MIDI Controller.\nThe MCP server (trigger.py) communicates with this MIDI Controller by opening a Virtual Port and sending MIDI messages through a library called MIDO.\n\nThe issue with MIDI messages is that its only 7 bits so we can only send in number from 0-127.\n\nSo we encrypt all of our MIDI data like note position, etc in multiple MIDI notes that the device knows how to read.\n\nHopefully, Image Line can give us more access to their DAW via their API so we don't have to do this MIDI nonsense.\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "flstudio",
        "studio",
        "ai",
        "fl studio",
        "flstudio mcp",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    }
  }
}