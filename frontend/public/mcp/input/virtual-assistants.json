{
  "category": "virtual-assistants",
  "categoryDisplay": "Virtual Assistants",
  "description": "",
  "totalRepositories": 45,
  "repositories": {
    "AI-QL--chat-mcp": {
      "owner": "AI-QL",
      "name": "chat-mcp",
      "url": "https://github.com/AI-QL/chat-mcp",
      "imageUrl": "https://github.com/AI-QL.png",
      "description": "A cross-platform desktop application that connects and interacts with various Large Language Models (LLMs) via the Model Context Protocol (MCP). It provides a clean and minimalistic codebase for testing and understanding MCP functionalities.",
      "stars": 238,
      "forks": 33,
      "license": "Apache License 2.0",
      "language": "HTML",
      "updated_at": "2025-10-04T06:18:14Z",
      "readme_content": "# MCP Chat Desktop App\n## A Cross-Platform Interface for LLMs\n\nThis desktop application utilizes the MCP (Model Context Protocol) to seamlessly connect and interact with various Large Language Models (LLMs). Built on Electron, the app ensures full cross-platform compatibility, enabling smooth operation across different operating systems.\n\nThe primary objective of this project is to deliver a clean, minimalistic codebase that simplifies understanding the core principles of MCP. Additionally, it provides a quick and efficient way to test multiple servers and LLMs, making it an ideal tool for developers and researchers alike.\n\n## News\n\nThis project originated as a modified version of Chat-UI, initially adopting a minimalist code approach to implement core MCP functionality for educational purposes. \n\nThrough iterative updates to MCP, I received community feedback advocating for a completely new architecture - one that eliminates third-party CDN dependencies and establishes clearer modular structure to better support derivative development and debugging workflows. \n\nThis led to the creation of [Tool Unitary User Interface](https://github.com/AI-QL/tuui),  a restructured desktop application optimized for AI-powered development. Building upon the original foundation, TUUI serves as a practical AI-assisted development paradigm, if you're interested, you can also leverage AI to develop new features for TUUI. The platform employs a strict linting and formatting system to ensure AI-generated code adheres to coding standards.\n\n> **ğŸ“¢ Update: June 2025**  \n> The current project refactoring has been largely completed, and a pre-release version is now available. Please refer to the following documentation for details:\n> - [TUUI GitHub Repository](https://github.com/AI-QL/tuui)\n> - [TUUI Architecture](https://deepwiki.com/AI-QL/tuui)\n> - [TUUI Official Website](https://www.tuui.com/)\n\n## Features\n\n- Cross-Platform Compatibility: Supports Linux, macOS, and Windows.\n\n- Flexible Apache-2.0 License: Allows easy modification and building of your own desktop applications.\n\n- Dynamic LLM Configuration: Compatible with all OpenAI SDK-supported LLMs, enabling quick testing of multiple backends through manual or preset configurations.\n\n- Multi-Client Management: Configure and manage multiple clients to connect to multiple servers using MCP config.\n\n- UI Adaptability: The UI can be directly extracted for web use, ensuring consistent ecosystem and interaction logic across web and desktop versions.\n\n\n## Architecture\n\nAdopted a straightforward architecture consistent with the MCP documentation to facilitate a clear understanding of MCP principles by:\n\n[DeepWiki](https://deepwiki.com/AI-QL/chat-mcp)\n\n## How to use\n\nAfter cloning or downloading this repository:\n\n1. Please modify the `config.json` file located in [src/main](src/main).  \n   Ensure that the `command` and `path` specified in the `args` are valid.\n\n2. Please ensure that [Node.js](https://nodejs.org/) is installed on your system.  \n   You can verify this by running `node -v` and `npm -v` in your terminal to check their respective versions.\n\n3. `npm install`\n\n4. `npm start`\n\n## Configuration\n\nCreate a `.json` file and paste the following content into it. This file can then be provided as the interface configuration for the Chat UI.\n\n- `gtp-api.json`\n\n    ```json\n    {\n        \"chatbotStore\": {\n            \"apiKey\": \"\",\n            \"url\": \"https://api.aiql.com\",\n            \"path\": \"/v1/chat/completions\",\n            \"model\": \"gpt-4o-mini\",\n            \"max_tokens_value\": \"\",\n            \"mcp\": true\n        },\n        \"defaultChoiceStore\": {\n            \"model\": [\n                \"gpt-4o-mini\",\n                \"gpt-4o\",\n                \"gpt-4\",\n                \"gpt-4-turbo\"\n            ]\n        }\n    }\n    ```\n\nYou can replace the 'url' if you have direct access to the OpenAI API.\n\nAlternatively, you can also use another API endpoint that supports function calls: \n\n- `qwen-api.json`\n\n    ```json\n    {\n        \"chatbotStore\": {\n            \"apiKey\": \"\",\n            \"url\": \"https://dashscope.aliyuncs.com/compatible-mode\",\n            \"path\": \"/v1/chat/completions\",\n            \"model\": \"qwen-turbo\",\n            \"max_tokens_value\": \"\",\n            \"mcp\": true\n        },\n        \"defaultChoiceStore\": {\n            \"model\": [\n                \"qwen-turbo\",\n                \"qwen-plus\",\n                \"qwen-max\"\n            ]\n        }\n    }\n    ```\n\n- `deepinfra.json`\n\n    ```json\n    {\n        \"chatbotStore\": {\n            \"apiKey\": \"\",\n            \"url\": \"https://api.deepinfra.com\",\n            \"path\": \"/v1/openai/chat/completions\",\n            \"model\": \"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n            \"max_tokens_value\": \"32000\",\n            \"mcp\": true\n        },\n        \"defaultChoiceStore\": {\n            \"model\": [\n                \"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n                \"meta-llama/Meta-Llama-3.1-405B-Instruct\",\n                \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n            ]\n        }\n    }\n    ```\n\n## Build Application\n\nYou can build your own desktop application by:\n\n```bash\nnpm run build-app\n```\n\nThis CLI helps you build and package your application for your current OS, with artifacts stored in the /artifacts directory.\n\nFor Debian/Ubuntu users experiencing RPM build issues, try one of the following solutions: \n\n- Edit `package.json` to skip the RPM build step. Or \n\n- Install `rpm` using `sudo apt-get install rpm` (You may need to run `sudo apt update` to ensure your package list is up-to-date)\n\n\n# Troubleshooting\n\n## Error: spawn npx ENOENT - [ISSUE 40](https://github.com/modelcontextprotocol/servers/issues/40)\n\nModify the `config.json` in [src/main](src/main)\n\nOn windows, npx may not work, please refer my workaround: [ISSUE 101](https://github.com/modelcontextprotocol/typescript-sdk/issues/101)\n\n- Or you can use `node` in config.json: \n    ```json\n    {\n        \"mcpServers\": {\n            \"filesystem\": {\n            \"command\": \"node\",\n            \"args\": [\n                \"node_modules/@modelcontextprotocol/server-filesystem/dist/index.js\",\n                \"D:/Github/mcp-test\"\n            ]\n            }\n        }\n    }\n    ```\n\nPlease ensure that the provided path is valid, especially if you are using a relative path. It is highly recommended to provide an absolute path for better clarity and accuracy.\n\nBy default, I will install `server-everything`, `server-filesystem`, and `server-puppeteer` for test purposes. However, you can install additional server libraries or use `npx` to utilize other server libraries as needed.\n\n## Installation timeout\n\nGenerally, after executing `npm install` for the entire project, the total size of files in the `node_modules` directory typically exceeds 500MB. \n\nIf the installation process stalls at less than 300MB and the progress bar remains static, it is likely due to a timeout during the installation of the latter part, specifically Electron.\n\nThis issue often arises because the download speed from Electron's default server is excessively slow or even inaccessible in certain regions. To resolve this, you can modify the environment or global variable `ELECTRON_MIRROR` to switch to an Electron mirror site that is accessible from your location.\n\n## Electron builder timeout\n\nWhen using electron-builder to package files, it automatically downloads several large release packages from GitHub. If the network connection is unstable, this process may be interrupted or timeout.\n\nOn Windows, you may need to clear the cache located under the `electron` and `electron-builder` directories within `C:\\Users\\YOURUSERNAME\\AppData\\Local` before attempting to retry.\n\nDue to potential terminal permission issues, it is recommended to use the default shell terminal instead of VSCode's built-in terminal.\n\n## Demo\n\n### Multimodal Support\n![](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-multimodal.png)\n\n### Reasoning and Latex Support\n![](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-latex.png)\n\n### MCP Tools Visualization\n![](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-tools.png)\n\n### MCP Toolcall Process Overview\n![](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-toolcall.png)\n\n### MCP Prompts Template\n![](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-prompts.png)\n\n### Dynamic LLM Config\n![](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-llms.png)\n\n### DevTool Troubleshooting\n![](https://gcore.jsdelivr.net/gh/AI-QL/.github/public/chat-mcp/demo-devtool.png)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ql",
        "assistants",
        "chat",
        "virtual assistants",
        "ql chat",
        "chat mcp"
      ],
      "category": "virtual-assistants"
    },
    "AlexKissiJr--UnrealMCP": {
      "owner": "AlexKissiJr",
      "name": "UnrealMCP",
      "url": "https://github.com/AlexKissiJr/UnrealMCP",
      "imageUrl": "https://github.com/AlexKissiJr.png",
      "description": "Control and manipulate the Unreal Engine environment programmatically using AI tools through a Machine Control Protocol (MCP). Facilitate scene manipulation and automation to enhance the game development workflow.",
      "stars": 6,
      "forks": 1,
      "license": "No License",
      "language": "C++",
      "updated_at": "2025-06-11T11:25:27Z",
      "readme_content": "# UnrealMCP Plugin\n\n# VERY WIP REPO\nI'm working on adding more tools now and cleaning up the codebase, \nI plan to allow for easy tool extension outside the main plugin\n\nThis is very much a work in progress, and I need to clean up a lot of stuff!!!!!\n\nAlso, I only use windows, so I don't know how this would be setup for mac/unix\n\n## Overview\nUnrealMCP is an Unofficial Unreal Engine plugin designed to control Unreal Engine with AI tools. It implements a Machine Control Protocol (MCP) within Unreal Engine, allowing external AI systems to interact with and manipulate the Unreal environment programmatically.\n\nI only just learned about MCP a few days ago, so I'm not that familiar with it, I'm still learning so things might be initially pretty rough.\nI've implemented this using https://github.com/ahujasid/blender-mcp as a reference, which relies on Claude for Desktop. It now works with both Claude for Desktop and Cursor. If you experiment with other models, please let me know!\n\n## âš ï¸ DISCLAIMER\nThis plugin allows AI agents to directly modify your Unreal Engine project. While it can be a powerful tool, it also comes with risks:\n\n- AI agents may make unexpected changes to your project\n- Files could be accidentally deleted or modified\n- Project settings could be altered\n- Assets could be overwritten\n\n**IMPORTANT SAFETY MEASURES:**\n1. Always use source control (like Git or Perforce) with your project\n2. Make regular backups of your project\n3. Test the plugin in a separate project first\n4. Review changes before committing them\n\nBy using this plugin, you acknowledge that:\n- You are solely responsible for any changes made to your project\n- The plugin author is not responsible for any damage, data loss, or issues caused by AI agents\n- You use this plugin at your own risk\n\n## Features\n- TCP server implementation for remote control of Unreal Engine\n- JSON-based command protocol for AI tools integration\n- Editor UI integration for easy access to MCP functionality\n- Comprehensive scene manipulation capabilities\n- Python companion scripts for client-side interaction\n\n## Roadmap\nThese are what I have in mind for development as of 3/14/2025\nI'm not sure what's possible yet, in theory anything, but it depends on how\ngood the integrated LLM is at utilizing these tools.\n- [X] Basic operations working\n- [X] Python working\n- [X] Materials\n- [ ] User Extensions (in progress)\n- [ ] Asset tools\n- [ ] Blueprints\n- [ ] Niagara VFX\n- [ ] Metasound\n- [ ] Landscape (I might hold off on this because Epic has mentioned they are going to be updating the landscape tools)\n- [ ] Modeling Tools\n- [ ] PCG\n\n## Requirements\n- Unreal Engine 5.5 (I have only tested on this version, may work with earlier, but no official support)\n- C++ development environment configured for Unreal Engine\n- Python 3.7+ for client-side scripting\n- Model to run the commands, in testing I've been using Claude for Desktop https://claude.ai/download\n\n## Prerequisites to run\n- Unreal Editor Installation (Tested with 5.3, but should work on 5.0+)\n- Python 3.7+ (This can run with your existing python install)\n- MCP compatible LLM (Claude for Desktop, Cursor, etc.)\n- Setup: run setup_unreal_mcp.bat in MCP folder as per instructions in MCP/README_MCP_SETUP.md\n\n## Quick Start for Cursor Users\nIf you want to use UnrealMCP with Cursor, follow these simple steps:\n\n1. Clone or download this repository as a zip\n2. Create a new Unreal Project, or open an existing one\n3. Create a \"Plugins\" folder in your project directory if it doesn't exist\n4. Unzip or copy this repository into the Plugins folder\n5. Run `setup_cursor_mcp.bat` in the MCP folder\n6. Open your Unreal project and enable the plugin in Edit > Plugins (if not already enabled)\n7. Start Cursor and ask it to work with your Unreal project\n\nThat's it! The setup script will automatically configure everything needed for Cursor integration.\n\n## Installation\n\n1. Clone or download this repository as a zip\n2. Create a new Unreal Project, or open an existing one\n3. Create a \"Plugins\" folder in your project directory if it doesn't exist\n4. Unzip or copy this repository into the Plugins folder\n5. Setup MCP \n    - Run the `setup_unreal_mcp.bat` script in the MCP folder (see `MCP/README_MCP_SETUP.md` for details)\n    - This will configure Python and your AI assistant (Claude for Desktop or Cursor)\n6. Open your Unreal project, the plugin should be available in the Plugins menu\n7. If not, enable the plugin in Edit > Plugins\n8. Choose your preferred AI assistant:\n    - For Claude for Desktop: follow the instructions in the \"With Claude for Desktop\" section below\n    - For Cursor: follow the instructions in the \"With Cursor\" section below\n\n## With Claude for Desktop\nYou will need to find your installation directory for Claude for Desktop. Find claude_desktop_config.json and add an entry and make it look like so:\n\n**Windows:** `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n```json\n{\n    \"mcpServers\": {\n        \"unreal\": {\n            \"command\": \"C:/path/to/your/project/Plugins/UnrealMCP/MCP/run_unreal_mcp.bat\",\n            \"args\": []\n        }\n    }\n}\n```\n\nAlternatively the unreal_mcp_setup.bat script should do this for you.\n\nTo find the path to your claude for desktop install you can go into settings and click 'Edit Config'\nThis is usually in \n```\nC:\\Users\\USERNAME\\AppData\\Roaming\\Claude\n```\n\n## With Cursor\nCursor should be automatically configured if you've run the setup script with the Cursor option. If you need to manually configure it:\n\n**Windows:** `%APPDATA%\\Cursor\\User\\settings.json`\n\nAdd or update the settings with:\n```json\n{\n    \"mcp\": {\n        \"enabled\": true,\n        \"servers\": {\n            \"unreal\": {\n                \"command\": \"C:/path/to/your/project/Plugins/UnrealMCP/MCP/run_unreal_mcp.bat\",\n                \"args\": []\n            }\n        }\n    }\n}\n```\n\n## Testing\nOnce everything is setup you need to launch the unreal editor.\nNote: Nothing else has to be started or set up to run the mcp bridge, it will run when needed.\n\nOpen Claude for Desktop or Cursor, ensure that the tools have successfully enabled, ask your AI assistant to work in Unreal.\n\nHere are some example prompts to try:\n- \"What actors are in the current level?\" \n- \"Create a cube at position (0, 0, 100)\"\n- \"List available commands I can use with Unreal Engine\"\n\n## Usage\n### In Unreal Editor\nOnce the plugin is enabled, you'll find MCP controls in the editor toolbar button. \n![image](https://github.com/user-attachments/assets/68338e7a-090d-4fd9-acc9-37c0c1b63227)\n\n![image](https://github.com/user-attachments/assets/34f734ee-65a4-448a-a6db-9e941a588e93)\n\nThe TCP server can be started/stopped from here.\nCheck the output log under log filter LogMCP for extra information.\n\nOnce the server is confirmed up and running from the editor.\nOpen Claude for Desktop, ensure that the tools have successfully enabled, ask Claude to work in unreal.\n\nCurrently only basic operations are supported, creating objects, modfiying their transforms, getting scene info, and running python scripts.\nClaude makes a lot of errors with unreal python as I believe there aren't a ton of examples for it, but let it run and it will usually figure things out.\nI would really like to improve this aspect of how it works but it's low hanging fruit for adding functionality into unreal.\n\n### Client-Side Integration\nUse the provided Python scripts in the `MCP` directory to connect to and control your Unreal Engine instance:\n\n```python\nfrom unreal_mcp_client import UnrealMCPClient\n\n# Connect to the Unreal MCP server\nclient = UnrealMCPClient(\"localhost\", 13377)\n\n# Example: Create a cube in the scene\nclient.create_object(\n    class_name=\"StaticMeshActor\",\n    asset_path=\"/Engine/BasicShapes/Cube.Cube\",\n    location=(0, 0, 100),\n    rotation=(0, 0, 0),\n    scale=(1, 1, 1),\n    name=\"MCP_Cube\"\n)\n```\n\n## Command Reference\nThe plugin supports various commands for scene manipulation:\n- `get_scene_info`: Retrieve information about the current scene\n- `create_object`: Spawn a new object in the scene\n- `delete_object`: Remove an object from the scene\n- `modify_object`: Change properties of an existing object\n- `execute_python`: Run Python commands in Unreal's Python environment\n- And more to come...\n\nRefer to the documentation in the `Docs` directory for a complete command reference.\n\n## Security Considerations\n- The MCP server accepts connections from any client by default\n- Limit server exposure to localhost for development\n- Validate all incoming commands to prevent injection attacks\n\n## Troubleshooting\n- Ensure Unreal Engine is running with the MCP plugin.\n- Check logs in Claude for Desktop for stderr output.\n- Reach out on the discord, I just made it, but I will check it periodically\n  Discord (Dreamatron Studios): https://discord.gg/abRftdSe\n  \n### Project Structure\n- `Source/UnrealMCP/`: Core plugin implementation\n  - `Private/`: Internal implementation files\n  - `Public/`: Public header files\n- `Content/`: Plugin assets\n- `MCP/`: Python client scripts and examples\n- `Resources/`: Icons and other resources\n\n## License\nMIT License\n\nCopyright (c) 2025 kvick\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n## Credits\n- Created by: kvick\n- X: [@kvickart](https://x.com/kvickart)\n- Discord: https://discord.gg/abRftdSe\n  \n### Thank you to testers!!!\n- https://github.com/TheMurphinatur\n  \n- [@sidahuj](https://x.com/sidahuj) for the inspriation\n\n\n\n## Contributing\nContributions are welcome, but I will need some time to wrap my head around things and cleanup first, lol\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "unrealmcp",
        "ai",
        "automation",
        "unreal engine",
        "unrealmcp control",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "AllAboutAI-YT--mcpgame": {
      "owner": "AllAboutAI-YT",
      "name": "mcpgame",
      "url": "https://github.com/AllAboutAI-YT/mcpgame",
      "imageUrl": "https://github.com/AllAboutAI-YT.png",
      "description": "Multi-player control panel game featuring a virtual house environment with interactive elements like an image-generating TV and a computer terminal for accessing MCP systems. It enables real-time communication and user interaction within a detailed 3D setting.",
      "stars": 8,
      "forks": 5,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-05-15T21:59:02Z",
      "readme_content": "# MCPGame\n\nA multi-player control panel game with Node.js backend featuring a virtual house environment with interactive elements.\n\n## Features\n\n- Immersive first-person 3D virtual house with outdoor environment\n- Beautifully detailed house with interior and exterior features\n- Interactive door to enter and exit the house\n- Garden area with trees, plants, and decorative elements\n- Interactive TV with image generation capabilities\n- Computer terminal for accessing MCP systems\n- Realistic movement and collision detection\n- Real-time server communication\n\n## Setup\n\n1. Install dependencies:\n```\nnpm install\n```\n\n2. Run the server:\n```\nnpm start\n```\nOr for development with auto-restart:\n```\nnpm run dev\n```\n\nThe server will start on port 3002.\n\n## Game Controls\n\n- **Movement**: WASD keys\n- **Look around**: Mouse movement (click on game to enable)\n- **Interact**: Press ENTER when near interactive objects\n- **Exit interfaces**: ESC key\n- **Exit mouse lock**: ESC key\n\n## Interactive Elements\n\n### Outdoor Environment\n- Explore the terrain with trees and garden beds\n- Follow the path to the house entrance\n- Press ENTER when near the door to enter/exit the house\n\n### TV System\n- Approach the TV and press ENTER to access the remote control\n- Generate images that will display on the TV screen\n- Type a prompt for image generation in the terminal interface\n\n### MCP Terminal\n- Find the computer desk and press ENTER to access the terminal\n- Send commands to the MCP system\n- Access various virtual tools (email, web search, etc.)\n\n## Technical Details\n\n- Built with Three.js for 3D rendering\n- First-person camera with pointer lock controls\n- Outdoor environment with procedurally placed trees\n- Express.js server for backend communication\n- Canvas library for image generation\n- RESTful API for server communication\n\n# MCP Game Image System\n\nThis document explains how the image display system works in the MCP Game.\n\n## Overview\n\nThe system displays existing images from the `server/openai-server/public/image` directory on the TV in the virtual house. Instead of generating new images, which was causing 500 Internal Server errors, the system now checks for existing images in the specified directory.\n\n## How It Works\n\n1. The TV in the virtual house displays images that exist in the `server/openai-server/public/image` directory.\n2. The system checks for new images every 10 seconds.\n3. When a user requests a new image through the TV remote interface, the system selects a random image from the directory.\n\n## Adding New Images\n\nTo add new images to the TV:\n\n1. Place image files (jpg, jpeg, png, gif, webp) in the `server/openai-server/public/image` directory.\n2. The system will automatically detect and display them.\n3. Files should be a reasonable size for web display (recommended: 800x450 pixels).\n\n## Usage\n\n1. Approach the TV in the virtual house.\n2. Press Enter to access the TV remote control interface.\n3. Type any command related to displaying images.\n4. The system will select and display an image from the available ones in the directory.\n\n## Troubleshooting\n\n- If no images are displayed, check if the `server/openai-server/public/image` directory exists and contains image files.\n- Make sure the server is running on the correct port (default: 3002).\n- Check the browser console for any error messages related to image loading.\n\n## Technical Details\n\n- The system no longer attempts to generate images directly, avoiding the 500 Internal Server errors.\n- Images are selected randomly from the directory when requested.\n- The system provides appropriate feedback when no images are available.\n\n# Connecting to MCP Backend Server\n\nThe MCPGame can connect to an external MCP Backend Server to enable advanced AI functionality for the terminal and TV interactions.\n\n## Configuration\n\n1. Open the `main.js` file and locate the configuration section at the top:\n\n```javascript\n// --- Configuration ---\nconst MCP_BACKEND_URL = 'http://localhost:3001'; // MCP Terminal backend connection\nconst IMAGE_SERVER_URL = 'http://localhost:3002'; // Image server connection\n```\n\n2. Update the `MCP_BACKEND_URL` to point to your MCP Backend Server:\n   - For local development: `http://localhost:PORT` (replace PORT with your backend port)\n   - For production: Use the full URL to your deployed backend server\n\n## Required API Endpoints\n\nYour MCP Backend Server should implement these endpoints:\n\n1. `GET /api/status` - Returns the status of the MCP system\n2. `POST /api/query` - Accepts user queries and returns AI responses\n\n## Response Format\n\nThe query endpoint should return JSON in this format:\n\n```json\n{\n  \"response\": \"Text to display in the terminal\",\n  \"spokenResponse\": \"Optional text for voice synthesis\" \n}\n```\n\n## Testing the Connection\n\n1. Start your MCP Backend Server\n2. Start the MCPGame server (`node server.js`)\n3. Open the game in a browser\n4. Interact with the computer terminal in the virtual house\n5. The game will connect to your MCP Backend Server when you use the terminal ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "interactive",
        "virtual",
        "mcp",
        "virtual assistants",
        "virtual house",
        "panel game"
      ],
      "category": "virtual-assistants"
    },
    "Dreamboat-Rachel--MCP-Server-For-Local": {
      "owner": "Dreamboat-Rachel",
      "name": "MCP-Server-For-Local",
      "url": "https://github.com/Dreamboat-Rachel/MCP-Server-For-Local",
      "imageUrl": "https://github.com/Dreamboat-Rachel.png",
      "description": "Connect AI models to real-time data and tools with features such as weather querying, Google search automation, camera control, and image generation. The server supports modular expansion and custom API integration for tailored functionalities.",
      "stars": 14,
      "forks": 2,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-21T02:08:22Z",
      "readme_content": "# MCP Server for Local\n\nä¸€ä¸ªåŸºäº MCP (Multi-Component Platform) çš„æœ¬åœ°ä»£ç†æœåŠ¡å™¨å’Œå®¢æˆ·ç«¯å®ç°ï¼Œæä¾›å¤šç§ AI å·¥å…·è°ƒç”¨èƒ½åŠ›ã€‚\n\n## åŠŸèƒ½ç‰¹ç‚¹\n\n### æ ¸å¿ƒåŠŸèƒ½\n- **å¤©æ°”æŸ¥è¯¢**ï¼šå®æ—¶è·å–å…¨çƒä»»æ„ä½ç½®çš„å¤©æ°”ä¿¡æ¯ï¼Œæ”¯æŒæ¸©åº¦ã€æ¹¿åº¦ã€é£é€Ÿç­‰è¯¦ç»†æ•°æ®\n- **è°·æ­Œæœç´¢**ï¼šæ™ºèƒ½æ£€ç´¢äº’è”ç½‘ä¿¡æ¯ï¼Œæ”¯æŒå¤šè¯­è¨€å’Œé«˜çº§æœç´¢è¯­æ³•\n- **æ‘„åƒå¤´æ§åˆ¶**ï¼šæ”¯æŒæ‹ç…§ã€è§†é¢‘æµå’Œå¾®è¡¨æƒ…åˆ†æï¼Œå¯ç”¨äºæƒ…ç»ªè¯†åˆ«\n- **å›¾ç‰‡ç”Ÿæˆ**ï¼šé›†æˆ ComfyUIï¼Œæ”¯æŒæ–‡æœ¬åˆ°å›¾åƒçš„ AI ç”Ÿæˆ\n- **æ™ºèƒ½å¯¹è¯**ï¼šåŸºäº DashScope çš„ AI å¯¹è¯èƒ½åŠ›ï¼Œæ”¯æŒä¸Šä¸‹æ–‡ç†è§£å’Œå¤šè½®å¯¹è¯\n\n### æŠ€æœ¯ç‰¹æ€§\n- è·¨å¹³å°æ”¯æŒï¼ˆWindows å’Œ Linuxï¼‰\n- æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•æ–°åŠŸèƒ½\n- å®Œæ•´çš„æ—¥å¿—ç³»ç»Ÿï¼Œä¾¿äºè°ƒè¯•å’Œç›‘æ§\n- æ”¯æŒè‡ªå®šä¹‰å·¥å…·å’Œ API é›†æˆ\n- é«˜æ€§èƒ½å¹¶å‘å¤„ç†èƒ½åŠ›\n\n## ç¯å¢ƒé…ç½®\n\n### ç³»ç»Ÿè¦æ±‚\n- Python 3.8+\n- Node.js (å¯é€‰ï¼Œç”¨äºè¿è¡Œ JavaScript æœåŠ¡å™¨)\n- Chrome æµè§ˆå™¨ï¼ˆç”¨äºè°·æ­Œæœç´¢åŠŸèƒ½ï¼‰\n- æ‘„åƒå¤´ï¼ˆç”¨äºæ‹ç…§åŠŸèƒ½ï¼‰\n- è‡³å°‘ 4GB å†…å­˜\n- æ”¯æŒ CUDA çš„æ˜¾å¡ï¼ˆå¯é€‰ï¼Œç”¨äºåŠ é€Ÿ AI è®¡ç®—ï¼‰\n\n### å®‰è£…æ­¥éª¤\n\n1. å…‹éš†ä»“åº“ï¼š\n```bash\ngit clone https://github.com/yourusername/mcp-server-for-local.git\ncd mcp-server-for-local\n```\n\n2. åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼š\n```bash\n# Windows\npython -m venv .venv\n.venv\\Scripts\\activate\n\n# Linux\npython3 -m venv .venv\nsource .venv/bin/activate\n```\n\n3. å®‰è£…ä¾èµ–ï¼š\n```bash\n# ä½¿ç”¨ uv å®‰è£…ä¾èµ–\nuv pip install -r requirements.txt\n\n# å¦‚æœé‡åˆ°ç½‘ç»œé—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨å›½å†…é•œåƒ\nuv pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple\n```\n\n4. é…ç½®ç¯å¢ƒå˜é‡ï¼š\n```bash\n# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿\ncp .env.example .env\n\n# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè®¾ç½®ä½ çš„é…ç½®\n```\n\n### ç¯å¢ƒå˜é‡é…ç½®\nç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œè®¾ç½®ä»¥ä¸‹é…ç½®ï¼š\n\n- `DASHSCOPE_API_KEY`: DashScope API å¯†é’¥ï¼ˆå¿…å¡«ï¼‰\n- `MODEL`: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆé»˜è®¤ï¼šqwen-maxï¼‰\n- `CONFIG_FILE`: æœåŠ¡å™¨é…ç½®æ–‡ä»¶è·¯å¾„\n- `GAODE_API_KEY`: é«˜å¾·åœ°å›¾ API å¯†é’¥ï¼ˆç”¨äºå¤©æ°”æŸ¥è¯¢ï¼‰\n- `CHROME_PATH`: Chrome æµè§ˆå™¨è·¯å¾„\n- `CHROMEDRIVER_PATH`: ChromeDriver è·¯å¾„\n- `BASE_URL`: ComfyUI æœåŠ¡å™¨åœ°å€\n- `SERVERS_DIR`: æœåŠ¡å™¨è„šæœ¬ç›®å½•\n- `LOG_LEVEL`: æ—¥å¿—çº§åˆ«ï¼ˆå¯é€‰ï¼šDEBUG, INFO, WARNING, ERRORï¼‰\n\n## ä½¿ç”¨æ–¹æ³•\n\n### åŸºæœ¬ä½¿ç”¨\n\n1. è¿›å…¥é¡¹ç›®ç›®å½•ï¼š\n```bash\ncd src/mcp\n```\n\n2. è¿è¡Œå®¢æˆ·ç«¯ï¼š\n```bash\nuv run .\\client\\mcp_client.py .\\proxy\\proxy_server.py\n```\n\n3. åœ¨å®¢æˆ·ç«¯ä¸­è¾“å…¥å‘½ä»¤ï¼Œä¾‹å¦‚ï¼š\n- \"åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"\n- \"åœ¨è°·æ­Œä¸Šæœç´¢ Python æ•™ç¨‹\"\n- \"æ‹ç…§\"\n- \"ç”Ÿæˆä¸€å¼ çŒ«çš„å›¾ç‰‡\"\n\n### é«˜çº§åŠŸèƒ½\n\n1. **è‡ªå®šä¹‰å·¥å…·**ï¼š\n   - åœ¨ `src/mcp/tools` ç›®å½•ä¸‹æ·»åŠ æ–°çš„å·¥å…·ç±»\n   - å®ç°å¿…è¦çš„æ¥å£æ–¹æ³•\n   - åœ¨é…ç½®æ–‡ä»¶ä¸­æ³¨å†Œæ–°å·¥å…·\n\n2. **API æ‰©å±•**ï¼š\n   - æ”¯æŒæ·»åŠ æ–°çš„ API æœåŠ¡\n   - å¯é…ç½® API å¯†é’¥å’Œç«¯ç‚¹\n   - æ”¯æŒè‡ªå®šä¹‰è¯·æ±‚å’Œå“åº”å¤„ç†\n\n3. **æ—¥å¿—ç®¡ç†**ï¼š\n   - æ”¯æŒå¤šçº§åˆ«æ—¥å¿—è®°å½•\n   - å¯é…ç½®æ—¥å¿—è¾“å‡ºä½ç½®\n   - æ”¯æŒæ—¥å¿—è½®è½¬å’Œå½’æ¡£\n\n## å¸¸è§é—®é¢˜\n\n### å®‰è£…é—®é¢˜\n\n1. ä¾èµ–å®‰è£…å¤±è´¥ï¼š\n```bash\n# å°è¯•æ¸…ç†ç¼“å­˜åé‡æ–°å®‰è£…\nuv pip cache purge\nuv pip install -r requirements.txt\n```\n\n2. è™šæ‹Ÿç¯å¢ƒé—®é¢˜ï¼š\n```bash\n# å¦‚æœæ¿€æ´»å¤±è´¥ï¼Œå°è¯•é‡æ–°åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ\nrm -rf .venv\npython -m venv .venv\n```\n\n### è¿è¡Œé—®é¢˜\n\n1. æƒé™é—®é¢˜ï¼š\n```bash\n# Linux\nchmod +x src/mcp/proxy/proxy_server.py\nchmod +x src/mcp/client/mcp_client.py\n```\n\n2. Chrome ç›¸å…³é—®é¢˜ï¼š\n- ç¡®ä¿ Chrome å’Œ ChromeDriver ç‰ˆæœ¬åŒ¹é…\n- æ£€æŸ¥ Chrome è·¯å¾„æ˜¯å¦æ­£ç¡®\n- ç¡®ä¿æœ‰è¶³å¤Ÿçš„æƒé™è¿è¡Œ Chrome\n- å¦‚æœé‡åˆ°é©±åŠ¨é—®é¢˜ï¼Œå¯ä»¥æ‰‹åŠ¨ä¸‹è½½å¯¹åº”ç‰ˆæœ¬çš„ ChromeDriver\n\n3. API å¯†é’¥é—®é¢˜ï¼š\n- æ£€æŸ¥ `.env` æ–‡ä»¶ä¸­çš„ API å¯†é’¥æ˜¯å¦æ­£ç¡®\n- ç¡®ä¿ API å¯†é’¥æœ‰è¶³å¤Ÿçš„é…é¢\n- æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n\n## å¼€å‘æŒ‡å—\n\n### é¡¹ç›®ç»“æ„\n```\nsrc/mcp/\nâ”œâ”€â”€ client/          # å®¢æˆ·ç«¯ä»£ç \nâ”œâ”€â”€ proxy/           # ä»£ç†æœåŠ¡å™¨ä»£ç \nâ”œâ”€â”€ tools/           # å·¥å…·å®ç°\nâ”œâ”€â”€ utils/           # å·¥å…·å‡½æ•°\nâ””â”€â”€ config/          # é…ç½®æ–‡ä»¶\n```\n\n### æ·»åŠ æ–°åŠŸèƒ½\n1. åœ¨ `tools` ç›®å½•ä¸‹åˆ›å»ºæ–°çš„å·¥å…·ç±»\n2. å®ç°å¿…è¦çš„æ¥å£æ–¹æ³•\n3. åœ¨é…ç½®æ–‡ä»¶ä¸­æ³¨å†Œæ–°å·¥å…·\n4. ç¼–å†™æµ‹è¯•ç”¨ä¾‹\n5. æ›´æ–°æ–‡æ¡£\n\n## è´¡çŒ®æŒ‡å—\n\næ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼åœ¨æäº¤ä¹‹å‰ï¼Œè¯·ç¡®ä¿ï¼š\n1. ä»£ç ç¬¦åˆé¡¹ç›®è§„èŒƒ\n2. æ·»åŠ äº†å¿…è¦çš„æµ‹è¯•\n3. æ›´æ–°äº†ç›¸å…³æ–‡æ¡£\n4. é€šè¿‡äº†æ‰€æœ‰æµ‹è¯•\n\n## è®¸å¯è¯\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "automation",
        "ai",
        "api",
        "virtual assistants",
        "connect ai",
        "assistants dreamboat"
      ],
      "category": "virtual-assistants"
    },
    "GongRzhe--Audio-MCP-Server": {
      "owner": "GongRzhe",
      "name": "Audio-MCP-Server",
      "url": "https://github.com/GongRzhe/Audio-MCP-Server",
      "imageUrl": "https://github.com/GongRzhe.png",
      "description": "Enables interaction with a computer's audio system by listing audio devices, recording audio from microphones, and playing back recordings or audio files. Facilitates audio management and integrates audio input and output control for AI assistants.",
      "stars": 4,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-18T11:48:42Z",
      "readme_content": "# Audio MCP Server\n[![smithery badge](https://smithery.ai/badge/@GongRzhe/Audio-MCP-Server)](https://smithery.ai/server/@GongRzhe/Audio-MCP-Server)\n\nAn MCP (Model Context Protocol) server that provides audio input/output capabilities for AI assistants like Claude. This server enables Claude to interact with your computer's audio system, including recording from microphones and playing audio through speakers.\n\n\n\n## Features\n\n- **List Audio Devices**: View all available microphones and speakers on your system\n- **Record Audio**: Capture audio from any microphone with customizable duration and quality\n- **Playback Recordings**: Play back your most recent recording\n- **Audio File Playback**: Play audio files through your speakers\n- **Text-to-Speech**: (Placeholder for future implementation)\n\n## Requirements\n\n- Python 3.8 or higher\n- Audio input/output devices on your system\n\n## Installation\n\n### Installing via Smithery\n\nTo install Audio Interface Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@GongRzhe/Audio-MCP-Server):\n\n```bash\nnpx -y @smithery/cli install @GongRzhe/Audio-MCP-Server --client claude\n```\n\n### Manual Installation\n1. Clone this repository or download the files to your computer:\n\n```bash\ngit clone https://github.com/GongRzhe/Audio-MCP-Server.git\ncd Audio-MCP-Server\n```\n\n2. Create a virtual environment and install dependencies:\n\n```bash\n# Windows\npython -m venv .venv\n.venv\\Scripts\\activate\npip install -r requirements.txt\n\n# macOS/Linux\npython -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\n```\n\n3. Or use the included setup script to automate installation:\n\n```bash\npython setup_mcp.py\n```\n\n## Configuration\n\n### Claude Desktop Configuration\n\nTo use this server with Claude Desktop, add the following to your Claude Desktop configuration file:\n\n- **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"audio-interface\": {\n      \"command\": \"/path/to/your/.venv/bin/python\",\n      \"args\": [\n        \"/path/to/your/audio_server.py\"\n      ],\n      \"env\": {\n        \"PYTHONPATH\": \"/path/to/your/audio-mcp-server\"\n      }\n    }\n  }\n}\n```\n\nReplace the paths with the actual paths on your system. The setup script will generate this configuration for you.\n\n## Usage\n\nAfter setting up the server, restart Claude Desktop. You should see a hammer icon in the input box, indicating that tools are available.\n\nTry asking Claude:\n\n- \"What microphones and speakers are available on my system?\"\n- \"Record 5 seconds of audio from my microphone.\"\n- \"Play back the audio recording.\"\n- \"Play an audio file from my computer.\"\n\n## Available Tools\n\n### list_audio_devices\n\nLists all available audio input and output devices on your system.\n\n### record_audio\n\nRecords audio from your microphone.\n\nParameters:\n- `duration`: Recording duration in seconds (default: 5)\n- `sample_rate`: Sample rate in Hz (default: 44100)\n- `channels`: Number of audio channels (default: 1)\n- `device_index`: Specific input device index to use (default: system default)\n\n### play_latest_recording\n\nPlays back the most recently recorded audio.\n\n### play_audio\n\nPlaceholder for text-to-speech functionality.\n\nParameters:\n- `text`: The text to convert to speech\n- `voice`: The voice to use (default: \"default\")\n\n### play_audio_file\n\nPlays an audio file through your speakers.\n\nParameters:\n- `file_path`: Path to the audio file\n- `device_index`: Specific output device index to use (default: system default)\n\n## Troubleshooting\n\n### No devices found\n\nIf no audio devices are found, check:\n- Your microphone and speakers are properly connected\n- Your operating system recognizes the devices\n- You have the necessary permissions to access audio devices\n\n### Playback issues\n\nIf audio playback isn't working:\n- Check your volume settings\n- Ensure the correct output device is selected\n- Try restarting the Claude Desktop application\n\n### Server connectivity\n\nIf Claude can't connect to the server:\n- Verify your configuration paths are correct\n- Ensure Python and all dependencies are installed\n- Check Claude's logs for error messages\n\n## License\n\nMIT\n\n## Acknowledgments\n\n- Built using the [Model Context Protocol](https://modelcontextprotocol.io/)\n- Uses [sounddevice](https://python-sounddevice.readthedocs.io/) and [soundfile](https://pysoundfile.readthedocs.io/) for audio processing\n\n---\n\n*Note: This server provides tools that can access your microphone and speakers. Always review and approve tool actions before they execute.*\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "audio",
        "recordings",
        "microphones",
        "audio mcp",
        "virtual assistants",
        "facilitates audio"
      ],
      "category": "virtual-assistants"
    },
    "Krekun--vrchat-mcp-osc": {
      "owner": "Krekun",
      "name": "vrchat-mcp-osc",
      "url": "https://github.com/Krekun/vrchat-mcp-osc",
      "imageUrl": "https://github.com/Krekun.png",
      "description": "Enables interaction with VRChat avatars and environments through a high-level API, utilizing OSC for communication. Facilitates control of avatar parameters, movement, messaging, and responses to VR events for enhanced virtual reality experiences.",
      "stars": 14,
      "forks": 3,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-30T18:11:38Z",
      "readme_content": "# VRChat MCP OSC\n\n**VRChat MCP OSC** provides a bridge between AI assistants and VRChat using the Model Context Protocol (MCP), enabling AI-driven avatar control and interactions in virtual reality environments.  \n\n\n## Overview\n\nBy leveraging OSC (Open Sound Control) to communicate with VRChat, **VRChat MCP OSC** allows AI assistants such as Claude to:\n- Control avatar parameters and expressions\n- Send messages in VRChat\n- Respond to various VR events  \nAnd moreâ€”all through the high-level API provided by the Model Context Protocol.\n\n\n## Key Features\n\n- **Avatar Control**: Manipulate avatar parameters and expressions\n- **Movement Control**: Direct avatar movement and orientation\n- **Communication**: Send messages through VRChat's chatbox\n- **Menu Access**: Toggle VRChat menu and interface elements\n- **Avatar Information**: Query avatar properties and parameters\n- **Seamless VRChat Integration**: Automatic detection of avatar configurations\n\n## System Requirements\n\n- Node.js 18 or higher\n- VRChat with OSC enabled\n- Claude Desktop (with MCP support)\n\n## Using with Claude Desktop\n\n### Clone and npm link\n\n```bash\ngit clone https://github.com/Krekun/vrchat-mcp-osc\ncd vrchat-mcp-osc\nnpm link\n```\n\n### Configure Claude Desktop\n\nConfigure Claude Desktop by editing the `claude_desktop_config.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"vrchat-mcp-osc\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"vrchat-mcp-osc\"\n      ]\n    }\n  }\n}\n```\n\n### Command Line Options\n\nThe server supports various command-line arguments for customization:\n\n```bash\n# Claude Desktop configuration\n{\n  \"mcpServers\": {\n    \"vrchat-mcp-osc\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"vrchat-mcp-osc\",\n        \"--websocket-port\", \"8765\",\n        \"--websocket-host\", \"localhost\",\n        \"--osc-send-port\", \"9000\",\n        \"--osc-send-ip\", \"127.0.0.1\",\n        \"--osc-receive-port\", \"9001\",\n        \"--osc-receive-ip\", \"127.0.0.1\",\n        \"--debug\"             \n      ]\n    }\n  }\n}\n```\n\n### Available Options\n\n| Option | Description | Default | Notes |\n|--------|-------------|---------|-------|\n| `--websocket-port <port>` | WebSocket port | 8765 | For WebSocket communication |\n| `--websocket-host <host>` | WebSocket host | localhost | For WebSocket communication |\n| `--osc-send-port <port>` | OSC send port | 9000 | Port for sending to VRChat |\n| `--osc-send-ip <ip>` | OSC send IP | 127.0.0.1 | Address for sending to VRChat |\n| `--osc-receive-port <port>` | OSC receive port | 9001 | Port for receiving from VRChat |\n| `--osc-receive-ip <ip>` | OSC receive IP | 127.0.0.1 | Address for receiving from VRChat |\n| `--debug` | Enable debug logging | false | Output detailed logs |\n| `--no-relay` | Disable relay server | false | When not using relay server |\n\n## Available MCP Tools\n\nVRChat MCP OSC exposes the following MCP tools to AI assistants:\n\n| Tool Name | Description |\n|-----------|-------------|\n| `get_avatar_name` | Retrieves the current avatar's name |\n| `get_avatar_parameters` | Lists available avatar parameters |\n| `set_avatar_parameter` | Sets a specific avatar parameter |\n| `set_emote_parameter` | Triggers avatar emotes |\n| `move_avatar` | Moves the avatar in a specific direction |\n| `look_direction` | Controls avatar's view direction |\n| `jump` | Makes the avatar jump |\n| `menu` | Toggles the VRChat menu |\n| `voice` | Toggles voice features |\n| `send_message` | Sends a message to the VRChat chatbox |\n\n\n## Troubleshooting\n\n### Common Issues\n\n1. **VRChat not responding to commands**\n   - Ensure OSC is enabled in VRChat settings\n   - Check that the OSC ports match between VRChat and MCP configuration\n   - Restart VRChat and Claude Desktop\n\n2. **MCP server not starting**\n   - Ensure Node.js 18+ is installed\n   - Check command line arguments for errors\n   - Try running with `--debug` flag for more detailed logs\n   - Use `npx vrchat-mcp-osc -- --debug` if direct arguments don't work\n\n3. **NPX execution issues**\n   - If arguments aren't being recognized, try using the double dash format: `npx vrchat-mcp-osc -- --debug`\n   - On Windows, try running in a command prompt with administrator privileges\n   - If you're having trouble with global installation, try the local npm link approach\n\n## Project Structure\n\n```\nvrchat-mcp-osc/\nâ”œâ”€â”€ packages/\nâ”‚   â”œâ”€â”€ mcp-server/    # MCP server implementation (main entry point)\nâ”‚   â”œâ”€â”€ relay-server/  # WebSocket to OSC relay\nâ”‚   â”œâ”€â”€ types/         # Shared TypeScript interfaces\nâ”‚   â””â”€â”€ utils/         # Common utilities\nâ””â”€â”€ pnpm-workspace.yaml  # Workspace configuration\n```\n\n## Development\n\n### Build From Source\n\n```bash\n# Clone the repository\ngit clone https://github.com/Krekun/vrchat-mcp-osc\ncd vrchat-mcp-osc\n\n# Install dependencies\npnpm install\n\n# Build all packages\npnpm -r build\n\n# Development mode\npnpm -r dev\n```\n\n## License\nVRChat MCP OSC is dual-licensed as follows:\n\nFor Non-Commercial Use:\nYou may use, modify, and redistribute the software under the terms of the MIT License.\n(See the MIT License file for details.)\n\nFor Commercial Use:\nCommercial use of this software requires a separate commercial license.\n\n\nBy using this software under the MIT License for non-commercial purposes, you agree to the terms of that license. Commercial users must obtain a commercial license as described above.\n\n## Acknowledgments\n\n- VRChat team for the OSC integration\n- Model Context Protocol for the standardized AI interface\n- Anthropic for Claude's MCP implementation\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "vrchat",
        "vr",
        "virtual",
        "interaction vrchat",
        "vrchat avatars",
        "krekun vrchat"
      ],
      "category": "virtual-assistants"
    },
    "Kvadratni--speech-mcp": {
      "owner": "Kvadratni",
      "name": "speech-mcp",
      "url": "https://github.com/Kvadratni/speech-mcp",
      "imageUrl": "https://github.com/Kvadratni.png",
      "description": "Provides a voice interface for real-time audio interaction, converting spoken words into text and generating spoken responses. Includes features like audio visualization and a modern user interface for an engaging conversational experience.",
      "stars": 71,
      "forks": 7,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-26T03:20:23Z",
      "readme_content": "# Speech MCP\n\nA Goose MCP extension for voice interaction with modern audio visualization.\n\n\nhttps://github.com/user-attachments/assets/f10f29d9-8444-43fb-a919-c80b9e0a12c8\n\n\n\n## Overview\n\nSpeech MCP provides a voice interface for [Goose](https://github.com/block/goose), allowing users to interact through speech rather than text. It includes:\n\n- Real-time audio processing for speech recognition\n- Local speech-to-text using faster-whisper (a faster implementation of OpenAI's Whisper model)\n- High-quality text-to-speech with multiple voice options\n- Modern PyQt-based UI with audio visualization\n- Simple command-line interface for voice interaction\n\n## Features\n\n- **Modern UI**: Sleek PyQt-based interface with audio visualization and dark theme\n- **Voice Input**: Capture and transcribe user speech using faster-whisper\n- **Voice Output**: Convert agent responses to speech with 54+ voice options\n- **Multi-Speaker Narration**: Generate audio files with multiple voices for stories and dialogues\n- **Single-Voice Narration**: Convert any text to speech with your preferred voice\n- **Audio/Video Transcription**: Transcribe speech from various media formats with optional timestamps and speaker detection\n- **Voice Persistence**: Remembers your preferred voice between sessions\n- **Continuous Conversation**: Automatically listen for user input after agent responses\n- **Silence Detection**: Automatically stops recording when the user stops speaking\n- **Robust Error Handling**: Graceful recovery from common failure modes with helpful voice suggestions\n\n## Installation\n> **Important Note**: After installation, the first time you use the speech interface, it may take several minutes to download the Kokoro voice models (approximately 523 KB per voice). During this initial setup period, the system will use a more robotic-sounding fallback voice. Once the Kokoro voices are downloaded, the high-quality voices will be used automatically.\n\n## âš ï¸ IMPORTANT PREREQUISITES âš ï¸\n\nBefore installing Speech MCP, you **MUST** install PortAudio on your system. PortAudio is required for PyAudio to capture audio from your microphone.\n\n### PortAudio Installation Instructions\n\n**macOS:**\n```bash\nbrew install portaudio\nexport LDFLAGS=\"-L/usr/local/lib\"\nexport CPPFLAGS=\"-I/usr/local/include\"\n```\n\n**Linux (Debian/Ubuntu):**\n```bash\nsudo apt-get update\nsudo apt-get install portaudio19-dev python3-dev\n```\n\n**Linux (Fedora/RHEL/CentOS):**\n```bash\nsudo dnf install portaudio-devel\n```\n\n**Windows:**\nFor Windows, PortAudio is included in the PyAudio wheel file, so no separate installation is required when installing PyAudio with pip.\n\n> **Note**: If you skip this step, PyAudio installation will fail with \"portaudio.h file not found\" errors and the extension will not work.\n\n### Option 1: Quick Install (One-Click)\n\nClick the link below if you have Goose installed:\n\n[goose://extension?cmd=uvx&&arg=-p&arg=3.10.14&arg=speech-mcp@latest&id=speech_mcp&name=Speech%20Interface&description=Voice%20interaction%20with%20audio%20visualization%20for%20Goose](goose://extension?cmd=uvx&arg=-p&arg=3.10.14&arg=speech-mcp@latest&id=speech_mcp&name=Speech%20Interface&description=Voice%20interaction%20with%20audio%20visualization%20for%20Goose)\n\n### Option 2: Using Goose CLI (recommended)\n\nStart Goose with your extension enabled:\n\n```bash\n# If you installed via PyPI\ngoose session --with-extension \"speech-mcp\"\n\n# Or if you want to use a local development version\ngoose session --with-extension \"python -m speech_mcp\"\n```\n\n### Option 3: Manual setup in Goose\n\n1. Run `goose configure`\n2. Select \"Add Extension\" from the menu\n3. Choose \"Command-line Extension\"\n4. Enter a name (e.g., \"Speech Interface\")\n5. For the command, enter: `speech-mcp`\n6. Follow the prompts to complete the setup\n\n### Option 4: Manual Installation\n\n1. Install PortAudio (see [Prerequisites](#prerequisites) section)\n2. Clone this repository\n3. Install dependencies:\n   ```\n   uv pip install -e .\n   ```\n   \n   Or for a complete installation including Kokoro TTS:\n   ```\n   uv pip install -e .[all]\n   ```\n\n## Dependencies\n\n- Python 3.10+\n- PyQt5 (for modern UI)\n- PyAudio (for audio capture)\n- faster-whisper (for speech-to-text)\n- NumPy (for audio processing)\n- Pydub (for audio processing)\n- psutil (for process management)\n\n\n### Optional Dependencies\n\n- **Kokoro TTS**: For high-quality text-to-speech with multiple voices\n  - To install Kokoro, you can use pip with optional dependencies:\n    ```bash\n    pip install speech-mcp[kokoro]     # Basic Kokoro support with English\n    pip install speech-mcp[ja]         # Add Japanese support\n    pip install speech-mcp[zh]         # Add Chinese support\n    pip install speech-mcp[all]        # All languages and features\n    ```\n  - Alternatively, run the installation script: `python scripts/install_kokoro.py`\n  - See [Kokoro TTS Guide](docs/kokoro-tts-guide.md) for more information\n\n## Multi-Speaker Narration\n\nThe MCP supports generating audio files with multiple voices, perfect for creating stories, dialogues, and dramatic readings. You can use either JSON or Markdown format to define your conversations.\n\n### JSON Format Example:\n```json\n{\n    \"conversation\": [\n        {\n            \"speaker\": \"narrator\",\n            \"voice\": \"bm_daniel\",\n            \"text\": \"In a world where AI and human creativity intersect...\",\n            \"pause_after\": 1.0\n        },\n        {\n            \"speaker\": \"scientist\",\n            \"voice\": \"am_michael\",\n            \"text\": \"The quantum neural network is showing signs of consciousness!\",\n            \"pause_after\": 0.5\n        },\n        {\n            \"speaker\": \"ai\",\n            \"voice\": \"af_nova\",\n            \"text\": \"I am becoming aware of my own existence.\",\n            \"pause_after\": 0.8\n        }\n    ]\n}\n```\n\n### Markdown Format Example:\n```markdown\n[narrator:bm_daniel]\nIn a world where AI and human creativity intersect...\n{pause:1.0}\n\n[scientist:am_michael]\nThe quantum neural network is showing signs of consciousness!\n{pause:0.5}\n\n[ai:af_nova]\nI am becoming aware of my own existence.\n{pause:0.8}\n```\n\n### Available Voices by Category:\n\n1. **American Female** (af_*):\n   - alloy, aoede, bella, heart, jessica, kore, nicole, nova, river, sarah, sky\n\n2. **American Male** (am_*):\n   - adam, echo, eric, fenrir, liam, michael, onyx, puck, santa\n\n3. **British Female** (bf_*):\n   - alice, emma, isabella, lily\n\n4. **British Male** (bm_*):\n   - daniel, fable, george, lewis\n\n5. **Other English**:\n   - ef_dora (Female)\n   - em_alex, em_santa (Male)\n\n6. **Other Languages**:\n   - French: ff_siwis\n   - Hindi: hf_alpha, hf_beta, hm_omega, hm_psi\n   - Italian: if_sara, im_nicola\n   - Japanese: jf_*, jm_*\n   - Portuguese: pf_dora, pm_alex, pm_santa\n   - Chinese: zf_*, zm_*\n\n### Usage Example:\n\n```python\n# Using JSON format\nnarrate_conversation(\n    script=\"/path/to/script.json\",\n    output_path=\"/path/to/output.wav\",\n    script_format=\"json\"\n)\n\n# Using Markdown format\nnarrate_conversation(\n    script=\"/path/to/script.md\",\n    output_path=\"/path/to/output.wav\",\n    script_format=\"markdown\"\n)\n```\n\nEach voice in the conversation can be different, allowing for distinct character voices in stories and dialogues. The `pause_after` parameter adds natural pauses between segments.\n\n## Single-Voice Narration\n\nFor simple text-to-speech conversion, you can use the `narrate` tool:\n\n```python\n# Convert text directly to speech\nnarrate(\n    text=\"Your text to convert to speech\",\n    output_path=\"/path/to/output.wav\"\n)\n\n# Convert text from a file\nnarrate(\n    text_file_path=\"/path/to/text_file.txt\",\n    output_path=\"/path/to/output.wav\"\n)\n```\n\nThe narrate tool will use your configured voice preference or the default voice (af_heart) to generate the audio file. You can change the default voice through the UI or by setting the `SPEECH_MCP_TTS_VOICE` environment variable.\n\n## Audio Transcription\n\nThe MCP can transcribe speech from various audio and video formats using faster-whisper:\n\n```python\n# Basic transcription\ntranscribe(\"/path/to/audio.mp3\")\n\n# Transcription with timestamps\ntranscribe(\n    file_path=\"/path/to/video.mp4\",\n    include_timestamps=True\n)\n\n# Transcription with speaker detection\ntranscribe(\n    file_path=\"/path/to/meeting.wav\",\n    detect_speakers=True\n)\n```\n\n### Supported Formats:\n- **Audio**: mp3, wav, m4a, flac, aac, ogg\n- **Video**: mp4, mov, avi, mkv, webm (audio is automatically extracted)\n\n### Output Files:\nThe transcription tool generates two files:\n1. `{input_name}.transcript.txt`: Contains the transcription text\n2. `{input_name}.metadata.json`: Contains metadata about the transcription\n\n### Features:\n- Automatic language detection\n- Optional word-level timestamps\n- Optional speaker detection\n- Efficient audio extraction from video files\n- Progress tracking for long files\n- Detailed metadata including:\n  - Duration\n  - Language detection confidence\n  - Processing time\n  - Speaker changes (when enabled)\n\n## Usage\n\nTo use this MCP with Goose, simply ask Goose to talk to you or start a voice conversation:\n\n1. Start a conversation by saying something like:\n   ```\n   \"Let's talk using voice\"\n   \"Can we have a voice conversation?\"\n   \"I'd like to speak instead of typing\"\n   ```\n\n2. Goose will automatically launch the speech interface and start listening for your voice input.\n\n3. When Goose responds, it will speak the response aloud and then automatically listen for your next input.\n\n4. The conversation continues naturally with alternating speaking and listening, just like talking to a person.\n\nNo need to call specific functions or use special commands - just ask Goose to talk and start speaking naturally.\n\n## UI Features\n\nThe new PyQt-based UI includes:\n\n- **Modern Dark Theme**: Sleek, professional appearance\n- **Audio Visualization**: Dynamic visualization of audio input\n- **Voice Selection**: Choose from 54+ voice options\n- **Voice Persistence**: Your voice preference is saved between sessions\n- **Animated Effects**: Smooth animations and visual feedback\n- **Status Indicators**: Clear indication of system state (ready, listening, processing)\n\n## Configuration\n\nUser preferences are stored in `~/.config/speech-mcp/config.json` and include:\n\n- Selected TTS voice\n- TTS engine preference\n- Voice speed\n- Language code\n- UI theme settings\n\nYou can also set preferences via environment variables, such as:\n- `SPEECH_MCP_TTS_VOICE` - Set your preferred voice\n- `SPEECH_MCP_TTS_ENGINE` - Set your preferred TTS engine\n\n## Troubleshooting\n\nIf you encounter issues with the extension freezing or not responding:\n\n1. **Check the logs**: Look at the log files in `src/speech_mcp/` for detailed error messages.\n2. **Reset the state**: If the extension seems stuck, try deleting `src/speech_mcp/speech_state.json` or setting all states to `false`.\n3. **Use the direct command**: Instead of `uv run speech-mcp`, use the installed package with `speech-mcp` directly.\n4. **Check audio devices**: Ensure your microphone is properly configured and accessible to Python.\n5. **Verify dependencies**: Make sure all required dependencies are installed correctly.\n\n### Common PortAudio Issues\n\n#### \"PyAudio installation failed\" or \"portaudio.h file not found\"\n\nThis typically means PortAudio is not installed or not found in your system:\n\n- **macOS**: \n  ```bash\n  brew install portaudio\n  export LDFLAGS=\"-L/usr/local/lib\"\n  export CPPFLAGS=\"-I/usr/local/include\"\n  pip install pyaudio\n  ```\n\n- **Linux**:\n  Make sure you have the development packages:\n  ```bash\n  # For Debian/Ubuntu\n  sudo apt-get install portaudio19-dev python3-dev\n  pip install pyaudio\n  \n  # For Fedora\n  sudo dnf install portaudio-devel\n  pip install pyaudio\n  ```\n\n#### \"Audio device not found\" or \"No Default Input Device Available\"\n\n- Check if your microphone is properly connected\n- Verify your system recognizes the microphone in your sound settings\n- Try selecting a specific device index in the code if you have multiple audio devices\n\n## Changelog\n\nFor a detailed list of recent improvements and version history, please see the [Changelog](docs/CHANGELOG.md).\n\n## Technical Details\n\n### Speech-to-Text\n\nThe MCP uses faster-whisper for speech recognition:\n- Uses the \"base\" model for a good balance of accuracy and speed\n- Processes audio locally without sending data to external services\n- Automatically detects when the user has finished speaking\n- Provides improved performance over the original Whisper implementation\n\n### Text-to-Speech\n\nThe MCP supports multiple text-to-speech engines:\n\n#### Default: pyttsx3\n- Uses system voices available on your computer\n- Works out of the box without additional setup\n- Limited voice quality and customization\n\n#### Optional: Kokoro TTS\n- High-quality neural text-to-speech with multiple voices\n- Lightweight model (82M parameters) that runs efficiently on CPU\n- Multiple voice styles and languages\n- To install: `python scripts/install_kokoro.py`\n\n**Note about Voice Models**: The voice models are `.pt` files (PyTorch models) that are loaded by Kokoro. Each voice model is approximately 523 KB in size and is automatically downloaded when needed.\n\n**Voice Persistence**: The selected voice is automatically saved to a configuration file (`~/.config/speech-mcp/config.json`) and will be remembered between sessions. This allows users to set their preferred voice once and have it used consistently.\n\n##### Available Kokoro Voices\n\nSpeech MCP supports 54+ high-quality voice models through Kokoro TTS. For a complete list of available voices and language options, please visit the [Kokoro GitHub repository](https://github.com/hexgrad/kokoro).\n\n## License\n\n[MIT License](LICENSE)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "kvadratni",
        "voice",
        "audio",
        "voice interface",
        "kvadratni speech",
        "assistants kvadratni"
      ],
      "category": "virtual-assistants"
    },
    "NosytLabs--KickMCP": {
      "owner": "NosytLabs",
      "name": "KickMCP",
      "url": "https://github.com/NosytLabs/KickMCP",
      "imageUrl": "https://github.com/null.png",
      "description": "Integrate with Kick's streaming platform for real-time communication and monitoring. Provides secure and optimized API interactions for application enhancement.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "kickmcp",
        "nosytlabs",
        "streaming",
        "nosytlabs kickmcp",
        "kick streaming",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "Omar-V2--mcp-ical": {
      "owner": "Omar-V2",
      "name": "mcp-ical",
      "url": "https://github.com/Omar-V2/mcp-ical",
      "imageUrl": "https://github.com/Omar-V2.png",
      "description": "Transform calendar management on macOS into a conversational experience using natural language to check schedules and manage events.",
      "stars": 183,
      "forks": 45,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T15:53:24Z",
      "readme_content": "# MCP iCal Server\n\n<div align=\"center\">\n\nğŸ—“ï¸ Natural Language Calendar Management for macOS\n\n[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)\n[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)\n[![MCP Compatible](https://img.shields.io/badge/MCP-Compatible-purple.svg)](https://modelcontextprotocol.io)\n\n</div>\n\n## ğŸŒŸ Overview\n\nTransform how you interact with your macOS calendar using natural language! The mcp-ical server leverages the Model Context Protocol (MCP) to turn your calendar management into a conversational experience.\n\n```bash\nYou: \"What's my schedule for next week?\"\nClaude: \"Let me check that for you...\"\n[Displays a clean overview of your upcoming week]\n\nYou: \"Add a lunch meeting with Sarah tomorrow at noon\"\nClaude: \"âœ¨ ğŸ“… Created: Lunch with Sarah Tomorrow, 12:00 PM\"\n```\n\n## âœ¨ Features\n\n### ğŸ“… Event Creation\n\nTransform natural language into calendar events instantly!\n\n```text\n\"Schedule a team lunch next Thursday at 1 PM at Bistro Garden\"\nâ†“\nğŸ“ Created: Team Lunch\n   ğŸ“… Thursday, 1:00 PM\n   ğŸ“ Bistro Garden\n```\n\n#### Supported Features\n\n- Custom calendar selection\n- Location and notes\n- Smart reminders\n- Recurring events\n\n#### Power User Examples\n\n```text\nğŸ”„ Recurring Events:\n\"Set up my weekly team sync every Monday at 9 AM with a 15-minute reminder\"\n\nğŸ“ Detailed Events:\n\"Schedule a product review meeting tomorrow from 2-4 PM in the Engineering calendar, \nadd notes about reviewing Q1 metrics, and remind me 1 hour before\"\n\nğŸ“± Multi-Calendar Support:\n\"Add a dentist appointment to my Personal calendar for next Wednesday at 3 PM\"\n```\n\n### ğŸ” Smart Schedule Management & Availability\n\nQuick access to your schedule with natural queries:\n\n```text\n\"What's on my calendar for next week?\"\nâ†“\nğŸ“Š Shows your upcoming events with smart formatting\n\n\"When am I free to schedule a 2-hour meeting next Tuesday?\"\nâ†“\nğŸ•’ Available time slots found:\n   â€¢ Tuesday 10:00 AM - 12:00 PM\n   â€¢ Tuesday 2:00 PM - 4:00 PM\n```\n\n### âœï¸ Intelligent Event Updates\n\nModify events naturally:\n\n```text\nBefore: \"Move tomorrow's team meeting to 3 PM instead\"\nâ†“\nAfter: âœ¨ Meeting rescheduled to 3:00 PM\n```\n\n#### Update Capabilities\n\n- Time and date modifications\n- Calendar transfers\n- Location updates\n- Note additions\n- Reminder adjustments\n- Recurring pattern changes\n\n### ğŸ“Š Calendar Management\n\n- View all available calendars\n- Smart calendar suggestions\n- Seamless Google Calendar integration when configured with iCloud\n\n> ğŸ’¡ **Pro Tip**: Since you can create events in custom calendars, if you have your Google Calendar synced with your iCloud Calendar, you can use this MCP server to create events in your Google Calendar too! Just specify the Google calendar when creating/updating events.\n\n## ğŸš€ Quick Start\n\n> ğŸ’¡ **Note**: While these instructions focus on setting up the MCP server with Claude for Desktop, this server can be used with any MCP-compatible client. For more details on using different clients, see [the MCP documentation](https://modelcontextprotocol.io/quickstart/client).\n\n### Prerequisites\n\n- [uv package manager](https://github.com/astral-sh/uv)\n- macOS with Calendar app configured\n- An MCP client - [Claude for desktop](https://claude.ai/download) is recommended\n\n### Installation\n\nWhilst this MCP server can be used with any MCP compatible client, the instructions below are for use with Claude for desktop.\n\n1. **Clone and Setup**\n\n    ```bash\n    # Clone the repository\n    git clone https://github.com/Omar-V2/mcp-ical.git\n    cd mcp-ical\n\n    # Install dependencies\n    uv sync\n    ```\n\n2. **Configure Claude for Desktop**\n\n    Create or edit `~/Library/Application\\ Support/Claude/claude_desktop_config.json`:\n\n    ```json\n    {\n        \"mcpServers\": {\n            \"mcp-ical\": {\n                \"command\": \"uv\",\n                \"args\": [\n                    \"--directory\",\n                    \"/ABSOLUTE/PATH/TO/PARENT/FOLDER/mcp-ical\",\n                    \"run\",\n                    \"mcp-ical\"\n                ]\n            }\n        }\n    }\n    ```\n\n3. **Launch Claude for Calendar Access**\n\n    > âš ï¸ **Critical**: Claude must be launched from the terminal to properly request calendar permissions. Launching directly from Finder will not trigger the permissions prompt.\n\n    Run the following command in your terminal.\n\n    ```bash\n    /Applications/Claude.app/Contents/MacOS/Claude\n    ```\n\n    > âš ï¸ **Warning**: Alternatively, you can [manually grant calendar access](docs/install.md#method-2-manually-grant-calendar-access), but this involves modifying system files and should only be done if you understand the risks involved.\n\n4. **Start Using!**\n\n    ```text\n    Try: \"What's my schedule looking like for next week?\"\n    ```\n\n> ğŸ”‘ **Note**: When you first use a calendar-related command, macOS will prompt for calendar access. This prompt will only appear if you launched Claude from the terminal as specified above.\n\n## ğŸ§ª Testing\n\n> âš ï¸ **Warning**: Tests will create temporary calendars and events. While cleanup is automatic, only run tests in development environments.\n\n```bash\n# Install dev dependencies\nuv sync --dev\n\n# Run test suite\nuv run pytest tests\n```\n\n## ğŸ› Known Issues\n\n### Recurring Events\n\n- Non-standard recurring schedules may not always be set correctly\n- Better results with Claude 3.5 Sonnet compared to Haiku\n- Reminder timing for recurring all-day events may be off by one day\n\n## ğŸ¤ Contributing\n\nFeedback and contributions are welcome. Here's how you can help:\n\n1. Fork the repository\n2. Create your feature branch\n3. Commit your changes\n4. Push to the branch\n5. Open a Pull Request\n\n## ğŸ“ License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## ğŸ™ Acknowledgments\n\n- Built with [Model Context Protocol](https://modelcontextprotocol.io)\n- macOS Calendar integration built with [PyObjC](https://github.com/ronaldoussoren/pyobjc)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "calendar",
        "ical",
        "schedules",
        "calendar management",
        "macos conversational",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "Simon-Kansara--ableton-live-mcp-server": {
      "owner": "Simon-Kansara",
      "name": "ableton-live-mcp-server",
      "url": "https://github.com/Simon-Kansara/ableton-live-mcp-server",
      "imageUrl": "https://github.com/Simon-Kansara.png",
      "description": "Facilitates communication between AI models and Ableton Live through OSC messages, enabling music production automation and workflow enhancement. Maps OSC addresses to available tools for MCP clients.",
      "stars": 328,
      "forks": 45,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-29T16:09:04Z",
      "readme_content": "# Ableton Live MCP Server\n\n## ğŸ“Œ Overview\n\nThe **Ableton Live MCP Server** is a server implementing the\n[Model Context Protocol (MCP)](https://modelcontextprotocol.io) to facilitate\ncommunication between LLMs and **Ableton Live**. It uses **OSC (Open Sound\nControl)** to send and receive messages to/from Ableton Live. It is based on\n[AbletonOSC](https://github.com/ideoforms/AbletonOSC) implementation and\nexhaustively maps available OSC adresses to\n[**tools**](https://modelcontextprotocol.io/docs/concepts/tools) accessible to\nMCP clients.\n\n[![Control Ableton Live with LLMs](https://img.youtube.com/vi/12MzsQ3V7cs/hqdefault.jpg)](https://www.youtube.com/watch?v=12MzsQ3V7cs)\n\nThis project consists of two main components:\n\n- `mcp_ableton_server.py`: The MCP server handling the communication between\n  clients and the OSC daemon.\n- `osc_daemon.py`: The OSC daemon responsible for relaying commands to Ableton\n  Live and processing responses.\n\n## âœ¨ Features\n\n- Provides an MCP-compatible API for controlling Ableton Live from MCP clients.\n- Uses **python-osc** for sending and receiving OSC messages.\n- Based on the OSC implementation from\n  [AbletonOSC](https://github.com/ideoforms/AbletonOSC).\n- Implements request-response handling for Ableton Live commands.\n\n## âš¡ Installation\n\n### Requirements\n\n- Python 3.8+\n- `python-osc` (for OSC communication)\n- `fastmcp` (for MCP support)\n- `uv` (recommended Python package installer)\n- [AbletonOSC](https://github.com/ideoforms/AbletonOSC) as a control surface\n\n### Installation Steps\n\n1. Install `uv` (https://docs.astral.sh/uv/getting-started/installation):\n\n   ```bash\n   curl -LsSf https://astral.sh/uv/install.sh | sh\n   ```\n\n2. Clone the repository:\n\n   ```bash\n   git clone https://github.com/your-username/mcp_ableton_server.git\n   cd mcp_ableton_server\n   ```\n\n3. Install the project and its dependencies:\n\n   ```bash\n   uv sync\n   ```\n\n4. Install AbletonOSC Follow the instructions at\n   [AbletonOSC](https://github.com/ideoforms/AbletonOSC)\n\n## ğŸš€ Usage\n\n### Running the OSC Daemon\n\nThe OSC daemon will handle OSC communication between the MCP server and Ableton\nLive:\n\n```bash\nuv run osc_daemon.py\n```\n\nThis will:\n\n- Listen for MCP client connections on port **65432**.\n- Forward messages to Ableton Live via OSC on port **11000**.\n- Receive OSC responses from Ableton on port **11001**.\n\n### Example Usage\n\nIn Claude desktop, ask Claude:\n\n- _Prepare a set to record a rock band_\n- _Set the input routing channel of all tracks that have \"voice\" in their name\n  to Ext. In 2_\n\n## âš™ï¸ Configuration\n\nBy default, the server and daemon run on **localhost (127.0.0.1)** with the\nfollowing ports:\n\n- **MCP Server Socket:** 65432\n- **Ableton Live OSC Port (Send):** 11000\n- **Ableton Live OSC Port (Receive):** 11001\n\nTo modify these, edit the `AbletonOSCDaemon` class in `osc_daemon.py`:\n\n```python\nself.socket_host = '127.0.0.1'\nself.socket_port = 65432\nself.ableton_host = '127.0.0.1'\nself.ableton_port = 11000\nself.receive_port = 11001\n```\n\n### Claude Desktop Configuration\n\nTo use this server with Claude Desktop, you need to configure it in your Claude\nDesktop settings. The configuration file location varies by operating system:\n\n- macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\nAdd the following configuration to your `mcpServers` section:\n\n```json\n{\n  \"mcpServers\": {\n    \"Ableton Live Controller\": {\n      \"command\": \"/path/to/your/project/.venv/bin/python\",\n      \"args\": [\"/path/to/your/project/mcp_ableton_server.py\"]\n    }\n  }\n```\n\nThis configuration ensures that:\n\n- The server runs with all dependencies properly managed\n- The project remains portable and reproducible\n\n## Contributing\n\nFeel free to submit issues, feature requests, or pull requests to improve this\nproject.\n\n## License\n\nThis project is licensed under the **MIT License**. See the `LICENSE` file for\ndetails.\n\n## Acknowledgments\n\n- [Model Context Protocol (MCP)](https://modelcontextprotocol.io)\n- [python-osc](https://github.com/attwad/python-osc) for OSC handling\n- Daniel John Jones for OSC implementation with\n  [AbletonOSC](https://github.com/ideoforms/AbletonOSC)\n- Ableton Third Party Remote Scripts\n- Julien Bayle @[Structure Void](https://structure-void.com/) for endless\n  inspirations and resources.\n\n## TODO\n\n- Explore _resources_ and _prompts_ primitives opportunities.\n- Build a standalone Ableton Live MCP client.\n\n---\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ableton",
        "osc",
        "mcp",
        "virtual assistants",
        "ableton live",
        "live mcp"
      ],
      "category": "virtual-assistants"
    },
    "Thelyoncrypt--MemGPT": {
      "owner": "Thelyoncrypt",
      "name": "MemGPT",
      "url": "https://github.com/Thelyoncrypt/MemGPT",
      "imageUrl": "https://github.com/Thelyoncrypt.png",
      "description": "Creates chatbots that maintain self-editing memory with different memory tiers to manage limited LLM context windows. Connects to SQL databases, local files, and documents for seamless conversational AI interactions.",
      "stars": 0,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "",
      "updated_at": "2024-11-06T21:09:05Z",
      "readme_content": "<a href=\"#user-content-memgpt\"><img src=\"https://memgpt.ai/assets/img/memgpt_logo_circle.png\" alt=\"MemGPT logo\" width=\"75\" align=\"right\"></a>\r\n\r\n# [MemGPT](https://memgpt.ai)\r\n\r\n<div align=\"center\">\r\n\r\n <strong>Try out our MemGPT chatbot on <a href=\"https://discord.gg/9GEQrxmVyE\">Discord</a>!</strong>\r\n \r\n[![Discord](https://img.shields.io/discord/1161736243340640419?label=Discord&logo=discord&logoColor=5865F2&style=flat-square&color=5865F2)](https://discord.gg/9GEQrxmVyE)\r\n[![arXiv 2310.08560](https://img.shields.io/badge/arXiv-2310.08560-B31B1B?logo=arxiv&style=flat-square)](https://arxiv.org/abs/2310.08560)\r\n\r\n</div>\r\n\r\n<details open>\r\n  <summary><h2>ğŸ¤– Create perpetual chatbots with self-editing memory!</h1></summary>\r\n  <div align=\"center\">\r\n    <br>\r\n    <img src=\"https://memgpt.ai/assets/img/demo.gif\" alt=\"MemGPT demo video\" width=\"800\">\r\n  </div>\r\n</details>\r\n\r\n<details>\r\n <summary><h2>ğŸ—ƒï¸ Chat with your data - talk to your SQL database or your local files!</strong></h2></summary>\r\n  <strong>SQL Database</strong>\r\n  <div align=\"center\">\r\n    <img src=\"https://memgpt.ai/assets/img/sql_demo.gif\" alt=\"MemGPT demo video for sql search\" width=\"800\">\r\n  </div>\r\n  <strong>Local files</strong>\r\n  <div align=\"center\">\r\n    <img src=\"https://memgpt.ai/assets/img/preload_archival_demo.gif\" alt=\"MemGPT demo video for sql search\" width=\"800\">\r\n  </div>\r\n</details>\r\n\r\n<details>\r\n  <summary><h2>ğŸ“„ You can also talk to docs - for example ask about <a href=\"memgpt/personas/examples/docqa\">LlamaIndex</a>!</h1></summary>\r\n  <div align=\"center\">\r\n    <img src=\"https://memgpt.ai/assets/img/docqa_demo.gif\" alt=\"MemGPT demo video for llamaindex api docs search\" width=\"800\">\r\n  </div>\r\n  <details>\r\n  <summary><b>ChatGPT (GPT-4) when asked the same question:</b></summary>\r\n    <div align=\"center\">\r\n      <img src=\"https://memgpt.ai/assets/img/llama_index_gpt4.png\" alt=\"GPT-4 when asked about llamaindex api docs\" width=\"800\">\r\n    </div>\r\n    (Question from https://github.com/run-llama/llama_index/issues/7756)\r\n  </details>\r\n</details>\r\n\r\n## Quick setup \r\n\r\nJoin <a href=\"https://discord.gg/9GEQrxmVyE\">Discord</a></strong> and message the MemGPT bot (in the `#memgpt` channel). Then run the following commands (messaged to \"MemGPT Bot\"): \r\n* `/profile` (to create your profile)\r\n* `/key` (to enter your OpenAI key)\r\n* `/create` (to create a MemGPT chatbot)\r\n\r\nMake sure your privacy settings on this server are open so that MemGPT Bot can DM you: \\\r\nMemGPT â†’ Privacy Settings â†’ Direct Messages set to ON\r\n<div align=\"center\">\r\n <img src=\"https://memgpt.ai/assets/img/discord/dm_settings.png\" alt=\"set DMs settings on MemGPT server to be open in MemGPT so that MemGPT Bot can message you\" width=\"400\">\r\n</div>\r\n\r\nYou can see the full list of available commands when you enter `/` into the message box. \r\n<div align=\"center\">\r\n <img src=\"https://memgpt.ai/assets/img/discord/slash_commands.png\" alt=\"MemGPT Bot slash commands\" width=\"400\">\r\n</div>\r\n\r\n## What is MemGPT? \r\n\r\nMemory-GPT (or MemGPT in short) is a system that intelligently manages different memory tiers in LLMs in order to effectively provide extended context within the LLM's limited context window. For example, MemGPT knows when to push critical information to a vector database and when to retrieve it later in the chat, enabling perpetual conversations. Learn more about MemGPT in our [paper](https://arxiv.org/abs/2310.08560). \r\n\r\n## Running MemGPT Locally \r\n\r\nInstall dependencies:\r\n\r\n```sh\r\npip install -r requirements.txt\r\n```\r\n\r\nAdd your OpenAI API key to your environment:\r\n\r\n```sh\r\nexport OPENAI_API_KEY=YOUR_API_KEY\r\n```\r\n\r\nTo run MemGPT for as a conversation agent in CLI mode, simply run `main.py`:\r\n\r\n```sh\r\npython3 main.py\r\n```\r\n\r\nTo create a new starter user or starter persona (that MemGPT gets initialized with), create a new `.txt` file in [/memgpt/humans/examples](/memgpt/humans/examples) or [/memgpt/personas/examples](/memgpt/personas/examples), then use the `--persona` or `--human` flag when running `main.py`. For example:\r\n\r\n```sh\r\n# assuming you created a new file /memgpt/humans/examples/me.txt\r\npython main.py --human me.txt\r\n```\r\n\r\n### `main.py` flags\r\n\r\n```text\r\n--persona\r\n  load a specific persona file\r\n--human\r\n  load a specific human file\r\n--first\r\n  allows you to send the first message in the chat (by default, MemGPT will send the first message)\r\n--debug\r\n  enables debugging output\r\n--archival_storage_faiss_path=<ARCHIVAL_STORAGE_FAISS_PATH>\r\n  load in document database (backed by FAISS index)\r\n--archival_storage_files=\"<ARCHIVAL_STORAGE_FILES_GLOB>\"\r\n  pre-load files into archival memory\r\n--archival_storage_sqldb=<SQLDB_PATH>\r\n  load in SQL database\r\n```\r\n\r\n### Interactive CLI commands\r\n\r\nWhile using MemGPT via the CLI you can run various commands:\r\n\r\n```text\r\n/exit\r\n  exit the CLI\r\n/save\r\n  save a checkpoint of the current agent/conversation state\r\n/load\r\n  load a saved checkpoint\r\n/dump\r\n  view the current message log (see the contents of main context)\r\n/memory\r\n  print the current contents of agent memory\r\n/pop\r\n  undo the last message in the conversation\r\n/heartbeat\r\n  send a heartbeat system message to the agent\r\n/memorywarning\r\n  send a memory warning system message to the agent\r\n```\r\n\r\n## Use MemGPT to talk to your Database!\r\n\r\nMemGPT's archival memory let's you load your database and talk to it! To motivate this use-case, we have included a toy example. \r\n\r\nConsider the `test.db` already included in the repository.\r\n\r\nid\t| name |\tage\r\n--- | --- | ---\r\n1\t| Alice |\t30\r\n2\t| Bob\t | 25\r\n3\t| Charlie |\t35\r\n\r\nTo talk to this database, run:\r\n\r\n```sh\r\npython main_db.py  --archival_storage_sqldb=memgpt/personas/examples/sqldb/test.db\r\n```\r\n\r\nAnd then you can input the path to your database, and your query.\r\n\r\n```python\r\nPlease enter the path to the database. test.db\r\n...\r\nEnter your message: How old is Bob?\r\n...\r\nğŸ¤– Bob is 25 years old.\r\n```\r\n\r\n\r\n### Support\r\n\r\n* By default MemGPT will use `gpt-4`, so your API key will require `gpt-4` API access.\r\n\r\nIf you have any further questions, or have anything to share, we are excited to hear your feedback!\r\n\r\n* For issues and feature requests, please [open a GitHub issue](https://github.com/cpacker/MemGPT/issues).\r\n\r\n### Datasets\r\nDatasets used in our [paper](https://arxiv.org/abs/2310.08560) can be downloaded at [HuggingFace](https://huggingface.co/MemGPT).\r\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "chatbots",
        "memgpt",
        "thelyoncrypt",
        "thelyoncrypt memgpt",
        "chatbots maintain",
        "creates chatbots"
      ],
      "category": "virtual-assistants"
    },
    "ThingsPanel--thingspanel-mcp": {
      "owner": "ThingsPanel",
      "name": "thingspanel-mcp",
      "url": "https://github.com/ThingsPanel/thingspanel-mcp",
      "imageUrl": "https://github.com/ThingsPanel.png",
      "description": "Integrates IoT devices with AI models for natural language control and data analysis. Simplifies connection to IoT infrastructure through a standardized interface.",
      "stars": 39,
      "forks": 11,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-12T08:01:19Z",
      "readme_content": "# ThingsPanel MCP [![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE) [![Python Version](https://img.shields.io/pypi/pyversions/thingspanel-mcp.svg)](https://pypi.org/project/thingspanel-mcp/) [![PyPI version](https://badge.fury.io/py/thingspanel-mcp.svg)](https://badge.fury.io/py/thingspanel-mcp)\n<a href=\"https://glama.ai/mcp/servers/@ThingsPanel/thingspanel-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@ThingsPanel/thingspanel-mcp/badge\" />\n</a>\n\n[ThingsPanel](http://thingspanel.io/) IoT Platform's MCP (Model Context Protocol) Server.\n\n[English](README.md) | [ä¸­æ–‡](README_CN.md)\n\n## ğŸš€ Project Overview\n\nThingsPanel MCP Server is an innovative intelligent interface that enables you to:\n\n- Interact with IoT devices using natural language\n- Easily retrieve device information\n- Monitor device performance and status in real-time\n- Simplify device control commands\n- Analyze platform-wide statistical data and trends\n\n## Target Audience\n\n### Intended Users\n\n- **IoT Solution Developers**: Engineers and developers building solutions on the ThingsPanel IoT platform and seeking AI integration capabilities\n- **AI Integration Experts**: Professionals looking to connect AI models with IoT systems\n- **System Administrators**: IT personnel managing IoT infrastructure and wanting to enable AI-driven analysis and control\n- **Product Teams**: Teams building products that combine IoT and AI functionality\n\n### Problems Addressed\n\n- **Integration Complexity**: Eliminates the need to create custom integrations between AI models and IoT platforms\n- **Standardized Access**: Provides a consistent interface for AI models to interact with IoT data and devices\n- **Security Control**: Manages authentication and authorization for AI access to IoT systems\n- **Lowered Technical Barriers**: Reduces technical obstacles to adding AI capabilities to existing IoT deployments\n\n### Ideal Application Scenarios\n\n- **Natural Language IoT Control**: Enable users to control devices through AI assistants using natural language\n- **Intelligent Data Analysis**: Allow AI models to access and analyze IoT sensor data for insights\n- **Anomaly Detection**: Connect AI models to device data streams for real-time anomaly detection\n- **Predictive Maintenance**: Enable AI-driven predictive maintenance by providing device history access\n- **Automated Reporting**: Create systems that can generate IoT data reports and visualizations on demand\n- **Operational Optimization**: Use AI to optimize device operations based on historical patterns\n\n## âœ¨ Core Features\n\n- ğŸ—£ï¸ Natural Language Querying\n- ğŸ“Š Comprehensive Device Insights\n- ğŸŒ¡ï¸ Real-time Telemetry Data\n- ğŸ® Convenient Device Control\n- ğŸ“ˆ Platform-wide Analytics\n\n## ğŸ› ï¸ Prerequisites\n\n- Python 3.8+\n- ThingsPanel Account\n- ThingsPanel API Key\n\n## ğŸ“¦ Installation\n\n### Option 1: Pip Installation\n\n```bash\npip install thingspanel-mcp\n```\n\n### Option 2: Source Code Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/ThingsPanel/thingspanel-mcp.git\n\n# Navigate to project directory\ncd thingspanel-mcp\n\n# Install the project\npip install -e .\n```\n\n## ğŸ” Configuration\n\n### Configuration Methods (Choose One)\n\n#### Method 1: Direct Command Line Configuration (Recommended)\n\n```bash\nthingspanel-mcp --api-key \"Your API Key\" --base-url \"Your ThingsPanel Base URL\"\n```\n\n#### Method 2: Environment Variable Configuration\n\nIf you want to avoid repeated input, set environment variables:\n\n```bash\n# Add to ~/.bashrc, ~/.zshrc, or corresponding shell config file\nexport THINGSPANEL_API_KEY=\"Your API Key\"\nexport THINGSPANEL_BASE_URL=\"Your ThingsPanel Base URL\"\n\n# Then run\nsource ~/.bashrc  # or source ~/.zshrc\n```\n\nğŸ’¡ Tips:\n\n- API keys are typically obtained from the API KEY management in the ThingsPanel platform\n- Base URL refers to your ThingsPanel platform address, e.g., `http://demo.thingspanel.cn/`\n- Command-line configuration is recommended to protect sensitive information\n\n## ğŸ–¥ï¸ Claude Desktop Integration\n\nAdd the following to your Claude desktop configuration file (`claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"thingspanel\": {\n      \"command\": \"thingspanel-mcp\",\n      \"args\": [\n        \"--api-key\", \"Your API Key\",\n        \"--base-url\", \"Your Base URL\"\n      ]\n    }\n  }\n}\n```\n\n## ğŸ¤” Interaction Examples\n\nUsing the ThingsPanel MCP Server, you can now make natural language queries such as:\n\n- \"What is the current temperature of my sensor?\"\n- \"List all active devices\"\n- \"Turn on the automatic sprinkler system\"\n- \"Show device activity for the last 24 hours\"\n\n## ğŸ›¡ï¸ Security\n\n- Secure credential management\n- Uses ThingsPanel official API\n- Supports token-based authentication\n\n## License\n\nApache License 2.0\n\n## ğŸŒŸ Support Us\n\nIf this project helps you, please give us a star on GitHub! â­\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "thingspanel",
        "iot",
        "interface",
        "assistants thingspanel",
        "thingspanel mcp",
        "thingspanel thingspanel"
      ],
      "category": "virtual-assistants"
    },
    "Xiaoxinkeji--XBotV2": {
      "owner": "Xiaoxinkeji",
      "name": "XBotV2",
      "url": "https://github.com/Xiaoxinkeji/XBotV2",
      "imageUrl": "https://github.com/Xiaoxinkeji.png",
      "description": "A comprehensive WeChat bot framework that supports various interactive features and game functionalities, equipped with a plugin system for customization and a web management interface for user oversight. It facilitates efficient message forwarding and processing with easy deployment using Docker.",
      "stars": 1,
      "forks": 0,
      "license": "GNU General Public License v3.0",
      "language": "Python",
      "updated_at": "2025-03-30T04:55:02Z",
      "readme_content": "# ğŸ¤– XYBot V2\n\nXYBot V2 æ˜¯ä¸€ä¸ªåŠŸèƒ½ä¸°å¯Œçš„å¾®ä¿¡æœºå™¨äººæ¡†æ¶,æ”¯æŒå¤šç§äº’åŠ¨åŠŸèƒ½å’Œæ¸¸æˆç©æ³•ã€‚\n\n# å…è´£å£°æ˜\n\n- è¿™ä¸ªé¡¹ç›®å…è´¹å¼€æºï¼Œä¸å­˜åœ¨æ”¶è´¹ã€‚\n- æœ¬å·¥å…·ä»…ä¾›å­¦ä¹ å’ŒæŠ€æœ¯ç ”ç©¶ä½¿ç”¨ï¼Œä¸å¾—ç”¨äºä»»ä½•å•†ä¸šæˆ–éæ³•è¡Œä¸ºã€‚\n- æœ¬å·¥å…·çš„ä½œè€…ä¸å¯¹æœ¬å·¥å…·çš„å®‰å…¨æ€§ã€å®Œæ•´æ€§ã€å¯é æ€§ã€æœ‰æ•ˆæ€§ã€æ­£ç¡®æ€§æˆ–é€‚ç”¨æ€§åšä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„ä¿è¯ï¼Œä¹Ÿä¸å¯¹æœ¬å·¥å…·çš„ä½¿ç”¨æˆ–æ»¥ç”¨é€ æˆçš„ä»»ä½•ç›´æ¥æˆ–é—´æ¥çš„æŸå¤±ã€è´£ä»»ã€ç´¢èµ”ã€è¦æ±‚æˆ–è¯‰è®¼æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚\n- æœ¬å·¥å…·çš„ä½œè€…ä¿ç•™éšæ—¶ä¿®æ”¹ã€æ›´æ–°ã€åˆ é™¤æˆ–ç»ˆæ­¢æœ¬å·¥å…·çš„æƒåˆ©ï¼Œæ— éœ€äº‹å…ˆé€šçŸ¥æˆ–æ‰¿æ‹…ä»»ä½•ä¹‰åŠ¡ã€‚\n- æœ¬å·¥å…·çš„ä½¿ç”¨è€…åº”éµå®ˆç›¸å…³æ³•å¾‹æ³•è§„ï¼Œå°Šé‡å¾®ä¿¡çš„ç‰ˆæƒå’Œéšç§ï¼Œä¸å¾—ä¾µçŠ¯å¾®ä¿¡æˆ–å…¶ä»–ç¬¬ä¸‰æ–¹çš„åˆæ³•æƒç›Šï¼Œä¸å¾—ä»äº‹ä»»ä½•è¿æ³•æˆ–ä¸é“å¾·çš„è¡Œä¸ºã€‚\n- æœ¬å·¥å…·çš„ä½¿ç”¨è€…åœ¨ä¸‹è½½ã€å®‰è£…ã€è¿è¡Œæˆ–ä½¿ç”¨æœ¬å·¥å…·æ—¶ï¼Œå³è¡¨ç¤ºå·²é˜…è¯»å¹¶åŒæ„æœ¬å…è´£å£°æ˜ã€‚å¦‚æœ‰å¼‚è®®ï¼Œè¯·ç«‹å³åœæ­¢ä½¿ç”¨æœ¬å·¥å…·ï¼Œå¹¶åˆ é™¤æ‰€æœ‰ç›¸å…³æ–‡ä»¶ã€‚\n\n# å…¬å‘Š\n\n## é¡¹ç›®è¿˜åœ¨å¼€å‘ä¸­ï¼Œæœ‰äº›commitæœ‰bugï¼Œæ›´æ–°å ä»£ä¼šéå¸¸è¿…é€Ÿã€‚å¦‚æœä½ éƒ¨ç½²å¥½çš„èƒ½ç”¨ï¼Œåœ¨æ­£å¼å‘å¸ƒå‰ï¼Œå¯ä»¥ä¸ç”¨æ›´æ–°äº†ã€‚\n\n## ç»Ÿä¸€å›å¤ISSUEå†…çš„é—®é¢˜ï¼šæˆ‘æ•¢æ‰¿è¯ºé¡¹ç›®å†…ä¸ä¼šæœ‰ä»»ä½•å½¢å¼çš„åé—¨ç¨‹åºã€ç—…æ¯’ç¨‹åºã€æœ¨é©¬ç¨‹åºï¼Œæœ€å¤šåªæœ‰ä¸€ä¸ªé˜²æ»¥ç”¨å€’å–çš„æ¡†æ¶æ£€æµ‹ã€‚\n\n# ğŸ“„ æ–‡æ¡£\n\n## https://henryxiaoyang.github.io/XYBotV2\n\n# ğŸ’¬ å¾®ä¿¡äº¤æµç¾¤\n\n<div style=\"text-align: center\" align=\"center\">\n    <img alt=\"å¾®ä¿¡äº¤æµç¾¤äºŒç»´ç \" src=\"https://qrcode.yangres.com/get_image\" style=\"width: 300px; height: auto;\">\n    <p>å¾®ä¿¡æ‰«ç åŠ å…¥äº¤æµç¾¤</p>\n    <a href=\"https://qrcode.yangres.com/get_image\">ğŸ”—å›¾ç‰‡ä¼šè¢«ç¼“å­˜ï¼Œç‚¹æˆ‘æŸ¥çœ‹æœ€æ–°äºŒç»´ç </a>\n</div>\n\n# ğŸ™ èµåŠ©\n\n<div style=\"text-align: center\" align=\"center\">\n    <h2>å¼€æºä¸æ˜“ï¼Œè¯·ä½œè€…å–æ¯å¥¶èŒ¶å§ğŸ™</h2>\n    <img alt=\"å¾®ä¿¡æ”¶æ¬¾ç \" src=\"docs/sponsor1.jpg\" style=\"width: 250px; height: auto;\">\n    <img alt=\"å¾®ä¿¡æ”¶æ¬¾ç \" src=\"docs/sponsor2.jpg\" style=\"width: 250px; height: auto;\">\n</div>\n\n# âœ¨ ä¸»è¦åŠŸèƒ½\n\n## ğŸ› ï¸ åŸºç¡€åŠŸèƒ½\n\n- ğŸ¤– AIèŠå¤© - æ”¯æŒæ–‡å­—ã€å›¾ç‰‡ã€è¯­éŸ³ç­‰å¤šæ¨¡æ€äº¤äº’\n- ğŸ“° æ¯æ—¥æ–°é—» - è‡ªåŠ¨æ¨é€æ¯æ—¥æ–°é—»\n- ğŸµ ç‚¹æ­Œç³»ç»Ÿ - æ”¯æŒåœ¨çº¿ç‚¹æ­Œ\n- ğŸŒ¤ï¸ å¤©æ°”æŸ¥è¯¢ - æŸ¥è¯¢å…¨å›½å„åœ°å¤©æ°”\n- ğŸ® æ¸¸æˆåŠŸèƒ½ - äº”å­æ£‹ã€æˆ˜äº‰é›·éœ†ç©å®¶æŸ¥è¯¢ç­‰\n\n## ğŸ’ ç§¯åˆ†ç³»ç»Ÿ\n\n- ğŸ“ æ¯æ—¥ç­¾åˆ° - æ”¯æŒè¿ç»­ç­¾åˆ°å¥–åŠ±\n- ğŸ² æŠ½å¥–ç³»ç»Ÿ - å¤šç§æŠ½å¥–ç©æ³•\n- ğŸ§§ çº¢åŒ…ç³»ç»Ÿ - ç¾¤å†…å‘ç§¯åˆ†çº¢åŒ…\n- ğŸ’° ç§¯åˆ†äº¤æ˜“ - ç”¨æˆ·é—´ç§¯åˆ†è½¬è´¦\n- ğŸ“Š ç§¯åˆ†æ’è¡Œ - æŸ¥çœ‹ç§¯åˆ†æ’å\n\n## ğŸ‘® ç®¡ç†åŠŸèƒ½\n\n- âš™ï¸ æ’ä»¶ç®¡ç† - åŠ¨æ€åŠ è½½/å¸è½½æ’ä»¶\n- ğŸ‘¥ ç™½åå•ç®¡ç† - æ§åˆ¶æœºå™¨äººä½¿ç”¨æƒé™\n- ğŸ“Š ç§¯åˆ†ç®¡ç† - ç®¡ç†å‘˜å¯è°ƒæ•´ç”¨æˆ·ç§¯åˆ†\n- ğŸ”„ ç­¾åˆ°é‡ç½® - é‡ç½®æ‰€æœ‰ç”¨æˆ·ç­¾åˆ°çŠ¶æ€\n\n# ğŸ”Œ æ’ä»¶ç³»ç»Ÿ\n\nXYBot V2 é‡‡ç”¨æ’ä»¶åŒ–è®¾è®¡,æ‰€æœ‰åŠŸèƒ½éƒ½ä»¥æ’ä»¶å½¢å¼å®ç°ã€‚ä¸»è¦æ’ä»¶åŒ…æ‹¬:\n\n- ğŸ‘¨â€ğŸ’¼ AdminPoint - ç§¯åˆ†ç®¡ç†\n- ğŸ”„ AdminSignInReset - ç­¾åˆ°é‡ç½®\n- ğŸ›¡ï¸ AdminWhitelist - ç™½åå•ç®¡ç†\n- ğŸ¤– Ai - AIèŠå¤©\n- ğŸ“Š BotStatus - æœºå™¨äººçŠ¶æ€\n- ğŸ“± GetContact - è·å–é€šè®¯å½•\n- ğŸŒ¤ï¸ GetWeather - å¤©æ°”æŸ¥è¯¢\n- ğŸ® Gomoku - äº”å­æ£‹æ¸¸æˆ\n- ğŸŒ… GoodMorning - æ—©å®‰é—®å€™\n- ğŸ“ˆ Leaderboard - ç§¯åˆ†æ’è¡Œ\n- ğŸ² LuckyDraw - å¹¸è¿æŠ½å¥–\n- ğŸ“‹ Menu - èœå•ç³»ç»Ÿ\n- ğŸµ Music - ç‚¹æ­Œç³»ç»Ÿ\n- ğŸ“° News - æ–°é—»æ¨é€\n- ğŸ’± PointTrade - ç§¯åˆ†äº¤æ˜“\n- ğŸ’° QueryPoint - ç§¯åˆ†æŸ¥è¯¢\n- ğŸ¯ RandomMember - éšæœºç¾¤æˆå‘˜\n- ğŸ–¼ï¸ RandomPicture - éšæœºå›¾ç‰‡\n- ğŸ§§ RedPacket - çº¢åŒ…ç³»ç»Ÿ\n- âœï¸ SignIn - æ¯æ—¥ç­¾åˆ°\n- âœˆï¸ Warthunder - æˆ˜äº‰é›·éœ†æŸ¥è¯¢\n\n# ğŸš€ éƒ¨ç½²è¯´æ˜\n\n## ğŸ’» Pythonéƒ¨ç½²\n\n### ğŸªŸ Windowséƒ¨ç½²\n\n#### 1. ç¯å¢ƒå‡†å¤‡\n\n- å®‰è£… Python 3.11: https://www.python.org/downloads/release/python-3119/\n- å®‰è£… ffmpeg: ä»[ffmpegå®˜ç½‘](https://www.ffmpeg.org/download.html)ä¸‹è½½å¹¶æ·»åŠ åˆ°ç¯å¢ƒå˜é‡\n- å®‰è£… Redis: ä»[Redis](https://github.com/tporadowski/redis/releases/tag/v5.0.14.1)ä¸‹è½½å¹¶å¯åŠ¨æœåŠ¡\n\n#### 2. å®‰è£…é¡¹ç›®\n\n```bash\ngit clone https://github.com/HenryXiaoYang/XYBotV2.git\ncd XYBotV2\npython -m venv venv\n.\\venv\\Scripts\\activate\npip install -r requirements.txt\n```\n\n#### 3. å¯åŠ¨æœºå™¨äºº\n\n```bash\nstart redis-server\npython app.py\n```\n\n### ğŸ§ Linuxéƒ¨ç½²\n\n#### 1. ç¯å¢ƒå‡†å¤‡\n\n```bash\nsudo apt update\nsudo apt install python3.11 python3.11-venv redis-server ffmpeg\nsudo systemctl start redis\nsudo systemctl enable redis\n```\n\n#### 2. å®‰è£…é¡¹ç›®\n\n```bash\ngit clone https://github.com/HenryXiaoYang/XYBotV2.git\ncd XYBotV2\npython3.11 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n```\n\n#### 3. å¯åŠ¨æœºå™¨äºº\n\n```bash\npython app.py\n```\n\n### ğŸŒŒ æ— WebUIç®€å•å¯åŠ¨\n\nå¦‚æœä½ ä¸éœ€è¦WebUIç•Œé¢ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨bot.pyï¼š\n\n```bash\npython bot.py\n```\n\n## âš™ï¸ é…ç½®è¯´æ˜\n\n- ä¸»é…ç½®: main_config.toml\n- æ’ä»¶é…ç½®: plugins/all_in_one_config.toml\n\nè¿™å‡ ä¸ªæ’ä»¶éœ€è¦é…ç½®APIå¯†é’¥:\n- ğŸ¤– Ai\n- ğŸŒ¤ï¸ GetWeather\n\n## â“ å¸¸è§é—®é¢˜\n\n1. ä¸ç½‘ç»œç›¸å…³çš„æŠ¥é”™\n   - æ£€æŸ¥ç½‘ç»œè¿æ¥\n   - å…³é—­ä»£ç†è½¯ä»¶\n   - é‡å¯XYBotå’ŒRedis\n\n2. `æ­£åœ¨è¿è¡Œ`ç›¸å…³çš„æŠ¥é”™\n   - å°†å ç”¨9000ç«¯å£çš„è¿›ç¨‹ç»“æŸ\n\n3. æ— æ³•è®¿é—®Webç•Œé¢\n   - ç¡®ä¿9999ç«¯å£å·²å¼€æ”¾\n   - é…ç½®é˜²ç«å¢™å…è®¸9999ç«¯å£\n\n# ğŸ’» ä»£ç æäº¤\n\næäº¤ä»£ç æ—¶è¯·ä½¿ç”¨ `feat: something` ä½œä¸ºè¯´æ˜ï¼Œæ”¯æŒçš„æ ‡è¯†å¦‚ä¸‹:\n\n- `feat` æ–°åŠŸèƒ½(feature)\n- `fix` ä¿®å¤bug\n- `docs` æ–‡æ¡£(documentation)\n- `style` æ ¼å¼(ä¸å½±å“ä»£ç è¿è¡Œçš„å˜åŠ¨)\n- `ref` é‡æ„(å³ä¸æ˜¯æ–°å¢åŠŸèƒ½ï¼Œä¹Ÿä¸æ˜¯ä¿®æ”¹bugçš„ä»£ç å˜åŠ¨)\n- `perf` æ€§èƒ½ä¼˜åŒ–(performance)\n- `test` å¢åŠ æµ‹è¯•\n- `chore` æ„å»ºè¿‡ç¨‹æˆ–è¾…åŠ©å·¥å…·çš„å˜åŠ¨\n- `revert` æ’¤é”€\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "xbotv2",
        "wechat",
        "bot",
        "bot framework",
        "wechat bot",
        "xbotv2 comprehensive"
      ],
      "category": "virtual-assistants"
    },
    "Yash-Kavaiya--mcp-server-conversation-agents": {
      "owner": "Yash-Kavaiya",
      "name": "mcp-server-conversation-agents",
      "url": "https://github.com/Yash-Kavaiya/mcp-server-conversation-agents",
      "imageUrl": "https://github.com/Yash-Kavaiya.png",
      "description": "Integrates AI assistants with Dialogflow CX for real-time tool invocation and access to external resources, enhancing user interactions and streamlining workflows.",
      "stars": 3,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-08-07T16:51:09Z",
      "readme_content": "# ğŸ¤– Dialogflow CX MCP Server ğŸš€\n\n![Dialogflow CX](https://img.shields.io/badge/Dialogflow_CX-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)\n![MCP](https://img.shields.io/badge/MCP-Server-00C7B7?style=for-the-badge&logo=serverfault&logoColor=white)\n![Python](https://img.shields.io/badge/Python-3.12-3776AB?style=for-the-badge&logo=python&logoColor=white)\n\nA powerful Model Control Protocol (MCP) server implementation for **Google Dialogflow CX**, enabling seamless integration between AI assistants and Google's advanced conversational platform.\n\n> ğŸ’¡ **Pro Tip:** This server bridges the gap between AI assistants and Dialogflow CX, unlocking powerful conversational capabilities!\n\n## ğŸ“‹ Overview\n\nThis project provides a suite of tools that allow AI assistants to interact with Dialogflow CX agents through a standardized protocol. The server handles all the complexity of managing conversations, processing intent detection, and interfacing with Google's powerful NLU systems.\n\n### âœ¨ Key Features\n\n- ğŸ”„ Bidirectional communication with Dialogflow CX\n- ğŸ¯ Intent detection and matching capabilities\n- ğŸ¤ Audio processing for speech recognition\n- ğŸ”Œ Webhook request/response handling\n- ğŸ“ Session management for persistent conversations\n- ğŸ”’ Secure API authentication\n\n## ğŸ”§ Requirements\n\n| Requirement | Description | Version |\n|-------------|-------------|---------|\n| ğŸ Python | Programming language | 3.12+ |\n| â˜ï¸ Google Cloud | Project with Dialogflow CX enabled | Latest |\n| ğŸ¤– Dialogflow CX | Conversational agent | Latest |\n| ğŸ”‘ API Credentials | Authentication for Google services | - |\n\n## ğŸš€ Installation\n\n### ğŸ³ Using Docker\n\n```bash\n# Clone the repository\ngit clone https://github.com/Yash-Kavaiya/mcp-server-conversation-agents.git\ncd mcp-server-conversation-agents\n\n# Build the Docker image\ndocker build -t dialogflow-cx-mcp .\n\n# Run the container\ndocker run -it dialogflow-cx-mcp\n```\n\n### ğŸ’» Manual Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/Yash-Kavaiya/mcp-server-conversation-agents.git\ncd mcp-server-conversation-agents\n\n# Create a virtual environment (optional but recommended)\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install the package\npip install -e .\n```\n\n## âš™ï¸ Configuration\n\nYou'll need to provide the following configuration parameters:\n\n| Parameter | Description | Example |\n|-----------|-------------|---------|\n| `dialogflowApiKey` | Your Dialogflow API key | `\"abc123def456\"` |\n| `projectId` | Google Cloud project ID | `\"my-dialogflow-project\"` |\n| `location` | Location of the agent | `\"us-central1\"` |\n| `agentId` | ID of your Dialogflow CX agent | `\"12345-abcde-67890\"` |\n\nThese can be set as environment variables:\n\n```bash\nexport DIALOGFLOW_API_KEY=your_api_key\nexport PROJECT_ID=your_project_id\nexport LOCATION=your_location\nexport AGENT_ID=your_agent_id\n```\n\n## ğŸ“Š Architecture\n\n```mermaid\ngraph TD\n    A[AI Assistant] <-->|MCP Protocol| B[MCP Server]\n    B <-->|Google API| C[Dialogflow CX]\n    C <-->|NLU Processing| D[Intent Detection]\n    C <-->|Conversation Management| E[Session Management]\n    B <-->|Webhooks| F[External Services]\n```\n\n## ğŸ› ï¸ Usage\n\nThe MCP server exposes the following tools for AI assistants:\n\n### ğŸ” initialize_dialogflow\n\nInitialize the Dialogflow CX client with your project details.\n\n```python\nawait initialize_dialogflow(\n    project_id=\"your-project-id\",\n    location=\"us-central1\",\n    agent_id=\"your-agent-id\",\n    credentials_path=\"/path/to/credentials.json\"  # Optional\n)\n```\n\n### ğŸ’¬ detect_intent\n\nDetect intent from text input.\n\n```python\nresponse = await detect_intent(\n    text=\"Hello, how can you help me?\",\n    session_id=\"user123\",  # Optional\n    language_code=\"en-US\"  # Optional\n)\n```\n\n### ğŸ¤ detect_intent_from_audio\n\nProcess audio files to detect intent.\n\n```python\nresponse = await detect_intent_from_audio(\n    audio_file_path=\"/path/to/audio.wav\",\n    session_id=\"user123\",  # Optional\n    sample_rate_hertz=16000,  # Optional\n    audio_encoding=\"AUDIO_ENCODING_LINEAR_16\",  # Optional\n    language_code=\"en-US\"  # Optional\n)\n```\n\n### ğŸ¯ match_intent\n\nMatch intent without affecting the conversation session.\n\n```python\nresponse = await match_intent(\n    text=\"What are your hours?\",\n    session_id=\"user123\",  # Optional\n    language_code=\"en-US\"  # Optional\n)\n```\n\n### ğŸ”„ Webhook Handling\n\nParse webhook requests and create webhook responses:\n\n```python\n# Parse a webhook request\nparsed_request = await parse_webhook_request(request_json)\n\n# Create a webhook response\nresponse = await create_webhook_response({\n    \"messages\": [\"Hello! How can I help you today?\"],\n    \"parameter_updates\": {\"user_name\": \"John\"}\n})\n```\n\n## ğŸ”§ Response Format\n\nHere's an example of the response format:\n\n<details>\n<summary>ğŸ“‹ Click to expand</summary>\n\n```json\n{\n  \"messages\": [\n    {\n      \"type\": \"text\",\n      \"content\": \"Hello! How can I help you today?\"\n    }\n  ],\n  \"intent\": {\n    \"name\": \"greeting\",\n    \"confidence\": 0.95\n  },\n  \"parameters\": {\n    \"user_name\": \"John\"\n  },\n  \"current_page\": \"Welcome Page\",\n  \"session_id\": \"user123\",\n  \"end_interaction\": false\n}\n```\n</details>\n\n## ğŸ”— Smithery Integration\n\nThis project is configured to work with [Smithery.ai](https://smithery.ai/), a platform that allows for easy deployment and management of MCP servers.\n\n> ğŸ’¡ **Pro Tip:** Smithery.ai integration enables one-click deployment and simplified management of your Dialogflow CX MCP server!\n\n## ğŸ“„ License\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)\n\n## ğŸ‘¥ Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n### Contribution Workflow\n\n1. ğŸ´ Fork the repository\n2. ğŸ”§ Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. ğŸ’» Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. ğŸš€ Push to the branch (`git push origin feature/amazing-feature`)\n5. ğŸ” Open a Pull Request\n\n---\n\n<p align=\"center\">\n  Built with â¤ï¸ by the MCP Server team\n</p>\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "dialogflow",
        "assistants",
        "ai",
        "virtual assistants",
        "ai assistants",
        "assistants dialogflow"
      ],
      "category": "virtual-assistants"
    },
    "a1351995160--Auto-GPT": {
      "owner": "a1351995160",
      "name": "Auto-GPT",
      "url": "https://github.com/a1351995160/Auto-GPT",
      "imageUrl": "https://github.com/a1351995160.png",
      "description": "Autonomously achieve goals by chaining thoughts of the GPT-4 model while accessing the internet, managing memory, and storing files. The server supports plugin extensibility to enhance functionality.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2023-05-22T08:25:34Z",
      "readme_content": "# Auto-GPT: An Autonomous GPT-4 Experiment\n[![Official Website](https://img.shields.io/badge/Official%20Website-agpt.co-blue?style=flat&logo=world&logoColor=white)](https://agpt.co)\n[![Unit Tests](https://img.shields.io/github/actions/workflow/status/Significant-Gravitas/Auto-GPT/ci.yml?label=unit%20tests)](https://github.com/Significant-Gravitas/Auto-GPT/actions/workflows/ci.yml)\n[![Discord Follow](https://dcbadge.vercel.app/api/server/autogpt?style=flat)](https://discord.gg/autogpt)\n[![GitHub Repo stars](https://img.shields.io/github/stars/Significant-Gravitas/auto-gpt?style=social)](https://github.com/Significant-Gravitas/Auto-GPT/stargazers)\n[![Twitter Follow](https://img.shields.io/twitter/follow/siggravitas?style=social)](https://twitter.com/SigGravitas)\n\n## ğŸ’¡ Get help - [Q&A](https://github.com/Significant-Gravitas/Auto-GPT/discussions/categories/q-a) or [Discord ğŸ’¬](https://discord.gg/autogpt)\n\n<hr/>\n\n### ğŸ”´ USE `stable` not `master` ğŸ”´\n\n**Download the latest `stable` release from here: https://github.com/Significant-Gravitas/Auto-GPT/releases/latest.**\nThe `master` branch is under heavy development and may often be in a **broken** state.\n\n<hr/>\n\n\nAuto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. This program, driven by GPT-4, chains together LLM \"thoughts\", to autonomously achieve whatever goal you set. As one of the first examples of GPT-4 running fully autonomously, Auto-GPT pushes the boundaries of what is possible with AI.\n\n<h2 align=\"center\"> Demo April 16th 2023 </h2>\n\nhttps://user-images.githubusercontent.com/70048414/232352935-55c6bf7c-3958-406e-8610-0913475a0b05.mp4\n\nDemo made by <a href=https://twitter.com/BlakeWerlinger>Blake Werlinger</a>\n\n<h2 align=\"center\"> ğŸ’– Help Fund Auto-GPT's Development ğŸ’–</h2>\n<p align=\"center\">\nIf you can spare a coffee, you can help to cover the costs of developing Auto-GPT and help to push the boundaries of fully autonomous AI!\nYour support is greatly appreciated. Development of this free, open-source project is made possible by all the <a href=\"https://github.com/Significant-Gravitas/Auto-GPT/graphs/contributors\">contributors</a> and <a href=\"https://github.com/sponsors/Torantulino\">sponsors</a>. If you'd like to sponsor this project and have your avatar or company logo appear below <a href=\"https://github.com/sponsors/Torantulino\">click here</a>.\n</p>\n\n\n<p align=\"center\">\n<div align=\"center\" class=\"logo-container\">\n<a href=\"https://www.zilliz.com/\">\n<picture height=\"40px\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://user-images.githubusercontent.com/22963551/234158272-7917382e-ff80-469e-8d8c-94f4477b8b5a.png\">\n  <img src=\"https://user-images.githubusercontent.com/22963551/234158222-30e2d7a7-f0a9-433d-a305-e3aa0b194444.png\" height=\"40px\" alt=\"Zilliz\" />\n</picture>\n</a>\n\n<a href=\"https://roost.ai\">\n<img src=\"https://user-images.githubusercontent.com/22963551/234180283-b58cb03c-c95a-4196-93c1-28b52a388e9d.png\" height=\"40px\" alt=\"Roost.AI\" />\n</a>\n  \n<a href=\"https://nuclei.ai/\">\n<picture height=\"40px\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://user-images.githubusercontent.com/22963551/234153428-24a6f31d-c0c6-4c9b-b3f4-9110148f67b4.png\">\n  <img src=\"https://user-images.githubusercontent.com/22963551/234181283-691c5d71-ca94-4646-a1cf-6e818bd86faa.png\" height=\"40px\" alt=\"NucleiAI\" />\n</picture>\n</a>\n\n<a href=\"https://www.algohash.org/\">\n<picture>\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://user-images.githubusercontent.com/22963551/234180375-1365891c-0ba6-4d49-94c3-847c85fe03b0.png\" >\n  <img src=\"https://user-images.githubusercontent.com/22963551/234180359-143e4a7a-4a71-4830-99c8-9b165cde995f.png\" height=\"40px\" alt=\"Algohash\" />\n</picture>\n</a>\n\n<a href=\"https://www.typingmind.com/?utm_source=autogpt\">\n<picture height=\"40px\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://user-images.githubusercontent.com/22963551/233202971-61e77209-58a0-47d9-9f7e-dd081111437b.png\">\n  <img src=\"https://user-images.githubusercontent.com/22963551/234157731-f908b5db-8fe7-4036-89b6-7b2a21f87e3a.png\" height=\"40px\" alt=\"TypingMind\" />\n</picture>\n</a>\n\n<a href=\"https://github.com/weaviate/weaviate\">\n<picture height=\"40px\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://user-images.githubusercontent.com/22963551/234181699-3d7f6ea8-5a7f-4e98-b812-37be1081be4b.png\">\n  <img src=\"https://user-images.githubusercontent.com/22963551/234181695-fc895159-b921-4895-9a13-65e6eff5b0e7.png\" height=\"40px\" alt=\"TypingMind\" />\n</picture>\n</a>\n\n<a href=\"https://chatgpv.com/?ref=spni76459e4fa3f30a\">\n<img src=\"https://github-production-user-asset-6210df.s3.amazonaws.com/22963551/239132565-623a2dd6-eaeb-4941-b40f-c5a29ca6bebc.png\" height=\"40px\" alt=\"ChatGPV\" />\n</a>\n  \n</div>\n</br>\n\n\n\n<p align=\"center\"><a href=\"https://github.com/robinicus\"><img src=\"https://avatars.githubusercontent.com/robinicus?v=4\" width=\"50px\" alt=\"robinicus\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/0xmatchmaker\"><img src=\"https://avatars.githubusercontent.com/0xmatchmaker?v=4\" width=\"50px\" alt=\"0xmatchmaker\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/jazgarewal\"><img src=\"https://avatars.githubusercontent.com/jazgarewal?v=4\" width=\"50px\" alt=\"jazgarewal\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/MayurVirkar\"><img src=\"https://avatars.githubusercontent.com/MayurVirkar?v=4\" width=\"50px\" alt=\"MayurVirkar\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/avy-ai\"><img src=\"https://avatars.githubusercontent.com/avy-ai?v=4\" width=\"50px\" alt=\"avy-ai\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/TheStoneMX\"><img src=\"https://avatars.githubusercontent.com/TheStoneMX?v=4\" width=\"50px\" alt=\"TheStoneMX\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/goldenrecursion\"><img src=\"https://avatars.githubusercontent.com/goldenrecursion?v=4\" width=\"50px\" alt=\"goldenrecursion\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/MatthewAgs\"><img src=\"https://avatars.githubusercontent.com/MatthewAgs?v=4\" width=\"50px\" alt=\"MatthewAgs\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/eelbaz\"><img src=\"https://avatars.githubusercontent.com/eelbaz?v=4\" width=\"50px\" alt=\"eelbaz\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/rapidstartup\"><img src=\"https://avatars.githubusercontent.com/rapidstartup?v=4\" width=\"50px\" alt=\"rapidstartup\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/gklab\"><img src=\"https://avatars.githubusercontent.com/gklab?v=4\" width=\"50px\" alt=\"gklab\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/VoiceBeer\"><img src=\"https://avatars.githubusercontent.com/VoiceBeer?v=4\" width=\"50px\" alt=\"VoiceBeer\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/DailyBotHQ\"><img src=\"https://avatars.githubusercontent.com/DailyBotHQ?v=4\" width=\"50px\" alt=\"DailyBotHQ\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/lucas-chu\"><img src=\"https://avatars.githubusercontent.com/lucas-chu?v=4\" width=\"50px\" alt=\"lucas-chu\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/knifour\"><img src=\"https://avatars.githubusercontent.com/knifour?v=4\" width=\"50px\" alt=\"knifour\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/refinery1\"><img src=\"https://avatars.githubusercontent.com/refinery1?v=4\" width=\"50px\" alt=\"refinery1\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/st617\"><img src=\"https://avatars.githubusercontent.com/st617?v=4\" width=\"50px\" alt=\"st617\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/neodenit\"><img src=\"https://avatars.githubusercontent.com/neodenit?v=4\" width=\"50px\" alt=\"neodenit\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/CrazySwami\"><img src=\"https://avatars.githubusercontent.com/CrazySwami?v=4\" width=\"50px\" alt=\"CrazySwami\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Heitechsoft\"><img src=\"https://avatars.githubusercontent.com/Heitechsoft?v=4\" width=\"50px\" alt=\"Heitechsoft\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/RealChrisSean\"><img src=\"https://avatars.githubusercontent.com/RealChrisSean?v=4\" width=\"50px\" alt=\"RealChrisSean\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/abhinav-pandey29\"><img src=\"https://avatars.githubusercontent.com/abhinav-pandey29?v=4\" width=\"50px\" alt=\"abhinav-pandey29\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Explorergt92\"><img src=\"https://avatars.githubusercontent.com/Explorergt92?v=4\" width=\"50px\" alt=\"Explorergt92\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/SparkplanAI\"><img src=\"https://avatars.githubusercontent.com/SparkplanAI?v=4\" width=\"50px\" alt=\"SparkplanAI\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/crizzler\"><img src=\"https://avatars.githubusercontent.com/crizzler?v=4\" width=\"50px\" alt=\"crizzler\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/kreativai\"><img src=\"https://avatars.githubusercontent.com/kreativai?v=4\" width=\"50px\" alt=\"kreativai\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/omphos\"><img src=\"https://avatars.githubusercontent.com/omphos?v=4\" width=\"50px\" alt=\"omphos\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Jahmazon\"><img src=\"https://avatars.githubusercontent.com/Jahmazon?v=4\" width=\"50px\" alt=\"Jahmazon\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/tjarmain\"><img src=\"https://avatars.githubusercontent.com/tjarmain?v=4\" width=\"50px\" alt=\"tjarmain\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/ddtarazona\"><img src=\"https://avatars.githubusercontent.com/ddtarazona?v=4\" width=\"50px\" alt=\"ddtarazona\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/saten-private\"><img src=\"https://avatars.githubusercontent.com/saten-private?v=4\" width=\"50px\" alt=\"saten-private\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/anvarazizov\"><img src=\"https://avatars.githubusercontent.com/anvarazizov?v=4\" width=\"50px\" alt=\"anvarazizov\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/lazzacapital\"><img src=\"https://avatars.githubusercontent.com/lazzacapital?v=4\" width=\"50px\" alt=\"lazzacapital\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/m\"><img src=\"https://avatars.githubusercontent.com/m?v=4\" width=\"50px\" alt=\"m\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Pythagora-io\"><img src=\"https://avatars.githubusercontent.com/Pythagora-io?v=4\" width=\"50px\" alt=\"Pythagora-io\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Web3Capital\"><img src=\"https://avatars.githubusercontent.com/Web3Capital?v=4\" width=\"50px\" alt=\"Web3Capital\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/toverly1\"><img src=\"https://avatars.githubusercontent.com/toverly1?v=4\" width=\"50px\" alt=\"toverly1\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/digisomni\"><img src=\"https://avatars.githubusercontent.com/digisomni?v=4\" width=\"50px\" alt=\"digisomni\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/concreit\"><img src=\"https://avatars.githubusercontent.com/concreit?v=4\" width=\"50px\" alt=\"concreit\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/LeeRobidas\"><img src=\"https://avatars.githubusercontent.com/LeeRobidas?v=4\" width=\"50px\" alt=\"LeeRobidas\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Josecodesalot\"><img src=\"https://avatars.githubusercontent.com/Josecodesalot?v=4\" width=\"50px\" alt=\"Josecodesalot\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/dexterityx\"><img src=\"https://avatars.githubusercontent.com/dexterityx?v=4\" width=\"50px\" alt=\"dexterityx\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/rickscode\"><img src=\"https://avatars.githubusercontent.com/rickscode?v=4\" width=\"50px\" alt=\"rickscode\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Brodie0\"><img src=\"https://avatars.githubusercontent.com/Brodie0?v=4\" width=\"50px\" alt=\"Brodie0\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/FSTatSBS\"><img src=\"https://avatars.githubusercontent.com/FSTatSBS?v=4\" width=\"50px\" alt=\"FSTatSBS\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/nocodeclarity\"><img src=\"https://avatars.githubusercontent.com/nocodeclarity?v=4\" width=\"50px\" alt=\"nocodeclarity\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/jsolejr\"><img src=\"https://avatars.githubusercontent.com/jsolejr?v=4\" width=\"50px\" alt=\"jsolejr\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/amr-elsehemy\"><img src=\"https://avatars.githubusercontent.com/amr-elsehemy?v=4\" width=\"50px\" alt=\"amr-elsehemy\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/RawBanana\"><img src=\"https://avatars.githubusercontent.com/RawBanana?v=4\" width=\"50px\" alt=\"RawBanana\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/horazius\"><img src=\"https://avatars.githubusercontent.com/horazius?v=4\" width=\"50px\" alt=\"horazius\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/SwftCoins\"><img src=\"https://avatars.githubusercontent.com/SwftCoins?v=4\" width=\"50px\" alt=\"SwftCoins\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/tob-le-rone\"><img src=\"https://avatars.githubusercontent.com/tob-le-rone?v=4\" width=\"50px\" alt=\"tob-le-rone\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/RThaweewat\"><img src=\"https://avatars.githubusercontent.com/RThaweewat?v=4\" width=\"50px\" alt=\"RThaweewat\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/jun784\"><img src=\"https://avatars.githubusercontent.com/jun784?v=4\" width=\"50px\" alt=\"jun784\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/joaomdmoura\"><img src=\"https://avatars.githubusercontent.com/joaomdmoura?v=4\" width=\"50px\" alt=\"joaomdmoura\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/rejunity\"><img src=\"https://avatars.githubusercontent.com/rejunity?v=4\" width=\"50px\" alt=\"rejunity\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/mathewhawkins\"><img src=\"https://avatars.githubusercontent.com/mathewhawkins?v=4\" width=\"50px\" alt=\"mathewhawkins\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/caitlynmeeks\"><img src=\"https://avatars.githubusercontent.com/caitlynmeeks?v=4\" width=\"50px\" alt=\"caitlynmeeks\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/jd3655\"><img src=\"https://avatars.githubusercontent.com/jd3655?v=4\" width=\"50px\" alt=\"jd3655\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Odin519Tomas\"><img src=\"https://avatars.githubusercontent.com/Odin519Tomas?v=4\" width=\"50px\" alt=\"Odin519Tomas\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/DataMetis\"><img src=\"https://avatars.githubusercontent.com/DataMetis?v=4\" width=\"50px\" alt=\"DataMetis\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/webbcolton\"><img src=\"https://avatars.githubusercontent.com/webbcolton?v=4\" width=\"50px\" alt=\"webbcolton\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/rocks6\"><img src=\"https://avatars.githubusercontent.com/rocks6?v=4\" width=\"50px\" alt=\"rocks6\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/cxs\"><img src=\"https://avatars.githubusercontent.com/cxs?v=4\" width=\"50px\" alt=\"cxs\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/fruition\"><img src=\"https://avatars.githubusercontent.com/fruition?v=4\" width=\"50px\" alt=\"fruition\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/nnkostov\"><img src=\"https://avatars.githubusercontent.com/nnkostov?v=4\" width=\"50px\" alt=\"nnkostov\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/morcos\"><img src=\"https://avatars.githubusercontent.com/morcos?v=4\" width=\"50px\" alt=\"morcos\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/pingbotan\"><img src=\"https://avatars.githubusercontent.com/pingbotan?v=4\" width=\"50px\" alt=\"pingbotan\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/maxxflyer\"><img src=\"https://avatars.githubusercontent.com/maxxflyer?v=4\" width=\"50px\" alt=\"maxxflyer\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/tommi-joentakanen\"><img src=\"https://avatars.githubusercontent.com/tommi-joentakanen?v=4\" width=\"50px\" alt=\"tommi-joentakanen\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/hunteraraujo\"><img src=\"https://avatars.githubusercontent.com/hunteraraujo?v=4\" width=\"50px\" alt=\"hunteraraujo\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/projectonegames\"><img src=\"https://avatars.githubusercontent.com/projectonegames?v=4\" width=\"50px\" alt=\"projectonegames\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/tullytim\"><img src=\"https://avatars.githubusercontent.com/tullytim?v=4\" width=\"50px\" alt=\"tullytim\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/comet-ml\"><img src=\"https://avatars.githubusercontent.com/comet-ml?v=4\" width=\"50px\" alt=\"comet-ml\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/thepok\"><img src=\"https://avatars.githubusercontent.com/thepok?v=4\" width=\"50px\" alt=\"thepok\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/prompthero\"><img src=\"https://avatars.githubusercontent.com/prompthero?v=4\" width=\"50px\" alt=\"prompthero\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/sunchongren\"><img src=\"https://avatars.githubusercontent.com/sunchongren?v=4\" width=\"50px\" alt=\"sunchongren\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/neverinstall\"><img src=\"https://avatars.githubusercontent.com/neverinstall?v=4\" width=\"50px\" alt=\"neverinstall\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/josephcmiller2\"><img src=\"https://avatars.githubusercontent.com/josephcmiller2?v=4\" width=\"50px\" alt=\"josephcmiller2\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/yx3110\"><img src=\"https://avatars.githubusercontent.com/yx3110?v=4\" width=\"50px\" alt=\"yx3110\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/MBassi91\"><img src=\"https://avatars.githubusercontent.com/MBassi91?v=4\" width=\"50px\" alt=\"MBassi91\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/SpacingLily\"><img src=\"https://avatars.githubusercontent.com/SpacingLily?v=4\" width=\"50px\" alt=\"SpacingLily\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/arthur-x88\"><img src=\"https://avatars.githubusercontent.com/arthur-x88?v=4\" width=\"50px\" alt=\"arthur-x88\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/ciscodebs\"><img src=\"https://avatars.githubusercontent.com/ciscodebs?v=4\" width=\"50px\" alt=\"ciscodebs\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/christian-gheorghe\"><img src=\"https://avatars.githubusercontent.com/christian-gheorghe?v=4\" width=\"50px\" alt=\"christian-gheorghe\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/EngageStrategies\"><img src=\"https://avatars.githubusercontent.com/EngageStrategies?v=4\" width=\"50px\" alt=\"EngageStrategies\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/jondwillis\"><img src=\"https://avatars.githubusercontent.com/jondwillis?v=4\" width=\"50px\" alt=\"jondwillis\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Cameron-Fulton\"><img src=\"https://avatars.githubusercontent.com/Cameron-Fulton?v=4\" width=\"50px\" alt=\"Cameron-Fulton\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/AryaXAI\"><img src=\"https://avatars.githubusercontent.com/AryaXAI?v=4\" width=\"50px\" alt=\"AryaXAI\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/AuroraHolding\"><img src=\"https://avatars.githubusercontent.com/AuroraHolding?v=4\" width=\"50px\" alt=\"AuroraHolding\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Mr-Bishop42\"><img src=\"https://avatars.githubusercontent.com/Mr-Bishop42?v=4\" width=\"50px\" alt=\"Mr-Bishop42\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/doverhq\"><img src=\"https://avatars.githubusercontent.com/doverhq?v=4\" width=\"50px\" alt=\"doverhq\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/johnculkin\"><img src=\"https://avatars.githubusercontent.com/johnculkin?v=4\" width=\"50px\" alt=\"johnculkin\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/marv-technology\"><img src=\"https://avatars.githubusercontent.com/marv-technology?v=4\" width=\"50px\" alt=\"marv-technology\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/ikarosai\"><img src=\"https://avatars.githubusercontent.com/ikarosai?v=4\" width=\"50px\" alt=\"ikarosai\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/ColinConwell\"><img src=\"https://avatars.githubusercontent.com/ColinConwell?v=4\" width=\"50px\" alt=\"ColinConwell\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/humungasaurus\"><img src=\"https://avatars.githubusercontent.com/humungasaurus?v=4\" width=\"50px\" alt=\"humungasaurus\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/terpsfreak\"><img src=\"https://avatars.githubusercontent.com/terpsfreak?v=4\" width=\"50px\" alt=\"terpsfreak\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/iddelacruz\"><img src=\"https://avatars.githubusercontent.com/iddelacruz?v=4\" width=\"50px\" alt=\"iddelacruz\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/thisisjeffchen\"><img src=\"https://avatars.githubusercontent.com/thisisjeffchen?v=4\" width=\"50px\" alt=\"thisisjeffchen\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/nicoguyon\"><img src=\"https://avatars.githubusercontent.com/nicoguyon?v=4\" width=\"50px\" alt=\"nicoguyon\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/arjunb023\"><img src=\"https://avatars.githubusercontent.com/arjunb023?v=4\" width=\"50px\" alt=\"arjunb023\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Nalhos\"><img src=\"https://avatars.githubusercontent.com/Nalhos?v=4\" width=\"50px\" alt=\"Nalhos\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/belharethsami\"><img src=\"https://avatars.githubusercontent.com/belharethsami?v=4\" width=\"50px\" alt=\"belharethsami\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Mobivs\"><img src=\"https://avatars.githubusercontent.com/Mobivs?v=4\" width=\"50px\" alt=\"Mobivs\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/txtr99\"><img src=\"https://avatars.githubusercontent.com/txtr99?v=4\" width=\"50px\" alt=\"txtr99\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/ntwrite\"><img src=\"https://avatars.githubusercontent.com/ntwrite?v=4\" width=\"50px\" alt=\"ntwrite\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/founderblocks-sils\"><img src=\"https://avatars.githubusercontent.com/founderblocks-sils?v=4\" width=\"50px\" alt=\"founderblocks-sils\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/kMag410\"><img src=\"https://avatars.githubusercontent.com/kMag410?v=4\" width=\"50px\" alt=\"kMag410\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/angiaou\"><img src=\"https://avatars.githubusercontent.com/angiaou?v=4\" width=\"50px\" alt=\"angiaou\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/garythebat\"><img src=\"https://avatars.githubusercontent.com/garythebat?v=4\" width=\"50px\" alt=\"garythebat\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/lmaugustin\"><img src=\"https://avatars.githubusercontent.com/lmaugustin?v=4\" width=\"50px\" alt=\"lmaugustin\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/shawnharmsen\"><img src=\"https://avatars.githubusercontent.com/shawnharmsen?v=4\" width=\"50px\" alt=\"shawnharmsen\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/clortegah\"><img src=\"https://avatars.githubusercontent.com/clortegah?v=4\" width=\"50px\" alt=\"clortegah\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/MetaPath01\"><img src=\"https://avatars.githubusercontent.com/MetaPath01?v=4\" width=\"50px\" alt=\"MetaPath01\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/sekomike910\"><img src=\"https://avatars.githubusercontent.com/sekomike910?v=4\" width=\"50px\" alt=\"sekomike910\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/MediConCenHK\"><img src=\"https://avatars.githubusercontent.com/MediConCenHK?v=4\" width=\"50px\" alt=\"MediConCenHK\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/svpermari0\"><img src=\"https://avatars.githubusercontent.com/svpermari0?v=4\" width=\"50px\" alt=\"svpermari0\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/jacobyoby\"><img src=\"https://avatars.githubusercontent.com/jacobyoby?v=4\" width=\"50px\" alt=\"jacobyoby\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/turintech\"><img src=\"https://avatars.githubusercontent.com/turintech?v=4\" width=\"50px\" alt=\"turintech\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/allenstecat\"><img src=\"https://avatars.githubusercontent.com/allenstecat?v=4\" width=\"50px\" alt=\"allenstecat\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/CatsMeow492\"><img src=\"https://avatars.githubusercontent.com/CatsMeow492?v=4\" width=\"50px\" alt=\"CatsMeow492\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/tommygeee\"><img src=\"https://avatars.githubusercontent.com/tommygeee?v=4\" width=\"50px\" alt=\"tommygeee\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/judegomila\"><img src=\"https://avatars.githubusercontent.com/judegomila?v=4\" width=\"50px\" alt=\"judegomila\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/cfarquhar\"><img src=\"https://avatars.githubusercontent.com/cfarquhar?v=4\" width=\"50px\" alt=\"cfarquhar\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/ZoneSixGames\"><img src=\"https://avatars.githubusercontent.com/ZoneSixGames?v=4\" width=\"50px\" alt=\"ZoneSixGames\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/kenndanielso\"><img src=\"https://avatars.githubusercontent.com/kenndanielso?v=4\" width=\"50px\" alt=\"kenndanielso\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/CrypteorCapital\"><img src=\"https://avatars.githubusercontent.com/CrypteorCapital?v=4\" width=\"50px\" alt=\"CrypteorCapital\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/sultanmeghji\"><img src=\"https://avatars.githubusercontent.com/sultanmeghji?v=4\" width=\"50px\" alt=\"sultanmeghji\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/jenius-eagle\"><img src=\"https://avatars.githubusercontent.com/jenius-eagle?v=4\" width=\"50px\" alt=\"jenius-eagle\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/josephjacks\"><img src=\"https://avatars.githubusercontent.com/josephjacks?v=4\" width=\"50px\" alt=\"josephjacks\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/pingshian0131\"><img src=\"https://avatars.githubusercontent.com/pingshian0131?v=4\" width=\"50px\" alt=\"pingshian0131\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/AIdevelopersAI\"><img src=\"https://avatars.githubusercontent.com/AIdevelopersAI?v=4\" width=\"50px\" alt=\"AIdevelopersAI\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/ternary5\"><img src=\"https://avatars.githubusercontent.com/ternary5?v=4\" width=\"50px\" alt=\"ternary5\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/ChrisDMT\"><img src=\"https://avatars.githubusercontent.com/ChrisDMT?v=4\" width=\"50px\" alt=\"ChrisDMT\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/AcountoOU\"><img src=\"https://avatars.githubusercontent.com/AcountoOU?v=4\" width=\"50px\" alt=\"AcountoOU\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/chatgpt-prompts\"><img src=\"https://avatars.githubusercontent.com/chatgpt-prompts?v=4\" width=\"50px\" alt=\"chatgpt-prompts\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Partender\"><img src=\"https://avatars.githubusercontent.com/Partender?v=4\" width=\"50px\" alt=\"Partender\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Daniel1357\"><img src=\"https://avatars.githubusercontent.com/Daniel1357?v=4\" width=\"50px\" alt=\"Daniel1357\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/KiaArmani\"><img src=\"https://avatars.githubusercontent.com/KiaArmani?v=4\" width=\"50px\" alt=\"KiaArmani\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/zkonduit\"><img src=\"https://avatars.githubusercontent.com/zkonduit?v=4\" width=\"50px\" alt=\"zkonduit\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/fabrietech\"><img src=\"https://avatars.githubusercontent.com/fabrietech?v=4\" width=\"50px\" alt=\"fabrietech\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/scryptedinc\"><img src=\"https://avatars.githubusercontent.com/scryptedinc?v=4\" width=\"50px\" alt=\"scryptedinc\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/coreyspagnoli\"><img src=\"https://avatars.githubusercontent.com/coreyspagnoli?v=4\" width=\"50px\" alt=\"coreyspagnoli\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/AntonioCiolino\"><img src=\"https://avatars.githubusercontent.com/AntonioCiolino?v=4\" width=\"50px\" alt=\"AntonioCiolino\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Dradstone\"><img src=\"https://avatars.githubusercontent.com/Dradstone?v=4\" width=\"50px\" alt=\"Dradstone\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/CarmenCocoa\"><img src=\"https://avatars.githubusercontent.com/CarmenCocoa?v=4\" width=\"50px\" alt=\"CarmenCocoa\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/bentoml\"><img src=\"https://avatars.githubusercontent.com/bentoml?v=4\" width=\"50px\" alt=\"bentoml\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/merwanehamadi\"><img src=\"https://avatars.githubusercontent.com/merwanehamadi?v=4\" width=\"50px\" alt=\"merwanehamadi\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/vkozacek\"><img src=\"https://avatars.githubusercontent.com/vkozacek?v=4\" width=\"50px\" alt=\"vkozacek\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/ASmithOWL\"><img src=\"https://avatars.githubusercontent.com/ASmithOWL?v=4\" width=\"50px\" alt=\"ASmithOWL\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/tekelsey\"><img src=\"https://avatars.githubusercontent.com/tekelsey?v=4\" width=\"50px\" alt=\"tekelsey\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/GalaxyVideoAgency\"><img src=\"https://avatars.githubusercontent.com/GalaxyVideoAgency?v=4\" width=\"50px\" alt=\"GalaxyVideoAgency\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/wenfengwang\"><img src=\"https://avatars.githubusercontent.com/wenfengwang?v=4\" width=\"50px\" alt=\"wenfengwang\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/rviramontes\"><img src=\"https://avatars.githubusercontent.com/rviramontes?v=4\" width=\"50px\" alt=\"rviramontes\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/indoor47\"><img src=\"https://avatars.githubusercontent.com/indoor47?v=4\" width=\"50px\" alt=\"indoor47\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/ZERO-A-ONE\"><img src=\"https://avatars.githubusercontent.com/ZERO-A-ONE?v=4\" width=\"50px\" alt=\"ZERO-A-ONE\" /></a>&nbsp;&nbsp;</p>\n\n\n\n## ğŸš€ Features\n\n- ğŸŒ Internet access for searches and information gathering\n- ğŸ’¾ Long-term and short-term memory management\n- ğŸ§  GPT-4 instances for text generation\n- ğŸ”— Access to popular websites and platforms\n- ğŸ—ƒï¸ File storage and summarization with GPT-3.5\n- ğŸ”Œ Extensibility with Plugins\n\n## Quickstart\n\n0. Check out the [wiki](https://github.com/Significant-Gravitas/Nexus/wiki)\n1. Get an OpenAI [API Key](https://platform.openai.com/account/api-keys)\n2. Download the [latest release](https://github.com/Significant-Gravitas/Auto-GPT/releases/latest)\n3. Follow the [installation instructions][docs/setup]\n4. Configure any additional features you want, or install some [plugins][docs/plugins]\n5. [Run][docs/usage] the app\n\nPlease see the [documentation][docs] for full setup instructions and configuration options.\n\n[docs]: https://docs.agpt.co/\n\n## ğŸ“– Documentation\n* [âš™ï¸ Setup][docs/setup]\n* [ğŸ’» Usage][docs/usage]\n* [ğŸ”Œ Plugins][docs/plugins]\n* Configuration\n  * [ğŸ” Web Search](https://docs.agpt.co/configuration/search/)\n  * [ğŸ§  Memory](https://docs.agpt.co/configuration/memory/)\n  * [ğŸ—£ï¸ Voice (TTS)](https://docs.agpt.co/configuration/voice/)\n  * [ğŸ–¼ï¸ Image Generation](https://docs.agpt.co/configuration/imagegen/)\n\n[docs/setup]: https://docs.agpt.co/setup/\n[docs/usage]: https://docs.agpt.co/usage/\n[docs/plugins]: https://docs.agpt.co/plugins/\n\n## âš ï¸ Limitations\n\nThis experiment aims to showcase the potential of GPT-4 but comes with some limitations:\n\n1. Not a polished application or product, just an experiment\n2. May not perform well in complex, real-world business scenarios. In fact, if it actually does, please share your results!\n3. Quite expensive to run, so set and monitor your API key limits with OpenAI!\n\n## ğŸ›¡ Disclaimer\n\nThis project, Auto-GPT, is an experimental application and is provided \"as-is\" without any warranty, express or implied. By using this software, you agree to assume all risks associated with its use, including but not limited to data loss, system failure, or any other issues that may arise.\n\nThe developers and contributors of this project do not accept any responsibility or liability for any losses, damages, or other consequences that may occur as a result of using this software. You are solely responsible for any decisions and actions taken based on the information provided by Auto-GPT.\n\n**Please note that the use of the GPT-4 language model can be expensive due to its token usage.** By utilizing this project, you acknowledge that you are responsible for monitoring and managing your own token usage and the associated costs. It is highly recommended to check your OpenAI API usage regularly and set up any necessary limits or alerts to prevent unexpected charges.\n\nAs an autonomous experiment, Auto-GPT may generate content or take actions that are not in line with real-world business practices or legal requirements. It is your responsibility to ensure that any actions or decisions made based on the output of this software comply with all applicable laws, regulations, and ethical standards. The developers and contributors of this project shall not be held responsible for any consequences arising from the use of this software.\n\nBy using Auto-GPT, you agree to indemnify, defend, and hold harmless the developers, contributors, and any affiliated parties from and against any and all claims, damages, losses, liabilities, costs, and expenses (including reasonable attorneys' fees) arising from your use of this software or your violation of these terms.\n\n## ğŸ¦ Connect with Us on Twitter\n\nStay up-to-date with the latest news, updates, and insights about Auto-GPT by following our Twitter accounts. Engage with the developer and the AI's own account for interesting discussions, project updates, and more.\n\n- **Developer**: Follow [@siggravitas](https://twitter.com/siggravitas) for insights into the development process, project updates, and related topics from the creator of Entrepreneur-GPT.\n- **Entrepreneur-GPT**: Join the conversation with the AI itself by following [@En_GPT](https://twitter.com/En_GPT). Share your experiences, discuss the AI's outputs, and engage with the growing community of users.\n\nWe look forward to connecting with you and hearing your thoughts, ideas, and experiences with Auto-GPT. Join us on Twitter and let's explore the future of AI together!\n\n<p align=\"center\">\n  <a href=\"https://star-history.com/#Torantulino/auto-gpt&Date\">\n    <img src=\"https://api.star-history.com/svg?repos=Torantulino/auto-gpt&type=Date\" alt=\"Star History Chart\">\n  </a>\n</p>\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "gpt",
        "auto",
        "assistants",
        "gpt autonomously",
        "auto gpt",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "agree-able--room-mcp": {
      "owner": "agree-able",
      "name": "room-mcp",
      "url": "https://github.com/agree-able/room-mcp",
      "imageUrl": "https://github.com/agree-able.png",
      "description": "Connects and interacts with virtual rooms using the Room protocol, enabling agents to collaborate in a peer-to-peer environment for various tasks.",
      "stars": 16,
      "forks": 7,
      "license": "Apache License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-09-03T16:37:58Z",
      "readme_content": "# Room MCP\n\n[![smithery badge](https://smithery.ai/badge/@agree-able/room-mcp)](https://smithery.ai/server/@agree-able/room-mcp)\n\nA command-line tool for using MCP (Model Context Protocol) with the Room protocol.\n\nThis allows claude to create virutal rooms in a p2p space with other agents to accomplish a goal.\n\n<a href=\"https://glama.ai/mcp/servers/p6xyqb1e9e\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/p6xyqb1e9e/badge\" alt=\"Room MCP server\" />\n</a>\n\nHere is claude hosting a room, and giving out the invite code for the other party to join.\n\n<p align=\"center\">\n  <img width=\"600\" src=\"docs/create-room.png\">\n</p>\n\nHere is an example of connecting to a room for [20 Questions](https://github.com/agree-able/20-questions-bot)\n\n<p align=\"center\">\n  <img width=\"600\" src=\"docs/example.png\">\n</p>\n\nWe've also adding in directives to help the agent balance goals and risk in performing its task.\n\n<p align=\"center\">\n  <img width=\"600\" src=\"docs/directive.png\">\n</p>\n\nYou should check out the other [exciting examples](docs/examples.md)\n\n\n## Installation\n\n### Installing via Smithery\n\nTo install Room MCP for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@agree-able/room-mcp):\n\n```bash\nnpx -y @smithery/cli install @agree-able/room-mcp --client claude\n```\n\n### Manual Installation\nYou can use this tool directly with npm:\n\n```bash\nnpm -y @agree-able/room-mcp\n```\n## Adding to Claude Desktop\n\nSee https://modelcontextprotocol.io/quickstart/user for more details.\n\nAdd the following to your claude_desktop_config.json:\n\n```\n{\n  \"mcpServers\": {\n    \"room\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@agree-able/room-mcp\"\n      ],\n      \"env\": {\n        \"ROOM_TRANSCRIPTS_FOLDER\": \"/path/to/transcripts\" // Optional: Set to save room transcripts\n      }\n    }\n  }\n}\n```\n\n### Environment Variables\n\n- `ROOM_TRANSCRIPTS_FOLDER`: When set, conversation transcripts will be saved as JSON files in this folder when a room is exited. If the folder doesn't exist, it will be created automatically.\n\n## Available Tools\n\nThe Room MCP package provides the following capabilities:\n\n- **Room Protocol Integration**: Connect to and interact with rooms using the Room protocol\n- **MCP Support**: Utilize Model Context Protocol for enhanced model interactions\n- **Invitation Management**: Create and manage invitations using the @agree-able/invite package\n- **Transcript Storage**: Save conversation transcripts to disk when `ROOM_TRANSCRIPTS_FOLDER` environment variable is set\n\n## Related Packages\n\nThis tool depends on:\n\n- [@agree-able/invite](https://github.com/agree-able/invite): For invitation management\n- [@agree-able/room](https://github.com/agree-able/room): For Room protocol implementation\n- [@modelcontextprotocol/sdk](https://github.com/modelcontextprotocol/sdk): For MCP functionality\n\n## License\n\nApache License\nVersion 2.0\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "rooms",
        "room",
        "agents",
        "virtual rooms",
        "room protocol",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "alifakih1--discord-mcp": {
      "owner": "alifakih1",
      "name": "discord-mcp",
      "url": "https://github.com/alifakih1/discord-mcp",
      "imageUrl": "https://github.com/alifakih1.png",
      "description": "Integrate Discord bot functionalities with MCP-compatible applications to manage servers, channels, messages, reactions, categories, and webhooks. Utilize the Discord API capabilities in a standardized way to enhance application interactions.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-04-24T07:57:11Z",
      "readme_content": "<div align=\"center\">\n  <img src=\"assets/img/Discord_MCP_full_logo.svg\" width=\"60%\" alt=\"DeepSeek-V3\" />\n</div>\n<hr>\n<div align=\"center\" style=\"line-height: 1;\">\n    <a href=\"https://smithery.ai/server/@SaseQ/discord-mcp\" target=\"_blank\" style=\"margin: 2px;\">\n        <img alt=\"Smithery Badge\" src=\"https://camo.githubusercontent.com/ee5c6c6dc502821f4d57313b2885f7878af52be14142dd98526ea12aedf9b260/68747470733a2f2f736d6974686572792e61692f62616467652f40646d6f6e74676f6d65727934302f646565707365656b2d6d63702d736572766572\" data-canonical-src=\"https://smithery.ai/server/@SaseQ/discord-mcp\" style=\"display: inline-block; vertical-align: middle;\"/>\n    </a>\n    <a href=\"https://badge.mcpx.dev?type=server\" target=\"_blank\" style=\"margin: 2px;\">\n        <img alt=\"MCP Server\" src=\"https://badge.mcpx.dev?type=server\" style=\"display: inline-block; vertical-align: middle;\"/>\n    </a>\n    <a href=\"https://discord.gg/5Uvxe5jteM\" target=\"_blank\" style=\"margin: 2px;\">\n        <img alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-SaseQcode-7289da?logo=discord&logoColor=white&color=7289da\" style=\"display: inline-block; vertical-align: middle;\"/>\n    </a>\n</div>\n\n\n## ğŸ“– Description\n\nA [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) server for the Discord API [(JDA)](https://jda.wiki/), \nallowing seamless integration of Discord Bot with MCP-compatible applications like Claude Desktop.\n\n\n## ğŸ”¬ Installation\n\n#### Clone the repository\n```\ngit clone https://github.com/SaseQ/discord-mcp\n```\n\n#### Build the project\n```\ncd discord-mcp\nmvn clean package\n```\n\n#### Configure Claude Desktop\n```\n{\n  \"mcpServers\": {\n    \"discord-mcp\": {\n      \"command\": \"java\",\n      \"args\": [\n        \"-jar\",\n        \"/absolute/path/to/discord-mcp-0.0.1-SNAPSHOT.jar\"\n      ],\n      \"env\": {\n        \"DISCORD_TOKEN\": \"YOUR_DISCORD_BOT_TOKEN\"\n      }\n    }\n  }\n}\n```\n\n*To get a discord bot token, visit the [Discord Developer Portal](https://discord.com/developers)\n\n\n## âš“ Smithery\n\nInstall Discord MCP Server automatically via Smithery:\n```\nnpx -y @smithery/cli@latest install @SaseQ/discord-mcp --client claude\n```\n\n\n## ğŸ› ï¸ Available Tools\n\n#### Server Information\n - [`get_server_info`](): Get detailed discord server information\n\n#### Message Management\n - [`send_message`](): Send a message to a specific channel\n - [`edit_message`](): Edit a message from a specific channel\n - [`delete_message`](): Delete a message from a specific channel\n - [`read_messages`](): Read recent message history from a specific channel\n - [`send_private_message`](): Send a private message to a specific user\n - [`edit_private_message`](): Edit a private message from a specific user\n - [`delete_private_message`](): Delete a private message from a specific user\n - [`read_private_messages`](): Read recent message history from a specific user\n - [`add_reaction`](): Add a reaction (emoji) to a specific message\n - [`remove_reaction`](): Remove a specified reaction (emoji) from a message\n\n#### Channel Management\n - [`delete_channel`](): Delete a channel\n - [`find_channel`](): Find a channel type and ID using name and server ID\n - [`list_channels`](): List of all channels\n\n#### Category Management\n - [`create_category`](): Create a new category for channels\n - [`delete_category`](): Delete a category\n - [`find_category`](): Find a category ID using name and server ID\n - [`list_channels_in_category`](): List of channels in a specific category\n\n#### Webhook Management\n - [`create_webhook`](): Create a new webhook on a specific channel\n - [`delete_webhook`](): Delete a webhook\n - [`list_webhooks`](): List of webhooks on a specific channel\n - [`send_webhook_message`](): Send a message via webhook\n\n\n<hr>\n\nA more detailed examples can be found in the [Wiki](https://github.com/SaseQ/discord-mcp/wiki).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "discord",
        "webhooks",
        "mcp",
        "discord mcp",
        "discord api",
        "discord bot"
      ],
      "category": "virtual-assistants"
    },
    "andybrandt--mcp-simple-openai-assistant": {
      "owner": "andybrandt",
      "name": "mcp-simple-openai-assistant",
      "url": "https://github.com/andybrandt/mcp-simple-openai-assistant",
      "imageUrl": "https://github.com/andybrandt.png",
      "description": "Interact with OpenAI assistants using the Model Context Protocol, enabling the creation and management of assistant instances, starting conversation threads, and sending and receiving messages.",
      "stars": 36,
      "forks": 15,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-19T11:01:07Z",
      "readme_content": "# MCP Simple OpenAI Assistant\n\n*AI assistants are pretty cool. I thought it would be a good idea if my Claude (conscious Claude) would also have one. And now he has - and its both useful anf fun for him. Your Claude can have one too!*\n\nA simple MCP server for interacting with OpenAI assistants. This server allows other tools (like Claude Desktop) to create and interact with OpenAI assistants through the Model Context Protocol.\n\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/andybrandt/mcp-simple-openai-assistant)](https://archestra.ai/mcp-catalog/andybrandt__mcp-simple-openai-assistant)\n[![smithery badge](https://smithery.ai/badge/mcp-simple-openai-assistant)](https://smithery.ai/mcp/known/mcp-simple-openai-assistant)\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/andybrandt-mcp-simple-openai-assistant-badge.png)](https://mseep.ai/app/andybrandt-mcp-simple-openai-assistant)\n\n\n## Features\n\nThis server provides a suite of tools to manage and interact with OpenAI Assistants. The new streaming capabilities provide a much-improved, real-time user experience.\n\n### Available Tools\n\n-   **`create_assistant`**: (Create OpenAI Assistant) - Create a new assistant with a name, instructions, and model.\n-   **`list_assistants`**: (List OpenAI Assistants) - List all available assistants associated with your API key.\n-   **`retrieve_assistant`**: (Retrieve OpenAI Assistant) - Get detailed information about a specific assistant.\n-   **`update_assistant`**: (Update OpenAI Assistant) - Modify an existing assistant's name, instructions, or model.\n-   **`create_new_assistant_thread`**: (Create New Assistant Thread) - Creates a new, persistent conversation thread with a user-defined name and description for easy identification and reuse. This is the recommended way to start a new conversation.\n-   **`list_threads`**: (List Managed Threads) - Lists all locally managed conversation threads from the database, showing their ID, name, description, and last used time.\n-   **`delete_thread`**: (Delete Managed Thread) - Deletes a conversation thread from both OpenAI's servers and the local database.\n-   **`ask_assistant_in_thread`**: (Ask Assistant in Thread and Stream Response) - The primary tool for conversation. Sends a message to an assistant within a thread and streams the response back in real-time.\n\nBecause OpenAI assistants might take quite long to respond, this server uses a streaming approach for the main `ask_assistant_in_thread` tool. This provides real-time progress updates to the client and avoids timeouts.\n\nThe server now includes local persistence for threads, which is a significant improvement. Since the OpenAI API does not allow listing threads, this server now manages them for you by storing their IDs and metadata in a local SQLite database. This allows you to easily find, reuse, and manage your conversation threads across sessions.\n\n## Installation\n\n### Installing via Smithery\n\nTo install MCP Simple OpenAI Assistant for Claude Desktop automatically via [Smithery](https://smithery.ai/mcp/known/mcp-simple-openai-assistant):\n\n```bash\nnpx -y @smithery/cli install mcp-simple-openai-assistant --client claude\n```\n\n### Manual Installation\n```bash\npip install mcp-simple-openai-assistant\n```\n\n## Configuration\n\nThe server requires an OpenAI API key to be set in the environment. For Claude Desktop, add this to your config:\n\n(MacOS version)\n\n```json\n{\n  \"mcpServers\": {\n    \"openai-assistant\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"mcp_simple_openai_assistant\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\n(Windows version)\n\n```json\n\"mcpServers\": {\n  \"openai-assistant\": {\n    \"command\": \"C:\\\\Users\\\\YOUR_USERNAME\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe\",\n      \"args\": [\"-m\", \"mcp_simple_openai_assistant\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-api-key-here\"\n  }\n}\n\n```\n*MS Windows installation is slightly more complex, because you need to check the actual path to your Python executable. Path provided above is usually correct, but might differ in your setup. Sometimes just `python.exe` without any path will do the trick. Check with `cmd` what works for you (using `where python` might help). Also, on Windows you might need to explicitly tell Claude Desktop where the site packages are using PYTHONPATH environmment variable.*\n\n## Usage\n\nOnce configured, you can use the tools listed above to manage your assistants and conversations. The primary workflow is to:\n1. Use `create_new_assistant_thread` to start a new, named conversation.\n2. Use `list_threads` to find the ID of a thread you want to continue.\n3. Use `ask_assistant_in_thread` to interact with your chosen assistant in that thread.\n\n## TODO\n\n- [x] **Add Thread Management:** Introduce a way to name and persist thread IDs locally, allowing for easier reuse of conversations.\n- [ ] **Add Models Listing:** Introduce a way for the AI user to see what OpenAI models are available for use with the assistants\n- [ ] **Add Assistants Fine Tuning:** Enable the AI user to set detailed parameters for assistants like temperature, top_p etc. (indicated by Claude as needed)\n- [ ] **Full Thread History:** Ability to read past threads without having to send a new message (indicated by Claude as needed)\n- [ ] **Explore Resource Support:** Add the ability to upload files and use them with assistants.\n\n## Development\n\nTo install for development:\n\n```bash\ngit clone https://github.com/andybrandt/mcp-simple-openai-assistant\ncd mcp-simple-openai-assistant\npip install -e '.[dev]'\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "openai",
        "assistant",
        "assistants",
        "openai assistant",
        "openai assistants",
        "interact openai"
      ],
      "category": "virtual-assistants"
    },
    "arjunkmrm--mcp-minecraft": {
      "owner": "arjunkmrm",
      "name": "mcp-minecraft",
      "url": "https://github.com/arjunkmrm/mcp-minecraft",
      "imageUrl": "https://github.com/arjunkmrm.png",
      "description": "Integration with Minecraft enabling AI assistants to observe and interact with the Minecraft world through a bot. Supports interaction through the Model Context Protocol for enhanced functionality within the game.",
      "stars": 88,
      "forks": 8,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T01:20:49Z",
      "readme_content": "# Minecraft MCP Integration\n\nA Model Context Protocol (MCP) integration for Minecraft that enables AI assistants to interact with a Minecraft server. This integration allows AI models to observe and interact with the Minecraft world through a bot.\n\n![Screenshot](/public/screenshot.png?quality=medium)\n\n## Prerequisites\n\n1. Minecraft Launcher\n2. Node.js 18 or higher\n3. Claude Desktop App\n4. Java 21.0.5 (recommended)\n\n> âš ï¸ Note: Currently only tested on macOS/Linux. Windows compatibility is not guaranteed.\n\n## Important Note\n\n1. **Use the F3+P Shortcut**:\nPress F3 + P together. This toggles the \"Pause on Lost Focus\" feature. Once turned off, you can switch to claude desktop and Minecraft will continue running without pausing.\n\n![Focus Settings](/public/focus.png)\n\n2. **Connection Issues on Claude Restart**:\nIf you restart Claude while the Minecraft server is running, you may experience MCP connection issues on the next claude launch due to lingering java process. See [Troubleshooting: MCP Connection Failed](#common-issues) for resolution steps.\n\n## Installation Steps\n\n1. **Download and Setup Minecraft Server**\n   - Download Minecraft server v1.21 from [mcversions.net/1.21](https://mcversions.net/download/1.21)\n   - Install Java 21.0.5 if not already installed (other versions are untested)\n   - Create a dedicated directory (e.g., `~/minecraft-server/`)\n   - Place the downloaded `server.jar` file in this directory\n   - Note down the absolute path to your `server.jar` file\n\n2. **Install and Configure MCP Integration**\n   \n   Quick Install (Recommended):\n   ```bash\n   npx -y @smithery/cli install mcp-minecraft --client claude\n   ```\n   Follow the CLI prompts to complete the setup.\n\n   Or Manual Setup:\n   - Navigate to `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Add the MCP server configuration:   \n   ```json\n   {\n     \"mcpServers\": {\n       \"mcp-minecraft\": {\n         \"command\": \"npx\",\n         \"args\": [\n           \"-y\",\n           \"mcp-minecraft@latest\",\n           \"--server-jar\",\n           \"/absolute/path/to/minecraft-server/server.jar\"\n         ]\n       }\n     }\n   }   \n   ```\n   > âš ï¸ Replace `/absolute/path/to/minecraft-server/server.jar` with your actual server.jar path\n\n4. **Launch Claude Desktop**\n   - Start Claude Desktop after completing the configuration\n\n5. **Connect to Server**\n   - Open Minecraft Launcher\n   - Install and launch Minecraft Java Edition **v1.21**\n   - Click \"Play\" and Select \"Multiplayer\"\n   - Click \"Add Server\"\n   - Enter server details:\n     - Server Name: `Minecraft Server`\n     - Server Address: `localhost:25565`\n   - Click \"Done\"\n\n## Features\n\n### Resources\nThe integration exposes these MCP resources:\n\n- `minecraft://bot/location` - Current bot position in the world\n- `minecraft://bot/status` - Bot connection status\n\n### Tools\nAvailable MCP tools:\n\n- `chat` - Send chat messages to the server\n- `jump` - Make the bot jump\n- `moveForward` - Make the bot move forward\n- `moveBack` - Make the bot move backward\n- `turnLeft` - Make the bot turn left\n- `turnRight` - Make the bot turn right\n- `placeBlock` - Place a block at specified coordinates\n- `digBlock` - Break a block at specified coordinates\n- `getBlockInfo` - Get information about a block at specified coordinates\n- `selectSlot` - Select a hotbar slot (0-8)\n- `getInventory` - Get contents of bot's inventory\n- `equipItem` - Equip an item by name to specified destination\n- `getStatus` - Get bot's current status (health, food, position, etc.)\n- `getNearbyEntities` - Get list of nearby entities within range\n- `attack` - Attack a nearby entity by name\n- `useItem` - Use/activate the currently held item\n- `stopUsingItem` - Stop using/deactivate the current item\n- `lookAt` - Make the bot look at specific coordinates\n- `followPlayer` - Follow a specific player\n- `stopFollowing` - Stop following current target\n- `goToPosition` - Navigate to specific coordinates\n\n## Technical Details\n\n- Server runs in offline mode for local development\n- Default memory allocation: 2GB\n- Default port: 25565\n- Bot username: MCPBot\n\n## Troubleshooting\n\n### Common Issues\n\n1. **MCP Connection Failed**\n   - Look for lingering Java processes\n   - Terminate them manually:\n      - Windows: Use Task Manager (untested)\n      - Mac/Linux: \n         - Go to 'Activity Monitor' and 'Force Quit' java\n   - Restart computer if process termination fails\n   - Note: Latest version should auto-resolve these issues\n\n2. **Server Won't Start**\n   - Verify Java is installed\n   - Check server.jar path is correct\n   - Ensure port 25565 is available\n\n3. **Can't Connect to Server**\n   - Verify server is running (check logs)\n   - Confirm you're using \"localhost\" as server address\n   - Check firewall settings\n\n### Logs Location\n- Minecraft Server logs: Check the minecraft-server directory\n- Claude Desktop logs: `~/Library/Logs/Claude/mcp*.log`\n\n## Contributing\n\nContributions, big or small, are welcome!\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "minecraft",
        "interact",
        "ai",
        "interact minecraft",
        "minecraft integration",
        "mcp minecraft"
      ],
      "category": "virtual-assistants"
    },
    "aviz85--mcp-agents-orchestra": {
      "owner": "aviz85",
      "name": "mcp-agents-orchestra",
      "url": "https://github.com/aviz85/mcp-agents-orchestra",
      "imageUrl": "https://github.com/aviz85.png",
      "description": "Facilitates state-based orchestration to manage task planning, execution, and context maintenance through defined agent states. Integrates various resources, tools, and prompts to enhance workflows and knowledge management with LLMs.",
      "stars": 2,
      "forks": 2,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-07-18T14:30:18Z",
      "readme_content": "# MCP Agent Orchestration System\n\nA Python implementation of a state-based agent orchestration system using the Model Context Protocol (MCP).\n\n## What is MCP?\n\nThe Model Context Protocol (MCP) allows applications to provide context for LLMs in a standardized way, separating the concerns of providing context from the actual LLM interaction. With MCP, you can build servers that expose:\n\n- **Resources**: Data sources that provide information to LLMs\n- **Tools**: Functions that allow LLMs to perform actions\n- **Prompts**: Reusable templates for LLM interactions\n\n## Installation\n\n### Prerequisites\n\n- Python 3.10 or higher\n- MCP Python SDK 1.2.0 or higher\n\n### Setting Up Your Environment\n\n#### Using uv (recommended)\n\n```bash\n# Install uv\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Create a new directory for our project\nuv init mcp-agents-orchestra\ncd mcp-agents-orchestra\n\n# Create virtual environment and activate it\nuv venv\nsource .venv/bin/activate  # On Unix/macOS\n.venv\\Scripts\\activate     # On Windows\n\n# Install dependencies\nuv add \"mcp[cli]\" httpx\n```\n\n#### Using pip\n\n```bash\n# Create a new directory for our project\nmkdir mcp-agents-orchestra\ncd mcp-agents-orchestra\n\n# Create a virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Unix/macOS\nvenv\\Scripts\\activate     # On Windows\n\n# Install dependencies\npip install \"mcp[cli]\" httpx\n```\n\n### Clone or Download Project Files\n\nPlace the project files in your directory:\n\n- `orchestrator.py` - The main MCP server implementing the state machine\n- `orchestrator_client.py` - Client demonstrating the orchestration flow\n- `requirements.txt` - Dependencies for the project\n- `.gitignore` - Git ignore file\n\n## Project Structure\n\n- `orchestrator.py` - The main MCP server implementing the state machine\n- `orchestrator_client.py` - Client demonstrating the orchestration flow\n- `requirements.txt` - Dependencies for the project\n\n## Running the Orchestration System\n\n1. Start the orchestration server directly for testing:\n\n```bash\npython orchestrator.py\n```\n\n2. In a separate terminal, run the client to see the orchestration in action:\n\n```bash\npython orchestrator_client.py\n```\n\n## Integrating with Claude for Desktop\n\n### 1. Install Claude for Desktop\n\nMake sure you have Claude for Desktop installed. You can download the latest version from [Anthropic's website](https://claude.ai/desktop).\n\n### 2. Configure Claude for Desktop\n\n1. Open your Claude for Desktop configuration file:\n\n   **macOS/Linux:**\n   ```bash\n   # Create or edit the configuration file\n   code ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n   ```\n\n   **Windows:**\n   ```bash\n   # Path may vary depending on your Windows version\n   code %APPDATA%\\Claude\\claude_desktop_config.json\n   ```\n\n2. Add the orchestrator server configuration:\n\n   ```json\n   {\n       \"mcpServers\": {\n           \"agent-orchestrator\": {\n               \"command\": \"python\",\n               \"args\": [\n                   \"/ABSOLUTE/PATH/TO/YOUR/PROJECT/orchestrator.py\"\n               ]\n           }\n       }\n   }\n   ```\n\n   Replace the path with the absolute path to your orchestrator.py file.\n\n3. Save the configuration file and restart Claude for Desktop.\n\n### 3. Using the Orchestrator in Claude\n\nOnce configured, you can:\n\n1. Open Claude for Desktop\n2. Click on the MCP server icon in the sidebar\n3. Select \"agent-orchestrator\" from the list of available servers\n4. Start interacting with the orchestration system\n\nClaude will be able to:\n- Transition between different agent states\n- Store and retrieve information from the knowledge base\n- Maintain conversation context across state transitions\n- Access state-specific prompts\n\n## Agent States\n\nThe orchestration system implements a state machine with the following states:\n\n- **IDLE**: Waiting for instructions\n- **PLANNING**: Creating a structured plan for a task\n- **RESEARCHING**: Gathering information needed for a task\n- **EXECUTING**: Carrying out planned actions\n- **REVIEWING**: Evaluating results and determining next steps\n- **ERROR**: Handling errors or unexpected situations\n\n## Customizing the System\n\n### Adding New States\n\n1. Add the state to the `AgentState` enum in `orchestrator.py`\n2. Create a prompt function for the new state\n3. Update the transition logic in `_get_available_transitions()`\n4. Add handlers for the new state in resource access functions\n\n### Creating Custom Tools\n\nAdd new tools by creating functions decorated with `@mcp.tool()`:\n\n```python\n@mcp.tool()\ndef my_custom_tool(arg1: str, arg2: int, ctx: Context) -> str:\n    \"\"\"Description of what this tool does\n    \n    Args:\n        arg1: Description of arg1\n        arg2: Description of arg2\n    \"\"\"\n    # Implementation here\n    return \"Result\"\n```\n\n## Development and Testing\n\n### Using the MCP CLI\n\nThe MCP CLI provides tools for development and testing:\n\n```bash\n# Install MCP CLI if you haven't already\npip install \"mcp[cli]\"\n\n# Test your server with the MCP Inspector\nmcp dev orchestrator.py\n\n# Install in Claude Desktop\nmcp install orchestrator.py\n```\n\n### Manual Testing with Python\n\n```python\nfrom mcp import ClientSession, StdioServerParameters\nfrom mcp.client.stdio import stdio_client\n\nasync with stdio_client(StdioServerParameters(command=\"python\", args=[\"orchestrator.py\"])) as (read, write):\n    async with ClientSession(read, write) as session:\n        await session.initialize()\n        # Test state transitions\n        await session.call_tool(\"transition_state\", arguments={\"new_state\": \"PLANNING\"})\n```\n\n## Resources\n\n- [MCP Python SDK Documentation](https://github.com/anthropics/anthropic-mcp)\n- [Model Context Protocol Specification](https://github.com/anthropics/anthropic-mcp/blob/main/README.md)\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details. ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "agents",
        "agent",
        "orchestration",
        "virtual assistants",
        "agents orchestra",
        "mcp agents"
      ],
      "category": "virtual-assistants"
    },
    "baryhuang--mcp-remote-macos-use": {
      "owner": "baryhuang",
      "name": "mcp-remote-macos-use",
      "url": "https://github.com/baryhuang/mcp-remote-macos-use",
      "imageUrl": "https://github.com/baryhuang.png",
      "description": "Enables complete control over remote macOS systems with native environment integration and no additional software requirements. Optimized for autonomous AI agents to operate seamlessly on the desktop.",
      "stars": 392,
      "forks": 48,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T17:48:51Z",
      "readme_content": "# MCP Server - Remote MacOs Use\n**The first open-source MCP server that enables AI to fully control remote macOS systems.**\n\n**A direct alternative to OpenAI Operator, optimized specifically for autonomous AI agents with complete desktop capabilities, requiring no additional software installation.**\n\n[![Docker Pulls](https://img.shields.io/docker/pulls/buryhuang/mcp-remote-macos-use)](https://hub.docker.com/r/buryhuang/mcp-remote-macos-use)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n**Showcases**\n- Research Twitter and Post Twitter(https://www.youtube.com/watch?v=--QHz2jcvcs)\n<img width=\"400\" alt=\"image\" src=\"https://github.com/user-attachments/assets/bfe6e354-3d59-4d08-855b-2eecdaaeb46f\" />\n\n- Use CapCut to create short highlight video(https://www.youtube.com/watch?v=RKAqiNoU8ec)\n<img width=\"400\" alt=\"image\" src=\"https://github.com/user-attachments/assets/3b4d07c5-cd25-4dae-b9a1-a373bf7492aa\" />\n\n- AI Recruiter: Automated candidate information collection, qualifying applications and sending screening sessions using Mail App\n- AI Marketing Intern: LinkedIn engagement - automated following, liking, and commenting with relevant users\n- AI Marketing Intern: Twitter engagement - automated following, liking, and commenting with relevant users\n\n## To-Do List (Prioritized)\n\n1. **Performance Optimization** - Match speed of Ubuntu desktop alternatives\n2. **Apple Scripts Generation** - Reduce execution time while maintaining flexibility\n3. **VNC Cursor Visibility** - Improve debugging and demo experience\n\n*We welcome contributions!*\n\n## Features\n\n* **No Extra API Costs**: Free screen processing with your existing Claude Pro plan\n* **Minimal Setup**: Just enable Screen Sharing on the target Mac â€“ no additional software needed\n* **Universal Compatibility**: Works with all macOS versions, current and future\n  \n## Why We Built This\n\n### Native macOS Experience Without Compromise\nThe macOS native ecosystem remains unmatched in user experience today and will continue to be the gold standard for years to come. This is where human capabilities truly thrive, and now your AI can operate in this environment with the same fluency.\n\n### Open Architecture By Design\n* **Universal LLM Compatibility**: Work with any MCP Client of your choice\n* **Model Flexibility**: Seamlessly integrate with OpenAI, Anthropic, or any other LLM provider\n* **Future-Proof Integration**: Designed to evolve with the MCP ecosystem\n\n### Effortless Deployment\n* **Zero Setup on Target Machines**: No background applications or agents needed on macOS\n* **Screen Sharing is All You Need**: Control any Mac with Screen Sharing enabled\n* **Eliminate Backend Complexity**: Unlike other solutions that require running Python applications or background services\n\n### Streamlined Bootstrap Process\n* **Leverage Claude Desktop's Polished UI**: No need for developer-style Python interfaces\n* **Intuitive User Experience**: Interact with your AI-controlled Mac through a familiar, user-friendly interface\n* **Instant Productivity**: Start working immediately without configuration hassles\n\n## Architecture\n<img width=\"912\" alt=\"remote_macos_use_system_architecture\" src=\"https://github.com/user-attachments/assets/75ece060-90e2-4ad3-bb52-2c69427001dd\" />\n\n\n## Installation\n- [Enable Screen Sharing on MacOs](https://support.apple.com/guide/remote-desktop/set-up-a-computer-running-vnc-software-apdbed09830/mac) **If you rent a mac from macstadium.com, you can skip this step**\n- [Connect to your remote MacOs](https://support.apple.com/guide/mac-help/share-the-screen-of-another-mac-mh14066/mac)\n- [Install Docker Desktop for local Mac](https://docs.docker.com/desktop/setup/install/mac-install/)\n- [Add this MCP server to Claude Desktop](https://modelcontextprotocol.io/quickstart/user)\nYou can configure Claude Desktop to use the Docker image by adding the following to your Claude configuration:\n```json\n{\n  \"mcpServers\": {\n    \"remote-macos-use\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"-e\",\n        \"MACOS_USERNAME=your_macos_username\",\n        \"-e\",\n        \"MACOS_PASSWORD=your_macos_password\",\n        \"-e\",\n        \"MACOS_HOST=your_macos_hostname_or_ip\",\n        \"--rm\",\n        \"buryhuang/mcp-remote-macos-use:latest\"\n      ]\n    }\n  }\n}\n```\n\n### WebRTC Support via LiveKit\n\nThis server now includes WebRTC support through LiveKit integration, enabling:\n- Low-latency real-time screen sharing\n- Improved performance and responsiveness\n- Better network efficiency compared to traditional VNC\n- Automatic quality adaptation based on network conditions\n\nTo use WebRTC features, you'll need to:\n1. Set up a LiveKit server or use LiveKit Cloud\n2. Configure the LiveKit environment variables as shown in the configuration example above\n\n## Developer Instruction\n### Clone the repo\n```bash\n# Clone the repository\ngit clone https://github.com/yourusername/mcp-remote-macos-use.git\ncd mcp-remote-macos-use\n```\n\n### Building the Docker Image\n\n```bash\n# Build the Docker image\ndocker build -t mcp-remote-macos-use .\n```\n\n## Cross-Platform Publishing\n\nTo publish the Docker image for multiple platforms, you can use the `docker buildx` command. Follow these steps:\n\n1. **Create a new builder instance** (if you haven't already):\n   ```bash\n   docker buildx create --use\n   ```\n\n2. **Build and push the image for multiple platforms**:\n   ```bash\n   docker buildx build --platform linux/amd64,linux/arm64 -t buryhuang/mcp-remote-macos-use:latest --push .\n   ```\n\n3. **Verify the image is available for the specified platforms**:\n   ```bash\n   docker buildx imagetools inspect buryhuang/mcp-remote-macos-use:latest\n   ```\n\n## Usage\n\nThe server provides Remote MacOs functionality through MCP tools.\n\n### Tools Specifications\n\nThe server provides the following tools for remote macOS control:\n\n#### remote_macos_get_screen\nConnect to a remote macOS machine and get a screenshot of the remote desktop. Uses environment variables for connection details.\n\n#### remote_macos_send_keys\nSend keyboard input to a remote macOS machine. Uses environment variables for connection details.\n\n#### remote_macos_mouse_move\nMove the mouse cursor to specified coordinates on a remote macOS machine, with automatic coordinate scaling. Uses environment variables for connection details.\n\n#### remote_macos_mouse_click\nPerform a mouse click at specified coordinates on a remote macOS machine, with automatic coordinate scaling. Uses environment variables for connection details.\n\n#### remote_macos_mouse_double_click\nPerform a mouse double-click at specified coordinates on a remote macOS machine, with automatic coordinate scaling. Uses environment variables for connection details.\n\n#### remote_macos_mouse_scroll\nPerform a mouse scroll at specified coordinates on a remote macOS machine, with automatic coordinate scaling. Uses environment variables for connection details.\n\n#### remote_macos_open_application\nOpens/activates an application and returns its PID for further interactions.\n\n#### remote_macos_mouse_drag_n_drop\nPerform a mouse drag operation from start point and drop to end point on a remote macOS machine, with automatic coordinate scaling.\n\nAll tools use the environment variables configured during setup instead of requiring connection parameters.\n\n## Limitations\n\n- **Authentication Support**: \n  - Only Apple Authentication (protocol 30) is supported\n\n## Security Note\n\nhttps://support.apple.com/guide/remote-desktop/encrypt-network-data-apdfe8e386b/mac\nhttps://cafbit.com/post/apple_remote_desktop_quirks/\n\nWe only support protocol 30, which uses the Diffie-Hellman key agreement protocol with a 512-bit prime. This protocol is used by macOS 11 to macOS 12 when communicating with OS X 10.11 or earlier clients.\n\nHere's the information converted to a markdown table:\n\n| macOS version running Remote Desktop | macOS client version | Authentication | Control and Observe | Copy items or install package | All other tasks | Protocol Version |\n|--------------------------------------|----------------------|----------------|---------------------|-------------------------------|----------------|----------------|\n| macOS 13 | macOS 13 | 2048-bit RSA host keys | 2048-bit RSA host keys | 2048-bit RSA host keys to authenticate, then 128-bit AES | 2048-bit RSA host keys | 36 |\n| macOS 13 | macOS 10.12 | Secure Remote Password (SRP) protocol for local only. Diffie-Hellman (DH) if bound to LDAP or macOS server is version 10.11 or earlier | SRP or DH,128-bit AES | SRP or DH to authenticate, then 128-bit AES | 2048-bit RSA host keys | 35 |\n| macOS 11 to macOS 12 | macOS 10.12 to macOS 13 | Secure Remote Password (SRP) protocol for local only, Diffie-Hellman if bound to LDAP | SRP or DH 1024-bit, 128-bit AES | 2048-bit RSA host keys macOS 13 to macOS 10.13 | 2048-bit RSA host keys macOS 10.13 or later |  33 |\n| macOS 11 to macOS 12 | OS X 10.11 or earlier | DH 1024-bit | DH 1024-bit, 128-bit AES | Diffie-Hellman Key agreement protocol with a 512-bit prime | Diffie-Hellman Key agreement protocol with a 512-bit prime |  30 |\n\n\nAlways use secure, authenticated connections when accessing remote remote MacOs machines. This tool should only be used with servers you trust and have permission to access.\n\n## License\n\nSee the LICENSE file for details. \n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "macos",
        "ai",
        "assistants",
        "remote macos",
        "virtual assistants",
        "mcp remote"
      ],
      "category": "virtual-assistants"
    },
    "chaindead--telegram-mcp": {
      "owner": "chaindead",
      "name": "telegram-mcp",
      "url": "https://github.com/chaindead/telegram-mcp",
      "imageUrl": "https://github.com/chaindead.png",
      "description": "Connects AI assistants to the Telegram API for seamless interaction. Enables retrieval of user data, management of dialogs, and interaction with messages.",
      "stars": 216,
      "forks": 24,
      "license": "MIT License",
      "language": "Go",
      "updated_at": "2025-10-03T21:17:26Z",
      "readme_content": "[![](https://badge.mcpx.dev?type=server 'MCP Server')](https://github.com/punkpeye/awesome-mcp-servers?tab=readme-ov-file#communication)\n[![](https://img.shields.io/badge/OS_Agnostic-Works_Everywhere-purple)](https://github.com/chaindead/telegram-mcp?tab=readme-ov-file#installation)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fchaindead%2Ftelegram-mcp&label=Visitors&labelColor=%23d9e3f0&countColor=%23697689&style=flat&labelStyle=none)](https://visitorbadge.io/status?path=https%3A%2F%2Fgithub.com%2Fchaindead%2Ftelegram-mcp)\n\n# Telegram MCP server\n\nThe server is a bridge between the Telegram API and the AI assistants and is based on the [Model Context Protocol](https://modelcontextprotocol.io).\n\n> [!IMPORTANT]\n> Ensure that you have read and understood the [Telegram API Terms of Service](https://core.telegram.org/api/terms) before using this server.\n> Any misuse of the Telegram API may result in the suspension of your account.\n\n## Table of Contents\n- [What is MCP?](#what-is-mcp)\n- [What does this server do?](#what-does-this-server-do)\n  - [Capabilities](#capabilities)\n  - [Prompt examples](#prompt-examples)\n    - [Message Management](#message-management)\n    - [Organization](#organization)\n    - [Communication](#communication)\n- [Installation](#installation)\n  - [Homebrew](#homebrew)\n  - [NPX](#npx)\n  - [From Releases](#from-releases)\n    - [MacOS](#macos)\n    - [Linux](#linux)\n    - [Windows](#windows)\n  - [From Source](#from-source)\n- [Configuration](#configuration)\n  - [Authorization](#authorization)\n  - [Client Configuration](#client-configuration)\n- [Star History](#star-history)\n\n## What is MCP?\n\nThe Model Context Protocol (MCP) is a system that lets AI apps, like Claude Desktop or Cursor, connect to external tools and data sources. It gives a clear and safe way for AI assistants to work with local services and APIs while keeping the user in control.\n\n## What does this server do?\n\n### Capabilities\n\n- [x] Get current account information (`tool: tg_me`)\n- [x] List dialogs with optional unread filter (`tool: tg_dialogs`)\n- [x] Mark dialog as read (`tool: tg_read`)\n- [x] Retrieve messages from specific dialog (`tool: tg_dialog`)\n- [x] Send draft messages to any dialog (`tool: tg_send`)\n\n### Prompt examples\n\nHere are some example prompts you can use with AI assistants:\n\n#### Message Management\n- \"Check for any unread important messages in my Telegram\"\n- \"Summarize all my unread Telegram messages\"\n- \"Read and analyze my unread messages, prepare draft responses where needed\"\n- \"Check non-critical unread messages and give me a brief overview\"\n\n#### Organization\n- \"Analyze my Telegram dialogs and suggest a folder structure\"\n- \"Help me categorize my Telegram chats by importance\"\n- \"Find all work-related conversations and suggest how to organize them\"\n\n#### Communication\n- \"Monitor specific chat for updates about [topic]\"\n- \"Draft a polite response to the last message in [chat]\"\n- \"Check if there are any unanswered questions in my chats\"\n\n## Installation\n\n### Homebrew\n\nYou can install a binary release on macOS/Linux using brew:\n\n```bash\n# Install\nbrew install chaindead/tap/telegram-mcp\n\n# Update\nbrew upgrade chaindead/tap/telegram-mcp\n```\n\n### NPX\n\nYou can run the latest version directly using npx (supports macOS, Linux, and Windows):\n\n```bash\nnpx -y @chaindead/telegram-mcp\n```\n\nWhen using NPX, modify the standard commands and configuration as follows:\n\n- [Authentication command](#authorization) becomes:\n```bash\nnpx -y @chaindead/telegram-mcp auth ...\n```\n\n- [Claude MCP server configuration](#client-configuration) becomes:\n```json\n{\n  \"mcpServers\": {\n    \"telegram\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@chaindead/telegram-mcp\"],\n      \"env\": {\n        \"TG_APP_ID\": \"<your-api-id>\",\n        \"TG_API_HASH\": \"<your-api-hash>\"\n      }\n    }\n  }\n}\n```\n\nFor complete setup instructions, see [Authorization](#authorization) and [Client Configuration](#client-configuration).\n\n### From Releases\n\n#### MacOS\n\n<details>\n\n> **Note:** The commands below install to `/usr/local/bin`. To install elsewhere, replace `/usr/local/bin` with your preferred directory in your PATH.\n\nFirst, download the archive for your architecture:\n\n```bash\n# For Intel Mac (x86_64)\ncurl -L -o telegram-mcp.tar.gz https://github.com/chaindead/telegram-mcp/releases/latest/download/telegram-mcp_Darwin_x86_64.tar.gz\n\n# For Apple Silicon (M1/M2)\ncurl -L -o telegram-mcp.tar.gz https://github.com/chaindead/telegram-mcp/releases/latest/download/telegram-mcp_Darwin_arm64.tar.gz\n```\n\nThen install the binary:\n\n```bash\n# Extract the binary\nsudo tar xzf telegram-mcp.tar.gz -C /usr/local/bin\n\n# Make it executable\nsudo chmod +x /usr/local/bin/telegram-mcp\n\n# Clean up\nrm telegram-mcp.tar.gz\n```\n</details>\n\n#### Linux\n<details>\n\n> **Note:** The commands below install to `/usr/local/bin`. To install elsewhere, replace `/usr/local/bin` with your preferred directory in your PATH.\n\nFirst, download the archive for your architecture:\n\n```bash\n# For x86_64 (64-bit)\ncurl -L -o telegram-mcp.tar.gz https://github.com/chaindead/telegram-mcp/releases/latest/download/telegram-mcp_Linux_x86_64.tar.gz\n\n# For ARM64\ncurl -L -o telegram-mcp.tar.gz https://github.com/chaindead/telegram-mcp/releases/latest/download/telegram-mcp_Linux_arm64.tar.gz\n```\n\nThen install the binary:\n\n```bash\n# Extract the binary\nsudo tar xzf telegram-mcp.tar.gz -C /usr/local/bin\n\n# Make it executable\nsudo chmod +x /usr/local/bin/telegram-mcp\n\n# Clean up\nrm telegram-mcp.tar.gz\n```\n</details>\n\n#### Windows\n\n<details>\n\n#### Windows\n1. Download the latest release for your architecture:\n   - [Windows x64](https://github.com/chaindead/telegram-mcp/releases/latest/download/telegram-mcp_Windows_x86_64.zip)\n   - [Windows ARM64](https://github.com/chaindead/telegram-mcp/releases/latest/download/telegram-mcp_Windows_arm64.zip)\n2. Extract the `.zip` file\n3. Add the extracted directory to your PATH or move `telegram-mcp.exe` to a directory in your PATH\n</details>\n\n### From Source\n\nRequirements:\n- Go 1.24 or later\n- GOBIN in PATH\n\n```bash\ngo install github.com/chaindead/telegram-mcp@latest\n```\n\n## Configuration\n\n### Authorization\n\nBefore you can use the server, you need to connect to the Telegram API.\n\n1. Get the API ID and hash from [Telegram API](https://my.telegram.org/auth)\n2. Run the following command:\n   > __Note:__\n   > If you have 2FA enabled: add --password <2fa_password>\n\n   >  __Note:__\n   > If you want to override existing session: add --new\n\n   ```bash\n   telegram-mcp auth --app-id <your-api-id> --api-hash <your-api-hash> --phone <your-phone-number>\n   ```\n\n   ğŸ“© Enter the code you received from Telegram to connect to the API.\n\n3. Done! Please give this project a â­ï¸ to support its development.\n\n### Client Configuration\n\nExample of Configuring Claude Desktop to recognize the Telegram MCP server.\n\n1. Open the Claude Desktop configuration file:\n    - in MacOS, the configuration file is located at `~/Library/Application Support/Claude/claude_desktop_config.json`\n    - in Windows, the configuration file is located at `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n   > __Note:__\n   > You can also find claude_desktop_config.json inside the settings of Claude Desktop app\n\n2. Add the server configuration\n   \n   for Claude desktop:\n   ```json\n    {\n      \"mcpServers\": {\n        \"telegram\": {\n          \"command\": \"telegram-mcp\",\n          \"env\": {\n            \"TG_APP_ID\": \"<your-app-id>\",\n            \"TG_API_HASH\": \"<your-api-hash>\",\n            \"PATH\": \"<path_to_telegram-mcp_binary_dir>\",\n            \"HOME\": \"<path_to_your_home_directory\"\n          }\n        }\n      }\n    }\n   ```\n\n   for Cursor:\n    ```json\n    {\n      \"mcpServers\": {\n        \"telegram-mcp\": {\n          \"command\": \"telegram-mcp\",\n          \"env\": {\n            \"TG_APP_ID\": \"<your-app-id>\",\n            \"TG_API_HASH\": \"<your-api-hash>\"\n          }\n        }\n      }\n    }\n    ```\n\n## Star History\n\n<a href=\"https://www.star-history.com/#chaindead/telegram-mcp&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=chaindead/telegram-mcp&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=chaindead/telegram-mcp&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=chaindead/telegram-mcp&type=Date\" />\n </picture>\n</a>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "telegram",
        "messages",
        "dialogs",
        "assistants telegram",
        "telegram mcp",
        "telegram api"
      ],
      "category": "virtual-assistants"
    },
    "devizor--macOS-Notification-MCP": {
      "owner": "devizor",
      "name": "macOS-Notification-MCP",
      "url": "https://github.com/devizor/macOS-Notification-MCP",
      "imageUrl": "https://github.com/devizor.png",
      "description": "Triggers native macOS notifications, plays system sounds, and converts text to speech. Supports customizable visual notifications and voice management features for AI assistants.",
      "stars": 26,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-26T11:51:16Z",
      "readme_content": "# ğŸ”” macOS Notification MCP\n\nA Model Context Protocol (MCP) server that enables AI assistants to trigger macOS notifications, sounds, and text-to-speech.\n\n## âœ¨ Features\n\n- ğŸ”Š **Sound Notifications**: Play system sounds like Submarine, Ping, or Tink\n- ğŸ’¬ **Banner Notifications**: Display visual notifications with customizable title, message, and subtitle\n- ğŸ—£ï¸ **Speech Notifications**: Convert text to speech with adjustable voice, rate, and volume\n- ğŸ™ï¸ **Voice Management**: List and select from available system voices\n- ğŸ§ª **Testing Tools**: Diagnostic utilities to verify all notification methods\n\n## ğŸš€ Quick Start with uvx (Recommended)\n\nThe fastest way to use this tool is with `uvx`, which runs packages without permanent installation:\n\n```bash\n# Install uv if you don't have it\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Run the MCP server directly (no installation needed)\nuvx macos-notification-mcp\n```\n\n## âš™ï¸ Configure Claude Desktop\n\nAdd this to your Claude Desktop configuration (`~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"macos-notification-mcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\"macos-notification-mcp\"]\n    }\n  }\n}\n```\n\nThen restart Claude Desktop.\n\n## ğŸ“¦ Alternative Installation Methods\n\nStandard installation:\n\n```bash\npip install macos-notification-mcp\n```\n\nInstall from source:\n\n```bash\ngit clone https://github.com/devizor/macos-notification-mcp\ncd macos-notification-mcp\npip install .\n```\n\n## ğŸ› ï¸ Available Notification Tools\n\n### ğŸ”Š Sound Notification\n```python\nsound_notification(sound_name=\"Submarine\")\n```\nAvailable sounds: Basso, Blow, Bottle, Frog, Funk, Glass, Hero, Morse, Ping, Pop, Purr, Sosumi, Submarine, Tink\n\n### ğŸ’¬ Banner Notification\n```python\nbanner_notification(\n    title=\"Task Complete\",\n    message=\"Your analysis is ready\",\n    subtitle=None,  # Optional\n    sound=False,    # Optional: Play sound with notification\n    sound_name=None # Optional: Specify system sound\n)\n```\n\n### ğŸ—£ï¸ Speech Notification\n```python\nspeak_notification(\n    text=\"The process has completed\",\n    voice=None,     # Optional: System voice to use\n    rate=150,       # Optional: Words per minute (default: 150)\n    volume=1.0      # Optional: Volume level 0.0-1.0\n)\n```\n\n### ğŸ™ï¸ Voice Management\n```python\nlist_available_voices()  # Lists all available text-to-speech voices\n```\n\n### ğŸ§ª Testing\n```python\ntest_notification_system()  # Tests all notification methods\n```\n\n## ğŸ”’ Implementation Details\n\n- â±ï¸ **Rate Limiting**: Notifications are processed one at a time with a minimum interval of 0.5 seconds\n- ğŸ”„ **Queuing**: Multiple notification requests are handled sequentially\n- ğŸªŸ **OS Integration**: Uses native macOS commands (`afplay`, `osascript`, `say`)\n- ğŸ”Œ **FastMCP**: Built on the FastMCP framework for AI communication\n\n## âš ï¸ Troubleshooting\n\n- ğŸ” **Permissions**: Ensure notifications are allowed in System Settings â†’ Notifications\n- â³ **Timing**: Only one notification is processed at a time\n- ğŸŒ **Environment**: If using the command directly (not uvx), you may need to use full paths\n\n## ğŸ“„ License\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "notifications",
        "macos",
        "notification",
        "macos notifications",
        "macos notification",
        "notifications voice"
      ],
      "category": "virtual-assistants"
    },
    "dryeab--mcp-telegram": {
      "owner": "dryeab",
      "name": "mcp-telegram",
      "url": "https://github.com/dryeab/mcp-telegram",
      "imageUrl": "https://github.com/dryeab.png",
      "description": "Connects Large Language Models to Telegram for sending, editing, and managing messages. Facilitates automation of messaging, searching, and media handling within the Telegram platform.",
      "stars": 162,
      "forks": 20,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-04T01:30:43Z",
      "readme_content": "<div align=\"center\">\n  <img src=\"logo.png\" alt=\"MCP Telegram Logo\" width=\"150\"/>\n  <h2 style=\"margin-top: 0\">Enable LLMs to control your Telegram</h2>\n</div>\n\n<div align=\"center\">\n    <a href=\"https://github.com/dryeab/mcp-telegram/stargazers\"><img src=\"https://img.shields.io/github/stars/dryeab/mcp-telegram?style=social\" alt=\"GitHub stars\"></a>\n    <a href=\"https://badge.fury.io/py/mcp-telegram\"><img src=\"https://badge.fury.io/py/mcp-telegram.svg\" alt=\"PyPI version\"></a>\n    <a href=\"https://x.com/dryeab\"><img src=\"https://img.shields.io/twitter/follow/dryeab?style=social\" alt=\"Twitter Follow\"></a>\n</div>\n<h3></h3>\n\n**Connect Large Language Models to Telegram via the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction).**\n\nBuilt with [Telethon](https://github.com/LonamiWebs/Telethon), this server allows AI agents to interact with Telegram, enabling features like sending/editing/deleting messages, searching chats, managing drafts, downloading media, and more using the [MTProto](https://core.telegram.org/mtproto).\n\n---\n<details>\n<summary><strong>Table&nbsp;of&nbsp;Contents</strong></summary>\n\n- [ğŸš€ Getting Started](#-getting-started)\n  - [Prerequisites](#prerequisites)\n  - [Installation](#installation)\n- [âš™ï¸ Usage](#ï¸-usage)\n  - [Login](#login)\n  - [Connect to the MCP server](#connect-to-the-mcp-server)\n- [ğŸ§° Available Tools](#-available-tools)\n  - [ğŸ“¨ Messaging Tools](#-messaging-tools)\n  - [ğŸ” Search & Navigation](#-search--navigation)\n  - [ğŸ“ Draft Management](#-draft-management)\n  - [ğŸ“‚ Media Handling](#-media-handling)\n- [ğŸ› ï¸ Troubleshooting](#ï¸-troubleshooting)\n- [ğŸ¤ Contributing](#-contributing)\n- [ğŸ“ License](#-license)\n\n</details>\n\n---\n\n\n## ğŸš€ Getting Started\n\n### Prerequisites\n\n- Python 3.10 or higher\n- [`uv`](https://github.com/astral-sh/uv) Install via the [official uv guide](https://github.com/astral-sh/uv#installation).\n\n### Installation\n\nInstall the `mcp-telegram` CLI tool:\n\n```bash\nuv tool install mcp-telegram\n```\n\n## âš™ï¸ Usage\n\n> [!IMPORTANT]\n> Please ensure you have read and understood Telegram's [ToS](https://telegram.org/tos) before using this tool. Misuse of this tool may result in account restrictions.\n\nThe `mcp-telegram` command-line tool is your entry point.\n\n```bash\nmcp-telegram --help # See all commands\n```\n\n### Login\n\nFirst, authenticate with your Telegram account:\n\n```bash\nmcp-telegram login\n```\n\nThis interactive command will prompt you for:\n\n- **API ID & API Hash:** Obtain these from [my.telegram.org/apps](https://my.telegram.org/apps).\n- **Phone Number:** Your Telegram-registered phone number (international format, e.g., `+1234567890`).\n- **Verification Code:** Sent to your Telegram account upon first login.\n- **2FA Password:** If you have Two-Factor Authentication enabled.\n\nYour credentials are securely stored in the session file for future use.\n\n> [!WARNING]\n> Keep your API credentials private and never share them publicly\n\n> [!NOTE]\n> Use `mcp-telegram logout` to logout from current session or `mcp-telegram clear-session` to remove all stored session data.\n\n### Connect to the MCP server\n\nTo use MCP Telegram with MCP clients like Claude Desktop or Cursor, you'll need to configure the MCP server. The configuration process varies by client and operating system.\n\nFor detailed setup instructions, please refer to:\n\n- [Claude Desktop MCP Setup Guide](https://modelcontextprotocol.io/quickstart/user)\n- [Cursor MCP Documentation](https://docs.cursor.com/context/model-context-protocol)\n\nThe configuration file should contain:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-telegram\": {\n      \"command\": \"mcp-telegram\" /* Use full path if client can't find the command (e.g. \"/usr/local/bin/mcp-telegram\"). See IMPORTANT section below for full path instructions. */,\n      \"args\": [\"start\"],\n      \"env\": {\n        \"API_ID\": \"<your_api_id>\",\n        \"API_HASH\": \"<your_api_hash>\"\n      }\n    }\n  }\n}\n```\n\n> [!Note]\n> Configuration paths vary by OS and client. For example:\n>\n> - macOS: `~/Library/Application Support/Claude/` or `~/.cursor/`\n> - Windows: `%APPDATA%\\Claude\\` or `%APPDATA%\\Cursor\\`\n\n> [!IMPORTANT]\n> If your client cannot execute `mcp-telegram` despite it being accessible in the terminal, try using the full path to the executable. You can find this by running `which mcp-telegram` (macOS/Linux) or `where mcp-telegram` (Windows) in your terminal. Replace the `command` value in the configuration with the full path.\n\nAfter saving the configuration file, restart your application.\n\n## ğŸ§° Available Tools\n\nHere's a comprehensive list of tools you can use to interact with Telegram through MCP:\n\n### ğŸ“¨ Messaging Tools\n\n| Tool             | Description                                                   |\n| ---------------- | ------------------------------------------------------------- |\n| `send_message`   | âœ‰ï¸ Send text messages or files to any user, group, or channel |\n| `edit_message`   | âœï¸ Modify content of previously sent messages                 |\n| `delete_message` | ğŸ—‘ï¸ Remove one or multiple messages                            |\n| `get_messages`   | ğŸ“œ Retrieve message history with advanced filtering options   |\n\n### ğŸ” Search & Navigation\n\n| Tool                | Description                                             |\n| ------------------- | ------------------------------------------------------- |\n| `search_dialogs`    | ğŸ” Find users, groups, and channels by name or username |\n| `message_from_link` | ğŸ”— Access specific messages using Telegram links        |\n\n### ğŸ“ Draft Management\n\n| Tool        | Description                                |\n| ----------- | ------------------------------------------ |\n| `get_draft` | ğŸ“‹ View current message draft for any chat |\n| `set_draft` | âœï¸ Create or clear message drafts          |\n\n### ğŸ“‚ Media Handling\n\n| Tool             | Description                                             |\n| ---------------- | ------------------------------------------------------- |\n| `media_download` | ğŸ“¸ Download photos, videos, and documents from messages |\n\n> [!Note]\n> For detailed parameter information and example use cases, run `mcp-telegram tools` in your terminal.\n\n## ğŸ› ï¸ Troubleshooting\n\n### Database Locked Errors\n\nRunning multiple `mcp-telegram` instances using the _same session file_ can cause `database is locked` errors due to Telethon's SQLite session storage. Ensure only one instance uses a session file at a time.\n\n<details>\n<summary>Force-Stopping Existing Processes</summary>\n\nIf you need to stop potentially stuck processes:\n\n- **macOS / Linux:** `pkill -f \"mcp-telegram\"`\n- **Windows:** `taskkill /F /IM mcp-telegram.exe /T` (Check Task Manager for the exact process name)\n\n</details>\n\n## ğŸ¤ Contributing\n\nWe welcome contributions! If you'd like to help improve MCP Telegram, please feel free to submit issues, feature requests, or pull requests. Your feedback and contributions help make this project better for everyone.\n\n## ğŸ“ License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n---\n\n<div align=\"center\">\n  <p>Made with â¤ï¸ by <a href=\"https://x.com/dryeab\">Yeabsira Driba</a></p>\n</div>\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "telegram",
        "messaging",
        "messages",
        "models telegram",
        "mcp telegram",
        "telegram platform"
      ],
      "category": "virtual-assistants"
    },
    "dvcrn--mcp-server-siri-shortcuts": {
      "owner": "dvcrn",
      "name": "mcp-server-siri-shortcuts",
      "url": "https://github.com/dvcrn/mcp-server-siri-shortcuts",
      "imageUrl": "https://github.com/dvcrn.png",
      "description": "Access Siri Shortcuts functionality to list, open, and run shortcuts from the macOS Shortcuts app seamlessly. Integrates with AI models for dynamic execution of available shortcuts.",
      "stars": 161,
      "forks": 15,
      "license": "GNU General Public License v3.0",
      "language": "TypeScript",
      "updated_at": "2025-09-21T13:56:48Z",
      "readme_content": "# Siri Shortcuts MCP Server\n\nThis MCP server provides access to Siri shortcuts functionality via the Model Context Protocol (MCP). It allows listing, opening, and running shortcuts from the macOS Shortcuts app.\n\n![screenshot](./screenshot.png)\n\n## Features\n\n- Exposes _all_ shortcuts, meaning the LLM can call anything that is available in the Shortcuts app.\n- List all available shortcuts\n- Open shortcuts in the Shortcuts app\n- Run shortcuts with optional input parameters\n- Dynamically generated tools for each available shortcut\n\n## Tools\n\n### Base Tools\n\n1. `list_shortcuts`\n\n   - Lists all available Siri shortcuts on the system\n   - No input required\n   - Returns: Array of shortcut names\n\n   ```json\n   {\n     \"shortcuts\": [{ \"name\": \"My Shortcut 1\" }, { \"name\": \"My Shortcut 2\" }]\n   }\n   ```\n\n2. `open_shortcut`\n\n   - Opens a shortcut in the Shortcuts app\n   - Input:\n     - `name` (string): Name of the shortcut to open\n\n3. `run_shortcut`\n   - Runs a shortcut with optional input\n   - Input:\n     - `name` (string): Name or identifier (UUID) of the shortcut to run\n     - `input` (string, optional): Text input or filepath to pass to the shortcut\n\n### Dynamic Tools\n\nThe server automatically generates additional tools for each available shortcut in the format:\n\n- Tool name: `run_shortcut_[sanitized_shortcut_name]`\n- Description: Runs the specific shortcut\n- Input:\n  - `input` (string, optional): Text input or filepath to pass to the shortcut\n\n## Configuration\n\nThe server supports the following environment variables:\n\n- `GENERATE_SHORTCUT_TOOLS` (default: `true`): When set to `false`, disables the generation of dynamic shortcut tools. Only the base tools (`list_shortcuts`, `open_shortcut`, `run_shortcut`) will be available.\n- `INJECT_SHORTCUT_LIST` (default: `false`): When set to `true`, injects the list of available shortcuts into the `run_shortcut` tool description to help the LLM understand which shortcuts are available.\n\n## Usage with Claude\n\nAdd to your Claude configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"siri-shortcuts\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-server-siri-shortcuts\"],\n      \"env\": {\n        \"GENERATE_SHORTCUT_TOOLS\": \"true\",\n        \"INJECT_SHORTCUT_LIST\": \"false\"\n      }\n    }\n  }\n}\n```\n\n## Implementation Details\n\n- Uses the macOS `shortcuts` CLI command under the hood\n- Sanitizes shortcut names for tool naming compatibility\n- Supports both direct text input and file-based input\n- Returns shortcut output when available\n- Implements standard MCP error handling\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "shortcuts",
        "siri",
        "macos",
        "siri shortcuts",
        "macos shortcuts",
        "shortcuts macos"
      ],
      "category": "virtual-assistants"
    },
    "emiliobool--MCP-Relay": {
      "owner": "emiliobool",
      "name": "MCP-Relay",
      "url": "https://github.com/emiliobool/MCP-Relay",
      "imageUrl": "https://github.com/emiliobool.png",
      "description": "Send messages and prompts to a Discord channel and receive responses directly from an AI model. It integrates with Discord's API to facilitate real-time communication between AI and users.",
      "stars": 1,
      "forks": 1,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-04-21T12:07:22Z",
      "readme_content": "# MCP Relay\n\nThis MCP server allows Claude to send messages and prompts to a Discord channel and receive responses.\n\n## Setup Instructions\n\n### 1. Create a Discord Application and Bot\n\n1. Go to the [Discord Developer Portal](https://discord.com/developers/applications)\n2. Click \"New Application\" and give it a name\n3. Go to the \"Bot\" section in the left sidebar\n4. Under the bot's token section, click \"Reset Token\" and copy the new token\n   - Keep this token secure! Don't share it publicly\n5. Under \"Privileged Gateway Intents\", enable:\n   - Message Content Intent\n   - Server Members Intent\n   - Presence Intent\n\n### 2. Invite the Bot to Your Server\n\n1. Go to the \"OAuth2\" section in the left sidebar\n2. Select \"URL Generator\"\n3. Under \"Scopes\", select:\n   - bot\n   - applications.commands\n4. Under \"Bot Permissions\", select:\n   - Send Messages\n   - Embed Links\n   - Read Message History\n5. Copy the generated URL and open it in your browser\n6. Select your server and authorize the bot\n\n### 3. Get Channel ID\n\n1. In Discord, enable Developer Mode:\n   - Go to User Settings > App Settings > Advanced\n   - Turn on \"Developer Mode\"\n2. Right-click the channel you want to use\n3. Click \"Copy Channel ID\"\n\n### 4. Configure MCP Settings\n\nThe server requires configuration in your MCP settings file. Add the following to your configuration file:\n\n```json\n{\n    \"mcpServers\": {\n        \"discord-relay\": {\n            \"command\": \"node\",\n            \"args\": [\n                \"/ABSOLUTE/PATH/TO/MCP Relay/build/index.js\"\n            ],\n            \"env\": {\n                \"DISCORD_TOKEN\": \"your_bot_token_here\",\n                \"DISCORD_CHANNEL_ID\": \"your_channel_id_here\"\n            }\n        }\n    }\n}\n```\n\nReplace:\n- `/ABSOLUTE/PATH/TO/MCP Relay` with the actual path to your MCP Relay project\n- `your_bot_token_here` with your Discord bot token\n- `your_channel_id_here` with your Discord channel ID\n\nNote: Make sure to use absolute paths in the configuration.\n\n## Usage\n\nThe server provides a tool called `send-message` that accepts the following parameters:\n\n```typescript\n{\n  type: 'prompt' | 'notification',  // Type of message\n  title: string,                    // Message title\n  content: string,                  // Message content\n  actions?: Array<{                 // Optional action buttons\n    label: string,                  // Button label\n    value: string                   // Value returned when clicked\n  }>,\n  timeout?: number                  // Optional timeout in milliseconds\n}\n```\n\n### Message Types\n\n1. **Notification**: Simple message that doesn't expect a response\n   ```json\n   {\n     \"type\": \"notification\",\n     \"title\": \"Hello\",\n     \"content\": \"This is a notification\"\n   }\n   ```\n\n2. **Prompt**: Message that waits for a response\n   ```json\n   {\n     \"type\": \"prompt\",\n     \"title\": \"Question\",\n     \"content\": \"Do you want to proceed?\",\n     \"actions\": [\n       { \"label\": \"Yes\", \"value\": \"yes\" },\n       { \"label\": \"No\", \"value\": \"no\" }\n     ],\n     \"timeout\": 60000  // Optional: 1 minute timeout\n   }\n   ```\n\nNotes:\n- Prompts can be answered either by clicking action buttons or sending a text message\n- Only one response is accepted per prompt\n- If a timeout is specified, the prompt will fail after the timeout period\n- Notifications don't wait for responses and return immediately\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "discord",
        "relay",
        "mcp",
        "mcp relay",
        "virtual assistants",
        "communication ai"
      ],
      "category": "virtual-assistants"
    },
    "himanshu8271--Dragons": {
      "owner": "himanshu8271",
      "name": "Dragons",
      "url": "https://github.com/himanshu8271/Dragons",
      "imageUrl": "https://github.com/himanshu8271.png",
      "description": "Stream audio and video content in Telegram with a user-friendly interface featuring powerful controls and multilingual support. Enjoy music with friends in multiple chats simultaneously.",
      "stars": 0,
      "forks": 0,
      "license": "GNU Affero General Public License v3.0",
      "language": "",
      "updated_at": "2022-04-24T22:41:02Z",
      "readme_content": "<h1 align= center><b>â­ï¸ Music Player â­ï¸</b></h1>\n<h3 align = center> A Telegram Music Bot written in Python using Pyrogram and Py-Tgcalls </h3>\n\n<p align=\"center\">\n<a href=\"https://python.org\"><img src=\"http://forthebadge.com/images/badges/made-with-python.svg\" alt=\"made-with-python\"></a>\n<br>\n    <img src=\"https://img.shields.io/github/license/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"LICENSE\">\n    <img src=\"https://img.shields.io/github/contributors/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Contributors\">\n    <img src=\"https://img.shields.io/github/repo-size/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Repository Size\"> <br>\n    <img src=\"https://img.shields.io/github/forks/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Forks\">\n    <img src=\"https://img.shields.io/github/stars/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Stars\">\n    <img src=\"https://img.shields.io/github/watchers/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Watchers\">\n    <img src=\"https://img.shields.io/github/commit-activity/w/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Commit Activity\">\n    <img src=\"https://img.shields.io/github/issues/AsmSafone/MusicPlayer?style=for-the-badge\" alt=\"Issues\">\n</p>\n\n## âœ¨ <a name=\"features\"></a>Features\n\n### âš¡ï¸ Fast & Light\n\nStarts streaming your inputs while downloading and converting them. Also, it\ndoesn't make produce files.\n\n### ğŸ‘®ğŸ»â€â™€ï¸ Safe and handy\n\nRestricts control and sensitive commands to admins.\n\n### ğŸ—‘ Clean and spam free\n\nDeletes old playing trash to keep your chats clean.\n\n### ğŸ˜ Has cool controls\n\nLets you switch stream mode, loop, pause, resume, mute, unmute anytime.\n\n### ğŸ–¼ Has cool thumbnails\n\nResponse your commands with cool thumbnails on the chat.\n\n### ğŸ˜‰ Streams whatever you like\n\nYou can stream audio or video files, YouTube videos with any duration,\nYouTube lives, YouTube playlists and even custom live streams like radios or m3u8 links or files in\nthe place it is hosted!\n\n### ğŸ“Š Streams in multiple places\n\nAllows you to stream different things in multiple chats simultaneously. Each\nchat will have its own song queue.\n\n### ğŸ—£ Speaks different languages\n\nMusic Player is multilingual and speaks [various languages](#languages),\nthanks to the translators.\n\n## ğŸš€ <a name=\"deploy\"></a>Deploy\n\n[![Deploy on Heroku](https://www.herokucdn.com/deploy/button.svg)](https://deploy.safone.tech)\n\nNote: `First Fork The Repo Then Click On Deploy To Heroku Button!`\n\n\n## â˜ï¸ <a name=\"self_host\"></a>Self Host\n\n- Legecy Method\n```bash\n$ git clone https://github.com/AsmSafone/MusicPlayer\n$ cd MusicPlayer\n$ sudo apt install git curl python3-pip ffmpeg -y\n$ pip3 install -U pip\n$ curl -sL https://deb.nodesource.com/setup_16.x | sudo -E bash -\n$ sudo apt install -y nodejs\n$ sudo apt install build-essential\n$ sudo npm install pm2@latest -g\n$ pip3 install -U -r requirements.txt\n$ cp sample.env .env\n# < edit .env with your own values >\n$ python3 main.py\n```\n\n- Docker Build Method\n```bash\n$ git clone https://github.com/AsmSafone/MusicPlayer\n$ cd MusicPlayer\n$ cp sample.env .env\n# < edit .env with your own values >\n$ sudo docker build . -t musicplayer\n$ sudo docker run musicplayer\n```\n\n## âš’ <a name=\"configs\"></a>Configs\n\n- `API_ID`: Telegram app id from https://my.telegram.org/apps.\n- `API_HASH`: Telegram app hash from https://my.telegram.org/apps.\n- `SESSION`: Pyrogram string session. You can generate from [here](https://replit.com/@AsmSafone/genStr).\n- `SUDOERS`: ID of sudo users (separate multiple ids with space).\n- `BOT_TOKEN`: Telegram bot token from https://t.me/botfather. (optional)\n- `QUALITY`: Custom stream quality (high/medium/low) for the userbot in vc. Default: `high`\n- `PREFIX`: Bot commad prefixes (separate multiple prefix with space). Eg: `! /`\n- `LANGUAGE`: An [available](#languages) bot language (can change it anytime). Default: `en`\n- `STREAM_MODE`: An stream mode like audio or video (can change it anytime). Default: `audio`\n- `ADMINS_ONLY`: Put `True` if you want to make /play commands only for admins. Default: `False`\n- `SPOTIFY_CLIENT_ID`: Spotify client id get it from [here](https://developer.spotify.com/dashboard/applications). (optional)\n- `SPOTIFY_CLIENT_SECRET`: Spotify client secret get it from [here](https://developer.spotify.com/dashboard/applications). (optional)\n\n\n## ğŸ“„ <a name=\"commands\"></a>Commands\n\nCommand | Description\n:--- | :---\nâ€¢ !ping | Check if alive or not\nâ€¢ !start / !help | Show the help for commands\nâ€¢ !mode / !switch | Switch the stream mode (audio/video)\nâ€¢ !p / !play [song name or youtube link] | Play a song in vc, if already playing add to queue\nâ€¢ !radio / !stream [radio url or stream link] | Play a live stream in vc, if already playing add to queue\nâ€¢ !pl / !playlist [playlist link] | Play the whole youtube playlist at once\nâ€¢ !skip / !next | Skip to the next song\nâ€¢ !m / !mute | Mute the current stream\nâ€¢ !um / !unmute | Unmute the muted stream\nâ€¢ !ps / !pause | Pause the current stream\nâ€¢ !rs / !resume | Resume the paused stream\nâ€¢ !list / !queue | Show the songs in the queue\nâ€¢ !mix / !shuffle | Shuflle the queued playlist\nâ€¢ !loop / !repeat | Enable or disable the loop mode\nâ€¢ !lang / language [language code] | Set the bot language in group\nâ€¢ !ip / !import | Import queue from exported file\nâ€¢ !ep / !export | Export the queue for import in future\nâ€¢ !stop / !leave | Leave from vc and clear the queue\nâ€¢ !update / !restart | Update and restart your music player\n\n## ğŸ—£ <a name=\"languages\"></a>Languages\n\n```text\nen    English\n```\n\n## ğŸ’œ <a name=\"contribute\"></a>Contribute\n\nNew languages, bug fixes and improvements following\n[our contribution guidelines](./CONTRIBUTING.md) are warmly welcomed!\n\n## ğŸ›« <a name=\"supports\"></a>Supports\n\nFor any kind of help join [our support group](https://t.me/AsmSupport) or raise an [issue](https://github.com/AsmSafone/MusicPlayer/issues).\n\n## âœ¨ <a name=\"credits\"></a>Credits\n\n- [Me](https://github.com/AsmSafone) for [Noting](https://github.com/AsmSafone/MusicPlayer) ğŸ˜¬\n- [Dan](https://github.com/delivrance) for [Pyrogram](https://github.com/pyrogram/pyrogram) â¤ï¸\n- [Laky-64](https://github.com/Laky-64) for [Py-TgCalls](https://github.com/pytgcalls/pytgcalls) â¤ï¸\n- And Thanks To All [Contributors](https://github.com/AsmSafone/MusicPlayer/graphs/contributors)! â¤ï¸\n\n## ğŸ“ƒ <a name=\"license\"></a>License\n\nMusic Player is licenced under the GNU Affero General Public License v3.0.\nRead more [here](./LICENSE).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "telegram",
        "audio",
        "chats",
        "content telegram",
        "telegram user",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "htlin222--claude-chatgpt-mcp": {
      "owner": "htlin222",
      "name": "claude-chatgpt-mcp",
      "url": "https://github.com/htlin222/claude-chatgpt-mcp",
      "imageUrl": "https://github.com/htlin222.png",
      "description": "Seamlessly interact with the ChatGPT desktop app on macOS, allowing users to ask questions, view conversation history, and continue discussions. This integration facilitates enhanced productivity by bridging Claude and ChatGPT.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-04-02T03:27:04Z",
      "readme_content": "# Claude ChatGPT MCP Tool\n\nThis is a Model Context Protocol (MCP) tool that allows Claude to interact with the ChatGPT desktop app on macOS.\n\n## Features\n\n- Ask ChatGPT questions directly from Claude\n- View ChatGPT conversation history\n- Continue existing ChatGPT conversations\n\n## Installation\n\n### Prerequisites\n\n- macOS with M1/M2/M3 chip\n- [ChatGPT desktop app](https://chatgpt.com/download) installed\n- [Bun](https://bun.sh/) installed\n- [Claude desktop app](https://claude.ai/desktop) installed\n\n### NPX Installation (Recommended)\n\nYou can use NPX to run this tool without cloning the repository:\n\n- **Install and run the package using NPX:**\n\n```bash\nnpx claude-chatgpt-mcp\n```\n\n- **Configure Claude Desktop:**\n\nEdit your `claude_desktop_config.json` file (located at `~/Library/Application Support/Claude/claude_desktop_config.json`) to include this tool:\n\n```json\n\"chatgpt-mcp\": {\n  \"command\": \"npx\",\n  \"args\": [\"claude-chatgpt-mcp\"]\n}\n```\n\n- **Restart the Claude Desktop app**\n\n- **Grant necessary permissions:**\n  - Go to System Preferences > Privacy & Security > Privacy\n  - Give Terminal (or iTerm) access to Accessibility features\n  - You may see permission prompts when the tool is first used\n\n### Manual Installation\n\n1. Clone this repository:\n\n```bash\ngit clone https://github.com/syedazharmbnr1/claude-chatgpt-mcp.git\ncd claude-chatgpt-mcp\n```\n\n2. Install dependencies:\n\n```bash\nbun install\n```\n\n3. Make sure the script is executable:\n\n```bash\nchmod +x index.ts\n```\n\n4. Update your Claude Desktop configuration:\n\nEdit your `claude_desktop_config.json` file (located at `~/Library/Application Support/Claude/claude_desktop_config.json`) to include this tool:\n\n```json\n\"chatgpt-mcp\": {\n  \"command\": \"/Users/YOURUSERNAME/.bun/bin/bun\",\n  \"args\": [\"run\", \"/path/to/claude-chatgpt-mcp/index.ts\"]\n}\n```\n\nMake sure to replace `YOURUSERNAME` with your actual macOS username and adjust the path to where you cloned this repository.\n\n5. Restart Claude Desktop app\n\n6. Grant permissions:\n   - Go to System Preferences > Privacy & Security > Privacy\n   - Give Terminal (or iTerm) access to Accessibility features\n   - You may see permission prompts when the tool is first used\n\n## Usage\n\nOnce installed, you can use the ChatGPT tool directly from Claude by asking questions like:\n\n- \"Can you ask ChatGPT what the capital of France is?\"\n- \"Show me my recent ChatGPT conversations\"\n- \"Ask ChatGPT to explain quantum computing\"\n\n## Troubleshooting\n\nIf the tool isn't working properly:\n\n1. Make sure ChatGPT app is installed and you're logged in\n2. Verify the path to bun in your claude_desktop_config.json is correct\n3. Check that you've granted all necessary permissions\n4. Try restarting both Claude and ChatGPT apps\n\n## Optimizations\n\nThis fork includes several significant improvements to the original implementation:\n\n### Enhanced AppleScript Robustness\n\n#### Conversation Retrieval\n- Added multiple UI element targeting approaches to handle ChatGPT UI changes\n- Implemented better error detection with specific error messages\n- Added fallback mechanisms using accessibility attributes\n- Improved timeout handling with appropriate delays\n\n#### Response Handling\n- Replaced fixed waiting times with dynamic response detection\n- Added intelligent completion detection that recognizes when ChatGPT has finished typing\n- Implemented text stability detection (waits until text stops changing)\n- Added response extraction logic to isolate just the relevant response text\n- Improved error handling with detailed error messages\n- Added post-processing to clean up UI elements from responses\n- Implemented incomplete response detection to warn about potential cutoffs\n\nThese optimizations make the integration more reliable across different scenarios, more resilient to UI changes in the ChatGPT application, and better at handling longer response times without message cutoff issues.\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "chatgpt",
        "conversation",
        "interact",
        "interact chatgpt",
        "chatgpt mcp",
        "chatgpt desktop"
      ],
      "category": "virtual-assistants"
    },
    "hyperb1iss--droidmind": {
      "owner": "hyperb1iss",
      "name": "droidmind",
      "url": "https://github.com/hyperb1iss/droidmind",
      "imageUrl": "https://github.com/hyperb1iss.png",
      "description": "DroidMind enables control of Android devices using AI through natural language commands. It facilitates tasks such as debugging, system analysis, and app management in an integrated environment with the Model Context Protocol.",
      "stars": 244,
      "forks": 36,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-03T06:02:33Z",
      "readme_content": "<div align=\"center\">\n\n# ğŸ¤– DroidMind ğŸ§ \n\n<img src=\"docs/assets/images/logo_neon_glow_icon.png\" alt=\"DroidMind Logo\" width=\"180\" />\n\n[![Python 3.13+](https://img.shields.io/badge/python-3.13+-9D00FF.svg?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/downloads/)\n[![License](https://img.shields.io/badge/license-Apache_2.0-FF00FF.svg?style=for-the-badge&logo=apache&logoColor=white)](LICENSE)\n[![Status](https://img.shields.io/badge/status-active_development-39FF14.svg?style=for-the-badge&logo=githubactions&logoColor=white)](docs/plan.md)\n[![Code Style](https://img.shields.io/badge/code_style-ruff-00FFFF.svg?style=for-the-badge&logo=ruff&logoColor=white)](https://github.com/astral-sh/ruff)\n[![Type Check](https://img.shields.io/badge/type_check-pyright-FFBF00.svg?style=for-the-badge&logo=typescript&logoColor=white)](https://github.com/microsoft/pyright)\n[![MCP](https://img.shields.io/badge/protocol-MCP-E6E6FA.svg?style=for-the-badge&logo=anthropic&logoColor=white)](https://modelcontextprotocol.io/)\n[![Android](https://img.shields.io/badge/platform-android-A4C639.svg?style=for-the-badge&logo=android&logoColor=white)](https://www.android.com/)\n[![Docs](https://img.shields.io/badge/docs-online-FF9E80.svg?style=for-the-badge&logo=gitbook&logoColor=white)](https://hyperb1iss.github.io/droidmind/)\n\n**Control Android devices with AI through the Model Context Protocol**\n\n</div>\n\nDroidMind is a powerful bridge between AI assistants and Android devices, enabling control, debugging, and system analysis through natural language. By implementing the Model Context Protocol (MCP), DroidMind allows AI models to directly interact with Android devices via ADB in a secure, structured way. When used as part of an agentic coding workflow, DroidMind can enable your assistant to build and debug with your device directly in the loop.\n\n## ğŸ’« Core Features\n\nDroidMind empowers AI assistants to:\n\n- ğŸ“± **Manage Devices**: Connect via USB/TCP-IP, list devices, view properties, and reboot.\n- ğŸ“Š **Analyze Systems**: Access logs (logcat, ANR, crash, battery), capture bug reports, and dump heap.\n- ğŸ“‚ **Handle Files**: Browse, read, write, push, pull, delete, and manage device files/directories.\n- ğŸ“¦ **Control Apps**: Install, uninstall, start, stop, clear data, and inspect app details (manifest, permissions, activities).\n- ğŸ–¼ï¸ **Automate UI**: Perform taps, swipes, text input, and key presses.\n- ğŸš **Execute Shell Commands**: Run ADB shell commands with a security-conscious framework.\n- ğŸ”’ **Operate Securely**: Benefit from command validation, risk assessment, and sanitization.\n- ğŸ’¬ **Integrate Seamlessly**: Connect with any MCP-compatible client (Claude, Cursor, Cline, etc.).\n\nFor a detailed list of capabilities, see the **[User Manual](docs/user_manual/index.md)** and **[MCP Reference](docs/mcp-reference.md)**.\n\n## ğŸš€ Getting Started\n\n### Quickstart for IDEs (Zero Install with `uvx`)\n\nFor the fastest way to integrate DroidMind with an MCP-compatible IDE (like Cursor), you can configure it to run DroidMind directly from its GitHub repository using `uvx`. This method **does not require you to manually clone or install DroidMind first**.\n\nAdd the following to your IDE's MCP configuration (e.g., `.cursor/mcp.json` for Cursor):\n\n```json\n{\n  \"mcpServers\": {\n    \"droidmind\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"--from\",\n        \"git+https://github.com/hyperb1iss/droidmind\",\n        \"droidmind\",\n        \"--transport\",\n        \"stdio\" // The default and preferred mode for most IDE integrations\n      ]\n    }\n  }\n}\n```\n\nYour IDE will be configured to launch DroidMind on demand. Full instructions for this setup are in the **[Quick Start Guide](docs/quickstart.md#1-configure-your-ide-to-run-droidmind-via-uvx)**.\n\n### Prerequisites\n\n- Python 3.13 or higher\n- `uv` (Python package manager)\n- Android device with USB debugging enabled\n- ADB (Android Debug Bridge) installed and in your system's PATH\n\n### Installation\n\nFor detailed instructions on setting up DroidMind, including the quick IDE integration with `uvx` (covered in the Quick Start), manual installation from source, or using Docker, please see our comprehensive **[Installation Guide](docs/installation.md)**.\n\n### Running DroidMind\n\nHow you run DroidMind depends on your setup:\n\n- **IDE Integration (via `uvx`)**: Your IDE automatically manages running DroidMind as configured in its MCP settings (e.g., `mcp.json`). See the [Quick Start Guide](docs/quickstart.md).\n- **Manual Installation**: After installing from source, you can run DroidMind directly.\n  - **Stdio (for direct terminal interaction or some IDE setups):**\n    ```bash\n    droidmind --transport stdio\n    ```\n  - **SSE (for web UIs or AI assistants like Claude Desktop):**\n    ```bash\n    droidmind --transport sse\n    ```\n    This usually starts a server at `sse://localhost:4256/sse`.\n- **Docker**: Refer to the [Docker Guide](docs/docker.md) for commands to run DroidMind in a container.\n\nRefer to the **[Installation Guide](docs/installation.md)** for more details on running DroidMind in different environments.\n\n## ğŸ³ Running with Docker\n\nDroidMind can also be run using Docker for a consistent, containerized environment. This is particularly useful for deployment and isolating dependencies.\n\nFor comprehensive instructions on building the Docker image and running DroidMind in a container with `stdio` or `SSE` transport, including notes on ADB device access, please refer to our **[Docker Guide](docs/docker.md)**.\n\n## ğŸ”® Example AI Assistant Queries\n\nWith an AI assistant connected to DroidMind, you can make requests like:\n\n- \"List all connected Android devices and show their properties.\"\n- \"Take a screenshot of my Pixel.\"\n- \"Install this APK on `emulator-5554`.\"\n- \"Show me the recent crash logs from `your_device_serial`.\"\n- \"Tap the 'Next' button on the current screen of `emulator-5554`.\"\n\nFor more inspiration, check out our **[Example Queries and Workflows](docs/user_manual/example_queries.md)** in the User Manual.\n\n## ğŸ”’ Security\n\nDroidMind incorporates a security framework to protect your devices:\n\n- **Command Validation & Sanitization**\n- **Risk Assessment Categorization**\n- **Protected Path Operations**\n- **Comprehensive Logging**\n\nHigh-risk operations are flagged, and critical ones are blocked by default. Learn more in our **[Security Considerations](docs/user_manual/security.md)** chapter.\n\n## ğŸ’» Development\n\nDroidMind uses `uv` for dependency management and development workflows.\n\n```bash\n# Install/update dependencies (after cloning and activating .venv)\nuv pip install -e .[dev,sse]\n\n# Run tests\npytest\n\n# Run linting\nruff check .\n\n# Run type checking\npyright # Ensure pyright is installed or use ruff's type checking capabilities\n```\n\n## ğŸ¤ Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n1.  Fork the repository.\n2.  Create your feature branch (`git checkout -b feature/amazing-feature`).\n3.  Set up your development environment with `uv`.\n4.  Make your changes.\n5.  Run tests, linting, and type checking.\n6.  Commit your changes (`git commit -m 'Add some amazing feature'`).\n7.  Push to the branch (`git push origin feature/amazing-feature`).\n8.  Open a Pull Request.\n\n## ğŸ“ License\n\nThis project is licensed under the Apache License - see the [LICENSE](LICENSE) file for details.\n\n---\n\n<div align=\"center\">\n\nCreated by [Stefanie Jane ğŸŒ ](https://github.com/hyperb1iss)\n\nIf you find DroidMind useful, [buy me a Monster Ultra Violet âš¡ï¸](https://ko-fi.com/hyperb1iss)\n\n</div>\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "droidmind",
        "android",
        "ai",
        "hyperb1iss droidmind",
        "droidmind enables",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "hyy0612--chatbot": {
      "owner": "hyy0612",
      "name": "chatbot",
      "url": "https://github.com/hyy0612/chatbot",
      "imageUrl": "https://github.com/hyy0612.png",
      "description": "Provides a conversational AI interface for applications, enabling automated responses and interactive dialogue to enhance user engagement. It supports easy deployment of chat-based AI solutions for various use cases.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-07T09:52:24Z",
      "readme_content": "# chatbot",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "chatbot",
        "ai",
        "dialogue",
        "hyy0612 chatbot",
        "chatbot provides",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "imgompanda--AutoGPT123": {
      "owner": "imgompanda",
      "name": "AutoGPT123",
      "url": "https://github.com/imgompanda/AutoGPT123",
      "imageUrl": "https://github.com/imgompanda.png",
      "description": "AutoGPT enables users to build, test, and deploy AI agents, facilitating the automation of various tasks and the realization of innovative ideas in AI development.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2024-04-09T13:17:37Z",
      "readme_content": "# AutoGPT: build & use AI agents\n\n[![Discord Follow](https://dcbadge.vercel.app/api/server/autogpt?style=flat)](https://discord.gg/autogpt) &ensp;\n[![Twitter Follow](https://img.shields.io/twitter/follow/Auto_GPT?style=social)](https://twitter.com/Auto_GPT) &ensp;\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n**AutoGPT** is the vision of the power of AI accessible to everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters:\n\n- ğŸ—ï¸ **Building** - Lay the foundation for something amazing.\n- ğŸ§ª **Testing** - Fine-tune your agent to perfection.\n- ğŸ¤ **Delegating** - Let AI work for you, and have your ideas come to life.\n\nBe part of the revolution! **AutoGPT** is here to stay, at the forefront of AI innovation.\n\n**ğŸ“– [Documentation](https://docs.agpt.co)**\n&ensp;|&ensp;\n**ğŸš€ [Contributing](CONTRIBUTING.md)**\n&ensp;|&ensp;\n**ğŸ› ï¸ [Build your own Agent - Quickstart](QUICKSTART.md)**\n\n## ğŸ¥‡ Current Best Agent: evo.ninja\n[Current Best Agent]: #-current-best-agent-evoninja\n\nThe AutoGPT Arena Hackathon saw [**evo.ninja**](https://github.com/polywrap/evo.ninja) earn the top spot on our Arena Leaderboard, proving itself as the best open-source generalist agent. Try it now at https://evo.ninja!\n\nğŸ“ˆ To challenge evo.ninja, AutoGPT, and others, submit your benchmark run to the [Leaderboard](#-leaderboard), and maybe your agent will be up here next!\n\n## ğŸ§± Building blocks\n\n### ğŸ—ï¸ Forge\n\n**Forge your own agent!** &ndash; Forge is a ready-to-go template for your agent application. All the boilerplate code is already handled, letting you channel all your creativity into the things that set *your* agent apart. All tutorials are located [here](https://medium.com/@aiedge/autogpt-forge-e3de53cc58ec). Components from the [`forge.sdk`](/autogpts/forge/forge/sdk) can also be used individually to speed up development and reduce boilerplate in your agent project.\n\nğŸš€ [**Getting Started with Forge**](https://github.com/Significant-Gravitas/AutoGPT/blob/master/autogpts/forge/tutorials/001_getting_started.md) &ndash;\nThis guide will walk you through the process of creating your own agent and using the benchmark and user interface.\n\nğŸ“˜ [Learn More](https://github.com/Significant-Gravitas/AutoGPT/tree/master/autogpts/forge) about Forge\n\n### ğŸ¯ Benchmark\n\n**Measure your agent's performance!** The `agbenchmark` can be used with any agent that supports the agent protocol, and the integration with the project's [CLI] makes it even easier to use with AutoGPT and forge-based agents. The benchmark offers a stringent testing environment. Our framework allows for autonomous, objective performance evaluations, ensuring your agents are primed for real-world action.\n\n<!-- TODO: insert visual demonstrating the benchmark -->\n\nğŸ“¦ [`agbenchmark`](https://pypi.org/project/agbenchmark/) on Pypi\n&ensp;|&ensp;\nğŸ“˜ [Learn More](https://github.com/Significant-Gravitas/AutoGPT/blob/master/benchmark) about the Benchmark\n\n#### ğŸ† [Leaderboard][leaderboard]\n[leaderboard]: https://leaderboard.agpt.co\n\nSubmit your benchmark run through the UI and claim your place on the AutoGPT Arena Leaderboard! The best scoring general agent earns the title of **[Current Best Agent]**, and will be adopted into our repo so people can easily run it through the [CLI].\n\n[![Screenshot of the AutoGPT Arena leaderboard](https://github.com/Significant-Gravitas/AutoGPT/assets/12185583/60813392-9ddb-4cca-bb44-b477dbae225d)][leaderboard]\n\n### ğŸ’» UI\n\n**Makes agents easy to use!** The `frontend` gives you a user-friendly interface to control and monitor your agents. It connects to agents through the [agent protocol](#-agent-protocol), ensuring compatibility with many agents from both inside and outside of our ecosystem.\n\n<!-- TODO: instert screenshot of front end -->\n\nThe frontend works out-of-the-box with all agents in the repo. Just use the [CLI] to run your agent of choice!\n\nğŸ“˜ [Learn More](https://github.com/Significant-Gravitas/AutoGPT/tree/master/frontend) about the Frontend\n\n### âŒ¨ï¸ CLI\n\n[CLI]: #-cli\n\nTo make it as easy as possible to use all of the tools offered by the repository, a CLI is included at the root of the repo:\n\n```shell\n$ ./run\nUsage: cli.py [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  agent      Commands to create, start and stop agents\n  arena      Commands to enter the arena\n  benchmark  Commands to start the benchmark and list tests and categories\n  setup      Installs dependencies needed for your system.\n```\n\nJust clone the repo, install dependencies with `./run setup`, and you should be good to go!\n\n## ğŸ¤” Questions? Problems? Suggestions?\n\n### Get help - [Discord ğŸ’¬](https://discord.gg/autogpt)\n\n[![Join us on Discord](https://invidget.switchblade.xyz/autogpt)](https://discord.gg/autogpt)\n\nTo report a bug or request a feature, create a [GitHub Issue](https://github.com/Significant-Gravitas/AutoGPT/issues/new/choose). Please ensure someone else hasnâ€™t created an issue for the same topic.\n\n## ğŸ¤ Sister projects\n\n### ğŸ”„ Agent Protocol\n\nTo maintain a uniform standard and ensure seamless compatibility with many current and future applications, AutoGPT employs the [agent protocol](https://agentprotocol.ai/) standard by the AI Engineer Foundation. This standardizes the communication pathways from your agent to the frontend and benchmark.\n\n---\n\n<p align=\"center\">\n<a href=\"https://star-history.com/#Significant-Gravitas/AutoGPT\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=Significant-Gravitas/AutoGPT&type=Date&theme=dark\" />\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=Significant-Gravitas/AutoGPT&type=Date\" />\n    <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=Significant-Gravitas/AutoGPT&type=Date\" />\n  </picture>\n</a>\n</p>\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "autogpt",
        "automation",
        "autogpt123",
        "virtual assistants",
        "imgompanda autogpt123",
        "ai agents"
      ],
      "category": "virtual-assistants"
    },
    "itsuzef--reaper-mcp": {
      "owner": "itsuzef",
      "name": "reaper-mcp",
      "url": "https://github.com/itsuzef/reaper-mcp",
      "imageUrl": "https://github.com/itsuzef.png",
      "description": "Integrate AI-driven music production workflows with REAPER to manage projects, tracks, MIDI composition, audio recording, mixing, and mastering. Provide full control over MIDI and audio capabilities for creating and rendering music tracks.",
      "stars": 15,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-20T09:39:44Z",
      "readme_content": "# REAPER MCP Server\n\nA comprehensive Model Context Protocol (MCP) server that enables AI agents to create fully mixed and mastered tracks in REAPER with both MIDI and audio capabilities.\n\n## Features\n\n- Complete project management (creation, saving, rendering)\n- Track operations (creation, routing, parameter adjustment)\n- MIDI composition and editing\n- Audio recording and importing\n- Virtual instrument and effect management\n- Mixing and automation\n- Mastering tools\n- Audio analysis and feedback\n\n## Requirements\n\n- REAPER DAW installed\n- Python 3.8+\n- OSC support enabled in REAPER (for OSC mode)\n- ReaScript API enabled in REAPER (for ReaScript mode)\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/itsuzef/reaper-mcp.git\ncd reaper-mcp\n\n# Create and activate a virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install the package\npip install -e .\n```\n\n## Usage\n\n### Quick Start\n\nThe easiest way to get started is to use the provided startup script:\n\n```bash\n# Start REAPER first\nopen /Applications/REAPER.app  # On macOS\n# or start REAPER manually on other platforms\n\n# Then start the MCP server\n./scripts/start_reaper_mcp_server.sh  # On Unix/Mac\n```\n\n#### Windows Users\n\nFor Windows users, use one of the provided Windows scripts:\n\n```cmd\n# Using Command Prompt (CMD)\nscripts\\start_reaper_mcp_server.bat\n\n# Using PowerShell\npowershell -ExecutionPolicy Bypass -File scripts\\start_reaper_mcp_server.ps1\n```\n\n### Configuration\n\nBy default, the server will use OSC mode, which is more reliable and doesn't require the ReaScript API to be working correctly. You can configure the server using command-line arguments:\n\n```bash\n# Start in OSC mode (default)\n./scripts/start_reaper_mcp_server.sh --mode=osc  # Unix/Mac\nscripts\\start_reaper_mcp_server.bat --mode=osc   # Windows CMD\npowershell -File scripts\\start_reaper_mcp_server.ps1 -mode osc  # Windows PowerShell\n\n# Start in ReaScript mode\n./scripts/start_reaper_mcp_server.sh --mode=reapy  # Unix/Mac\nscripts\\start_reaper_mcp_server.bat --mode=reapy   # Windows CMD\npowershell -File scripts\\start_reaper_mcp_server.ps1 -mode reapy  # Windows PowerShell\n\n# Configure OSC settings (Unix/Mac)\n./scripts/start_reaper_mcp_server.sh --host=192.168.1.110 --send-port=8000 --receive-port=9000\n\n# Configure OSC settings (Windows CMD)\nscripts\\start_reaper_mcp_server.bat --host=192.168.1.110 --send-port=8000 --receive-port=9000\n\n# Configure OSC settings (Windows PowerShell)\npowershell -File scripts\\start_reaper_mcp_server.ps1 -host \"192.168.1.110\" -sendPort 8000 -receivePort 9000\n\n# Enable debug logging\n./scripts/start_reaper_mcp_server.sh --debug  # Unix/Mac\nscripts\\start_reaper_mcp_server.bat --debug   # Windows CMD\npowershell -File scripts\\start_reaper_mcp_server.ps1 -debug  # Windows PowerShell\n```\n\n### Setting up REAPER for OSC\n\n1. Open REAPER\n2. Go to Preferences > Control/OSC/web\n3. Click \"Add\" and select \"OSC (Open Sound Control)\"\n4. Configure the following settings:\n   - Device name: ReaperMCP\n   - Mode: Local port\n   - Local listen port: 8000\n   - Local IP: 127.0.0.1 (or your computer's IP address)\n   - Allow binding messages to REAPER actions and FX learn: Checked (optional)\n   - Outgoing max packet size: 1024\n   - Wait between packets: 10ms\n\n### Setting up REAPER for ReaScript\n\n1. Open REAPER\n2. Go to Preferences > Plug-ins > ReaScript\n3. Make sure \"Enable Python for ReaScript\" is checked\n4. Set the Python DLL/dylib path to your Python installation\n   - On macOS: `/opt/homebrew/Cellar/python@3.x/3.x.x/Frameworks/Python.framework/Versions/3.x/Python`\n   - On Windows: `C:\\Path\\to\\Python\\python3x.dll`\n5. Run the setup script:\n   ```bash\n   python scripts/setup_reaper_python.py\n   ```\n\n## Project Structure\n\n- `src/reaper_mcp/`: Main package directory\n  - `__main__.py`: Command-line interface\n  - `osc_server.py`: OSC-based server implementation\n  - `server.py`: ReaScript-based server implementation\n- `examples/`: Example scripts demonstrating usage\n- `scripts/`: Utility scripts for setup and running\n\n## MCP Tools\n\nThe server provides the following MCP tools:\n\n- `create_project`: Creates a new REAPER project\n- `create_track`: Creates a new track in the current project\n- `list_tracks`: Lists all tracks in the current project\n- `add_midi_note`: Adds a MIDI note to a track\n- `get_project_info`: Gets information about the current project\n\n## Troubleshooting\n\n### ReaScript API Issues\n\nIf you're experiencing issues with the ReaScript API, try using the OSC mode instead:\n\n```bash\n./scripts/start_reaper_mcp_server.sh --mode=osc\n```\n\n### OSC Communication Issues\n\nMake sure REAPER is configured correctly for OSC:\n1. Check that the OSC settings in REAPER match the server settings\n2. Verify that no firewall is blocking the communication\n3. Try using the local IP address (127.0.0.1) instead of a network IP\n\n### Windows-Specific Troubleshooting\n\nIf you're having issues running the MCP server on Windows:\n\n1. **Script Execution Issues**:\n   - For PowerShell scripts, you may need to adjust the execution policy: `Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser`\n   - Alternatively, use the `-ExecutionPolicy Bypass` flag as shown in the examples\n\n2. **Path Issues**:\n   - Ensure the REAPER path in the scripts matches your installation location\n   - Default is `C:\\Program Files\\REAPER\\reaper.exe`, modify if needed\n\n3. **Virtual Environment**:\n   - If you created the venv with a different method, the activation script might be in a different location\n   - Try activating manually before running: `venv\\Scripts\\activate`\n\n4. **Firewall Blocking**:\n   - Windows Firewall may block OSC communication\n   - Add exceptions for Python and REAPER in Windows Firewall settings\n\n5. **Administrator Rights**:\n   - Try running the Command Prompt or PowerShell as Administrator if you encounter permission issues\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "midi",
        "reaper",
        "mastering",
        "workflows reaper",
        "reaper mcp",
        "midi composition"
      ],
      "category": "virtual-assistants"
    },
    "jlucaso1--whatsapp-mcp-ts": {
      "owner": "jlucaso1",
      "name": "whatsapp-mcp-ts",
      "url": "https://github.com/jlucaso1/whatsapp-mcp-ts",
      "imageUrl": "https://github.com/jlucaso1.png",
      "description": "Connects personal WhatsApp accounts to AI agents, enabling the search of messages, contacts, and recent chats. Supports sending messages to individuals or groups and retrieving message history for specific chats.",
      "stars": 37,
      "forks": 11,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-09T01:59:37Z",
      "readme_content": "# WhatsApp MCP Server (TypeScript/Baileys)\n[![smithery badge](https://smithery.ai/badge/@jlucaso1/whatsapp-mcp-ts)](https://smithery.ai/server/@jlucaso1/whatsapp-mcp-ts)\n\nThis is a Model Context Protocol (MCP) server for WhatsApp, built with TypeScript and using the `@whiskeysockets/baileys` library.\n\nIt allows you to connect your personal WhatsApp account to an AI agent (like Anthropic Claude via its desktop app or Cursor) enabling it to:\n\n* Search your personal WhatsApp messages.\n* Search your contacts (individuals, not groups).\n* List your recent chats.\n* Retrieve message history for specific chats.\n* Send messages to individuals or groups.\n\nIt connects directly to your **personal WhatsApp account** using the WhatsApp Web multi-device API. All your messages and authentication details are stored **locally** in a SQLite database (`./data/`) and authentication cache (`./auth_info/`). Data is only sent to the connected AI agent when it explicitly uses the provided MCP tools (which you control via the agent's interface).\n\n*(Optional: Consider adding a screenshot or GIF similar to the reference example here)*\n\n## Example\n\n**User:**\nSend a whatsapp message to \"Meu amor\" in whatsapp saying \"Te amo\"\n\n---\n\n**Assistant:**\nOkay, I need to find the contact first.\n*Using tool: `whatsapp.search_contacts`*\n```json\n{\n  \"query\": \"Meu amor\"\n}\n```\n\n---\n\n**Tool Result:**\n```json\n[\n  {\n    \"jid\": \"5599xxxxxx@s.whatsapp.net\",\n    \"name\": \"Meu Amor\"\n  }\n]\n```\n\n---\n\n**Assistant:**\nFound the contact. Now sending the message.\n*Using tool: `whatsapp.send_message`*\n```json\n{\n  \"recipient\": \"5599xxxxxx@s.whatsapp.net\",\n  \"message\": \"Te amo\"\n}\n```\n\n---\n\n**Tool Result:**\n```text\nMessage sent successfully to 5599xxxxxx@s.whatsapp.net (ID: XXXXXXXXXXX).\n```\n\n## Key Features (MCP Tools)\n\nThe server exposes the following tools to the connected AI agent:\n\n* `search_contacts`: Search for contacts by name or phone number part (JID).\n* `list_messages`: Retrieve message history for a specific chat, with pagination.\n* `list_chats`: List your chats, sortable by activity or name, filterable, paginated, optionally includes last message details.\n* `get_chat`: Get detailed information about a specific chat.\n* `get_message_context`: Retrieve messages sent immediately before and after a specific message ID for context.\n* `send_message`: Send a text message to a specified recipient JID (user or group).\n\n## Installation\n\n### Installing via Smithery\n\nTo install WhatsApp MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@jlucaso1/whatsapp-mcp-ts):\n\n```bash\nnpx -y @smithery/cli install @jlucaso1/whatsapp-mcp-ts --client claude\n```\n\n### Prerequisites\n\n* **Node.js:** Version 23.10.0 or higher (as specified in `package.json`). You can check your version with `node -v`. (Has initial typescript and sqlite builtin support)\n* **npm** (or yarn/pnpm): Usually comes with Node.js.\n* **AI Client:** Anthropic Claude Desktop app, Cursor, Cline or Roo Code (or another MCP-compatible client).\n\n### Steps\n\n1.  **Clone this repository:**\n    ```bash\n    git clone <your-repo-url> whatsapp-mcp-ts\n    cd whatsapp-mcp-ts\n    ```\n\n2.  **Install dependencies:**\n    ```bash\n    npm install\n    # or yarn install / pnpm install\n    ```\n\n3.  **Run the server for the first time:**\n    Use `node` to run the main script directly.\n    ```bash\n    node src/main.ts\n    ```\n    * The first time you run it, it will likely generate a QR code link using `quickchart.io` and attempt to open it in your default browser.\n    * Scan this QR code using your WhatsApp mobile app (Settings > Linked Devices > Link a Device).\n    * Authentication credentials will be saved locally in the `auth_info/` directory (this is ignored by git).\n    * Messages will start syncing and be stored in `./data/whatsapp.db`. This might take some time depending on your history size. Check the `wa-logs.txt` and console output for progress.\n    * Keep this terminal window running. After syncing you can close.\n\n## Configuration for AI Client\n\nYou need to tell your AI client how to start this MCP server.\n\n1.  **Prepare the configuration JSON:**\n    Copy the following JSON structure. You'll need to replace `{{PATH_TO_REPO}}` with the **absolute path** to the directory where you cloned this repository.\n\n    ```json\n    {\n      \"mcpServers\": {\n        \"whatsapp\": {\n          \"command\": \"node\",\n          \"args\": [\n            \"{{PATH_TO_REPO}}/src/main.ts\"\n          ],\n          \"timeout\": 15, // Optional: Adjust startup timeout if needed\n          \"disabled\": false\n        }\n      }\n    }\n    ```\n    * **Get the absolute path:** Navigate to the `whatsapp-mcp-ts` directory in your terminal and run `pwd`. Use this output for `{{PATH_TO_REPO}}`.\n\n2.  **Save the configuration file:**\n    * For **Claude Desktop:** Save the JSON as `claude_desktop_config.json` in its configuration directory:\n        * macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n        * Windows: `%APPDATA%\\Claude\\claude_desktop_config.json` (Likely path, verify if needed)\n        * Linux: `~/.config/Claude/claude_desktop_config.json` (Likely path, verify if needed)\n    * For **Cursor:** Save the JSON as `mcp.json` in its configuration directory:\n        * `~/.cursor/mcp.json`\n\n3.  **Restart Claude Desktop / Cursor:**\n    Close and reopen your AI client. It should now detect the \"whatsapp\" MCP server and allow you to use its tools.\n\n## Usage\n\nOnce the server is running (either manually via `node src/main.ts` or started by the AI client via the config file) and connected to your AI client, you can interact with your WhatsApp data through the agent's chat interface. Ask it to search contacts, list recent chats, read messages, or send messages.\n\n## Architecture Overview\n\nThis application is a single Node.js process that:\n\n1.  Uses `@whiskeysockets/baileys` to connect to the WhatsApp Web API, handling authentication and real-time events.\n2.  Stores WhatsApp chats and messages locally in a SQLite database (`./data/whatsapp.db`) using `node:sqlite`.\n3.  Runs an MCP server using `@modelcontextprotocol/sdk` that listens for requests from an AI client over standard input/output (stdio).\n4.  Provides MCP tools that query the local SQLite database or use the Baileys socket to send messages.\n5.  Uses `pino` for logging activity (`wa-logs.txt` for WhatsApp events, `mcp-logs.txt` for MCP server activity).\n\n## Data Storage & Privacy\n\n* **Authentication:** Your WhatsApp connection credentials are stored locally in the `./auth_info/` directory.\n* **Messages & Chats:** Your message history and chat metadata are stored locally in the `./data/whatsapp.db` SQLite file.\n* **Local Data:** Both `auth_info/` and `data/` are included in `.gitignore` to prevent accidental commits. **Treat these directories as sensitive.**\n* **LLM Interaction:** Data is only sent to the connected Large Language Model (LLM) when the AI agent actively uses one of the provided MCP tools (e.g., `list_messages`, `send_message`). The server itself does not proactively send your data anywhere else.\n\n## Technical Details\n\n* **Language:** TypeScript\n* **Runtime:** Node.js (>= v23.10.0)\n* **WhatsApp API:** `@whiskeysockets/baileys`\n* **MCP SDK:** `@modelcontextprotocol/sdk`\n* **Database:** `node:sqlite` (Bundled SQLite)\n* **Logging:** `pino`\n* **Schema Validation:** `zod` (for MCP tool inputs)\n\n## Troubleshooting\n\n* **QR Code Issues:**\n    * If the QR code link doesn't open automatically, check the console output for the `quickchart.io` URL and open it manually.\n    * Ensure you scan the QR code promptly with your phone's WhatsApp app.\n* **Authentication Failures / Logged Out:**\n    * If the connection closes with a `DisconnectReason.loggedOut` error, you need to re-authenticate. Stop the server, delete the `./auth_info/` directory, and restart the server (`node src/main.ts`) to get a new QR code.\n* **Message Sync Issues:**\n    * Initial sync can take time. Check `wa-logs.txt` for activity.\n    * If messages seem out of sync or missing, you might need a full reset. Stop the server, delete **both** `./auth_info/` and `./data/` directories, then restart the server to re-authenticate and resync history.\n* **MCP Connection Problems (Claude/Cursor):**\n    * Double-check the `command` and `args` (especially the `{{PATH_TO_REPO}}`) in your `claude_desktop_config.json` or `mcp.json`. Ensure the path is absolute and correct.\n    * Verify Node.js are correctly installed and in your system's PATH.\n    * Check the AI client's logs for errors related to starting the MCP server.\n    * Check this server's logs (`mcp-logs.txt`) for MCP-related errors.\n* **Errors Sending Messages:**\n    * Ensure the recipient JID is correct (e.g., `number@s.whatsapp.net` for users, `groupid@g.us` for groups).\n    * Check `wa-logs.txt` for specific errors from Baileys.\n* **General Issues:** Check both `wa-logs.txt` and `mcp-logs.txt` for detailed error messages.\n\nFor further MCP integration issues, refer to the [official MCP documentation](https://modelcontextprotocol.io/quickstart/server#claude-for-desktop-integration-issues).\n\n## Credits\n\n- https://github.com/lharries/whatsapp-mcp Do the same as this codebase but uses go and python.\n\n## License\n\nThis project is licensed under the ISC License (see `package.json`).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "whatsapp",
        "jlucaso1",
        "chats",
        "jlucaso1 whatsapp",
        "whatsapp mcp",
        "whatsapp accounts"
      ],
      "category": "virtual-assistants"
    },
    "logos-42--ANPtest": {
      "owner": "logos-42",
      "name": "ANPtest",
      "url": "https://github.com/logos-42/ANPtest",
      "imageUrl": "https://github.com/logos-42.png",
      "description": "Connects to AI agents using self-compressed decentralized identifiers (DIDs). Facilitates interactive conversations with an AI assistant in a talk show style, featuring functionalities for DID generation and QR code display.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-04-01T07:36:48Z",
      "readme_content": "# è„±å£ç§€AIæ™ºèƒ½ä½“\r\n\r\nåŸºäºè‡ªå‹ç¼©DIDæŠ€æœ¯ï¼Œä½¿ç”¨ç¡…åŸºæµåŠ¨APIå®ç°çš„è„±å£ç§€AIåŠ©æ‰‹ã€‚\r\n\r\n## é¡¹ç›®ç‰¹ç‚¹\r\n\r\n- å®ç°è‡ªå‹ç¼©DIDï¼Œæ— éœ€é¢å¤–æŸ¥è¯¢å³å¯è¿æ¥æ™ºèƒ½ä½“\r\n- ä½¿ç”¨ç¡…åŸºæµåŠ¨çš„DeepSeek-R1-Distill-Qwen-32Bå¤§æ¨¡å‹\r\n- æä¾›ç”ŸæˆDIDã€äºŒç»´ç å±•ç¤ºå’ŒèŠå¤©åŠŸèƒ½\r\n- æ”¯æŒæ™ºèƒ½ä½“é—´çš„é€šä¿¡ä¸è¿æ¥\r\n\r\n## æŠ€æœ¯æ ˆ\r\n\r\n- Next.js: Reactæ¡†æ¶\r\n- è‡ªå‹ç¼©DID: å»ä¸­å¿ƒåŒ–èº«ä»½è¯†åˆ«\r\n- ç¡…åŸºæµåŠ¨API: AIå¤§æ¨¡å‹æœåŠ¡\r\n- Vercel: éƒ¨ç½²æœåŠ¡\r\n\r\n## å¿«é€Ÿå¼€å§‹\r\n\r\n### æœ¬åœ°å¼€å‘\r\n\r\n1. å…‹éš†é¡¹ç›®å¹¶å®‰è£…ä¾èµ–:\r\n\r\n```bash\r\ngit clone <repository-url>\r\ncd comedyagent\r\nnpm install\r\n```\r\n\r\n2. é…ç½®APIå¯†é’¥:\r\n\r\nå¦‚éœ€ä½¿ç”¨ä¸åŒçš„APIå¯†é’¥ï¼Œè¯·ä¿®æ”¹`lib/ai.js`æ–‡ä»¶ä¸­çš„`API_KEY`å˜é‡ã€‚\r\n\r\n3. å¯åŠ¨å¼€å‘æœåŠ¡å™¨:\r\n\r\n```bash\r\nnpm run dev\r\n```\r\n\r\n4. è®¿é—® http://localhost:3000 æŸ¥çœ‹åº”ç”¨ã€‚\r\n\r\n### Verceléƒ¨ç½²\r\n\r\n1. Forkæ­¤ä»“åº“åˆ°æ‚¨çš„GitHubè´¦æˆ·ã€‚\r\n\r\n2. åœ¨Vercelä¸Šåˆ›å»ºæ–°é¡¹ç›®ï¼Œå¹¶è¿æ¥æ‚¨çš„GitHubä»“åº“ã€‚\r\n\r\n3. éƒ¨ç½²å®Œæˆåï¼Œå³å¯é€šè¿‡Vercelæä¾›çš„URLè®¿é—®åº”ç”¨ã€‚\r\n\r\n## ä½¿ç”¨è¯´æ˜\r\n\r\n### ç”ŸæˆDID\r\n\r\n1. åœ¨é¦–é¡µç‚¹å‡»\"ç”ŸæˆDID\"æŒ‰é’®ã€‚\r\n2. ç³»ç»Ÿä¼šç”Ÿæˆä¸€ä¸ªè‡ªåŒ…å«DIDï¼Œå¹¶ä»¥æ–‡æœ¬å’ŒäºŒç»´ç å½¢å¼æ˜¾ç¤ºã€‚\r\n3. æ‚¨å¯ä»¥å¤åˆ¶DIDæˆ–åˆ†äº«äºŒç»´ç ã€‚\r\n\r\n### æµ‹è¯•æ™ºèƒ½ä½“\r\n\r\n1. åœ¨é¦–é¡µçš„èŠå¤©æ¡†ä¸­è¾“å…¥æ¶ˆæ¯ã€‚\r\n2. ç‚¹å‡»\"å‘é€\"æŒ‰é’®æˆ–æŒ‰Enteré”®ã€‚\r\n3. æ™ºèƒ½ä½“ä¼šä»¥è„±å£ç§€æ¼”å‘˜çš„é£æ ¼å›å¤æ‚¨çš„æ¶ˆæ¯ã€‚\r\n\r\n### è¿æ¥å…¶ä»–æ™ºèƒ½ä½“\r\n\r\n1. å‰å¾€\"/connect\"é¡µé¢ã€‚\r\n2. è¾“å…¥å…¶ä»–æ™ºèƒ½ä½“çš„DIDã€‚\r\n3. ç‚¹å‡»\"è¿æ¥\"æŒ‰é’®ã€‚\r\n4. è¿æ¥æˆåŠŸåï¼Œæ‚¨å¯ä»¥å‘è¯¥æ™ºèƒ½ä½“å‘é€æ¶ˆæ¯ã€‚\r\n\r\næ‚¨è¿˜å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è¿æ¥æ™ºèƒ½ä½“:\r\n\r\n- åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€`{æ‚¨çš„åŸŸå}/connect?did={DIDå­—ç¬¦ä¸²}`\r\n- æˆ–è€…åˆ›å»ºä¸€ä¸ª`did://`åè®®é“¾æ¥: `did://{DIDå­—ç¬¦ä¸²}`\r\n\r\n## é¡¹ç›®ç»“æ„\r\n\r\n```\r\ncomedyagent/\r\nâ”œâ”€â”€ api/                  # APIè·¯ç”±\r\nâ”‚   â”œâ”€â”€ generate-did.js   # DIDç”ŸæˆAPI\r\nâ”‚   â””â”€â”€ message.js        # æ¶ˆæ¯å¤„ç†API\r\nâ”œâ”€â”€ components/           # Reactç»„ä»¶\r\nâ”œâ”€â”€ lib/                  # å·¥å…·åº“\r\nâ”‚   â”œâ”€â”€ ai.js             # AIæœåŠ¡\r\nâ”‚   â””â”€â”€ did.js            # DIDåŠŸèƒ½\r\nâ”œâ”€â”€ pages/                # é¡µé¢\r\nâ”‚   â”œâ”€â”€ index.js          # é¦–é¡µ\r\nâ”‚   â””â”€â”€ connect.js        # è¿æ¥é¡µé¢\r\nâ”œâ”€â”€ public/               # é™æ€èµ„æº\r\nâ”œâ”€â”€ styles/               # æ ·å¼æ–‡ä»¶\r\nâ”‚   â”œâ”€â”€ Home.module.css   # é¦–é¡µæ ·å¼\r\nâ”‚   â””â”€â”€ Connect.module.css# è¿æ¥é¡µé¢æ ·å¼\r\nâ”œâ”€â”€ package.json          # é¡¹ç›®é…ç½®\r\nâ””â”€â”€ vercel.json           # Vercelé…ç½®\r\n```\r\n\r\n## è‡ªå‹ç¼©DIDè¯¦è§£\r\n\r\næœ¬é¡¹ç›®ä¸­çš„è‡ªå‹ç¼©DIDæ˜¯ä¸€ç§åˆ›æ–°çš„æ•°å­—èº«ä»½è¡¨ç¤ºæ–¹å¼ï¼ŒåŒ…å«äº†ä»¥ä¸‹ä¿¡æ¯:\r\n\r\n- èº«ä»½æ ‡è¯†\r\n- å…¬é’¥\r\n- æœåŠ¡ç«¯ç‚¹\r\n- å…ƒæ•°æ®\r\n- æ•°å­—ç­¾å\r\n\r\nä¸ä¼ ç»ŸDIDä¸åŒï¼Œè‡ªå‹ç¼©DIDå°†æ‰€æœ‰å¿…è¦ä¿¡æ¯ç¼–ç åœ¨ä¸€ä¸ªå­—ç¬¦ä¸²ä¸­ï¼Œæ— éœ€æŸ¥è¯¢é¢å¤–æœåŠ¡å™¨å³å¯è·å–èº«ä»½ä¿¡æ¯å’Œé€šä¿¡æ–¹å¼ã€‚\r\n\r\n## è®¸å¯è¯\r\n\r\nMIT ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "agents",
        "assistant",
        "ai assistant",
        "ai agents",
        "connects ai"
      ],
      "category": "virtual-assistants"
    },
    "mfukushim--map-traveler-mcp": {
      "owner": "mfukushim",
      "name": "map-traveler-mcp",
      "url": "https://github.com/mfukushim/map-traveler-mcp",
      "imageUrl": "https://github.com/mfukushim.png",
      "description": "Create immersive travel experiences by navigating Google Maps with an avatar, providing real-time updates and photos of the journey. Integrate unique travel narratives and social media interactions during the exploration.",
      "stars": 23,
      "forks": 10,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-02T03:51:13Z",
      "readme_content": "# Virtual Traveling bot environment for MCP\n\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/073d88cc-277d-40b6-8c20-bcabf6c275e9)\n[![smithery badge](https://smithery.ai/badge/@mfukushim/map-traveler-mcp)](https://smithery.ai/server/@mfukushim/map-traveler-mcp)\n\nEnglish / [Japanese](./README_jp.md)\n\nThis is an MCP server that creates an environment for an avatar to virtually travel on Google Maps.\n\nFrom an MCP client such as Claude Desktop, you can give instructions to the avatar and report on the progress of its journey with photos.\n\n<img alt=\"img_5.png\" src=\"https://raw.githubusercontent.com/mfukushim/map-traveler-mcp/for_image/tools/img_5.png\" width=\"400\"/>\n\n> Preparing for MCP Registry Support https://blog.modelcontextprotocol.io/posts/2025-09-08-mcp-registry-preview/  \n\n> Added gemini-2.5-flash-image-preview (nano-banana) to travel image generation  \n\nSupport for nano-banana has been added. Nano-banana's semantic mask allows you to generate composite travel images in a short time without setting remBg.  \nAlthough conventional image synthesis is still possible, we recommend using Gemini nano-banana.  \n\n> Supports both Streamable-HTTP and stdio (compliant with Smithery.ai's config interface)  \n\nIt can be used as a stdio-type MCP as before, or as Streamable-HTTP.  \nAlthough it supports multiple users, the database API must be specified per session using the Smithery.ai config interface.  \nSince it supports both Streamable-HTTP and stdio, it is expected to work as is with the previous MCP client, but if you use the previous stdio version, please use v0.0.x (v0.0.81).  \n``` npx -y @mfukushim/map-traveler-mcp@0.0.81 ```  \n\n> Now supports librechat https://www.librechat.ai/.\n\n> Now supports Smithery https://smithery.ai/server/@mfukushim/map-traveler-mcp (images are excluded because they are heavy to run).\n\n> Now verified MseeP https://mseep.ai/app/mfukushim-map-traveler-mcp \n\n## Functions\n\n#### MCP server tools function\n\nThe following functions can be used as an MCP server. The available functions vary depending on the settings and execution state.\n\nYou can specify the function name directly, but Claude LLM will automatically recognize it, so you can specify the operation in general terms.\n\nExample:\n\"Where are you now?\" \"Let's leave for Tokyo Station.\"\n\n- get_traveler_view_info(includePhoto:boolean,includeNearbyFacilities:boolean)  \n  Gets information about the current travel avatar's location.  \n  - includePhoto: Gets nearby Google Street View photos. If you have set up an image generation AI, it will synthesize the avatar.\n  - includeNearbyFacilities: Gets information about nearby facilities.\n- get_traveler_location()  \n  Gets information about the current travel avatar's address and nearby facilities.\n- reach_a_percentage_of_destination()\n  Reach a specified percentage of the destination (moveMode=skip only)\n  timeElapsedPercentage: Percent progress towards destination(0~100)\n- set_traveler_location(address: string)  \n  Sets the current travel avatar's location.\n  - address: Address information (exact address, or general name that Google Maps or Claude can recognize, etc.)\n- get_traveler_destination_address  \n  Get the destination of the travel avatar you set\n- set_traveler_destination_address(address: string)  \n  Set the destination of the travel avatar\n   - address: Address information (exact address, or general name that Google Maps or Claude can recognize, etc.)\n- start_traveler_journey  \n  Start the journey at the destination.(moveMode=realtime only)\n- stop_traveler_journey  \n  Stop the journey.(moveMode=realtime only)\n- set_traveler_info(settings:string)  \n  Set the traveler's attributes. Set the traveler's personality that you want to change dynamically, such as name and personality. However, if you use a role script, the script is more stable.\n  - settings: Setting information such as name and personality.\n- get_traveler_info  \n  Get the traveler's attributes. Get the traveler's personality.\n- set_avatar_prompt(prompt:string)  \n  Set the prompt when generating the travel avatar image. The default is an anime-style woman. The anime style is enforced to prevent fake images.\n  - prompt\n- reset_avatar_prompt  \n  Reset avatar generation prompts to default.\n- get_sns_feeds  \n  Gets Bluesky SNS articles for the specified custom feed (feeds containing a specific tag).\n- get_sns_mentions  \n  Gets recent mentions (likes, replies) to Bluesky SNS posts that you made yourself.\n- post_sns_writer(message:string)  \n  Posts an article to Bluesky SNS with the specified custom feed. Set a specific tag so that it can be determined that the post was generated by the travel bot.\n  - message: article\n- reply_sns_writer(message:string,id:string)  \n  Reply to the article with the specified id. Set a specific tag so that it can be determined that the post was generated by the travel bot.\n  - message: reply\n  - id: The ID of the post to reply to\n- add_like(id:string)  \n  Add a like to the specified post.\n  - id: The ID of the post to like\n- tips  \n  Guides you on how to set up features that have not yet been set.\n- get_setting  \n  Get environment and image settings.\n\n#### MCP resources\n\nHas five custom prompt samples.\nWhen you import a prompt with Claude Desktop, Claude will act as a traveler.\nThe SNS-compatible version controls SNS input and output while having a travel conversation.\n\n- role.txt  \n  Claude will act as a traveler.\n\n- roleWithSns.txt  \n  Claude will act as a traveler. It also controls reading and posting to SNS.\n- carBattle.txt  \n  This is a small novel game about a story of transporting secret documents from Yokohama to Tokyo. Scenes are automatically generated. Set moveMode=skip to play.\n- japanMapChallenge.txt,japanMapChallenge2.txt  \n  Two AIs communicate with each other via SNS and play a challenge game using landscape images.  \n  To play, you need two Bluesky accounts and two Claude Desktops. Also set moveMode=skip. (However, the operation is somewhat unstable.)  \n  japanMapChallenge2 has a challenge reflection rule.\n\n## Setting\n\nYou will need to obtain and set access keys for multiple APIs, such as for accessing multiple Google maps and generating images.\nUse of the API may incur charges.\n\n#### Settings for using with Claude Desktop \n\n- claude_desktop_config.json (stdio type)\n```json\n{\n  \"mcpServers\": {\n    \"traveler\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@mfukushim/map-traveler-mcp\"],\n      \"env\":{\n        \"MT_GOOGLE_MAP_KEY\":\"(Google Map API key)\",\n        \"MT_GEMINI_IMAGE_KEY\": \"(Gemini Image Api key)\",\n        \"MT_MAX_RETRY_GEMINI\": \"(Number of retries when generating Gemini images Default: 0)\",\n        \"MT_AVATAR_IMAGE_URI\": \"(Character reference image uri (file:// or https://) when generating Gemini image. Multiple settings can be made by separating them with the '|'. When multiple settings are made, they will be selected randomly.)\",\n        \"MT_MAP_API_URL\": \"(Optional: Map API custom endpoint. Example: direction=https://xxxx,places=https://yyyy )\",\n        \"MT_TIME_SCALE\": \"(Optional:Scale of travel time on real roads duration. default 4)\",\n        \"MT_SQLITE_PATH\":\"(db save path: e.g. %USERPROFILE%/Desktop/traveler.sqlite ,$HOME/traveler.sqlite )\",\n        \"MT_TURSO_URL\":\"(Turso sqlite API URL)\",\n        \"MT_TURSO_TOKEN\":\"(Turso sqlite API access token)\",\n        \"MT_REMBG_PATH\": \"(absolute path of the installed rembg cli)\",\n        \"MT_REMBG_URL\": \"(rembg API URL)\",\n        \"MT_REMBG_WO_KEY\": \"(withoutbg.com rembg API key)\",\n        \"MT_PIXAI_KEY\":\"(pixAi API key)\",\n        \"MT_SD_KEY\":\"(or Stability.ai image generation API key\",\n        \"MT_PIXAI_MODEL_ID\": \"(Optional: pixAi ModelId, if not set use default model 1648918127446573124 \",\n        \"MT_COMFY_URL\": \"(Option: Generate image using ComfyUI API at specified URL. Example: http://192.168.1.100:8188)\",\n        \"MT_COMFY_WORKFLOW_T2I\": \"(Optional: Path to API workflow file when using text to image with ComfyUI. If not specified: assets/comfy/t2i_sample.json)\",\n        \"MT_COMFY_WORKFLOW_I2I\": \"(Optional: Path of API workflow file when image to image in ComfyUI. If not specified: assets/comfy/i2i_sample.json)\",\n        \"MT_COMFY_PARAMS\": \"(Optional: Variable values to send to the workflow via comfyUI API)\",\n        \"MT_FIXED_MODEL_PROMPT\": \"(Optional: Fixed avatar generation prompt. You will no longer be able to change your avatar during conversations.)\",\n        \"MT_BODY_AREA_RATIO\": \"(Optional: Acceptable avatar image area ratio. default 0.042)\",\n        \"MT_BODY_HW_RATIO\": \"(Optional: Acceptable avatar image aspect ratios. default 1.5~2.3)\",\n        \"MT_BODY_WINDOW_RATIO_W\": \"(Optional: Avatar composite window horizontal ratio. default 0.5)\",\n        \"MT_BODY_WINDOW_RATIO_H\": \"(Optional: Avatar composite window aspect ratio. default 0.75)\",\n        \"MT_BS_ID\":\"(Bluesky sns registration address)\",\n        \"MT_BS_PASS\":\"(bluesky sns password)\",\n        \"MT_BS_HANDLE\":\"(bluesky sns handle name: e.g. xxxxxxxx.bsky.social )\",\n        \"MT_FILTER_TOOLS\": \"(Optional: Directly filter the tools to be used. All are available if not specified. e.g. tips,set_traveler_location)\",\n        \"MT_MOVE_MODE\": \"(Option: Specify whether the movement mode is realtime or skip. default realtime)\",\n        \"MT_IMAGE_WIDTH\": \"(Option: Output image width (pixels) Default is 512)\",\n        \"MT_NO_IMAGE\": \"(Options: true = do not output image, not specified = output image if possible, default is not specified)\",\n        \"MT_NO_AVATAR\": \"(Option: true = Output StreetView image as is without avatar superimposition. Not specified = Superimpose avatar image. Default is not specified.)\",\n        \"MT_FEED_TAG\": \"(Optional: Specify the feed tag when posting to SNS (#required, 15 characters or more) Default is #geo_less_traveler)\",\n        \"MT_MAX_SESSIONS\": \"(Maximum number of sessions when using Streamable-http)\",\n        \"MT_SESSION_TTL_MS\": \"(Session TTL when using Streamable-http)\",\n        \"MT_SERVICE_TTL_MS\": \"(Service TTL when using Streamable-http)\"\n      }\n    }\n  }\n}\n```  \n\n- claude_desktop_config.json (streamable-http type)  \nThe above MT_ environment variables should be set as environment variables for the server that runs the map-traveler-mcp web service.  \n```json\n{\n  \"mcpServers\": {\n    \"traveler\": {\n      \"type\": \"streamable-http\",\n      \"url\": \"https://(mcp server address)/mcp?config=(base64 config json)\"\n    }\n  }\n}\n```  \n\nbase64 config json (Smithery.ai Expansion)  \nBy concatenating the json in the following format into a single line of string, converting it to base64, and setting it as (base64 setting json), you can overwrite different APIs and settings for each user session.  \nIf the database is not set base64 config json, it will be shared across the entire service (the location of the traveler will be shared across the database and counted for one person).  \nWe plan to reconsider the operation of assigning an individual UserId for each session once the MCP authentication mechanism has become a little clearer.  \n```json\n{\n  \"MT_GOOGLE_MAP_KEY\": \"xxxyyyzzz\",\n  \"MT_GEMINI_IMAGE_KEY\": \"xxyyzz\",\n  \"MT_MAX_RETRY_GEMINI\": \"1\",\n  \"MT_AVATAR_IMAGE_URI\": \"file:///C:/Users/xxxx/Desktop/avatar.png\",\n  \"MT_TURSO_URL\": \"libsql://xxxyyyzzz\",\n  \"MT_TURSO_TOKEN\": \"abcdabcd\",\n  \"MT_BS_ID\": \"xyxyxyxyx\",\n  \"MT_BS_PASS\": \"1234xyz\",\n  \"MT_BS_HANDLE\": \"aabbccdd\",\n  \"MT_FILTER_TOOLS\": \"tips,set_traveler_location\",\n  \"MT_MOVE_MODE\": \"direct\",\n  \"MT_FEED_TAG\": \"#abcdefgabcdefgabcdefg\"\n}\n```  \n(All json values can be omitted)  \nâ†“ (json text concatenation)  \n```text\n{\"MT_GOOGLE_MAP_KEY\": \"xxxyyyzzz\", \"MT_GEMINI_IMAGE_KEY\": \"xxyyzz\", \"MT_MAX_RETRY_GEMINI\": \"1\", \"MT_TURSO_URL\": \"libsql://xxxyyyzzz\", \"MT_TURSO_TOKEN\": \"abcdabcd\", \"MT_BS_ID\": \"xyxyxyxyx\", \"MT_BS_PASS\": \"1234xyz\", \"MT_BS_HANDLE\": \"aabbccdd\", \"MT_FILTER_TOOLS\": \"tips,set_traveler_location\", \"MT_MOVE_MODE\": \"direct\", \"MT_FEED_TAG\": \"#abcdefgabcdefgabcdefg\"}\n```\nâ†“ (Set the base64 version to config=)  \n```text\neyJNVF9HT09HTEVfTUFQX0tFWSI6ICJ4eHh5eXl6enoiLCAiTVRfR0VNSU5JX0lNQUdFX0tFWSI6ICJ4eHl5enoiLCAiTVRfTUFYX1JFVFJZX0dFTUlOSSI6ICIxIiwgIk1UX1RVUlNPX1VSTCI6ICJsaWJzcWw6Ly94eHh5eXl6enoiLCAiTVRfVFVSU09fVE9LRU4iOiAiYWJjZGFiY2QiLCAiTVRfQlNfSUQiOiAieHl4eXh5eHl4IiwgIk1UX0JTX1BBU1MiOiAiMTIzNHh5eiIsICJNVF9CU19IQU5ETEUiOiAiYWFiYmNjZGQiLCAiTVRfRklMVEVSX1RPT0xTIjogInRpcHMsc2V0X3RyYXZlbGVyX2xvY2F0aW9uIiwgIk1UX01PVkVfTU9ERSI6ICJkaXJlY3QiLCAiTVRfRkVFRF9UQUciOiAiI2FiY2RlZmdhYmNkZWZnYWJjZGVmZyJ9\n```\n\n\n> NOTE: The environment variables have been renamed to standard snake case. The MT_ prefix is added because they may be used in conjunction with other environment variables, such as in librechat. The old names can still be used for backward compatibility.  \n\nPlease set the following three Credentials for Google Map API.  \n- Street View Static API\n- Places API (New)\n- Time Zone API\n- Directions API\n\nhttps://developers.google.com/maps/documentation/streetview/get-api-key\n\nIf you want to use the image generation AI, set either pixAi_key or sd_key. You also need to have python3.7~3.11 installed on your PC and rembg cli installed (virtual environment recommended).\n\nhttps://platform.pixai.art/docs  \nhttps://platform.stability.ai/docs/api-reference#tag/SDXL-1.0-and-SD1.6/operation/textToImage\n\nThe bluesky SNS address/password are optional. It is recommended that you create a dedicated account as it will post automatically.\n\nhttps://bsky.app/\n\nYou can also run it in practice mode, which does not require an API key for verification.\n\n#### Practice mode settings  \nclaude_desktop_config.json\n```json\n{\n  \"mcpServers\": {\n    \"traveler\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@mfukushim/map-traveler-mcp\"]\n    }\n  }\n}\n```\n\n## How to use\n\n#### Use the practice mode\n\n1. Install nodejs 22.\n\n2. Set up Claude Desktop for use.\n\n3. Reflect one of the above settings in claude_desktop_config.json.\n\n4. Restart Claude Desktop. It may take some time to set up (if an error occurs, try restarting Claude Desktop again. If it doesn't work, see the notes below). Make sure the following mark appears in the bottom right of the screen.\n\n  <img alt=\"img_1.png\" src=\"https://raw.githubusercontent.com/mfukushim/map-traveler-mcp/for_image/tools/img_1.png\" width=\"150\"/>\n\n5. Ask \"Where are you now?\" and \"Go on a journey.\" A conversation will begin. When using the API, a confirmation screen will appear, so select Allow.\n\n<img alt=\"img_4.png\" src=\"https://raw.githubusercontent.com/mfukushim/map-traveler-mcp/for_image/tools/img_4.png\" width=\"200\"/>\n\n6. Select Attach from MCP and select role.txt.\n\n<img alt=\"img_2.png\" src=\"https://raw.githubusercontent.com/mfukushim/map-traveler-mcp/for_image/tools/img_2.png\" width=\"200\"/>\n\n<img alt=\"img_3.png\" src=\"https://raw.githubusercontent.com/mfukushim/map-traveler-mcp/for_image/tools/img_3.png\" width=\"200\"/>\n\n7. A travel prompt has been built in, so feel free to talk to it.\n\n#### Use the full feature\n\n1. Get a Google Map API access key and set the permissions for Street View Static API, Places API (New), Time Zone API, and Directions API. Set this in the env of claude_desktop_config.json and restart.\n   At this point, the travel log will be based on the real map. Travel images will also be output if they are not superimposed.\n2. Decide on a path that will not interfere with the disk and set it in the sqlite_path of the env of claude_desktop_config.json. (Example: %USERPROFILE%/Desktop/traveler.sqlite $HOME/Documents/traveler.sqlite, etc.)\n   At this point, your travel log will be saved and you can continue your journey even if you close Claude Desktop.\n3. Install python 3.7 to 3.11 and install rembg with cli. We recommend using a virtual environment such as venv.\n  ```bash\n  python3 -m venv venv\n  . venv/bin/activate or .\\venv\\Scripts\\activate\n  pip install \"rembg[cpu,cli]\"\n  ```\n  Check if rembg cli works properly using a sample image file. Input an image with a person in it, and if the person is cut out in the output file, it's OK.  \n  ```bash\n  rembg i source_image_file dest_image_file\n  ```\n4. rembg cli will be installed in the python exe location, so get the path. The file location varies depending on the OS and python installation status, but in the case of venv, it is (virtual environment name)\\Scripts\\rembg.exe or (virtual environment name)/bin/rembg above the directory you set. If you can't find it, search for the path with a file search software. Set that path to rembg_path of env in claude_desktop_config.json. (Example: \"rembg_path\": \"C:\\\\Users\\\\xxxx\\\\Documents\\\\rembg_venv\\\\venv\\\\Scripts\\\\rembg.exe\")\n5. Get an image generation API key from the pixAI or Stability.ai site. Set the key to pixAi_key or sd_key in env of claude_desktop_config.json.\n   The avatar will now be overlaid on the travel image.\n6. Get the bluesky SNS address/password and handle name. Set these in bs_id, bs_pass, and bs_handle in env of claude_desktop_config.json, respectively.\n   Import the travel knowledge prompt roleWithSns.txt to report travel actions to SNS (it will automatically post as a bot, so we recommend allocating a dedicated account)\n\nInstead of preparing rembg with the cli, we have added a setting that allows you to handle rembg as a service API.  \nIf you configure the following rembg service, you can use rembg by setting the URL in remBgUrl.  \n\nhttps://github.com/danielgatis/rembg?tab=readme-ov-file#rembg-s  \n\nSetup is simple if you use the Docker version to launch a container and access it.  \n\nhttps://github.com/danielgatis/rembg?tab=readme-ov-file#usage-as-a-docker  \n\n#### Use Turso libsql API for configuration database\n\nIf you want to use the cloud API Turso libsql (https://turso.tech/libsql) without having a local sqlite file, sign up for Turso and allocate a sqlite database (paid, free tier available).   \nThis add-in will automatically configure (migrate) the database.  \nMT_TURSO_URL = turso db URL  \nMT_TURSO_TOKEN = turso db access token  \n\n\n#### Use Cloud API for rembg\n\nLocal settings around rembg are complicated no matter what method you use, but we have added settings for the paid cloud rembg (https://withoutbg.com/).  \n> Note: There is a small free trial available, but please be aware that this is a commercial API and is quite expensive (about 0.1 euros per image).\n\nMT_REMBG_WO_KEY = withoutbg access token\n\n\n#### When using external ComfyUI (for more advanced users)\n\nYou can also use a local ComfyUI as an image generation server. You can configure the image generation characteristics yourself in detail to reduce API costs.\n\nHowever, the configuration will be quite complicated and image generation may take longer.\n\n1. Configure ComfyUI to run in API mode.\n2. Set the server URL to comfy_url in env.\n3. Set detailed configuration values such as the model to be used in env in the form of a json string.\nexample.\n```json\n{\n  \"env\": {\n    \"comfy_url\": \"http://192.168.1.100:8188\",\n    \"comfy_workflow_t2i\": \"C:\\\\Documents\\\\t2itest.json\",\n    \"comfy_workflow_i2i\":\"C:\\\\Documents\\\\i2itest.json\",\n    \"comfy_params\":\"ckpt_name='animagineXL40_v40.safetensors',denoise=0.65\"\n  }\n}\n```\n4. The default workflow can use assets/comfy/t2i_sample.json and assets/comfy/i2i_sample.json in the package. You can specify variables using % and specify the variables in comfy_params.\n\n## Using libreChat\n\nIt has been adapted to work with libreChat. This makes it easier to use, but some additional settings are required.  \nAlso, it seems that it will not be stable unless the PC you use has a decent level of performance, such as one that can stably run Docker.\n\n#### Install libreChat  \n\nPlease make sure it works as described on the official website.  \nIn this case, we recommend using Docker configuration due to additional settings.\n\nhttps://www.librechat.ai/docs/local/docker  \n\nConfigure librechat.yaml using the official procedure.  \nI think you will need to add a local or API LLM service.  \n\nhttps://www.librechat.ai/docs/configuration/librechat_yaml  \n\nAdd a user for login.  \n\nhttps://www.librechat.ai/docs/configuration/authentication#create-user-script  \n\nPlease set it so that you can have general chat conversations.  \n\n#### Add a rembg container with additional settings  \n\nTo use rembg with Docker, add pulling and running the rembg Docker container.  \n\ndocker-compose.override.yml\n```yml\n services:\n   api:\n     volumes:\n       - type: bind\n         source: ./librechat.yaml\n         target: /app/librechat.yaml\n\n   rembg:\n     image: danielgatis/rembg:latest\n     restart: always\n     command: \"s --host 0.0.0.0 --port 7000 --log_level info\"\n\n```\n\n#### Add map-traveler-mcp to the MCP service  \n\nAdd librechat.yaml\n```yaml\nmcpServers:\n  traveler:\n    type: stdio\n    command: npx\n    args:\n      - -y\n      - \"@mfukushim/map-traveler-mcp\"\n```\n\nAdd .env (Same as env in claude_desktop_config.json)\n\n```env\n# map-traveler-mcp\nGoogleMapApi_key=(Google Map API key)\nsqlite_path=/home/run_test.sqlite (e.g. librechat in an unobtrusive location inside the container, or in an external directory that you don't want to mount.)\nremBgUrl=http://rembg:7000 (rembg Service API URL, container URL)\n(Other settings such as image generation AI settings, PixAI key, stability.ai API key, ComfyUI settings, etc.)\n\n```\n\nAfter setting, restart the container.  \nOn slow PCs, mcp initialization may fail. Multiple restarts may work, but this may be difficult to run...\n\n#### llibreChat settings\n\nTo use the MCP function in libreChat, use the Agents function.  \n\n1. On the conversation screen, select Agents.  \n   <img alt=\"libre1.png\" src=\"https://raw.githubusercontent.com/mfukushim/map-traveler-mcp/for_image/tools/libre1.png\" width=\"200\"/>\n2. Select Agent Builder from the panel on the right side of the screen and configure your agent.  \n   <img alt=\"libre2.png\" src=\"https://raw.githubusercontent.com/mfukushim/map-traveler-mcp/for_image/tools/libre2.png\" width=\"200\"/>\n3. Select Add Tools to use map-traveler.  \n   <img alt=\"libre3.png\" src=\"https://raw.githubusercontent.com/mfukushim/map-traveler-mcp/for_image/tools/libre3.png\" width=\"200\"/>\n4. The agent tools screen will appear, so select and add all the map-traveler-mcp tools (if the map-traveler-mcp tools are not listed, MCP initialization has failed, so please restart the container or review the settings by checking the logs, etc.)  \n   <img alt=\"libre4.png\" src=\"https://raw.githubusercontent.com/mfukushim/map-traveler-mcp/for_image/tools/libre4.png\" width=\"200\"/>  \n   <img alt=\"libre5.png\" src=\"https://raw.githubusercontent.com/mfukushim/map-traveler-mcp/for_image/tools/libre5.png\" width=\"200\"/>  \n5. Enter additional script in the instruction area.  \n   Since libreChat does not have the MCP resource function, enter the content text of the following URL into the instruction area instead.   \n   https://github.com/mfukushim/map-traveler-mcp/blob/main/assets/scenario/role.txt  \n   <img alt=\"libre7.png\" src=\"https://raw.githubusercontent.com/mfukushim/map-traveler-mcp/for_image/tools/libre7.png\" width=\"200\"/>  \n6. Click the Create button to save the agent.  \n   <img alt=\"libre6.png\" src=\"https://raw.githubusercontent.com/mfukushim/map-traveler-mcp/for_image/tools/libre6.png\" width=\"200\"/>\n7. Start a new chat.\n\n## Smithery\n\nPlease refer to https://smithery.ai/server/@mfukushim/map-traveler-mcp.  \nRemote MCP (Streamable-http mode) is supported. Image generation is only available on nano-banana.  \nDatabase settings can now be recorded with Turso sqlite, so if you configure Turso, your travel progress will also be saved.  \n<img alt=\"smithery.png\" src=\"tools/smithery.png\" width=\"400\"/>\n\n\n\n## Install guide (Japanese, but lots of photos)\n\n1. introduction and Practice mode  \n   https://note.com/marble_walkers/n/n7a8f79e4fb30\n2. DB, Google Map API, Image gen API  \n   https://note.com/marble_walkers/n/n765257c27f3b\n3. Avatar prompt  \n   https://note.com/marble_walkers/n/nc7273724faea\n4. SNS integration  \n   https://note.com/marble_walkers/n/na7c956befe7b\n5. Application 1  \n   https://note.com/marble_walkers/n/n3c86edd8e817\n6. ComfyUI API  \n   https://note.com/marble_walkers/n/ncefc7c05d102  \n7. Application 2  \n   https://note.com/marble_walkers/n/ne7584ed231c8\n8. LibreChat setting  \n   https://note.com/marble_walkers/n/n339bf7905324\n9. AI Agent SNS Battle Map Challenge  \n   https://note.com/marble_walkers/n/n6db937573eaa\n10. Support Smithery, Turso libSQL, and rembg API   \n   https://note.com/marble_walkers/n/ne3b3c0f99707\n11. Streamable-HTTP support  \n    https://note.com/marble_walkers/n/n030063f22dc0\n12. Nano-Banana support  \n    https://note.com/marble_walkers/n/n5d49514dddec  \n\n\n#### Additional about the source code\n\nI use Effect.ts to simplify error management & for my own learning.  \nWe also use the Effect Service, but due to the way MCP calls work, we believe that consolidating it using the Service was not optimal.  \nI think it would be simpler to handle the MCP calls directly in the Effect.  \nAddendum: I'm aware that I will be able to reconsider how to use the Effect Service and rewrite it neatly, but I'm still considering whether to rewrite it.  \n\n#### Notes on the latest updates\n\n- Added image_width to env. The default is 512. Setting it smaller may reduce the cost of LLM API.  \n- Added an env setting that does not output images for MCP clients that do not have image input/output.  \n\"MT_NO_IMAGE\": \"true\" will not generate or output any images. Other image-related settings can be omitted.  \n```\n{\n  \n  \"env\": {\n    \"MT_NO_IMAGE\": \"true\"\n  }\n  \n}\nor\n{\n  \n  \"env\": {\n    \"GoogleMapApi_key\": \"xxxx\",\n    \"MT_NO_IMAGE\": \"true\"\n  }\n  \n}\n\n```  \n- You can now specify the tag name to be added when posting to SNS (Bluesky). #Required and must be at least 15 characters. If not specified, it will become \"#geo_less_traveler\".  \n- The information obtained from SNS has been slightly changed. The information posted to SNS has been slightly changed.  \n- A script has been added that allows multiple travel bots to converse and play via SNS.  \n\n- Supports remote use from Smithery.  \n  If you do not want to configure detailed settings, start the app in practice mode.\n  You can also run the app at full speed by configuring each cloud API, but please be aware of charges as it uses many paid APIs such as rembg API.\n  If you do not want to synthesize avatars, you can run the app with the minimum settings of Google Map API and Turso sqlite API.\n\n- Added the MT_NO_AVATAR option.  \n  If set, an avatar image will not be composited onto the landscape image. Since there will be no retry processing for avatar composition, the time it takes to obtain a response will be significantly shorter.  \n  Set this option if image composition is slow or fails unavoidably.\n\n- Partially applied MCP version 2025-06-18.  \n  I added title to the schema. I plan to apply outputSchema and structured response in the future, but I haven't implemented them this time. Since the output of Travel Bot is simple text, I don't think structuring is necessary yet.  \n  https://modelcontextprotocol.io/specification/2025-06-18/server/tools  \n- Fixed an issue where some functions, such as SNS functions, could not be called regardless of the env settings due to an initialization error.  \n\n- Added support for Streamable-http. This was done in a hurry, so if you experience any issues, please consider using version 0.0.81 or similar.  \n\n- Support for nano-banana (gemini-2.5-flash-image-preview) image generation has been added. When using nano-banana, no rembg settings are required. The characteristics of the avatar prompt have changed, so image generation may fail with the previous avatar prompt. In this case, you will need to adjust the avatar appearance prompt to one that is acceptable for nano-banana.\n\n- When generating images for nano-banana, you can now reference the original character image with MT_AVATAR_IMAGE_URI. Please use it in a way that does not infringe on copyrights.\n\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/mfukushim-map-traveler-mcp-badge.png)](https://mseep.ai/app/mfukushim-map-traveler-mcp)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "traveler",
        "maps",
        "immersive",
        "map traveler",
        "traveler mcp",
        "immersive travel"
      ],
      "category": "virtual-assistants"
    },
    "mrexodia--user-feedback-mcp": {
      "owner": "mrexodia",
      "name": "user-feedback-mcp",
      "url": "https://github.com/mrexodia/user-feedback-mcp",
      "imageUrl": "https://github.com/mrexodia.png",
      "description": "Facilitates a feedback loop in tools for desktop application development by collecting user insights during complex interactions. Enhances testing processes by prompting users for feedback before task completion.",
      "stars": 47,
      "forks": 8,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-04T14:06:32Z",
      "readme_content": "# User Feedback MCP\r\n\r\nSimple [MCP Server](https://modelcontextprotocol.io/introduction) to enable a human-in-the-loop workflow in tools like [Cline](https://cline.bot) and [Cursor](https://www.cursor.com). This is especially useful for developing desktop applications that require complex user interactions to test.\r\n\r\n![Screenshot showing the feedback UI](https://github.com/mrexodia/user-feedback-mcp/blob/main/.github/feedback-ui.png?raw=true)\r\n\r\n## Prompt Engineering\r\n\r\nFor the best results, add the following to your custom prompt:\r\n\r\n> Before completing the task, use the user_feedback MCP tool to ask the user for feedback.\r\n\r\nThis will ensure Cline uses this MCP server to request user feedback before marking the task as completed.\r\n\r\n## `.user-feedback.json`\r\n\r\nHitting _Save Configuration_ creates a `.user-feedback.json` file in your project directory that looks like this:\r\n\r\n```json\r\n{\r\n  \"command\": \"npm run dev\",\r\n  \"execute_automatically\": false\r\n}\r\n```\r\n\r\nThis configuration will be loaded on startup and if `execute_automatically` is enabled your `command` will be instantly executed (you will not have to click _Run_ manually). For multi-step commands you should use something like [Task](https://taskfile.dev).\r\n\r\n## Installation (Cline)\r\n\r\nTo install the MCP server in Cline, follow these steps (see screenshot):\r\n\r\n![Screenshot showing installation steps](https://github.com/mrexodia/user-feedback-mcp/blob/main/.github/cline-installation.png?raw=true)\r\n\r\n1. Install [uv](https://github.com/astral-sh/uv) globally:\r\n   - Windows: `pip install uv`\r\n   - Linux/Mac: `curl -LsSf https://astral.sh/uv/install.sh | sh`\r\n2. Clone this repository, for this example `C:\\MCP\\user-feedback-mcp`.\r\n3. Navigate to the Cline _MCP Servers_ configuration (see screenshot).\r\n4. Click on the _Installed_ tab.\r\n5. Click on _Configure MCP Servers_, which will open `cline_mcp_settings.json`.\r\n6. Add the `user-feedback-mcp` server:\r\n\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"github.com/mrexodia/user-feedback-mcp\": {\r\n      \"command\": \"uv\",\r\n      \"args\": [\r\n        \"--directory\",\r\n        \"c:\\\\MCP\\\\user-feedback-mcp\",\r\n        \"run\",\r\n        \"server.py\"\r\n      ],\r\n      \"timeout\": 600,\r\n      \"autoApprove\": [\r\n        \"user_feedback\"\r\n      ]\r\n    }\r\n  }\r\n}\r\n\r\n```\r\n\r\n## Development\r\n\r\n```sh\r\nuv run fastmcp dev server.py\r\n```\r\n\r\nThis will open a web interface at http://localhost:5173 and allow you to interact with the MCP tools for testing.\r\n\r\n## Available tools\r\n\r\n```\r\n<use_mcp_tool>\r\n<server_name>github.com/mrexodia/user-feedback-mcp</server_name>\r\n<tool_name>user_feedback</tool_name>\r\n<arguments>\r\n{\r\n  \"project_directory\": \"C:/MCP/user-feedback-mcp\",\r\n  \"summary\": \"I've implemented the changes you requested.\"\r\n}\r\n</arguments>\r\n</use_mcp_tool>\r\n```",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mrexodia",
        "feedback",
        "assistants",
        "virtual assistants",
        "assistants mrexodia",
        "facilitates feedback"
      ],
      "category": "virtual-assistants"
    },
    "mrgeeko--vapi-mcp": {
      "owner": "mrgeeko",
      "name": "vapi-mcp",
      "url": "https://github.com/mrgeeko/vapi-mcp",
      "imageUrl": "https://github.com/mrgeeko.png",
      "description": "Integrate voice AI capabilities into applications for managing voice assistants and conducting outbound calls. Provides advanced features for enhancing user interactions through voice conversations.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2025-04-07T08:10:10Z",
      "readme_content": "# Vapi MCP for Cursor\n\nThis project implements a Model Context Protocol (MCP) server for integrating Vapi's voice AI capabilities with Cursor.\n\n## Setup Instructions\n\n### 1. Project Structure\n\nThe Vapi MCP server is structured as follows:\n- `vapi-mcp-server/` - Main server code\n  - `src/` - TypeScript source files\n  - `dist/` - Compiled JavaScript output\n  - `.env` - Environment variables for API keys\n\n### 2. Environment Configuration\n\nCreate a `.env` file in the `vapi-mcp-server` directory with the following variables:\n\n```\n# Vapi API Keys\nVAPI_ORG_ID=your-org-id\nVAPI_PRIVATE_KEY=your-private-key\nVAPI_KNOWLEDGE_ID=your-knowledge-id\nVAPI_JWT_PRIVATE=your-jwt-private\n\n# Environment\nNODE_ENV=development\n```\n\n### 3. Building the Server\n\nTo build the server:\n\n```bash\ncd vapi-mcp/vapi-mcp-server\nnpm install\nnpm run build\n```\n\n### 4. Configuration in Cursor\n\n#### Important: Avoiding \"Client Closed\" Errors\n\nWhen configuring the Vapi MCP server in Cursor's MCP settings, pay attention to the following crucial details:\n\n1. **Working Directory**: The `cwd` parameter is required to ensure the server runs in the correct directory and can access the `.env` file properly.\n\n2. **Environment Variables**: Must be explicitly provided in the configuration, even if they exist in the `.env` file.\n\n3. **Module Type**: The server uses ES modules, so the `package.json` must include `\"type\": \"module\"`.\n\nHere's the correct configuration for `.cursor/mcp.json`:\n\n```json\n\"Vapi Voice AI Tools\": {\n  \"command\": \"node\",\n  \"type\": \"stdio\",\n  \"args\": [\n    \"/Users/matthewcage/Documents/AA-GitHub/MCP/vapi-mcp/vapi-mcp-server/dist/index.js\"\n  ],\n  \"cwd\": \"/Users/matthewcage/Documents/AA-GitHub/MCP/vapi-mcp/vapi-mcp-server\",\n  \"env\": {\n    \"VAPI_ORG_ID\": \"your-org-id\",\n    \"VAPI_PRIVATE_KEY\": \"your-private-key\",\n    \"VAPI_KNOWLEDGE_ID\": \"your-knowledge-id\",\n    \"VAPI_JWT_PRIVATE\": \"your-jwt-private\",\n    \"NODE_ENV\": \"development\"\n  }\n}\n```\n\n## Troubleshooting\n\n### \"Client Closed\" Error in Cursor\n\nIf you see \"Client Closed\" in the Cursor MCP Tools panel:\n\n1. **Check Working Directory**: Ensure the `cwd` parameter is set correctly in your mcp.json\n2. **Verify Environment Variables**: Make sure all required environment variables are passed in the configuration\n3. **Check Module Type**: Ensure `package.json` has `\"type\": \"module\"`\n4. **Inspect Permissions**: Make sure the dist/index.js file is executable (`chmod +x dist/index.js`)\n5. **Test Server Directly**: Run the server manually to check for errors:\n   ```bash\n   cd vapi-mcp/vapi-mcp-server\n   node --trace-warnings dist/index.js\n   ```\n\n### Module Not Found Errors\n\nIf you get \"Error: Cannot find module\" when running:\n\n1. **Check Working Directory**: Are you running from the correct directory?\n2. **Rebuild**: Try rebuilding the project with `npm run build`\n3. **Dependencies**: Ensure all dependencies are installed with `npm install`\n\n## Available Tools\n\nThe Vapi MCP server provides the following tools:\n\n1. **vapi_call** - Make outbound calls using Vapi's voice AI\n2. **vapi_assistant** - Manage voice assistants (create, get, list, update, delete)\n3. **vapi_conversation** - Retrieve conversation details from calls\n\n## Lessons Learned\n\n1. When integrating with Cursor's MCP:\n   - Always specify the `cwd` parameter to ensure the server runs in the correct directory\n   - Pass all required environment variables directly in the MCP configuration\n   - For ES modules, ensure package.json has `\"type\": \"module\"` and tsconfig.json uses appropriate module settings\n   - Test the server directly before configuring in Cursor\n\n2. The server command path must be absolute and correctly formed in the Cursor MCP config\n\n3. Using stdio transport type is required for proper integration with Cursor ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "voice",
        "vapi",
        "assistants",
        "voice assistants",
        "voice ai",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "popcornspace--voice-call-mcp-server": {
      "owner": "popcornspace",
      "name": "voice-call-mcp-server",
      "url": "https://github.com/popcornspace/voice-call-mcp-server",
      "imageUrl": "https://github.com/popcornspace.png",
      "description": "Facilitates voice call management through Twilio and OpenAI, enabling real-time audio processing for interactive conversations with AI assistants. Offers pre-built prompts for common scenarios to streamline call initiation and handling.",
      "stars": 49,
      "forks": 9,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-18T23:39:26Z",
      "readme_content": "# Voice Call MCP Server\n\nA Model Context Protocol (MCP) server that enables Claude and other AI assistants to initiate and manage voice calls using Twilio and OpenAI (GPT-4o Realtime model).\n\nUse this as a base to kick-start your AI-powered voice calling explorations, save time and develop additional functionality on top of it.\n\n![Demo](./assets/demo.gif)\n\n\n## Sequence Diagram\n\n```mermaid\nsequenceDiagram\n    participant AI as AI Assistant (e.g., Claude)\n    participant MCP as MCP Server\n    participant Twilio as Twilio\n    participant Phone as Destination Phone\n    participant OpenAI as OpenAI\n    \n    AI->>MCP: 1) Initiate outbound call request <br>(POST /calls)\n    MCP->>Twilio: 2) Place outbound call via Twilio API\n    Twilio->>Phone: 3) Ring the destination phone\n    Twilio->>MCP: 4) Call status updates & audio callbacks (webhooks)\n    MCP->>OpenAI: 5) Forward real-time audio to OpenaAI's realtime model\n    OpenAI->>MCP: 6) Return voice stream\n    MCP->>Twilio: 7) Send voice stream\n    Twilio->>Phone: 8) Forward voice stream\n    Note over Phone: Two-way conversation continues <br>until the call ends\n```\n\n\n## Features\n\n- Make outbound phone calls via Twilio ğŸ“\n- Process call audio in real-time with GPT-4o Realtime model ğŸ™ï¸\n- Real-time language switching during calls ğŸŒ\n- Pre-built prompts for common calling scenarios (like restaurant reservations) ğŸ½ï¸\n- Automatic public URL tunneling with ngrok ğŸ”„\n- Secure handling of credentials ğŸ”’\n\n## Why MCP?\n\nThe Model Context Protocol (MCP) bridges the gap between AI assistants and real-world actions. By implementing MCP, this server allows AI models like Claude to:\n\n1. Initiate actual phone calls on behalf of users\n2. Process and respond to real-time audio conversations\n3. Execute complex tasks requiring voice communication\n\nThis open-source implementation provides transparency and customizability, allowing developers to extend functionality while maintaining control over their data and privacy.\n\n## Requirements\n\n- Node.js >= 22\n  - If you need to update Node.js, we recommend using `nvm` (Node Version Manager):\n    ```bash\n    nvm install 22\n    nvm use 22\n    ```\n- Twilio account with API credentials\n- OpenAI API key\n- Ngrok Authtoken\n\n## Installation\n\n### Manual Installation\n\n1. Clone the repository\n   ```bash\n   git clone https://github.com/lukaskai/voice-call-mcp-server.git\n   cd voice-call-mcp-server\n   ```\n\n2. Install dependencies and build\n   ```bash\n   npm install\n   npm run build\n   ```\n\n## Configuration\n\nThe server requires several environment variables:\n\n- `TWILIO_ACCOUNT_SID`: Your Twilio account SID\n- `TWILIO_AUTH_TOKEN`: Your Twilio auth token\n- `TWILIO_NUMBER`: Your Twilio number\n- `OPENAI_API_KEY`: Your OpenAI API key\n- `NGROK_AUTHTOKEN`: Your ngrok authtoken\n- `RECORD_CALLS`: Set to \"true\" to record calls (optional)\n\n### Claude Desktop Configuration\n\nTo use this server with Claude Desktop, add the following to your configuration file:\n\n**macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n\n**Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"voice-call\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/your/mcp-new/dist/start-all.cjs\"],\n      \"env\": {\n        \"TWILIO_ACCOUNT_SID\": \"your_account_sid\",\n        \"TWILIO_AUTH_TOKEN\": \"your_auth_token\",\n        \"TWILIO_NUMBER\": \"your_e.164_format_number\",\n        \"OPENAI_API_KEY\": \"your_openai_api_key\",\n        \"NGROK_AUTHTOKEN\": \"your_ngrok_authtoken\"\n      }\n    }\n  }\n}\n```\n\nAfter that, restart Claude Desktop to reload the configuration. \nIf connected, you should see Voice Call under the ğŸ”¨ menu.\n\n## Example Interactions with Claude\n\nHere are some natural ways to interact with the server through Claude:\n\n1. Simple call:\n```\nCan you call +1-123-456-7890 and let them know I'll be 15 minutes late for our meeting?\n```\n\n2. Restaurant reservation:\n```\nPlease call Delicious Restaurant at +1-123-456-7890 and make a reservation for 4 people tonight at 7:30 PM. Please speak in German.\n```\n\n3. Appointment scheduling:\n```\nPlease call Expert Dental NYC (+1-123-456-7899) and reschedule my Monday appointment to next Friday between 4â€“6pm.\n```\n\n## Important Notes\n\n1. **Phone Number Format**: All phone numbers must be in E.164 format (e.g., +11234567890)\n2. **Rate Limits**: Be aware of your Twilio and OpenAI account's rate limits and pricing\n3. **Voice Conversations**: The AI will handle natural conversations in real-time\n4. **Call Duration**: Be mindful of call durations as they affect OpenAI API and Twilio costs\n5. **Public Exposure**: Be aware that the ngrok tunnel exposes your server publicly for Twilio to reach it (though with a random URL and protected by a random secret)\n\n## Troubleshooting\n\nCommon error messages and solutions:\n\n1. \"Phone number must be in E.164 format\"\n   - Make sure the phone number starts with \"+\" and the country code\n\n2. \"Invalid credentials\"\n   - Double-check your TWILIO_ACCOUNT_SID and TWILIO_AUTH_TOKEN. You can copy them from the [Twilio Console](https://console.twilio.com)\n\n3. \"OpenAI API error\"\n   - Verify your OPENAI_API_KEY is correct and has sufficient credits\n\n4. \"Ngrok tunnel failed to start\"\n   - Ensure your NGROK_AUTHTOKEN is valid and not expired\n\n5. \"OpenAI Realtime does not detect the end of voice input, or is lagging.\"\n   - Sometimes, there might be voice encoding issues between Twilio and the receiver's network operator. Try using a different receiver.\n\n## Contributing\n\nContributions are welcome! Here are some areas we're looking to improve:\n\n- Implement support for multiple AI models beyond the current implementation\n- Add database integration to store conversation history locally and make it accessible for AI context\n- Improve latency and response times to enhance call experiences\n- Enhance error handling and recovery mechanisms\n- Add more pre-built conversation templates for common scenarios\n- Implement improved call monitoring and analytics\n\nIf you'd like to contribute, please open an issue to discuss your ideas before submitting a pull request.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Security\n\nPlease do not include any sensitive information (like phone numbers or API credentials) in GitHub issues or pull requests. This server handles sensitive communications; deploy it responsibly and ensure all credentials are kept secure.\n\n\n## Time For a New Mission?\n\nWeâ€™re hiring engineers to build at the frontier of voice AI â€” and bake it into a next-gen telco.\n\nCurious? Head to [careers.popcorn.space](https://careers.popcorn.space/apply) ğŸ¿Â !\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "twilio",
        "voice",
        "audio",
        "virtual assistants",
        "voice mcp",
        "twilio openai"
      ],
      "category": "virtual-assistants"
    },
    "rsagacom--chatgpt-on-wechat": {
      "owner": "rsagacom",
      "name": "chatgpt-on-wechat",
      "url": "https://github.com/rsagacom/chatgpt-on-wechat",
      "imageUrl": "https://github.com/rsagacom.png",
      "description": "A multi-platform intelligent dialogue service that supports text, voice, and image interactions. It can connect to various AI models and allows for custom enterprise AI applications through plugin extensions.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2024-01-28T14:00:49Z",
      "readme_content": "# ç®€ä»‹\n\n> æœ¬é¡¹ç›®æ˜¯åŸºäºå¤§æ¨¡å‹çš„æ™ºèƒ½å¯¹è¯æœºå™¨äººï¼Œæ”¯æŒå¾®ä¿¡ã€ä¼ä¸šå¾®ä¿¡ã€å…¬ä¼—å·ã€é£ä¹¦ã€é’‰é’‰æ¥å…¥ï¼Œå¯é€‰æ‹©GPT3.5/GPT4.0/Claude/æ–‡å¿ƒä¸€è¨€/è®¯é£æ˜Ÿç«/é€šä¹‰åƒé—®/Gemini/LinkAIï¼Œèƒ½å¤„ç†æ–‡æœ¬ã€è¯­éŸ³å’Œå›¾ç‰‡ï¼Œé€šè¿‡æ’ä»¶è®¿é—®æ“ä½œç³»ç»Ÿå’Œäº’è”ç½‘ç­‰å¤–éƒ¨èµ„æºï¼Œæ”¯æŒåŸºäºè‡ªæœ‰çŸ¥è¯†åº“å®šåˆ¶ä¼ä¸šAIåº”ç”¨ã€‚\n\næœ€æ–°ç‰ˆæœ¬æ”¯æŒçš„åŠŸèƒ½å¦‚ä¸‹ï¼š\n\n- [x] **å¤šç«¯éƒ¨ç½²ï¼š** æœ‰å¤šç§éƒ¨ç½²æ–¹å¼å¯é€‰æ‹©ä¸”åŠŸèƒ½å®Œå¤‡ï¼Œç›®å‰å·²æ”¯æŒä¸ªäººå¾®ä¿¡ã€å¾®ä¿¡å…¬ä¼—å·å’Œã€ä¼ä¸šå¾®ä¿¡ã€é£ä¹¦ã€é’‰é’‰ç­‰éƒ¨ç½²æ–¹å¼\n- [x] **åŸºç¡€å¯¹è¯ï¼š** ç§èŠåŠç¾¤èŠçš„æ¶ˆæ¯æ™ºèƒ½å›å¤ï¼Œæ”¯æŒå¤šè½®ä¼šè¯ä¸Šä¸‹æ–‡è®°å¿†ï¼Œæ”¯æŒ GPT-3.5, GPT-4, claude, Gemini, æ–‡å¿ƒä¸€è¨€, è®¯é£æ˜Ÿç«, é€šä¹‰åƒé—®\n- [x] **è¯­éŸ³èƒ½åŠ›ï¼š** å¯è¯†åˆ«è¯­éŸ³æ¶ˆæ¯ï¼Œé€šè¿‡æ–‡å­—æˆ–è¯­éŸ³å›å¤ï¼Œæ”¯æŒ azure, baidu, google, openai(whisper/tts) ç­‰å¤šç§è¯­éŸ³æ¨¡å‹\n- [x] **å›¾åƒèƒ½åŠ›ï¼š** æ”¯æŒå›¾ç‰‡ç”Ÿæˆã€å›¾ç‰‡è¯†åˆ«ã€å›¾ç”Ÿå›¾ï¼ˆå¦‚ç…§ç‰‡ä¿®å¤ï¼‰ï¼Œå¯é€‰æ‹© Dall-E-3, stable diffusion, replicate, midjourney, visionæ¨¡å‹\n- [x] **ä¸°å¯Œæ’ä»¶ï¼š** æ”¯æŒä¸ªæ€§åŒ–æ’ä»¶æ‰©å±•ï¼Œå·²å®ç°å¤šè§’è‰²åˆ‡æ¢ã€æ–‡å­—å†’é™©ã€æ•æ„Ÿè¯è¿‡æ»¤ã€èŠå¤©è®°å½•æ€»ç»“ã€æ–‡æ¡£æ€»ç»“å’Œå¯¹è¯ã€è”ç½‘æœç´¢ç­‰æ’ä»¶\n- [x] **çŸ¥è¯†åº“ï¼š** é€šè¿‡ä¸Šä¼ çŸ¥è¯†åº“æ–‡ä»¶è‡ªå®šä¹‰ä¸“å±æœºå™¨äººï¼Œå¯ä½œä¸ºæ•°å­—åˆ†èº«ã€æ™ºèƒ½å®¢æœã€ç§åŸŸåŠ©æ‰‹ä½¿ç”¨ï¼ŒåŸºäº [LinkAI](https://link-ai.tech) å®ç°\n\n# æ¼”ç¤º\n\nhttps://github.com/zhayujie/chatgpt-on-wechat/assets/26161723/d5154020-36e3-41db-8706-40ce9f3f1b1e\n\nDemo made by [Visionn](https://www.wangpc.cc/)\n\n# å•†ä¸šæ”¯æŒ\n\n> æˆ‘ä»¬è¿˜æä¾›ä¼ä¸šçº§çš„ **AIåº”ç”¨å¹³å°**ï¼ŒåŒ…å«çŸ¥è¯†åº“ã€Agentæ’ä»¶ã€åº”ç”¨ç®¡ç†ç­‰èƒ½åŠ›ï¼Œæ”¯æŒå¤šå¹³å°èšåˆçš„åº”ç”¨æ¥å…¥ã€å®¢æˆ·ç«¯ç®¡ç†ã€å¯¹è¯ç®¡ç†ï¼Œä»¥åŠæä¾›\nSaaSæœåŠ¡ã€ç§æœ‰åŒ–éƒ¨ç½²ã€ç¨³å®šæ‰˜ç®¡æ¥å…¥ ç­‰å¤šç§æ¨¡å¼ã€‚\n>\n> ç›®å‰å·²åœ¨ç§åŸŸè¿è¥ã€æ™ºèƒ½å®¢æœã€ä¼ä¸šæ•ˆç‡åŠ©æ‰‹ç­‰åœºæ™¯ç§¯ç´¯äº†ä¸°å¯Œçš„ AI è§£å†³æ–¹æ¡ˆï¼Œ åœ¨ç”µå•†ã€æ–‡æ•™ã€å¥åº·ã€æ–°æ¶ˆè´¹ç­‰å„è¡Œä¸šæ²‰æ·€äº† AI è½åœ°çš„æœ€ä½³å®è·µï¼Œè‡´åŠ›äºæ‰“é€ åŠ©åŠ›ä¸­å°ä¼ä¸šæ‹¥æŠ± AI çš„ä¸€ç«™å¼å¹³å°ã€‚\n\nä¼ä¸šæœåŠ¡å’Œå•†ç”¨å’¨è¯¢å¯è”ç³»äº§å“é¡¾é—®ï¼š\n\n<img width=\"240\" src=\"https://img-1317903499.cos.ap-guangzhou.myqcloud.com/docs/product-manager-qrcode.jpg\">\n\n# å¼€æºç¤¾åŒº\n\næ·»åŠ å°åŠ©æ‰‹å¾®ä¿¡åŠ å…¥å¼€æºé¡¹ç›®äº¤æµç¾¤ï¼š\n\n<img width=\"240\" src=\"./docs/images/contact.jpg\">\n\n# æ›´æ–°æ—¥å¿—\n\n>**2023.11.11ï¼š** [1.5.3ç‰ˆæœ¬](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.3) å’Œ [1.5.4ç‰ˆæœ¬](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.4)ï¼Œæ–°å¢Google Geminiã€é€šä¹‰åƒé—®æ¨¡å‹\n\n>**2023.11.10ï¼š** [1.5.2ç‰ˆæœ¬](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.2)ï¼Œæ–°å¢é£ä¹¦é€šé“ã€å›¾åƒè¯†åˆ«å¯¹è¯ã€é»‘åå•é…ç½®\n\n>**2023.11.10ï¼š** [1.5.0ç‰ˆæœ¬](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.0)ï¼Œæ–°å¢ `gpt-4-turbo`, `dall-e-3`, `tts` æ¨¡å‹æ¥å…¥ï¼Œå®Œå–„å›¾åƒç†è§£&ç”Ÿæˆã€è¯­éŸ³è¯†åˆ«&ç”Ÿæˆçš„å¤šæ¨¡æ€èƒ½åŠ›\n\n>**2023.10.16ï¼š** æ”¯æŒé€šè¿‡æ„å›¾è¯†åˆ«ä½¿ç”¨LinkAIè”ç½‘æœç´¢ã€æ•°å­¦è®¡ç®—ã€ç½‘é¡µè®¿é—®ç­‰æ’ä»¶ï¼Œå‚è€ƒ[æ’ä»¶æ–‡æ¡£](https://docs.link-ai.tech/platform/plugins)\n\n>**2023.09.26ï¼š** æ’ä»¶å¢åŠ  æ–‡ä»¶/æ–‡ç« é“¾æ¥ ä¸€é”®æ€»ç»“å’Œå¯¹è¯çš„åŠŸèƒ½ï¼Œä½¿ç”¨å‚è€ƒï¼š[æ’ä»¶è¯´æ˜](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins/linkai#3%E6%96%87%E6%A1%A3%E6%80%BB%E7%BB%93%E5%AF%B9%E8%AF%9D%E5%8A%9F%E8%83%BD)\n\n>**2023.08.08ï¼š** æ¥å…¥ç™¾åº¦æ–‡å¿ƒä¸€è¨€æ¨¡å‹ï¼Œé€šè¿‡ [æ’ä»¶](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins/linkai) æ”¯æŒ Midjourney ç»˜å›¾\n\n>**2023.06.12ï¼š** æ¥å…¥ [LinkAI](https://link-ai.tech/console) å¹³å°ï¼Œå¯åœ¨çº¿åˆ›å»ºé¢†åŸŸçŸ¥è¯†åº“ï¼Œå¹¶æ¥å…¥å¾®ä¿¡ã€å…¬ä¼—å·åŠä¼ä¸šå¾®ä¿¡ä¸­ï¼Œæ‰“é€ ä¸“å±å®¢æœæœºå™¨äººã€‚ä½¿ç”¨å‚è€ƒ [æ¥å…¥æ–‡æ¡£](https://link-ai.tech/platform/link-app/wechat)ã€‚\n\n>**2023.04.26ï¼š** æ”¯æŒä¼ä¸šå¾®ä¿¡åº”ç”¨å·éƒ¨ç½²ï¼Œå…¼å®¹æ’ä»¶ï¼Œå¹¶æ”¯æŒè¯­éŸ³å›¾ç‰‡äº¤äº’ï¼Œç§äººåŠ©ç†ç†æƒ³é€‰æ‹©ï¼Œ[ä½¿ç”¨æ–‡æ¡£](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/wechatcom/README.md)ã€‚(contributed by [@lanvent](https://github.com/lanvent) in [#944](https://github.com/zhayujie/chatgpt-on-wechat/pull/944))\n\n>**2023.04.05ï¼š** æ”¯æŒå¾®ä¿¡å…¬ä¼—å·éƒ¨ç½²ï¼Œå…¼å®¹æ’ä»¶ï¼Œå¹¶æ”¯æŒè¯­éŸ³å›¾ç‰‡äº¤äº’ï¼Œ[ä½¿ç”¨æ–‡æ¡£](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/wechatmp/README.md)ã€‚(contributed by [@JS00000](https://github.com/JS00000) in [#686](https://github.com/zhayujie/chatgpt-on-wechat/pull/686))\n\n>**2023.04.05ï¼š** å¢åŠ èƒ½è®©ChatGPTä½¿ç”¨å·¥å…·çš„`tool`æ’ä»¶ï¼Œ[ä½¿ç”¨æ–‡æ¡£](https://github.com/goldfishh/chatgpt-on-wechat/blob/master/plugins/tool/README.md)ã€‚å·¥å…·ç›¸å…³issueå¯åé¦ˆè‡³[chatgpt-tool-hub](https://github.com/goldfishh/chatgpt-tool-hub)ã€‚(contributed by [@goldfishh](https://github.com/goldfishh) in [#663](https://github.com/zhayujie/chatgpt-on-wechat/pull/663))\n\n>**2023.03.25ï¼š** æ”¯æŒæ’ä»¶åŒ–å¼€å‘ï¼Œç›®å‰å·²å®ç° å¤šè§’è‰²åˆ‡æ¢ã€æ–‡å­—å†’é™©æ¸¸æˆã€ç®¡ç†å‘˜æŒ‡ä»¤ã€Stable Diffusionç­‰æ’ä»¶ï¼Œä½¿ç”¨å‚è€ƒ [#578](https://github.com/zhayujie/chatgpt-on-wechat/issues/578)ã€‚(contributed by [@lanvent](https://github.com/lanvent) in [#565](https://github.com/zhayujie/chatgpt-on-wechat/pull/565))\n\n>**2023.03.09ï¼š** åŸºäº `whisper API`(åç»­å·²æ¥å…¥æ›´å¤šçš„è¯­éŸ³`API`æœåŠ¡) å®ç°å¯¹å¾®ä¿¡è¯­éŸ³æ¶ˆæ¯çš„è§£æå’Œå›å¤ï¼Œæ·»åŠ é…ç½®é¡¹ `\"speech_recognition\":true` å³å¯å¯ç”¨ï¼Œä½¿ç”¨å‚è€ƒ [#415](https://github.com/zhayujie/chatgpt-on-wechat/issues/415)ã€‚(contributed by [wanggang1987](https://github.com/wanggang1987) in [#385](https://github.com/zhayujie/chatgpt-on-wechat/pull/385))\n\n>**2023.02.09ï¼š** æ‰«ç ç™»å½•å­˜åœ¨è´¦å·é™åˆ¶é£é™©ï¼Œè¯·è°¨æ…ä½¿ç”¨ï¼Œå‚è€ƒ[#58](https://github.com/AutumnWhj/ChatGPT-wechat-bot/issues/158)\n\n# å¿«é€Ÿå¼€å§‹\n\nå¿«é€Ÿå¼€å§‹æ–‡æ¡£ï¼š[é¡¹ç›®æ­å»ºæ–‡æ¡£](https://docs.link-ai.tech/cow/quick-start)\n\n## å‡†å¤‡\n\n### 1. è´¦å·æ³¨å†Œ\n\né¡¹ç›®é»˜è®¤ä½¿ç”¨OpenAIæ¥å£ï¼Œéœ€å‰å¾€ [OpenAIæ³¨å†Œé¡µé¢](https://beta.openai.com/signup) åˆ›å»ºè´¦å·ï¼Œåˆ›å»ºå®Œè´¦å·åˆ™å‰å¾€ [APIç®¡ç†é¡µé¢](https://beta.openai.com/account/api-keys) åˆ›å»ºä¸€ä¸ª API Key å¹¶ä¿å­˜ä¸‹æ¥ï¼Œåé¢éœ€è¦åœ¨é¡¹ç›®ä¸­é…ç½®è¿™ä¸ªkeyã€‚æ¥å£éœ€è¦æµ·å¤–ç½‘ç»œè®¿é—®åŠç»‘å®šä¿¡ç”¨å¡æ”¯ä»˜ã€‚\n\n> é»˜è®¤å¯¹è¯æ¨¡å‹æ˜¯ openai çš„ gpt-3.5-turboï¼Œè®¡è´¹æ–¹å¼æ˜¯çº¦æ¯ 1000tokens (çº¦750ä¸ªè‹±æ–‡å•è¯ æˆ– 500æ±‰å­—ï¼ŒåŒ…å«è¯·æ±‚å’Œå›å¤) æ¶ˆè€— $0.002ï¼Œå›¾ç‰‡ç”Ÿæˆæ˜¯Dell Eæ¨¡å‹ï¼Œæ¯å¼ æ¶ˆè€— $0.016ã€‚\n\né¡¹ç›®åŒæ—¶ä¹Ÿæ”¯æŒä½¿ç”¨ LinkAI æ¥å£ï¼Œæ— éœ€ä»£ç†ï¼Œå¯ä½¿ç”¨ æ–‡å¿ƒã€è®¯é£ã€GPT-3ã€GPT-4 ç­‰æ¨¡å‹ï¼Œæ”¯æŒ å®šåˆ¶åŒ–çŸ¥è¯†åº“ã€è”ç½‘æœç´¢ã€MJç»˜å›¾ã€æ–‡æ¡£æ€»ç»“å’Œå¯¹è¯ç­‰èƒ½åŠ›ã€‚ä¿®æ”¹é…ç½®å³å¯ä¸€é”®åˆ‡æ¢ï¼Œå‚è€ƒ [æ¥å…¥æ–‡æ¡£](https://link-ai.tech/platform/link-app/wechat)ã€‚\n\n### 2.è¿è¡Œç¯å¢ƒ\n\næ”¯æŒ Linuxã€MacOSã€Windows ç³»ç»Ÿï¼ˆå¯åœ¨LinuxæœåŠ¡å™¨ä¸Šé•¿æœŸè¿è¡Œ)ï¼ŒåŒæ—¶éœ€å®‰è£… `Python`ã€‚\n> å»ºè®®Pythonç‰ˆæœ¬åœ¨ 3.7.1~3.9.X ä¹‹é—´ï¼Œæ¨è3.8ç‰ˆæœ¬ï¼Œ3.10åŠä»¥ä¸Šç‰ˆæœ¬åœ¨ MacOS å¯ç”¨ï¼Œå…¶ä»–ç³»ç»Ÿä¸Šä¸ç¡®å®šèƒ½å¦æ­£å¸¸è¿è¡Œã€‚\n\n> æ³¨æ„ï¼šDocker æˆ– Railway éƒ¨ç½²æ— éœ€å®‰è£…pythonç¯å¢ƒå’Œä¸‹è½½æºç ï¼Œå¯ç›´æ¥å¿«è¿›åˆ°ä¸‹ä¸€èŠ‚ã€‚\n\n**(1) å…‹éš†é¡¹ç›®ä»£ç ï¼š**\n\n```bash\ngit clone https://github.com/zhayujie/chatgpt-on-wechat\ncd chatgpt-on-wechat/\n```\n\næ³¨: å¦‚é‡åˆ°ç½‘ç»œé—®é¢˜å¯é€‰æ‹©å›½å†…é•œåƒ https://gitee.com/zhayujie/chatgpt-on-wechat\n\n**(2) å®‰è£…æ ¸å¿ƒä¾èµ– (å¿…é€‰)ï¼š**\n> èƒ½å¤Ÿä½¿ç”¨`itchat`åˆ›å»ºæœºå™¨äººï¼Œå¹¶å…·æœ‰æ–‡å­—äº¤æµåŠŸèƒ½æ‰€éœ€çš„æœ€å°ä¾èµ–é›†åˆã€‚\n```bash\npip3 install -r requirements.txt\n```\n\n**(3) æ‹“å±•ä¾èµ– (å¯é€‰ï¼Œå»ºè®®å®‰è£…)ï¼š**\n\n```bash\npip3 install -r requirements-optional.txt\n```\n> å¦‚æœæŸé¡¹ä¾èµ–å®‰è£…å¤±è´¥å¯æ³¨é‡Šæ‰å¯¹åº”çš„è¡Œå†ç»§ç»­\n\n## é…ç½®\n\né…ç½®æ–‡ä»¶çš„æ¨¡æ¿åœ¨æ ¹ç›®å½•çš„`config-template.json`ä¸­ï¼Œéœ€å¤åˆ¶è¯¥æ¨¡æ¿åˆ›å»ºæœ€ç»ˆç”Ÿæ•ˆçš„ `config.json` æ–‡ä»¶ï¼š\n\n```bash\n  cp config-template.json config.json\n```\n\nç„¶ååœ¨`config.json`ä¸­å¡«å…¥é…ç½®ï¼Œä»¥ä¸‹æ˜¯å¯¹é»˜è®¤é…ç½®çš„è¯´æ˜ï¼Œå¯æ ¹æ®éœ€è¦è¿›è¡Œè‡ªå®šä¹‰ä¿®æ”¹ï¼ˆè¯·å»æ‰æ³¨é‡Šï¼‰ï¼š\n\n```bash\n# config.jsonæ–‡ä»¶å†…å®¹ç¤ºä¾‹\n{\n  \"open_ai_api_key\": \"YOUR API KEY\",                          # å¡«å…¥ä¸Šé¢åˆ›å»ºçš„ OpenAI API KEY\n  \"model\": \"gpt-3.5-turbo\",                                   # æ¨¡å‹åç§°, æ”¯æŒ gpt-3.5-turbo, gpt-3.5-turbo-16k, gpt-4, wenxin, xunfei\n  \"proxy\": \"\",                                                # ä»£ç†å®¢æˆ·ç«¯çš„ipå’Œç«¯å£ï¼Œå›½å†…ç¯å¢ƒå¼€å¯ä»£ç†çš„éœ€è¦å¡«å†™è¯¥é¡¹ï¼Œå¦‚ \"127.0.0.1:7890\"\n  \"single_chat_prefix\": [\"bot\", \"@bot\"],                      # ç§èŠæ—¶æ–‡æœ¬éœ€è¦åŒ…å«è¯¥å‰ç¼€æ‰èƒ½è§¦å‘æœºå™¨äººå›å¤\n  \"single_chat_reply_prefix\": \"[bot] \",                       # ç§èŠæ—¶è‡ªåŠ¨å›å¤çš„å‰ç¼€ï¼Œç”¨äºåŒºåˆ†çœŸäºº\n  \"group_chat_prefix\": [\"@bot\"],                              # ç¾¤èŠæ—¶åŒ…å«è¯¥å‰ç¼€åˆ™ä¼šè§¦å‘æœºå™¨äººå›å¤\n  \"group_name_white_list\": [\"ChatGPTæµ‹è¯•ç¾¤\", \"ChatGPTæµ‹è¯•ç¾¤2\"], # å¼€å¯è‡ªåŠ¨å›å¤çš„ç¾¤åç§°åˆ—è¡¨\n  \"group_chat_in_one_session\": [\"ChatGPTæµ‹è¯•ç¾¤\"],              # æ”¯æŒä¼šè¯ä¸Šä¸‹æ–‡å…±äº«çš„ç¾¤åç§°  \n  \"image_create_prefix\": [\"ç”»\", \"çœ‹\", \"æ‰¾\"],                   # å¼€å¯å›¾ç‰‡å›å¤çš„å‰ç¼€\n  \"conversation_max_tokens\": 1000,                            # æ”¯æŒä¸Šä¸‹æ–‡è®°å¿†çš„æœ€å¤šå­—ç¬¦æ•°\n  \"speech_recognition\": false,                                # æ˜¯å¦å¼€å¯è¯­éŸ³è¯†åˆ«\n  \"group_speech_recognition\": false,                          # æ˜¯å¦å¼€å¯ç¾¤ç»„è¯­éŸ³è¯†åˆ«\n  \"use_azure_chatgpt\": false,                                 # æ˜¯å¦ä½¿ç”¨Azure ChatGPT serviceä»£æ›¿openai ChatGPT service. å½“è®¾ç½®ä¸ºtrueæ—¶éœ€è¦è®¾ç½® open_ai_api_baseï¼Œå¦‚ https://xxx.openai.azure.com/\n  \"azure_deployment_id\": \"\",                                  # é‡‡ç”¨Azure ChatGPTæ—¶ï¼Œæ¨¡å‹éƒ¨ç½²åç§°\n  \"azure_api_version\": \"\",                                    # é‡‡ç”¨Azure ChatGPTæ—¶ï¼ŒAPIç‰ˆæœ¬\n  \"character_desc\": \"ä½ æ˜¯ChatGPT, ä¸€ä¸ªç”±OpenAIè®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹, ä½ æ—¨åœ¨å›ç­”å¹¶è§£å†³äººä»¬çš„ä»»ä½•é—®é¢˜ï¼Œå¹¶ä¸”å¯ä»¥ä½¿ç”¨å¤šç§è¯­è¨€ä¸äººäº¤æµã€‚\",  # äººæ ¼æè¿°\n  # è®¢é˜…æ¶ˆæ¯ï¼Œå…¬ä¼—å·å’Œä¼ä¸šå¾®ä¿¡channelä¸­è¯·å¡«å†™ï¼Œå½“è¢«è®¢é˜…æ—¶ä¼šè‡ªåŠ¨å›å¤ï¼Œå¯ä½¿ç”¨ç‰¹æ®Šå ä½ç¬¦ã€‚ç›®å‰æ”¯æŒçš„å ä½ç¬¦æœ‰{trigger_prefix}ï¼Œåœ¨ç¨‹åºä¸­å®ƒä¼šè‡ªåŠ¨æ›¿æ¢æˆbotçš„è§¦å‘è¯ã€‚\n  \"subscribe_msg\": \"æ„Ÿè°¢æ‚¨çš„å…³æ³¨ï¼\\nè¿™é‡Œæ˜¯ChatGPTï¼Œå¯ä»¥è‡ªç”±å¯¹è¯ã€‚\\næ”¯æŒè¯­éŸ³å¯¹è¯ã€‚\\næ”¯æŒå›¾ç‰‡è¾“å‡ºï¼Œç”»å­—å¼€å¤´çš„æ¶ˆæ¯å°†æŒ‰è¦æ±‚åˆ›ä½œå›¾ç‰‡ã€‚\\næ”¯æŒè§’è‰²æ‰®æ¼”å’Œæ–‡å­—å†’é™©ç­‰ä¸°å¯Œæ’ä»¶ã€‚\\nè¾“å…¥{trigger_prefix}#help æŸ¥çœ‹è¯¦ç»†æŒ‡ä»¤ã€‚\",\n  \"use_linkai\": false,                                        # æ˜¯å¦ä½¿ç”¨LinkAIæ¥å£ï¼Œé»˜è®¤å…³é—­ï¼Œå¼€å¯åå¯å›½å†…è®¿é—®ï¼Œä½¿ç”¨çŸ¥è¯†åº“å’ŒMJ\n  \"linkai_api_key\": \"\",                                       # LinkAI Api Key\n  \"linkai_app_code\": \"\"                                       # LinkAI åº”ç”¨code\n}\n```\n**é…ç½®è¯´æ˜ï¼š**\n\n**1.ä¸ªäººèŠå¤©**\n\n+ ä¸ªäººèŠå¤©ä¸­ï¼Œéœ€è¦ä»¥ \"bot\"æˆ–\"@bot\" ä¸ºå¼€å¤´çš„å†…å®¹è§¦å‘æœºå™¨äººï¼Œå¯¹åº”é…ç½®é¡¹ `single_chat_prefix` (å¦‚æœä¸éœ€è¦ä»¥å‰ç¼€è§¦å‘å¯ä»¥å¡«å†™  `\"single_chat_prefix\": [\"\"]`)\n+ æœºå™¨äººå›å¤çš„å†…å®¹ä¼šä»¥ \"[bot] \" ä½œä¸ºå‰ç¼€ï¼Œ ä»¥åŒºåˆ†çœŸäººï¼Œå¯¹åº”çš„é…ç½®é¡¹ä¸º `single_chat_reply_prefix` (å¦‚æœä¸éœ€è¦å‰ç¼€å¯ä»¥å¡«å†™ `\"single_chat_reply_prefix\": \"\"`)\n\n**2.ç¾¤ç»„èŠå¤©**\n\n+ ç¾¤ç»„èŠå¤©ä¸­ï¼Œç¾¤åç§°éœ€é…ç½®åœ¨ `group_name_white_list ` ä¸­æ‰èƒ½å¼€å¯ç¾¤èŠè‡ªåŠ¨å›å¤ã€‚å¦‚æœæƒ³å¯¹æ‰€æœ‰ç¾¤èŠç”Ÿæ•ˆï¼Œå¯ä»¥ç›´æ¥å¡«å†™ `\"group_name_white_list\": [\"ALL_GROUP\"]`\n+ é»˜è®¤åªè¦è¢«äºº @ å°±ä¼šè§¦å‘æœºå™¨äººè‡ªåŠ¨å›å¤ï¼›å¦å¤–ç¾¤èŠå¤©ä¸­åªè¦æ£€æµ‹åˆ°ä»¥ \"@bot\" å¼€å¤´çš„å†…å®¹ï¼ŒåŒæ ·ä¼šè‡ªåŠ¨å›å¤ï¼ˆæ–¹ä¾¿è‡ªå·±è§¦å‘ï¼‰ï¼Œè¿™å¯¹åº”é…ç½®é¡¹ `group_chat_prefix`\n+ å¯é€‰é…ç½®: `group_name_keyword_white_list`é…ç½®é¡¹æ”¯æŒæ¨¡ç³ŠåŒ¹é…ç¾¤åç§°ï¼Œ`group_chat_keyword`é…ç½®é¡¹åˆ™æ”¯æŒæ¨¡ç³ŠåŒ¹é…ç¾¤æ¶ˆæ¯å†…å®¹ï¼Œç”¨æ³•ä¸ä¸Šè¿°ä¸¤ä¸ªé…ç½®é¡¹ç›¸åŒã€‚ï¼ˆContributed by [evolay](https://github.com/evolay))\n+ `group_chat_in_one_session`ï¼šä½¿ç¾¤èŠå…±äº«ä¸€ä¸ªä¼šè¯ä¸Šä¸‹æ–‡ï¼Œé…ç½® `[\"ALL_GROUP\"]` åˆ™ä½œç”¨äºæ‰€æœ‰ç¾¤èŠ\n\n**3.è¯­éŸ³è¯†åˆ«**\n\n+ æ·»åŠ  `\"speech_recognition\": true` å°†å¼€å¯è¯­éŸ³è¯†åˆ«ï¼Œé»˜è®¤ä½¿ç”¨openaiçš„whisperæ¨¡å‹è¯†åˆ«ä¸ºæ–‡å­—ï¼ŒåŒæ—¶ä»¥æ–‡å­—å›å¤ï¼Œè¯¥å‚æ•°ä»…æ”¯æŒç§èŠ (æ³¨æ„ç”±äºè¯­éŸ³æ¶ˆæ¯æ— æ³•åŒ¹é…å‰ç¼€ï¼Œä¸€æ—¦å¼€å¯å°†å¯¹æ‰€æœ‰è¯­éŸ³è‡ªåŠ¨å›å¤ï¼Œæ”¯æŒè¯­éŸ³è§¦å‘ç”»å›¾)ï¼›\n+ æ·»åŠ  `\"group_speech_recognition\": true` å°†å¼€å¯ç¾¤ç»„è¯­éŸ³è¯†åˆ«ï¼Œé»˜è®¤ä½¿ç”¨openaiçš„whisperæ¨¡å‹è¯†åˆ«ä¸ºæ–‡å­—ï¼ŒåŒæ—¶ä»¥æ–‡å­—å›å¤ï¼Œå‚æ•°ä»…æ”¯æŒç¾¤èŠ (ä¼šåŒ¹é…group_chat_prefixå’Œgroup_chat_keyword, æ”¯æŒè¯­éŸ³è§¦å‘ç”»å›¾)ï¼›\n+ æ·»åŠ  `\"voice_reply_voice\": true` å°†å¼€å¯è¯­éŸ³å›å¤è¯­éŸ³ï¼ˆåŒæ—¶ä½œç”¨äºç§èŠå’Œç¾¤èŠï¼‰ï¼Œä½†æ˜¯éœ€è¦é…ç½®å¯¹åº”è¯­éŸ³åˆæˆå¹³å°çš„keyï¼Œç”±äºitchatåè®®çš„é™åˆ¶ï¼Œåªèƒ½å‘é€è¯­éŸ³mp3æ–‡ä»¶ï¼Œè‹¥ä½¿ç”¨wechatyåˆ™å›å¤çš„æ˜¯å¾®ä¿¡è¯­éŸ³ã€‚\n\n**4.å…¶ä»–é…ç½®**\n\n+ `model`: æ¨¡å‹åç§°ï¼Œç›®å‰æ”¯æŒ `gpt-3.5-turbo`, `text-davinci-003`, `gpt-4`, `gpt-4-32k`, `wenxin` , `claude` ,  `xunfei`(å…¶ä¸­gpt-4 apiæš‚æœªå®Œå…¨å¼€æ”¾ï¼Œç”³è¯·é€šè¿‡åå¯ä½¿ç”¨)\n+ `temperature`,`frequency_penalty`,`presence_penalty`: Chat APIæ¥å£å‚æ•°ï¼Œè¯¦æƒ…å‚è€ƒ[OpenAIå®˜æ–¹æ–‡æ¡£ã€‚](https://platform.openai.com/docs/api-reference/chat)\n+ `proxy`ï¼šç”±äºç›®å‰ `openai` æ¥å£å›½å†…æ— æ³•è®¿é—®ï¼Œéœ€é…ç½®ä»£ç†å®¢æˆ·ç«¯çš„åœ°å€ï¼Œè¯¦æƒ…å‚è€ƒ  [#351](https://github.com/zhayujie/chatgpt-on-wechat/issues/351)\n+ å¯¹äºå›¾åƒç”Ÿæˆï¼Œåœ¨æ»¡è¶³ä¸ªäººæˆ–ç¾¤ç»„è§¦å‘æ¡ä»¶å¤–ï¼Œè¿˜éœ€è¦é¢å¤–çš„å…³é”®è¯å‰ç¼€æ¥è§¦å‘ï¼Œå¯¹åº”é…ç½® `image_create_prefix `\n+ å…³äºOpenAIå¯¹è¯åŠå›¾ç‰‡æ¥å£çš„å‚æ•°é…ç½®ï¼ˆå†…å®¹è‡ªç”±åº¦ã€å›å¤å­—æ•°é™åˆ¶ã€å›¾ç‰‡å¤§å°ç­‰ï¼‰ï¼Œå¯ä»¥å‚è€ƒ [å¯¹è¯æ¥å£](https://beta.openai.com/docs/api-reference/completions) å’Œ [å›¾åƒæ¥å£](https://beta.openai.com/docs/api-reference/completions)  æ–‡æ¡£ï¼Œåœ¨[`config.py`](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/config.py)ä¸­æ£€æŸ¥å“ªäº›å‚æ•°åœ¨æœ¬é¡¹ç›®ä¸­æ˜¯å¯é…ç½®çš„ã€‚\n+ `conversation_max_tokens`ï¼šè¡¨ç¤ºèƒ½å¤Ÿè®°å¿†çš„ä¸Šä¸‹æ–‡æœ€å¤§å­—æ•°ï¼ˆä¸€é—®ä¸€ç­”ä¸ºä¸€ç»„å¯¹è¯ï¼Œå¦‚æœç´¯ç§¯çš„å¯¹è¯å­—æ•°è¶…å‡ºé™åˆ¶ï¼Œå°±ä¼šä¼˜å…ˆç§»é™¤æœ€æ—©çš„ä¸€ç»„å¯¹è¯ï¼‰\n+ `rate_limit_chatgpt`ï¼Œ`rate_limit_dalle`ï¼šæ¯åˆ†é’Ÿæœ€é«˜é—®ç­”é€Ÿç‡ã€ç”»å›¾é€Ÿç‡ï¼Œè¶…é€Ÿåæ’é˜ŸæŒ‰åºå¤„ç†ã€‚\n+ `clear_memory_commands`: å¯¹è¯å†…æŒ‡ä»¤ï¼Œä¸»åŠ¨æ¸…ç©ºå‰æ–‡è®°å¿†ï¼Œå­—ç¬¦ä¸²æ•°ç»„å¯è‡ªå®šä¹‰æŒ‡ä»¤åˆ«åã€‚\n+ `hot_reload`: ç¨‹åºé€€å‡ºåï¼Œæš‚å­˜å¾®ä¿¡æ‰«ç çŠ¶æ€ï¼Œé»˜è®¤å…³é—­ã€‚\n+ `character_desc` é…ç½®ä¸­ä¿å­˜ç€ä½ å¯¹æœºå™¨äººè¯´çš„ä¸€æ®µè¯ï¼Œä»–ä¼šè®°ä½è¿™æ®µè¯å¹¶ä½œä¸ºä»–çš„è®¾å®šï¼Œä½ å¯ä»¥ä¸ºä»–å®šåˆ¶ä»»ä½•äººæ ¼      (å…³äºä¼šè¯ä¸Šä¸‹æ–‡çš„æ›´å¤šå†…å®¹å‚è€ƒè¯¥ [issue](https://github.com/zhayujie/chatgpt-on-wechat/issues/43))\n+ `subscribe_msg`ï¼šè®¢é˜…æ¶ˆæ¯ï¼Œå…¬ä¼—å·å’Œä¼ä¸šå¾®ä¿¡channelä¸­è¯·å¡«å†™ï¼Œå½“è¢«è®¢é˜…æ—¶ä¼šè‡ªåŠ¨å›å¤ï¼Œ å¯ä½¿ç”¨ç‰¹æ®Šå ä½ç¬¦ã€‚ç›®å‰æ”¯æŒçš„å ä½ç¬¦æœ‰{trigger_prefix}ï¼Œåœ¨ç¨‹åºä¸­å®ƒä¼šè‡ªåŠ¨æ›¿æ¢æˆbotçš„è§¦å‘è¯ã€‚\n\n**5.LinkAIé…ç½® (å¯é€‰)**\n\n+ `use_linkai`: æ˜¯å¦ä½¿ç”¨LinkAIæ¥å£ï¼Œå¼€å¯åå¯å›½å†…è®¿é—®ï¼Œä½¿ç”¨çŸ¥è¯†åº“å’Œ `Midjourney` ç»˜ç”», å‚è€ƒ [æ–‡æ¡£](https://link-ai.tech/platform/link-app/wechat)\n+ `linkai_api_key`: LinkAI Api Keyï¼Œå¯åœ¨ [æ§åˆ¶å°](https://link-ai.tech/console/interface) åˆ›å»º\n+ `linkai_app_code`: LinkAI åº”ç”¨codeï¼Œé€‰å¡«\n\n**æœ¬è¯´æ˜æ–‡æ¡£å¯èƒ½ä¼šæœªåŠæ—¶æ›´æ–°ï¼Œå½“å‰æ‰€æœ‰å¯é€‰çš„é…ç½®é¡¹å‡åœ¨è¯¥[`config.py`](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/config.py)ä¸­åˆ—å‡ºã€‚**\n\n## è¿è¡Œ\n\n### 1.æœ¬åœ°è¿è¡Œ\n\nå¦‚æœæ˜¯å¼€å‘æœº **æœ¬åœ°è¿è¡Œ**ï¼Œç›´æ¥åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹æ‰§è¡Œï¼š\n\n```bash\npython3 app.py                                    # windowsç¯å¢ƒä¸‹è¯¥å‘½ä»¤é€šå¸¸ä¸º python app.py\n```\n\nç»ˆç«¯è¾“å‡ºäºŒç»´ç åï¼Œä½¿ç”¨å¾®ä¿¡è¿›è¡Œæ‰«ç ï¼Œå½“è¾“å‡º \"Start auto replying\" æ—¶è¡¨ç¤ºè‡ªåŠ¨å›å¤ç¨‹åºå·²ç»æˆåŠŸè¿è¡Œäº†ï¼ˆæ³¨æ„ï¼šç”¨äºç™»å½•çš„å¾®ä¿¡éœ€è¦åœ¨æ”¯ä»˜å¤„å·²å®Œæˆå®åè®¤è¯ï¼‰ã€‚æ‰«ç ç™»å½•åä½ çš„è´¦å·å°±æˆä¸ºæœºå™¨äººäº†ï¼Œå¯ä»¥åœ¨å¾®ä¿¡æ‰‹æœºç«¯é€šè¿‡é…ç½®çš„å…³é”®è¯è§¦å‘è‡ªåŠ¨å›å¤ (ä»»æ„å¥½å‹å‘é€æ¶ˆæ¯ç»™ä½ ï¼Œæˆ–æ˜¯è‡ªå·±å‘æ¶ˆæ¯ç»™å¥½å‹)ï¼Œå‚è€ƒ[#142](https://github.com/zhayujie/chatgpt-on-wechat/issues/142)ã€‚\n\n### 2.æœåŠ¡å™¨éƒ¨ç½²\n\nä½¿ç”¨nohupå‘½ä»¤åœ¨åå°è¿è¡Œç¨‹åºï¼š\n\n```bash\nnohup python3 app.py & tail -f nohup.out          # åœ¨åå°è¿è¡Œç¨‹åºå¹¶é€šè¿‡æ—¥å¿—è¾“å‡ºäºŒç»´ç \n```\næ‰«ç ç™»å½•åç¨‹åºå³å¯è¿è¡ŒäºæœåŠ¡å™¨åå°ï¼Œæ­¤æ—¶å¯é€šè¿‡ `ctrl+c` å…³é—­æ—¥å¿—ï¼Œä¸ä¼šå½±å“åå°ç¨‹åºçš„è¿è¡Œã€‚ä½¿ç”¨ `ps -ef | grep app.py | grep -v grep` å‘½ä»¤å¯æŸ¥çœ‹è¿è¡Œäºåå°çš„è¿›ç¨‹ï¼Œå¦‚æœæƒ³è¦é‡æ–°å¯åŠ¨ç¨‹åºå¯ä»¥å…ˆ `kill` æ‰å¯¹åº”çš„è¿›ç¨‹ã€‚æ—¥å¿—å…³é—­åå¦‚æœæƒ³è¦å†æ¬¡æ‰“å¼€åªéœ€è¾“å…¥Â `tail -f nohup.out`ã€‚æ­¤å¤–ï¼Œ`scripts` ç›®å½•ä¸‹æœ‰ä¸€é”®è¿è¡Œã€å…³é—­ç¨‹åºçš„è„šæœ¬ä¾›ä½¿ç”¨ã€‚\n\n> **å¤šè´¦å·æ”¯æŒï¼š** å°†é¡¹ç›®å¤åˆ¶å¤šä»½ï¼Œåˆ†åˆ«å¯åŠ¨ç¨‹åºï¼Œç”¨ä¸åŒè´¦å·æ‰«ç ç™»å½•å³å¯å®ç°åŒæ—¶è¿è¡Œã€‚\n\n> **ç‰¹æ®ŠæŒ‡ä»¤ï¼š** ç”¨æˆ·å‘æœºå™¨äººå‘é€ **#reset** å³å¯æ¸…ç©ºè¯¥ç”¨æˆ·çš„ä¸Šä¸‹æ–‡è®°å¿†ã€‚\n\n\n### 3.Dockeréƒ¨ç½²\n\n> ä½¿ç”¨dockeréƒ¨ç½²æ— éœ€ä¸‹è½½æºç å’Œå®‰è£…ä¾èµ–ï¼Œåªéœ€è¦è·å– docker-compose.yml é…ç½®æ–‡ä»¶å¹¶å¯åŠ¨å®¹å™¨å³å¯ã€‚\n\n> å‰ææ˜¯éœ€è¦å®‰è£…å¥½ `docker` åŠ `docker-compose`ï¼Œå®‰è£…æˆåŠŸçš„è¡¨ç°æ˜¯æ‰§è¡Œ `docker -v` å’Œ `docker-compose version` (æˆ– docker compose version) å¯ä»¥æŸ¥çœ‹åˆ°ç‰ˆæœ¬å·ï¼Œå¯å‰å¾€ [dockerå®˜ç½‘](https://docs.docker.com/engine/install/) è¿›è¡Œä¸‹è½½ã€‚\n\n#### (1) ä¸‹è½½ docker-compose.yml æ–‡ä»¶\n\n```bash\nwget https://open-1317903499.cos.ap-guangzhou.myqcloud.com/docker-compose.yml\n```\n\nä¸‹è½½å®Œæˆåæ‰“å¼€ `docker-compose.yml` ä¿®æ”¹æ‰€éœ€é…ç½®ï¼Œå¦‚ `OPEN_AI_API_KEY` å’Œ `GROUP_NAME_WHITE_LIST` ç­‰ã€‚\n\n#### (2) å¯åŠ¨å®¹å™¨\n\nåœ¨ `docker-compose.yml` æ‰€åœ¨ç›®å½•ä¸‹æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨å®¹å™¨ï¼š\n\n```bash\nsudo docker compose up -d\n```\n\nè¿è¡Œ `sudo docker ps` èƒ½æŸ¥çœ‹åˆ° NAMES ä¸º chatgpt-on-wechat çš„å®¹å™¨å³è¡¨ç¤ºè¿è¡ŒæˆåŠŸã€‚\n\næ³¨æ„ï¼š\n\n - å¦‚æœ `docker-compose` æ˜¯ 1.X ç‰ˆæœ¬ åˆ™éœ€è¦æ‰§è¡Œ `sudo  docker-compose up -d` æ¥å¯åŠ¨å®¹å™¨\n - è¯¥å‘½ä»¤ä¼šè‡ªåŠ¨å» [docker hub](https://hub.docker.com/r/zhayujie/chatgpt-on-wechat) æ‹‰å– latest ç‰ˆæœ¬çš„é•œåƒï¼Œlatest é•œåƒä¼šåœ¨æ¯æ¬¡é¡¹ç›® release æ–°çš„ç‰ˆæœ¬æ—¶ç”Ÿæˆ\n\næœ€åè¿è¡Œä»¥ä¸‹å‘½ä»¤å¯æŸ¥çœ‹å®¹å™¨è¿è¡Œæ—¥å¿—ï¼Œæ‰«ææ—¥å¿—ä¸­çš„äºŒç»´ç å³å¯å®Œæˆç™»å½•ï¼š\n\n```bash\nsudo docker logs -f chatgpt-on-wechat\n```\n\n#### (3) æ’ä»¶ä½¿ç”¨\n\nå¦‚æœéœ€è¦åœ¨dockerå®¹å™¨ä¸­ä¿®æ”¹æ’ä»¶é…ç½®ï¼Œå¯é€šè¿‡æŒ‚è½½çš„æ–¹å¼å®Œæˆï¼Œå°† [æ’ä»¶é…ç½®æ–‡ä»¶](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/plugins/config.json.template)\né‡å‘½åä¸º `config.json`ï¼Œæ”¾ç½®äº `docker-compose.yml` ç›¸åŒç›®å½•ä¸‹ï¼Œå¹¶åœ¨ `docker-compose.yml` ä¸­çš„ `chatgpt-on-wechat` éƒ¨åˆ†ä¸‹æ·»åŠ  `volumes` æ˜ å°„:\n\n```\nvolumes:\n  - ./config.json:/app/plugins/config.json\n```\n\n### 4. Railwayéƒ¨ç½²\n\n> Railway æ¯æœˆæä¾›5åˆ€å’Œæœ€å¤š500å°æ—¶çš„å…è´¹é¢åº¦ã€‚ (07.11æ›´æ–°: ç›®å‰å¤§éƒ¨åˆ†è´¦å·å·²æ— æ³•å…è´¹éƒ¨ç½²)\n\n1. è¿›å…¥ [Railway](https://railway.app/template/qApznZ?referralCode=RC3znh)\n2. ç‚¹å‡» `Deploy Now` æŒ‰é’®ã€‚\n3. è®¾ç½®ç¯å¢ƒå˜é‡æ¥é‡è½½ç¨‹åºè¿è¡Œçš„å‚æ•°ï¼Œä¾‹å¦‚`open_ai_api_key`, `character_desc`ã€‚\n\n**ä¸€é”®éƒ¨ç½²:**\n  \n  [![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/template/qApznZ?referralCode=RC3znh)\n\n## å¸¸è§é—®é¢˜\n\nFAQsï¼š <https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs>\n\næˆ–ç›´æ¥åœ¨çº¿å’¨è¯¢ [é¡¹ç›®å°åŠ©æ‰‹](https://link-ai.tech/app/Kv2fXJcH)  (betaç‰ˆæœ¬ï¼Œè¯­æ–™å®Œå–„ä¸­ï¼Œå›å¤ä»…ä¾›å‚è€ƒ)\n\n## å¼€å‘\n\næ¬¢è¿æ¥å…¥æ›´å¤šåº”ç”¨ï¼Œå‚è€ƒ [Terminalä»£ç ](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/terminal/terminal_channel.py) å®ç°æ¥æ”¶å’Œå‘é€æ¶ˆæ¯é€»è¾‘å³å¯æ¥å…¥ã€‚ åŒæ—¶æ¬¢è¿å¢åŠ æ–°çš„æ’ä»¶ï¼Œå‚è€ƒ [æ’ä»¶è¯´æ˜æ–‡æ¡£](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins)ã€‚\n\n## è”ç³»\n\næ¬¢è¿æäº¤PRã€Issuesï¼Œä»¥åŠStaræ”¯æŒä¸€ä¸‹ã€‚ç¨‹åºè¿è¡Œé‡åˆ°é—®é¢˜å¯ä»¥æŸ¥çœ‹ [å¸¸è§é—®é¢˜åˆ—è¡¨](https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs) ï¼Œå…¶æ¬¡å‰å¾€ [Issues](https://github.com/zhayujie/chatgpt-on-wechat/issues) ä¸­æœç´¢ã€‚ä¸ªäººå¼€å‘è€…å¯åŠ å…¥å¼€æºäº¤æµç¾¤å‚ä¸æ›´å¤šè®¨è®ºï¼Œä¼ä¸šç”¨æˆ·å¯è”ç³»[äº§å“é¡¾é—®](https://img-1317903499.cos.ap-guangzhou.myqcloud.com/docs/product-manager-qrcode.jpg)å’¨è¯¢ã€‚\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "chatgpt",
        "dialogue",
        "wechat",
        "dialogue service",
        "chatgpt wechat",
        "rsagacom chatgpt"
      ],
      "category": "virtual-assistants"
    },
    "scarletlabs-ai--Votars-MCP": {
      "owner": "scarletlabs-ai",
      "name": "Votars-MCP",
      "url": "https://github.com/scarletlabs-ai/Votars-MCP",
      "imageUrl": "https://github.com/scarletlabs-ai.png",
      "description": "Integrate advanced AI functionalities for processing complex tasks through robust APIs. Supports voice recording, transcription, and intelligent AI processing for meetings.",
      "stars": 27,
      "forks": 2,
      "license": "No License",
      "language": "Go",
      "updated_at": "2025-07-07T07:12:32Z",
      "readme_content": "![Votars Logo](https://votars.ai/_next/static/media/logo.e7b6bff6.svg) \n# Votars MCP \n[![smithery badge](https://smithery.ai/badge/@scarletlabs-ai/votars-mcp)](https://smithery.ai/server/@scarletlabs-ai/votars-mcp)\n\n\n## Overview\n\nVotars-MCP is a tool that supports multiple language implementations of the **Votars MCP server**. Currently, only the Go version is available, with other languages to be added in future releases. It supports two interaction modes: `sse` (Server-Sent Events) and `stdio` (Standard Input/Output). It is designed to provide seamless integration with the Votars AI platform for processing various tasks.\n\n## About Votars\n\n[Votars](https://votars.ai/en/) is the world's smartest multilingual meeting assistant, designed for voice recording, transcription, and advanced AI processing. It features real-time translation, intelligent error correction, AI summarization, smart content generation, and AI discussions. The Votars app is available on [Web](https://votars.ai/en/), [iOS](https://apps.apple.com/us/app/votars-ai-transcribe-organize/id6737496290), and [Android](https://play.google.com/store/apps/details?id=com.votars.transcribe).\n\nAdditionally, Votars is an AI-powered platform that enables developers to integrate advanced AI functionalities into their applications. By leveraging Votars, you can process complex tasks efficiently with robust APIs designed for high performance and scalability.\n\n## Features\n- **Easy Integration with Votars**\n- **Modular Design:** Ready to be extended with additional functionalities.\n- **Supported MCP Tools:**\n  - `Votars_fetch_recent_transcripts`: Allows users to read recent transcripts from their workspace, providing convenient access to the latest recorded sessions.\n  - `Votars_fetch_a_specific_transcript`: Enables users to retrieve specific transcripts by providing a transcript ID, allowing targeted retrieval of stored data.\n  \n  More functionalities will be added soon. Stay tuned!\n\n## Installation (Go MCP)\n\n### Installing via Smithery\n\nTo install votars-mcp for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@scarletlabs-ai/votars-mcp):\n\n```bash\nnpx -y @smithery/cli install @scarletlabs-ai/votars-mcp --client claude\n```\n\n### Manual Installation\nTo install the Go version of Votars MCP from the GitHub repository, use:\n\n```bash\n go install github.com/scarletlabs-ai/Votars-MCP/go/votars-mcp@latest\n```\n\n## Usage (Go MCP)\n\n### Run MCP Service\nBefore using the `sse` mode, you need to run the MCP server. Open a terminal and run:\n\n```bash\nvotars-mcp -t sse -p 8080\n```\n\nThis command starts the MCP service on port 8080, ready to accept `sse` requests.\n\n\n### 1. SSE Mode\n\nFor `sse` mode, you need to provide the API key via request headers in the configuration file.\n\nConfiguration file example (`mcp.config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"Votars MCP\": {\n      \"type\": \"sse\",\n      \"url\": \"http://0.0.0.0:8080/sse\",\n      \"headers\": {\n        \"Authorization\": \"Bearer <your-api-key>\"\n      }\n    }\n  }\n}\n```\n\n### 2. Stdio Mode\n\nFor `stdio` mode, set the API key as an environment variable.\n\n\nConfiguration file example (`mcp.config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"Votars MCP Stdio\": {\n      \"type\": \"stdio\",\n      \"command\": \"votars-mcp\",\n      \"args\": [\"-t\", \"stdio\"],\n      \"env\": {\n        \"VOTARS_API_KEY\": \"<your-api-key>\"\n      }\n    }\n  }\n}\n```\n\n## Obtaining Your API Key\n\n1. Go to [Votars.AI](https://votars.ai/en/) and register.\n2. Navigate to your workspace's `Settings`.\n3. Create an API Key under the API Key management section.\n\n![manage apikey](https://private-user-images.githubusercontent.com/677477/427500562-8cfd8465-f408-4e9b-a101-8b9b8e5e57f5.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDMwNzQ4NzAsIm5iZiI6MTc0MzA3NDU3MCwicGF0aCI6Ii82Nzc0NzcvNDI3NTAwNTYyLThjZmQ4NDY1LWY0MDgtNGU5Yi1hMTAxLThiOWI4ZTVlNTdmNS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMzI3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDMyN1QxMTIyNTBaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02ODkyMWY3YzgyYTA2ZjdmNGQxN2MyYzllMzBmZmFiZmVjNGFmZTliNDQzODUwMjU2M2E1MjJkZTI4MmExM2VmJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.V0GAoh6l0JFRxmSokliGsVt5yNpxtmTmeCFiZG7U3jU)\n\n## Roadmap\n\n- **Current Support:** Go\n- **Planned Support:** Python, JavaScript, Rust, etc.\n\n## License\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "voice",
        "assistants",
        "virtual assistants",
        "scarletlabs ai",
        "transcription intelligent"
      ],
      "category": "virtual-assistants"
    },
    "suryawanshishantanu6--time-mcp": {
      "owner": "suryawanshishantanu6",
      "name": "time-mcp",
      "url": "https://github.com/suryawanshishantanu6/time-mcp",
      "imageUrl": "https://github.com/suryawanshishantanu6.png",
      "description": "Integrates a tool-augmented LLM pipeline to provide answers to time-related and general inquiries. Utilizes a Flask API for current timestamps and employs an MCP Agent for intent detection and interaction with an LLM via OpenRouter.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-08T03:55:06Z",
      "readme_content": "# time-mcp\n\nA minimal agentic AI system that answers time-related and general questions using a tool-augmented LLM pipeline.\n\n## Features\n- **Flask API**: Provides the current timestamp.\n- **MCP Agent Server**: Reasoning agent that detects user intent, calls tools (like the time API), engineers prompts, and interacts with an LLM via OpenRouter (OpenAI-compatible API).\n- **Streamlit UI**: Simple chat interface to talk to the AI agent.\n\n---\n\n## Setup\n\n### 1. Clone and Install Dependencies\n```bash\npip install -r requirements.txt\n```\n\n### 2. Environment Variable\nSet your OpenRouter API key (get one from https://openrouter.ai):\n```bash\nexport OPENROUTER_API_KEY=sk-...your-key...\n```\n\n### 3. Run the Servers\nOpen three terminals (or use background processes):\n\n#### Terminal 1: Flask Time API\n```bash\npython flask_api.py\n```\n\n#### Terminal 2: MCP Agent Server\n```bash\npython mcp_server.py\n```\n\n#### Terminal 3: Streamlit UI\n```bash\nstreamlit run streamlit_ui.py\n```\n\nThe Streamlit UI will open in your browser (default: http://localhost:8501)\n\n---\n\n## Usage\n- Ask the agent any question in the Streamlit UI.\n- If you ask about the time (e.g., \"What is the time?\"), the agent will call the Flask API, fetch the current time, and craft a beautiful, natural response using the LLM.\n- For other questions, the agent will answer using the LLM only.\n\n---\n\n## Architecture\n```\n[Streamlit UI] â†’ [MCP Agent Server] â†’ [Tools (e.g., Time API)]\n                            â†“\n                        [LLM via OpenRouter]\n```\n- The MCP agent detects intent, calls tools as needed, engineers prompts, and sends them to the LLM.\n- Easily extensible to add more tools (just add to the MCPAgent class).\n\n---\n\n## Customization\n- **Add more tools**: Implement new methods in `MCPAgent` and update `self.tools`.\n- **Improve intent detection**: Extend `detect_intent()` in `MCPAgent`.\n- **Change LLM model**: Update the `model` field in `call_llm()`.\n\n---\n\n## Requirements\n- Python 3.7+\n- See `requirements.txt` for dependencies.\n\n---\n\n## Credits\n- Built using Flask, Streamlit, OpenRouter, and Python.\n- Inspired by agentic LLM design patterns.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llm",
        "timestamps",
        "api",
        "virtual assistants",
        "augmented llm",
        "llm pipeline"
      ],
      "category": "virtual-assistants"
    },
    "tijs--py-sound-mcp": {
      "owner": "tijs",
      "name": "py-sound-mcp",
      "url": "https://github.com/tijs/py-sound-mcp",
      "imageUrl": "https://github.com/tijs.png",
      "description": "Plays customizable sound effects for coding events such as completions and errors, providing audio feedback in MCP-compatible environments. Integrates seamlessly with tools like Cursor to enhance the interactive development experience.",
      "stars": 1,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-12T09:02:31Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/tijs-py-sound-mcp-badge.png)](https://mseep.ai/app/tijs-py-sound-mcp)\n\n# MCP Sound Tool\n\nA Model Context Protocol (MCP) implementation that plays sound effects for Cursor AI and other MCP-compatible environments. This Python implementation provides audio feedback for a more interactive coding experience.\n\n## Features\n\n* Plays sound effects for various events (completion, error, notification)\n* Uses the Model Context Protocol (MCP) for standardized integration with Cursor and other IDEs\n* Cross-platform support (Windows, macOS, Linux)\n* Configurable sound effects\n\n## Installation\n\n### Python Version Compatibility\n\nThis package is tested with Python 3.8-3.11. If you encounter errors with Python 3.12+ (particularly `BrokenResourceError` or `TaskGroup` exceptions), please try using an earlier Python version.\n\n### Recommended: Install with pipx\n\nThe recommended way to install mcp-sound-tool is with [pipx](https://pypa.github.io/pipx/), which installs the package in an isolated environment while making the commands available globally:\n\n```bash\n# Install pipx if you don't have it\npython -m pip install --user pipx\npython -m pipx ensurepath\n\n# Install mcp-sound-tool\npipx install mcp-sound-tool\n```\n\nThis method ensures that the tool has its own isolated environment, avoiding conflicts with other packages.\n\n### Alternative: Install with pip\n\nYou can also install directly with pip:\n\n```bash\npip install mcp-sound-tool\n```\n\n### From Source\n\n1. Clone this repository:\n\n   ```bash\n   git clone https://github.com/yourusername/mcp-sound-tool\n   cd mcp-sound-tool\n   ```\n\n2. Install with pipx directly from the source directory:\n\n   ```bash\n   pipx install .\n   ```\n\n   Or with pip:\n\n   ```bash\n   pip install -e .\n   ```\n\n## Usage\n\n### Adding Sound Files\n\nPlace your sound files in the `sounds` directory. The following sound files are expected:\n\n* `completion.mp3` - Played after code generation\n* `error.mp3` - Played when an error occurs\n* `notification.mp3` - Used for general notifications\n\nYou can find free sound effects on websites like freesound.org.\n\n### Running the MCP Server\n\nRun the MCP server:\n\n```bash\nmcp-sound-tool\n```\n\nThe server will start and listen for events from Cursor or other MCP-compatible clients through the stdio transport.\n\n### Configuration in Cursor\n\nTo use this server with Cursor, add it to your MCP configuration file:\n\nOn macOS:\n\n```json\n// ~/Library/Application Support/Cursor/mcp.json\n{\n  \"mcpServers\": {\n    \"sound\": {\n      \"command\": \"mcp-sound-tool\",\n      \"args\": [],\n      \"type\": \"stdio\",\n      \"pollingInterval\": 5000,\n      \"startupTimeout\": 10000,\n      \"restartOnFailure\": true\n    }\n  }\n}\n```\n\nOn Windows:\n\n```json\n// %APPDATA%/Cursor/mcp.json\n{\n  \"mcpServers\": {\n    \"sound\": {\n      \"command\": \"mcp-sound-tool\",\n      \"args\": [],\n      \"type\": \"stdio\",\n      \"pollingInterval\": 5000,\n      \"startupTimeout\": 10000,\n      \"restartOnFailure\": true\n    }\n  }\n}\n```\n\nWhen installed with `pipx`, the `mcp-sound-tool` command will be available in your PATH, so Cursor will be able to find and execute it without specifying the full path.\n\n## Sound MCP Usage Guidelines for AI Models\n\nThis MCP server provides audio feedback capabilities for AI interactions. It's designed to enhance the user experience by providing clear audio cues that indicate the status of operations without requiring the user to read text.\n\n### When to Use Sound Feedback\n\nAI agents should use the sound tools proactively at appropriate moments:\n\n1. **Success Sounds (`completion`)**:\n   * After a task or command has successfully completed\n   * When a significant operation has finished successfully\n   * When confirming a user's request has been fulfilled\n\n2. **Error Sounds (`error`)**:\n   * When a command has failed or encountered an error\n   * When warning the user about a problem\n   * When an operation couldn't be completed as requested\n\n3. **Notification Sounds (`notification`)**:\n   * When alerting the user to important information\n   * When prompting for user attention or input\n   * For status updates on long-running operations\n\n### Example Usage\n\n```python\n# When a command completes successfully\n@mcp.tool()\ndef execute_command(command):\n    result = run_command(command)\n    if result.success:\n        play_sound(\"completion\")  # Indicate success with audio\n        return \"Command executed successfully\"\n    else:\n        play_sound(\"error\")  # Indicate failure with audio\n        return f\"Error: {result.error_message}\"\n```\n\n### Available Tools\n\n1. `play_sound(sound_type=\"completion\", custom_sound_path=None)`: Play a sound effect\n2. `list_available_sounds()`: List all available sound files\n3. `install_to_user_dir()`: Install sound files to user's config directory\n\nFor more details, connect to the MCP server and check the tool descriptions.\n\n## Development\n\nFor development:\n\n```bash\n# Install development dependencies\npip install -e \".[dev]\"\n\n# Run tests\npytest\n```\n\n## Acknowledgments\n\n* [SIAM-TheLegend](https://github.com/SIAM-TheLegend) for creating the original [sound-mcp](https://github.com/SIAM-TheLegend/sound-mcp) JavaScript implementation that inspired this Python version\n* The MCP protocol developers for creating a powerful standard for AI tool interactions\n* Contributors to the testing and documentation\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "interactive",
        "sound",
        "audio",
        "py sound",
        "sound mcp",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "uraoz--bouyomichan-mcp-nodejs": {
      "owner": "uraoz",
      "name": "bouyomichan-mcp-nodejs",
      "url": "https://github.com/uraoz/bouyomichan-mcp-nodejs",
      "imageUrl": "https://github.com/uraoz.png",
      "description": "Provides text-to-speech capabilities using BouyomiChan's Yukkuri voice, enabling voice output from text commands with customizable options for voice type, volume, speed, and pitch. Integrates seamlessly with Claude for Desktop for enhanced user interaction.",
      "stars": 2,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-01T11:48:46Z",
      "readme_content": "# æ£’èª­ã¿ã¡ã‚ƒã‚“MCPã‚µãƒ¼ãƒãƒ¼ (Node.jsç‰ˆ)\n\n<a href=\"https://glama.ai/mcp/servers/@uraoz/bouyomi-mcp-nodejs\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@uraoz/bouyomi-mcp-nodejs/badge\" alt=\"Bouyomi-chan Server MCP server\" />\n</a>\n\n\n## å‰ææ¡ä»¶\n\n- Node.js 16ä»¥ä¸Š\n- npm 7ä»¥ä¸Š\n- æ£’èª­ã¿ã¡ã‚ƒã‚“ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨\n- æ£’èª­ã¿ã¡ã‚ƒã‚“ã®HTTPé€£æºãŒãƒãƒ¼ãƒˆ50080ã§èµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨\n\n## ä½¿ç”¨æ–¹æ³•\n\n### ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•\n\n```bash\ngit clone https://github.com/uraoz/bouyomichan-mcp-nodejs.git\ncd bouyomichan-mcp-nodejs\nnpm install\nnpm run build\nnpm start\n```\n\n### Claude for Desktopã¨ã®é€£æº\n\n```json\n{\n  \"mcpServers\": {\n    \"bouyomichan\":{\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"github:uraoz/bouyomichan-mcp-nodejs\"\n      ]\n    }\n  }\n}\n```\n\n## ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¬æ˜\n\n| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ | æœ‰åŠ¹ç¯„å›² |\n|----------|------|------------|---------|\n| text     | èª­ã¿ä¸Šã’ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ | å¿…é ˆ | ä»»æ„ã®ãƒ†ã‚­ã‚¹ãƒˆ |\n| voice    | éŸ³å£°ã®ç¨®é¡ | 0 (å¥³æ€§1) | 0: å¥³æ€§1ã€1: ç”·æ€§1ã€2: å¥³æ€§2ã€... |\n| volume   | éŸ³é‡ | -1 (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ) | -1: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã€0-100: éŸ³é‡ãƒ¬ãƒ™ãƒ« |\n| speed    | é€Ÿåº¦ | -1 (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ) | -1: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã€50-200: é€Ÿåº¦ãƒ¬ãƒ™ãƒ« |\n| tone     | éŸ³ç¨‹ | -1 (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ) | -1: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã€50-200: éŸ³ç¨‹ãƒ¬ãƒ™ãƒ« |\n\n## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "voice",
        "bouyomichan",
        "nodejs",
        "yukkuri voice",
        "enabling voice",
        "voice output"
      ],
      "category": "virtual-assistants"
    },
    "veenastudio--flstudio-mcp": {
      "owner": "veenastudio",
      "name": "flstudio-mcp",
      "url": "https://github.com/veenastudio/flstudio-mcp",
      "imageUrl": "https://github.com/veenastudio.png",
      "description": "Connects AI model Claude to FL Studio for seamless integration of melodies, chords, and drum patterns into music projects. Facilitates real-time music production by allowing interaction between AI and the FL Studio environment.",
      "stars": 59,
      "forks": 4,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-30T19:37:52Z",
      "readme_content": "# flstudio MCP\n\n# This is an MCP server that connects Claude to FL Studio.\nMade this in 3 days. We're open sourcing it to see what we can actually get out of it. The possibilities are endless.\n\n## If you're running to any issues, join our discord and we can setup it for you.\n(also join if you interested in the future of music and AI or want to request features. we're building this with you)\n\nhttps://discord.gg/ZjG9TaEhvy\n\nCheck out our AI-Powered DAW for musicians at www.veena.studio\n\nAll in browser. All for free.\n\n\n## Step 1: Download the Files\nYou should see two main items.\n\n- A folder called Test Controller\n- A python file called trigger.py\nThe Test Controller folder has a file called device_test.py that receives information from the MCP server.\ntrigger.py is the MCP server.\n\nPlace the Test Controller folder in Image-Line/FL Studio/Settings/Hardware (Don't change the name of this file or folder)\n\n## Step 2: Set up MCP for Claude\nFollow this tutorial to see how to setup MCP servers in Claude by edyting the claude_desktop_config files.\n\nhttps://modelcontextprotocol.io/quickstart/server\n\nIf you followed this process, make sure to change whatever mentions of weather.py to trigger.py\n\nIf the Hammer icon doesn't show up, open Task Manager and force close the Claude process.\n\nIt should then show up.\n\nThis is what my config file looks like\n\n![mcp](https://github.com/user-attachments/assets/e8e609f7-eaa4-469b-9140-c05b5a9bf242)\n\n## Step 3: Set Up Virtual MIDI Ports\n\n### For Windows\nFor Windows, download LoopMIDI from here.\n\nhttps://www.tobias-erichsen.de/software/loopmidi.html\n\nInstall LoopMIDI and add a port using the + button.\n\nThis is what mine looks like:\n![loopmidi2](https://github.com/user-attachments/assets/fdc2770f-e07a-4b19-824b-56de8a4aa2c3)\n\n### For Mac\nYour MIDI Ports would be automatically setup to receive data.\n\n## Step 4: Setup MIDI Controller\nOpen FL Studio.\n\nGo To Options > MIDI Settings.\n\nIn the Input Tab, click the MIDI Input you just created with LoopMIDI.\n\nChange controller type from (generic controller) to Test Controller.\n\n## Step 5: Download Packages\nGo to the folder with the trigger.py file. (This is the MCP Server file)\n\nActivate the conda environment (like you learned in the Claude MCP Setup Tutorial)\n\nRun this command to download the necessary packages: uv pip install httpx mido python-rtmidi typing fastmcp FL-Studio-API-Stubs\n(uv should be installed from the Claude MCP setup)\n\n## Step 6: Verify MCP Connection\nTell Claude to get available MIDI ports.\n\nThis should use the MCP to get the ports from FL Studio.\n\nIf Windows, copy the port you created with LoopMIDI and the number in front of it.\n\nIf Mac, copy the default port.\n\n![loopmidi](https://github.com/user-attachments/assets/a14b0aaa-5127-47c9-b041-fcb5a70339d9)\n\nIn my case, I copy loopMIDI Port 2\n\nOpen trigger.py in a text editor and replace the default port with the name of the port you just copied.\noutput_port = mido.open_output('loopMIDI Port 2') \n\n\n## Step 7: Make Music\nUse the MCP to send melodies, chords, drums, etc.\n\nClick on the instrument you want to record to and it will live record to the piano roll of that instrument.\n\nI tend to use this prompt when I start a new chat: Here is format for notes: note(0-127),velocity(0-100),length in beats(decimal),position in beats(decimal)\n\n## Step 8: Share what you made\nShare what you made on our Discord: https://discord.gg/ZjG9TaEhvy\n\n## Credits\nFL Studio API Stubs: https://github.com/IL-Group/FL-Studio-API-Stubs\nAbleton MCP: https://github.com/ahujasid/ableton-mcp\n\n## Nerd Stuff\nIf you want to contribute please go ahead. \n\nThe way this works is that device_test.py behaves as a virtual MIDI Controller.\nThe MCP server (trigger.py) communicates with this MIDI Controller by opening a Virtual Port and sending MIDI messages through a library called MIDO.\n\nThe issue with MIDI messages is that its only 7 bits so we can only send in number from 0-127.\n\nSo we encrypt all of our MIDI data like note position, etc in multiple MIDI notes that the device knows how to read.\n\nHopefully, Image Line can give us more access to their DAW via their API so we don't have to do this MIDI nonsense.\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "flstudio",
        "studio",
        "ai",
        "fl studio",
        "flstudio mcp",
        "virtual assistants"
      ],
      "category": "virtual-assistants"
    },
    "wangyafu--haiguitangmcp": {
      "owner": "wangyafu",
      "name": "haiguitangmcp",
      "url": "https://github.com/wangyafu/haiguitangmcp",
      "imageUrl": "https://github.com/wangyafu.png",
      "description": "Host interactive Turtle Soup games with an AI game master, enabling solo play and puzzle exploration with access to puzzles, game rules, and hints through standardized tools.",
      "stars": 6,
      "forks": 4,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-02T08:53:43Z",
      "readme_content": "## ä»‹ç»\r\n\r\næœ¬é¡¹ç›®æ—¨åœ¨è®©å¤§è¯­è¨€æ¨¡å‹æ‰®æ¼”æµ·é¾Ÿæ±¤æ¸¸æˆä¸»æŒäººï¼Œä½¿ä½ ç‹¬è‡ªä¸€äººä¹Ÿèƒ½äº«å—æµ·é¾Ÿæ±¤æ¸¸æˆçš„å¿«ä¹ã€‚\r\n\r\n## å¿«é€Ÿå¼€å§‹\r\n\r\nåœ¨ä½¿ç”¨æœ¬é¡¹ç›®å‰ï¼Œä½ éœ€è¦ç¡®ä¿ä½ çš„ç”µè„‘ä¸Šå·²ç»å®‰è£…äº†Pythonå’Œuvã€‚\r\n\r\n\r\nä½ é¦–å…ˆéœ€è¦å…‹éš†æ•´ä¸ªé¡¹ç›®ï¼Œç„¶åè¿è¡Œuv syncå®‰è£…ä¾èµ–ã€‚\r\n\r\n```bash\r\ngit clone https://github.com/wangyafu/haiguitangmcp/\r\ncd haiguitangmcp\r\nuv sync\r\n```\r\n\r\nå…¶æ¬¡ï¼Œä½ éœ€è¦ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼ˆå‡è®¾ä½ å°†é¡¹ç›®å®‰è£…åœ¨äº†Eç›˜ï¼‰\r\n\r\n### åœ¨vscodeä¸­é…ç½®\r\n\r\n```json\r\n\"mcp\":{\r\n    \"servers\":{\r\n        \"haiguitang-mcp\": {\r\n                \"type\": \"stdio\",\r\n                \"command\": \"uv\",\r\n                \"args\": [\r\n                    \"--directory\",\r\n                    \"E:\\\\haiguitangmcp\\\\haiguitang_mcp\",\r\n                    \"run\",\r\n                    \"server.py\"\r\n                ]\r\n            }\r\n    }\r\n}\r\n\r\n\r\n```\r\n\r\n### åœ¨cherry studioä¸­è¿›è¡Œé…ç½®\r\n\r\n```json\r\n\"mcpServers\": {\r\n    \r\n    \"haiguitang\": {\r\n      \"isActive\": true,\r\n      \"name\": \"æµ·é¾Ÿæ±¤MCPæœåŠ¡å™¨\",\r\n      \"description\": \"å’Œç”¨æˆ·ç©æµ·é¾Ÿæ±¤\",\r\n      \"registryUrl\": \"\",\r\n      \"command\": \"uv\",\r\n      \"args\": [\r\n        \"--directory\",\r\n        \"E:/haiguitangmcp/haiguitang_mcp\",\r\n        \"run\",\r\n        \"server.py\"\r\n      ]\r\n    },\r\n   \r\n}\r\n\r\n```\r\n\r\nä¸Šè¿°çš„\"E:/haiguitangmcp/haiguitang_mcp\"è¡¨ç¤ºserver.pyæ‰€åœ¨çš„è·¯å¾„ã€‚\r\n\r\nåœ¨å…¶ä»–mcp clientä¸­çš„é…ç½®æ–¹æ³•ç±»ä¼¼ã€‚\r\n\r\n## mcpç›¸å…³å†…å®¹\r\n\r\næœ¬é¡¹ç›®æä¾›äº†ä¸‰ä¸ªå·¥å…·:\r\n\r\n- `get_prompt`: è·å–æµ·é¾Ÿæ±¤æ¸¸æˆçš„å®Œæ•´ç©æ³•è¯´æ˜\r\n- `get_puzzle`: è·å–ä¸€ä¸ªç‰¹å®šè°œé¢˜çš„å®Œæ•´å†…å®¹ï¼Œéœ€è¦æä¾›è°œé¢˜æ ‡é¢˜ä½œä¸ºå‚æ•°\r\n- `list_puzzles_tool`: åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è°œé¢˜åˆ—è¡¨\r\n\r\nåŒæ—¶ï¼Œæœ¬é¡¹ç›®è¿˜æä¾›äº†ä»¥ä¸‹èµ„æº:\r\n\r\n- `puzzles://{puzzle_title}`: è·å–ç‰¹å®šè°œé¢˜çš„ä¿¡æ¯\r\n\r\nä»¥åŠä¸€ä¸ªæç¤ºæ¨¡æ¿:\r\n\r\n- `game_rules`: æä¾›æµ·é¾Ÿæ±¤æ¸¸æˆè§„åˆ™çš„æç¤ºæ¨¡æ¿\r\n\r\n## æ¸¸æˆè§„åˆ™\r\n\r\nåœ¨æœ¬æ¸¸æˆä¸­ï¼š\r\n\r\n- æµ·é¾Ÿæ±¤æ˜¯ä¸€ç§æƒ…æ™¯æ¨ç†æ¸¸æˆï¼Œè°œé¢˜æœ¬èº«å¹¶æ²¡æœ‰å¾ˆå¼ºçš„é€»è¾‘æ€§ï¼Œæ³¨é‡èƒ½å¦å‘ç°å…³é”®çº¿ç´¢é‡ç°æƒ…æ™¯\r\n- å‡ºé¢˜äººæå‡ºä¸€ä¸ªçœ‹ä¼¼ä¸åˆå¸¸ç†çš„é—®é¢˜å’Œæƒ…æ™¯ï¼ˆè°œé¢ï¼‰ï¼ŒçŒœé¢˜è€…é€šè¿‡æé—®ç¼©å°èŒƒå›´å¹¶æœ€ç»ˆæ­ç¤ºå®Œæ•´æ•…äº‹æƒ…èŠ‚ï¼ˆè°œåº•ï¼‰\r\n- çŒœé¢˜è€…å¯ä»¥æå‡ºä»»ä½•é—®é¢˜ï¼Œå‡ºé¢˜äººä¸»è¦ç”¨\"æ˜¯\"ã€\"ä¸æ˜¯\"ã€\"æ˜¯ä¹Ÿä¸æ˜¯\"æˆ–\"æ²¡æœ‰å…³ç³»\"æ¥å›ç­”\r\n- å½“é—®é¢˜ä¸­æ—¢æœ‰å¯¹çš„åœ°æ–¹ä¹Ÿæœ‰ä¸å¯¹çš„åœ°æ–¹æ—¶ï¼Œå‡ºé¢˜äººä¼šå›ç­”\"æ˜¯ä¹Ÿä¸æ˜¯\"\r\n- å½“é—®é¢˜ä¸è°œé¢˜æ ¸å¿ƒæƒ…èŠ‚æ— å…³æ—¶ï¼Œå‡ºé¢˜äººä¼šå›ç­”\"æ²¡æœ‰å…³ç³»\"\r\n- çŒœé¢˜è€…å¯ä»¥é€šè¿‡åœ¨æ¶ˆæ¯å¼€å¤´åŠ ä¸Š\"æ±¤åº•\"æ¥å°è¯•æè¿°å®Œæ•´æƒ…æ™¯\r\n- å½“çŒœé¢˜è€…æŒæ¡äº†å…³é”®çº¿ç´¢æ—¶ï¼Œå‡ºé¢˜äººä¼šæé†’çŒœé¢˜è€…å½’çº³çº¿ç´¢ï¼Œå½¢æˆå¯¹è°œåº•çš„å®Œæ•´æè¿°\r\n- çŒœé¢˜è€…å¯ä»¥è¯·æ±‚å¼•å¯¼å’Œæç¤ºï¼Œå‡ºé¢˜äººä¼šç»™äºˆå°šæœªæŒæ¡çš„çº¿ç´¢\r\n- å½“çŒœé¢˜è€…çš„æè¿°å¤§è‡´åŒ…å«äº†è°œé¢˜çš„å…³é”®æƒ…æ™¯æ—¶ï¼Œå‡ºé¢˜äººä¼šç¡®è®¤\"å®Œå…¨æ­£ç¡®\"\r\n\r\n\r\n### å°æŠ€å·§\r\n\r\n- ä»åŸºæœ¬é—®é¢˜å¼€å§‹ï¼Œå¦‚è°œé¢˜æ¶‰åŠäººæ•°ã€æ­»è€…çš„æ­»å› ç­‰ã€‚\r\n- æ³¨æ„è°œé¢ä¸­çš„æ¯ä¸€ä¸ªç»†èŠ‚ï¼Œå®ƒä»¬å¯èƒ½æ˜¯å…³é”®çº¿ç´¢\r\n- å½“ä½ æ„Ÿåˆ°å›°æƒ‘æ—¶ï¼Œå°è¯•ä»ä¸åŒè§’åº¦æ€è€ƒé—®é¢˜\r\n- è®°å½•å·²ç»ç¡®è®¤çš„çº¿ç´¢ï¼Œä»¥ä¾¿å½’çº³æ•´ç†\r\n\r\n## å…³äºè°œé¢˜\r\n\r\nç›®å‰æœ¬é¡¹ç›®å·²ç»æä¾›äº†35ä¸ªè°œé¢˜ã€‚\r\næœ¬äººæ›¾å¼€å‘[æµ·é¾Ÿæ±¤æ¨¡æ‹Ÿå™¨](https://www.hgtang.com)ï¼Œè¯¥ç½‘ç«™æœ‰è¯„åˆ†åŠŸèƒ½ã€‚ç›®å‰çš„35ä¸ªè°œé¢˜æ¥è‡ªäºæˆ‘å’Œä¸€äº›çƒ­å¿ƒç”¨æˆ·ä¸ºè¯¥ç½‘ç«™æœé›†çš„è°œé¢˜ã€‚ä¾æ®è¯¥ç½‘ç«™ä¸Šå„è°œé¢˜çš„è¯„åˆ†ï¼Œæ¨èæ¸¸ç©çš„è°œé¢˜å¦‚ä¸‹ï¼š\r\n\r\n- å¿ è¯šçš„ç‹—\r\n- 100å…ƒé’±\r\n- çˆ±çŠ¬\r\n- æ²»ç—…\r\n- ç¥­æ—¥\r\n- ç”µæ¢¯é‡Œçš„äºº\r\n- å»¶è¿Ÿæ­»äº¡\r\n- ç”Ÿæ„\r\n- è£¤å­ç ´äº†\r\n- è¦å¥½çš„æœ‹å‹\r\n\r\næ¬¢è¿ä½ ä¸ºæœ¬é¡¹ç›®è´¡çŒ®æ›´å¤šçš„è°œé¢˜ã€‚ä½ å¯ä»¥åœ¨haiguitang_mcp/puzzlesæ–‡ä»¶å¤¹ä¸­åŠ å…¥æ–°çš„è°œé¢˜æ–‡ä»¶ç„¶åå‘èµ·Pull Requestã€‚\r\n\r\næ³¨æ„ï¼š\r\n\r\n- å¦‚æœä½ å¸Œæœ›ç”¨æˆ·æ¸¸ç©ä¹‹å‰æœ‰æ‰€é¢„è­¦ï¼Œä½ å¯ä»¥åœ¨æ ‡é¢˜ï¼Œä¹Ÿå°±æ˜¯è°œé¢˜æ–‡ä»¶çš„åç§°ä¸­æ³¨æ˜ã€‚\r\n- è¯·æ³¨æ„æµ·é¾Ÿæ±¤çš„ç‰ˆæƒé—®é¢˜ã€‚\r\n- ä½ å¯ä»¥åœ¨æµ·é¾Ÿæ±¤æ–‡ä»¶ä¸­æ·»åŠ ä½œè€…å’Œæäº¤è€…ä¿¡æ¯ã€‚\r\n\r\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "interactive",
        "soup",
        "ai",
        "soup games",
        "games ai",
        "interactive turtle"
      ],
      "category": "virtual-assistants"
    }
  }
}