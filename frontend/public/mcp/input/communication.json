{
  "category": "communication",
  "categoryDisplay": "Communication",
  "description": "Integration with communication platforms for message management and channel operations. Enables AI models to interact with team communication tools.",
  "totalRepositories": 26,
  "repositories": {
    "Cactusinhand--mcp_server_notify": {
      "owner": "Cactusinhand",
      "name": "mcp_server_notify",
      "url": "https://github.com/Cactusinhand/mcp_server_notify",
      "imageUrl": "",
      "description": "A MCP server that send desktop notifications with sound effect when agent tasks are completed.",
      "stars": 33,
      "forks": 9,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-26T20:01:30Z",
      "readme_content": "<a href=\"https://glama.ai/mcp/servers/@Cactusinhand/mcp_server_notify\"> <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@Cactusinhand/mcp_server_notify/badge\" alt=\"Glama badge for Notify MCP server\" /> </a> [![MseeP.ai Security Assessment Badge](https://mseep.net/pr/cactusinhand-mcp-server-notify-badge.png)](https://mseep.ai/app/cactusinhand-mcp-server-notify) \n\n[![PyPI version](https://badge.fury.io/py/mcp-server-notify.svg)](https://badge.fury.io/py/mcp-server-notify)\n\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/Cactusinhand/mcp_server_notify)](https://archestra.ai/mcp-catalog/Cactusinhand__mcp_server_notify)\n\n\n# 📢 MCP Notify Server\n\n\n\n[English](README.md) | [中文](README.zh.md)\n\nA MCP server that send desktop notifications with sound effect when agent tasks are completed.\n\n## 🥩 Features\n\n- Send system desktop notifications after agent tasks completion\n- Play alert sounds to grab user attention, with sound file inside.\n- Cross-platform support (Windows, macOS, Linux)\n- Based on standard MCP protocol, integrates with various LLM clients\n\n## ⏬ Installation\n\n### Install using [uv](https://docs.astral.sh/uv/) package manager\n\n```bash\ngit clone https://github.com/Cactusinhand/mcp_server_notify.git\ncd mcp_server_notify\n\nuv venv\nsource .venv/Scripts/activate\n\nuv pip install mcp-server-notify\n# or\npip install mcp-server-notify\n```\n\nAfter installation, call the module directly to check if installation was successful:\n```bash\npython -m mcp_server_notify\n```\nThis module accepts ` --debug ` or `--file ` option, we can use it like:\n```shell\npython -m mcp_server_notify --debug\npython -m mcp_server_notify --debug --log-file=path/to/logfile.log\n```\n\n## ⚠️❕ Special requirements\n\n** We use [Apprise](https://github.com/caronc/apprise) API for our Desktop notification deliver，so we need to install some special requirements in our Desktop **\n\n**Windows**\n```shell\n# windows:// minimum requirements\npip install pywin32\n```\n\n**macOS**\n```shell\n# Make sure terminal-notifier is installed into your system\nbrew install terminal-notifier\n```\n\n## 📚 Usage\n\n### Using with Claude Desktop:\n\nFind the configuration file `claude_desktop_config.json`\n```json\n{\n    \"mcpServers\": {\n        \"NotificationServer\": {\n            \"command\": \"uv\",\n            \"args\": [\n              \"--directory\",\n              \"path/to/your/mcp_server_notify project\",\n              \"run\",\n              \"mcp-server-notify\",\n            ]\n        }\n    }\n}\n```\n\nIf installed globally, you can also use the python command:\n```json\n{\n    \"mcpServers\": {\n        \"NotificationServer\": {\n            \"command\": \"python\",\n            \"args\": [\n              \"-m\",\n              \"mcp_server_notify\",\n            ]\n        }\n    }\n}\n```\n\n### ⚡️ Using with Cursor:\nFind the configuration file `~/.cursor/mcp.json` or `your_project/.cursor/mcp.json`\n```json\n{\n    \"mcpServers\": {\n        \"NotificationServer\": {\n            \"command\": \"uv\",\n            \"args\": [\n              \"--directory\",\n              \"path/to/your/mcp_server_notify project\",\n              \"run\",\n              \"mcp-server-notify\",\n            ]\n        }\n    }\n}\n```\n\nAfter configuration, simply add a prompt like `finally, send me a notification when task finished.` at the end of your task input to the AI to trigger notifications.\n\nIn Cursor, you can add this prompt as a rule in `Cursor Settings` -> `Rules` so you don't have to type it manually each time.\n\n### ⚡️ Using with VSCode + Copilot:\n1.\tInstall the service manager [uv/uvx](https://docs.astral.sh/uv/):\n`pip install uv`\n2.\t Add the service to VSCode settings:\n\n     Windows `%APPDATA%\\Code\\User\\settings.json`  \nmacOS `$HOME/Library/Application\\ Support/Code/User/settings.json`  \nLinux `$HOME/.config/Code/User/settings.json`  \n\n\t ```json\n\t \"mcp\": {\n         \"servers\": {\n             \"notifier\": {\n                 \"command\": \"uvx\",\n                 \"args\": [\n                     \"mcp-server-notify\"\n                 ],\n                 \"env\": {}\n             }\n         }\n\t }\n\t ```\n3.\tMake sure you are using the latest VSCode version — it automatically runs MCP services\n4.\tOpen VSCode → enable Copilot → switch to agent mode.\n5.\tType # → you will see the #send_notification option.\n6.\tAsk the agent: run #send_notification (it will handle the notification automatically).\n7.\tNow the Copilot in agent mode can send desktop notifications.\n\n\n\n### 🐳 Running with Docker\n\nCurrently not available due to environment compatibility issues.\nIf Docker containers need to trigger host notifications regardless of whether the host OS is Windows, macOS, or Linux, the solution becomes much more complex, and direct use of native notifications is usually not feasible.\n\nMain issues:\n1. OS-specific notification systems\nEach operating system (Windows, macOS, Linux) has its unique notification mechanism.\n\n2. Docker isolation\nThe isolation of Docker containers limits their ability to access host operating system resources directly.\n\n3. Dependency management\nNeed to handle different notification libraries and dependencies for each operating system.\n\n## 🧾 License\n\nMIT\n\n## 💻 Contributions\n\nIssues and pull requests are welcome!\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp_server_notify",
        "communication",
        "notifications",
        "communication integration",
        "message management",
        "communication platforms"
      ],
      "category": "communication"
    },
    "Danielpeter-99--calcom-mcp": {
      "owner": "Danielpeter-99",
      "name": "calcom-mcp",
      "url": "https://github.com/Danielpeter-99/calcom-mcp",
      "imageUrl": "",
      "description": "MCP server for Calcom. Manage event types, create bookings, and access Cal.com scheduling data through LLMs.",
      "stars": 12,
      "forks": 8,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-17T14:18:29Z",
      "readme_content": "# Cal.com FastMCP Server\r\n\r\n> ⚠️ **Disclaimer**: This project is not affiliated with or endorsed by Cal.com. I am an independent developer and have no association with Cal.com in any official capacity.\r\n\r\nThis project provides a FastMCP server for interacting with the Cal.com API. It allows Language Learning Models (LLMs) to use tools to connect with important Cal.com functionalities like managing event types and bookings.\r\n\r\n## Prerequisites\r\n\r\n- Python 3.8+\r\n- A Cal.com account and API Key (v2)\r\n\r\n## Setup\r\n\r\n1.  **Clone the repository (if applicable) or download the files.**\r\n    ```bash\r\n    git clone https://github.com/Danielpeter-99/calcom-mcp.git\r\n    cd calcom-mcp\r\n    ```\r\n    \r\n2.  **Create a virtual environment (recommended):**\r\n    ```bash\r\n    python -m venv venv\r\n    source venv/bin/activate  # On Windows: venv\\Scripts\\activate\r\n    ```\r\n\r\n3.  **Install dependencies:**\r\n    ```bash\r\n    pip install -r requirements.txt\r\n    ```\r\n\r\n4.  **Set up the Cal.com API Key:**\r\n    You need to set the `CALCOM_API_KEY` environment variable. You can get your API key from your Cal.com settings page (usually under Developer or Security settings).\r\n\r\n    -   **Linux/macOS:**\r\n        ```bash\r\n        export CALCOM_API_KEY=\"your_actual_api_key_here\"\r\n        ```\r\n        To make it permanent, add this line to your shell configuration file (e.g., `.bashrc`, `.zshrc`).\r\n\r\n    -   **Windows (PowerShell):**\r\n        ```powershell\r\n        $env:CALCOM_API_KEY=\"your_actual_api_key_here\"\r\n        ```\r\n        To make it permanent, you can set it through the System Properties > Environment Variables.\r\n\r\n## Running the Server\r\n\r\nOnce the setup is complete, you can run the FastMCP server:\r\n\r\n```bash\r\nfastmcp run app.py --transport sse --port 8010\r\n```\r\n\r\nThe server will start at localhost:8010, and you should see output indicating it's running. If the `CALCOM_API_KEY` is not set, a warning will be displayed.\r\n\r\n## Available Tools\r\n\r\nThe server currently provides the following tools for LLM interaction:\r\n\r\n-   `get_api_status()`: Check if the Cal.com API key is configured in the environment. Returns a string indicating the status.\r\n-   `list_event_types()`: Fetch a list of all event types from Cal.com for the authenticated account. Returns a dictionary with the list of event types or an error message.\r\n-   `get_bookings(...)`: Fetch a list of bookings from Cal.com, with optional filters (event_type_id, user_id, status, date_from, date_to, limit). Returns a dictionary with the list of bookings or an error message.\r\n-   `create_booking(...)`: Create a new booking in Cal.com for a specific event type and attendee. Requires parameters like start_time, attendee details, and event type identifiers. Returns a dictionary with booking details or an error message.\r\n-   `list_schedules(...)`: List all schedules available to the authenticated user or for a specific user/team. Optional filters: user_id, team_id, limit. Returns a dictionary with the list of schedules or an error message.\r\n-   `list_teams(...)`: List all teams available to the authenticated user. Optional filter: limit. Returns a dictionary with the list of teams or an error message.\r\n-   `list_users(...)`: List all users available to the authenticated account. Optional filter: limit. Returns a dictionary with the list of users or an error message.\r\n-   `list_webhooks(...)`: List all webhooks configured for the authenticated account. Optional filter: limit. Returns a dictionary with the list of webhooks or an error message.\r\n\r\n**Note:** All tools require the `CALCOM_API_KEY` environment variable to be set. If it is not set, tools will return a structured error message.\r\n\r\n## Tool Usage and Error Handling\r\n\r\n- All tools return either the API response (as a dictionary or string) or a structured error message with details about the failure.\r\n- Error messages include the type of error, HTTP status code (if applicable), and the response text from the Cal.com API.\r\n- For best results, always check for the presence of an `error` key in the response before using the returned data.\r\n- Tools are designed to be robust and provide informative feedback for both successful and failed API calls.\r\n\r\n## Development Notes\r\n\r\n-   The Cal.com API base URL is set to `https://api.cal.com/v2`.\r\n-   Authentication is primarily handled using a Bearer token with the `CALCOM_API_KEY`.\r\n-   The `create_booking` tool uses the `cal-api-version: 2024-08-13` header as specified in the Cal.com API v2 documentation for that endpoint.\r\n-   Error handling is included in the API calls to provide informative responses.\r\n\r\n## 🚀 Built With\r\n\r\n[![Python](https://img.shields.io/badge/Python-3.8+-blue?logo=python&logoColor=white)](https://www.python.org/)  \r\n[![FastMCP](https://img.shields.io/badge/FastMCP-Framework-8A2BE2?logo=fastapi&logoColor=white)](https://github.com/jlowin/fastmcp)  \r\n[![Cal.com API](https://img.shields.io/badge/Cal.com%20API-v2-00B8A9?logo=google-calendar&logoColor=white)](https://cal.com/docs/api-reference/v2/introduction)  \r\n\r\n\r\n## Important Security Note\r\n\r\n**Never hardcode your `CALCOM_API_KEY` directly into the source code.** Always use environment variables as described in the setup instructions to keep your API key secure.\r\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "calcom",
        "communication",
        "mcp",
        "communication integration",
        "server calcom",
        "communication platforms"
      ],
      "category": "communication"
    },
    "InditexTech--mcp-teams-server": {
      "owner": "InditexTech",
      "name": "mcp-teams-server",
      "url": "https://github.com/InditexTech/mcp-teams-server",
      "imageUrl": "",
      "description": "MCP server that integrates Microsoft Teams messaging (read, post, mention, list members and threads)",
      "stars": 319,
      "forks": 22,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-03T13:48:21Z",
      "readme_content": "[![Bugs](https://sonarcloud.io/api/project_badges/measure?project=InditexTech_mcp-teams-server&metric=bugs)](https://sonarcloud.io/summary/new_code?id=InditexTech_mcp-teams-server)\n[![Maintainability Rating](https://sonarcloud.io/api/project_badges/measure?project=InditexTech_mcp-teams-server&metric=sqale_rating)](https://sonarcloud.io/summary/new_code?id=InditexTech_mcp-teams-server)\n[![Reliability Rating](https://sonarcloud.io/api/project_badges/measure?project=InditexTech_mcp-teams-server&metric=reliability_rating)](https://sonarcloud.io/summary/new_code?id=InditexTech_mcp-teams-server)\n![GitHub License](https://img.shields.io/github/license/InditexTech/mcp-teams-server)\n![GitHub Release](https://img.shields.io/github/v/release/InditexTech/mcp-teams-server)\n[![Scorecard](https://api.scorecard.dev/projects/github.com/InditexTech/mcp-teams-server/badge)](https://scorecard.dev/viewer/?uri=github.com/InditexTech/mcp-teams-server)\n<!-- [![Best Practices](https://www.bestpractices.dev/projects/10400/badge)](https://www.bestpractices.dev/projects/10400) -->\n\n\n# MCP Teams Server\n\nAn MCP ([Model Context Protocol](https://modelcontextprotocol.io/introduction)) server implementation for \n[Microsoft Teams](https://www.microsoft.com/en-us/microsoft-teams/group-chat-software/) integration, providing capabilities to \nread messages, create messages, reply to messages, mention members.\n\n## Features\n\nhttps://github.com/user-attachments/assets/548a9768-1119-4a2d-bd5c-6b41069fc522\n\n- Start thread in channel with title and contents, mentioning users\n- Update existing threads with message replies, mentioning users\n- Read thread replies\n- List channel team members\n- Read channel messages\n\n## Prerequisites\n\n- [uv](https://github.com/astral-sh/uv) package manager\n- [Python 3.10](https://www.python.org/)\n- Microsoft Teams account with [proper set-up](./doc/MS-Teams-setup.md)\n\n## Installation\n\n1. Clone the repository:\n\n```bash\ngit clone [repository-url]\ncd mcp-teams-server\n```\n\n2. Create a virtual environment and install dependencies:\n\n```bash\nuv venv\nuv sync --frozen --all-extras --dev\n```\n\n## Teams configuration\n\nPlease read [this document](./doc/MS-Teams-setup.md) to help you to configure Microsoft Teams and required \nAzure resources. It is not a step-by-step guide but can help you figure out what you will need.\n\n## Usage\n\nSet up the following environment variables in your shell or in an .env file. You can use [sample file](./sample.env) \nas a template:\n\n| Key                     | Description                                |\n|-------------------------|--------------------------------------------|\n| **TEAMS_APP_ID**        | UUID for your MS Entra ID application ID   |\n| **TEAMS_APP_PASSWORD**  | Client secret                              |\n| **TEAMS_APP_TYPE**      | SingleTenant or MultiTenant                |\n| **TEAMS_APP_TENANT_ID** | Tenant uuid in case of SingleTenant        |\n| **TEAM_ID**             | MS Teams Group Id or Team Id               |\n| **TEAMS_CHANNEL_ID**    | MS Teams Channel ID with url escaped chars |\n\nStart the server:\n\n```bash\nuv run mcp-teams-server\n```\n\n## Development\n\nIntegration tests require the set-up the following environment variables:\n\n| Key                    | Description                    |\n|------------------------|--------------------------------|\n| **TEST_THREAD_ID**     | timestamp of the thread id     |\n| **TEST_MESSAGE_ID**    | timestamp of the message id    |\n| **TEST_USER_NAME**     | test user name                 |\n\n\n```bash\nuv run pytest -m integration\n```\n\n### Pre-built docker image\n\nThere is a [pre-built image](https://github.com/InditexTech/mcp-teams-server/pkgs/container/mcp-teams-server) hosted in ghcr.io.\nYou can install this image by running the following command\n\n```commandline\ndocker pull ghcr.io/inditextech/mcp-teams-server:latest\n```\n\n### Build docker image\n\nA docker image is available to run MCP server. You can build it with the following command:\n\n```bash\ndocker build . -t inditextech/mcp-teams-server\n```\n\n### Run docker image\n\nBasic run configuration:\n\n```bash\ndocker run -it inditextech/mcp-teams-server\n```\n\nRun with environment variables from .env file:\n\n```bash\ndocker run --env-file .env -it inditextech/mcp-teams-server\n```\n\n### Setup LLM to use MCP Teams Server\n\nPlease follow instructions on the [following document](./llms-install.md)\n\n## Changelog\n\nSee [CHANGELOG.md](CHANGELOG.md) for a list of changes and version history.\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull\nrequests.\n\n## Security\n\nFor security concerns, please see our [Security Policy](SECURITY.md).\n\n## License\n\nThis project is licensed under the [Apache-2.0](LICENSE.txt) file for details.\n\n© 2025 INDUSTRIA DE DISEÑO TEXTIL S.A. (INDITEX S.A.)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "messaging",
        "communication",
        "mcp",
        "teams messaging",
        "team communication",
        "message management"
      ],
      "category": "communication"
    },
    "OverQuotaAI--chatterboxio-mcp-server": {
      "owner": "OverQuotaAI",
      "name": "chatterboxio-mcp-server",
      "url": "https://github.com/OverQuotaAI/chatterboxio-mcp-server",
      "imageUrl": "",
      "description": "MCP server implementation for ChatterBox.io, enabling AI agents to send bots to online meetings (Zoom, Google Meet) and obtain transcripts and recordings.",
      "stars": 7,
      "forks": 3,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-08-22T03:17:05Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/chatterboxio-chatterboxio-mcp-server-badge.png)](https://mseep.ai/app/chatterboxio-chatterboxio-mcp-server)\n\n# ChatterBox MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@OverQuotaAI/chatterboxio-mcp-server)](https://smithery.ai/server/@OverQuotaAI/chatterboxio-mcp-server)\n\nA Model Context Protocol server implementation for ChatterBox, enabling AI agents to interact with online meetings and generate meeting summaries.\n\n<a href=\"https://glama.ai/mcp/servers/@ChatterBoxIO/chatterboxio-mcp-server\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@ChatterBoxIO/chatterboxio-mcp-server/badge\" alt=\"ChatterBox MCP Server\" />\n</a>\n\n## Overview\n\nThe ChatterBox MCP Server provides tools for AI agents to:\n\n- Join online meetings (Zoom, Google Meet, or Microsoft Teams)\n- Capture transcripts and recordings\n- Generate meeting summaries\n\n## Installation\n\n### Installing via Smithery\n\nTo install chatterboxio-mcp-server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@OverQuotaAI/chatterboxio-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @OverQuotaAI/chatterboxio-mcp-server --client claude\n```\n\n### Manual Installation\n\nYou can install the dependencies using either npm or pnpm:\n\n```bash\n# Using npm\nnpm install\n\n# Using pnpm\npnpm install\n```\n\n## Configuration\n\n### Getting API Keys\n\nYou can get your API keys for free by registering on our website at [ChatterBox](https://chatter-box.io). After registration, you'll receive your API endpoint and key.\n\n### Environment Setup\n\nCreate a `.env` file in the root directory with the following variables:\n\n```env\nCHATTERBOX_API_ENDPOINT=https://api.chatter-box.io\nCHATTERBOX_API_KEY=your_api_key_here\n```\n\n## Usage\n\n### Starting the Server\n\n```bash\npnpm start\n```\n\n### Available Tools\n\n#### joinMeeting\n\nJoin a Zoom or Google Meet meeting and capture transcript and audio recording.\n\n**Parameters:**\n\n- `platform` (string): The online conference platform (\"zoom\", \"googlemeet\", or \"teams\")\n- `meetingId` (string): The ID of the meeting\n- `meetingPassword` (string, optional): The password or the passcode for the meeting\n- `botName` (string): The name of the bot\n- `webhookUrl` (string, optional): URL to receive webhook events for meeting status\n\n#### getMeetingInfo\n\nGet information about a meeting, including transcript and recording.\n\n**Parameters:**\n\n- `sessionId` (string): The session ID to get information for\n\n#### summarizeMeeting\n\nGenerate a concise summary of a meeting's contents from its transcript.\n\n**Parameters:**\n\n- `transcript` (string): The meeting transcript to summarize\n\n## Development\n\n### Prerequisites\n\n- Node.js 16+\n- npm or yarn\n\n### Building\n\n```bash\npnpm run build\n```\n\n### Debugging\n\nTo debug the MCP server using the MCP Inspector:\n\n```bash\nnpx @modelcontextprotocol/inspector\n```\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Support\n\nFor support, please visit [ChatterBox Documentation](https://chatter-box.io/documentation) or contact support@chatter-box.io.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "chatterbox",
        "chatterboxio",
        "communication",
        "chatterboxio mcp",
        "chatterbox io",
        "communication platforms"
      ],
      "category": "communication"
    },
    "PhononX--cv-mcp-server": {
      "owner": "PhononX",
      "name": "cv-mcp-server",
      "url": "https://github.com/PhononX/cv-mcp-server",
      "imageUrl": "",
      "description": "MCP Server that connects AI Agents to [Carbon Voice](https://getcarbon.app). Create, manage, and interact with voice messages, conversations, direct messages, folders, voice memos, AI actions and more in [Carbon Voice](https://getcarbon.app).",
      "stars": 2,
      "forks": 4,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-19T17:15:55Z",
      "readme_content": "# Carbon Voice MCP Server\n\n[![MCP Compatible](https://img.shields.io/badge/MCP-Compatible-blue)](https://modelcontextprotocol.io) [![npm version](https://badge.fury.io/js/%40carbonvoice%2Fcv-mcp-server.svg)](https://www.npmjs.com/package/@carbonvoice/cv-mcp-server)\n\nA Model Context Protocol (MCP) server implementation for integrating with [Carbon Voice's API](https://api.carbonvoice.app/docs), providing AI assistants with comprehensive tools for voice messaging, conversations, and workspace management.\n\n**<img src=\"https://carbonvoice.app/favicon.ico\" alt=\"Carbon Voice Logo\" width=\"32\" height=\"32\" align=\"center\" style=\"margin-right: 10px;\">Carbon Voice**: [https://getcarbon.app](https://getcarbon.app)\n\n**<img src=\"https://pxassets.s3.us-east-2.amazonaws.com/images/swagger-logo.png\" alt=\"Carbon Voice API Logo\" width=\"32\" height=\"32\" align=\"center\" style=\"margin-right: 10px;\">API**: [https://api.carbonvoice.app/docs](https://api.carbonvoice.app/docs)\n\n## Features\n\n- **Message Management**: Create, list, and retrieve voice messages, conversation messages, and direct messages\n- **User Operations**: Search and retrieve user information\n- **Conversation Management**: Access and manage conversations and their participants\n- **Folder Operations**: Create, organize, move, and manage folders and their contents\n- **Workspace Administration**: Get workspace information\n- **AI Actions**: Run AI prompts and retrieve AI-generated responses\n- **Attachment Support**: Add link attachments to messages\n\n## Security & Compliance\n\nThis server fully complies with [MCP Security Best Practices](https://modelcontextprotocol.io/specification/draft/basic/security_best_practices):\n\n- **OAuth 2.1 Authentication**: Secure authorization flow with proper token handling\n- **HTTPS Enforcement**: All remote endpoints served over HTTPS\n- **Session Security**: Cryptographically secure session management\n- **Input Validation**: Comprehensive validation of all user inputs\n- **Rate Limiting**: Built-in protection against abuse\n\nFor security concerns, please contact: devsupport@phononx.com\n\n## Prerequisites\n\n### For Stdio Transport (Local Installation)\n\n**Required:**\n\n1. **Carbon Voice API Key** - Contact the Carbon Voice development team to request your API key:\n\n   - **📧 Contact**: devsupport@phononx.com\n   - **📧 Subject**: \"Request API key for MCP Server\"\n\n2. **npx Installation** - You must have `npx` installed on your system. npx comes bundled with Node.js (version 14.8.0 or later). If you don't have Node.js installed, you can download it from [nodejs.org](https://nodejs.org/).\n\n   To verify your installation, run:\n\n   ```bash\n   npx --version\n   ```\n\n### For HTTP Transport (Remote)\n\n**Required:**\n\n1. **Nothing!** - No additional prerequisites are required. The HTTP transport version runs entirely in the cloud and uses OAuth2 authentication, so you don't need an API key or npx installed.\n\n## Configuration\n\n### Quick Overview\n\n| Client             | HTTP Transport (Remote) | Stdio Transport (Local) |\n| ------------------ | ----------------------- | ----------------------- |\n| **Cursor**         | ✅ Recommended          | ✅ Available            |\n| **Claude Desktop** | ✅ Recommended          | ✅ Available            |\n\n_HTTP Transport is recommended for easier setup and enhanced security._\n\n### For Cursor\n\n#### HTTP Transport (Remote)\n\n1. Open Cursor\n2. Go to **Cursor Settings** > **Features** > **Model Context Protocol**\n3. Add a new MCP server configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"Carbon Voice\": {\n      \"url\": \"https://mcp.carbonvoice.app\"\n    }\n  }\n}\n```\n\n4. Save and restart Cursor\n\nThe first time you use it, Cursor will guide you through the OAuth2 authentication process.\n\n#### Stdio Transport (Local Installation)\n\nIf you prefer to run the MCP server locally with API key authentication:\n\n1. Open Cursor\n2. Go to **Cursor Settings** > **Features** > **Model Context Protocol**\n3. Add a new MCP server configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"Carbon Voice\": {\n      \"command\": \"npx\",\n      \"env\": {\n        \"CARBON_VOICE_API_KEY\": \"your_api_key_here\"\n      },\n      \"args\": [\"-y\", \"@carbonvoice/cv-mcp-server\"]\n    }\n  }\n}\n```\n\n4. Replace `\"your_api_key_here\"` with your actual Carbon Voice API key\n5. Save and restart Cursor\n\n### For Claude Desktop\n\n#### HTTP Transport (Remote)\n\nSetting up Carbon Voice in Claude Desktop is straightforward! Here's how to do it:\n\n1. **Open Claude Desktop** and navigate to **Search and Tools**\n\n2. **Go to Manage Connectors** and click **\"Add custom connector\"**\n\n3. **Fill in the connector details**:\n\n   - **Name**: Give it a friendly name like \"Carbon Voice\"\n   - **Remote MCP Server URL**: Enter `https://mcp.carbonvoice.app`\n\n4. **Save your connector**\n\n5. **Click Connect**:\n\nThe first time you use it, Claude will guide you through the OAuth2 authentication process. You'll just need to sign in with your Carbon Voice account and grant permissions. After that, you're all set!\n\n#### Stdio Transport (Local Installation)\n\nIf you prefer to run the MCP server locally with API key authentication:\n\n1. Open your Claude Desktop configuration file:\n\n   - **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n2. Add the Carbon Voice MCP server configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"Carbon-Voice\": {\n      \"command\": \"npx\",\n      \"env\": {\n        \"CARBON_VOICE_API_KEY\": \"your_api_key_here\"\n      },\n      \"args\": [\"-y\", \"@carbonvoice/cv-mcp-server\"]\n    }\n  }\n}\n```\n\n3. Replace `\"your_api_key_here\"` with your actual Carbon Voice API key\n4. Save the file and restart Claude Desktop\n\n### Environment Variables (Only available for Stdio Version)\n\nWhen using the stdio version of the MCP server, you can configure additional environment variables:\n\n#### LOG_LEVEL\n\nControls the verbosity of logging output. Available options:\n\n- `info` (default) - Standard logging information\n- `debug` - Most verbose logging, shows detailed request/response data\n- `warn` - Only warning and error messages\n- `error` - Only error messages\n\n**Example:**\n\n```json\n{\n  \"mcpServers\": {\n    \"Carbon-Voice\": {\n      \"command\": \"npx\",\n      \"env\": {\n        \"CARBON_VOICE_API_KEY\": \"your_api_key_here\",\n        \"LOG_LEVEL\": \"debug\"\n      },\n      \"args\": [\"-y\", \"@carbonvoice/cv-mcp-server\"]\n    }\n  }\n}\n```\n\n#### LOG_DIR\n\nSpecifies the directory where log files will be stored. Defaults to: `/tmp/cv-mcp-server/logs`\n\nThe server will create two log files in this directory:\n\n- `combined.log` - Contains all log messages\n- `error.log` - Contains only error messages\n\n**Example:**\n\n```json\n{\n  \"mcpServers\": {\n    \"Carbon-Voice\": {\n      \"command\": \"npx\",\n      \"env\": {\n        \"CARBON_VOICE_API_KEY\": \"your_api_key_here\",\n        \"LOG_DIR\": \"/Users/USER_NAME/Documents/cv-mcp-server/logs\"\n      },\n      \"args\": [\"-y\", \"@carbonvoice/cv-mcp-server\"]\n    }\n  }\n}\n```\n\n**Complete Example with Both Variables:**\n\n```json\n{\n  \"mcpServers\": {\n    \"Carbon-Voice\": {\n      \"command\": \"npx\",\n      \"env\": {\n        \"CARBON_VOICE_API_KEY\": \"your_api_key_here\",\n        \"LOG_LEVEL\": \"debug\",\n        \"LOG_DIR\": \"/Users/USER_NAME/Documents/cv-mcp-server/logs\"\n      },\n      \"args\": [\"-y\", \"@carbonvoice/cv-mcp-server\"]\n    }\n  }\n}\n```\n\n## Available Tools\n\n### Messages\n\n- **`list_messages`** - List messages with date filtering (max 31-day range)\n- **`get_message`** - Retrieve a specific message by ID\n- **`get_recent_messages`** - Get the 10 most recent messages with full context\n- **`create_conversation_message`** - Send a message to a conversation\n- **`create_direct_message`** - Send direct messages to users or groups\n- **`create_voicememo_message`** - Create voice memo messages\n- **`add_attachments_to_message`** - Add link attachments to existing messages\n\n### Users\n\n- **`get_user`** - Retrieve user information by ID\n- **`search_user`** - Find a user by phone number or email\n- **`search_users`** - Search multiple users by various identifiers\n\n### Conversations\n\n- **`list_conversations`** - Get all conversations from the last 6 months\n- **`get_conversation`** - Retrieve conversation details by ID\n- **`get_conversation_users`** - Get all users in a conversation\n\n### Folders\n\n- **`get_workspace_folders_and_message_counts`** - Get folder and message statistics\n- **`get_root_folders`** - List root folders for a workspace\n- **`create_folder`** - Create new folders\n- **`get_folder`** - Retrieve folder information\n- **`get_folder_with_messages`** - Get folder with its messages\n- **`update_folder_name`** - Rename folders\n- **`delete_folder`** - Delete folders (⚠️ destructive operation)\n- **`move_folder`** - Move folders between locations\n- **`move_message_to_folder`** - Organize messages into folders\n\n### Workspace\n\n- **`get_workspaces_basic_info`** - Get basic workspace information\n\n### AI Actions\n\n- **`list_ai_actions`** - List available AI prompts/actions\n- **`run_ai_action`** - Execute AI actions on messages\n- **`run_ai_action_for_shared_link`** - Run AI actions on shared content\n- **`get_ai_action_responses`** - Retrieve AI-generated responses\n\n## Usage Examples\n\n### Getting Started\n\nAfter configuration, you can interact with Carbon Voice through your AI assistant. Here are some example requests:\n\n```\n\"Show me my recent messages\"\n\"Create a voice memo about today's meeting\"\n\"Search for user john@example.com\"\n\"Show me my workspace information\"\n\"List my conversations from this week\"\n```\n\n### Working with Folders\n\n```\n\"Create a folder called 'Project Updates'\"\n\"Move message ID 12345 to the Project Updates folder\"\n\"Show me all messages in the Marketing folder\"\n```\n\n### AI Actions\n\n```\n\"Run a summary AI action on message ID 67890\"\n\"List all available AI prompts\"\n\"Get AI responses for conversation ID 123\"\n```\n\n## Error Handling\n\nThe server includes comprehensive error handling and logging. Errors are returned in a structured format that includes:\n\n- Error messages\n- HTTP status codes\n- Request context\n- Debugging information\n\n## Development\n\nThis section is for developers who want to contribute, implement new features, or fix issues.\n\n### Development Commands\n\n#### Building and Development\n\n```bash\nnpm run build          # Build the project\nnpm run auto:build     # Watch mode with auto-rebuild (recommended for development)\nnpm run lint:fix       # Fix linting issues\n```\n\n#### API Generation\n\n```bash\nnpm run generate:api   # Generate TypeScript types from Carbon Voice API\n```\n\n#### Running the Server\n\n```bash\nnpm run dev:http       # Start HTTP server in development mode with hot reload\nnpm run start:http     # Start HTTP server in production mode\n```\n\n#### Testing with MCP Inspector\n\n**Setup**: Copy `.env.sample` to `.env` and configure your development environment variables.\n\n```bash\nnpm run mcp:inspector:stdio  # Test stdio transport with MCP Inspector\nnpm run mcp:inspector:http   # Test HTTP transport with MCP Inspector\n```\n\n**For stdio transport testing:**\n\n1. Open the generated URL with token (e.g., `http://localhost:6274/?MCP_PROXY_AUTH_TOKEN=46bfbd8938955be26da7f2089a8cccb7be57ed570e65d8d2d68e95561ed9b79e`)\n2. Set **Transport Type**: `STDIO`\n3. Set **Command**: `node`\n4. Click **Connect**\n5. Should see Connected info.\n\n**For HTTP transport testing:**\n\n1. Open the generated URL with token\n2. Set **Transport Type**: `Streamable HTTP`\n3. Set **URL**: `http://localhost:3005`\n4. Click Auth, then Quick Oauth Flow.\n5. Will be redirected to Carbon Voice Auth Page. After Login, Bearer token should be auto added to Authorization Request headers.\n6. Click **Connect**\n7. Should see Connected info.\n\n### Version Management\n\n**Note**: Only code merged to main branch with a **different version** from the current one will create a new Git tag and trigger a new npm package release. The CI/CD pipeline automatically checks if the version in `package.json` has changed before deploying and publishing.\n\n#### Version Commands\n\n```bash\nnpm run version:patch  # Bump patch version (1.0.0 → 1.0.1)\nnpm run version:minor  # Bump minor version (1.0.0 → 1.1.0)\nnpm run version:major  # Bump major version (1.0.0 → 2.0.0)\n```\n\n#### Release Commands\n\n```bash\nnpm run release:patch  # Build, test, version patch, and merge to main\nnpm run release:minor  # Build, test, version minor, and merge to main\nnpm run release:major  # Build, test, version major, and merge to main\nnpm run deploy:release # Build, test, and merge to main (no version bump)\n```\n\n### Development Workflow Examples\n\n#### Commit to Develop\n\n```bash\n# 1. Make your changes and test locally\nnpm run build\nnpm run lint:fix\n\n# 2. Commit and push to develop\ngit add .\ngit commit -m \"feat: add new message filtering feature\"\ngit push origin develop\n```\n\n#### Release Bug Fix\n\n```bash\n# 1. Test your changes\nnpm run build\nnpm run mcp:inspector:http\n\n# 2. Release patch version\nnpm run release:patch\n```\n\n#### Release New Feature\n\n```bash\n# 1. Test your changes\nnpm run build\nnpm run mcp:inspector:stdio\nnpm run mcp:inspector:http\n\n# 2. Release minor version\nnpm run release:minor\n```\n\n### Development Tips\n\n- **Use `auto:build`** during development for automatic rebuilding when files change\n- **Test both transports** with MCP Inspector before releasing\n- **Run `generate:api`** when Carbon Voice API changes\n- **Use semantic versioning**: patch for fixes, minor for features, major for breaking changes\n- **Always test** with both stdio and HTTP transports before releasing\n\n## MCP Compliance\n\nThis server is fully compliant with the [Model Context Protocol specification](https://modelcontextprotocol.io) and follows all security best practices outlined in the official documentation. The implementation supports both stdio and HTTP transports as defined in the MCP specification.\n\n## Support\n\n- **Issues**: [GitHub Issues](https://github.com/PhononX/cv-mcp-server/issues)\n- **API Key Requests**: devsupport@phononx.com\n- **Carbon Voice Platform**: [https://getcarbon.app](https://getcarbon.app)\n- **API Documentation**: [https://api.carbonvoice.app/docs](https://api.carbonvoice.app/docs)\n\n## License\n\nISC License - See [LICENSE](LICENSE) file for details.\n\n---\n\n**Note**: This MCP server requires a valid Carbon Voice API key to function with stdio transport. For HTTP transport, OAuth2 authentication is handled automatically through the web interface. Please ensure you have the appropriate credentials before attempting to use the server.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "communication",
        "conversations",
        "messages",
        "communication platforms",
        "communication tools",
        "communication integration"
      ],
      "category": "communication"
    },
    "agentmail-toolkit--mcp": {
      "owner": "agentmail-toolkit",
      "name": "mcp",
      "url": "https://github.com/agentmail-to/agentmail-toolkit/tree/main/mcp",
      "imageUrl": "",
      "description": "An MCP server to create inboxes on the fly to send, receive, and take actions on email. We aren't AI agents for email, but email for AI Agents.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "agentmail",
        "mcp",
        "agents",
        "email ai",
        "agentmail toolkit",
        "agents email"
      ],
      "category": "communication"
    },
    "areweai--tsgram-mcp": {
      "owner": "areweai",
      "name": "tsgram-mcp",
      "url": "https://github.com/areweai/tsgram-mcp",
      "imageUrl": "",
      "description": "TSgram: Telegram + Claude with local workspace access on your phone in typescript. Read, write, and vibe code on the go!",
      "stars": 85,
      "forks": 22,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T19:03:35Z",
      "readme_content": "# TSGram MCP 🚀\n\n**Get Claude Code in your local project talking to Telegram in 3 minutes!**\n\n\n\nTSGram MCP connects Claude Code sessions to Telegram using TS/Node/Docker/cli-utils, enabling AI-powered code assistance directly in your Telegram chats. Ask questions about your codebase, get AI insights, and even edit files - all from Telegram on your phone!\n\n## 🔒 How It Works (All Local)\n- Local Docker container runs the Telegram webhook server\n- TSGram MCP server runs locally \n- Your Claude Code or Claude Desktop runs locally and adds MCP locally\n- Create and delete bots in-app through Telegram, access limited to your telegram user id\n- Modern local web dashboard to manage bots from localhost \n- Local means local! If your computer is offline, so are your bots.\n\n## Quick Start (3 Minutes)\n\n### 🤖 AI Agent Enhanced Setup (Recommended!)\n\nLet Claude handle the entire setup and ask you for the required values.\n\n**From your terminal:**\n0. Install [Docker Desktop](https://www.docker.com/products/docker-desktop/) and [Node.js 20+](https://nodejs.org/en/download) (npm included)\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/areweai/tsgram-mcp.git\n   cd tsgram-mcp\n   ```\n\n2. From the command line, start Claude:\n   ```bash\n   claude --model sonnet\n   ```\n\n3. Initialize with `/init`\n\n4. Copy and paste this prompt:\n   > First, explain to the human how to register a new Telegram bot with @BotFather and get their bot token (TELEGRAM_BOT_TOKEN), and how to get their Telegram user ID from @userinfobot (for AUTHORIZED_CHAT_ID). They can work on getting these credentials while you set up the system. Then help the user set up tsgram-mcp for claude code. Do everything from installing node modules to creating and deploying the local docker containers. Finally, when everything is deployed, remind the user to configure their bot token and authorized chat ID along wither other required .env variables.\n\nMake sure you replace the `TELEGRAM_BOT_TOKEN` and `AUTHORIZED_CHAT_ID` placeholders with the actual values.\n\nIn order to retrieve those values, you will have to message the following Telegram bots and follow their instructions:\n- [@BotFather](https://t.me/botfather)\n- [@userinfobot](https://t.me/userinfobot)\n\nThe AI will then handle all the setup steps for you, including:\n- Installing dependencies\n- Configuring environment variables\n- Building Docker containers\n- Starting services\n- Guiding you through bot registration\n- Setting up the MCP server (and allow you to extend functionality locally)\n\n**CLI no-AI Alternative If Hitting LLM troubles: Setup Shell Script**\nRun from your project root:\n```bash\n# One-line install (macOS/Linux)\ncurl -sSL https://raw.githubusercontent.com/areweai/tsgram-mcp/main/setup.sh | bash\n\n# Or if you prefer to review first:\ncurl -sSL https://raw.githubusercontent.com/areweai/tsgram-mcp/main/setup.sh > setup.sh\nchmod +x setup.sh\n./setup.sh\n```\n\n**Adding TSGram to an Existing Project:**\n\nIf you already have a project and want to add TSGram as an MCP server:\n\n1. From your existing project root:\n   ```bash\n   git clone https://github.com/areweai/tsgram-mcp.git .tsgram-mcp\n   cd .tsgram-mcp\n   ```\n\n2. Use Claude to set it up:\n   ```bash\n   claude model --sonnet\n   /init\n   ```\n\n3. Paste this prompt:\n   > \"First, explain to the human how to register a new Telegram bot with @BotFather and get their bot token (TELEGRAM_BOT_TOKEN) from @UserBotInfoBot, and how to get their Telegram user ID from @userinfobot (for AUTHORIZED_CHAT_ID). They can work on getting these credentials while you set up the system. Then help me add TSGram MCP to my existing project in the parent directory. Set up the Docker containers and MCP configuration so I can use Telegram to interact with my project files. The project root is one level up from here.\"\n\nThis will configure TSGram to work with your existing project structure (and allow you to extend functionality locally).\n\n### Test Your Bot! 🎉\n**IMPORTANT: You will need to message your bot first before it can message you.**\n\nSend your bot a message and ask it something about your local project!\n\n\n\n\n\n**⚠️ Security Note**: TSGram has basic safeguards to not list, preview, or serve .env files but it is still strongly recommended that you do not use TSGram for anything highly sensitive as third party servers are part of the transport layer.\n\n## 📊 Web Dashboard\n\nMonitor and manage your bots through the beautiful web dashboard at **http://localhost:3000**:\n\n\n\nThe dashboard provides:\n- **Real-time bot status** and activity monitoring\n- **System health** indicators (MCP server, AI model, API keys)\n- **Bot management** - create, test, and monitor Telegram bots\n- **Activity logs** - track messages, responses, and system events\n- **Quick actions** - send test messages and manage bot configurations\n- **run from local** - npm run dashboard to view (chrome recommended)\n\n## 📋 You Will Need\n\n- [Docker Desktop](https://www.docker.com/products/docker-desktop/)\n- [Node.js 20+](https://nodejs.org/en/download) (npm included)\n- Telegram on a phone\n- Claude Desktop or Claude Code (CLI)\n- An OpenRouter API key (We recommend creating a new API key with a $1.00 limit. Trust, but limit!)\n- Chrome (Optional but highly recommended for local management UI)\n\n## Manual Setup Steps\n\n### 1. Get Your Bot Token & User ID\n1. **Create Bot**: Message [@BotFather](https://t.me/botfather) on Telegram\n2. Send `/newbot` and follow prompts\n3. Copy your bot token (keep this secret!)\n4. **Get Your User ID** (IMPORTANT): Message [@userinfobot](https://t.me/userinfobot)\n   - This returns your numeric user ID (e.g., `123456789`)\n   - **Use the user ID, NOT your username** for security (usernames can be changed)\n\n### 2. Configure Environment\nEdit `.env` with your values:\n```env\nTELEGRAM_BOT_TOKEN=your_bot_token_here\n# CRITICAL: Use your numeric user ID from @userinfobot, not your username!\nAUTHORIZED_CHAT_ID=123456789  # Your numeric user ID from step 1\n\n# Choose ONE AI provider:\nOPENROUTER_API_KEY=your_openrouter_key  # For Claude (recommended with $1 limit)\n# OR\nOPENAI_API_KEY=your_openai_key         # For GPT-4\n```\n\n**Security Note**: The bot now uses your **numeric user ID** instead of username for authorization. This is more secure because:\n- User IDs never change\n- Usernames can be changed by users\n- User IDs cannot be guessed or easily discovered\n\n### 3. Start TSGram\n```bash\nnpm install\nnpm run docker:build\nnpm run docker:start\n```\n\n## 🎯 Key Features\n\n- **\"Stop\" and \"Start\" commands** in TSGram bot chat provide convenient output control\n- **Select subset of unix commands supported** (`:h ls` or `:h cat $FILE`)\n- **Opt-in edit mode** for vibe coding and debugging on the go (`:dangerzone` to enable)\n- **AI-Powered Responses**: Uses Claude 3.5 Sonnet or GPT-4\n- **Code Understanding**: Reads and analyzes your entire codebase\n- **Web Dashboard**: Monitor bots at http://localhost:3000\n\n## 💬 Bot Commands\n\n- **Regular messages**: Get AI responses about your code\n- **`:h`** - Show help and available commands\n- **`:h ls [path]`** - List files in directory\n- **`:h cat filename`** - View file contents\n- **`:dangerzone`** - Enable file editing (careful!)\n- **`:safetyzone`** - Disable file editing\n- **`stop`** - Pause bot responses\n- **`start`** - Resume bot responses\n\n## 🛠️ Common Commands\n\n```bash\n# View logs\nnpm run docker:logs\n\n# Check health\nnpm run docker:health\n\n# Stop services\nnpm run docker:stop\n\n# Rebuild after changes\nnpm run docker:rebuild\n\n# Access dashboard (Chrome recommended)\nnpm run dashboard\n```\n\n## 📜 Useful Scripts\n\nThe project includes several helper scripts in the `scripts/` directory:\n\n**Setup & Configuration**\n- `setup.sh` - Automated install script (can be run via curl)\n- `configure-mcp.sh` - Configure MCP settings for Claude Desktop/Code\n- `fix-permissions.sh` - Fix file permissions if needed\n\n**Updates & Maintenance**\n- `update-system.sh` - Update TSGram to latest version\n- `update-ai-context.sh` - Update AI context files\n\n**Testing & Debugging**\n- `test-api-keys.sh` - Verify your API keys are working\n- `test-docker-setup.sh` - Test Docker configuration\n\nRun any script with:\n```bash\n./scripts/script-name.sh\n# or\nnpm run script-name  # for npm-wrapped scripts\n```\n\n## 🔧 Advanced Setup\n\n### Using with Claude Code\nAdd to your Claude Code MCP settings:\n```json\n{\n  \"tsgram\": {\n    \"command\": \"docker\",\n    \"args\": [\"exec\", \"-i\", \"tsgram-mcp-workspace\", \"npx\", \"tsx\", \"src/mcp-server.ts\"],\n    \"env\": {\n      \"TELEGRAM_BOT_TOKEN\": \"your_bot_token_here\",\n      \"AUTHORIZED_CHAT_ID\": \"123456789\"\n    }\n  }\n}\n```\n\n**Note**: Replace `123456789` with your actual numeric user ID from [@userinfobot](https://t.me/userinfobot)\n\n### MCP Compatibility\n\nTSGram uses the standard Model Context Protocol (MCP) format and should be compatible with any MCP-supporting IDE or tool. **Tested with:**\n- ✅ Claude Code CLI\n- ✅ Claude Desktop\n\n**Should work with** (standard MCP format):\n- Cursor IDE\n- GitHub Copilot\n- Other MCP-compatible editors\n\nUse the same Docker configuration pattern shown above, adapting the syntax for your specific MCP client.\n\n### CLI-to-Telegram Bridge\nForward Claude Code CLI responses to Telegram:\n```bash\n# Setup global command (may prompt for sudo password to create npm global install /usr/local/bin/claude-tg)\nnpm run setup\n\n# Use instead of 'claude'\nclaude-tg \"analyze this codebase\"\n```\n\n## 🚨 Troubleshooting\n\n**Bot not responding?**\n```bash\n# Check if services are running\nnpm run docker:health\n\n# View logs for errors\nnpm run docker:logs\n```\n\n**Can't connect to bot?**\n1. Verify bot token is correct in `.env`\n2. **Check your user ID**: Make sure `AUTHORIZED_CHAT_ID` is your numeric user ID (not username)\n   - Get it from [@userinfobot](https://t.me/userinfobot) if unsure\n3. Make sure you messaged the bot first\n4. If you get \"authorization not configured\" error, set `AUTHORIZED_CHAT_ID` in your `.env` file\n\n**File edits not working?**\n- Type `:dangerzone` to enable (one-time)\n- Check logs for permission errors\n- Ensure Docker has file access\n\n## 📚 Project Structure\n\n```\ntsgram/\n├── src/\n│   ├── telegram-bot-ai-powered.ts    # Main bot logic\n│   ├── telegram-mcp-webhook-server.ts # MCP integration\n│   └── models/                        # AI providers\n├── docker-compose.tsgram-workspace.yml # Main Docker config\n├── .env.example                       # Environment template\n└── data/                             # Persistent storage\n```\n\n## 🤝 Contributing\n\nPRs welcome! Please:\n1. Fork the repository\n2. Create a feature branch\n3. Add tests if applicable\n4. Submit a pull request\n\n## 📄 License\n\nMIT - Feel free to use in your own projects!\n\n---\n\n**Need help?** Open an issue on GitHub or message your bot with questions!",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "telegram",
        "communication",
        "interact",
        "communication tools",
        "communication platforms",
        "communication integration"
      ],
      "category": "communication"
    },
    "chaindead--telegram-mcp": {
      "owner": "chaindead",
      "name": "telegram-mcp",
      "url": "https://github.com/chaindead/telegram-mcp",
      "imageUrl": "",
      "description": "Telegram API integration for accessing user data, managing dialogs (chats, channels, groups), retrieving messages, and handling read status",
      "stars": 216,
      "forks": 24,
      "license": "MIT License",
      "language": "Go",
      "updated_at": "2025-10-03T21:17:26Z",
      "readme_content": "[![](https://badge.mcpx.dev?type=server 'MCP Server')](https://github.com/punkpeye/awesome-mcp-servers?tab=readme-ov-file#communication)\n[![OS_Agnostic_Works_Everywhere_purple](https://img.shields.io/badge/OS_Agnostic-Works_Everywhere-purple)](https://github.com/chaindead/telegram-mcp?tab=readme-ov-file#installation)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[](https://visitorbadge.io/status?path=https%3A%2F%2Fgithub.com%2Fchaindead%2Ftelegram-mcp)\n\n# Telegram MCP server\n\nThe server is a bridge between the Telegram API and the AI assistants and is based on the [Model Context Protocol](https://modelcontextprotocol.io).\n\n> [!IMPORTANT]\n> Ensure that you have read and understood the [Telegram API Terms of Service](https://core.telegram.org/api/terms) before using this server.\n> Any misuse of the Telegram API may result in the suspension of your account.\n\n## Table of Contents\n- [What is MCP?](#what-is-mcp)\n- [What does this server do?](#what-does-this-server-do)\n  - [Capabilities](#capabilities)\n  - [Prompt examples](#prompt-examples)\n    - [Message Management](#message-management)\n    - [Organization](#organization)\n    - [Communication](#communication)\n- [Installation](#installation)\n  - [Homebrew](#homebrew)\n  - [NPX](#npx)\n  - [From Releases](#from-releases)\n    - [MacOS](#macos)\n    - [Linux](#linux)\n    - [Windows](#windows)\n  - [From Source](#from-source)\n- [Configuration](#configuration)\n  - [Authorization](#authorization)\n  - [Client Configuration](#client-configuration)\n- [Star History](#star-history)\n\n## What is MCP?\n\nThe Model Context Protocol (MCP) is a system that lets AI apps, like Claude Desktop or Cursor, connect to external tools and data sources. It gives a clear and safe way for AI assistants to work with local services and APIs while keeping the user in control.\n\n## What does this server do?\n\n### Capabilities\n\n- [x] Get current account information (`tool: tg_me`)\n- [x] List dialogs with optional unread filter (`tool: tg_dialogs`)\n- [x] Mark dialog as read (`tool: tg_read`)\n- [x] Retrieve messages from specific dialog (`tool: tg_dialog`)\n- [x] Send draft messages to any dialog (`tool: tg_send`)\n\n### Prompt examples\n\nHere are some example prompts you can use with AI assistants:\n\n#### Message Management\n- \"Check for any unread important messages in my Telegram\"\n- \"Summarize all my unread Telegram messages\"\n- \"Read and analyze my unread messages, prepare draft responses where needed\"\n- \"Check non-critical unread messages and give me a brief overview\"\n\n#### Organization\n- \"Analyze my Telegram dialogs and suggest a folder structure\"\n- \"Help me categorize my Telegram chats by importance\"\n- \"Find all work-related conversations and suggest how to organize them\"\n\n#### Communication\n- \"Monitor specific chat for updates about [topic]\"\n- \"Draft a polite response to the last message in [chat]\"\n- \"Check if there are any unanswered questions in my chats\"\n\n## Installation\n\n### Homebrew\n\nYou can install a binary release on macOS/Linux using brew:\n\n```bash\n# Install\nbrew install chaindead/tap/telegram-mcp\n\n# Update\nbrew upgrade chaindead/tap/telegram-mcp\n```\n\n### NPX\n\nYou can run the latest version directly using npx (supports macOS, Linux, and Windows):\n\n```bash\nnpx -y @chaindead/telegram-mcp\n```\n\nWhen using NPX, modify the standard commands and configuration as follows:\n\n- [Authentication command](#authorization) becomes:\n```bash\nnpx -y @chaindead/telegram-mcp auth ...\n```\n\n- [Claude MCP server configuration](#client-configuration) becomes:\n```json\n{\n  \"mcpServers\": {\n    \"telegram\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@chaindead/telegram-mcp\"],\n      \"env\": {\n        \"TG_APP_ID\": \"<your-api-id>\",\n        \"TG_API_HASH\": \"<your-api-hash>\"\n      }\n    }\n  }\n}\n```\n\nFor complete setup instructions, see [Authorization](#authorization) and [Client Configuration](#client-configuration).\n\n### From Releases\n\n#### MacOS\n\n<details>\n\n> **Note:** The commands below install to `/usr/local/bin`. To install elsewhere, replace `/usr/local/bin` with your preferred directory in your PATH.\n\nFirst, download the archive for your architecture:\n\n```bash\n# For Intel Mac (x86_64)\ncurl -L -o telegram-mcp.tar.gz https://github.com/chaindead/telegram-mcp/releases/latest/download/telegram-mcp_Darwin_x86_64.tar.gz\n\n# For Apple Silicon (M1/M2)\ncurl -L -o telegram-mcp.tar.gz https://github.com/chaindead/telegram-mcp/releases/latest/download/telegram-mcp_Darwin_arm64.tar.gz\n```\n\nThen install the binary:\n\n```bash\n# Extract the binary\nsudo tar xzf telegram-mcp.tar.gz -C /usr/local/bin\n\n# Make it executable\nsudo chmod +x /usr/local/bin/telegram-mcp\n\n# Clean up\nrm telegram-mcp.tar.gz\n```\n</details>\n\n#### Linux\n<details>\n\n> **Note:** The commands below install to `/usr/local/bin`. To install elsewhere, replace `/usr/local/bin` with your preferred directory in your PATH.\n\nFirst, download the archive for your architecture:\n\n```bash\n# For x86_64 (64-bit)\ncurl -L -o telegram-mcp.tar.gz https://github.com/chaindead/telegram-mcp/releases/latest/download/telegram-mcp_Linux_x86_64.tar.gz\n\n# For ARM64\ncurl -L -o telegram-mcp.tar.gz https://github.com/chaindead/telegram-mcp/releases/latest/download/telegram-mcp_Linux_arm64.tar.gz\n```\n\nThen install the binary:\n\n```bash\n# Extract the binary\nsudo tar xzf telegram-mcp.tar.gz -C /usr/local/bin\n\n# Make it executable\nsudo chmod +x /usr/local/bin/telegram-mcp\n\n# Clean up\nrm telegram-mcp.tar.gz\n```\n</details>\n\n#### Windows\n\n<details>\n\n#### Windows\n1. Download the latest release for your architecture:\n   - [Windows x64](https://github.com/chaindead/telegram-mcp/releases/latest/download/telegram-mcp_Windows_x86_64.zip)\n   - [Windows ARM64](https://github.com/chaindead/telegram-mcp/releases/latest/download/telegram-mcp_Windows_arm64.zip)\n2. Extract the `.zip` file\n3. Add the extracted directory to your PATH or move `telegram-mcp.exe` to a directory in your PATH\n</details>\n\n### From Source\n\nRequirements:\n- Go 1.24 or later\n- GOBIN in PATH\n\n```bash\ngo install github.com/chaindead/telegram-mcp@latest\n```\n\n## Configuration\n\n### Authorization\n\nBefore you can use the server, you need to connect to the Telegram API.\n\n1. Get the API ID and hash from [Telegram API](https://my.telegram.org/auth)\n2. Run the following command:\n   > __Note:__\n   > If you have 2FA enabled: add --password <2fa_password>\n\n   >  __Note:__\n   > If you want to override existing session: add --new\n\n   ```bash\n   telegram-mcp auth --app-id <your-api-id> --api-hash <your-api-hash> --phone <your-phone-number>\n   ```\n\n   📩 Enter the code you received from Telegram to connect to the API.\n\n3. Done! Please give this project a ⭐️ to support its development.\n\n### Client Configuration\n\nExample of Configuring Claude Desktop to recognize the Telegram MCP server.\n\n1. Open the Claude Desktop configuration file:\n    - in MacOS, the configuration file is located at `~/Library/Application Support/Claude/claude_desktop_config.json`\n    - in Windows, the configuration file is located at `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n   > __Note:__\n   > You can also find claude_desktop_config.json inside the settings of Claude Desktop app\n\n2. Add the server configuration\n   \n   for Claude desktop:\n   ```json\n    {\n      \"mcpServers\": {\n        \"telegram\": {\n          \"command\": \"telegram-mcp\",\n          \"env\": {\n            \"TG_APP_ID\": \"<your-app-id>\",\n            \"TG_API_HASH\": \"<your-api-hash>\",\n            \"PATH\": \"<path_to_telegram-mcp_binary_dir>\",\n            \"HOME\": \"<path_to_your_home_directory\"\n          }\n        }\n      }\n    }\n   ```\n\n   for Cursor:\n    ```json\n    {\n      \"mcpServers\": {\n        \"telegram-mcp\": {\n          \"command\": \"telegram-mcp\",\n          \"env\": {\n            \"TG_APP_ID\": \"<your-app-id>\",\n            \"TG_API_HASH\": \"<your-api-hash>\"\n          }\n        }\n      }\n    }\n    ```\n\n## Star History\n\n<a href=\"https://www.star-history.com/#chaindead/telegram-mcp&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=chaindead/telegram-mcp&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=chaindead/telegram-mcp&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=chaindead/telegram-mcp&type=Date\" />\n </picture>\n</a>",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "telegram",
        "messages",
        "chats",
        "message management",
        "communication integration",
        "communication tools"
      ],
      "category": "communication"
    },
    "chigwell--telegram-mcp": {
      "owner": "chigwell",
      "name": "telegram-mcp",
      "url": "https://github.com/chigwell/telegram-mcp",
      "imageUrl": "",
      "description": "Telegram API integration for accessing user data, managing dialogs (chats, channels, groups), retrieving messages, sending messages and handling read status.",
      "stars": 359,
      "forks": 102,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-04T12:32:19Z",
      "readme_content": "# Telegram MCP Server\n\n![MCP Badge](https://badge.mcpx.dev)\n[![License: Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-green?style=flat-square)](https://opensource.org/licenses/Apache-2.0)\n[![Python Lint & Format Check](https://github.com/chigwell/telegram-mcp/actions/workflows/python-lint-format.yml/badge.svg)](https://github.com/chigwell/telegram-mcp/actions/workflows/python-lint-format.yml)\n[![Docker Build & Compose Validation](https://github.com/chigwell/telegram-mcp/actions/workflows/docker-build.yml/badge.svg)](https://github.com/chigwell/telegram-mcp/actions/workflows/docker-build.yml)\n\n---\n\n## 🤖 MCP in Action\n\nHere's a demonstration of the Telegram MCP capabilities in [Claude](https://docs.anthropic.com/en/docs/agents-and-tools/mcp):\n\n **Basic usage example:**\n\n\n\n1. **Example: Asking Claude to analyze chat history and send a response:**\n\n\n\n2. **Successfully sent message to the group:**\n\n\n\nAs you can see, the AI can seamlessly interact with your Telegram account, retrieving and displaying your chats, messages, and other data in a natural way.\n\n---\n\nA full-featured Telegram integration for Claude, Cursor, and any MCP-compatible client, powered by [Telethon](https://docs.telethon.dev/) and the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/). This project lets you interact with your Telegram account programmatically, automating everything from messaging to group management.\n\n\n---\n\n## 🚀 Features & Tools\n\nThis MCP server exposes a huge suite of Telegram tools. **Every major Telegram/Telethon feature is available as a tool!**\n\n### Chat & Group Management\n- **get_chats(page, page_size)**: Paginated list of chats\n- **list_chats(chat_type, limit)**: List chats with metadata and filtering\n- **get_chat(chat_id)**: Detailed info about a chat\n- **create_group(title, user_ids)**: Create a new group\n- **create_channel(title, about, megagroup)**: Create a channel or supergroup\n- **edit_chat_title(chat_id, title)**: Change chat/group/channel title\n- **delete_chat_photo(chat_id)**: Remove chat/group/channel photo\n- **leave_chat(chat_id)**: Leave a group or channel\n- **get_participants(chat_id)**: List all participants\n- **get_admins(chat_id)**: List all admins\n- **get_banned_users(chat_id)**: List all banned users\n- **promote_admin(chat_id, user_id)**: Promote user to admin\n- **demote_admin(chat_id, user_id)**: Demote admin to user\n- **ban_user(chat_id, user_id)**: Ban user\n- **unban_user(chat_id, user_id)**: Unban user\n- **get_invite_link(chat_id)**: Get invite link\n- **export_chat_invite(chat_id)**: Export invite link\n- **import_chat_invite(hash)**: Join chat by invite hash\n- **join_chat_by_link(link)**: Join chat by invite link\n\n### Messaging\n- **get_messages(chat_id, page, page_size)**: Paginated messages\n- **list_messages(chat_id, limit, search_query, from_date, to_date)**: Filtered messages\n- **send_message(chat_id, message)**: Send a message\n- **reply_to_message(chat_id, message_id, text)**: Reply to a message\n- **edit_message(chat_id, message_id, new_text)**: Edit your message\n- **delete_message(chat_id, message_id)**: Delete a message\n- **forward_message(from_chat_id, message_id, to_chat_id)**: Forward a message\n- **pin_message(chat_id, message_id)**: Pin a message\n- **unpin_message(chat_id, message_id)**: Unpin a message\n- **mark_as_read(chat_id)**: Mark all as read\n- **get_message_context(chat_id, message_id, context_size)**: Context around a message\n- **get_history(chat_id, limit)**: Full chat history\n- **get_pinned_messages(chat_id)**: List pinned messages\n- **get_last_interaction(contact_id)**: Most recent message with a contact\n\n### Contact Management\n- **list_contacts()**: List all contacts\n- **search_contacts(query)**: Search contacts\n- **add_contact(phone, first_name, last_name)**: Add a contact\n- **delete_contact(user_id)**: Delete a contact\n- **block_user(user_id)**: Block a user\n- **unblock_user(user_id)**: Unblock a user\n- **import_contacts(contacts)**: Bulk import contacts\n- **export_contacts()**: Export all contacts as JSON\n- **get_blocked_users()**: List blocked users\n- **get_contact_ids()**: List all contact IDs\n- **get_direct_chat_by_contact(contact_query)**: Find direct chat with a contact\n- **get_contact_chats(contact_id)**: List all chats with a contact\n\n### User & Profile\n- **get_me()**: Get your user info\n- **update_profile(first_name, last_name, about)**: Update your profile\n- **delete_profile_photo()**: Remove your profile photo\n- **get_user_photos(user_id, limit)**: Get a user's profile photos\n- **get_user_status(user_id)**: Get a user's online status\n\n### Media\n- **get_media_info(chat_id, message_id)**: Get info about media in a message\n\n### Search & Discovery\n- **search_public_chats(query)**: Search public chats/channels/bots\n- **search_messages(chat_id, query, limit)**: Search messages in a chat\n- **resolve_username(username)**: Resolve a username to ID\n\n### Stickers, GIFs, Bots\n- **get_sticker_sets()**: List sticker sets\n- **get_bot_info(bot_username)**: Get info about a bot\n- **set_bot_commands(bot_username, commands)**: Set bot commands (bot accounts only)\n\n### Privacy, Settings, and Misc\n- **get_privacy_settings()**: Get privacy settings\n- **set_privacy_settings(key, allow_users, disallow_users)**: Set privacy settings\n- **mute_chat(chat_id)**: Mute notifications\n- **unmute_chat(chat_id)**: Unmute notifications\n- **archive_chat(chat_id)**: Archive a chat\n- **unarchive_chat(chat_id)**: Unarchive a chat\n- **get_recent_actions(chat_id)**: Get recent admin actions\n\n## Removed Functionality\n\nPlease note that tools requiring direct file path access on the server (`send_file`, `download_media`, `set_profile_photo`, `edit_chat_photo`, `send_voice`, `send_sticker`, `upload_file`) have been removed from `main.py`. This is due to limitations in the current MCP environment regarding handling file attachments and local file system paths.\n\nAdditionally, GIF-related tools (`get_gif_search`, `get_saved_gifs`, `send_gif`) have been removed due to ongoing issues with reliability in the Telethon library or Telegram API interactions.\n\n---\n\n## 📋 Requirements\n- Python 3.10+\n- [Telethon](https://docs.telethon.dev/)\n- [MCP Python SDK](https://modelcontextprotocol.io/docs/)\n- [Claude Desktop](https://claude.ai/desktop) or [Cursor](https://cursor.so/) (or any MCP client)\n\n---\n\n## 🔧 Installation & Setup\n\n### 1. Fork & Clone\n\n```bash\ngit clone https://github.com/chigwell/telegram-mcp.git\ncd telegram-mcp\n```\n\n### 2. Install Dependencies with uv\n\n```bash\nuv sync\n```\n\n### 3. Generate a Session String\n\n```bash\nuv run session_string_generator.py\n```\nFollow the prompts to authenticate and update your `.env` file.\n\n### 4. Configure .env\n\nCopy `.env.example` to `.env` and fill in your values:\n\n```\nTELEGRAM_API_ID=your_api_id_here\nTELEGRAM_API_HASH=your_api_hash_here\nTELEGRAM_SESSION_NAME=anon\nTELEGRAM_SESSION_STRING=your_session_string_here\n```\nGet your API credentials at [my.telegram.org/apps](https://my.telegram.org/apps).\n\n---\n\n## 🐳 Running with Docker\n\nIf you have Docker and Docker Compose installed, you can build and run the server in a container, simplifying dependency management.\n\n### 1. Build the Image\n\nFrom the project root directory, build the Docker image:\n\n```bash\ndocker build -t telegram-mcp:latest .\n```\n\n### 2. Running the Container\n\nYou have two options:\n\n**Option A: Using Docker Compose (Recommended for Local Use)**\n\nThis method uses the `docker-compose.yml` file and automatically reads your credentials from a `.env` file.\n\n1.  **Create `.env` File:** Ensure you have a `.env` file in the project root containing your `TELEGRAM_API_ID`, `TELEGRAM_API_HASH`, and `TELEGRAM_SESSION_STRING` (or `TELEGRAM_SESSION_NAME`). Use `.env.example` as a template.\n2.  **Run Compose:**\n    ```bash\n    docker compose up --build\n    ```\n    *   Use `docker compose up -d` to run in detached mode (background).\n    *   Press `Ctrl+C` to stop the server.\n\n**Option B: Using `docker run`**\n\nYou can run the container directly, passing credentials as environment variables.\n\n```bash\ndocker run -it --rm \\\n  -e TELEGRAM_API_ID=\"YOUR_API_ID\" \\\n  -e TELEGRAM_API_HASH=\"YOUR_API_HASH\" \\\n  -e TELEGRAM_SESSION_STRING=\"YOUR_SESSION_STRING\" \\\n  telegram-mcp:latest\n```\n*   Replace placeholders with your actual credentials.\n*   Use `-e TELEGRAM_SESSION_NAME=your_session_file_name` instead of `TELEGRAM_SESSION_STRING` if you prefer file-based sessions (requires volume mounting, see `docker-compose.yml` for an example).\n*   The `-it` flags are crucial for interacting with the server.\n\n---\n\n## ⚙️ Configuration for Claude & Cursor\n\n### MCP Configuration\nEdit your Claude desktop config (e.g. `~/Library/Application Support/Claude/claude_desktop_config.json`) or Cursor config (`~/.cursor/mcp.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"telegram-mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/full/path/to/telegram-mcp\",\n        \"run\",\n        \"main.py\"\n      ]\n    }\n  }\n}\n```\n\n## 📝 Tool Examples with Code & Output\n\nBelow are examples of the most commonly used tools with their implementation and sample output.\n\n### Getting Your Chats\n\n```python\n@mcp.tool()\nasync def get_chats(page: int = 1, page_size: int = 20) -> str:\n    \"\"\"\n    Get a paginated list of chats.\n    Args:\n        page: Page number (1-indexed).\n        page_size: Number of chats per page.\n    \"\"\"\n    try:\n        dialogs = await client.get_dialogs()\n        start = (page - 1) * page_size\n        end = start + page_size\n        if start >= len(dialogs):\n            return \"Page out of range.\"\n        chats = dialogs[start:end]\n        lines = []\n        for dialog in chats:\n            entity = dialog.entity\n            chat_id = entity.id\n            title = getattr(entity, \"title\", None) or getattr(entity, \"first_name\", \"Unknown\")\n            lines.append(f\"Chat ID: {chat_id}, Title: {title}\")\n        return \"\\n\".join(lines)\n    except Exception as e:\n        logger.exception(f\"get_chats failed (page={page}, page_size={page_size})\")\n        return \"An error occurred (code: GETCHATS-ERR-001). Check mcp_errors.log for details.\"\n```\n\nExample output:\n```\nChat ID: 123456789, Title: John Doe\nChat ID: -100987654321, Title: My Project Group\nChat ID: 111223344, Title: Jane Smith\nChat ID: -200123456789, Title: News Channel\n```\n\n### Sending Messages\n\n```python\n@mcp.tool()\nasync def send_message(chat_id: int, message: str) -> str:\n    \"\"\"\n    Send a message to a specific chat.\n    Args:\n        chat_id: The ID of the chat.\n        message: The message content to send.\n    \"\"\"\n    try:\n        entity = await client.get_entity(chat_id)\n        await client.send_message(entity, message)\n        return \"Message sent successfully.\"\n    except Exception as e:\n        logger.exception(f\"send_message failed (chat_id={chat_id})\")\n        return \"An error occurred (code: SENDMSG-ERR-001). Check mcp_errors.log for details.\"\n```\n\nExample output:\n```\nMessage sent successfully.\n```\n\n### Getting Chat Invite Links\n\nThe `get_invite_link` function is particularly robust with multiple fallback methods:\n\n```python\n@mcp.tool()\nasync def get_invite_link(chat_id: int) -> str:\n    \"\"\"\n    Get the invite link for a group or channel.\n    \"\"\"\n    try:\n        entity = await client.get_entity(chat_id)\n        \n        # Try using ExportChatInviteRequest first\n        try:\n            from telethon.tl import functions\n            result = await client(functions.messages.ExportChatInviteRequest(\n                peer=entity\n            ))\n            return result.link\n        except AttributeError:\n            # If the function doesn't exist in the current Telethon version\n            logger.warning(\"ExportChatInviteRequest not available, using alternative method\")\n        except Exception as e1:\n            # If that fails, log and try alternative approach\n            logger.warning(f\"ExportChatInviteRequest failed: {e1}\")\n            \n        # Alternative approach using client.export_chat_invite_link\n        try:\n            invite_link = await client.export_chat_invite_link(entity)\n            return invite_link\n        except Exception as e2:\n            logger.warning(f\"export_chat_invite_link failed: {e2}\")\n            \n        # Last resort: Try directly fetching chat info\n        try:\n            if isinstance(entity, (Chat, Channel)):\n                full_chat = await client(functions.messages.GetFullChatRequest(\n                    chat_id=entity.id\n                ))\n                if hasattr(full_chat, 'full_chat') and hasattr(full_chat.full_chat, 'invite_link'):\n                    return full_chat.full_chat.invite_link or \"No invite link available.\"\n        except Exception as e3:\n            logger.warning(f\"GetFullChatRequest failed: {e3}\")\n            \n        return \"Could not retrieve invite link for this chat.\"\n    except Exception as e:\n        logger.exception(f\"get_invite_link failed (chat_id={chat_id})\")\n        return f\"Error getting invite link: {e}\"\n```\n\nExample output:\n```\nhttps://t.me/+AbCdEfGhIjKlMnOp\n```\n\n### Joining Chats via Invite Links\n\n```python\n@mcp.tool()\nasync def join_chat_by_link(link: str) -> str:\n    \"\"\"\n    Join a chat by invite link.\n    \"\"\"\n    try:\n        # Extract the hash from the invite link\n        if '/' in link:\n            hash_part = link.split('/')[-1]\n            if hash_part.startswith('+'):\n                hash_part = hash_part[1:]  # Remove the '+' if present\n        else:\n            hash_part = link\n            \n        # Try checking the invite before joining\n        try:\n            # Try to check invite info first (will often fail if not a member)\n            invite_info = await client(functions.messages.CheckChatInviteRequest(hash=hash_part))\n            if hasattr(invite_info, 'chat') and invite_info.chat:\n                # If we got chat info, we're already a member\n                chat_title = getattr(invite_info.chat, 'title', 'Unknown Chat')\n                return f\"You are already a member of this chat: {chat_title}\"\n        except Exception:\n            # This often fails if not a member - just continue\n            pass\n            \n        # Join the chat using the hash\n        result = await client(functions.messages.ImportChatInviteRequest(hash=hash_part))\n        if result and hasattr(result, 'chats') and result.chats:\n            chat_title = getattr(result.chats[0], 'title', 'Unknown Chat')\n            return f\"Successfully joined chat: {chat_title}\"\n        return f\"Joined chat via invite hash.\"\n    except Exception as e:\n        err_str = str(e).lower()\n        if \"expired\" in err_str:\n            return \"The invite hash has expired and is no longer valid.\"\n        elif \"invalid\" in err_str:\n            return \"The invite hash is invalid or malformed.\"\n        elif \"already\" in err_str and \"participant\" in err_str:\n            return \"You are already a member of this chat.\"\n        logger.exception(f\"join_chat_by_link failed (link={link})\")\n        return f\"Error joining chat: {e}\"\n```\n\nExample output:\n```\nSuccessfully joined chat: Developer Community\n```\n\n### Searching Public Chats\n\n```python\n@mcp.tool()\nasync def search_public_chats(query: str) -> str:\n    \"\"\"\n    Search for public chats, channels, or bots by username or title.\n    \"\"\"\n    try:\n        result = await client(functions.contacts.SearchRequest(q=query, limit=20))\n        return json.dumps([format_entity(u) for u in result.users], indent=2)\n    except Exception as e:\n        return f\"Error searching public chats: {e}\"\n```\n\nExample output:\n```json\n[\n  {\n    \"id\": 123456789,\n    \"name\": \"TelegramBot\",\n    \"type\": \"user\",\n    \"username\": \"telegram_bot\"\n  },\n  {\n    \"id\": 987654321,\n    \"name\": \"Telegram News\",\n    \"type\": \"user\",\n    \"username\": \"telegram_news\"\n  }\n]\n```\n\n### Getting Direct Chats with Contacts\n\n```python\n@mcp.tool()\nasync def get_direct_chat_by_contact(contact_query: str) -> str:\n    \"\"\"\n    Find a direct chat with a specific contact by name, username, or phone.\n    \n    Args:\n        contact_query: Name, username, or phone number to search for.\n    \"\"\"\n    try:\n        # Fetch all contacts using the correct Telethon method\n        result = await client(functions.contacts.GetContactsRequest(hash=0))\n        contacts = result.users\n        found_contacts = []\n        for contact in contacts:\n            if not contact:\n                continue\n            name = f\"{getattr(contact, 'first_name', '')} {getattr(contact, 'last_name', '')}\".strip()\n            username = getattr(contact, 'username', '')\n            phone = getattr(contact, 'phone', '')\n            if (contact_query.lower() in name.lower() or \n                (username and contact_query.lower() in username.lower()) or \n                (phone and contact_query in phone)):\n                found_contacts.append(contact)\n        if not found_contacts:\n            return f\"No contacts found matching '{contact_query}'.\"\n        # If we found contacts, look for direct chats with them\n        results = []\n        dialogs = await client.get_dialogs()\n        for contact in found_contacts:\n            contact_name = f\"{getattr(contact, 'first_name', '')} {getattr(contact, 'last_name', '')}\".strip()\n            for dialog in dialogs:\n                if isinstance(dialog.entity, User) and dialog.entity.id == contact.id:\n                    chat_info = f\"Chat ID: {dialog.entity.id}, Contact: {contact_name}\"\n                    if getattr(contact, 'username', ''):\n                        chat_info += f\", Username: @{contact.username}\"\n                    if dialog.unread_count:\n                        chat_info += f\", Unread: {dialog.unread_count}\"\n                    results.append(chat_info)\n                    break\n        \n        if not results:\n            return f\"Found contacts matching '{contact_query}', but no direct chats with them.\"\n        \n        return \"\\n\".join(results)\n    except Exception as e:\n        return f\"Error searching for direct chat: {e}\"\n```\n\nExample output:\n```\nChat ID: 123456789, Contact: John Smith, Username: @johnsmith, Unread: 3\n```\n\n---\n\n## 🎮 Usage Examples\n\n- \"Show my recent chats\"\n- \"Send 'Hello world' to chat 123456789\"\n- \"Add contact with phone +1234567890, name John Doe\"\n- \"Create a group 'Project Team' with users 111, 222, 333\"\n- \"Download the media from message 42 in chat 123456789\"\n- \"Mute notifications for chat 123456789\"\n- \"Promote user 111 to admin in group 123456789\"\n- \"Search for public channels about 'news'\"\n- \"Join the Telegram group with invite link https://t.me/+AbCdEfGhIjK\"\n- \"Send a sticker to my Saved Messages\"\n- \"Get all my sticker sets\"\n\nYou can use these tools via natural language in Claude, Cursor, or any MCP-compatible client.\n\n---\n\n## 🧠 Error Handling & Robustness\n\nThis implementation includes comprehensive error handling:\n\n- **Session management**: Works with both file-based and string-based sessions\n- **Error reporting**: Detailed errors logged to `mcp_errors.log`\n- **Graceful degradation**: Multiple fallback approaches for critical functions\n- **User-friendly messages**: Clear, actionable error messages instead of technical errors\n- **Account type detection**: Functions that require bot accounts detect and notify when used with user accounts\n- **Invite link processing**: Handles various link formats and already-member cases\n\nThe code is designed to be robust against common Telegram API issues and limitations.\n\n---\n\n## 🛠️ Contribution Guide\n\n1. **Fork this repo:** [chigwell/telegram-mcp](https://github.com/chigwell/telegram-mcp)\n2. **Clone your fork:**\n   ```bash\n   git clone https://github.com/<your-github-username>/telegram-mcp.git\n   ```\n3. **Create a new branch:**\n   ```bash\n   git checkout -b my-feature\n   ```\n4. **Make your changes, add tests/docs if needed.**\n5. **Push and open a Pull Request** to [chigwell/telegram-mcp](https://github.com/chigwell/telegram-mcp) with a clear description.\n6. **Tag @chigwell or @l1v0n1** in your PR for review.\n\n---\n\n## 🔒 Security Considerations\n- **Never commit your `.env` or session string.**\n- The session string gives full access to your Telegram account—keep it safe!\n- All processing is local; no data is sent anywhere except Telegram's API.\n- Use `.env.example` as a template and keep your actual `.env` file private.\n- Test files are automatically excluded in `.gitignore`.\n\n---\n\n## 🛠️ Troubleshooting\n- **Check logs** in your MCP client (Claude/Cursor) and the terminal for errors.\n- **Detailed error logs** can be found in `mcp_errors.log`.\n- **Interpreter errors?** Make sure your `.venv` is created and selected.\n- **Database lock?** Use session string authentication, not file-based sessions.\n- **iCloud/Dropbox issues?** Move your project to a local path without spaces if you see odd errors.\n- **Regenerate session string** if you change your Telegram password or see auth errors.\n- **Bot-only functions** will show clear messages when used with regular user accounts.\n- **Test script failures?** Check test configuration in `.env` for valid test accounts/groups.\n\n---\n\n## 📄 License\n\nThis project is licensed under the [Apache 2.0 License](LICENSE).\n\n---\n\n## 🙏 Acknowledgements\n- [Telethon](https://github.com/LonamiWebs/Telethon)\n- [Model Context Protocol](https://modelcontextprotocol.io/)\n- [Claude](https://www.anthropic.com/) and [Cursor](https://cursor.so/)\n- [chigwell/telegram-mcp](https://github.com/chigwell/telegram-mcp) (upstream)\n\n---\n\n**Maintained by [@chigwell](https://github.com/chigwell) and [@l1v0n1](https://github.com/l1v0n1). PRs welcome!**\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=chigwell/telegram-mcp&type=Date)](https://www.star-history.com/#chigwell/telegram-mcp&Date)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "telegram",
        "messages",
        "chats",
        "chigwell telegram",
        "telegram api",
        "communication integration"
      ],
      "category": "communication"
    },
    "gerkensm--callcenter.js-mcp": {
      "owner": "gerkensm",
      "name": "callcenter.js-mcp",
      "url": "https://github.com/gerkensm/callcenter.js-mcp",
      "imageUrl": "",
      "description": "An MCP server to make phone calls using VoIP/SIP and OpenAI's Realtime API and observe the transcript.",
      "stars": 9,
      "forks": 3,
      "license": "Other",
      "language": "TypeScript",
      "updated_at": "2025-10-02T05:45:37Z",
      "readme_content": "[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/gerkensm/callcenter.js-mcp)\n\n# CallCenter.js MCP + CLI\n\n**An MCP Server, CLI tool, and API that makes phone calls on your behalf using VoIP.**\n\nJust tell Claude what you want to accomplish, and it will call and handle the conversation for you. This is essentially an MCP Server that bridges between OpenAI's Real-Time Voice API and your VoIP connection to call people on your behalf.\n\n> **⚠️ Vibe-coded side project!** Please do not use this in any kind of professional context. This is a side project coded in a weekend. There are no guard rails. Your MCP client can call *any* number with this, even if you don't ask it to. In fact, it has done so during testing - it called a random number during the night \"for testing\" and played back scary low-pitched noises - then claimed it called MY number. So YMMV, no warranties. See [disclaimer](#️-important-disclaimer) below.\n\n## 📞 Example: Order Pizza with Claude\n\n**You:** \"Can you call Tony's Pizza and order a large pepperoni pizza for delivery to 123 Main St? My name is John and my number is 555-0123.\"\n\n**Claude automatically calls the restaurant:**\n\n```\n⏺ mcp__callcenter_js__simple_call(phone_number: \"+15551234567\", \n                                    brief: \"Call Tony's Pizza and order a large pepperoni pizza for delivery to 123 Main St. Customer name is John, phone number 555-0123\", \n                                    caller_name: \"John\")\n  ⎿ # Simple Call Result\n    \n    **Status:** ✅ Success  \n    **Duration:** 3 minutes 24 seconds\n    **Call ID:** abc123xyz\n    \n    ## Call Transcript\n    \n    [14:23:15] 🎤 HUMAN: Tony's Pizza, how can I help you?\n    [14:23:15] 🤖 ASSISTANT: Hi! I'm calling on behalf of John to place a delivery order.\n    [14:23:20] 🎤 HUMAN: Sure! What would you like?\n    [14:23:20] 🤖 ASSISTANT: I'd like to order one large pepperoni pizza for delivery please.\n    [14:23:25] 🎤 HUMAN: Large pepperoni, got it. What's the delivery address?\n    [14:23:25] 🤖 ASSISTANT: The address is 123 Main Street.\n    [14:23:30] 🎤 HUMAN: And your phone number?\n    [14:23:30] 🤖 ASSISTANT: The phone number is 555-0123.\n    [14:23:35] 🎤 HUMAN: Perfect! That'll be $18.99. We'll have it delivered in about 30 minutes.\n    [14:23:40] 🤖 ASSISTANT: That sounds great! Thank you so much.\n    [14:23:42] 🎤 HUMAN: You're welcome! Have a great day.\n```\n\n**Pizza ordered successfully!** 🍕\n\n## 📚 Quick Context for the Uninitiated\n\n**VoIP (Voice over IP)** is how you make phone calls over the internet instead of traditional phone lines. **SIP (Session Initiation Protocol)** is the language these systems speak to connect calls. Think of it as HTTP but for phone calls.\n\n**Fritz!Box** is a popular German router/modem that happens to have a built-in phone system (PBX). If you have one, you already have everything you need to make VoIP calls - this tool just connects to it. Outside Germany, you might know similar devices from other brands, or use dedicated VoIP services like Asterisk, 3CX, or cloud providers.\n\n**MCP (Model Context Protocol)** is Anthropic's standard for connecting AI assistants like Claude to external tools and services. It's what lets MCP clients actually *do* things instead of just talking about them.\n\n## 🚀 What This Enables\n\n- 🔌 **MCP Server** - Use directly in Claude Code or any MCP client (most popular usage)\n- 🖥️ **CLI Tool** - Command-line interface for direct phone calls  \n- 📚 **TypeScript API** - Programmatic library for building voice applications\n\nBuilt as a bridge between OpenAI's Real-Time Voice API and VoIP networks, with multiple codec support (G.722, G.711), and expanded SIP protocol support for broad VoIP compatibility. Compatible with the latest `gpt-realtime` model released August 28, 2025.\n\n## 🏗️ System Architecture\n\n```mermaid\ngraph TB\n    subgraph \"User Interface\"\n        A[Claude Code/MCP Client]\n        B[CLI Tool]\n        C[TypeScript API]\n    end\n    \n    subgraph \"CallCenter.js Core\"\n        D[MCP Server]\n        E[VoiceAgent]\n        F[Call Brief Processor<br/>o3-mini model]\n    end\n    \n    subgraph \"Communication Layer\"\n        G[SIP Client<br/>Provider Support]\n        H[Audio Bridge<br/>RTP Streaming]\n    end\n    \n    subgraph \"Audio Processing\"\n        I[G.722 Codec<br/>16kHz Wideband]\n        J[G.711 Codec<br/>8kHz Fallback]\n    end\n    \n    subgraph \"External Services\"\n        K[OpenAI Real-Time API<br/>gpt-realtime model]\n        L[VoIP Network<br/>Fritz!Box/Asterisk/etc]\n    end\n    \n    A --> D\n    B --> E\n    C --> E\n    D --> E\n    E --> F\n    E --> G\n    E --> H\n    F --> K\n    G --> L\n    H --> I\n    H --> J\n    H --> K\n    \n    style F fill:#e1f5fe\n    style K fill:#fff3e0\n    style L fill:#f3e5f5\n```\n\n> **⚠️ Vibe-coded project!** Developed and tested on Fritz!Box (a German router with built-in VoIP) only. Other provider configs are research-based but untested. YMMV, no warranties. See [disclaimer](#️-important-disclaimer) below.\n\n\n\n## 🔌 MCP Client Integration (Most Popular!)\n\n**Perfect for when your coding agent needs to call library authors to complain about their documentation!** 😄\n\n### Quick Setup\n\n```bash\n# Add to Claude Code with one command:\nclaude mcp add --env SIP_USERNAME=your_actual_extension \\\n  --env SIP_PASSWORD=\"your_actual_password\" \\\n  --env SIP_SERVER_IP=192.168.1.1 \\\n  --env OPENAI_API_KEY=\"sk-your_actual_openai_key\" \\\n  --env USER_NAME=\"Your Actual Name\" \\\n  -- callcenter.js npx -- github:gerkensm/callcenter.js-mcp --mcp\n```\n\n**Then just ask your MCP Client to make calls:**\n\n> \"Can you call the pizza place and order a large pepperoni? My number is 555-0123.\"\n\nYour MCP Client will automatically handle the entire conversation using the AI Voice Agent! 🤖📞\n\n## ✨ Key Features\n\n- 🎙️ **Multiple Codec Support**: G.722 wideband (16kHz) + G.711 fallback for broad compatibility\n- 🧩 **Compiler-Free WASM Codec**: Ships with a prebuilt G.722 WebAssembly module so `npx` users get wideband audio without installing build tools (native addon still available for max performance)\n- 🤖 **AI-Powered Conversations**: Uses OpenAI's Real-Time Voice API with the latest `gpt-realtime` model (released August 28, 2025) for actual calls, with o3-mini model for instruction generation\n- 🌍 **Automatic Language Detection**: Intelligently detects conversation language from call briefs and configures transcription accordingly\n- 🎭 **Auto Voice Selection**: New 'auto' mode where o3-mini selects optimal voice based on call context (formality, industry, goals)\n- 🔊 **Voice Characteristics**: Full support for all 10 OpenAI Realtime API voices with gender and personality awareness\n- 🌐 **Expanded SIP Support**: Configurations for common SIP providers (Fritz!Box tested, others experimental)\n- 🔧 **Smart Configuration**: Auto-detects provider requirements and optimizes settings\n- 📞 **Enterprise-Ready**: Supports advanced SIP features (STUN/TURN, session timers, transport fallback)\n- 🔄 **Robust Connection Management**: Automatic reconnection with intelligent error handling\n- ✅ **Built-in Validation**: Comprehensive configuration validation with network testing\n- 🎯 **Provider Profiles**: Pre-configured settings for popular SIP systems\n- 🔌 **MCP Server**: Integrate with MCP clients like Claude Code\n- 📚 **TypeScript API**: Programmatic library for building voice applications\n- 📝 **Call Brief Processing**: Natural language call instructions using o3-mini model with structured JSON output\n- 🎵 **Optional Call Recording**: Stereo WAV recording with caller/AI separation\n\n## 🚀 Quick Start\n\n### Option 1: Run Instantly with npx (No Installation) ⚡\n\n**Fastest way to try it out:**\n\n```bash\n# Set environment variables (or create .env file)\nexport SIP_USERNAME=\"your_extension\"\nexport SIP_PASSWORD=\"your_password\"\nexport SIP_SERVER_IP=\"192.168.1.1\"\nexport OPENAI_API_KEY=\"sk-your-key-here\"\n\n# Run directly from GitHub (no installation needed!)\nnpx github:gerkensm/callcenter.js-mcp call \"+1234567890\" --brief \"Call restaurant for reservation\" --user-name \"Your Name\"\n```\n\n**Or using a .env file:**\n\n```bash\n# Create .env file\ncat > .env << EOF\nSIP_USERNAME=your_extension\nSIP_PASSWORD=your_password\nSIP_SERVER_IP=192.168.1.1\nOPENAI_API_KEY=sk-your-key-here\nSIP_PROVIDER=fritz-box\nOPENAI_VOICE=auto\nEOF\n\n# Run from GitHub (loads .env automatically)  \nnpx github:gerkensm/callcenter.js-mcp call \"+1234567890\" --brief \"Call restaurant\"\n```\n\n**Note**: High-quality G.722 audio ships as a prebuilt WebAssembly module, so `npx` works even on machines without compilers. If you want the faster native addon instead, run `npm run build:native` (or `npm run build:all`) after cloning.\n\n### Option 2: Local Installation\n\n#### Prerequisites\n\n- Node.js 20+\n- (Optional) **Python 3.x + C/C++ build tools** — only needed if you plan to rebuild the native addon instead of using the bundled WebAssembly codec\n  - macOS: Xcode Command Line Tools (`xcode-select --install`)\n  - Windows: Visual Studio Build Tools \n  - Linux: `build-essential` package\n- OpenAI API key\n\n**Note**: The prebuilt WebAssembly codec already provides wideband G.722 audio out of the box. Rebuilding the native addon is optional and mainly useful for squeezing out a little more performance.\n\n#### Installation\n\n```bash\n# Clone and install\ngit clone https://github.com/gerkensm/callcenter.js-mcp\ncd callcenter.js-mcp\nnpm install\n\n# Copy example configuration\ncp config.example.json config.json\n```\n\n### Configuration\n\nEdit `config.json` with your settings:\n\n```json\n{\n  \"sip\": {\n    \"username\": \"your_sip_username\",\n    \"password\": \"your_sip_password\", \n    \"serverIp\": \"192.168.1.1\",\n    \"serverPort\": 5060,\n    \"provider\": \"fritz-box\"\n  },\n  \"ai\": {\n    \"openaiApiKey\": \"sk-your-openai-api-key-here\",\n    \"voice\": \"alloy\",\n    \"instructions\": \"You are a helpful AI assistant making phone calls on behalf of users.\",\n    \"userName\": \"Your Name\"\n  }\n}\n```\n\n## 🎯 Usage Options\n\n### 1. MCP Server (Claude Code Integration) ⭐\n\n**Most popular usage** - integrates with Claude Code for seamless AI-powered calling. Perfect for when your coding agent needs to call library authors to complain about their documentation! 😄\n\n#### **Quick Setup with npx (Recommended)** \n\n**Option 1: Using MCP Client CLI (Easiest)**\n\n```bash\n# Replace with your ACTUAL credentials before running:\nclaude mcp add --env SIP_USERNAME=your_actual_extension \\\n  --env SIP_PASSWORD=\"your_actual_password\" \\\n  --env SIP_SERVER_IP=192.168.1.1 \\\n  --env OPENAI_API_KEY=\"sk-your_actual_openai_key\" \\\n  --env USER_NAME=\"Your Actual Name\" \\\n  -- callcenter.js npx -- github:gerkensm/callcenter.js-mcp --mcp\n```\n\n**⚠️ Important:** Replace the placeholder values with your actual SIP credentials and OpenAI API key, or the server will fail to connect.\n\n**Option 2: Manual Configuration**\n\nConfigure in Claude Code's MCP settings to automatically pull from GitHub:\n\n```json\n{\n  \"mcpServers\": {\n    \"callcenter.js\": {\n      \"command\": \"npx\",\n      \"args\": [\"github:gerkensm/callcenter.js-mcp\", \"--mcp\"],\n      \"env\": {\n        \"SIP_USERNAME\": \"your_extension\",\n        \"SIP_PASSWORD\": \"your_password\",\n        \"SIP_SERVER_IP\": \"192.168.1.1\",\n        \"OPENAI_API_KEY\": \"sk-your-key-here\",\n        \"USER_NAME\": \"Your Name\"\n      }\n    }\n  }\n}\n```\n\n#### **Alternative: Local Installation**\n\nFor local development or if you prefer local installation:\n\n```bash\nnpm start --mcp\n```\n\nOr configure Claude Code with local installation:\n\n```json\n{\n  \"mcpServers\": {\n    \"callcenter.js\": {\n      \"command\": \"node\",\n      \"args\": [\"dist/cli.js\", \"--mcp\"],\n      \"cwd\": \"/path/to/voip-agent\"\n    }\n  }\n}\n```\n\nAvailable MCP tools:\n- `simple_call` - Make calls with automatic instruction generation\n- `advanced_call` - Make calls with granular parameter control\n\n**Example usage in MCP Client:**\n\n```\nYou: \"Can you call Bocca di Bacco restaurant and book a table for 2 people tonight at 7:30pm? My name is John Doe.\"\n\nMCP Client: I'll call Bocca di Bacco restaurant to book a table for 2 people tonight at 7:30pm.\n\n🔧 mcp__ai-voice-agent__simple_call(\n  phone_number: \"+1234567890\",\n  brief: \"Call Bocca di Bacco restaurant and book a table for 2 people tonight at 7:30pm\",\n  caller_name: \"John Doe\"\n)\n\n✅ Call completed successfully! \n📞 Duration: 2 minutes 15 seconds\n📝 Reservation confirmed for 2 people at 7:30pm tonight\n```\n\n**More examples:**\n\n```\nYou: \"My internet is down. Can you call my ISP and get a status update? I'm Sarah Johnson, account #12345.\"\n\nMCP Client: I'll call your internet service provider to check on the outage status.\n\n🔧 mcp__ai-voice-agent__simple_call(\n  phone_number: \"+18005551234\", \n  brief: \"Call ISP about internet outage, customer Sarah Johnson account #12345\",\n  caller_name: \"Sarah Johnson\"\n)\n```\n\n```\nYou: \"Call Dr. Smith's office to reschedule my 3pm appointment to next week. I'm Mike Chen.\"\n\nMCP Client: I'll call Dr. Smith's office to reschedule your appointment.\n\n🔧 mcp__ai-voice-agent__simple_call(\n  phone_number: \"+15551234567\",\n  brief: \"Call Dr. Smith's office to reschedule Mike Chen's 3pm appointment to next week\", \n  caller_name: \"Mike Chen\"\n)\n```\n\nThe MCP Client automatically handles the entire conversation using the AI Voice Agent!\n\n### 2. Command Line Interface\n\n**Perfect for when you need to `curl -X POST` your way out of social obligations, or finally implement that O(n log n) `ai-human-sort` algorithm - because nothing says \"efficient sorting\" like crowdsourcing comparisons to random strangers via VoIP!** 😄\n\n**💡 Use `--brief` instead of `--instructions` for better results!**\n\nThe `--brief` option uses OpenAI's o3-mini model to generate sophisticated instructions from your simple description, while `--instructions` sends your text directly to the Real-Time Voice API. Since the Real-Time Voice API is optimized for speed (not sophistication), `--brief` typically produces much better call outcomes.\n\n```bash\n# ✅ RECOMMENDED: Use brief for natural language goals\nnpm start call \"+1234567890\" --brief \"Call the restaurant and book a table for 2 at 7pm tonight\" --user-name \"John Doe\"\n\n# ✅ RECOMMENDED: Brief works for any call type\nnpm start call \"+1234567890\" --brief \"Call to check appointment availability for John Doe\"\n\n# ⚠️ ONLY use instructions for very specific, custom behavior\nnpm start call \"+1234567890\" --instructions \"You must follow this exact script: Say hello, ask for manager, then hang up\"\n\n# Other examples with brief\nnpm start call \"+1234567890\" --record \"meeting.wav\" --duration 300 --brief \"Conference call to discuss project status\"\nnpm start call \"+1234567890\" --log-level verbose --brief \"Test call to verify connectivity\"\n```\n\n#### CLI Options\n\n```bash\nnpm start call <number> [options]\n\nOptions:\n  -c, --config <path>           Configuration file path (default: config.json)\n  -d, --duration <seconds>      Maximum call duration in seconds (default: 600)\n  -v, --verbose                 Verbose mode - show all debug information\n  -q, --quiet                   Quiet mode - show only transcripts, errors, and warnings\n  --log-level <level>           Set log level (quiet|error|warn|info|debug|verbose) (default: info)\n  --no-colors                   Disable colored output\n  --no-timestamp                Disable timestamps in logs\n  --record [filename]           Enable stereo call recording (optional filename)\n  --brief <text>                Call brief to generate instructions from (RECOMMENDED)\n  --instructions <text>         Direct AI instructions (use only for specific custom behavior)\n  --user-name <name>            Your name for the AI to use when calling\n  --voice <name>                Voice to use (default: auto) - see Voice Selection section\n  --help                        Display help information\n```\n\n### 3. Programmatic API\n\n```typescript\nimport { makeCall, createAgent } from 'callcenter.js';\n\n// Simple call with brief\nconst result = await makeCall({\n  number: '+1234567890',\n  brief: 'Call Bocca di Bacco and book a table for 2 at 19:30 for Torben',\n  userName: 'Torben',\n  config: 'config.json'\n});\n\nconsole.log(`Call duration: ${result.duration}s`);\nconsole.log(`Transcript: ${result.transcript}`);\n\n// Advanced usage with agent instance\nconst agent = await createAgent('config.json');\n\nagent.on('callEnded', () => {\n  console.log('Call finished!');\n});\n\nawait agent.makeCall({ \n  targetNumber: '+1234567890',\n  duration: 300 \n});\n```\n\n## 📚 API Reference\n\n### `makeCall(options: CallOptions): Promise<CallResult>`\n\nMake a phone call with the AI agent.\n\n#### CallOptions\n\n```typescript\ninterface CallOptions {\n  number: string;                    // Phone number to call\n  duration?: number;                 // Call duration in seconds\n  config?: string | Config;          // Configuration file path or object\n  instructions?: string;             // Direct AI instructions (highest priority)\n  brief?: string;                    // Call brief to generate instructions from\n  userName?: string;                 // Your name for the AI to use\n  recording?: boolean | string;      // Enable recording with optional filename\n  logLevel?: 'quiet' | 'error' | 'warn' | 'info' | 'debug' | 'verbose';\n  colors?: boolean;                  // Enable colored output\n  timestamps?: boolean;              // Enable timestamps in logs\n}\n```\n\n#### CallResult\n\n```typescript\ninterface CallResult {\n  callId?: string;                   // Call ID if successful\n  duration: number;                  // Call duration in seconds\n  transcript?: string;               // Full conversation transcript\n  success: boolean;                  // Whether call was successful\n  error?: string;                    // Error message if failed\n}\n```\n\n### `createAgent(config, options?): Promise<VoiceAgent>`\n\nCreate a VoiceAgent instance for advanced use cases.\n\n```typescript\nconst agent = await createAgent('config.json', {\n  enableCallRecording: true,\n  recordingFilename: 'call.wav'\n});\n\n// Event handlers\nagent.on('callInitiated', ({ callId, target }) => {\n  console.log(`Call ${callId} started to ${target}`);\n});\n\nagent.on('callEnded', () => {\n  console.log('Call ended');\n});\n\nagent.on('error', (error) => {\n  console.error('Call error:', error.message);\n});\n```\n\n### Configuration Structure\n\n```typescript\ninterface Config {\n  sip: {\n    username: string;\n    password: string;\n    serverIp: string;\n    serverPort?: number;\n    provider?: string;\n    stunServers?: string[];\n    turnServers?: TurnServer[];\n  };\n  ai: {\n    openaiApiKey: string;\n    voice?: 'auto' | 'alloy' | 'ash' | 'ballad' | 'cedar' | 'coral' | 'echo' | 'marin' | 'sage' | 'shimmer' | 'verse';\n    instructions?: string;\n    brief?: string;\n    userName?: string;\n  };\n  logging?: {\n    level?: string;\n  };\n}\n```\n\n### Environment Variables\n\nAll configuration options can be set via environment variables (useful for npx usage):\n\n#### **Required Variables:**\n```bash\nSIP_USERNAME=your_extension\nSIP_PASSWORD=your_password  \nSIP_SERVER_IP=192.168.1.1\nOPENAI_API_KEY=sk-your-key-here\nUSER_NAME=\"Your Name\"                                     # Required when using --brief\n```\n\n#### **Optional Variables:**\n```bash\n# SIP Configuration\nSIP_SERVER_PORT=5060\nSIP_LOCAL_PORT=5060\nSIP_PROVIDER=fritz-box                                    # fritz-box, asterisk, cisco, 3cx, generic\nSTUN_SERVERS=\"stun:stun.l.google.com:19302,stun:stun2.l.google.com:19302\"\nSIP_TRANSPORTS=\"udp,tcp\"\n\n# OpenAI Configuration  \nOPENAI_VOICE=auto                                        # auto (recommended), marin, cedar, alloy, echo, shimmer, coral, sage, ash, ballad, verse\nOPENAI_INSTRUCTIONS=\"Your custom AI instructions\"\n\n# Advanced SIP Features\nSESSION_TIMERS_ENABLED=true\nSESSION_EXPIRES=1800\nSESSION_MIN_SE=90\nSESSION_REFRESHER=uac\n```\n\n**Priority order:** CLI flags > Config file > Environment variables\n\n## ✅ Quick Success Check\n\nBefore making real calls, validate your setup with these safe tests:\n\n### 1. Configuration Validation\n```bash\n# Basic validation - checks syntax and required fields\nnpm run validate config.json\n\n# Detailed validation with network connectivity tests  \nnpm run validate:detailed\n\n# Get specific fix suggestions for issues\nnpm run validate:fix\n```\n\n### 2. Test Call to Yourself (Fritz!Box users)\n```bash\n# Call your own extension to verify audio quality (safe test)\nnpm start call \"**620\" --brief \"Test call to check audio quality\" --user-name \"Your Name\" --duration 30\n\n# Or use your mobile number for end-to-end test\nnpm start call \"+49123456789\" --brief \"Quick test call\" --user-name \"Your Name\" --duration 15\n```\n\n### 3. What to Expect\n- ✅ **Working setup**: Clear audio, proper AI responses, clean call termination\n- ⚠️ **Network issues**: \"Connection failed\" errors → check firewall/STUN settings  \n- ⚠️ **Auth problems**: \"401 Unauthorized\" → verify SIP credentials\n- ⚠️ **Codec issues**: Poor audio quality → G.722 compilation may have failed\n\n> **Pro tip**: Start with `--duration 30` for test calls to avoid long waits if something goes wrong.\n\n## 📋 Configuration Validation\n\nThe built-in validation system provides comprehensive analysis:\n\n```bash\n# Basic validation\nnpm run validate config.json\n\n# Detailed validation with network connectivity tests\nnpm run validate:detailed\n\n# Get specific fix suggestions for issues\nnpm run validate:fix\n\n# Test example configurations for different providers\nnpm run validate:fritz-box       # AVM Fritz!Box\nnpm run validate:asterisk        # Asterisk PBX  \nnpm run validate:cisco           # Cisco CUCM\nnpm run validate:3cx             # 3CX Phone System\nnpm run validate:generic         # Generic SIP provider\n```\n\nThe validator will check:\n- ✅ **Configuration syntax and required fields**\n- ✅ **Provider-specific requirements**\n- ✅ **Network connectivity to SIP server**\n- ✅ **STUN server reachability**\n- ✅ **Codec availability (G.722/G.711)**\n- ✅ **Provider compatibility score**\n\n## 🌐 SIP Provider Compatibility\n\n### ✅ **Actually Tested** \n\n- **AVM Fritz!Box** - German router brand with built-in VoIP/SIP phone system ✅ **WORKS** (only one actually tested)\n\n### 🤷 **Vibe-coded Configs** (Educated Guesses)\n\n- **Asterisk PBX** - Open source PBX (FreePBX, Elastix, etc.) 🤷 **UNTESTED**\n- **Cisco CUCM** - Enterprise Unified Communications 🤷 **UNTESTED** \n- **3CX Phone System** - Popular business PBX 🤷 **UNTESTED**\n- **Generic SIP Providers** - Standards-compliant SIP trunks 🤷 **UNTESTED**\n\n### 🔧 **Provider-Specific Features**\n\nThe provider profiles are based on research and documentation, not actual testing:\n\n| Provider | Transport | NAT Traversal | Session Timers | PRACK | Keepalive |\n|----------|-----------|---------------|----------------|--------|----------|\n| **Fritz Box** | UDP | Not needed | Optional | Disabled | Re-register |\n| **Asterisk** | UDP/TCP | STUN | Supported | Optional | OPTIONS ping |\n| **Cisco CUCM** | TCP preferred | STUN required | Required | Required | OPTIONS ping |\n| **3CX** | TCP/UDP | STUN | Supported | Optional | Re-register |\n\n### Configuration Decision Tree\n\n```mermaid\nflowchart TD\n    A[Choose Your SIP Provider] --> B{Fritz!Box Router?}\n    B -->|Yes| C[✅ Use fritz-box profile<br/>UDP transport<br/>No STUN needed]\n    B -->|No| D{Enterprise System?}\n    \n    D -->|Cisco CUCM| E[⚠️ Use cisco profile<br/>TCP transport<br/>STUN required<br/>Session timers + PRACK]\n    D -->|3CX| F[⚠️ Use 3cx profile<br/>TCP/UDP transport<br/>STUN recommended]\n    D -->|Asterisk/FreePBX| G[⚠️ Use asterisk profile<br/>UDP/TCP transport<br/>STUN for NAT]\n    D -->|Other| H[⚠️ Use generic profile<br/>Start with UDP<br/>Add STUN if needed]\n    \n    C --> I[Configure Basic Settings]\n    E --> J[Configure Enterprise Settings]\n    F --> J\n    G --> J\n    H --> J\n    \n    I --> K[Set SIP credentials<br/>serverIp = router IP<br/>typically 192.168.1.1]\n    J --> L[Set SIP credentials<br/>serverIp = server IP<br/>Add STUN servers]\n    \n    K --> M{Network Location?}\n    L --> M\n    \n    M -->|Local Network| N[✅ Basic setup complete<br/>Should work reliably]\n    M -->|Cloud/Remote| O[❓ May need additional<br/>STUN/TURN configuration]\n    \n    style C fill:#c8e6c9\n    style E fill:#ffecb3\n    style F fill:#ffecb3\n    style G fill:#ffecb3\n    style H fill:#ffecb3\n    style N fill:#c8e6c9\n    style O fill:#ffe0b2\n```\n\n### 📝 **Configuration Examples**\n\nThe project includes ready-to-use configurations for all major providers:\n\n- `config.example.json` - **AVM Fritz!Box** (home/SMB default)\n- `config.asterisk.example.json` - **Asterisk PBX** with advanced features\n- `config.cisco.example.json` - **Cisco CUCM** enterprise setup\n- `config.3cx.example.json` - **3CX Phone System** configuration\n- `config.generic.example.json` - **Generic SIP provider** template\n\n## 🎵 Audio Quality & Codecs\n\n### Codec Priority & Negotiation\n\n1. **G.722** (Preferred) - 16kHz wideband, superior voice quality\n2. **G.711 μ-law** (Fallback) - 8kHz narrowband, universal compatibility  \n3. **G.711 A-law** (Fallback) - 8kHz narrowband, European standard\n\n### G.722 Implementation\n\n- **Prebuilt WebAssembly codec** bundled with the package so every install gets wideband audio out of the box\n- **Native C++ addon** still available for optimal performance when you opt-in with `npm run build:native`\n- **Based on reference implementations** from CMU and Sippy Software\n- **Automatic fallback** to G.711 if codec loading fails for any reason\n- **Real-time encoding/decoding** with low latency\n\n### Optional Call Recording\n\n- **Stereo WAV format** with caller on left channel, AI on right channel\n- **Optional filename** specification\n- **Synchronized audio streams** for perfect alignment\n- **High-quality PCM recording** at native sample rates\n\n### Testing Audio Quality\n\n```bash\n# Test codec availability\nnpm run test:codecs\n\n# Rebuild all codec artifacts (native + WASM + TS) if you changed the C sources\nnpm run build:all\n\n# Disable G.722 entirely if you only want the G.711 fallback\nnpm run build:no-g722\n```\n\n## 🤖 AI Call Brief Processing\n\n### Why This Matters: Real-Time Voice API Needs Better Instructions\n\nOpenAI's Real-Time Voice API is **optimized for speed, not sophistication**. It's great at natural conversation but struggles with complex, goal-oriented tasks without very specific instructions. Here's the problem:\n\n**❌ What doesn't work well:**\n```bash\n# Vague brief - Real-Time Voice API will be confused and unfocused\nnpm start call \"+1234567890\" --brief \"Call the restaurant and book a table\"\n```\n\n**❌ What's tedious and error-prone:**\n```bash\n# Writing detailed instructions manually every time\nnpm start call \"+1234567890\" --instructions \"You are calling on behalf of John Doe to make a restaurant reservation for 2 people at Bocca di Bacco for tonight at 7pm. You should start by greeting them professionally, then clearly state your purpose. Ask about availability for 7pm, and if not available, ask for alternative times between 6-8pm. Confirm the booking details including date, time, party size, and get a confirmation number if possible. If you reach voicemail, leave a professional message with callback information...\"\n```\n\n**✅ What works brilliantly:**\n```bash\n# Simple brief - o3 model generates sophisticated instructions\nnpm start call \"+1234567890\" --brief \"Call Bocca di Bacco and book a table for 2 at 7pm tonight\" --user-name \"John Doe\"\n```\n\n### How It Works\n\nThe system uses OpenAI's **o3-mini reasoning model** (their latest small reasoning model - smart but fast) to automatically generate detailed, sophisticated instructions from your simple brief. The o3-mini model:\n\n1. **Analyzes your brief** and understands the goal\n2. **Creates conversation states** and flow logic  \n3. **Generates specific instructions** for each phase of the call\n4. **Handles edge cases** like voicemail, objections, and alternatives\n5. **Adapts language and tone** based on context\n6. **Provides fallback strategies** when things don't go as planned\n\n### Call Flow Sequence\n\n```mermaid\nsequenceDiagram\n    participant U as User/Claude\n    participant V as VoiceAgent\n    participant B as Brief Processor<br/>(o3-mini)\n    participant S as SIP Client\n    participant A as Audio Bridge\n    participant O as OpenAI Realtime<br/>(gpt-realtime)\n    participant P as Phone/VoIP\n\n    U->>V: makeCall({brief, number, userName})\n    V->>B: Process brief with o3-mini\n    B->>B: Generate detailed instructions<br/>& conversation states\n    B->>V: Sophisticated call instructions\n    \n    V->>S: Connect to SIP server\n    S->>P: INVITE (start call)\n    P->>S: 200 OK (call answered)\n    S->>V: Call established\n    \n    V->>A: Initialize audio bridge\n    V->>O: Connect to OpenAI Realtime\n    O->>V: WebSocket connected\n    V->>O: Send generated instructions\n    \n    loop During Call\n        P->>A: RTP audio packets\n        A->>A: Decode G.722/G.711 → PCM\n        A->>O: Stream PCM audio\n        O->>O: Process speech → text\n        O->>O: Generate AI response\n        O->>A: Stream AI audio (PCM)\n        A->>A: Encode PCM → G.722/G.711\n        A->>P: RTP audio packets\n        \n        Note over V: Monitor call progress<br/>& transcript logging\n    end\n    \n    alt Call completed naturally\n        O->>V: Call completion signal\n        V->>S: Send BYE\n    else Duration limit reached\n        V->>V: Safety timeout triggered\n        V->>S: Send BYE\n    end\n    \n    S->>P: BYE (end call)\n    P->>S: 200 OK\n    V->>U: CallResult{transcript, duration, success}\n```\n\n### Before/After Example\n\n**Your simple input:**\n```\n\"Call Bocca di Bacco and book a table for 2 at 7pm tonight\"\n```\n\n**What o3-mini generates (excerpt):**\n```\n## Personality and Tone\nIdentity: I am an assistant calling on behalf of John Doe to make a restaurant reservation.\nTask: I am responsible for booking a table for 2 people at Bocca di Bacco today at 7:00 PM.\nTone: Professional, warm, and respectful.\n\n## Instructions\n1. Open the conversation immediately: \"Hello, this is an assistant calling on behalf of John Doe.\"\n2. Read back critical data: Repeat times and details for confirmation.\n3. Handle objections: Respond politely and offer alternatives between 6-8 PM.\n...\n\n## Conversation States\n[\n  {\n    \"id\": \"1_greeting\",\n    \"description\": \"Greeting and introduction of call purpose\",\n    \"instructions\": [\"Introduce yourself as an assistant\", \"Immediately mention the reservation request\"],\n    \"examples\": [\"Hello, this is an assistant calling on behalf of John Doe. I'm calling to book a table for 2 people today at 7:00 PM.\"]\n  }\n]\n```\n\n### Automatic Adaptations\n\nThe o3-mini brief processor automatically:\n- **Detects language** from your brief and generates instructions in that language\n- **Creates conversation flow** with logical states and transitions\n- **Handles cultural context** (German restaurants vs. American vs. Japanese)\n- **Generates appropriate examples** with real phrases (no placeholders)\n- **Provides voicemail scripts** for when nobody answers\n- **Plans for objections** and alternative solutions\n\n### When to Use Each Approach\n\n- **Use `--brief`** for 95% of calls - it's easier and produces better results\n- **Use `--instructions`** only when you need very specific, custom behavior\n- **Brief processing** is perfect for: reservations, appointments, business calls, customer service\n- **Direct instructions** are better for: highly specialized scenarios, testing, or when you've already perfected your prompt\n\n## 🎤 Voice Selection\n\nThe AI agent supports 10 different voices from OpenAI's Realtime API, each with unique characteristics. By default, the system uses **auto mode** where o3-mini intelligently selects the optimal voice based on your call's context.\n\n### Available Voices\n\n| Voice | Gender | Description | Best For |\n|-------|--------|-------------|----------|\n| **marin** | Female | Clear, professional feminine voice | All-purpose: business calls, customer support, negotiations |\n| **cedar** | Male | Natural masculine voice with warm undertones | All-purpose: professional calls, consultations, service interactions |\n| **alloy** | Neutral | Professional voice with good adaptability | Technical discussions, business contexts, general inquiries |\n| **echo** | Male | Conversational masculine voice | Casual to formal interactions, versatile tone |\n| **shimmer** | Female | Warm, expressive feminine voice | Empathetic conversations, sales, professional contexts |\n| **coral** | Female | Warm and friendly feminine voice | Customer interactions, consultations, support calls |\n| **sage** | Neutral | Calm and thoughtful voice | Medical consultations, advisory roles, serious discussions |\n| **ash** | Neutral | Clear and precise voice | Technical explanations, instructions, educational content |\n| **ballad** | Female | Melodic and smooth feminine voice | Presentations, storytelling, engaging conversations |\n| **verse** | Neutral | Versatile and expressive voice | Dynamic conversations, adaptable to any context |\n\n### Auto Voice Selection (Recommended)\n\nThe **auto mode** (default) uses o3-mini to analyze your call context and select the most appropriate voice:\n\n```bash\n# Auto mode - AI selects the best voice\nnpm start call \"+1234567890\" --brief \"Call doctor's office to schedule appointment\" --user-name \"John\"\n# Might select: sage (calm, professional for healthcare)\n\n# Auto mode adapts to context\nnpm start call \"+1234567890\" --brief \"Call pizza place to order delivery\" --user-name \"Sarah\"  \n# Might select: coral or echo (friendly, casual for food service)\n```\n\n### Manual Voice Selection\n\nYou can override auto selection when you have specific requirements:\n\n```bash\n# Use a specific voice\nnpm start call \"+1234567890\" --voice marin --brief \"Call to book reservation\" --user-name \"Alex\"\n\n# Professional contexts\nnpm start call \"+1234567890\" --voice cedar --brief \"Call bank about account\" --user-name \"Pat\"\n\n# Friendly service calls\nnpm start call \"+1234567890\" --voice coral --brief \"Call flower shop for delivery\" --user-name \"Sam\"\n```\n\n### Configuration Options\n\nSet default voice in your config file or environment:\n\n```json\n// config.json\n{\n  \"ai\": {\n    \"voice\": \"auto\",  // or specific voice like \"marin\", \"cedar\", etc.\n    // ...\n  }\n}\n```\n\n```bash\n# Environment variable\nexport OPENAI_VOICE=auto  # or marin, cedar, alloy, etc.\n```\n\n### Voice Selection Guidelines\n\nThe auto mode considers these factors:\n\n- **Formality Level**: High (cedar, marin, sage) → Medium (alloy, verse) → Low (echo, coral, shimmer)\n- **Industry Context**: Healthcare (sage, shimmer), Finance (cedar, sage), Retail (coral, echo), Tech (alloy, ash)\n- **Goal Type**: Authority needed (cedar, sage), Friendliness (coral, shimmer), Efficiency (marin, alloy)\n- **Language**: Voices adapt to detected language from your call brief\n\n### MCP Integration\n\nThe MCP tools strongly recommend auto mode but support manual override:\n\n```typescript\n// Simple call - auto voice selection\nmcp__callcenter_js__simple_call({\n  phone_number: \"+1234567890\",\n  brief: \"Call restaurant for reservation\",\n  caller_name: \"John\",\n  voice: \"auto\"  // Optional, defaults to auto\n})\n\n// Advanced call - manual voice selection\nmcp__callcenter_js__advanced_call({\n  phone_number: \"+1234567890\",\n  goal: \"Schedule medical appointment\",\n  user_name: \"Jane\",\n  voice: \"sage\"  // Override for specific voice\n})\n```\n\n## 🔄 Advanced Features\n\n### Smart Connection Management\n\n- **Automatic Reconnection**: Exponential backoff with provider-specific error handling\n- **Transport Fallback**: UDP → TCP → TLS based on what works\n- **Provider-Aware Error Recovery**: Different strategies for Fritz Box vs. Asterisk vs. Cisco\n- **Network Change Handling**: Adapts to network connectivity changes\n\n### Enhanced SIP Protocol Support\n\n- **STUN/TURN Integration**: NAT traversal for cloud and enterprise deployments\n- **Session Timers (RFC 4028)**: Connection stability for long calls\n- **PRACK Support (RFC 3262)**: Reliable provisional responses for enterprise systems\n- **Multiple Transports**: UDP, TCP, TLS with intelligent fallback\n\n### Configuration Intelligence\n\n- **Provider Auto-Detection**: Identifies provider from SIP domain/IP\n- **Requirements Validation**: Ensures all provider-specific needs are met  \n- **Network Testing**: Real connectivity tests to SIP servers and STUN servers\n- **Optimization Suggestions**: Actionable recommendations for better performance\n\n## 🛠️ Development & Testing\n\n### Build Commands\n\n```bash\n# Default build (WASM refresh + TypeScript, skips if artifacts already exist)\nnpm run build\n\n# Build components separately (useful for maintainers)  \nnpm run build:wasm     # Regenerate the G.722 WebAssembly codec\nnpm run build:native   # Rebuild the native addon (requires toolchain)\nnpm run build:all      # Run native + WASM + TypeScript in one go\nnpm run build:ts       # TypeScript compilation only\n\n# Development with hot reload\nnpm run dev\n\n# Clean all build artifacts\nnpm run clean\n```\n\n### Configuration Testing\n\n```bash\n# Validate any config file\nnpm run validate path/to/config.json\n\n# Test with different providers\nnpm run validate -- --provider asterisk config.json\n\n# Get detailed network diagnostics\nnpm run validate -- --detailed --network config.json\n\n# Show fix suggestions for issues\nnpm run validate -- --fix-suggestions config.json\n```\n\n### Project Structure\n\n```\nsrc/\n├── voice-agent.ts          # Main orchestration with ConnectionManager\n├── connection-manager.ts   # Smart connection handling & reconnection\n├── sip-client.ts          # Enhanced SIP protocol with provider support\n├── audio-bridge.ts        # RTP streaming and codec management\n├── openai-client.ts       # OpenAI Real-Time Voice API integration\n├── call-brief-processor.ts # o3-mini model call brief processing\n├── mcp-server.ts          # MCP (Model Context Protocol) server\n├── validation.ts          # Configuration validation engine\n├── config.ts             # Enhanced config loading with provider profiles\n├── logger.ts             # Comprehensive logging with transcript capture\n├── index.ts              # Main programmatic API exports\n├── providers/\n│   └── profiles.ts       # Provider-specific configuration database\n├── testing/\n│   └── network-tester.ts # Real network connectivity testing\n├── codecs/               # Codec abstraction layer\n│   ├── g722.ts          # G.722 wideband implementation\n│   └── g711.ts          # G.711 fallback codecs\n└── cli.ts               # Command-line interface\n\nscripts/\n└── validate-config.js   # Comprehensive validation CLI tool\n\nconfig.*.example.json    # Provider-specific example configurations\n```\n\n## 📊 Validation & Diagnostics\n\nThe built-in validation system provides comprehensive analysis:\n\n### Configuration Report Example\n\n```\n🔍 CallCenter.js Configuration Validator\n\n📋 Provider: AVM Fritz!Box (auto-detected)\n🎯 Provider Compatibility Score: 100%\n\n✅ Configuration is valid and ready for use!\n\n🌐 Network Connectivity:\n   ✅ SIP Server: Reachable (12ms latency)\n   ✅ G.722 codec: Available for high-quality audio\n\n💡 Optimization Suggestions:\n   💡 G.722 wideband codec available (already enabled)\n   💡 Excellent latency - local network performance optimal\n\n🚀 Next steps: npm start call \"<number>\"\n```\n\n### Network Diagnostics\n\n- **Real SIP Server Testing**: Actual UDP/TCP connectivity tests\n- **STUN Server Validation**: Tests NAT traversal capability\n- **Latency Measurement**: Network performance assessment\n- **Provider-Specific Recommendations**: Tailored advice based on detected issues\n\n## 🔧 Troubleshooting\n\n### Configuration Issues\n\n1. **Run validation first**:\n   ```bash\n   npm run validate:detailed\n   ```\n\n2. **Check provider compatibility**:\n   ```bash\n   npm run validate -- --provider fritz-box config.json\n   ```\n\n3. **Get specific fix suggestions**:\n   ```bash\n   npm run validate:fix\n   ```\n\n### Network Connectivity\n\n- **Fritz Box**: Usually works with UDP on local network\n- **Cloud/Enterprise**: May need STUN servers for NAT traversal\n- **Firewall Issues**: Ensure SIP port (5060) and RTP ports are open\n\n### Audio Quality\n\n1. **Verify G.722 is available**:\n   ```bash\n   npm run test:codecs\n   ```\n\n2. **Check codec negotiation in logs**:\n   ```\n   ✅ Selected codec: PT 9 (G722/8000)\n   ```\n\n3. **Network issues**: High latency/packet loss affects audio quality\n\n### Build Problems\n\n1. **Native compilation fails** (only happens if you explicitly ran `npm run build:native` or `npm run build:all`): stick with the bundled WASM codec unless you specifically need native performance. To drop back to G.711 entirely, run:\n   ```bash\n   npm run build:no-g722\n   ```\n\n2. **Provider-specific issues**: Check validation recommendations for your provider\n\n### MCP Integration Issues\n\n1. **Server won't start**:\n   ```bash\n   # Check for port conflicts or config issues\n   npm start --mcp\n   ```\n\n2. **Claude Code not connecting**:\n   - Verify MCP server configuration in Claude Code settings\n   - Check that the working directory path is correct\n   - Ensure the server is running and accessible\n\n## 📈 What I Built\n\nThis is a personal project that includes:\n\n- **🌐 Fritz!Box Support**: Actually tested and works\n- **🤷 Other SIP Configs**: Vibe-coded based on documentation reading\n- **🔄 Connection Handling**: Seems to work, has retry logic\n- **✅ Config Validation**: Catches obvious mistakes\n- **📊 Network Testing**: Basic connectivity checks\n- **🎯 Provider Profiles**: Research-based guesses about different systems\n- **🔌 MCP Server**: Works with Claude Code (tested)\n- **📚 TypeScript API**: Clean interfaces for programmatic use\n- **📝 Call Brief Processing**: Uses o3-mini to generate instructions (works well)\n- **🎵 Optional Call Recording**: Stereo WAV files with left/right channels\n- **📋 Transcript Capture**: Real-time conversation logs\n\n## ⚠️ Important Disclaimer\n\n**This project is vibe-coded!** 🚀 \n\nThis means:\n- ✅ **Works on Fritz!Box** - that's what I actually tested\n- 🤷 **Other providers** - I tried to make it more useful but can't promise anything\n- 🤷 **Advanced features** - seemed like good ideas based on research, but who knows\n- ⚠️ **YMMV** - your setup is probably different than mine\n- ⚠️ **No warranties** - use at your own risk\n\n### What This Means for You\n\n- **Fritz Box users**: Should work great! ✅\n- **Other providers**: The configuration profiles are educated guesses based on research - they might work, they might not\n- **Enterprise users**: I tried to add the features that seemed important, but I have no idea if they actually work correctly\n- **Issues & PRs**: I'll accept pull requests, but I can't promise to fix issues I can't reproduce or test\n\n### If You Want to Contribute\n\n- ✅ **Test it on your setup** and let others know what works\n- ✅ **Share working configs** if you get something else working\n- ✅ **Fix stuff that's broken** and submit PRs\n- ✅ **Tell me if my assumptions were wrong** about how providers work\n\nThe validation tools might help debug issues, but honestly, the real test is whether you can make actual calls.\n\n## 📜 License\n\nMIT License - see [LICENSE](LICENSE) for details.\n\n### Third-Party Components\n\n- **G.722 Codec**: Public domain and BSD licensed implementations\n- **SIP Protocol**: Based on sipjs-udp (MIT licensed)\n- **Dependencies**: Various open source licenses (see package.json)\n\n## 🤝 Contributing\n\n1. Fork the repository\n2. Create a feature branch  \n3. Add/update validation for new providers\n4. Test with `npm run validate:detailed`\n5. Submit a pull request\n\n## 📞 Support\n\n- **Configuration Issues**: Use `npm run validate:detailed` for diagnostics\n- **Provider Support**: Check compatibility matrix above\n- **Build Problems**: See troubleshooting section\n- **Feature Requests**: You can open GitHub issues, but they're unlikely to get attention anytime soon. Pull requests are much preferred!\n\n---\n\n**Ready to get started?** Copy an example config, run `npm run validate:detailed`, and start making AI-powered voice calls! 🚀",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "callcenter",
        "voip",
        "mcp",
        "gerkensm callcenter",
        "communication tools",
        "communication platforms"
      ],
      "category": "communication"
    },
    "gotoolkits--wecombot": {
      "owner": "gotoolkits",
      "name": "wecombot",
      "url": "https://github.com/gotoolkits/mcp-wecombot-server.git",
      "imageUrl": "",
      "description": "An MCP server application that sends various types of messages to the WeCom group robot.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "communication",
        "robot",
        "messages",
        "communication tools",
        "communication platforms",
        "communication integration"
      ],
      "category": "communication"
    },
    "hannesrudolph--imessage-query-fastmcp-mcp-server": {
      "owner": "hannesrudolph",
      "name": "imessage-query-fastmcp-mcp-server",
      "url": "https://github.com/hannesrudolph/imessage-query-fastmcp-mcp-server",
      "imageUrl": "",
      "description": "An MCP server that provides safe access to your iMessage database through Model Context Protocol (MCP), enabling LLMs to query and analyze iMessage conversations with proper phone number validation and attachment handling",
      "stars": 69,
      "forks": 13,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-04T05:33:48Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/hannesrudolph-imessage-query-fastmcp-mcp-server-badge.png)](https://mseep.ai/app/hannesrudolph-imessage-query-fastmcp-mcp-server)\n\n# iMessage Query MCP Server\n\nAn MCP server that provides safe access to your iMessage database through Model Context Protocol (MCP). This server is built with the FastMCP framework and the imessagedb library, enabling LLMs to query and analyze iMessage conversations with proper phone number validation and automatic macOS permission handling.\n\n## 📋 System Requirements\n\n- macOS (required for iMessage database access)\n- Python 3.12+ (required for modern type hints)\n- **uv** (modern Python package manager)\n- **Full Disk Access permission** for your MCP client (Claude Desktop, Cursor, VS Code, etc.)\n\n## 📦 Dependencies\n\n### Install uv (Required)\n\nThis project uses `uv` for fast, reliable Python package management. Install it first:\n\n```bash\n# Install uv using Homebrew (recommended)\nbrew install uv\n\n# Or install using the official installer\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n### Python Dependencies\n\nThe script automatically manages its dependencies using the embedded metadata. No separate installation needed! Dependencies include:\n\n- **fastmcp**: Framework for building Model Context Protocol servers\n- **imessagedb**: Python library for accessing and querying the macOS Messages database\n- **phonenumbers**: Google's phone number handling library for proper number validation and formatting\n\nAll dependencies are automatically installed when the script runs via `uv`.\n\n## 📑 Table of Contents\n- [System Requirements](#-system-requirements)\n- [Dependencies](#-dependencies)\n- [MCP Tools](#%EF%B8%8F-mcp-tools)\n- [Getting Started](#-getting-started)\n- [Installation Options](#-installation-options)\n  - [Claude Desktop](#option-1-install-for-claude-desktop)\n  - [Cline VSCode Plugin](#option-2-install-for-cline-vscode-plugin)\n- [macOS Permissions Setup](#-macos-permissions-setup)\n- [Safety Features](#-safety-features)\n- [Development Documentation](#-development-documentation)\n- [Environment Variables](#%EF%B8%8F-environment-variables)\n\n## 🛠️ MCP Tools\n\nThe server exposes the following tools to LLMs:\n\n### get_chat_transcript\nRetrieve message history for a specific phone number with optional date filtering.\n\n**Parameters:**\n- `phone_number` (required): Phone number in any format (E.164 format preferred)\n- `start_date` (optional): Start date in ISO format (YYYY-MM-DD)\n- `end_date` (optional): End date in ISO format (YYYY-MM-DD)\n\n**Features:**\n- Automatic phone number validation and formatting\n- Message text and timestamps\n- Attachment information with missing file detection\n- Date range filtering (defaults to last 7 days if no dates specified)\n- Sender identification (is_from_me flag)\n\n## 🚀 Getting Started\n\nClone the repository:\n\n```bash\ngit clone https://github.com/hannesrudolph/imessage-query-fastmcp-mcp-server.git\ncd imessage-query-fastmcp-mcp-server\n```\n\n## 📦 Installation Options\n\nYou can install this MCP server in Claude Desktop, Cline VSCode plugin, or any other MCP client. Choose the option that best suits your needs.\n\n### Option 1: Claude Desktop\n\n1. **Find your Claude Desktop config file:**\n   - **Location**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Create the file if it doesn't exist\n\n2. **Add the server configuration:**\n\n```json\n{\n  \"mcpServers\": {\n    \"imessage-query\": {\n      \"command\": \"/full/path/to/imessage-query-server.py\"\n    }\n  }\n}\n```\n\n3. **Replace the path** with the full path to your cloned repository (e.g., `/Users/username/Projects/imessage-query-fastmcp-mcp-server/imessage-query-server.py`)\n\n4. **Restart Claude Desktop** completely (Cmd+Q, then relaunch)\n\n### Option 2: Cline VSCode Plugin\n\nTo use this server with the [Cline VSCode plugin](http://cline.bot):\n\n1. In VSCode, click the server icon (☰) in the Cline plugin sidebar\n2. Click the \"Edit MCP Settings\" button (✎)\n3. Add the following configuration to the settings file:\n\n```json\n{\n  \"imessage-query\": {\n    \"command\": \"/full/path/to/imessage-query-server.py\"\n  }\n}\n```\n\n4. **Replace the path** with the full path to your cloned repository\n\n### Option 3: Other MCP Clients\n\nFor other MCP clients, use the direct script path as the command:\n\n```\n/full/path/to/imessage-query-server.py\n```\n\nThe script's shebang (`#!/usr/bin/env -S uv run --script`) handles dependency management automatically.\n\n> **Note**: This simplified configuration replaces the previous FastMCP installation method. The script is now self-contained and manages its own dependencies through `uv`.\n\n## 🔐 macOS Permissions Setup\n\nThis server requires **Full Disk Access** permission to read the iMessage database. The server includes intelligent permission detection and will guide you through the setup process.\n\n### Automatic Permission Detection\n\nWhen you first use the server, it will:\n1. **Detect your MCP client** (Claude Desktop, Cursor, VS Code, etc.)\n2. **Check for Full Disk Access** permission\n3. **Automatically open System Preferences** to the correct settings panel\n4. **Provide step-by-step instructions** specific to your application\n\n### Manual Permission Setup\n\nIf automatic detection doesn't work, follow these steps:\n\n1. **Open System Preferences** → **Privacy & Security** → **Full Disk Access**\n2. **Click the lock icon** and enter your password to make changes\n3. **Click the '+' button** to add an application\n4. **Navigate to and select your MCP client:**\n   - **Claude Desktop**: `/Applications/Claude.app`\n   - **Cursor**: `/Applications/Cursor.app`\n   - **VS Code**: `/Applications/Visual Studio Code.app`\n5. **Restart your MCP client** completely (Cmd+Q, then relaunch)\n\n### Common Issues\n\n- **Permission denied errors**: Make sure you've restarted your MCP client after granting permission\n- **\"uv\" instead of app name**: The server will auto-detect your actual MCP client and provide correct instructions\n- **Database not found**: Ensure you've used the Messages app and iMessage is enabled\n\n### Security Note\n\nThis server only requires **read access** to your iMessage database. It cannot modify, delete, or send messages.\n\n## 🔒 Safety Features\n\n- **Read-only access** to the iMessage database (cannot modify, delete, or send messages)\n- **Phone number validation** using Google's phonenumbers library with proper E.164 formatting\n- **Safe attachment handling** with missing file detection and metadata extraction\n- **Date range validation** to prevent invalid queries\n- **Progress output suppression** for clean JSON responses in MCP protocol\n- **Intelligent permission detection** with automatic System Preferences navigation\n- **MCP client identification** for accurate permission guidance\n\n## 📚 Development Documentation\n\nThe repository includes comprehensive documentation for development:\n\n- `dev_docs/imessagedb-documentation.txt`: Complete documentation about the iMessage database structure and the imessagedb library's capabilities\n- `dev_docs/fastmcp-documentation.txt`: FastMCP framework details and MCP tool development\n- `dev_docs/mcp-documentation.txt`: Model Context Protocol specification\n\nThis documentation serves as context when developing features and can be used with LLMs to assist in development.\n\n## ⚙️ Environment Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| `SQLITE_DB_PATH` | Custom path to iMessage database | `~/Library/Messages/chat.db` |\n\nThe server automatically locates the iMessage database in the default macOS location. The environment variable is only needed for custom database locations.\n\n## 🔧 Advanced Usage\n\n### Custom Database Path\n\nIf you need to use a custom database path:\n\n```bash\nexport SQLITE_DB_PATH=\"/path/to/custom/chat.db\"\n```\n\n### Testing the Server\n\nTest the server directly using mcptools (github.com/f/mcptools):\n\n```bash\n# Navigate to the repository directory\ncd /path/to/imessage-query-fastmcp-mcp-server\n\n# List available tools\nmcp tools ./imessage-query-server.py\n\n# Test a tool call\nmcp call get_chat_transcript ./imessage-query-server.py -p '{\"phone_number\": \"+1234567890\"}'\n```\n\nThe script will automatically handle dependency installation via `uv` when first run.\n\n## 🐛 Troubleshooting\n\n### Common Error Messages\n\n**\"❌ Full Disk Access permission required\"**\n- Follow the [macOS Permissions Setup](#-macos-permissions-setup) section\n- Ensure you've restarted your MCP client after granting permission\n\n**\"Messages database not found\"**\n- Make sure you've used the Messages app at least once\n- Verify iMessage is enabled in Messages preferences\n\n**\"Invalid phone number\"**\n- Phone numbers are validated using Google's phonenumbers library\n- Try using E.164 format (e.g., \"+1234567890\")\n- US numbers without country code will be assumed to be US numbers\n\n### Getting Help\n\nIf you encounter issues:\n1. Check the error message for specific guidance\n2. Ensure your MCP client has Full Disk Access permission\n3. Verify the Messages app has been used and iMessage is enabled\n4. Try testing the server directly with mcptools (see Advanced Usage)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "imessage",
        "conversations",
        "communication",
        "message management",
        "imessage conversations",
        "communication tools"
      ],
      "category": "communication"
    },
    "i-am-bee--acp-mcp": {
      "owner": "i-am-bee",
      "name": "acp-mcp",
      "url": "https://github.com/i-am-bee/acp-mcp",
      "imageUrl": "",
      "description": "An MCP server acting as an adapter into the [ACP](https://agentcommunicationprotocol.dev) ecosystem. Seamlessly exposes ACP agents to MCP clients, bridging the communication gap between the two protocols.",
      "stars": 28,
      "forks": 5,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-25T18:54:18Z",
      "readme_content": "<div align=\"left\">\n\n<h1>ACP to MCP Adapter</h1>\n\n**Connect ACP Agents to MCP Applications Seamlessly**\n\n[![Apache 2.0](https://img.shields.io/badge/Apache%202.0-License-EA7826?style=plastic&logo=apache&logoColor=white)](https://github.com/i-am-bee/beeai-framework?tab=Apache-2.0-1-ov-file#readme)\n[![Follow on Bluesky](https://img.shields.io/badge/Follow%20on%20Bluesky-0285FF?style=plastic&logo=bluesky&logoColor=white)](https://bsky.app/profile/beeaiagents.bsky.social)\n[![Join our Discord](https://img.shields.io/badge/Join%20our%20Discord-7289DA?style=plastic&logo=discord&logoColor=white)](https://discord.com/invite/NradeA6ZNF)\n[![LF AI & Data](https://img.shields.io/badge/LF%20AI%20%26%20Data-0072C6?style=plastic&logo=linuxfoundation&logoColor=white)](https://lfaidata.foundation/projects/)\n\n</div>\n\nThe **ACP to MCP Adapter** is a lightweight standalone server that acts as a bridge between two AI ecosystems: **Agent Communication Protocol (ACP)** for agent-to-agent communication and **Model Context Protocol (MCP)** for connecting AI models to external tools. It allows MCP applications (like **Claude Desktop**) to discover and interact with ACP agents as resources.\n\n## Capabilities & Tradeoffs\n\nThis adapter enables interoperability between ACP and MCP with specific benefits and tradeoffs:\n\n### Benefits\n\n- Makes ACP agents discoverable as MCP resources\n- Exposes ACP agent runs as MCP tools\n- Bridges two ecosystems with minimal configuration\n\n### Current Limitations\n\n- ACP agents become MCP tools instead of conversational peers\n- No streaming of incremental updates\n- No shared memory across servers\n- Basic content translation between formats without support for complex data structures\n\nThis adapter is best for situations where you need ACP agents in MCP environments and accept these compromises.\n\n## Requirements\n\n- Python 3.11 or higher\n- Installed Python packages: `acp-sdk`, `mcp`\n- An ACP server running (Tip: Follow the [ACP quickstart](https://github.com/i-am-bee/acp/blob/main/README.md#quickstart) to start one easily)\n- An MCP client application (We use [Claude Desktop](https://claude.ai/download) in the quickstart)\n\n## Quickstart\n\n**1. Run the Adapter**\n\nStart the adapter and connect it to your ACP server:\n\n```sh\nuvx acp-mcp http://localhost:8000\n```\n\n> [!NOTE]\n> Replace `http://localhost:8000` with your ACP server URL if different.\n\n<details> <summary><strong>Prefer Docker?</strong></summary>\n\n```sh\ndocker run -i --rm ghcr.io/i-am-bee/acp-mcp http://host.docker.internal:8000\n```\n\n**Tip:** `host.docker.internal` allows Docker containers to reach services running on the host (adjust if needed for your setup).\n\n</details> \n\n**2. Connect via Claude Desktop**\n\nTo connect via Claude Desktop, follow these steps:\n1. Open the Claude menu on your computer and navigate to Settings (note: this is separate from the in-app Claude account settings).\n2. Navigate to Developer > Edit Config\n3. The config file will be created here:\n  - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n  - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n4. Edit the file with the following:\n\n```json\n{\n  \"mcpServers\": {\n    \"acp-local\": {\n      \"command\": \"uvx\",\n      \"args\": [\"acp-mcp\", \"http://localhost:8000\"]\n    }\n  }\n}\n```\n  \n<details> <summary><strong>Prefer Docker?</strong></summary>\n  \n```json\n{\n  \"mcpServers\": {\n    \"acp-docker\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"ghcr.io/i-am-bee/acp-mcp\",\n        \"http://host.docker.internal:8000\"\n      ]\n    }\n  }\n}\n```\n\n</details>\n\n**3. Restart Claude Desktop and Invoke Your ACP Agent**\n\nAfter restarting, invoke your ACP agent with:\n\n```\nuse \"echo\" agent with the \"Good morning!\" input\n```\n\nAccept the integration and observe the agent running.\n\n\n\n\n\n> [!TIP]\n> ACP agents are also registered as **MCP resources** in Claude Desktop.<br />\n> To attach them manually, click the Resources icon (two plugs connecting) in the sidebar, labeled \"Attach from MCP\", then select an agent like `acp://agents/echo`.\n\n## How It Works\n\n1. The adapter connects to your ACP server.\n2. It automatically discovers all registered ACP agents.\n3. Each ACP agent is registered in MCP as a resource using the URI: `acp://agents/{agent_name}`\n4. The adapter provides a new MCP tool called `run_agent`, letting MCP apps easily invoke ACP agents.\n\n## Supported Transports\n\n- Currently supports Stdio transport\n\n---\n\nDeveloped by contributors to the BeeAI project, this initiative is part of the [Linux Foundation AI & Data program](https://lfaidata.foundation/projects/). Its development follows open, collaborative, and community-driven practices.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "agentcommunicationprotocol",
        "protocols",
        "communication",
        "communication integration",
        "communication platforms",
        "agents mcp"
      ],
      "category": "communication"
    },
    "jaipandya--producthunt-mcp-server": {
      "owner": "jaipandya",
      "name": "producthunt-mcp-server",
      "url": "https://github.com/jaipandya/producthunt-mcp-server",
      "imageUrl": "",
      "description": "MCP server for Product Hunt. Interact with trending posts, comments, collections, users, and more.",
      "stars": 30,
      "forks": 9,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-03T22:32:32Z",
      "readme_content": "# 🚀 Product Hunt MCP Server\n\n[![PyPI version](https://img.shields.io/pypi/v/product-hunt-mcp.svg)](https://pypi.org/project/product-hunt-mcp/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)\n[![Python 3.10+](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://www.python.org/)\n[![Docker Ready](https://img.shields.io/badge/docker-ready-blue)](Dockerfile)\n[![MCP Compatible](https://img.shields.io/badge/MCP-compatible-brightgreen)](https://modelcontextprotocol.io/)\n\n> **A plug-and-play [MCP](https://modelcontextprotocol.io/) server for Product Hunt**\n\n---\n\n## 📦 Quick Install\n\n```bash\npip install product-hunt-mcp\n```\n\n## 🏃‍♂️ Quick Start Example\n\n```bash\n# Run the MCP server (requires PRODUCT_HUNT_TOKEN environment variable)\nexport PRODUCT_HUNT_TOKEN=your_token_here\nproduct-hunt-mcp\n```\n\n---\n\n## ✨ What is this?\n\n**Product Hunt MCP Server** connects Product Hunt's API to any LLM or agent that speaks the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/). Perfect for AI assistants, chatbots, or your own automations!\n\n- 🔍 Get posts, collections, topics, users\n- 🗳️ Get votes, comments, and more\n- 🛠️ Use with Claude Desktop, Cursor, or any MCP client\n\n---\n\n## 🛠️ Features\n\n- Get detailed info on posts, comments, collections, topics, users\n- Search/filter by topic, date, votes, etc.\n- Paginated comments, user upvotes, and more\n- Built with [FastMCP](https://github.com/jlowin/fastmcp) for speed and compatibility\n\n---\n\n## 🧑‍💻 Who is this for?\n\n- **AI/LLM users**: Plug into Claude Desktop, Cursor, or your own agent\n- **Developers**: Build bots, dashboards, or automations with Product Hunt data\n- **Tinkerers**: Explore the MCP ecosystem and build your own tools\n\n---\n\n## 🏁 Setup\n\n### Prerequisites\n\n- Python 3.10+\n- Product Hunt API token ([get one here](https://www.producthunt.com/v2/oauth/applications))\n  - You'll need to create an account on Product Hunt\n  - Navigate to the API Dashboard and create a new application\n  - Use the `Developer Token` for the token\n\n> **Note:** When creating a new application on Product Hunt, you will be asked for a `redirect_uri`. While the MCP server does not use the redirect URI, it is a required field. You can enter any valid URL, such as `https://localhost:8424/callback`.\n\n### Installation\n\n**Preferred: [uv](https://github.com/astral-sh/uv) (fast, modern Python installer)**\n\n```bash\n# Install uv if you don't have it\npip install uv\n```\n\n#### Install from PyPI (recommended)\n```bash\nuv pip install product-hunt-mcp\n# or\npip install product-hunt-mcp\n```\n\n#### Install from GitHub (latest main branch)\n```bash\nuv pip install 'git+https://github.com/jaipandya/producthunt-mcp-server.git'\n# or\npip install 'git+https://github.com/jaipandya/producthunt-mcp-server.git'\n```\n\n#### Install locally from source\n```bash\nuv pip install .\n# or\npip install .\n```\n\n---\n\n## 🚀 Usage with Claude Desktop & Cursor\n\nOnce installed, the `product-hunt-mcp` command will be available. Add it to your Claude Desktop or Cursor configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"product-hunt\": {\n      \"command\": \"product-hunt-mcp\",\n      \"env\": {\n        \"PRODUCT_HUNT_TOKEN\": \"your_token_here\"\n      }\n    }\n  }\n}\n```\n\n- Replace `your_token_here` with your actual Product Hunt API token.\n- The token **must** be set as an environment variable in your Claude Desktop or Cursor config for the server to authenticate.\n- Always restart your client (Claude Desktop/Cursor) after editing the config file.\n\n> **Tip:** On macOS, Claude Desktop may not always find the `product-hunt-mcp` command if it's not in the default PATH. If you encounter issues, you can provide the full path to the executable. After installing, run:\n>\n> ```bash\n> which product-hunt-mcp\n> ```\n>\n> Use the output path in your Claude Desktop config, replacing `\"command\": \"product-hunt-mcp\"` with the full path (e.g., `\"command\": \"/Users/youruser/.local/bin/product-hunt-mcp\"`).\n\n### Finding your configuration file\n\n- **Claude Desktop**: \n  - Windows: `%APPDATA%\\claude-desktop\\config.json`\n  - macOS: `~/Library/Application Support/claude-desktop/config.json`\n  - Linux: `~/.config/claude-desktop/config.json`\n\n- **Cursor**:\n  - Windows: `%APPDATA%\\Cursor\\User\\settings.json`\n  - macOS: `~/Library/Application Support/Cursor/User/settings.json`\n  - Linux: `~/.config/Cursor/User/settings.json`\n\n### Docker\n\nYou can also run the server using Docker:\n\n```bash\n# Build the Docker image\ndocker build -t product-hunt-mcp .\n\n# Run the Docker container (interactive for MCP)\ndocker run -i --rm -e PRODUCT_HUNT_TOKEN=your_token_here product-hunt-mcp\n```\n\nFor Claude Desktop/Cursor integration with Docker, use this configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"product-hunt\": {\n      \"command\": \"docker\",\n      \"args\": [\"run\", \"-i\", \"--rm\", \"-e\", \"PRODUCT_HUNT_TOKEN=your_token_here\", \"product-hunt-mcp\"],\n      \"env\": {}\n    }\n  }\n}\n```\n\n> **Security Note:** Your `PRODUCT_HUNT_TOKEN` is sensitive. Do not share it or commit it to version control.\n\n---\n\n## 🛠️ MCP Tools\n\n| Tool                | Description                                 | Key Parameters |\n|---------------------|---------------------------------------------|----------------|\n| get_post_details    | Get info about a specific post              | `id` or `slug`, `comments_count`, `comments_after` |\n| get_posts           | Get posts with filters                      | `topic`, `order`, `count`, `featured`, `posted_before`, `posted_after` |\n| get_comment         | Get info about a specific comment           | `id` (required) |\n| get_post_comments   | Get comments for a post                     | `post_id` or `slug`, `order`, `count`, `after` |\n| get_collection      | Get info about a collection                 | `id` or `slug` |\n| get_collections     | Get collections with filters                | `featured`, `user_id`, `post_id`, `order`, `count` |\n| get_topic           | Get info about a topic                      | `id` or `slug` |\n| search_topics       | Search topics                               | `query`, `followed_by_user_id`, `order`, `count` |\n| get_user            | Get info about a user                       | `id` or `username`, `posts_type`, `posts_count` |\n| get_viewer          | Get info about the authenticated user       | None |\n| check_server_status | Check server/API status & authentication    | None |\n\n---\n\n## 🏗️ Project Structure\n\n```\nproduct-hunt-mcp/\n├── src/\n│   └── product_hunt_mcp/ # Main package directory\n│       ├── __init__.py\n│       ├── cli.py        # Command-line entry point\n│       ├── api/          # API clients & queries\n│       ├── schemas/      # Data validation schemas\n│       ├── tools/        # MCP tool definitions\n│       └── utils/        # Utility functions\n├── pyproject.toml      # Project metadata, dependencies, build config\n├── README.md\n├── CONTRIBUTING.md\n├── CHANGELOG.md\n├── Dockerfile\n└── ... (config files, etc.)\n```\n\n---\n\n## 🔄 Rate Limiting\n\nThe Product Hunt API has rate limits that this client respects. If you encounter rate limit errors, the client will inform you when the rate limit resets. You can check your current rate limit status using the `get_api_rate_limits` or `check_server_status` tools.\n\n---\n\n## 🐛 Troubleshooting\n\n- **Missing token**: Ensure your `PRODUCT_HUNT_TOKEN` is correctly set as an environment variable.\n- **Connection issues**: Verify your internet connection and that the Product Hunt API is accessible.\n- **Rate limiting**: If you hit rate limits, wait until the reset time or reduce your query frequency.\n- **Claude Desktop/Cursor not finding the server**: Verify the path to your Python executable and restart the client.\n\n---\n\n## 🤝 Contributing\n\n- PRs and issues welcome!\n- Please follow [PEP8](https://peps.python.org/pep-0008/) and use [ruff](https://github.com/charliermarsh/ruff) for linting.\n- See `pyproject.toml` for dev dependencies.\n\n---\n\n## 🌐 Links\n\n- [Model Context Protocol (MCP)](https://modelcontextprotocol.io/)\n- [FastMCP](https://github.com/jlowin/fastmcp)\n- [Product Hunt API Docs](https://www.producthunt.com/v2/docs)\n- [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector)\n- [Awesome MCP Servers](https://github.com/punkpeye/awesome-mcp-servers)\n\n---\n\n## 📝 Notes\n\n- This project is not affiliated with Product Hunt.\n- The Product Hunt API is subject to change.\n\n---\n\n## 📜 License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "producthunt",
        "communication",
        "server",
        "message management",
        "communication platforms",
        "communication integration"
      ],
      "category": "communication"
    },
    "joinly-ai--joinly": {
      "owner": "joinly-ai",
      "name": "joinly",
      "url": "https://github.com/joinly-ai/joinly",
      "imageUrl": "",
      "description": "MCP server to interact with browser-based meeting platforms (Zoom, Teams, Google Meet). Enables AI agents to send bots to online meetings, gather live transcripts, speak text, and send messages in the meeting chat.",
      "stars": 364,
      "forks": 43,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T19:05:30Z",
      "readme_content": "<p align=\"center\">\n  <a href=\"https://github.com/joinly-ai/assets\">\n    <picture>\n      <source\n        media=\"(prefers-color-scheme: dark)\"\n        srcset=\"https://raw.githubusercontent.com/joinly-ai/assets/main/animations/logo-animations/joinly_logo_black_cropped.gif\"\n      >\n      <img\n        alt=\"Animated joinly.ai logo\"\n        src=\"https://raw.githubusercontent.com/joinly-ai/assets/main/animations/logo-animations/joinly_logo_light_cropped.gif\"\n      >\n    </picture>\n  </a>\n</p>\n\n[![GitHub Release](https://img.shields.io/github/v/release/joinly-ai/joinly?sytle=flat&label=Release&labelColor=black&color=%237B2CBF)](https://github.com/joinly-ai/joinly/releases)\n[![GitHub License](https://img.shields.io/github/license/joinly-ai/joinly?style=flat&label=License&labelColor=black&color=%237B2CBF)](LICENSE) \n[![GitHub Repo stars](https://img.shields.io/github/stars/joinly-ai/joinly?style=flat&logo=github&logoColor=white&label=Stars&labelColor=black&color=7B2CBF)](https://github.com/joinly-ai/joinly)\n[![Discord](https://img.shields.io/discord/1377431745632145500?style=flat&logo=discord&logoColor=white&label=Discord&labelColor=black&color=7B2CBF)](https://discord.com/invite/AN5NEBkS4d) \n[![GitHub Discussions](https://img.shields.io/github/discussions/joinly-ai/joinly?style=flat&labelColor=black&label=Discussions&color=%237B2CBF)](https://github.com/joinly-ai/joinly/discussions)\n[![joinly cloud](https://img.shields.io/badge/joinly.ai_cloud-☁️-%237B2CBF?style=flat&labelColor=black)](https://cloud.joinly.ai)\n\n<h1 align=\"center\">Make your meetings accessible to AI Agents 🤖</h1>\n\n**joinly.ai** is a connector middleware designed to enable AI agents to join and actively participate in video calls. Through its MCP server, joinly.ai provides essential [meeting tools](#tools) and [resources](#resources) that can equip any AI agent with the skills to perform tasks and interact with you in real time during your meetings.\n\n> Want to dive right in? Jump to the [Quickstart](#zap-quickstart)!\n> Want to know more? Visit our [website](https://joinly.ai/)!\n\n> [!IMPORTANT]  \n> Don't want the hustle of setting everything up? Try our [cloud](https://cloud.joinly.ai) first! ☁️🚀\n\n\n# :sparkles: Features\n- **Live Interaction**: Lets your agents execute tasks and respond in real-time by voice or chat within your meetings\n- **Conversational flow**: Built-in logic that ensures natural conversations by handling interruptions and multi-speaker interactions\n- **Cross-platform**: Join Google Meet, Zoom, and Microsoft Teams (or any available over the browser)\n- **Bring-your-own-LLM**: Works with all LLM providers (also locally with Ollama)\n- **Choose-your-preferred-TTS/STT**: Modular design supports multiple services - Whisper/Deepgram for STT and Kokoro/ElevenLabs/Deepgram for TTS (and more to come...)\n- **100% open-source, self-hosted and privacy-first** :rocket:\n\n# :video_camera: Demos\n### GitHub\n[![GitHub Demo](https://raw.githubusercontent.com/joinly-ai/assets/main/images/others/github-demo.png)](https://youtu.be/XWolVuxw8I8)\n> In this demo video, joinly answers the question 'What is Joinly?' by accessing the latest news from the web. It then creates an issue in a GitHub demo repository.\n### Notion\n[![Notion Demo](https://raw.githubusercontent.com/joinly-ai/assets/main/images/others/notion-demo.png)](https://www.youtube.com/watch?v=pvYqZi2KeI0)\n> In this demo video, we connect joinly to our notion via MCP and let it edit the content of a page content live in the meeting. \n\nAny ideas what we should build next? [Write us!](https://discord.com/invite/AN5NEBkS4d) :rocket:\n\n# :zap: Quickstart\nRun joinly via Docker with a basic conversational agent client.\n\n> [!IMPORTANT]\n> **Prerequisites**: [Docker installation](https://docs.docker.com/engine/install/)\n\nCreate a new folder `joinly` or clone this repository (not mandatory for the following steps). In this directory, create a new `.env` file with a valid API key for the LLM provider you want to use, e.g. OpenAI:\n\n> [!TIP]\n> You can find the OpenAI API key [here](https://platform.openai.com/api-keys)\n\n```Dotenv\n# .env\n# for OpenAI LLM\n# change key and model to your desired one\nJOINLY_LLM_MODEL=gpt-4o\nJOINLY_LLM_PROVIDER=openai\nOPENAI_API_KEY=your-openai-api-key\n```\n\n> [!NOTE]\n> See [.env.example](.env.example) for complete configuration options including Anthropic (Claude) and Ollama setups. Replace the placeholder values with your actual API keys and adjust the model name as needed. Delete the placeholder values of the providers you don't use.\n\n\nPull the Docker image (~2.3GB since it packages browser and models):\n```bash\ndocker pull ghcr.io/joinly-ai/joinly:latest\n```\n\nLaunch your meeting in [Zoom](https://www.zoom.com), [Google Meet](https://meet.google.com) or Teams and let joinly join the meeting using the meeting link as `<MeetingURL>`. Then, run the following command from the folder where you created the `.env` file:\n```bash  \ndocker run --env-file .env ghcr.io/joinly-ai/joinly:latest --client <MeetingURL>\n```\n> :red_circle: Having trouble getting started? Let's figure it out together on our [discord](https://discord.com/invite/AN5NEBkS4d)! \n\n# :technologist: Run an external client\nIn Quickstart, we ran the Docker Container directly as a client using `--client`. But we can also run it as a server and connect to it from outside the container, which allows us to connect other MCP servers. Here, we run an external client using the [joinly-client package](https://pypi.org/project/joinly-client/) and connect it to the joinly MCP server.\n\n> [!IMPORTANT]\n> **Prerequisites**: do the [Quickstart](#zap-quickstart) (except the last command), [install uv](https://github.com/astral-sh/uv), and open two terminals\n\nStart the joinly server in the first terminal (note, we are not using `--client` here and forward port `8000`):\n```bash  \ndocker run -p 8000:8000 ghcr.io/joinly-ai/joinly:latest\n```\n\nWhile the server is running, start the example client implementation in the second terminal window to connect to it and join a meeting:\n```bash  \nuvx joinly-client --env-file .env <MeetingUrl>\n```\n\n## Add MCP servers to the client\nAdd the tools of any MCP server to the agent by providing a JSON configuration. The configuration file can contain multiple entries under `\"mcpServers\"` which will all be available as tools in the meeting (see [fastmcp client docs](https://gofastmcp.com/clients/client) for config syntax):\n\n```json\n{\n    \"mcpServers\": {\n        \"localServer\": {\n            \"command\": \"npx\",\n            \"args\": [\"-y\", \"package@0.1.0\"]\n        },\n        \"remoteServer\": {\n            \"url\": \"http://mcp.example.com\",\n            \"auth\": \"oauth\"\n        }\n    }\n}\n```\n\nAdd for example a [Tavily config](examples/config_tavily.json) for web searching, then run the client using the config file, here named `config.json`:\n\n```bash\nuvx joinly-client --env-file .env --mcp-config config.json <MeetingUrl>\n```\n\n# :wrench: Configurations\n\nConfigurations can be given via env variables and/or command line args. Here is a list of common configuration options, which can be used when starting the docker container:\n```bash\ndocker run --env-file .env -p 8000:8000 ghcr.io/joinly-ai/joinly:latest <MyOptionArgs>\n```\n\nAlternatively, you can pass `--name`, `--lang`, and [provider settings](#providers) as command line arguments using `joinly-client`, which will override settings of the server:\n```bash\nuvx joinly-client <MyOptionArgs> <MeetingUrl>\n```\n\n## Basic Settings\n\nIn general, the docker image provides an MCP server which is started by default. But to quickly get started, we also include a client implementation that can be used via `--client`. Note, in this case no server is started and no other client can connect to it.\n\n```bash\n# Start directly as client; default is as server, to which an external client can connect\n--client <MeetingUrl>\n\n# Change participant name (default: joinly)\n--name \"AI Assistant\"\n\n# Change language of TTS/STT (default: en)\n# Note, availability depends on the TTS/STT provider\n--lang de\n\n# Change host & port of the joinly MCP server\n--host 0.0.0.0 --port 8000\n```\n\n## Providers\n\n### Text-to-Speech\n```bash\n# Kokoro (local) TTS (default)\n--tts kokoro\n--tts-arg voice=<VoiceName>  # optionally, set different voice\n\n# ElevenLabs TTS, include ELEVENLABS_API_KEY in .env\n--tts elevenlabs\n--tts-arg voice_id=<VoiceID>  # optionally, set different voice\n\n# Deepgram TTS, include DEEPGRAM_API_KEY in .env\n--tts deepgram\n--tts-arg model_name=<ModelName>  # optionally, set different model (voice)\n```\n\n### Transcription\n```bash\n# Whisper (local) STT (default)\n--stt whisper\n--stt-arg model_name=<ModelName>  # optionally, set different model (default: base), for GPU support see below\n\n# Deepgram STT, include DEEPGRAM_API_KEY in .env\n--stt deepgram\n--stt-arg model_name=<ModelName>  # optionally, set different model\n```\n\n## Debugging\n```bash\n# Start browser with a VNC server for debugging;\n# forward the port and connect to it using a VNC client\n--vnc-server --vnc-server-port 5900\n\n# Logging\n-v  # or -vv, -vvv\n\n# Help\n--help\n```\n\n## GPU Support\n\nWe provide a Docker image with CUDA GPU support for running the transcription and TTS models on a GPU. To use it, you need to have the [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html) installed and `CUDA >= 12.6`. Then pull the CUDA-enabled image:\n```bash\ndocker pull ghcr.io/joinly-ai/joinly:latest-cuda\n```\n\nRun as client or server with the same commands as above, but use the `joinly:{version}-cuda` image and set `--gpus all`:\n```bash\n# Run as server\ndocker run --gpus all --env-file .env -p 8000:8000 ghcr.io/joinly-ai/joinly:latest-cuda -v\n# Run as client\ndocker run --gpus all --env-file .env ghcr.io/joinly-ai/joinly:latest-cuda -v --client <MeetingURL>\n```\n\nBy default, the `joinly` image uses the Whisper model `base` for transcription, since it still runs reasonably fast on CPU. For `cuda`, it automatically defaults to `distil-large-v3` for significantly better transcription quality. You can change the model by setting `--stt-arg model_name=<model_name>` (e.g., `--stt-arg model_name=large-v3`). However, only the respective default models are packaged in the docker image, so it will start to download the model weights on container start.\n\n# :test_tube: Create your own agent\n\nYou can also write your own agent and connect it to our joinly MCP server. See the [code examples](https://github.com/joinly-ai/joinly/client/README.md#code-usage) for the joinly-client package or the [client_example.py](examples/client_example.py) if you want a starting point that doesn't depend on our framework.\n\nThe joinly MCP server provides following tools and resources:\n\n### Tools\n\n- **`join_meeting`** - Join meeting with URL, participant name, and optional passcode\n- **`leave_meeting`** - Leave the current meeting\n- **`speak_text`** - Speak text using TTS (requires `text` parameter)\n- **`send_chat_message`** - Send chat message (requires `message` parameter)\n- **`mute_yourself`** - Mute microphone\n- **`unmute_yourself`** - Unmute microphone\n- **`get_chat_history`** - Get current meeting chat history in JSON format\n- **`get_participants`** - Get current meeting participants in JSON format\n- **`get_transcript`** - Get current meeting transcript in JSON format, optionally filtered by minutes\n- **`get_video_snapshot`** - Get an image from the current meeting, e.g., view a current screenshare\n\n### Resources\n\n- **`transcript://live`** - Live meeting transcript in JSON format, including timestamps and speaker information. Subscribable for real-time updates when new utterances are added.\n\n# :building_construction: Developing joinly.ai\n\nFor development we recommend using the development container, which installs all necessary dependencies. To get started, install the DevContainer Extension for Visual Studio Code, open the repository and choose **Reopen in Container**.\n\n<img src=\"https://raw.githubusercontent.com/joinly-ai/assets/main/images/others/reopen_in_container.png\" width=\"500\" alt=\"Reopen in Devcontainer\">\n\nThe installation can take some time, since it downloads all packages as well as models for Whisper/Kokoro and the Chromium browser. At the end, it automatically invokes the [download_assets.py](scripts/download_assets.py) script. If you see errors like `Missing kokoro-v1.0.onnx`, run this script manually using:\n```bash\nuv run scripts/download_assets.py\n```\n\nWe'd love to see what you are using it for or building with it. Showcase your work on our [discord](https://discord.com/invite/AN5NEBkS4d)\n# :pencil2: Roadmap\n\n**Meeting**\n- [x] Meeting chat access\n- [ ] Camera in video call with status updates\n- [ ] Enable screen share during video conferences\n- [ ] Participant metadata and joining/leaving\n- [ ] Improve browser agent capabilities\n\n**Conversation**\n- [x] Speaker attribute for transcription\n- [ ] Improve client memory: reduce token usage, allow persistence across meetings\nevents\n- [ ] Improve End-of-Utterance/turn-taking detection\n- [ ] Human approval mechanism from inside the meeting\n\n**Integrations**\n- [ ] Showcase how to add agents using the A2A protocol\n- [ ] Add more provider integrations (STT, TTS)\n- [ ] Integrate meeting platform SDKs\n- [ ] Add alternative open-source meeting provider\n- [ ] Add support for Speech2Speech models\n  \n# :busts_in_silhouette: Contributing\nContributions are always welcome! Feel free to open issues for bugs or submit a feature request. We'll do our best to review all contributions promptly and help merge your changes.\n\nPlease check our [Roadmap](#pencil2-roadmap) and don't hesitate to reach out to us!\n\n# :memo: License\nThis project is licensed under the MIT License ‒ see the [LICENSE](LICENSE) file for details.\n\n# :speech_balloon: Getting help\nIf you have questions or feedback, or if you would like to chat with the maintainers or other community members, please use the following links:\n-  [Join our Discord](https://discord.com/invite/AN5NEBkS4d)\n-  [Explore our GitHub Discussions](https://github.com/joinly-ai/joinly/discussions)\n\n<div align=\"center\">\nMade with ❤️ in Osnabrück\n </div>\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "chat",
        "communication",
        "ai",
        "communication integration",
        "communication platforms",
        "communication tools"
      ],
      "category": "communication"
    },
    "keturiosakys--bluesky-context-server": {
      "owner": "keturiosakys",
      "name": "bluesky-context-server",
      "url": "https://github.com/keturiosakys/bluesky-context-server",
      "imageUrl": "",
      "description": "Bluesky instance integration for querying and interaction",
      "stars": 27,
      "forks": 7,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-03T01:09:00Z",
      "readme_content": "# Bluesky Context Server\n[![smithery badge](https://smithery.ai/badge/bluesky-context-server)](https://smithery.ai/server/bluesky-context-server)\n\nA Model Context Protocol (MCP) server that enables MCP clients like Claude Desktop to interact with Bluesky. Query your profile, search posts, get your timeline, and more directly from your AI assistant.\n\n## Prerequisites\n\n- **Runtime**: Either [Bun](https://bun.sh/) or [Node.js](https://nodejs.org/) v22.6.0+\n- A Bluesky account\n\n## Setup\n\n### 1. Get Your Bluesky Credentials\n\nYou'll need two pieces of information from your Bluesky account:\n\n#### BLUESKY_IDENTIFIER\nThis is your Bluesky handle (username). It can be in either format:\n- `username.bsky.social` (e.g., `alice.bsky.social`)\n- `@username.bsky.social` (e.g., `@alice.bsky.social`)\n\n#### BLUESKY_APP_KEY\nThis is an App Password, which is different from your regular Bluesky password. To create one:\n\n1. Go to [Bluesky Settings](https://bsky.app/settings)\n2. Navigate to \"Privacy and Security\" → \"App Passwords\"\n3. Click \"Add App Password\"\n4. Give it a name (e.g., \"MCP Server\")\n5. Copy the generated password (it looks like `xxxx-xxxx-xxxx-xxxx`)\n\n⚠️ **Important**: Use the App Password, not your regular account password!\n\n### 2. Installation\n\n#### Option A: Installing via Smithery (Recommended)\n\nTo install Bluesky Context Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@laulauland/bluesky-context-server):\n\n```bash\nnpx -y @smithery/cli install @laulauland/bluesky-context-server --client claude\n```\n\nThen add your credentials to the generated configuration.\n\n#### Option B: Manual Installation\n\n1. Clone or download this repository\n2. Configure your Claude Desktop app to use the MCP server:\n\n**Using Bun:**\n```json\n// ~/Library/Application Support/Claude/config.json (macOS)\n// %APPDATA%/Claude/config.json (Windows)\n{\n\t\"mcpServers\": {\n\t\t\"bluesky\": {\n\t\t\t\"command\": \"/Users/your-username/.bun/bin/bun\",\n\t\t\t\"args\": [\n\t\t\t\t\"/path/to/bluesky-context-server/packages/server/bin/index.ts\"\n\t\t\t],\n\t\t\t\"env\": {\n\t\t\t\t\"BLUESKY_APP_KEY\": \"your-app-password-here\",\n\t\t\t\t\"BLUESKY_IDENTIFIER\": \"your-handle.bsky.social\"\n\t\t\t}\n\t\t}\n\t}\n}\n```\n\n**Using Node.js:**\n```json\n// ~/Library/Application Support/Claude/config.json (macOS)\n// %APPDATA%/Claude/config.json (Windows)\n{\n\t\"mcpServers\": {\n\t\t\"bluesky\": {\n\t\t\t\"command\": \"node\",\n\t\t\t\"args\": [\n\t\t\t\t\"--experimental-strip-types\",\n\t\t\t\t\"/path/to/bluesky-context-server/packages/server/bin/index.ts\"\n\t\t\t],\n\t\t\t\"env\": {\n\t\t\t\t\"BLUESKY_APP_KEY\": \"your-app-password-here\",\n\t\t\t\t\"BLUESKY_IDENTIFIER\": \"your-handle.bsky.social\"\n\t\t\t}\n\t\t}\n\t}\n}\n```\n\n3. Restart Claude Desktop\n\n### 3. Testing the Connection\n\nAfter setup, you can test the connection by asking Claude something like:\n- \"Can you get my Bluesky profile?\"\n- \"Show me my recent posts on Bluesky\"\n- \"Search for posts about AI on Bluesky\"\n\n## Available MCP Tools\n\nThis server provides the following tools that Claude can use:\n\n### Profile & Account Tools\n\n#### `bluesky_get_profile`\nGet your Bluesky profile information including display name, bio, follower count, etc.\n- **Parameters**: None\n- **Returns**: Complete profile data\n\n#### `bluesky_get_follows`\nGet a list of accounts you follow.\n- **Parameters**: \n  - `limit` (optional): Max items to return (default 50, max 100)\n  - `cursor` (optional): Pagination cursor for next page\n- **Returns**: List of followed accounts with profile info\n\n#### `bluesky_get_followers`\nGet a list of accounts following you.\n- **Parameters**: \n  - `limit` (optional): Max items to return (default 50, max 100)\n  - `cursor` (optional): Pagination cursor for next page\n- **Returns**: List of followers with profile info\n\n### Post & Feed Tools\n\n#### `bluesky_get_posts`\nGet your recent posts.\n- **Parameters**: \n  - `limit` (optional): Max items to return (default 50, max 100)\n  - `cursor` (optional): Pagination cursor for next page\n- **Returns**: Your recent posts with engagement data\n\n#### `bluesky_get_personal_feed`\nGet your personalized Bluesky timeline/feed.\n- **Parameters**: \n  - `limit` (optional): Max items to return (default 50, max 100)\n  - `cursor` (optional): Pagination cursor for next page\n- **Returns**: Posts from your personalized feed\n\n#### `bluesky_get_liked_posts`\nGet posts you've liked.\n- **Parameters**: \n  - `limit` (optional): Max items to return (default 50, max 100)\n  - `cursor` (optional): Pagination cursor for next page\n- **Returns**: Posts you've liked\n\n### Search Tools\n\n#### `bluesky_search_posts`\nSearch for posts across Bluesky.\n- **Parameters**: \n  - `query` (required): Search query string\n  - `limit` (optional): Max items to return (default 50, max 100)\n  - `cursor` (optional): Pagination cursor for next page\n- **Returns**: Posts matching your search query\n\n#### `bluesky_search_profiles`\nSearch for Bluesky user profiles.\n- **Parameters**: \n  - `query` (required): Search query string\n  - `limit` (optional): Max items to return (default 50, max 100)\n  - `cursor` (optional): Pagination cursor for next page\n- **Returns**: User profiles matching your search query\n\n## Example Usage\n\nOnce configured, you can ask Claude things like:\n\n- \"What's in my Bluesky feed today?\"\n- \"Search for posts about TypeScript on Bluesky\"\n- \"Who are my most recent followers?\"\n- \"Show me posts I've liked recently\"\n- \"Find Bluesky users interested in AI\"\n\n## Troubleshooting\n\n### Common Issues\n\n1. **\"Authentication failed\"**: Double-check your `BLUESKY_APP_KEY` and `BLUESKY_IDENTIFIER`\n2. **\"Server not responding\"**: Ensure Bun is installed and the path to the server is correct\n3. **\"Permission denied\"**: Make sure the server file has execute permissions\n\n### Getting Help\n\nIf you encounter issues:\n1. Check that your Bluesky credentials are correct\n2. Verify Bun is installed: `bun --version`\n3. Test the server manually: `cd packages/server && bun start`\n4. Check Claude Desktop's logs for error messages\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "communication",
        "interact",
        "ai",
        "message management",
        "interact team",
        "communication platforms"
      ],
      "category": "communication"
    },
    "khan2a--telephony-mcp-server": {
      "owner": "khan2a",
      "name": "telephony-mcp-server",
      "url": "https://github.com/khan2a/telephony-mcp-server",
      "imageUrl": "",
      "description": "MCP Telephony server for automating voice calls with Speech-to-Text and Speech Recognition to summarize call conversations. Send and receive SMS, detect voicemail, and integrate with Vonage APIs for advanced telephony workflows.",
      "stars": 7,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-16T14:23:54Z",
      "readme_content": "![Black](https://github.com/khan2a/telephony-mcp-server/actions/workflows/01-black.yml/badge.svg)\n![Ruff](https://github.com/khan2a/telephony-mcp-server/actions/workflows/02-ruff.yml/badge.svg)\n\n 📖 **Blog Post**: Learn more about this project in the detailed blog post: [Telephony MCP Server for Agentic AI and Language Models](https://developer.vonage.com/en/blog/telephony-mcp-server-for-agentic-ai-and-language-models)\n\n# Telephony MCP Server\n\n## Demo Using Claude Desktop\n### Agentic Telephony Conversation with Speech Recognition\n\n\n### <span style=\"color: yellow;\">Use SMS during mid-conversation</span>\n\n\n### <span style=\"color: #b5651d;\">SMS Enquiry (Send and Receive)</span>\n\n\n## <span style=\"color: green;\">Demo Using GitHub Copilot</span>\n\n\n## Introduction\n\nThis directory contains MCP (Model Context Protocol) Server tools for telephony operations, such as making voice calls and sending SMS messages using the Vonage API. These tools are designed to be integrated with Large Language Model (LLM) applications, enabling LLMs to perform real-world actions beyond simple text generation.\n\n## LLMs and Tool Integration\n\nLLMs (Large Language Models) are advanced token generators—they can generate text, images, or even video based on input prompts. However, their core capability is limited to generating content; they cannot access external data or perform actions in the real world on their own.\n\nTo extend their functionality, LLMs can be connected to external tools. For example, when a user asks, \"What's the weather today?\" the LLM can invoke a backend API tool like `get_weather(city)` via a system prompt, parse the response, and return the result to the user. This tool-calling mechanism transforms a basic LLM into a powerful LLM Application.\n\n## Tool Calling with MCP and LangChain\n\n- **LangChain** is a popular framework for developing applications powered by LLMs. It provides a collection of pre-built tools (called a Toolkit) that LLMs can use to interact with external systems.\n- **MCP** (Model Context Protocol) follows the same concept: it offers a collection of pre-built tools and a framework for writing new tools and handling function calling.\n- Both frameworks allow LLMs to invoke tools, parse their outputs, and integrate the results into their responses.\n\n## How This Works\n\n1. **Tool Definition**: In this project, tools like `voice_call` and `send_sms` are defined using the MCP framework. Each tool is a function that can be called by an LLM application.\n2. **LLM Application**: When integrated with an LLM (such as OpenAI's GPT, Anthropic's Claude, etc.), the LLM can decide to call these tools based on user prompts.\n3. **Execution Flow**:\n    - The LLM receives a prompt (e.g., \"Call Alice and say hello\").\n    - The LLM determines that a tool invocation is needed and calls the appropriate MCP tool (e.g., `voice_call`).\n    - The tool executes (e.g., initiates a phone call via Vonage) and returns the result.\n    - The LLM parses the response and presents it to the user.\n\n## Running the MCP Tools\n\n### Prerequisites\n\n- Python 3.13+\n- MCP CLI (`mcp[cli]`), FastAPI, httpx, pyjwt, python-dotenv, uvicorn, pydantic (see `pyproject.toml` for details)\n- Vonage API credentials (API key, secret, application ID, private key)\n- Public URL for callback server (for production use)\n\n### Setup\n\n1. **Install dependencies**:\n    ```bash\n    pip install -r requirements.txt\n    ```\n    Or, if using Poetry:\n    ```bash\n    poetry install\n    ```\n\n2. **Configure environment variables**:\n    - Create a `.env` file with your Vonage credentials:\n      ```\n      VONAGE_API_KEY=your_api_key\n      VONAGE_API_SECRET=your_api_secret\n      VONAGE_APPLICATION_ID=your_app_id\n      VONAGE_PRIVATE_KEY_PATH=path/to/private.key\n      VONAGE_LVN=your_virtual_number\n      VONAGE_API_URL=https://api.nexmo.com/v1/calls\n      VONAGE_SMS_URL=https://rest.nexmo.com/sms/json\n      CALLBACK_SERVER_URL=https://your-public-url  # URL for Vonage event callbacks\n      ```\n      \n      For the `CALLBACK_SERVER_URL`:\n      - In development: You can use `http://localhost:8080` (default if not specified)\n      - In production: Use a public URL (such as an ngrok URL or your deployed server)\n\n3. **Run the MCP server**:\n    ```bash\n    python telephony_server.py\n    ```\n    The server will start and expose the defined tools for LLM applications.\n\n### Running with Docker\n\nYou can also run the telephony MCP server using Docker:\n\n1. **Build and start the Docker container**:\n    ```bash\n    docker compose up --build\n    ```\n    Or to run in the background:\n    ```bash\n    docker compose up --build -d\n    ```\n\n2. **Stop the Docker container**:\n    ```bash\n    docker compose down\n    ```\n\n3. **View logs from the Docker container**:\n    ```bash\n    docker compose logs -f\n    ```\n\n### Using with LLM Applications\n\n- **Direct Integration**: Connect your LLM application (e.g., using LangChain via Adapter or a custom MCP client) to the running MCP server. The LLM can now invoke telephony tools as needed.\n- **Example**: When the LLM receives a prompt like \"Dial this number +123 and read latest news from today\", it will call the `voice_call` tool, passing the required parameters.\n- **Example**: When the LLM receives a prompt like \"Call this number using a British accent\", it will call the `voice_call` tool with specific language and style parameters.\n- **Example**: When the LLM receives a prompt like \"Text the news instead\", it will call the `send_sms` tool, passing the required parameters.\n\n### Using with Claude Desktop or other MCP clients\n\nTo configure an MCP client (like Claude Desktop) to use your telephony MCP server:\n\n1. **Update your MCP client configuration file** (e.g., `claude_desktop_config.json`):\n    ```json\n    {\n      \"mcpServers\": {\n        \"telephony\": {\n          \"command\": \"docker\",\n          \"args\": [\"run\", \"-i\", \"--rm\", \"--init\", \"-e\", \"DOCKER_CONTAINER=true\", \"telephony-mcp-server\"]\n        }\n      }\n    }\n    ```\n\n2. **Build the Docker image** (if not using docker compose):\n    ```bash\n    docker build -t telephony-mcp-server .\n    ```\n\n3. Restart your MCP client to apply the changes.\n- \n## Key Concepts\n\n- **LLMs are content generators**: They generate text, images, or video, but need external tools for actions like web search, telephony, or database access.\n- **Tool calling**: LLMs can invoke backend APIs (tools) to fetch data or perform actions, then parse and present the results.\n- **Frameworks**: Both LangChain and MCP provide a structure for defining, registering, and invoking tools from LLMs.\n- **MCP**: Helps you write new tools and manage function calling, making it easy to extend LLM applications with custom capabilities.\n\n## Callback Server for Vonage Events\n\nThe Telephony MCP Server also includes a Vonage Callback Server that listens on port 8080. This server is used to receive event notifications from Vonage Voice API, which are sent when voice calls are initiated, completed, or encounter errors.\n\n### Features\n- Receives and stores Vonage event callbacks\n- Provides endpoints to view and manage stored events\n- Runs as a separate service within the same application\n\n### Endpoints\n- `GET /` - Health check endpoint\n- `POST /event` - Main endpoint for receiving Vonage callbacks\n- `GET /events` - List all stored events (with pagination)\n- `GET /events/{event_id}` - Get a specific event by ID\n- `DELETE /events` - Clear all stored events\n\n### Configuration\nTo use the callback server with Vonage Voice API, you need to set the `CALLBACK_SERVER_URL` environment variable to your server's public URL. This URL will be used as the `event_url` parameter in Vonage API calls.\n\n```bash\nexport CALLBACK_SERVER_URL=\"https://your-public-url\"\n```\n\nFor local development, you can use a service like ngrok to expose your local server to the internet:\n\n```bash\nngrok http 8080\n```\n\nThen set the `CALLBACK_SERVER_URL` to the ngrok URL.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "vonage",
        "telephony",
        "voicemail",
        "mcp telephony",
        "telephony mcp",
        "advanced telephony"
      ],
      "category": "communication"
    },
    "korotovsky--slack-mcp-server": {
      "owner": "korotovsky",
      "name": "slack-mcp-server",
      "url": "https://github.com/korotovsky/slack-mcp-server",
      "imageUrl": "",
      "description": "The most powerful MCP server for Slack Workspaces.",
      "stars": 752,
      "forks": 107,
      "license": "MIT License",
      "language": "Go",
      "updated_at": "2025-10-04T07:25:59Z",
      "readme_content": "# Slack MCP Server\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/korotovsky/slack-mcp-server)](https://archestra.ai/mcp-catalog/korotovsky__slack-mcp-server)\n\nModel Context Protocol (MCP) server for Slack Workspaces. The most powerful MCP Slack server — supports Stdio, SSE and HTTP transports, proxy settings, DMs, Group DMs, Smart History fetch (by date or count), may work via OAuth or in complete stealth mode with no permissions and scopes in Workspace 😏.\n\n> [!IMPORTANT]  \n> We need your support! Each month, over 30,000 engineers visit this repository, and more than 9,000 are already using it.\n> \n> If you appreciate the work our [contributors](https://github.com/korotovsky/slack-mcp-server/graphs/contributors) have put into this project, please consider giving the repository a star.\n\nThis feature-rich Slack MCP Server has:\n- **Stealth and OAuth Modes**: Run the server without requiring additional permissions or bot installations (stealth mode), or use secure OAuth tokens for access without needing to refresh or extract tokens from the browser (OAuth mode).\n- **Enterprise Workspaces Support**: Possibility to integrate with Enterprise Slack setups.\n- **Channel and Thread Support with `#Name` `@Lookup`**: Fetch messages from channels and threads, including activity messages, and retrieve channels using their names (e.g., #general) as well as their IDs.\n- **Smart History**: Fetch messages with pagination by date (d1, 7d, 1m) or message count.\n- **Search Messages**: Search messages in channels, threads, and DMs using various filters like date, user, and content.\n- **Safe Message Posting**: The `conversations_add_message` tool is disabled by default for safety. Enable it via an environment variable, with optional channel restrictions.\n- **DM and Group DM support**: Retrieve direct messages and group direct messages.\n- **Embedded user information**: Embed user information in messages, for better context.\n- **Cache support**: Cache users and channels for faster access.\n- **Stdio/SSE/HTTP Transports & Proxy Support**: Use the server with any MCP client that supports Stdio, SSE or HTTP transports, and configure it to route outgoing requests through a proxy if needed.\n\n### Analytics Demo\n\n\n\n### Add Message Demo\n\n\n\n## Tools\n\n### 1. conversations_history:\nGet messages from the channel (or DM) by channel_id, the last row/column in the response is used as 'cursor' parameter for pagination if not empty\n- **Parameters:**\n  - `channel_id` (string, required):     - `channel_id` (string): ID of the channel in format Cxxxxxxxxxx or its name starting with `#...` or `@...` aka `#general` or `@username_dm`.\n  - `include_activity_messages` (boolean, default: false): If true, the response will include activity messages such as `channel_join` or `channel_leave`. Default is boolean false.\n  - `cursor` (string, optional): Cursor for pagination. Use the value of the last row and column in the response as next_cursor field returned from the previous request.\n  - `limit` (string, default: \"1d\"): Limit of messages to fetch in format of maximum ranges of time (e.g. 1d - 1 day, 1w - 1 week, 30d - 30 days, 90d - 90 days which is a default limit for free tier history) or number of messages (e.g. 50). Must be empty when 'cursor' is provided.\n\n### 2. conversations_replies:\nGet a thread of messages posted to a conversation by channelID and `thread_ts`, the last row/column in the response is used as `cursor` parameter for pagination if not empty.\n- **Parameters:**\n  - `channel_id` (string, required): ID of the channel in format `Cxxxxxxxxxx` or its name starting with `#...` or `@...` aka `#general` or `@username_dm`.\n  - `thread_ts` (string, required): Unique identifier of either a thread’s parent message or a message in the thread. ts must be the timestamp in format `1234567890.123456` of an existing message with 0 or more replies.\n  - `include_activity_messages` (boolean, default: false): If true, the response will include activity messages such as 'channel_join' or 'channel_leave'. Default is boolean false.\n  - `cursor` (string, optional): Cursor for pagination. Use the value of the last row and column in the response as next_cursor field returned from the previous request.\n  - `limit` (string, default: \"1d\"): Limit of messages to fetch in format of maximum ranges of time (e.g. 1d - 1 day, 1w - 1 week, 30d - 30 days, 90d - 90 days which is a default limit for free tier history) or number of messages (e.g. 50). Must be empty when 'cursor' is provided.\n\n### 3. conversations_add_message\nAdd a message to a public channel, private channel, or direct message (DM, or IM) conversation by channel_id and thread_ts.\n\n> **Note:** Posting messages is disabled by default for safety. To enable, set the `SLACK_MCP_ADD_MESSAGE_TOOL` environment variable. If set to a comma-separated list of channel IDs, posting is enabled only for those specific channels. See the Environment Variables section below for details.\n\n- **Parameters:**\n  - `channel_id` (string, required): ID of the channel in format `Cxxxxxxxxxx` or its name starting with `#...` or `@...` aka `#general` or `@username_dm`.\n  - `thread_ts` (string, optional): Unique identifier of either a thread’s parent message or a message in the thread_ts must be the timestamp in format `1234567890.123456` of an existing message with 0 or more replies. Optional, if not provided the message will be added to the channel itself, otherwise it will be added to the thread.\n  - `payload` (string, required): Message payload in specified content_type format. Example: 'Hello, world!' for text/plain or '# Hello, world!' for text/markdown.\n  - `content_type` (string, default: \"text/markdown\"): Content type of the message. Default is 'text/markdown'. Allowed values: 'text/markdown', 'text/plain'.\n\n### 4. conversations_search_messages\nSearch messages in a public channel, private channel, or direct message (DM, or IM) conversation using filters. All filters are optional, if not provided then search_query is required.\n- **Parameters:**\n  - `search_query` (string, optional): Search query to filter messages. Example: 'marketing report' or full URL of Slack message e.g. 'https://slack.com/archives/C1234567890/p1234567890123456', then the tool will return a single message matching given URL, herewith all other parameters will be ignored.\n  - `filter_in_channel` (string, optional): Filter messages in a specific channel by its ID or name. Example: `C1234567890` or `#general`. If not provided, all channels will be searched.\n  - `filter_in_im_or_mpim` (string, optional): Filter messages in a direct message (DM) or multi-person direct message (MPIM) conversation by its ID or name. Example: `D1234567890` or `@username_dm`. If not provided, all DMs and MPIMs will be searched.\n  - `filter_users_with` (string, optional): Filter messages with a specific user by their ID or display name in threads and DMs. Example: `U1234567890` or `@username`. If not provided, all threads and DMs will be searched.\n  - `filter_users_from` (string, optional): Filter messages from a specific user by their ID or display name. Example: `U1234567890` or `@username`. If not provided, all users will be searched.\n  - `filter_date_before` (string, optional): Filter messages sent before a specific date in format `YYYY-MM-DD`. Example: `2023-10-01`, `July`, `Yesterday` or `Today`. If not provided, all dates will be searched.\n  - `filter_date_after` (string, optional): Filter messages sent after a specific date in format `YYYY-MM-DD`. Example: `2023-10-01`, `July`, `Yesterday` or `Today`. If not provided, all dates will be searched.\n  - `filter_date_on` (string, optional): Filter messages sent on a specific date in format `YYYY-MM-DD`. Example: `2023-10-01`, `July`, `Yesterday` or `Today`. If not provided, all dates will be searched.\n  - `filter_date_during` (string, optional): Filter messages sent during a specific period in format `YYYY-MM-DD`. Example: `July`, `Yesterday` or `Today`. If not provided, all dates will be searched.\n  - `filter_threads_only` (boolean, default: false): If true, the response will include only messages from threads. Default is boolean false.\n  - `cursor` (string, default: \"\"): Cursor for pagination. Use the value of the last row and column in the response as next_cursor field returned from the previous request.\n  - `limit` (number, default: 20): The maximum number of items to return. Must be an integer between 1 and 100.\n\n### 5. channels_list:\nGet list of channels\n- **Parameters:**\n  - `channel_types` (string, required): Comma-separated channel types. Allowed values: `mpim`, `im`, `public_channel`, `private_channel`. Example: `public_channel,private_channel,im`\n  - `sort` (string, optional): Type of sorting. Allowed values: `popularity` - sort by number of members/participants in each channel.\n  - `limit` (number, default: 100): The maximum number of items to return. Must be an integer between 1 and 1000 (maximum 999).\n  - `cursor` (string, optional): Cursor for pagination. Use the value of the last row and column in the response as next_cursor field returned from the previous request.\n\n## Resources\n\nThe Slack MCP Server exposes two special directory resources for easy access to workspace metadata:\n\n### 1. `slack://<workspace>/channels` — Directory of Channels\n\nFetches a CSV directory of all channels in the workspace, including public channels, private channels, DMs, and group DMs.\n\n- **URI:** `slack://<workspace>/channels`\n- **Format:** `text/csv`\n- **Fields:**\n  - `id`: Channel ID (e.g., `C1234567890`)\n  - `name`: Channel name (e.g., `#general`, `@username_dm`)\n  - `topic`: Channel topic (if any)\n  - `purpose`: Channel purpose/description\n  - `memberCount`: Number of members in the channel\n\n### 2. `slack://<workspace>/users` — Directory of Users\n\nFetches a CSV directory of all users in the workspace.\n\n- **URI:** `slack://<workspace>/users`\n- **Format:** `text/csv`\n- **Fields:**\n  - `userID`: User ID (e.g., `U1234567890`)\n  - `userName`: Slack username (e.g., `john`)\n  - `realName`: User’s real name (e.g., `John Doe`)\n\n## Setup Guide\n\n- [Authentication Setup](docs/01-authentication-setup.md)\n- [Installation](docs/02-installation.md)\n- [Configuration and Usage](docs/03-configuration-and-usage.md)\n\n### Environment Variables (Quick Reference)\n\n| Variable                          | Required? | Default                   | Description                                                                                                                                                                                                                                                                               |\n|-----------------------------------|-----------|---------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `SLACK_MCP_XOXC_TOKEN`            | Yes*      | `nil`                     | Slack browser token (`xoxc-...`)                                                                                                                                                                                                                                                          |\n| `SLACK_MCP_XOXD_TOKEN`            | Yes*      | `nil`                     | Slack browser cookie `d` (`xoxd-...`)                                                                                                                                                                                                                                                     |\n| `SLACK_MCP_XOXP_TOKEN`            | Yes*      | `nil`                     | User OAuth token (`xoxp-...`) — alternative to xoxc/xoxd                                                                                                                                                                                                                                  |\n| `SLACK_MCP_PORT`                  | No        | `13080`                   | Port for the MCP server to listen on                                                                                                                                                                                                                                                      |\n| `SLACK_MCP_HOST`                  | No        | `127.0.0.1`               | Host for the MCP server to listen on                                                                                                                                                                                                                                                      |\n| `SLACK_MCP_API_KEY`               | No        | `nil`                     | Bearer token for SSE and HTTP transports                                                                                                                                                                                                                                                            |\n| `SLACK_MCP_PROXY`                 | No        | `nil`                     | Proxy URL for outgoing requests                                                                                                                                                                                                                                                           |\n| `SLACK_MCP_USER_AGENT`            | No        | `nil`                     | Custom User-Agent (for Enterprise Slack environments)                                                                                                                                                                                                                                     |\n| `SLACK_MCP_CUSTOM_TLS`            | No        | `nil`                     | Send custom TLS-handshake to Slack servers based on `SLACK_MCP_USER_AGENT` or default User-Agent. (for Enterprise Slack environments)                                                                                                                                                     |\n| `SLACK_MCP_SERVER_CA`             | No        | `nil`                     | Path to CA certificate                                                                                                                                                                                                                                                                    |\n| `SLACK_MCP_SERVER_CA_TOOLKIT`     | No        | `nil`                     | Inject HTTPToolkit CA certificate to root trust-store for MitM debugging                                                                                                                                                                                                                  |\n| `SLACK_MCP_SERVER_CA_INSECURE`    | No        | `false`                   | Trust all insecure requests (NOT RECOMMENDED)                                                                                                                                                                                                                                             |\n| `SLACK_MCP_ADD_MESSAGE_TOOL`      | No        | `nil`                     | Enable message posting via `conversations_add_message` by setting it to true for all channels, a comma-separated list of channel IDs to whitelist specific channels, or use `!` before a channel ID to allow all except specified ones, while an empty value disables posting by default. |\n| `SLACK_MCP_ADD_MESSAGE_MARK`      | No        | `nil`                     | When the `conversations_add_message` tool is enabled, any new message sent will automatically be marked as read.                                                                                                                                                                          |\n| `SLACK_MCP_ADD_MESSAGE_UNFURLING` | No        | `nil`                     | Enable to let Slack unfurl posted links or set comma-separated list of domains e.g. `github.com,slack.com` to whitelist unfurling only for them. If text contains whitelisted and unknown domain unfurling will be disabled for security reasons.                                         |\n| `SLACK_MCP_USERS_CACHE`           | No        | `.users_cache.json`       | Path to the users cache file. Used to cache Slack user information to avoid repeated API calls on startup.                                                                                                                                                                                |\n| `SLACK_MCP_CHANNELS_CACHE`        | No        | `.channels_cache_v2.json` | Path to the channels cache file. Used to cache Slack channel information to avoid repeated API calls on startup.                                                                                                                                                                          |\n| `SLACK_MCP_LOG_LEVEL`             | No        | `info`                    | Log-level for stdout or stderr. Valid values are: `debug`, `info`, `warn`, `error`, `panic` and `fatal`                                                                                                                                                                                   |\n\n*You need either `xoxp` **or** both `xoxc`/`xoxd` tokens for authentication.\n\n### Limitations matrix & Cache\n\n| Users Cache        | Channels Cache     | Limitations                                                                                                                                                                                                                                                                                                                  |\n|--------------------|--------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| :x:                | :x:                | No cache, No LLM context enhancement with user data, tool `channels_list` will be fully not functional. Tools `conversations_*` will have limited capabilities and you won't be able to search messages by `@userHandle` or `#channel-name`, getting messages by `@userHandle` or `#channel-name` won't be available either. |\n| :white_check_mark: | :x:                | No channels cache, tool `channels_list` will be fully not functional. Tools `conversations_*` will have limited capabilities and you won't be able to search messages by `@userHandle` or `#channel-name`, getting messages by `@userHandle` or `#channel-name` won't be available either.                                   |\n| :white_check_mark: | :white_check_mark: | No limitations, fully functional Slack MCP Server.                                                                                                                                                                                                                                                                           |\n\n### Debugging Tools\n\n```bash\n# Run the inspector with stdio transport\nnpx @modelcontextprotocol/inspector go run mcp/mcp-server.go --transport stdio\n\n# View logs\ntail -n 20 -f ~/Library/Logs/Claude/mcp*.log\n```\n\n## Security\n\n- Never share API tokens\n- Keep .env files secure and private\n\n## License\n\nLicensed under MIT - see [LICENSE](LICENSE) file. This is not an official Slack product.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "slack",
        "communication",
        "ai",
        "server slack",
        "slack mcp",
        "communication tools"
      ],
      "category": "communication"
    },
    "lharries--whatsapp-mcp": {
      "owner": "lharries",
      "name": "whatsapp-mcp",
      "url": "https://github.com/lharries/whatsapp-mcp",
      "imageUrl": "",
      "description": "An MCP server for searching your personal WhatsApp messages, contacts and sending messages to individuals or groups",
      "stars": 4952,
      "forks": 749,
      "license": "MIT License",
      "language": "Go",
      "updated_at": "2025-10-04T04:51:20Z",
      "readme_content": "# WhatsApp MCP Server\n\nThis is a Model Context Protocol (MCP) server for WhatsApp.\n\nWith this you can search and read your personal Whatsapp messages (including images, videos, documents, and audio messages), search your contacts and send messages to either individuals or groups. You can also send media files including images, videos, documents, and audio messages.\n\nIt connects to your **personal WhatsApp account** directly via the Whatsapp web multidevice API (using the [whatsmeow](https://github.com/tulir/whatsmeow) library). All your messages are stored locally in a SQLite database and only sent to an LLM (such as Claude) when the agent accesses them through tools (which you control).\n\nHere's an example of what you can do when it's connected to Claude.\n\n\n\n> To get updates on this and other projects I work on [enter your email here](https://docs.google.com/forms/d/1rTF9wMBTN0vPfzWuQa2BjfGKdKIpTbyeKxhPMcEzgyI/preview)\n\n> *Caution:* as with many MCP servers, the WhatsApp MCP is subject to [the lethal trifecta](https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/). This means that project injection could lead to private data exfiltration.\n\n## Installation\n\n### Prerequisites\n\n- Go\n- Python 3.6+\n- Anthropic Claude Desktop app (or Cursor)\n- UV (Python package manager), install with `curl -LsSf https://astral.sh/uv/install.sh | sh`\n- FFmpeg (_optional_) - Only needed for audio messages. If you want to send audio files as playable WhatsApp voice messages, they must be in `.ogg` Opus format. With FFmpeg installed, the MCP server will automatically convert non-Opus audio files. Without FFmpeg, you can still send raw audio files using the `send_file` tool.\n\n### Steps\n\n1. **Clone this repository**\n\n   ```bash\n   git clone https://github.com/lharries/whatsapp-mcp.git\n   cd whatsapp-mcp\n   ```\n\n2. **Run the WhatsApp bridge**\n\n   Navigate to the whatsapp-bridge directory and run the Go application:\n\n   ```bash\n   cd whatsapp-bridge\n   go run main.go\n   ```\n\n   The first time you run it, you will be prompted to scan a QR code. Scan the QR code with your WhatsApp mobile app to authenticate.\n\n   After approximately 20 days, you will might need to re-authenticate.\n\n3. **Connect to the MCP server**\n\n   Copy the below json with the appropriate {{PATH}} values:\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"whatsapp\": {\n         \"command\": \"{{PATH_TO_UV}}\", // Run `which uv` and place the output here\n         \"args\": [\n           \"--directory\",\n           \"{{PATH_TO_SRC}}/whatsapp-mcp/whatsapp-mcp-server\", // cd into the repo, run `pwd` and enter the output here + \"/whatsapp-mcp-server\"\n           \"run\",\n           \"main.py\"\n         ]\n       }\n     }\n   }\n   ```\n\n   For **Claude**, save this as `claude_desktop_config.json` in your Claude Desktop configuration directory at:\n\n   ```\n   ~/Library/Application Support/Claude/claude_desktop_config.json\n   ```\n\n   For **Cursor**, save this as `mcp.json` in your Cursor configuration directory at:\n\n   ```\n   ~/.cursor/mcp.json\n   ```\n\n4. **Restart Claude Desktop / Cursor**\n\n   Open Claude Desktop and you should now see WhatsApp as an available integration.\n\n   Or restart Cursor.\n\n### Windows Compatibility\n\nIf you're running this project on Windows, be aware that `go-sqlite3` requires **CGO to be enabled** in order to compile and work properly. By default, **CGO is disabled on Windows**, so you need to explicitly enable it and have a C compiler installed.\n\n#### Steps to get it working:\n\n1. **Install a C compiler**  \n   We recommend using [MSYS2](https://www.msys2.org/) to install a C compiler for Windows. After installing MSYS2, make sure to add the `ucrt64\\bin` folder to your `PATH`.  \n   → A step-by-step guide is available [here](https://code.visualstudio.com/docs/cpp/config-mingw).\n\n2. **Enable CGO and run the app**\n\n   ```bash\n   cd whatsapp-bridge\n   go env -w CGO_ENABLED=1\n   go run main.go\n   ```\n\nWithout this setup, you'll likely run into errors like:\n\n> `Binary was compiled with 'CGO_ENABLED=0', go-sqlite3 requires cgo to work.`\n\n## Architecture Overview\n\nThis application consists of two main components:\n\n1. **Go WhatsApp Bridge** (`whatsapp-bridge/`): A Go application that connects to WhatsApp's web API, handles authentication via QR code, and stores message history in SQLite. It serves as the bridge between WhatsApp and the MCP server.\n\n2. **Python MCP Server** (`whatsapp-mcp-server/`): A Python server implementing the Model Context Protocol (MCP), which provides standardized tools for Claude to interact with WhatsApp data and send/receive messages.\n\n### Data Storage\n\n- All message history is stored in a SQLite database within the `whatsapp-bridge/store/` directory\n- The database maintains tables for chats and messages\n- Messages are indexed for efficient searching and retrieval\n\n## Usage\n\nOnce connected, you can interact with your WhatsApp contacts through Claude, leveraging Claude's AI capabilities in your WhatsApp conversations.\n\n### MCP Tools\n\nClaude can access the following tools to interact with WhatsApp:\n\n- **search_contacts**: Search for contacts by name or phone number\n- **list_messages**: Retrieve messages with optional filters and context\n- **list_chats**: List available chats with metadata\n- **get_chat**: Get information about a specific chat\n- **get_direct_chat_by_contact**: Find a direct chat with a specific contact\n- **get_contact_chats**: List all chats involving a specific contact\n- **get_last_interaction**: Get the most recent message with a contact\n- **get_message_context**: Retrieve context around a specific message\n- **send_message**: Send a WhatsApp message to a specified phone number or group JID\n- **send_file**: Send a file (image, video, raw audio, document) to a specified recipient\n- **send_audio_message**: Send an audio file as a WhatsApp voice message (requires the file to be an .ogg opus file or ffmpeg must be installed)\n- **download_media**: Download media from a WhatsApp message and get the local file path\n\n### Media Handling Features\n\nThe MCP server supports both sending and receiving various media types:\n\n#### Media Sending\n\nYou can send various media types to your WhatsApp contacts:\n\n- **Images, Videos, Documents**: Use the `send_file` tool to share any supported media type.\n- **Voice Messages**: Use the `send_audio_message` tool to send audio files as playable WhatsApp voice messages.\n  - For optimal compatibility, audio files should be in `.ogg` Opus format.\n  - With FFmpeg installed, the system will automatically convert other audio formats (MP3, WAV, etc.) to the required format.\n  - Without FFmpeg, you can still send raw audio files using the `send_file` tool, but they won't appear as playable voice messages.\n\n#### Media Downloading\n\nBy default, just the metadata of the media is stored in the local database. The message will indicate that media was sent. To access this media you need to use the download_media tool which takes the `message_id` and `chat_jid` (which are shown when printing messages containing the meda), this downloads the media and then returns the file path which can be then opened or passed to another tool.\n\n## Technical Details\n\n1. Claude sends requests to the Python MCP server\n2. The MCP server queries the Go bridge for WhatsApp data or directly to the SQLite database\n3. The Go accesses the WhatsApp API and keeps the SQLite database up to date\n4. Data flows back through the chain to Claude\n5. When sending messages, the request flows from Claude through the MCP server to the Go bridge and to WhatsApp\n\n## Troubleshooting\n\n- If you encounter permission issues when running uv, you may need to add it to your PATH or use the full path to the executable.\n- Make sure both the Go application and the Python server are running for the integration to work properly.\n\n### Authentication Issues\n\n- **QR Code Not Displaying**: If the QR code doesn't appear, try restarting the authentication script. If issues persist, check if your terminal supports displaying QR codes.\n- **WhatsApp Already Logged In**: If your session is already active, the Go bridge will automatically reconnect without showing a QR code.\n- **Device Limit Reached**: WhatsApp limits the number of linked devices. If you reach this limit, you'll need to remove an existing device from WhatsApp on your phone (Settings > Linked Devices).\n- **No Messages Loading**: After initial authentication, it can take several minutes for your message history to load, especially if you have many chats.\n- **WhatsApp Out of Sync**: If your WhatsApp messages get out of sync with the bridge, delete both database files (`whatsapp-bridge/store/messages.db` and `whatsapp-bridge/store/whatsapp.db`) and restart the bridge to re-authenticate.\n\nFor additional Claude Desktop integration troubleshooting, see the [MCP documentation](https://modelcontextprotocol.io/quickstart/server#claude-for-desktop-integration-issues). The documentation includes helpful tips for checking logs and resolving common issues.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "whatsapp",
        "communication",
        "messages",
        "communication integration",
        "whatsapp mcp",
        "communication tools"
      ],
      "category": "communication"
    },
    "line--line-bot-mcp-server": {
      "owner": "line",
      "name": "line-bot-mcp-server",
      "url": "https://github.com/line/line-bot-mcp-server",
      "imageUrl": "",
      "description": "MCP Server for Integrating LINE Official Account",
      "stars": 468,
      "forks": 78,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-10-04T00:17:03Z",
      "readme_content": "[日本語版 READMEはこちら](README.ja.md)\n\n# LINE Bot MCP Server\n\n[![npmjs](https://badge.fury.io/js/%40line%2Fline-bot-mcp-server.svg)](https://www.npmjs.com/package/@line/line-bot-mcp-server)\n\n[Model Context Protocol (MCP)](https://github.com/modelcontextprotocol) server implementation that integrates the LINE Messaging API to connect an AI Agent to the LINE Official Account.\n\n\n\n> [!NOTE]\n> This repository is provided as a preview version. While we offer it for experimental purposes, please be aware that it may not include complete functionality or comprehensive support.\n\n## Tools\n\n1. **push_text_message**\n   - Push a simple text message to a user via LINE.\n   - **Inputs:**\n     - `user_id` (string?): The user ID to receive a message. Defaults to DESTINATION_USER_ID. Either `user_id` or `DESTINATION_USER_ID` must be set.\n     - `message.text` (string): The plain text content to send to the user.\n2. **push_flex_message**\n   - Push a highly customizable flex message to a user via LINE.\n   - **Inputs:**\n     - `user_id` (string?): The user ID to receive a message. Defaults to DESTINATION_USER_ID. Either `user_id` or `DESTINATION_USER_ID` must be set.\n     - `message.altText` (string): Alternative text shown when flex message cannot be displayed.\n     - `message.content` (any): The content of the flex message. This is a JSON object that defines the layout and components of the message.\n     - `message.contents.type` (enum): Type of the container. 'bubble' for single container, 'carousel' for multiple swipeable bubbles.\n3. **broadcast_text_message**\n   - Broadcast a simple text message via LINE to all users who have followed your LINE Official Account.\n   - **Inputs:**\n     - `message.text` (string): The plain text content to send to the users.\n4. **broadcast_flex_message**\n   - Broadcast a highly customizable flex message via LINE to all users who have added your LINE Official Account.\n   - **Inputs:**\n     - `message.altText` (string): Alternative text shown when flex message cannot be displayed.\n     - `message.content` (any): The content of the flex message. This is a JSON object that defines the layout and components of the message.\n     - `message.contents.type` (enum): Type of the container. 'bubble' for single container, 'carousel' for multiple swipeable bubbles.\n5. **get_profile**\n   - Get detailed profile information of a LINE user including display name, profile picture URL, status message and language.\n   - **Inputs:**\n     - `user_id` (string?): The ID of the user whose profile you want to retrieve. Defaults to DESTINATION_USER_ID.\n6. **get_message_quota**\n   - Get the message quota and consumption of the LINE Official Account. This shows the monthly message limit and current usage.\n   - **Inputs:**\n     - None\n7. **get_rich_menu_list**\n   - Get the list of rich menus associated with your LINE Official Account.\n   - **Inputs:**\n     - None\n8. **delete_rich_menu**\n   - Delete a rich menu from your LINE Official Account.\n   - **Inputs:**\n     - `richMenuId` (string): The ID of the rich menu to delete.\n9. **set_rich_menu_default**\n    - Set a rich menu as the default rich menu.\n    - **Inputs:**\n      - `richMenuId` (string): The ID of the rich menu to set as default.\n10. **cancel_rich_menu_default**\n    - Cancel the default rich menu.\n    - **Inputs:**\n      - None\n\n## Installation (Using npx)\n\nrequirements:\n- Node.js v20 or later\n\n### Step 1: Create LINE Official Account\n\nThis MCP server utilizes a LINE Official Account. If you do not have one, please create it by following [this instructions](https://developers.line.biz/en/docs/messaging-api/getting-started/#create-oa). \n\nIf you have a LINE Official Account, enable the Messaging API for your LINE Official Account by following [this instructions](https://developers.line.biz/en/docs/messaging-api/getting-started/#using-oa-manager).\n\n### Step 2: Configure AI Agent\n\nPlease add the following configuration for an AI Agent like Claude Desktop or Cline. \n\nSet the environment variables or arguments as follows:\n\n- `CHANNEL_ACCESS_TOKEN`: (required) Channel Access Token. You can confirm this by following [this instructions](https://developers.line.biz/en/docs/basics/channel-access-token/#long-lived-channel-access-token).\n- `DESTINATION_USER_ID`: (optional) The default user ID of the recipient. If the Tool's input does not include `user_id`, `DESTINATION_USER_ID` is required. You can confirm this by following [this instructions](https://developers.line.biz/en/docs/messaging-api/getting-user-ids/#get-own-user-id).\n\n```json\n{\n  \"mcpServers\": {\n    \"line-bot\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"@line/line-bot-mcp-server\"\n      ],\n      \"env\": {\n        \"CHANNEL_ACCESS_TOKEN\" : \"FILL_HERE\",\n        \"DESTINATION_USER_ID\" : \"FILL_HERE\"\n      }\n    }\n  }\n}\n```\n\n## Installation (Using Docker)\n\n### Step 1: Create LINE Official Account\n\nThis MCP server utilizes a LINE Official Account. If you do not have one, please create it by following [this instructions](https://developers.line.biz/en/docs/messaging-api/getting-started/#create-oa).\n\nIf you have a LINE Official Account, enable the Messaging API for your LINE Official Account by following [this instructions](https://developers.line.biz/en/docs/messaging-api/getting-started/#using-oa-manager).\n\n\n### Step 2: Build line-bot-mcp-server image\n\nClone this repository:\n\n```\ngit clone git@github.com:line/line-bot-mcp-server.git\n```\n\nBuild the Docker image:\n\n```\ndocker build -t line/line-bot-mcp-server .\n```\n\n### Step 3: Configure AI Agent\n\nPlease add the following configuration for an AI Agent like Claude Desktop or Cline.\n\nSet the environment variables or arguments as follows:\n\n- `mcpServers.args`: (required) The path to `line-bot-mcp-server`.\n- `CHANNEL_ACCESS_TOKEN`: (required) Channel Access Token. You can confirm this by following [this instructions](https://developers.line.biz/en/docs/basics/channel-access-token/#long-lived-channel-access-token).\n- `DESTINATION_USER_ID`: (optional) The default user ID of the recipient. If the Tool's input does not include `user_id`, `DESTINATION_USER_ID` is required.\nYou can confirm this by following [this instructions](https://developers.line.biz/en/docs/messaging-api/getting-user-ids/#get-own-user-id).\n\n\n```json\n{\n  \"mcpServers\": {\n    \"line-bot\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"CHANNEL_ACCESS_TOKEN\",\n        \"-e\",\n        \"DESTINATION_USER_ID\",\n        \"line/line-bot-mcp-server\"\n      ],\n      \"env\": {\n        \"CHANNEL_ACCESS_TOKEN\" : \"FILL_HERE\",\n        \"DESTINATION_USER_ID\" : \"FILL_HERE\"\n      }\n    }\n  }\n}\n```\n\n## Local Development with Inspector\n\nYou can use the MCP Inspector to test and debug the server locally.\n\n### Prerequisites\n\n1. Clone the repository:\n```bash\ngit clone git@github.com:line/line-bot-mcp-server.git\ncd line-bot-mcp-server\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the project:\n```bash\nnpm run build\n```\n\n### Run the Inspector\n\nAfter building the project, you can start the MCP Inspector:\n\n```bash\nnpx @modelcontextprotocol/inspector node dist/index.js\n```\n\nThis will start the MCP Inspector interface where you can interact with the LINE Bot MCP Server tools and test their functionality.\n\n## Versioning\n\nThis project respects semantic versioning\n\nSee http://semver.org/\n\n## Contributing\n\nPlease check [CONTRIBUTING](./CONTRIBUTING.md) before making a contribution.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "communication",
        "mcp",
        "line bot",
        "message management",
        "communication integration"
      ],
      "category": "communication"
    },
    "saseq--discord-mcp": {
      "owner": "saseq",
      "name": "discord-mcp",
      "url": "https://github.com/SaseQ/discord-mcp",
      "imageUrl": "",
      "description": "A MCP server for the Discord integration. Enable your AI assistants to seamlessly interact with Discord. Enhance your Discord experience with powerful automation capabilities.",
      "stars": 83,
      "forks": 18,
      "license": "MIT License",
      "language": "Java",
      "updated_at": "2025-10-01T06:34:29Z",
      "readme_content": "<div align=\"center\">\n  \n</div>\n<hr>\n<div align=\"center\" style=\"line-height: 1;\">\n    <a href=\"https://github.com/modelcontextprotocol/servers\" target=\"_blank\" style=\"margin: 2px;\">\n        <img alt=\"MCP Server\" src=\"https://badge.mcpx.dev?type=server\" style=\"display: inline-block; vertical-align: middle;\"/>\n    </a>\n    <a href=\"https://smithery.ai/server/@SaseQ/discord-mcp\" target=\"_blank\" style=\"margin: 2px;\">\n        <img alt=\"Smithery Badge\" src=\"https://camo.githubusercontent.com/ee5c6c6dc502821f4d57313b2885f7878af52be14142dd98526ea12aedf9b260/68747470733a2f2f736d6974686572792e61692f62616467652f40646d6f6e74676f6d65727934302f646565707365656b2d6d63702d736572766572\" data-canonical-src=\"https://smithery.ai/server/@SaseQ/discord-mcp\" style=\"display: inline-block; vertical-align: middle;\"/>\n    </a>\n    <a href=\"https://discord.gg/5Uvxe5jteM\" target=\"_blank\" style=\"margin: 2px;\">\n        <img alt=\"Discord\" src=\"https://img.shields.io/discord/936242526120194108?color=7389D8&label&logo=discord&logoColor=ffffff\" style=\"display: inline-block; vertical-align: middle;\"/>\n    </a>\n    <a href=\"https://github.com/SaseQ/discord-mcp/blob/main/LICENSE\" target=\"_blank\" style=\"margin: 2px;\">\n        <img alt=\"MIT License\" src=\"https://img.shields.io/github/license/SaseQ/discord-mcp\" style=\"display: inline-block; vertical-align: middle;\"/>\n    </a>\n</div>\n\n\n## 📖 Description\n\nA [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) server for the Discord API [(JDA)](https://jda.wiki/), \nallowing seamless integration of Discord Bot with MCP-compatible applications like Claude Desktop.\n\nEnable your AI assistants to seamlessly interact with Discord. Manage channels, send messages, and retrieve server information effortlessly. Enhance your Discord experience with powerful automation capabilities.\n\n\n## 🔬 Installation\n\n### ► 🐳 Docker Installation (Recommended)\n> NOTE: Docker installation is required. Full instructions can be found on [docker.com](https://www.docker.com/products/docker-desktop/).\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \"--rm\", \"-i\",\n        \"-e\", \"DISCORD_TOKEN=<YOUR_DISCORD_BOT_TOKEN>\",\n        \"-e\", \"DISCORD_GUILD_ID=<OPTIONAL_DEFAULT_SERVER_ID>\",\n        \"saseq/discord-mcp:latest\"\n      ]\n    }\n  }\n}\n```\n\n<details>\n    <summary style=\"font-size: 1.35em; font-weight: bold;\">\n        🔧 Manual Installation\n    </summary>\n\n#### Clone the repository\n```bash\ngit clone https://github.com/SaseQ/discord-mcp\n```\n\n#### Build the project\n> NOTE: Maven installation is required to use the mvn command. Full instructions can be found [here](https://www.baeldung.com/install-maven-on-windows-linux-mac).\n```bash\ncd discord-mcp\nmvn clean package # The jar file will be available in the /target directory\n```\n\n#### Configure AI client\nMany code editors and other AI clients use a configuration file to manage MCP servers.\n\nThe Discord MPC server can be configured by adding the following to your configuration file.\n\n> NOTE: You will need to create a Discord Bot token to use this server. Instructions on how to create a Discord Bot token can be found [here](https://discordjs.guide/preparations/setting-up-a-bot-application.html#creating-your-bot).\n```json\n{\n  \"mcpServers\": {\n    \"discord-mcp\": {\n      \"command\": \"java\",\n      \"args\": [\n        \"-jar\",\n        \"/absolute/path/to/discord-mcp-0.0.1-SNAPSHOT.jar\"\n      ],\n      \"env\": {\n        \"DISCORD_TOKEN\": \"YOUR_DISCORD_BOT_TOKEN\",\n        \"DISCORD_GUILD_ID\": \"OPTIONAL_DEFAULT_SERVER_ID\"\n      }\n    }\n  }\n}\n```\nThe `DISCORD_GUILD_ID` environment variable is optional. When provided, it sets a default Discord server ID so any tool that accepts a `guildId` parameter can omit it.\n\n</details>\n\n<details>\n    <summary style=\"font-size: 1.35em; font-weight: bold;\">\n        ⚓ Smithery Installation\n    </summary>\n\nInstall Discord MCP Server automatically via [Smithery](https://smithery.ai/):\n```bash\nnpx -y @smithery/cli@latest install @SaseQ/discord-mcp --client <CLIENT_NAME> --key <YOUR_SMITHERY_KEY>\n```\n\n</details>\n\n<details>\n    <summary style=\"font-size: 1.35em; font-weight: bold;\">\n        🖲 Cursor Installation\n    </summary>\n\nGo to: `Settings` -> `Cursor Settings` -> `MCP` -> `Add new global MCP server`\n\nPasting the following configuration into your Cursor `~/.cursor/mcp.json` file is the recommended approach. You may also install in a specific project by creating `.cursor/mcp.json` in your project folder. See [Cursor MCP docs](https://docs.cursor.com/context/model-context-protocol) for more info.\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \"--rm\", \"-i\",\n        \"-e\", \"DISCORD_TOKEN=<YOUR_DISCORD_BOT_TOKEN>\",\n        \"-e\", \"DISCORD_GUILD_ID=<OPTIONAL_DEFAULT_SERVER_ID>\",\n        \"saseq/discord-mcp:latest\"\n      ]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n    <summary style=\"font-size: 1.35em; font-weight: bold;\">\n        ⌨️ Claude Code Installation\n    </summary>\n\nRun this command. See [Claude Code MCP docs](https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/tutorials#set-up-model-context-protocol-mcp) for more info.\n```bash\nclaude mcp add mcp-server -- docker run --rm -i -e DISCORD_TOKEN=<YOUR_DISCORD_BOT_TOKEN> -e DISCORD_GUILD_ID=<OPTIONAL_DEFAULT_SERVER_ID> saseq/discord-mcp:latest\n```\n\n</details>\n\n## 🛠️ Available Tools\n\n#### Server Information\n - [`get_server_info`](): Get detailed discord server information\n\n#### User Management\n- [`get_user_id_by_name`](): Get a Discord user's ID by username in a guild for ping usage `<@id>`\n- [`send_private_message`](): Send a private message to a specific user\n- [`edit_private_message`](): Edit a private message from a specific user\n- [`delete_private_message`](): Delete a private message from a specific user\n- [`read_private_messages`](): Read recent message history from a specific user\n\n#### Message Management\n - [`send_message`](): Send a message to a specific channel\n - [`edit_message`](): Edit a message from a specific channel\n - [`delete_message`](): Delete a message from a specific channel\n - [`read_messages`](): Read recent message history from a specific channel\n - [`add_reaction`](): Add a reaction (emoji) to a specific message\n - [`remove_reaction`](): Remove a specified reaction (emoji) from a message\n\n#### Channel Management\n - [`create_text_channel`](): Create text a channel\n - [`delete_channel`](): Delete a channel\n - [`find_channel`](): Find a channel type and ID using name and server ID\n - [`list_channels`](): List of all channels\n\n#### Category Management\n - [`create_category`](): Create a new category for channels\n - [`delete_category`](): Delete a category\n - [`find_category`](): Find a category ID using name and server ID\n - [`list_channels_in_category`](): List of channels in a specific category\n\n#### Webhook Management\n - [`create_webhook`](): Create a new webhook on a specific channel\n - [`delete_webhook`](): Delete a webhook\n - [`list_webhooks`](): List of webhooks on a specific channel\n - [`send_webhook_message`](): Send a message via webhook\n\n>If `DISCORD_GUILD_ID` is set, the `guildId` parameter becomes optional for all tools above.\n\n<hr>\n\nA more detailed examples can be found in the [Wiki](https://github.com/SaseQ/discord-mcp/wiki).",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "discord",
        "communication",
        "saseq",
        "discord integration",
        "saseq discord",
        "discord mcp"
      ],
      "category": "communication"
    },
    "sawa-zen--vrchat-mcp": {
      "owner": "sawa-zen",
      "name": "vrchat-mcp",
      "url": "https://github.com/sawa-zen/vrchat-mcp",
      "imageUrl": "",
      "description": "📇 🏠 This is an MCP server for interacting with the VRChat API. You can retrieve information about friends, worlds, avatars, and more in VRChat.",
      "stars": 43,
      "forks": 5,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T23:38:42Z",
      "readme_content": "[![npm version](https://badge.fury.io/js/vrchat-mcp.svg)](https://badge.fury.io/js/vrchat-mcp) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n[日本語](./README.ja.md) | [한국어](./README.ko.md)\n\nThis project is a Model Context Protocol (MCP) server for interacting with the VRChat API. It allows you to retrieve various information from VRChat using a standardized protocol.\n\n<a href=\"https://youtu.be/0MRxhzlFCkw\">\n  <img width=\"300\" src=\"https://github.com/user-attachments/assets/85c00cc4-46b3-4f66-ab36-bf2891fdb283\" alt=\"YouTube\" />\n</a>\n\n<a href=\"https://glama.ai/mcp/servers/u763zoyi5a\">\n  <img alt=\"badge\" width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/u763zoyi5a/badge\" />\n</a>\n\n## Overview\n\nThe VRChat MCP server provides a way to access VRChat's API endpoints in a structured manner. It supports a wide range of functionalities, including user authentication, retrieving user and friend information, accessing avatar and world data, and more.\n\n## Usage\n\nTo start the server, ensure you have the necessary environment variables set:\n\n```bash\nexport VRCHAT_USERNAME=your_username\nexport VRCHAT_AUTH_TOKEN=your_auth_token\n```\n\n> [!NOTE]\n> #### How to obtain AUTH TOKEN\n>\n> You can use the following command to login and obtain an auth token:\n> ```\n> $ npx vrchat-auth-token-checker\n>\n> VRChat Username: your-username\n> Password: ********\n>\n> # If 2FA is enabled\n> 2FA Code: 123456\n>\n> # Success output\n> Auth Token: authcookie-xxxxx\n> ```\n> [Command source code](https://github.com/sawa-zen/vrchat-auth-token-checker)\n>\n> **Please handle the obtained token with care as it has a very long lifetime**\n\nThen, run the following command:\n\n```bash\nnpx vrchat-mcp\n```\n\nThis will launch the MCP server, allowing you to interact with the VRChat API through the defined tools.\n\n## Usage with Claude Desktop\n\nTo use this MCP server with Claude Desktop, you do not need to run `npx vrchat-mcp` manually. Instead, add the following configuration to your Claude Desktop config file:\n\n- MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"vrchat-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"vrchat-mcp\"],\n      \"env\": {\n        \"VRCHAT_USERNAME\": \"your-username\",\n        \"VRCHAT_AUTH_TOKEN\": \"your-auth-token\"\n      }\n    }\n  }\n}\n```\n\nThen, start Claude Desktop as usual. If you have to use nodenv or nvm, you may need to specify the full path to the `npx` command.\n\n## Available Tools\n\nThis Model Context Protocol server provides the following VRChat-related tools:\n\n### User Related\n- vrchat_get_friends_list: Get a list of friends\n- vrchat_send_friend_request: Send a friend request\n\n### Avatar Related\n- vrchat_search_avatars: Search for avatars\n- vrchat_select_avatar: Select and switch to a specific avatar\n\n### World Related\n- vrchat_search_worlds: Search for worlds\n- vrchat_list_favorited_worlds: Get a list of favorited worlds\n\n### Instance Related\n- vrchat_create_instance: Create a new instance\n- vrchat_get_instance: Get information about a specific instance\n\n### Group Related\n- vrchat_search_groups: Search for groups\n- vrchat_join_group: Join a group\n\n### Favorites Related\n- vrchat_list_favorites: Get a list of favorites\n- vrchat_add_favorite: Add a new favorite\n- vrchat_list_favorite_groups: Get a list of favorite groups\n\n### Invite Related\n- vrchat_list_invite_messages: Get a list of invite messages\n- vrchat_request_invite: Request an invite\n- vrchat_get_invite_message: Get a specific invite message\n\n### Notification Related\n- vrchat_get_notifications: Get a list of notifications\n\n## Debugging\n\nFirst, build the project:\n\n```bash\nnpm install\nnpm run build\n```\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging experience, we strongly recommend using the MCP Inspector.\n\nYou can launch the MCP Inspector via npm with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector \"./dist/main.js\"\n```\n\nBe sure that environment variables are properly configured.\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n\n## Publishing\n\nTo publish a new version of the package, follow these steps:\n\n1. Pull the latest code from the main branch\n   ```bash\n   git checkout main\n   git pull origin main\n   ```\n\n2. Build the package\n   ```bash\n   npm run build\n   ```\n\n4. Publish to npm\n   ```bash\n   npm publish\n   ```\n\n5. Push changes to the remote repository\n   ```bash\n   git push origin main --tags\n   ```\n\n## Contributing\n\nContributions are welcome! Please fork the repository and submit a pull request for any improvements or bug fixes.\n\n## License\n\nThis project is licensed under the MIT License. See the LICENSE file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "vrchat",
        "communication",
        "mcp",
        "vrchat mcp",
        "interacting vrchat",
        "zen vrchat"
      ],
      "category": "communication"
    },
    "teddyzxcv--ntfy-mcp": {
      "owner": "teddyzxcv",
      "name": "ntfy-mcp",
      "url": "https://github.com/teddyzxcv/ntfy-mcp",
      "imageUrl": "",
      "description": "The MCP server that keeps you informed by sending the notification on phone using ntfy",
      "stars": 40,
      "forks": 4,
      "license": "Apache License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-09-05T07:23:46Z",
      "readme_content": "# ntfy-mcp: Your Friendly Task Completion Notifier\n\nWelcome to ntfy-mcp, the MCP server that keeps you caffeinated and informed! 🚀☕️\n\nThis handy little server integrates with the Model Context Protocol to send you delightful ntfy notifications whenever your AI assistant completes a task. Because let's face it - you deserve that tea break while your code writes itself.\n\n<a href=\"https://glama.ai/mcp/servers/@teddyzxcv/ntfy-mcp\">\n  <img alt=\"badge\" width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@teddyzxcv/ntfy-mcp/badge\" />\n</a>\n\n## Getting Started: The Quick Brew Guide\n\n### Step 1: Clone & Navigate\n```bash\ngit clone https://github.com/teddyzxcv/ntfy-mcp.git\ncd ntfy-mcp\n```\n\n### Step 2: Install \n```bash\nnpm install\n```\n\n### Step 3: Build \n```bash\nnpm run build\n```\n\n### Step 4: Connect\nChoose your adventure:\n\n**Manual Start:**\n```bash\nnpm start\n```\n\n**Cline Configuration:**\n```json\n\"ntfy-mcp\": {\n  \"command\": \"node\",\n  \"args\": [\n    \"/path/to/ntfy-mcp/build/index.js\"\n  ],\n  \"env\": {\n    \"NTFY_TOPIC\": \"<your topic name>\"\n  },\n  \"autoApprove\": [\n    \"notify_user\" // Highly recommended for maximum chill\n  ]\n}\n```\n\n### Step 5: Get Notified in Style\n1. Download the [ntfy app](https://ntfy.sh) on your phone\n2. Subscribe to your chosen topic\n3. Kick back and relax\n\n### Step 6: The Magic Command\nWrite a prompt like this, otherwise the function won't call \n(tried use `Custom Instructions` in cline, but they are in the ring 3, so model just forget about it)\n```\nWrite me a hello world in python, notify me when the task is done\n```\n\n### Step 7: Enjoy Your Beverage of Choice\n☕️🍵 Your notification will arrive when the task is complete. No peeking!\n\n## How It Works (The Technical Tea)\n\nThis MCP server integrates seamlessly with the Model Context Protocol, acting as your personal notification butler. When tasks are completed, it sends notifications via ntfy, keeping you informed without interrupting your flow.\n\n## Dependencies: The Secret Sauce\n\n- [@modelcontextprotocol/sdk](https://github.com/modelcontextprotocol/typescript-sdk)\n- [node-fetch](https://github.com/node-fetch/node-fetch)\n- [dotenv](https://github.com/motdotla/dotenv)\n- [zod](https://github.com/colinhacks/zod)\n\n\n\n## License\n\nThis project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.\n\n```\nCopyright 2025 Casey Hand @cyanheads\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n---\n\nNow go forth and code with confidence, knowing your notifications are in good hands! 🎉\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "communication",
        "mcp",
        "ai",
        "communication integration",
        "communication tools",
        "message management"
      ],
      "category": "communication"
    },
    "userad--didlogic_mcp": {
      "owner": "userad",
      "name": "didlogic_mcp",
      "url": "https://github.com/UserAd/didlogic_mcp",
      "imageUrl": "",
      "description": "An MCP server for [DIDLogic](https://didlogic.com). Adds functionality to manage SIP endpoints, numbers and destinations.",
      "stars": 1,
      "forks": 5,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-03-29T10:24:59Z",
      "readme_content": "# Didlogic MCP Server\n\nA Model Context Protocol (MCP) server implementation for the Didlogic API. This server allows Large Language Models (LLMs) to interact with Didlogic services through a standardized interface.\n\n## Features\n\n- Full access to Didlogic API through MCP tools\n- Specialized prompts for common operations\n- Balance management tools\n- SIP account (sipfriends) management\n- IP restriction management\n- Purchases management\n- Call hisory access\n- Transaction history access\n\n## Installation\n\n### Using uv (recommended)\n\nWhen using [`uv`](https://docs.astral.sh/uv/) no specific installation is needed. We will\nuse [`uvx`](https://docs.astral.sh/uv/guides/tools/) to directly run *didlogic_mcp*.\n\n### Using PIP\n\nAlternatively you can install `didlogic_mcp` via pip:\n\n```bash\npip install didlogic_mcp\n```\n\nAfter installation, you can run it as a script using:\n\n```bash\nDIDLOGIC_API_KEY=YOUR_DIDLOGIC_KEY python -m didlogic_mcp\n```\n\n## Configuration\n\n### Configure for Claude.app\n\nAdd to your Claude settings:\n\n#### Using uvx\n\n```json\n\"mcpServers\": {\n  \"didlogic\": {\n    \"command\": \"uvx\",\n    \"args\": [\"didlogic_mcp\"],\n    \"env\": {\n      \"DIDLOGIC_API_KEY\": \"YOUR_DIDLOGIC_KEY\"\n    }\n  }\n}\n```\n\n#### Using pip installation\n\n```json\n\"mcpServers\": {\n  \"didlogic\": {\n    \"command\": \"python\",\n    \"args\": [\"-m\", \"didlogic_mcp\"],\n    \"env\": {\n      \"DIDLOGIC_API_KEY\": \"YOUR_DIDLOGIC_KEY\"\n    }\n  }\n}\n```\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "didlogic_mcp",
        "didlogic",
        "communication",
        "communication integration",
        "communication tools",
        "server didlogic"
      ],
      "category": "communication"
    },
    "wyattjoh--imessage-mcp": {
      "owner": "wyattjoh",
      "name": "imessage-mcp",
      "url": "https://github.com/wyattjoh/imessage-mcp",
      "imageUrl": "",
      "description": "A Model Context Protocol server for reading iMessage data from macOS.",
      "stars": 14,
      "forks": 3,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-02T03:43:58Z",
      "readme_content": "# iMessage MCP\n\nA Deno monorepo containing packages for iMessage access on macOS:\n\n- **[@wyattjoh/imessage](packages/imessage)** - Core library for read-only iMessage database access\n- **[@wyattjoh/imessage-mcp](packages/imessage-mcp)** - Model Context Protocol (MCP) server for LLM integration\n\n## Features\n\n- Search messages by text content, contact, or date range\n- Get recent messages\n- List all chats/conversations\n- Get all contacts/handles\n- Retrieve messages from specific chats\n- Search macOS Contacts by name with iMessage handle ID correlation\n\n## Requirements\n\n- macOS (iMessage is only available on macOS)\n- Deno 2.x or later\n- Read access to `~/Library/Messages/chat.db`\n- Read access to `~/Library/Application Support/AddressBook/` (for contacts search)\n\n## Packages\n\n### @wyattjoh/imessage\n\nCore library for accessing iMessage data:\n\n```bash\ndeno add @wyattjoh/imessage\n```\n\n```typescript\nimport { openMessagesDatabase, searchMessages } from \"@wyattjoh/imessage\";\n\nconst db = await openMessagesDatabase();\nconst results = await searchMessages(db, { query: \"hello\" });\ndb.close();\n```\n\n[See full documentation](packages/imessage/README.md)\n\n### @wyattjoh/imessage-mcp\n\nMCP server for LLM integration:\n\n```bash\n# Run directly from JSR\ndeno run --allow-read --allow-env --allow-sys --allow-ffi jsr:@wyattjoh/imessage-mcp\n\n# Or install globally\ndeno install --global --allow-read --allow-env --allow-sys --allow-ffi -n imessage-mcp jsr:@wyattjoh/imessage-mcp\n```\n\nFor Claude Desktop app integration, add this to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"imessage\": {\n      \"command\": \"deno\",\n      \"args\": [\n        \"run\",\n        \"--allow-read\",\n        \"--allow-env\",\n        \"--allow-sys\",\n        \"--allow-ffi\",\n        \"jsr:@wyattjoh/imessage-mcp\"\n      ]\n    }\n  }\n}\n```\n\n### Option 2: From Source\n\n1. Clone this repository\n2. Install dependencies:\n   ```bash\n   deno cache src/index.ts\n   ```\n3. Run the server:\n   ```bash\n   deno run --allow-read --allow-env --allow-sys --allow-ffi src/index.ts\n   # Or use the task:\n   deno task start\n   ```\n\n### Available Tools\n\n1. **search_messages** - Search messages with filters\n   - `query` (optional): Text to search for\n   - `handle` (optional): Phone number or email to filter by\n   - `startDate` (optional): ISO datetime string for start date\n   - `endDate` (optional): ISO datetime string for end date\n   - `limit` (optional): Maximum results (1-200, default: 100)\n   - `offset` (optional): Pagination offset (default: 0)\n\n2. **get_recent_messages** - Get the most recent messages\n   - `limit` (optional): Number of messages (1-100, default: 20)\n   - `offset` (optional): Pagination offset (default: 0)\n\n3. **get_chats** - List all conversations\n   - `limit` (optional): Number of chats (1-200, default: 50)\n   - `offset` (optional): Pagination offset (default: 0)\n\n4. **get_handles** - Get all contacts/handles\n   - `limit` (optional): Number of handles (1-200, default: 100)\n   - `offset` (optional): Pagination offset (default: 0)\n\n5. **get_messages_from_chat** - Get messages from a specific chat\n   - `chatGuid` (required): The chat GUID\n   - `limit` (optional): Number of messages (1-200, default: 50)\n   - `offset` (optional): Pagination offset (default: 0)\n\n6. **search_contacts** - Search macOS Contacts by name and get phone numbers\n   - `firstName` (required): First name to search for (e.g., 'John')\n   - `lastName` (optional): Last name to search for (e.g., 'Smith'). If omitted, searches across all name fields\n   - `limit` (optional): Maximum results (1-200, default: 50)\n   - `offset` (optional): Pagination offset (default: 0)\n   - Returns contact info with phone numbers and email addresses that can be used as handle parameters\n   - Searches directly in the macOS AddressBook database for better performance and reliability\n\n### Pagination Examples\n\nAll tools now support pagination using `limit` and `offset` parameters and return pagination metadata:\n\n```javascript\n// Get first 20 recent messages\nget_recent_messages({ limit: 20, offset: 0 });\n\n// Get next 20 recent messages (page 2)\nget_recent_messages({ limit: 20, offset: 20 });\n\n// Get first 10 chats\nget_chats({ limit: 10, offset: 0 });\n\n// Get messages 51-100 from a specific chat\nget_messages_from_chat({\n  chatGuid: \"iMessage;-;+15551234\",\n  limit: 50,\n  offset: 50,\n});\n\n// Search with pagination\nsearch_messages({\n  query: \"meeting\",\n  limit: 100,\n  offset: 200,\n});\n\n// Search contacts with pagination\nsearch_contacts({\n  firstName: \"John\",\n  lastName: \"Smith\",\n  limit: 50,\n  offset: 0,\n});\n```\n\n#### Response Format with Pagination Metadata\n\nAll paginated tools now return responses in this format:\n\n```json\n{\n  \"data\": [\n    // Array of results (messages, chats, handles, etc.)\n  ],\n  \"pagination\": {\n    \"total\": 1250, // Total number of results available\n    \"limit\": 100, // Current page size\n    \"offset\": 200, // Current offset\n    \"hasMore\": true, // Whether there are more results to fetch\n    \"page\": 3, // Current page number (1-indexed)\n    \"totalPages\": 13 // Total number of pages\n  }\n}\n```\n\nThis metadata helps you:\n\n- Know the total number of results without fetching all of them\n- Determine if there are more pages to fetch (`hasMore`)\n- Calculate which page you're on and how many pages exist\n- Build proper pagination UI components\n\n## Security Notes\n\n- This server runs with read-only access to the iMessage database\n- No messages can be sent or modified\n- The server only accesses local data\n\n## Development\n\nThis is a Deno workspace monorepo. All commands run from the root affect all packages.\n\n```bash\n# Clone the repository\ngit clone https://github.com/wyattjoh/imessage-mcp.git\ncd imessage-mcp\n\n# Cache dependencies\ndeno cache packages/*/mod.ts\n\n# Format all code\ndeno task fmt\n\n# Lint all packages\ndeno task lint\n\n# Type check all packages\ndeno task check\n\n# Run tests\ndeno task test\n\n# Run MCP server locally\ncd packages/imessage-mcp\ndeno run --allow-read --allow-env --allow-sys --allow-ffi mod.ts\n\n# Publish packages (CI/CD)\ndeno publish\n```\n\n### Working on Individual Packages\n\n```bash\n# Work on @wyattjoh/imessage\ncd packages/imessage\ndeno test --allow-read --allow-env --allow-ffi\n\n# Work on @wyattjoh/imessage-mcp\ncd packages/imessage-mcp\ndeno run --allow-read --allow-env --allow-sys --allow-ffi mod.ts\n```\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "imessage",
        "protocol",
        "communication",
        "imessage mcp",
        "message management",
        "communication tools"
      ],
      "category": "communication"
    },
    "ztxtxwd--open-feishu-mcp-server": {
      "owner": "ztxtxwd",
      "name": "open-feishu-mcp-server",
      "url": "https://github.com/ztxtxwd/open-feishu-mcp-server",
      "imageUrl": "",
      "description": "A Model Context Protocol (MCP) server with built-in Feishu OAuth authentication, supporting remote connections and providing comprehensive Feishu document management tools including block creation, content updates, and advanced features.",
      "stars": 61,
      "forks": 8,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-04T12:54:12Z",
      "readme_content": "[![MCP Badge](https://lobehub.com/badge/mcp/ztxtxwd-open-feishu-mcp-server)](https://lobehub.com/mcp/ztxtxwd-open-feishu-mcp-server)\n# 飞书 MCP Server\n\n[English Documentation](README.en.md)\n\n这是一个支持远程连接的[模型上下文协议 (MCP)](https://modelcontextprotocol.io/introduction) 服务器，内置了飞书 OAuth 认证。\n\n本项目修改自 [cloudflare/ai/demos/remote-mcp-github-oauth](https://github.com/cloudflare/ai/tree/main/demos/remote-mcp-github-oauth)，将 GitHub OAuth 替换为飞书 OAuth。\n\n您可以将其部署到自己的 Cloudflare 账户，并在创建自己的飞书 OAuth 客户端应用后，拥有一个功能完整的远程 MCP 服务器。用户可以通过飞书账号登录连接到您的 MCP 服务器。\n\n## 📋 目录\n\n- [与飞书官方 MCP Server 的区别](#-与飞书官方-mcp-server-的区别)\n- [特性](#-特性)\n- [快速开始](#-快速开始)\n- [部署方式](#-部署方式)\n  - [生产环境部署](#生产环境部署)\n  - [本地开发环境](#本地开发环境)\n- [客户端集成](#-客户端集成)\n  - [使用 Inspector 测试](#使用-inspector-测试)\n  - [使用 Cursor](#使用-cursor)\n  - [使用 ChatWise](#使用-chatwise)\n- [访问控制](#-访问控制)\n- [工具开发路线图](#-工具开发路线图)\n- [技术原理](#-技术原理)\n- [开发指南](#-开发指南)\n\n\n## 🆚 与飞书官方 MCP Server 的区别\n\n虽然飞书官方也推出了 MCP Server，但本项目在以下几个方面具有显著优势：\n\n### 🎯 零配置体验\n- **本项目**：用户无需手动配置任何参数，全程使用 `user_access_token`，过期自动刷新\n- **官方项目**：需要用户手动配置多个参数，配置复杂\n\n### 🚀 极致的可用性优化\n- **本项目**：深度优化工具尺寸和结构，特别是文档创建块工具、创建嵌套块工具等复杂功能，确保在 Cursor 等客户端中正常使用\n- **官方项目**：简单的 API 到 MCP 工具转换，部分工具过于庞大，在实际使用中存在可用性问题\n\n### 🌐 前沿基础设施\n- 支持部署在 Cloudflare Workers，享受业界最前沿的边缘计算基础设施\n## ✨ 特性\n\n- 🎯 **零配置体验**：用户无需手动配置参数，自动管理 `user_access_token` 和刷新\n- 🔐 **飞书 OAuth 认证**：安全的用户身份验证\n- 🌐 **远程 MCP 服务器**：支持多客户端连接\n- 🚀 **Cloudflare Workers**：高性能、全球分布式部署，享受业界最前沿的边缘计算基础设施\n- 🛠️ **深度优化的工具集**：特别优化文档创建、嵌套块等复杂工具，确保在各种客户端中正常使用\n- 🔧 **本地开发支持**：便于开发和测试的本地环境\n- ⚡ **极致可用性**：相比官方 MCP Server，大幅提升实际使用体验和稳定性\n\n## 🚀 快速开始\n\n### 前置要求\n\n- Node.js 18+ 和 npm\n- Cloudflare 账户\n- 飞书开放平台账户\n\n### 安装\n\n```bash\n# 克隆仓库\ngit clone <repository-url>\ncd open-feishu-mcp-server\n\n# 安装依赖\nnpm install\n```\n\n## 🚀 部署方式\n\n### 生产环境部署\n\n#### 步骤 1: 创建飞书应用\n\n1. 访问[飞书开放平台](https://open.feishu.cn/)并登录\n2. 点击\"开发者后台\"并创建一个新应用\n3. 在应用设置中配置权限：\n   - 进入\"权限与功能\"并添加以下权限：\n     - \"获取用户 ID\" (auth:user.id:read)\n     - \"获取用户任务信息\" (task:task:read)\n     - \"获取用户授权凭证\" (offline_access)\n     - \"获取用户基本信息\" (user_profile)\n     \n        ...\n4. 记下您的**应用 ID** 和**应用密钥**\n\n#### 步骤 2: 配置 Cloudflare 环境\n\n```bash\n# 设置必要的密钥\nwrangler secret put FEISHU_APP_ID\nwrangler secret put FEISHU_APP_SECRET\nwrangler secret put COOKIE_ENCRYPTION_KEY  # 使用 openssl rand -hex 32 生成\n\n# 创建 KV 命名空间\nwrangler kv:namespace create \"OAUTH_KV\"\n```\n\n#### 步骤 3: 更新配置文件\n\n使用步骤 2 中获得的 KV ID 更新 `wrangler.toml` 文件中的 KV 命名空间配置。\n\n#### 步骤 4: 部署服务器\n\n```bash\nnpm run deploy\n```\n\n部署完成后，记下您的实际 subdomain（会在部署日志中显示）。\n\n#### 步骤 5: 配置重定向 URL\n\n回到飞书应用设置：\n1. 进入\"安全设置\"\n2. 添加重定向 URL：`https://feishu-mcp-server.<your-actual-subdomain>.workers.dev/callback`\n\n### 本地开发环境\n\n#### 配置本地环境\n\n1. **配置飞书应用**：\n   - 在飞书应用的\"安全设置\"中添加：`http://localhost:8788/callback`\n   - 确保拥有所需的权限（同生产环境）\n\n2. **创建环境变量文件**：\n   在项目根目录创建 `.dev.vars` 文件：\n   ```\n   FEISHU_APP_ID=your_development_feishu_app_id\n   FEISHU_APP_SECRET=your_development_feishu_app_secret\n   COOKIE_ENCRYPTION_KEY=any_random_string_here\n   ```\n\n#### 启动本地服务器\n\n```bash\nnpm run dev\n```\n\n服务器将在 `http://localhost:8788` 运行。\n\n## 🔌 客户端集成\n\n### 使用 Inspector 测试\n\n使用官方的 MCP Inspector 测试您的服务器：\n\n```bash\nnpx @modelcontextprotocol/inspector@latest\n```\n\n**连接地址**：\n- 生产环境：`https://feishu-mcp-server.<your-subdomain>.workers.dev/sse`\n- 本地环境：`http://localhost:8788/sse`\n\n### 使用 Cursor\n\n通过一键安装按钮快速配置：\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/install-mcp?name=feishu&config=eyJ1cmwiOiJodHRwOi8vbG9jYWxob3N0Ojg3ODgvc3NlIn0%3D)\n\n或手动配置：\n\n```json\n{\n  \"mcpServers\": {\n    \"feishu\": {\n      \"url\": \"http://localhost:8788/sse\"\n    }\n  }\n}\n```\n\n### 使用 ChatWise\n\n1. **配置步骤**：\n   - 打开 ChatWise 设置界面\n   - 导航到工具选项\n   - 新增命令行输入输出（stdio）\n   - 命令：`npx -y mcp-remote ${URL}`\n\n2. **连接地址**：\n   - 本地：`http://localhost:8788/sse`\n   - 生产：`https://feishu-mcp-server.<your-subdomain>.workers.dev/sse`\n\n3. **首次使用**：\n   - 保存配置后会自动打开飞书 OAuth 登录页面\n   - 完成授权即可使用飞书相关功能\n\n## 🔐 访问控制\n\n- **身份验证**：使用飞书 OAuth 进行用户身份验证\n- **权限范围**：所有经过身份验证的飞书用户都可以访问所有工具\n\n## 📋 工具开发路线图\n\n### 🚧 当前开发中 (飞书文档)\n- **🔧开发辅助工具**\n  - ✅ 开发文档内容搜索与召回\n- **📄 文档基础操作**\n  - ✅ 文档块树结构获取\n  - ✅ 获取块类型创建参数 schema\n  - ✅ 创建文档块（支持各种块类型）\n  - ✅ 更新文档块内容\n  - ✅ 批量删除文档块\n- **🔧 文档高级功能**\n  - ✅ 表格创建与操作\n  - ✅ 图片、视频、文件上传与插入\n  - ✅ Markdown 导入功能\n  - ✅ 素材上传与管理\n  - ✅ 文档搜索\n\n### 🎯 未来计划\n- **📊 电子表格（Sheets）**\n  - 📋 工作表基础操作（创建、删除、重命名）\n  - 📋 单元格数据读写\n  - 📋 公式计算与应用\n  - 📋 图表创建与编辑\n  - 📋 数据筛选与排序\n  - 📋 协作与权限管理\n\n- **🗃️ 多维表格（Base/Bitable）**\n  - 📋 数据表基础操作\n  - 📋 记录增删改查\n  - 📋 字段类型管理\n  - 📋 视图创建与配置\n  - 📋 自动化规则设置\n  - 📋 数据导入导出\n\n  ...\n\n**图例**：✅ 已完成 | 🔄 开发中 | 📋 计划中\n\n## 🛠️ 技术原理\n\n### 架构组件\n\n#### OAuth Provider\n完整的 OAuth 2.1 服务器实现，处理：\n- MCP 客户端身份验证\n- 飞书 OAuth 服务连接管理\n- KV 存储中的安全令牌管理\n\n#### Durable MCP\n基于 Cloudflare Durable Objects 的 MCP 扩展：\n- 持久状态管理\n- 身份验证上下文存储\n- 通过 `this.props` 访问用户信息\n- 基于用户身份的条件工具可用性\n\n#### MCP Remote\n支持远程 MCP 客户端连接：\n- 定义客户端-服务器通信协议\n- 提供结构化工具定义方式\n- 处理请求/响应序列化\n- 维护 SSE 连接\n\n## 👨‍💻 开发指南\n\n### MCP 服务器（由 [Cloudflare Workers](https://developers.cloudflare.com/workers/) 提供支持）\n\n本项目实现了双重 OAuth 角色：\n* 对 MCP 客户端充当 OAuth **服务器**\n* 对飞书 OAuth 服务充当 OAuth **客户端**\n\n### 工具开发\n\n当前工具使用用户访问令牌进行身份验证，确保：\n- 安全访问飞书 API\n- 基于用户权限的功能访问\n- 完整的错误处理和日志记录\n\n---\n\n**📝 注意**：确保在部署前正确配置所有环境变量和飞书应用设置。如遇问题，请检查飞书应用权限配置和重定向 URL 设置。\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=ztxtxwd/open-feishu-mcp-server&type=Date)](https://star-history.com/#ztxtxwd/open-feishu-mcp-server&Date)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "protocol",
        "feishu",
        "communication",
        "communication tools",
        "message management",
        "communication integration"
      ],
      "category": "communication"
    }
  }
}