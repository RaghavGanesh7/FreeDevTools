{
  "category": "healthcare-and-medical",
  "categoryDisplay": "Healthcare and Medical",
  "description": "",
  "totalRepositories": 18,
  "repositories": {
    "ChristianHinge--dicom-mcp": {
      "owner": "ChristianHinge",
      "name": "dicom-mcp",
      "url": "https://github.com/ChristianHinge/dicom-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/ChristianHinge.webp",
      "description": "Enables interaction with DICOM servers for querying patient information and analyzing medical imaging metadata. Extracts text from encapsulated PDF documents in DICOM format to enhance clinical report analysis and streamline medical data access.",
      "stars": 66,
      "forks": 21,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T17:50:16Z",
      "readme_content": "# DICOM MCP Server for Medical Imaging Systems ğŸ¥\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Python Version](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)\n [![PyPI Version](https://img.shields.io/pypi/v/dicom-mcp.svg)](https://pypi.org/project/dicom-mcp/) [![PyPI Downloads](https://img.shields.io/pypi/dm/dicom-mcp.svg)](https://pypi.org/project/dicom-mcp/)  \n\nThe `dicom-mcp` server enables AI assistants to query, read, and move data on DICOM servers (PACS, VNA, etc.). \n\n<div align=\"center\">\n\nğŸ¤ **[Contribute](#contributing)** â€¢\nğŸ“ **[Report Bug](https://github.com/ChristianHinge/dicom-mcp/issues)**  â€¢\nğŸ“ **[Blog Post 1](https://www.christianhinge.com/projects/dicom-mcp/)** \n\n</div>\n\n```text\n---------------------------------------------------------------------\nğŸ§‘â€âš•ï¸ User: \"Any significant findings in John Doe's previous CT report?\"\n\nğŸ§  LLM â†’ âš™ï¸ Tools:\n   query_patients â†’ query_studies â†’ query_series â†’ extract_pdf_text_from_dicom\n\nğŸ’¬ LLM Response: \"The report from 2025-03-26 mentions a history of splenomegaly (enlarged spleen)\"\n\nğŸ§‘â€âš•ï¸ User: \"What's the volume of his spleen at the last scan and the scan today?\"\n\nğŸ§  LLM â†’ âš™ï¸ Tools:\n   (query_studies â†’ query_series â†’ move_series â†’ query_series â†’ extract_pdf_text_from_dicom) x2\n   (The move_series tool sends the latest CT to a DICOM segmentation node, which returns volume PDF report)\n\nğŸ’¬ LLM Response: \"last year 2024-03-26: 412cmÂ³, today 2025-04-10: 350cmÂ³\"\n---------------------------------------------------------------------\n```\n\n\n## âœ¨ Core Capabilities\n\n`dicom-mcp` provides tools to:\n\n* **ğŸ” Query Metadata**: Search for patients, studies, series, and instances using various criteria.\n* **ğŸ“„ Read DICOM Reports (PDF)**: Retrieve DICOM instances containing encapsulated PDFs (e.g., clinical reports) and extract the text content.\n* **â¡ï¸ Send DICOM Images**: Send series or studies to other DICOM destinations, e.g. AI endpoints for image segmentation, classification, etc.\n* **âš™ï¸ Utilities**: Manage connections and understand query options.\n\n## ğŸš€ Quick Start\n### ğŸ“¥ Installation\nInstall using uv or pip:\n\n```bash\nuv tool install dicom-mcp\n```\nOr by cloning the repository:\n\n```bash\n# Clone and set up development environment\ngit clone https://github.com/ChristianHinge/dicom-mcp\ncd dicom mcp\n\n# Create and activate virtual environment\nuv venv\nsource .venv/bin/activate\n\n# Install with test dependencies\nuv pip install -e \".[dev]\"\n```\n\n\n### âš™ï¸ Configuration\n\n`dicom-mcp` requires a YAML configuration file (`config.yaml` or similar) defining DICOM nodes and calling AE titles. Adapt the configuration or keep as is for compatibility with the sample ORTHANC  Server.\n\n```yaml\nnodes:\n  main:\n    host: \"localhost\"\n    port: 4242 \n    ae_title: \"ORTHANC\"\n    description: \"Local Orthanc DICOM server\"\n\ncurrent_node: \"main\"\ncalling_aet: \"MCPSCU\" \n```\n> [!WARNING]\nDICOM-MCP is not meant for clinical use, and should not be connected with live hospital databases or databases with patient-sensitive data. Doing so could lead to both loss of patient data, and leakage of patient data onto the internet. DICOM-MCP can be used with locally hosted open-weight LLMs for complete data privacy. \n\n### (Optional) Sample ORTHANC server\nIf you don't have a DICOM server available, you can run a local ORTHANC server using Docker:\n\nClone the repository and install test dependencies `pip install -e \".[dev]`\n\n```bash\ncd tests\ndocker ocmpose up -d\ncd ..\npytest # uploads dummy pdf data to ORTHANC server\n```\nUI at [http://localhost:8042](http://localhost:8042)\n\n### ğŸ”Œ MCP Integration\n\nAdd to your client configuration (e.g. `claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"dicom\": {\n      \"command\": \"uv\",\n      \"args\": [\"tool\",\"dicom-mcp\", \"/path/to/your_config.yaml\"]\n    }\n  }\n}\n```\n\nFor development:\n\n```json\n{\n    \"mcpServers\": {\n        \"arxiv-mcp-server\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"path/to/cloned/dicom-mcp\",\n                \"run\",\n                \"dicom-mcp\",\n                \"/path/to/your_config.yaml\"\n            ]\n        }\n    }\n}\n```\n\n\n## ğŸ› ï¸ Tools Overview\n\n`dicom-mcp` provides four categories of tools for interaction with DICOM servers and DICOM data. \n\n### ğŸ” Query Metadata\n\n* **`query_patients`**: Search for patients based on criteria like name, ID, or birth date.\n* **`query_studies`**: Find studies using patient ID, date, modality, description, accession number, or Study UID.\n* **`query_series`**: Locate series within a specific study using modality, series number/description, or Series UID.\n* **`query_instances`**: Find individual instances (images/objects) within a series using instance number or SOP Instance UID\n### ğŸ“„ Read DICOM Reports (PDF)\n\n* **`extract_pdf_text_from_dicom`**: Retrieve a specific DICOM instance containing an encapsulated PDF and extract its text content.\n\n### â¡ï¸ Send DICOM Images\n\n* **`move_series`**: Send a specific DICOM series to another configured DICOM node using C-MOVE.\n* **`move_study`**: Send an entire DICOM study to another configured DICOM node using C-MOVE.\n\n### âš™ï¸ Utilities\n\n* **`list_dicom_nodes`**: Show the currently active DICOM node and list all configured nodes.\n* **`switch_dicom_node`**: Change the active DICOM node for subsequent operations.\n* **`verify_connection`**: Test the DICOM network connection to the currently active node using C-ECHO.\n* **`get_attribute_presets`**: List the available levels of detail (minimal, standard, extended) for metadata query results.<p>\n\n\n### Example interaction\nThe tools can be chained together to answer complex questions:\n\n\n<div align=\"center\">\n<img src=\"images/example.png\" alt=\"My Awesome Diagram\" width=\"700\">\n</div>\n\n\n## ğŸ“ˆ Contributing\n### Running Tests\n\nTests require a running Orthanc DICOM server. You can use Docker:\n\n```bash\n# Navigate to the directory containing docker-compose.yml (e.g., tests/)\ncd tests\ndocker-compose up -d\n```\n\nRun tests using pytest:\n\n```bash\n# From the project root directory\npytest\n```\n\nStop the Orthanc container:\n\n```bash\ncd tests\ndocker-compose down\n```\n\n### Debugging\n\nUse the MCP Inspector for debugging the server communication:\n\n```bash\nnpx @modelcontextprotocol/inspector uv run dicom-mcp /path/to/your_config.yaml --transport stdio\n```\n\n## ğŸ™ Acknowledgments\n\n* Built using [pynetdicom](https://github.com/pydicom/pynetdicom)\n* Uses [PyPDF2](https://pypi.org/project/PyPDF2/) for PDF text extraction\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "dicom",
        "clinical",
        "medical",
        "documents dicom",
        "dicom format",
        "dicom mcp"
      ],
      "category": "healthcare-and-medical"
    },
    "HealthNoteLabs--Npub.Health": {
      "owner": "HealthNoteLabs",
      "name": "Npub.Health",
      "url": "https://github.com/HealthNoteLabs/Npub.Health",
      "imageUrl": "/freedevtools/mcp/pfp/HealthNoteLabs.webp",
      "description": "Manage health records securely with a user-controlled platform, enabling selective sharing of health data while maintaining privacy through end-to-end encryption.",
      "stars": 2,
      "forks": 1,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-07-30T16:46:32Z",
      "readme_content": "# Npub.Health\n\nA decentralized health records platform built on Nostr protocol.\n\n## Project Overview\n\nNpub.Health provides a secure, user-controlled platform for managing health data using the Nostr protocol. This application gives individuals ownership over their health information while enabling selective sharing with healthcare providers.\n\n## Features\n\n- Secure health record storage using Nostr protocol\n- User-controlled data sharing and permissions\n- Provider verification system\n- Cross-platform support (web, mobile)\n- End-to-end encryption for sensitive health data\n\n## Tech Stack\n\n- **Frontend**: React, TypeScript, TailwindCSS\n- **Backend**: Node.js\n- **Database**: SQLite with Drizzle ORM\n- **Protocol**: Nostr\n\n## Getting Started\n\n### Prerequisites\n\n- Node.js v18 or higher\n- npm or yarn\n\n### Installation\n\n1. Clone the repository\n   ```bash\n   git clone https://github.com/HealthNoteLabs/Npub.Health.git\n   cd Npub.Health\n   ```\n\n2. Install dependencies\n   ```bash\n   npm install\n   ```\n\n3. Set up environment variables\n   ```bash\n   cp .env.example .env\n   # Edit .env with your configuration\n   ```\n\n4. Start the development server\n   ```bash\n   npm run dev\n   ```\n\n### Project Structure\n\n```\nNpub.Health/\nâ”œâ”€â”€ client/           # Frontend React application\nâ”œâ”€â”€ server/           # Backend Node.js server\nâ”œâ”€â”€ shared/           # Shared utilities and types\nâ”œâ”€â”€ scripts/          # Utility scripts\nâ””â”€â”€ ...\n```\n\n## Development\n\n### Running the app in development mode\n\n```bash\nnpm run dev\n```\n\n### Building for production\n\n```bash\nnpm run build\n```\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Contact\n\nFor any questions or feedback, please open an issue on this repository.\n\n## AWS Integration for Blossom Server Deployment\n\nThis project includes AWS integration to automatically deploy Blossom servers for users. The implementation allows users to create their own private Blossom servers on AWS EC2 instances.\n\n### Setup Steps\n\n1. **Install AWS SDK**:\n   ```\n   npm install @aws-sdk/client-ec2\n   ```\n\n2. **Create Security Groups**:\n   The `scripts/create_aws_security_groups.js` script will create the necessary security groups in each AWS region:\n   ```\n   node scripts/create_aws_security_groups.js\n   ```\n   Make sure to update the VPC ID in the script for each region.\n\n3. **Configure AWS Credentials**:\n   Create a `.env` file with the following variables:\n   ```\n   AWS_ACCESS_KEY_ID=your_access_key_id\n   AWS_SECRET_ACCESS_KEY=your_secret_access_key\n   \n   # Security Groups for each region (output from the script)\n   SECURITY_GROUP_US_EAST=sg-xxxxxxxxxxxxxxxx\n   SECURITY_GROUP_US_WEST=sg-xxxxxxxxxxxxxxxx\n   SECURITY_GROUP_EU_CENTRAL=sg-xxxxxxxxxxxxxxxx\n   SECURITY_GROUP_AP_SOUTHEAST=sg-xxxxxxxxxxxxxxxx\n   \n   # Database URL\n   DATABASE_URL=postgres://postgres:postgres@localhost:5432/npubhealth\n   ```\n\n4. **Set up PostgreSQL database**:\n   Follow these steps to set up the database:\n   - Install PostgreSQL\n   - Create a database named `npubhealth`\n   - Run migrations to create tables:\n     ```\n     npm run db:push\n     ```\n\n5. **Test the integration**:\n   ```\n   npm run dev\n   ```\n\n### Architecture\n\nThe AWS integration consists of:\n\n1. **EC2 Manager** (`server/aws/ec2Manager.ts`): Handles creating and checking EC2 instances.\n2. **Server Monitor** (`server/aws/serverMonitor.ts`): Periodically checks and updates server status.\n3. **API Endpoints** (`server/routes.ts`): Provides REST endpoints for server management.\n4. **Database Integration** (`server/db`): Persists server information and status.\n\n### User Flow\n\n1. User selects a server tier, region, and name\n2. System generates a payment address\n3. User sends payment (simulated in development)\n4. System deploys an EC2 instance with the Blossom server installation script\n5. UI polls for server status until it's running\n6. User connects to their personal Blossom server\n\n### Security Considerations\n\n- The security groups allow HTTP, HTTPS, and the Blossom server port (3000)\n- SSH access should be restricted to specific IPs in production\n- AWS credentials should have limited permissions following the principle of least privilege\n- For production, consider using IAM roles instead of credentials\n\n### Troubleshooting\n\nIf you encounter issues:\n\n1. Check AWS credentials and permissions\n2. Verify that security groups are properly configured\n3. Look at server logs for deployment errors\n4. Check the database for server status information\n\nFor more information about the AWS SDK, refer to the [official documentation](https://docs.aws.amazon.com/sdk-for-javascript/v3/developer-guide/welcome.html). ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "healthnotelabs",
        "npub",
        "healthcare",
        "healthnotelabs npub",
        "npub health",
        "medical healthnotelabs"
      ],
      "category": "healthcare-and-medical"
    },
    "JackKuo666--ClinicalTrials-MCP-Server": {
      "owner": "JackKuo666",
      "name": "ClinicalTrials-MCP-Server",
      "url": "https://github.com/JackKuo666/ClinicalTrials-MCP-Server",
      "imageUrl": "/freedevtools/mcp/pfp/JackKuo666.webp",
      "description": "Connects to ClinicalTrials.gov to search for and access detailed clinical trial information programmatically, facilitating efficient data retrieval for health sciences research and analysis.",
      "stars": 13,
      "forks": 7,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-02T06:11:52Z",
      "readme_content": "# ClinicalTrials MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@JackKuo666/clinicaltrials-mcp-server)](https://smithery.ai/server/@JackKuo666/clinicaltrials-mcp-server)\n\nğŸ” Enable AI assistants to search and access ClinicalTrials.gov data through a simple MCP interface.\n\nThe ClinicalTrials MCP Server provides a bridge between AI assistants and ClinicalTrials.gov's clinical trial repository through the Model Context Protocol (MCP). It allows AI models to search for clinical trials and access their content in a programmatic way.\n\nğŸ¤ Contribute â€¢ ğŸ“ Report Bug\n\n## âœ¨ Core Features\n- ğŸ” Trial Search: Query clinical trials with custom search strings or advanced search parameters âœ…\n- ğŸš€ Efficient Retrieval: Fast access to trial metadata âœ…\n- ğŸ“Š Metadata Access: Retrieve detailed metadata for specific trials using NCT ID âœ…\n- ğŸ“Š Research Support: Facilitate health sciences research and analysis âœ…\n- ğŸ“‹ CSV Management: Save, load, and list CSV files with trial data âœ…\n- ğŸ—ƒï¸ Local Storage: Trials are saved locally for faster access âœ…\n- ğŸ“Š Statistics: Get statistics about clinical trials âœ…\n\n## ğŸš€ Quick Start\n\n### Installing via Smithery\n\nTo install ClinicalTrials Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/ClinicalTrials-mcp-server):\n\n#### Claude\n\n```bash\nnpx -y @smithery/cli@latest install ClinicalTrials-mcp-server --client claude --config \"{}\"\n```\n\n#### Cursor\n\nPaste the following into Settings â†’ Cursor Settings â†’ MCP â†’ Add new server: \n- Mac/Linux  \n```s\nnpx -y @smithery/cli@latest run ClinicalTrials-mcp-server --client cursor --config \"{}\" \n```\n#### Windsurf\n```sh\nnpx -y @smithery/cli@latest install ClinicalTrials-mcp-server --client windsurf --config \"{}\"\n```\n### CLine\n```sh\nnpx -y @smithery/cli@latest install ClinicalTrials-mcp-server --client cline --config \"{}\"\n```\n\n\n### Installing Manually\nInstall using uv:\n\n```bash\nuv tool install ClinicalTrials-mcp-server\n```\n\nFor development:\n\n```bash\n# Clone and set up development environment\ngit clone https://github.com/JackKuo666/ClinicalTrials-MCP-Server.git\ncd ClinicalTrials-MCP-Server\n\n# Create and activate virtual environment\nuv venv\nsource .venv/bin/activate\nuv pip install -r requirements.txt\n```\n\n## ğŸ“Š Usage\n\nStart the MCP server:\n\n```bash\npython clinical_trials_server.py\n```\n\nOnce the server is running, you can use the provided MCP tools in your AI assistant or application. Here are some examples of how to use the tools:\n\n### Example 1: Search for clinical trials using a search expression and save to CSV\n\n```python\nresult = await mcp.use_tool(\"search_clinical_trials_and_save_studies_to_csv\", {\n    \"search_expr\": \"COVID-19 vaccine efficacy\",\n    \"max_studies\": 5\n})\nprint(result)\n```\n\n### Example 2: Get studies by keyword\n\n```python\nresult = await mcp.use_tool(\"get_studies_by_keyword\", {\n    \"keyword\": \"diabetes\",\n    \"max_studies\": 10\n})\nprint(result)\n```\n\n### Example 3: Get full study details for a specific trial\n\n```python\nresult = await mcp.use_tool(\"get_full_study_details\", {\n    \"nct_id\": \"NCT04280705\"\n})\nprint(result)\n```\n\n### Example 4: Search and save studies with custom fields\n\n```python\nresult = await mcp.use_tool(\"search_clinical_trials_and_save_studies_to_csv\", {\n    \"search_expr\": \"alzheimer\",\n    \"max_studies\": 20,\n    \"filename\": \"alzheimer_studies.csv\",\n    \"fields\": [\"NCT Number\", \"Study Title\", \"Brief Summary\", \"Conditions\"]\n})\nprint(result)\n```\n\nThese examples demonstrate how to use the main tools provided by the ClinicalTrials MCP Server. Adjust the parameters as needed for your specific use case.\n\n## ğŸ›  MCP Tools\n\nThe ClinicalTrials MCP Server provides the following tools:\n\n### search_clinical_trials_and_save_studies_to_csv\n\nSearch for clinical trials using a search expression and save the results to a CSV file.\n\n**Parameters:**\n- `search_expr` (str): Search expression (e.g., \"Coronavirus+COVID\")\n- `max_studies` (int, optional): Maximum number of studies to return (default: 10)\n- `save_csv` (bool, optional): Whether to save the results as a CSV file (default: True)\n- `filename` (str, optional): Name of the CSV file to save (default: corona_fields.csv)\n- `fields` (list, optional): List of fields to include (default: NCT Number, Conditions, Study Title, Brief Summary)\n\n**Returns:** String representation of the search results\n\n### get_full_study_details\n\nGet detailed information about a specific clinical trial.\n\n**Parameters:**\n- `nct_id` (str): The NCT ID of the clinical trial\n\n**Returns:** String representation of the study details\n\n### get_studies_by_keyword\n\nGet studies related to a specific keyword.\n\n**Parameters:**\n- `keyword` (str): Keyword to search for\n- `max_studies` (int, optional): Maximum number of studies to return (default: 20)\n- `save_csv` (bool, optional): Whether to save the results as a CSV file (default: True)\n- `filename` (str, optional): Name of the CSV file to save (default: keyword_results_{keyword}.csv)\n\n**Returns:** String representation of the studies\n\n### get_study_statistics\n\nGet statistics about clinical trials.\n\n**Parameters:**\n- `condition` (str, optional): Optional condition to filter by\n\n**Returns:** String representation of the statistics\n\n### get_full_studies_and_save\n\nGet full studies data and save to CSV.\n\n**Parameters:**\n- `search_expr` (str): Search expression (e.g., \"Coronavirus+COVID\")\n- `max_studies` (int, optional): Maximum number of studies to return (default: 20)\n- `filename` (str, optional): Name of the CSV file to save (default: full_studies.csv)\n\n**Returns:** Message indicating the results were saved\n\n### load_csv_data\n\nLoad and display data from a CSV file.\n\n**Parameters:**\n- `filename` (str): Name of the CSV file to load\n\n**Returns:** String representation of the CSV data\n\n### list_saved_csv_files\n\nList all available CSV files in the current directory.\n\n**Returns:** String representation of the available CSV files\n\n## ğŸ” MCP Resources\n\nThe ClinicalTrials MCP Server also provides the following resources:\n\n### clinicaltrials://corona_fields\n\nGet the corona fields data as a resource.\n\n### clinicaltrials://full_studies\n\nGet the full studies data as a resource.\n\n### clinicaltrials://csv/{filename}\n\nGet data from a specific CSV file.\n\n**Parameters:**\n- `filename` (str): Name of the CSV file\n\n### clinicaltrials://available_files\n\nGet a list of all available CSV files.\n\n### clinicaltrials://study/{nct_id}\n\nGet a specific study by NCT ID.\n\n**Parameters:**\n- `nct_id` (str): The NCT ID of the clinical trial\n\n### clinicaltrials://condition/{condition}\n\nGet studies related to a specific condition.\n\n**Parameters:**\n- `condition` (str): The condition to search for\n\n## Usage with Claude Desktop\n\nAdd this configuration to your `claude_desktop_config.json`:\n\n(Mac OS)\n\n```json\n{\n  \"mcpServers\": {\n    \"ClinicalTrials\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"ClinicalTrials-mcp-server\"]\n      }\n  }\n}\n```\n\n(Windows version):\n\n```json\n{\n  \"mcpServers\": {\n    \"ClinicalTrials\": {\n      \"command\": \"C:\\\\Users\\\\YOUR_USERNAME\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe\",\n      \"args\": [\n        \"-m\",\n        \"ClinicalTrials-mcp-server\"\n      ]\n    }\n  }\n}\n```\nUsing with Cline\n```json\n{\n  \"mcpServers\": {\n    \"ClinicalTrials\": {\n      \"command\": \"bash\",\n      \"args\": [\n        \"-c\",\n        \"source /home/YOUR/PATH/ClinicalTrials-MCP-Server/.venv/bin/activate && python /home/YOUR/PATH/ClinicalTrials-MCP-Server/clinical_trials_server.py\"\n      ],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\nAfter restarting Claude Desktop, the following capabilities will be available:\n\n### Searching Clinical Trials\n\nYou can ask Claude to search for clinical trials using queries like:\n```\nCan you search for recent clinical trials about diabetes?\n```\n\nThe search will return basic information about matching trials including:\n\nâ€¢ Trial title\n\nâ€¢ NCT Number\n\nâ€¢ Conditions\n\nâ€¢ Brief Summary\n\n\n### Getting Trial Details\n\nOnce you have an NCT ID, you can ask for more details:\n```\nCan you show me the details for trial NCT04280705?\n```\n\nThis will return:\n\nâ€¢ Full trial title\n\nâ€¢ Conditions\n\nâ€¢ Brief Summary\n\nâ€¢ Other available details\n\n\n## ğŸ“ Project Structure\n\n- `clinical_trials_server.py`: The main MCP server implementation using FastMCP\n- `clinical_trials.py`: Contains helper functions for interacting with the ClinicalTrials.gov API\n\n## ğŸ”§ Dependencies\n\n- Python 3.10+\n- FastMCP\n- pytrials\n- pandas\n\nYou can install the required dependencies using:\n\n```bash\npip install FastMCP pytrials pandas\n```\n\n## ğŸ¤ Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## ğŸ“„ License\n\nThis project is licensed under the MIT License.\n\n## âš ï¸ Disclaimer\n\nThis tool is for research purposes only. Please respect ClinicalTrials.gov's terms of service and use this tool responsibly.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "clinical",
        "clinicaltrials",
        "mcp",
        "jackkuo666 clinicaltrials",
        "clinicaltrials mcp",
        "medical jackkuo666"
      ],
      "category": "healthcare-and-medical"
    },
    "NitayRabi--fitbit-mcp": {
      "owner": "NitayRabi",
      "name": "fitbit-mcp",
      "url": "https://github.com/NitayRabi/fitbit-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/NitayRabi.webp",
      "description": "Enables access and analysis of Fitbit health and fitness data, including activities, sleep logs, heart rate, steps, and body measurements through simple commands. Facilitates integration of Fitbit data insights into AI interactions.",
      "stars": 6,
      "forks": 2,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-19T18:39:25Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/nitayrabi-fitbit-mcp-badge.png)](https://mseep.ai/app/nitayrabi-fitbit-mcp)\n\n# Fitbit MCP (Model Context Protocol)\n[![smithery badge](https://smithery.ai/badge/@NitayRabi/fitbit-mcp)](https://smithery.ai/server/@NitayRabi/fitbit-mcp)\n\n**Disclaimer:** This is an unofficial integration built using Fitbit's public API and is not affiliated with or endorsed by Fitbit Inc.\n\nA Model Context Protocol (MCP) implementation for Fitbit, enabling AI assistants to access and analyze your Fitbit health and fitness data.\n\n## Usage\n\nFor JSON configuration (for use with AI assistant frameworks):\n\n```json\n{\n  \"command\": \"npx\",\n  \"args\": [\"-y\", \"fitbit-mcp\", \"--stdio\"],\n  \"env\": {\n    \"FITBIT_ACCESS_TOKEN\": \"YOUR_FITBIT_ACCESS_TOKEN\"\n  }\n}\n```\n\nOr with arguments instead of environment variables:\n\n```json\n{\n  \"command\": \"npx\",\n  \"args\": [\"-y\", \"fitbit-mcp\", \"--stdio\", \"--fitbit-token=YOUR_FITBIT_ACCESS_TOKEN\"]\n}\n```\n\n## Available Tools\n\nThis MCP provides the following tools for AI assistants to access your Fitbit data:\n\n- **getUserProfile**: Get your Fitbit profile information\n- **getActivities**: Get activity data for a specified date\n- **getSleepLogs**: Get sleep data for a specified date\n- **getHeartRate**: Get heart rate data for a specified date and period\n- **getSteps**: Get step count for a specified date and period\n- **getBodyMeasurements**: Get weight and body fat data\n- **getFoodLogs**: Get food log data for a specified date\n- **getWaterLogs**: Get water consumption data for a specified date\n- **getLifetimeStats**: Get lifetime activity statistics\n- **getUserSettings**: Get user settings and preferences\n- **getFloorsClimbed**: Get floors climbed data\n- **getDistance**: Get distance data\n- **getCalories**: Get calories burned data\n- **getActiveZoneMinutes**: Get active zone minutes data\n- **getDevices**: Get information about connected Fitbit devices\n- **getBadges**: Get earned badges and achievements\n\nMost tools accept optional parameters:\n- `date`: Date in YYYY-MM-DD format (defaults to today)\n- `period`: Time period for data (1d, 7d, 30d, 1w, 1m)\n\n## Obtaining a Fitbit Access Token\n\nTo get a Fitbit access token:\n\n1. Create an application at [Fitbit Developer Portal](https://dev.fitbit.com/apps/new)\n2. Set OAuth 2.0 Application Type to \"Personal\"\n3. Set Callback URL to \"http://localhost:3000\"\n4. After creating the application, note your Client ID and Client Secret\n5. Use the OAuth 2.0 authorization flow to obtain an access token\n\nFor detailed instructions on OAuth authentication, see the [Fitbit API Documentation](https://dev.fitbit.com/build/reference/web-api/oauth2/).\n\n## Contributing\n\nContributions are welcome! Here's how you can contribute:\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\nEvery pull request triggers a GitHub Actions workflow that verifies the build process.\n\n### Development Setup\n\n```bash\n# Clone the repository\ngit clone https://github.com/your-username/fitbit-mcp.git\ncd fitbit-mcp\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n\n# Run in development mode\nnpm run dev\n```\n\n### Release Process\n\nTo publish a new version to NPM:\n\n1. Update the version in `package.json`\n2. Create a new GitHub release with a tag like `v1.0.1`\n3. The GitHub Actions workflow will automatically build and publish the package to NPM\n\nMake sure you have the `NPM_TOKEN` secret configured in your GitHub repository settings.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "fitbit",
        "fitness",
        "nitayrabi",
        "fitbit health",
        "nitayrabi fitbit",
        "fitbit mcp"
      ],
      "category": "healthcare-and-medical"
    },
    "Wendong-Fan--HowToLiveLonger": {
      "owner": "Wendong-Fan",
      "name": "HowToLiveLonger",
      "url": "https://github.com/Wendong-Fan/HowToLiveLonger",
      "imageUrl": "/freedevtools/mcp/pfp/Wendong-Fan.webp",
      "description": "Provides evidence-based lifestyle insights aimed at improving longevity through nutrition, exercise, and wellness practices. Users can explore actionable recommendations to reduce mortality risk.",
      "stars": 13,
      "forks": 0,
      "license": "The Unlicense",
      "language": "",
      "updated_at": "2025-09-11T07:34:26Z",
      "readme_content": "# ç¨‹åºå‘˜å»¶å¯¿æŒ‡å—\n\n[![CN doc](https://img.shields.io/badge/æ–‡æ¡£-ä¸­æ–‡ç‰ˆ-blue.svg)](README.md)\n[![EN doc](https://img.shields.io/badge/document-English-blue.svg)](README_en.md)\n[![MetaGPT](https://img.shields.io/badge/å‡å°‘å·¥ä½œæ—¶é—´-MetaGPT-blue)](https://github.com/geekan/MetaGPT)\n\n\n- [1. æœ¯è¯­](#1-æœ¯è¯­)\n- [2. ç›®æ ‡](#2-ç›®æ ‡)\n- [3. å…³é”®ç»“æœ](#3-å…³é”®ç»“æœ)\n- [4. åˆ†æ](#4-åˆ†æ)\n- [5. è¡ŒåŠ¨](#5-è¡ŒåŠ¨)\n- [6. è¯æ®](#6-è¯æ®)\n  - [6.1. è¾“å…¥](#61-è¾“å…¥)\n    - [6.1.1. å›ºä½“](#611-å›ºä½“)\n    - [6.1.2. æ¶²ä½“](#612-æ¶²ä½“)\n    - [6.1.3. æ°”ä½“](#613-æ°”ä½“)\n    - [6.1.4. å…‰ç…§](#614-å…‰ç…§)\n    - [6.1.5. è¯ç‰©](#615-è¯ç‰©)\n  - [6.2. è¾“å‡º](#62-è¾“å‡º)\n    - [6.2.1. æŒ¥æ‹è¿åŠ¨](#621-æŒ¥æ‹è¿åŠ¨)\n    - [6.2.2. å‰§çƒˆè¿åŠ¨](#622-å‰§çƒˆè¿åŠ¨)\n    - [6.2.3. èµ°è·¯](#623-èµ°è·¯)\n    - [6.2.4. åˆ·ç‰™](#624-åˆ·ç‰™)\n    - [6.2.5. æ³¡æ¾¡](#625-æ³¡æ¾¡)\n    - [6.2.6. åšå®¶åŠ¡ï¼ˆè€å¹´ç”·æ€§ï¼‰](#626-åšå®¶åŠ¡è€å¹´ç”·æ€§)\n    - [6.2.7. ç¡çœ ](#627-ç¡çœ )\n    - [6.2.8. ä¹…å](#628-ä¹…å)\n  - [6.3. ä¸Šä¸‹æ–‡](#63-ä¸Šä¸‹æ–‡)\n    - [6.3.1. æƒ…ç»ª](#631-æƒ…ç»ª)\n    - [6.3.2. è´«å¯Œ](#632-è´«å¯Œ)\n    - [6.3.3. ä½“é‡](#633-ä½“é‡)\n    - [6.3.4. æ–°å† ](#634-æ–°å† )\n\n---\n\n### 1. æœ¯è¯­\n\n* ACM: All-Cause Mortality / å…¨å› æ­»äº¡ç‡\n\n### 2. ç›®æ ‡\n\n* ç¨³å¥çš„æ´»å¾—æ›´ä¹…\n* èŠ±æ›´å°‘æ—¶é—´å·¥ä½œï¼šè§[MetaGPT](https://github.com/geekan/MetaGPT)\n\n### 3. å…³é”®ç»“æœ\n\n* é™ä½66.67%å…¨å› æ­»äº¡ç‡\n* å¢åŠ \\~20å¹´é¢„æœŸå¯¿å‘½\n* ~~ç»´æŒå¤šå·´èƒºäºä¸­è½´~~\n\n### 4. åˆ†æ\n\n* ä¸»è¦å‚è€ƒï¼šå¯¹ACMçš„å­¦æœ¯æ–‡çŒ®ç›¸å¯¹è¾ƒå¤šï¼Œå¯ä»¥ä½œä¸ºä¸»è¦å‚è€ƒ\n* å¢åŠ å¯¿å‘½ä¸ACMå…³ç³»éçº¿æ€§ï¼šæ˜¾ç„¶å¢åŠ å¯¿å‘½ä¸ACMå…³ç³»æ˜¯éçº¿æ€§å‡½æ•°ï¼Œè¿™é‡Œå‡è®¾ `Î”LifeSpan=(1/(1+Î”ACM)-1)*10`ï¼ˆÎ”ACMä¸ºACMå˜åŒ–å€¼ï¼›å…¬å¼æ¬¢è¿ä¼˜åŒ–ï¼‰\n* å˜é‡æ— æ³•ç®€å•å åŠ ï¼šæ˜¾ç„¶å„ä¸ªå˜é‡ä¹‹é—´å¹¶ä¸ç¬¦åˆç‹¬ç«‹åŒåˆ†å¸ƒå‡è®¾ï¼Œå˜é‡ä¹‹é—´çš„å®é™…å½±å“ä¹Ÿå¹¶ä¸æ˜ç¡®\n* å­˜åœ¨çŸ›ç›¾è§‚ç‚¹ï¼šæ‰€æœ‰çš„è¯æ®éƒ½æœ‰æ–‡çŒ®/ç ”ç©¶å¯¹åº”ï¼Œä½†æ³¨æ„åˆ°ï¼šæœ‰äº›æ–‡çŒ®ä¹‹é—´æœ‰æ˜¾è‘—çŸ›ç›¾çš„è§‚ç‚¹ï¼ˆå¦‚å¯¹äºç¢³æ°´æ‘„å…¥æ¯”ä¾‹çš„çŸ›ç›¾ï¼‰ï¼›æœ‰äº›æ–‡çŒ®å­˜åœ¨è¾ƒå¤§äº‰è®®ï¼ˆå¦‚è®¤ä¸º22ç‚¹å‰ç¡è§‰ä¼šæå‡43%å…¨å› æ­»äº¡ç‡ï¼‰\n* ç ”ç©¶ä»…è¡¨è¾¾ç›¸å…³ï¼šæ‰€æœ‰æ–‡çŒ®è¡¨æ˜çš„æ›´å¤šæ˜¯ç›¸å…³è€Œéå› æœï¼Œåœ¨é˜…è¯»æ—¶è¦è€ƒè™‘æ–‡çŒ®æ˜¯å¦å……åˆ†è¯æ˜äº†å› æœ â€”â€” å¦‚æŸæ–‡çŒ®è¡¨æ˜äº†æ—¥å‡>=7000æ­¥çš„äººæœ‰æ˜¾è‘—ä½çš„å…¨å› æ­»äº¡ç‡ã€‚ä½†æ­¥æ•°å°‘çš„äººå¯èƒ½åŒ…å«æ›´å¤šé•¿æœŸç—…æ‚£ï¼Œå¦‚æœæ²¡æœ‰åˆç†çš„æ’é™¤è¿™å—æ•°æ®ï¼Œé‚£æ­¤æ–‡çŒ®è°ƒæŸ¥å¤±çœŸ\n\n### 5. è¡ŒåŠ¨\n\n* è¾“å…¥\n  * å›ºä½“ï¼šåƒç™½è‚‰ï¼ˆ-11%\\~-3% ACMï¼‰ã€è”¬æœä¸ºä¸»ï¼ˆ-26%\\~-17% ACMï¼‰ï¼Œå¤šåƒè¾£ï¼ˆ-23% ACMï¼‰ï¼Œå¤šåƒåšæœï¼ˆ-27%\\~-4% ACMï¼‰ï¼Œä¸­é‡ç¢³æ°´ã€å¤šåƒæ¤ç‰©è›‹ç™½ï¼ˆ-10% ACMï¼‰ï¼Œå°‘åƒè¶…åŠ å·¥é£Ÿç‰©ï¼ˆ-62%\\~-18%ï¼‰\n  * æ¶²ä½“ï¼šå–å’–å•¡ï¼ˆ-22%\\~-12% ACMï¼‰ï¼Œå–ç‰›å¥¶ï¼ˆ-17%\\~-10% ACMï¼‰ï¼Œå–èŒ¶ï¼ˆ-15%\\~-8% ACMï¼‰ï¼Œå°‘å–æˆ–ä¸å–ç”œå‘³é¥®æ–™ï¼ˆå¦åˆ™æ¯å¤©ä¸€æ¯+7% ACMï¼Œ+å¤šå·´èƒºï¼‰ï¼Œæˆ’é…’ï¼ˆå¦åˆ™+\\~50% ACMï¼Œæ— ä¸Šé™ï¼‰\n  * æ°”ä½“ï¼šä¸å¸çƒŸï¼ˆå¦åˆ™+~50% ACMï¼Œ-12\\~-11å¹´å¯¿å‘½ï¼‰\n  * å…‰ç…§ï¼šæ™’å¤ªé˜³ï¼ˆ-~40% ACMï¼‰\n  * è¯ç‰©ï¼šäºŒç”²åŒèƒï¼ˆç³–å°¿ç—…äººç›¸æ¯”æ­£å¸¸äººå¯ä»¥+3å¹´ï¼‰ã€å¤åˆç»´ç”Ÿç´ ï¼ˆ-8%ç™Œç—‡é£é™©ï¼‰ã€äºšç²¾èƒºï¼ˆ-60%\\~-30% ACMï¼‰ã€è‘¡è„ç³–èƒºï¼ˆ-39% ACMï¼‰\n* è¾“å‡º\n  * è¿åŠ¨ï¼šæ¯å‘¨3æ¬¡45åˆ†é’ŸæŒ¥æ‹è¿åŠ¨ï¼ˆ-47% ACMï¼‰\n  * æ—¥å¸¸ï¼šåˆ·ç‰™ï¼ˆ-25% ACMï¼‰\n  * ç¡çœ ï¼šæ¯å¤©ç¡7å°æ—¶å…¨å› æ­»äº¡ç‡æœ€ä½ï¼›ä¸”22-24ç‚¹é—´æœ€å¥½ï¼Œ*æ—©ç¡+43% ACMï¼Œæ™šç¡+15% ACMï¼ˆå­˜åœ¨äº‰è®®ï¼‰*\n* ä¸Šä¸‹æ–‡\n  * ä½“é‡ï¼šå‡è‚¥ï¼ˆ-54% ACMï¼‰\n\n### 6. è¯æ®\n\n#### 6.1. è¾“å…¥\n\n##### 6.1.1. å›ºä½“\n\n* ç™½è‚‰\n  * [JAMAå­åˆŠï¼šé£Ÿç”¨çº¢è‚‰å’ŒåŠ å·¥è‚‰ç±»ä¼šå¢åŠ å¿ƒè„ç—…å’Œæ­»äº¡é£é™©ï¼é±¼è‚‰å’Œå®¶ç¦½è‚‰åˆ™ä¸ä¼š](https://zhuanlan.zhihu.com/p/268401670)\n    * å‡ºå¤„ï¼š[Associations of Processed Meat, Unprocessed Red Meat, Poultry, or Fish Intake With Incident Cardiovascular Disease and All-Cause Mortality](https://jamanetwork.com/journals/jamainternalmedicine/articlepdf/2759737/jamainternal_zhong_2020_oi_190112.pdf)\n    * å¢åŠ çº¢è‚‰æ‘„å…¥ä¸æ­»äº¡é£é™©ç›¸å…³ã€‚å…«å¹´å†…å¹³å‡æ¯å¤©å¢åŠ è‡³å°‘åŠä»½çº¢è‚‰æ‘„å…¥ï¼ˆåŠä»½çº¢è‚‰ç›¸å½“äº14gåŠ å·¥çº¢è‚‰æˆ–40géåŠ å·¥çº¢è‚‰ï¼‰çš„è°ƒæŸ¥å¯¹è±¡ï¼Œåœ¨æ¥ä¸‹æ¥å…«å¹´å†…å…¨å› æ­»äº¡é£é™©å¢åŠ 10ï¼…ï¼ˆHR, 1.10; 95%CI, 1.04-1.17ï¼‰ï¼›æ¯å‘¨åƒä¸¤ä»½çº¢è‚‰æˆ–åŠ å·¥è‚‰ç±»ï¼ˆä½†ä¸åŒ…æ‹¬å®¶ç¦½æˆ–é±¼ç±»ï¼‰ä¼šä½¿å…¨å› æ­»äº¡é£é™©å¢åŠ 3%\n    * ![çº¢è‚‰](https://user-images.githubusercontent.com/2707039/163703960-6f321de5-4daa-4ea5-95b9-af9c96f1c1bc.jpg)\n  * [çº¢è‚‰å’Œç™½è‚‰æœ€å¤§çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿä¸ºå•¥è¦è¿™ä¹ˆåˆ†å‘¢ï¼Ÿ](https://www.zhihu.com/question/67223570/answer/809785380)\n* è”¬æœ\n  * [æ¯å¹´54ä¸‡äººæ­»äº¡ï¼Œç«Ÿæ˜¯å› ä¸ºæ°´æœåƒå¾—å°‘ï¼ï¼Ÿè¿™å·²æˆåå¤§æ­»äº¡å› ç´ ä¹‹ä¸€ï¼](https://www.sohu.com/a/322360740_164924)\n    * å‡ºå¤„ï¼š[Estimated Global, Regional, and National Cardiovascular Disease Burdens Related to Fruit and Vegetable Consumption: An Analysis from the Global Dietary Database (FS01-01-19) ](https://academic.oup.com/cdn/article-abstract/3/Supplement_1/nzz028.FS01-01-19/5516583)\n    * æ¯å¤©æ‘„å…¥200å…‹æ–°é²œæ°´æœå¯ä½¿æ­»äº¡ç‡é™ä½17%ï¼Œç³–å°¿ç—…å¤§è¡€ç®¡å¹¶å‘ç—‡ï¼ˆå¦‚ä¸­é£ã€ç¼ºè¡€æ€§å¿ƒè„ç—…ç­‰ï¼‰é£é™©é™ä½13%ï¼ŒåŠç³–å°¿ç—…å°è¡€ç®¡å¹¶å‘ç—‡ï¼ˆå¦‚ç³–å°¿ç—…è‚¾ç—…ã€ç³–å°¿ç—…çœ¼ç—…ã€ç³–å°¿ç—…è¶³ç—…ç­‰ï¼‰é£é™©é™ä½28%\n  * [ã€Šè‡ªç„¶ã€‹å­åˆŠï¼šæ¯å¤©äºŒä¸¤è¥¿å…°èŠ±ï¼Œå¥åº·é•¿å¯¿éƒ½æœ‰å•¦ï¼åˆ†æè¿‘6ä¸‡äºº23å¹´çš„æ•°æ®å‘ç°ï¼Œåƒå«é»„é…®ç±»é£Ÿç‰©ä¸æ­»äº¡é£é™©é™ä½20%ç›¸å…³ä¸¨ä¸´åºŠå¤§å‘ç°](https://mp.weixin.qq.com/s/E6BAi-Vnhr1jXBm0Pys2ZQ)\n    * å‡ºå¤„ï¼š[Flavonoid intake is associated with lower mortality in the Danish Diet Cancer and Health Cohort](https://www.nature.com/articles/s41467-019-11622-x)\n    * åƒå«é»„é…®ç±»é£Ÿç‰©ä¸æ­»äº¡é£é™©é™ä½20%ç›¸å…³\n    * ![é»„é…®](https://user-images.githubusercontent.com/2707039/163703969-42e64f88-e727-4e7d-85f2-07a92e29b613.jpg)\n    * Bondonnoåšå£«è¯´é“â€œåƒä¸åŒè”¬èœã€æ°´æœè¡¥å……ï¼Œä¸åŒç§ç±»çš„é»„é…®ç±»åŒ–åˆç‰©æ˜¯å¾ˆé‡è¦çš„ï¼Œè¿™å¾ˆå®¹æ˜“é€šè¿‡é¥®é£Ÿå®ç°ï¼šä¸€æ¯èŒ¶ã€ä¸€ä¸ªè‹¹æœã€ä¸€ä¸ªæ©˜å­ã€100å…‹è“è“ï¼Œæˆ–100å…‹è¥¿å…°èŠ±ï¼Œå°±èƒ½æä¾›å„ç§é»„é…®ç±»åŒ–åˆç‰©ï¼Œå¹¶ä¸”æ€»å«é‡è¶…è¿‡500æ¯«å…‹ã€‚\n* è¾£æ¤’\n  * [è¾£æ¤’æˆæ­»äº¡å…‹æ˜Ÿï¼Ÿæ®è°ƒç ”ï¼Œå¸¸åƒè¾£æ‚£ç—…æ­»äº¡é£é™©å¯é™ä½61%](https://3g.163.com/dy/article/F6Q7I1ME053228ZU.html)\n    * å‡ºå¤„1ï¼š[Chili pepper consumption and mortality in Italian adults](https://www.sciencedirect.com/science/article/pii/S0735109719382063)\n\t* å‡ºå¤„2ï¼š[The Association of Hot Red Chili Pepper Consumption and Mortality: A Large Population-Based Cohort Study](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0169876)\n    * 2017å¹´Plos One çš„å¦ä¸€é¡¹æ¥è‡ªç¾å›½çš„ç ”ç©¶ä»¥16179åï¼Œå¹´é¾„åœ¨18å²ä»¥ä¸Šçš„äººç¾¤ä¸ºå¯¹è±¡ï¼Œå¹¶å¯¹å…¶è¿›è¡Œäº†é«˜è¾¾19å¹´çš„éšè®¿ï¼Œå‘ç°åœ¨4946ä¾‹æ­»äº¡æ‚£è€…ä¸­ï¼Œé£Ÿç”¨è¾£æ¤’çš„å‚ä¸è€…çš„å…¨å› æ­»äº¡ç‡ä¸º21.6ï¼…ï¼Œè€Œæœªé£Ÿç”¨è¾£æ¤’çš„å‚ä¸è€…çš„å…¨å› æ­»äº¡ç‡ä¸º33.6ï¼…ã€‚ç›¸è¾ƒäºä¸åƒè¾£æˆ–å¾ˆå°‘åƒï¼ˆå°‘äºæ¯å‘¨ä¸¤æ¬¡ï¼‰çš„äººç¾¤ï¼Œæ¯å‘¨åƒè¾£ï¼4æ¬¡çš„äººç¾¤æ€»æ­»äº¡é£é™©é™ä½23%ï¼Œå¿ƒè¡€ç®¡æ­»äº¡é£é™©é™ä½34%ã€‚\n* é¸¡è›‹\n  * [æ¯å¤©å¤šåƒåŠä¸ªè›‹ï¼Œå¢åŠ 7%çš„å…¨å› å’Œå¿ƒè¡€ç®¡æ­»äº¡é£é™©ï¼Ÿ](https://m.thepaper.cn/baijiahao_11540780)\n    * å‡ºå¤„ï¼š[NIH-AARPå·¥ä½œä¸»é¡µ](https://dietandhealth.cancer.gov/)ã€[Egg and cholesterol consumption and mortality from cardiovascular and different causes in the United States: A population-based cohort study](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7872242/)\n    * æ¯å¤©å¤šåƒåŠä¸ªè›‹ï¼Œå¢åŠ 7%çš„å…¨å› å’Œå¿ƒè¡€ç®¡æ­»äº¡é£é™©ï¼Ÿåœ¨å‡è®¾æ€§æ›¿ä»£åˆ†æä¸­ï¼Œç ”ç©¶è€…å‘ç°ï¼Œç”¨ç­‰é‡çš„è›‹æ¸…/é¸¡è›‹æ›¿ä»£ç‰©ã€å®¶ç¦½ã€é±¼ã€ä¹³åˆ¶å“ã€åšæœå’Œè±†ç±»åˆ†åˆ«æ›¿ä»£åŠåªå…¨è›‹ï¼ˆ25å…‹/å¤©ï¼‰å¯ä»¥é™ä½6%ã€8%ã€9%ã€7%ã€13%å’Œ10%çš„å…¨å› æ­»äº¡ç‡ã€‚\n\t*[é¸¡è›‹](https://raw.githubusercontent.com/qhy040404/Image-Resources-Repo/master/pmed.1003508.g002.jpg)\n* åšæœ\n  * [å“ˆä½›20å¹´ç ”ç©¶ï¼šåƒæ ¸æ¡ƒçš„äººæ›´é•¿å¯¿ï¼Œæ˜¾è‘—å‡å°‘å…¨å› æ­»äº¡ï¼Œå»¶é•¿å¯¿å‘½](https://www.163.com/dy/article/GKVOMMMF05148PF4.html)\n    * å‡ºå¤„ï¼š[Association of Walnut Consumption with Total and Cause-Specific Mortality and Life Expectancy in US Adults](https://www.mdpi.com/2072-6643/13/8/2699/pdf)\n    * é€šè¿‡åˆ†æå‘ç°ï¼Œç»å¸¸é£Ÿç”¨æ ¸æ¡ƒå¯ä»¥å»¶é•¿å¯¿å‘½ï¼Œé™ä½å¿ƒè¡€ç®¡ç–¾ç—…æ­»äº¡é£é™©ã€‚æ¯”èµ·ä¸åƒæ ¸æ¡ƒï¼Œæ¯å‘¨é£Ÿç”¨æ ¸æ¡ƒ5ä»½ä»¥ä¸Šï¼ˆ1ä»½28å…‹ï¼‰çš„å¥åº·é¢„æœŸå¯¿å‘½å»¶é•¿1.3å²ï¼Œå…¨å› æ­»äº¡é£é™©é™ä½14%ï¼Œå¿ƒè¡€ç®¡ç–¾ç—…æ­»äº¡ç‡é™ä½25%ã€‚\n  * [ç ”ç©¶ï¼šæ¯æ—¥é£Ÿç”Ÿåšæœï¼Œæ­»äº¡ç‡é™20%](https://zhuanlan.zhihu.com/p/44454030)\n    * å‡ºå¤„1ï¼š[Association of nut consumption with total and cause-specific mortality](https://www.nejm.org/doi/full/10.1056/NEJMoa1307352)\n    * å‡ºå¤„2ï¼š[APG_Health-&-Nutrition-Research-Brochure_DEC-19-18](https://americanpistachios.cn/sites/china/files/inline-files/APG_Health-%26-Nutrition-Research-Brochure_DEC-19-18.pdf)\n    * ç ”ç©¶äººå‘˜å‘ç°ï¼Œæ¯å‘¨åƒæ ‘åšæœä½äº1ç›å¸ä»½é‡çš„äººï¼Œæ­»äº¡ç‡é™ä½7ï¼…ã€‚è€Œæ¯å‘¨åƒäº†1ç›å¸ä»½é‡çš„äººï¼Œå‡å°‘11ï¼…çš„æ­»äº¡ç‡ï¼›æ¯å‘¨åƒ2ä»½é‡çš„äººï¼Œå‡ä½13ï¼…ï¼›æ¯å‘¨5è‡³6ä»½é‡è€…ï¼Œå‡å°‘äº†15ï¼…ï¼›ä¸€å‘¨7ä»½ä»¥ä¸Šçš„äººï¼Œæ­»äº¡ç‡åˆ™å‡å°‘20ï¼…ã€‚\n    * å¦å¤–ä¸¤ç¯‡å‘è¡¨åœ¨ã€Šå…¬å…±ç§‘å­¦å›¾ä¹¦é¦†åœ¨çº¿æœŸåˆŠã€‹(Public Library of Science Online Journal)å’Œã€Šç”Ÿç‰©åŒ»å­¦ä¸­å¿ƒã€‹(BioMed Central)ä¸Šçš„åŒ»å­¦é¢„ç§‘ç ”ç©¶è®ºæ–‡ï¼Œå±•ç¤ºäº†è¯•éªŒå¼€å§‹æ—¶çš„æ¨ªæ–­é¢æ•°æ®ã€‚è¿™ä¸¤é¡¹ç ”ç©¶éƒ½è¯„ä¼°äº†7,216åå¯¹è±¡ï¼Œä»¥åŠä»–ä»¬é£Ÿç”¨åšæœçš„é¢‘ç‡å’Œæ•°é‡ä¹‹é—´çš„å…³ç³»ã€‚é‚£äº›æ¯å‘¨é£Ÿç”¨ä¸‰ä»½ä»¥ä¸Šåšæœ(åŒ…æ‹¬å¼€å¿ƒæœ)çš„ç ”ç©¶å¯¹è±¡çš„æ­»äº¡ç‡é™ä½39%ã€‚\n* é’ ï¼ˆå­˜æœ‰å¤§é‡äº‰è®®ï¼‰\n  * [Eur Heart Jï¼šé’ æ‘„å…¥é‡ä¸é¢„æœŸå¯¿å‘½ã€å…¨å› æ­»äº¡ç‡çš„å…³ç³»](https://nursing.medsci.cn/article/show_article.do;jsessionid=A34E8A33918A152CB55BDD2E5FB1798D?id=afe720486ee7)\n    * å‡ºå¤„ï¼š[Messerli F H, Hofstetter L, Syrogiannouli L, et al. Sodium intake, life expectancy, and all-cause mortality[J]. European heart journal, 2021, 42(21): 2103-2112.](https://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC8169157&blobtype=pdf)\n    * ![ehaa947f6](https://user-images.githubusercontent.com/2707039/164894778-9710f18d-e055-4f62-bdcb-618687771d77.jpeg)\n    * åœ¨è¯¥åˆ†ææ‰€åŒ…å«çš„181ä¸ªå›½å®¶ä¸­ï¼Œç ”ç©¶äººå‘˜å‘ç°é’ æ‘„å…¥é‡ä¸å‡ºç”Ÿæ—¶çš„å¥åº·é¢„æœŸå¯¿å‘½ï¼ˆÎ²=2.6å¹´/å…‹æ¯æ—¥é’ æ‘„å…¥é‡ï¼ŒR<sup>2</sup>=0.66ï¼ŒP<0.001ï¼‰å’Œ60å²æ—¶çš„å¥åº·é¢„æœŸå¯¿å‘½ï¼ˆÎ²=0.3å¹´/å…‹æ¯æ—¥é’ æ‘„å…¥é‡ï¼ŒR<sup>2</sup>=0.60ï¼ŒP=0.048ï¼‰ä¹‹é—´å­˜åœ¨æ­£ç›¸å…³å…³ç³»ï¼Œä½†ä¸éä¼ æŸ“æ€§ç–¾ç—…æ­»äº¡ï¼ˆÎ²=17æ¬¡äº‹ä»¶/å…‹æ¯æ—¥é’ æ‘„å…¥é‡ï¼ŒR<sup>2</sup>=0.43ï¼ŒP=0.100ï¼‰æ— å…³ã€‚ç›¸åï¼Œå…¨å› æ­»äº¡ç‡ä¸é’ æ‘„å…¥é‡æˆè´Ÿç›¸å…³ï¼ˆÎ²=âˆ’131æ¬¡äº‹ä»¶/å…‹æ¯æ—¥é’ æ‘„å…¥é‡ï¼ŒR<sup>2</sup>=0.60ï¼ŒP<0.001ï¼‰ã€‚åœ¨ä»…é™äº46ä¸ªæ”¶å…¥æœ€é«˜å›½å®¶çš„æ•æ„Ÿæ€§åˆ†æä¸­ï¼Œé’ æ‘„å…¥é‡ä¸å‡ºç”Ÿæ—¶çš„å¥åº·é¢„æœŸå¯¿å‘½å‘ˆæ­£ç›¸å…³ï¼ˆÎ²=3.4å¹´/å…‹æ¯æ—¥é’ æ‘„å…¥é‡ï¼ŒR<sup>2</sup>=0.53ï¼ŒP<0.001ï¼‰ï¼Œè€Œä¸å…¨å› æ­»äº¡ç‡ï¼ˆÎ²=âˆ’168æ¬¡äº‹ä»¶/å…‹æ¯æ—¥é’ æ‘„å…¥é‡ï¼ŒR<sup>2</sup>=0.50ï¼ŒP<0.001ï¼‰å‘ˆè´Ÿç›¸å…³ã€‚\n    * è¯¥ï¼ˆå¤§èŒƒå›´ï¼‰ç ”ç©¶è®¤ä¸ºæ›´å¤šçš„é’ æ‘„å…¥ä¸æ˜¾è‘—æ›´ä½çš„å…¨å› æ­»äº¡ç‡æœ‰å…³\n    * [é’ˆå¯¹è¯¥è®ºæ–‡çš„å»¶ä¼¸è§£è¯»å’Œè®¨è®ºï¼šA Fresh Foray in the Salt Wars: Life Expectancy Higher With Greater Sodium Intake](https://www.tctmd.com/news/fresh-foray-salt-wars-life-expectancy-higher-greater-sodium-intake)\n  * [NEJM/Lancetï¼šä¸è¦åƒå¤ªå¤šç›ï¼Œä¸­å›½é¥®é£Ÿæ‰€è‡´å¿ƒè¡€ç®¡ç—…å’Œç™Œç—‡æ­»äº¡å…¨çƒç¬¬ä¸€ï¼Œåƒä½é’ ç›å¯é™ä½å…¨å› æ­»äº¡ç‡](https://ibook.antpedia.com/x/669028.html)\n    * ä½†ä¹Ÿæœ‰å¤šé¡¹ç ”ç©¶è®¤ä¸ºç”¨ä½é’ ç›å¯ä»¥é™ä½ä¸€ç³»åˆ—ç–¾ç—…çš„å‘ç”Ÿæ¦‚ç‡ï¼Œå¯¹å…¨å› æ­»äº¡ç‡çš„å‡å°‘æœ‰ç§¯æå½±å“\n* ç¢³æ°´ï¼ˆå­˜æœ‰å¤§é‡äº‰è®®ï¼‰\n  * [ä½ç¢³ç”Ÿé…®é¥®é£Ÿï¼ˆå››ï¼‰ç¢³æ°´åŒ–åˆç‰©ä¸é•¿æœŸæ­»äº¡ç‡](https://zhuanlan.zhihu.com/p/137815934)\n    * å‡ºå¤„ï¼šThe Lancet Public Health - [Dietary carbohydrate intake and mortality: a prospective cohort study and meta-analysis](https://www.sciencedirect.com/science/article/pii/S246826671830135X)\n    * ç¢³æ°´è¶Šä½ï¼Œå¯¿å‘½è¶ŠçŸ­ï¼›ç¢³æ°´è¶Šé«˜ï¼Œå¯¿å‘½ä¹Ÿè½»å¾®ç¼©çŸ­ï¼›ç¢³æ°´50%å·¦å³ï¼ˆå…¶å®æŒ‰ç…§ä¸€èˆ¬çš„è¯´æ³•ï¼Œè¿™ä¹Ÿç®—é«˜ç¢³æ°´ï¼‰æ˜¯æœ€é•¿å¯¿å‘½åŒºé—´ \n    * ![ç¢³æ°´](https://user-images.githubusercontent.com/2707039/163703985-a2e2f8ac-101a-4f3c-903b-6850507f144b.jpg)\n  * [æœ€å¼ºè¥å…»æ­é…ï¼BMJï¼šè¿™ä¹ˆåƒï¼Œå¿ƒè¡€ç®¡ç–¾ç—…å’Œæ­»äº¡é£é™©æ›´ä½](https://www.chinacdc.cn/gwxx/202003/t20200323_214639.html)\n* æ§Ÿæ¦”\n  * [å¦‚ä½•çœ‹å¾…æ§Ÿæ¦”åš¼å‡ºæ¥çš„ç™Œç—‡ï¼Ÿæ§Ÿæ¦”è‡´ç™Œé£é™©ç©¶ç«Ÿæœ‰å¤šå¤§ï¼Ÿ - ä¸é¦™åŒ»ç”Ÿçš„å›ç­” - çŸ¥ä¹](https://www.zhihu.com/question/312784161/answer/603370131)\n    * å‡ºå¤„ï¼šChewing Betel Quid and the Risk of Metabolic Disease, Cardiovascular Disease, and All-Cause Mortality: A Meta-Analysis(https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0070679)\n    * åš¼æ§Ÿæ¦”ä¼šå¢åŠ 21%çš„å…¨å› æ­»äº¡ç‡\n* çƒ­é‡é™åˆ¶\n  * [æ€ä¹ˆçœ‹å¾…BBCã€Šè¿›é£Ÿã€æ–­é£Ÿä¸é•¿å¯¿ã€‹ï¼Ÿ](https://www.zhihu.com/question/31395511)\n    * é™åˆ¶å¡è·¯é‡ŒåŠ¨ç‰©å®éªŒï¼šCRï¼ˆçƒ­é‡é™åˆ¶ï¼Œå³å°‘åƒï¼‰å»¶è¿Ÿäº†æ’æ²³çŒ´çš„å¤šç§ç–¾ç—…å‘ç—…å’Œæ­»äº¡ç‡ï¼Œä¸CRåŠ¨ç‰©ç›¸æ¯”ï¼Œæ­£å¸¸å–‚å…»çš„çŒ´å­çš„å„ç§ç–¾ç—…æ‚£ç—…é£é™©å¢åŠ 2.9å€ï¼Œæ­»äº¡é£é™©å¢åŠ 3.0å€ã€‚\n    * ![çƒ­é‡é™åˆ¶-æ’æ²³çŒ´](https://user-images.githubusercontent.com/2707039/163703988-8767185b-326a-4783-b2e2-f190322bb7d6.jpg)\n* ç»¼åˆ\n  * [æœ€å¼ºè¥å…»æ­é…ï¼BMJï¼šè¿™ä¹ˆåƒï¼Œå¿ƒè¡€ç®¡ç–¾ç—…å’Œæ­»äº¡é£é™©æ›´ä½](https://www.chinacdc.cn/gwxx/202003/t20200323_214639.html)\n  * [Associations of fat and carbohydrate intake with cardiovascular disease and mortality: prospective cohort study of UK Biobank participants](https://doi.org/10.1136/bmj.m688)\n    * é€šè¿‡å¯¹è¿™äº›å‚ä¸è€…çš„æ•°æ®è¿›è¡Œåˆ†æï¼Œç ”ç©¶äººå‘˜å‘ç°ç¢³æ°´åŒ–åˆç‰©ï¼ˆç³–ã€æ·€ç²‰å’Œçº¤ç»´ï¼‰å’Œè›‹ç™½è´¨çš„æ‘„å…¥ä¸å…¨å› æ­»äº¡ç‡å‘ˆéçº¿æ€§å…³ç³»ï¼Œè€Œè„‚è‚ªåˆ™ä¸å…¨å› æ­»äº¡ç‡å‘ˆçº¿æ€§ç›¸å…³ã€‚å…¶ä¸­ï¼Œè¾ƒé«˜çš„ç³–åˆ†æ‘„å…¥ä¸å…¨å› æ­»äº¡é£é™©å’Œæ‚£å¿ƒè¡€ç®¡ç–¾ç—…çš„é£é™©è¾ƒé«˜å‡æœ‰å…³è”ï¼Œè€Œè¾ƒé«˜çš„é¥±å’Œè„‚è‚ªé…¸æ‘„å…¥ä¸å…¨å› æ­»äº¡é£é™©è¾ƒé«˜æœ‰å…³ã€‚\n    * å›¾1ï¼šå„ç§è¥å…»å…ƒç´ ä¸å…¨å› æ­»äº¡ä¹‹é—´çš„å…³ç³»\n    * ![å„ç§è¥å…»å…ƒç´ ä¸å…¨å› æ­»äº¡ä¹‹é—´çš„å…³ç³»](https://user-images.githubusercontent.com/2707039/163702022-8c2bfea9-ed5d-4fe0-8ead-e8740014b92b.jpg)\n    * å›¾2ï¼šå„ç§è¥å…»å…ƒç´ ä¸å¿ƒè¡€ç®¡ç–¾ç—…ä¹‹é—´çš„å…³ç³»\n    * ![å„ç§è¥å…»å…ƒç´ ä¸å¿ƒè¡€ç®¡ç–¾ç—…ä¹‹é—´çš„å…³ç³»](https://user-images.githubusercontent.com/2707039/163702084-97fb4a03-707c-475d-b88e-6fe2f8e87f92.jpg)\n    * **è¿›ä¸€æ­¥ç ”ç©¶è¡¨æ˜ï¼Œåœ¨æ‰€æœ‰çš„é¥®é£Ÿæ¨¡å¼ä¸­ï¼Œå…¨å› æ­»äº¡ç‡é£é™©æœ€ä½çš„é¥®é£Ÿæ–¹å¼ä¸ºï¼š10-30gé«˜çº¤ç»´ã€14-30%è›‹ç™½è´¨ã€10-25%å•ä¸é¥±å’Œè„‚è‚ªé…¸ã€5%-7%å¤šä¸é¥±å’Œè„‚è‚ªé…¸ä»¥åŠ20%-30%æ·€ç²‰æ‘„å…¥ã€‚**\n    * **æœ€ä¼˜èƒ½é‡æ¥æºé…æ¯”ï¼š<24%æ·€ç²‰ï¼Œ15%-17%è›‹ç™½è´¨ï¼Œ>15%å•ä¸é¥±å’Œè„‚è‚ªé…¸ï¼Œ<15%ç³–ï¼Œ6%é¥±å’Œè„‚è‚ªé…¸ï¼Œ6%å¤šä¸é¥±å’Œè„‚è‚ªé…¸ï¼Œ30g+é«˜çº¤ç»´**\n  * [BMJ | å¸¸åƒè–¯ç‰‡æ±‰å ¡å·§å…‹åŠ›ç­‰é£Ÿå“ï¼Œå¹³å‡æ­»äº¡å¹´é¾„ä»…ä»…ä¸º58å²ï¼Œæ­»äº¡é£é™©å‰§å¢](https://med.ckcest.cn/details.html?id=5183272274855936&classesEn=news)\n    * [Rico-CampÃ  A, MartÃ­nez-GonzÃ¡lez M A, Alvarez-Alvarez I, et al. Association between consumption of ultra-processed foods and all cause mortality: SUN prospective cohort study[J]. bmj, 2019, 365.](https://www.bmj.com/content/365/bmj.l1949.full)\n    * [Srour B, Fezeu L K, Kesse-Guyot E, et al. Ultra-processed food intake and risk of cardiovascular disease: prospective cohort study (NutriNet-SantÃ©)[J]. bmj, 2019, 365.](https://www.bmj.com/content/365/bmj.l1451)\n    * [Lawrence M A, Baker P I. Ultra-processed food and adverse health outcomes[J]. bmj, 2019, 365.](https://www.researchgate.net/profile/Phillip-Baker-5/publication/333483796_Ultra-processed_food_and_adverse_health_outcomes/links/5f0c646ca6fdcc2f32336a95/Ultra-processed-food-and-adverse-health-outcomes.pdf)\n\n##### 6.1.2. æ¶²ä½“\n\n* ç‰›å¥¶\n  * [ã€ŠæŸ³å¶åˆ€ã€‹è°ƒç ”21ä¸ªå›½å®¶13ä¸‡äººï¼šæ¯å¤©1æ–¤ç‰›å¥¶æˆ–é…¸å¥¶ï¼Œå¿ƒè¡€ç®¡æ­»äº¡é£é™©ä¸‹é™23%](https://www.sohu.com/a/253940257_419768)\n  * å‡ºå¤„ï¼š[Association of dairy intake with cardiovascular disease and mortality in 21 countries from five continents (PURE): a prospective cohort study](http://mdrf-eprints.in/1114/1/Association_of_dietary_patterns_and_dietary_diversity_with_cardiometabolic_disease_risk_factors.pdf)\n  * ä¸ä¸é£Ÿç”¨ä¹³åˆ¶å“çš„äººç›¸æ¯”ï¼Œæ¯å¤©æ‘„å…¥ä¸¤ä»½ä¹³åˆ¶å“ï¼ˆä¸€ä»½æŒ‡244å…‹ç‰›å¥¶/é…¸å¥¶ï¼Œ15å…‹å¥¶é…ªæˆ–5å…‹é»„æ²¹ï¼‰çš„äººï¼Œ**å…¨å› æ­»äº¡é£é™©ä¸‹é™äº†17%**ï¼Œå¿ƒè¡€ç®¡æ­»äº¡é£é™©ä¸‹é™23%ï¼Œä¸­é£é£é™©ä¸‹é™33%\n* èŒ¶\n  * [10ä¸‡ä¸­å›½äººéšè®¿7å¹´å‘ç°ï¼Œæ¯å‘¨å–ä¸‰æ¬¡èŒ¶ä¸å…¨å› æ­»äº¡é£é™©é™ä½15%ï¼Œé¢„æœŸå¯¿å‘½å¢åŠ 1.26å¹´ç›¸å…³ ](https://www.jianshu.com/p/5461a205cf95?utm_campaign=hugo)\n  * å‡ºå¤„ï¼š[Tea consumption and the risk of atherosclerotic cardiovascular disease and all-cause mortality: The China-PAR project](https://www.researchgate.net/profile/Fangchao-Liu-4/publication/338483323_Tea_consumption_and_the_risk_of_atherosclerotic_cardiovascular_disease_and_all-cause_mortality_The_China-PAR_project/links/5e55e5e94585152ce8efe511/Tea-consumption-and-the-risk-of-atherosclerotic-cardiovascular-disease-and-all-cause-mortality-The-China-PAR-project.pdf)\n  * [ä¸­å›½æˆå¹´äººé¥®èŒ¶ä¸æ­»äº¡é£é™©çš„å‰ç»æ€§å…³è”ç ”ç©¶](http://rs.yiigle.com/CN112338202202/1351516.htm)\n  * çº³å…¥åˆ†æçš„438 443ä¾‹ç ”ç©¶å¯¹è±¡éšè®¿11.1å¹´å…±å‘ç”Ÿæ­»äº¡34 661ä¾‹ã€‚ä¸ä»ä¸é¥®èŒ¶è€…ç›¸æ¯”ï¼Œå½“å‰éæ¯æ—¥é¥®èŒ¶è€…å’Œæ¯æ—¥é¥®èŒ¶è€…å…¨å› æ­»äº¡HRå€¼ï¼ˆ95%CIï¼‰ä¾æ¬¡ä¸º0.89ï¼ˆ0.86-0.91ï¼‰å’Œ0.92ï¼ˆ0.88-0.95ï¼‰ã€‚åˆ†æ€§åˆ«åˆ†ææ˜¾ç¤ºï¼Œé¥®èŒ¶å¯¹å…¨å› æ­»äº¡é£é™©çš„ä¿æŠ¤ä½œç”¨ä¸»è¦è§äºç”·æ€§ï¼ˆäº¤äº’P<0.05ï¼‰\n* æ— ç³–ï¼ˆç”œå‘³ï¼‰é¥®æ–™\n  * [ã€Œæ— ç³–é¥®æ–™ä½¿æ­»äº¡é£é™©å¢åŠ  26 %ã€ï¼Œæ˜¯çœŸçš„å—ï¼Ÿ](https://www.zhihu.com/question/418598272/answer/1450648364)\n    * ç›¸æ¯”äºè½¯é¥®æ–™æ‘„å…¥é‡ï¼œ1æ¯/æœˆçš„å‚ä¸è€…ï¼Œæ··åˆè½¯é¥®æ–™æ‘„å…¥â‰¥1æ¯/å¤©çš„å‚ä¸è€…æ­»äº¡é£é™©å¢åŠ 18%ï¼Œè€Œ**æ‘„å…¥å«ç³–è½¯é¥®æ–™æˆ–æ— ç³–è½¯é¥®æ–™ä¼šä»¤æ­»äº¡é£é™©åˆ†åˆ«å¢åŠ 11%å’Œ27%ã€‚**\n    * ![é¥®æ–™](https://user-images.githubusercontent.com/2707039/163704346-e7d92e7f-eba5-4673-8f15-3a96782c2e32.png)\n  * [Association Between Soft Drink Consumption and Mortality in 10 European Countries](https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2749350)\n* æœ‰ç³–é¥®æ–™\n  * [å¯ä¹å’Œå¥¶èŒ¶ï¼Œå¢åŠ å…¨å› æ­»äº¡ç‡é«˜è¾¾62%ï¼æœæ±é™ä½å…ç–«åŠ›ï¼Œå½±å“è‚ä»£è°¢ï¼å«ç³–é¥®æ–™é‚£äº›äº‹](https://zhuanlan.zhihu.com/p/400746073)\n    * æ¯å¤©1æ¯å«ç³–é¥®æ–™å¢åŠ 7%å…¨å› æ­»äº¡ç‡ï¼Œ2æ¯21%\n    * åœ¨34å¹´çš„éšè®¿ä¸­ï¼Œç ”ç©¶äººå‘˜å‘ç°ï¼Œç›¸æ¯”é‚£äº›ä¸€ä¸ªæœˆå–1æ¯æˆ–è€…æ›´å°‘å«ç³–é¥®æ–™çš„äººï¼Œæ¯å¤©å–2æ¯çš„äººæ€»ä½“æ­»äº¡é£é™©å‡é«˜äº†21%ï¼Œå¿ƒè¡€ç®¡ç–¾ç—…æ­»äº¡é£é™©å‡é«˜äº†31%ï¼Œç™Œç—‡æ­»äº¡é£é™©ä¸Šå‡äº†16%ã€‚\n    * åªè¦æ¯å¤©å¤šå–ä¸€æ¯å«ç³–é¥®æ–™ï¼Œæ€»ä½“æ­»äº¡é£é™©å°†å¢åŠ 7%ï¼Œå¿ƒè¡€ç®¡ç–¾ç—…çš„é£é™©å°†å¢åŠ 10%ï¼Œç™Œç—‡ç›¸å…³çš„æ­»äº¡é£é™©å°†16%ã€‚\n    * å‘è¡¨åœ¨å›½é™…é¡¶çº§æœŸåˆŠã€ŠBMJã€‹ä¸Šçš„ä¸€ç¯‡è®ºæ–‡å°±è¯æ˜äº†å«ç³–é¥®æ–™ä¼šåœ¨å¢åŠ æ‚£ç™Œé£é™©ï¼Œå½“ç„¶è¿™ç¯‡æ–‡ç« éªŒè¯çš„ä¸ä»…ä»…æ˜¯æœæ±ï¼Œå¥¶èŒ¶ä¹Ÿæœ‰ä»½â€”â€”å’Œå«ç³–é¥®æ–™ç›¸å…³çš„æ€»ä½“æ‚£ç™Œé£é™©è¦é«˜å‡ºé€šå¸¸å€¼18%ï¼Œ100%çš„é²œæ¦¨æœæ±ä¹Ÿä¼šä½¿å¾—æ•´ä½“çš„æ‚£ç™Œé£é™©ä¸Šå‡12%ã€‚\n* æœæ±\n  * [JAMAå­åˆŠï¼š100%çº¯æœæ±å¯èƒ½æ¯”å«ç³–é¥®æ–™æ›´å±é™©](https://zhuanlan.zhihu.com/p/66513350)\n    * æ¯å¤©å¤šæ‘„å…¥ä¸€ä»½12ç›å¸çš„å«ç³–é¥®æ–™ï¼Œå…¨å› æ­»äº¡ç‡é£é™©å¢åŠ 11%ï¼›\n    * æ¯å¤©å¤šæ‘„å…¥ä¸€ä»½12ç›å¸çš„æœæ±ï¼Œå…¨å› æ­»äº¡ç‡é£é™©å¢åŠ 24%ã€‚\n* å’–å•¡\n  * [é‡ç£…ï¼å¤šç¯‡ç ”ç©¶è¯å®å–å’–å•¡ä¸äººç¾¤å…¨å› æ­»äº¡ç‡é™ä½ç›´æ¥ç›¸å…³](https://news.bioon.com/article/6725420.html)\n  * [ç§‘æ™® | å–å’–å•¡åˆå¤šäº†ä¸€ä¸ªæ–°ç†ç”±ï¼šé™ä½æ­»äº¡ç‡ï¼ ](https://www.sohu.com/a/439412995_100003595)\n  * [åœ°ä¸­æµ·æˆå¹´äººå’–å•¡æ¶ˆè€—é‡åŠå…¨å› ï¼Œå¿ƒè¡€ç®¡ç–¾ç—…å’Œç™Œç—‡çš„æ­»äº¡ç‡](https://fanyi.pdf365.cn/help/249)\n    * åœ¨æœ€è¿‘çš„èŸèƒåˆ†æä¸­ï¼Œè¯¥ç ”ç©¶åŒ…æ‹¬æ¥è‡ªä¸åŒå›½å®¶çš„40é¡¹ç ”ç©¶å’Œ3,852,651åå—è¯•è€…ã€‚åœ¨è¿™é¡¹èŸèƒåˆ†ææ˜¾ç¤ºï¼Œå’–å•¡æ‘„å…¥é‡ä¸å„ç§åŸå› çš„æ­»äº¡ç‡ï¼ŒCVDå’Œç™Œç—‡æ­»äº¡ç‡ä¹‹é—´å­˜åœ¨éçº¿æ€§å…³ç³»ï¼Œæ¯å¤©æ‘„å…¥ä¸¤æ¯å’–å•¡çš„ç™Œç—‡æ­»äº¡ç‡æœ€ä½(RR = 0.96)ï¼ŒCVDæœ€ä½çš„æ­»äº¡ç‡ï¼Œæ¯å¤©2.5æ¯(RR= 0.83)ï¼Œå…¨å¤©æœ€ä½æ­»äº¡ç‡ä¸ºæ¯å¤©3.5æ¯(RR= 0.85)ï¼Œå¹¶ä¸”éšç€å’–å•¡æ¶ˆè´¹é‡çš„å¢åŠ ï¼Œæ­»äº¡ç‡æ²¡æœ‰è¿›ä¸€æ­¥é™ä½æˆ–å¢åŠ \n* äºšç²¾èƒº\n  * [Scienceï¼šç§‘å­¦èƒŒä¹¦ï¼ä»ç²¾æ¶²ä¸­å‘ç°çš„äºšç²¾èƒºï¼Œç«Ÿç„¶æœ‰ç€æŠ—è¡°è€ã€æŠ—ç™Œã€ä¿æŠ¤å¿ƒè¡€ç®¡å’Œç¥ç»ã€æ”¹å–„è‚¥èƒ–å’Œ2å‹ç³–å°¿ç—…ç­‰é€†å¤©ç¥æ•ˆ](https://www.medsci.cn/article/show_article.do?id=420d12904103)\n  * [é¥®é£Ÿä¸­äºšç²¾èƒºæ‘„å…¥é‡é«˜ä¼šé™ä½æ­»äº¡ç‡](https://zhuanlan.zhihu.com/p/388942219)\n\n##### 6.1.3. æ°”ä½“\n\n* å¸çƒŸ\n  * [å³ä½¿æ˜¯ä½å¼ºåº¦å¸çƒŸï¼Œä¹Ÿå¢åŠ æ­»äº¡é£é™©ï¼](https://www.medsci.cn/article/show_article.do?id=02ca2083319b)\n    * ç ”ç©¶å‘ç°ï¼šåœ¨42 416åç”·æ€§å’Œ86 735åå¥³æ€§ï¼ˆå¹´é¾„åœ¨35-89å²ä¹‹é—´ï¼Œä»¥å‰æ²¡æœ‰æ‚£ç—…ï¼‰ä¸­ï¼Œ18 985åç”·æ€§ï¼ˆ45%ï¼‰å’Œ18 072åå¥³æ€§ï¼ˆ21%ï¼‰ç›®å‰å¸çƒŸï¼Œå…¶ä¸­33%çš„ç”·æ€§å¸çƒŸè€…å’Œ39%çš„å¥³æ€§å¸çƒŸè€…å¹¶ä¸æ¯å¤©å¸çƒŸã€‚8866åç”·æ€§ï¼ˆ21%ï¼‰å’Œ53 912åå¥³æ€§ï¼ˆ62%ï¼‰ä»ä¸å¸çƒŸã€‚åœ¨éšè®¿æœŸé—´ï¼Œä¸ä»ä¸å¸çƒŸç›¸æ¯”ï¼Œæ¯å¤©<10æ”¯çƒŸæˆ–æ¯å¤©â‰¥10æ”¯çƒŸçš„å…¨å› æ­»äº¡ç‡å±é™©æ¯”åˆ†åˆ«ä¸º1.17ï¼ˆ95%ç½®ä¿¡åŒºé—´1.10-1.25ï¼‰å’Œ1.54ï¼ˆ1.42-1.67ï¼‰ã€‚æ— è®ºå¹´é¾„æˆ–æ€§åˆ«ï¼Œå±é™©æ¯”ç›¸ä¼¼ã€‚ä¸æ¯æ—¥å¸çƒŸå…³ç³»æœ€å¯†åˆ‡çš„ç–¾ç—…æ˜¯å‘¼å¸é“ç™Œç—‡ã€æ…¢æ€§é˜»å¡æ€§è‚ºç—…å’Œèƒƒè‚ é“åŠè¡€ç®¡ç–¾ç—…ã€‚åœ¨æ‹›å‹Ÿæ—¶å·²ç»æˆ’çƒŸçš„äººçš„æ­»äº¡ç‡ä½äºç°åœ¨æ¯å¤©å¸çƒŸè€…ã€‚\n    * å¸çƒŸè€…å¹³å‡å‡å°‘å¯¿å‘½11-12å¹´\n  * [å¸çƒŸè®©äººè¿‡ç˜¾æ˜¯ä»€ä¹ˆåŸç†ï¼Ÿæœ‰èŠ‚åˆ¶çš„å¸çƒŸä¾æ—§æœ‰å®³å—ï¼Ÿ](https://www.zhihu.com/question/24846224/answer/1719798177)\n\n##### 6.1.4. å…‰ç…§\n\n* æ™’å¤ªé˜³\n  * [æ™’å¤ªé˜³å’Œæ­»äº¡ç‡çš„å…³ç³»ï¼Œå¦‚ä½•ç§‘å­¦ï¼Œå®‰å…¨çš„æ™’å¤ªé˜³ï¼Ÿ\n](https://zhuanlan.zhihu.com/p/76301306)\n    * ä¸¹éº¦ä¸€é¡¹é•¿è¾¾26å¹´çš„ç ”ç©¶å‘ç°ï¼Œå¤šæ™’å¤ªé˜³èƒ½æ˜¾è‘—å»¶é•¿å¯¿å‘½ï¼Œå³ä½¿æ˜¯ç”±äºè¿‡åº¦æš´æ™’è¯±å‘çš®è‚¤ç™Œçš„æ‚£è€…ï¼Œå¹³å‡å¯¿å‘½ä¹Ÿæ¯”æ™®é€šäººé•¿äº†6å²ã€‚\n\n##### 6.1.5. è¯ç‰©\n\n* NMN\n* äºŒç”²åŒèƒ\n  * [â€œèƒâ€å¹å¿…çœ‹ ä¸¨æˆ‘å°±æ˜¯ç¥è¯â€”â€”äºŒç”²åŒèƒ](https://zhuanlan.zhihu.com/p/419202902)\n    * äºŒç”²åŒèƒä¸ä»…åœ¨å¤šç§è‚¿ç˜¤ã€å¿ƒè¡€ç®¡ç–¾ç—…åŠç³–å°¿ç—…ä¸­å‘æŒ¥ä¿æŠ¤ä½œç”¨ï¼Œè€Œä¸”åœ¨è‚¥èƒ–ã€è‚ç—…ã€è‚¾ç—…åŠè¡°è€æ–¹é¢ä¹Ÿå¤§æ”¾å¼‚å½©ã€‚\n  * [äºŒç”²åŒèƒ2020æœ€å€¼å¾—äº†è§£çš„â€œåƒç“œâ€å¤§æ–°é—»â€”â€”æŠ¤èƒƒã€å¥è„‘ã€æŠ—è¡°ã€é˜²ç™Œè¿˜æ˜¯è‡´ç™Œï¼Ÿ](https://zhuanlan.zhihu.com/p/357807109)\n  * [äºŒç”²åŒèƒçœŸçš„é‚£ä¹ˆç¥å—ï¼Ÿç¾ç ”ç©¶ï¼šçˆ¶äº²æœç”¨äºŒç”²åŒèƒæˆ–è‡´å­å¥³æœ‰ç¼ºé™·](https://baijiahao.baidu.com/s?id=1729999374705305768)\n  * ![äºŒç”²åŒèƒ](https://user-images.githubusercontent.com/2707039/163702325-5d427542-9ae5-4311-8979-d0d326a9832f.jpg)\n  * ä¸è‰¯ååº”\n    * ä½œä¸ºä¸€ç§ä½¿ç”¨è¿‘ç™¾å¹´çš„è¯ç‰©ï¼ŒäºŒç”²åŒèƒçš„ä¸è‰¯ååº”å·²ç»éå¸¸æ˜ç¡®ï¼Œå¸¸è§çš„æœ‰ï¼šç»´ç”Ÿç´ B12ç¼ºä¹ï¼ˆ7%-17.4%ï¼‰ï¼Œèƒƒè‚ é“ä¸è‰¯ååº”ï¼ˆæœ€é«˜53%ï¼‰ï¼Œç–²å€¦ï¼ˆ9%ï¼‰ï¼Œå¤´ç—›ï¼ˆ6%ï¼‰ï¼›ä¸¥é‡ä½†ä¸å¸¸è§çš„ä¸è‰¯ååº”åŒ…æ‹¬ä¹³é…¸é…¸ä¸­æ¯’ã€è‚æŸä¼¤ï¼›ä¹Ÿæœ‰ç ”ç©¶è¡¨æ˜å¯èƒ½å¯¹èƒå„¿è‡´ç•¸\n* å¤åˆç»´ç”Ÿç´ \n  * [æœç”¨å¤åˆç»´ç”Ÿç´ å¯é™ä½ç™Œç—‡å±é™©8%ï¼Œå…¶ä»–æ•ˆæœå¹¶ä¸æ˜¾è‘—](https://health.qq.com/a/20121023/000026.htm)\n* è‘¡è„ç³–èƒº\n  * [ç¥å¥‡ï¼æ°¨ç³–é™ä½å¿ƒè¡€ç®¡æ­»äº¡ç‡65%ï¼Œä¸å®šæœŸè¿åŠ¨æ•ˆæœç›¸å½“](https://www.sohu.com/a/436372221_120873241)\n  * ç¾å›½è¥¿å¼—å‰å°¼äºšå¤§å­¦æœ€æ–°ç ”ç©¶å‘ç° æ°¨ç³–ï¼ˆè½¯éª¨ç´ ï¼‰ å¯ä»¥é™ä½å¿ƒè¡€ç®¡æ­»äº¡ç‡65%ï¼Œé™ä½æ€»ä½“æ­»äº¡ç‡39%ï¼Œæ•ˆæœä¸åšæŒå®šæœŸè¿åŠ¨ç›¸å¯¹\n  * è¯¥ç ”ç©¶ä½¿ç”¨1999å¹´è‡³2010å¹´ï¼Œ16,686åæˆå¹´äººçš„å›½å®¶å¥åº·å’Œè¥å…»æ£€æŸ¥(NHANES)æ•°æ®ï¼Œå‚ä¸è€…çš„ä¸­ä½è¿½è¸ªæ—¶é—´ä¸º107ä¸ªæœˆï¼Œè€Œå…¶ä¸­æœ‰648ä½å‚ä¸è€…å®šæœŸä¸”æ¯æœç”¨æ—¥500-1000æ¯«å…‹çš„è‘¡è„ç³–èƒº/è½¯éª¨ç´ ä¸€å¹´ä»¥ä¸Šã€‚\n* äºšç²¾èƒº\n  * [Scienceï¼šç§‘å­¦èƒŒä¹¦ï¼ä»ç²¾æ¶²ä¸­å‘ç°çš„äºšç²¾èƒºï¼Œç«Ÿç„¶æœ‰ç€æŠ—è¡°è€ã€æŠ—ç™Œã€ä¿æŠ¤å¿ƒè¡€ç®¡å’Œç¥ç»ã€æ”¹å–„è‚¥èƒ–å’Œ2å‹ç³–å°¿ç—…ç­‰é€†å¤©ç¥æ•ˆ](https://www.medsci.cn/article/show_article.do?id=420d12904103)\n  * äºšç²¾èƒºæ˜¯æœ€å®¹æ˜“ä»äººä½“è‚ é“å¸æ”¶çš„å¤šèƒºã€‚è®¸å¤šçš„é£Ÿç‰©ä¸­éƒ½å«æœ‰å¤§é‡çš„äºšç²¾èƒºï¼Œä¾‹å¦‚æ–°é²œçš„é’æ¤’ã€å°éº¦èƒšèŠ½ã€èŠ±æ¤°èœã€è¥¿å…°èŠ±ã€è˜‘è‡å’Œå„ç§å¥¶é…ªï¼Œå°¤å…¶åœ¨çº³è±†ç­‰å¤§è±†åˆ¶å“ã€é¦™è‡å’Œæ¦´è²ä¸­å«é‡æ›´é«˜ã€‚åœ¨æœ¬å®éªŒä¸­ï¼Œç ”ç©¶äººå‘˜é€‰æ‹©äº†829ä½å¹´é¾„åœ¨45-84å²ä¹‹é—´çš„å‚ä¸è€…è¿›è¡Œäº†ä¸ºæœŸ20å¹´çš„éšè®¿ï¼Œåˆ†æäº†é¥®é£Ÿä¸­äºšç²¾èƒºæ‘„å…¥é‡ä¸äººç±»æ­»äº¡ç‡ä¹‹é—´çš„æ½œåœ¨å…³è”ã€‚\n  * ç ”ç©¶å‘ç°ï¼Œå¥³æ€§çš„äºšç²¾èƒºæ‘„å…¥é‡é«˜äºç”·æ€§ï¼Œå¹¶ä¸”æ‘„å…¥é‡éƒ½ä¼šéšç€å¹´é¾„çš„å¢é•¿è€Œä¸‹é™ã€‚äºšç²¾èƒºçš„ä¸»è¦æ¥æºæ˜¯å…¨è°·ç‰©ï¼ˆå 13.4%ï¼‰ã€è‹¹æœå’Œæ¢¨ï¼ˆå 13.3%ï¼‰ã€æ²™æ‹‰ï¼ˆå 9.8%ï¼‰ã€èŠ½èœï¼ˆå 7.3%ï¼‰å’Œé©¬é“ƒè–¯ï¼ˆå 6.4%ï¼‰ã€‚ç ”ç©¶æ ¹æ®äºšç²¾èƒºæ‘„å…¥é‡å°†äººç¾¤åˆ†ä¸ºä¸‰ç»„ï¼Œä½æ‘„å…¥é‡ç»„ï¼ˆ<62.2 Âµmol / dï¼‰ã€ä¸­æ‘„å…¥é‡ç»„ï¼ˆ62.2â€“79.8 Âµmol / dï¼‰å’Œé«˜æ‘„å…¥é‡ç»„ï¼ˆ> 79.8 Âµmol / dï¼‰ã€‚éšè®¿æœŸé—´å…±è®°å½•äº†341ä¾‹æ­»äº¡ï¼Œå…¶ä¸­è¡€ç®¡ç–¾ç—…137ä¾‹ï¼Œç™Œç—‡94ä¾‹ï¼Œå…¶ä»–åŸå› 110ä¾‹ã€‚ç»è®¡ç®—ä½ä¸­é«˜ä¸‰ç»„çš„ç²—ç•¥æ­»äº¡ç‡åˆ†åˆ«ä¸º40.5%ã€23.7%å’Œ15.1%ï¼Œè¿™äº›æ•°æ®è¡¨æ˜äºšç²¾èƒºæ‘„å…¥é‡ä¸å…¨å› æ­»äº¡ç‡ä¹‹é—´çš„è´Ÿç›¸å…³å…³ç³»æ˜¾è‘—ã€‚éšç€é€æ­¥å¯¹å¹´é¾„ã€æ€§åˆ«å’Œçƒ­é‡çš„æ¯”ä¾‹è¿›è¡Œè°ƒæ•´ï¼Œè¿™ç§ç›¸å…³å…³ç³»ä¾ç„¶æ˜¾è‘—ã€‚\n* ç»¼åˆ\n  * [ã€Šè‡ªç„¶ã€‹å­åˆŠæ·±åº¦ç»¼è¿°ï¼šå¦‚ä½•å¼€å‘æŠ—è¡°è€è¯](https://zhuanlan.zhihu.com/p/145495570)\n  * ![å¦‚ä½•å¼€å‘æŠ—è¡°è€è¯](https://user-images.githubusercontent.com/2707039/163702474-205baeec-f0ce-4e8d-96a4-36efe47534de.jpg)\n\n#### 6.2. è¾“å‡º\n\n##### 6.2.1. æŒ¥æ‹è¿åŠ¨\n\n* [å“ªç§è¿åŠ¨æ€§ä»·æ¯”æœ€é«˜ï¼Ÿæƒå¨åŒ»å­¦æ‚å¿—â€œæŸ³å¶åˆ€â€ç»™å‡ºç­”æ¡ˆäº† ](https://www.sohu.com/a/535581770_121124216)\n  * ä¸€å‘¨ä¸‰æ¬¡ï¼Œæ¯æ¬¡45-60åˆ†é’Ÿï¼ŒæŒ¥æ‹è¿åŠ¨ï¼Œé™ä½~47%å…¨å› æ­»äº¡ç‡\n  * ç¾½æ¯›çƒã€ä¹’ä¹“çƒã€ç½‘çƒç­‰éƒ½ç®—æŒ¥æ‹è¿åŠ¨ï¼Œä½†ç”±äºè¥¿åŒ–ç ”ç©¶èƒŒæ™¯ï¼Œå¯èƒ½æŒ‡ç½‘çƒæ›´å¤šã€‚è¿™éšå¼çš„è¡¨è¾¾äº†å…¨èº«é”»ç‚¼æ›´ä¸ºé‡è¦\n\n##### 6.2.2. å‰§çƒˆè¿åŠ¨\n\n* [æ–°ç ”ç©¶ï¼šæ¯å¤©å‰§çƒˆè¿åŠ¨8åˆ†é’Ÿï¼Œå¯é™ä½å…¨å› æ­»äº¡å’Œå¿ƒè„ç—…é£é™©](https://academic.oup.com/eurheartj/advance-article/doi/10.1093/eurheartj/ehac572/6771381)\n  * æ¯å‘¨15-20åˆ†é’Ÿçš„å‰§çƒˆè¿åŠ¨ï¼Œé™ä½16-40%çš„å…¨å› æ­»äº¡ç‡ï¼Œå‰§çƒˆè¿åŠ¨æ—¶é—´è¾¾åˆ°50-57åˆ†é’Ÿ/å‘¨ï¼Œå¯ä»¥è¿›ä¸€æ­¥é™ä½å…¨å› æ­»äº¡ç‡ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œé€šè¿‡åœ¨ä¸€å‘¨çš„çŸ­æ—¶é—´å†…ç´¯ç§¯ç›¸å¯¹å°‘é‡çš„å‰§çƒˆè¿åŠ¨å¯ä»¥é™ä½å¥åº·é£é™©ã€‚\n  \n##### 6.2.3. èµ°è·¯\n\n* [èµ°è·¯é™ä½å…¨å› æ­»äº¡ç‡è¶…è¿‡50%ï¼æ¯å¤©èµ°å¤šå°‘æ­¥æœ€åˆé€‚ï¼Ÿã€ŠJAMAã€‹å­åˆŠè¶…10å¹´ç ”ç©¶å‘Šè¯‰ä½ ç­”æ¡ˆ](http://www.shcell.org/219/3571.html)\n  * ![èµ°è·¯é™ä½å…¨å› æ­»äº¡ç‡](https://user-images.githubusercontent.com/2707039/163704147-afec1c79-799b-4db8-b547-1a2431d504c9.jpg)\n  * æ³¨1ï¼šè¿™é¡¹ç ”ç©¶å‚ä¸è€…çš„å¹³å‡å¹´é¾„ä¸º45.2å²\n  * æ³¨2ï¼šå¹³å‡æ­¥æ•°çš„å¤šå°‘ä¸èŒä¸šæœ‰å…³ï¼Œæ­¤é¡¹ç ”ç©¶ä»…è¡¨æ˜ç›¸å…³æ€§ï¼Œè¿˜æ²¡æœ‰æ›´æ·±åº¦çš„å› æœåˆ†æ\n\n##### 6.2.4. åˆ·ç‰™\n\n* [50ä¸‡å›½äººç ”ç©¶è¯å®ï¼šä¸å¥½å¥½åˆ·ç‰™ï¼Œè‡´ç™Œï¼è¡€ç®¡ç–¾ç—…ä¹Ÿä¼šå¢å¤šï¼](https://www.cn-healthcare.com/articlewm/20211209/content-1293760.html)\n  * ç»å¸¸ä¸åˆ·ç‰™çš„äººï¼šç™Œç—‡ã€æ…¢æ€§é˜»å¡æ€§è‚ºç—…åŠè‚ç¡¬åŒ–é£é™©åˆ†åˆ«å¢åŠ äº†9%ã€12%å’Œ25%ï¼Œè¿‡æ—©æ­»äº¡é£é™©å¢åŠ 25%ã€‚\n\n##### 6.2.5. æ³¡æ¾¡\n\n* [å®šæœŸæ´—æ¾¡é™ä½å¿ƒè¡€ç®¡ç–¾ç—…å‘ä½œé£é™©](https://www.cn-healthcare.com/article/20200326/content-533379.html)\n  * ä¸æ¯å‘¨ä¸€è‡³ä¸¤æ¬¡æ³¡æ¾¡æˆ–æ ¹æœ¬ä¸æ³¡æ¾¡ç›¸æ¯”ï¼Œæ¯å¤©æ´—çƒ­æ°´æ¾¡å¯ä»¥é™ä½28%çš„å¿ƒè¡€ç®¡ç–¾ç—…æ€»é£é™©ï¼Œé™ä½26%çš„ä¸­é£æ€»é£é™©ï¼Œè„‘å‡ºè¡€é£é™©ä¸‹é™46%ã€‚è€Œæµ´ç¼¸æµ´çš„é¢‘ç‡ä¸å¿ƒæºæ€§çŒæ­»çš„é£é™©å¢åŠ æ— å…³ã€‚\n\n##### 6.2.6. åšå®¶åŠ¡ï¼ˆè€å¹´ç”·æ€§ï¼‰\n\n* [Housework Reduces All-Cause and Cancer Mortality in Chinese Men](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061529)\n  * 72å²ä¹‹åç”·æ€§æ¯å‘¨åšé‡å‹å®¶åŠ¡å¯ä»¥å‡å°‘29%å¹³å‡æ­»äº¡ç‡\n  * é‡å‹å®¶åŠ¡ï¼šå¸å°˜ã€æ“¦åœ°æ¿ã€æ‹–åœ°ã€æ“¦æ´—çª—æˆ·ã€æ´—è½¦ã€æ¬åŠ¨å®¶å…·ã€æ¬ç…¤æ°”ç½ç­‰ç­‰ã€‚\n  * è½»å‹å®¶åŠ¡ï¼šæ¸ç°å°˜ã€æ´—ç¢—ã€æ‰‹æ´—è¡£æœã€ç†¨çƒ«ã€æ™¾è¡£æœã€åšé¥­ã€ä¹°æ—¥ç”¨å“ç­‰ç­‰ã€‚\n\n##### 6.2.7. ç¡çœ \n\n* [è¶…30ä¸‡äºšæ´²äººæ•°æ®ï¼šæ¯å¤©ç¡å‡ ä¸ªå°æ—¶æœ€æœ‰ç›Šé•¿å¯¿ï¼Ÿ](https://med.sina.com/article_detail_103_1_105491.html)\n  * åœ¨ç”·æ€§ä¸­ï¼Œä¸ç¡çœ æ—¶é•¿ä¸º7å°æ—¶ç›¸æ¯”ï¼šç¡çœ æŒç»­æ—¶é—´â‰¥10å°æ—¶ä¸å…¨å› æ­»äº¡é£é™©å¢åŠ 34%ç›¸å…³ï¼›\n  * ![ç¡çœ -ç”·](https://user-images.githubusercontent.com/2707039/163704166-226b7ebb-92ce-4753-a3e7-77a87652a104.jpg)\n  * åœ¨å¥³æ€§ä¸­ï¼Œä¸ç¡çœ æŒç»­æ—¶é—´7å°æ—¶ç›¸æ¯”ï¼šç¡çœ æŒç»­æ—¶é—´â‰¥10å°æ—¶ä¸å…¨å› æ­»äº¡é£é™©å¢åŠ 48%ç›¸å…³ï¼›\n  * ![ç¡çœ -å¥³](https://user-images.githubusercontent.com/2707039/163704169-c5c715aa-7130-403b-b0d1-ec34fab094d8.png)\n* [é¢ è¦†è®¤çŸ¥ï¼åŠ æ‹¿å¤§ç ”ç©¶å‘ç°ï¼šæ—©ç¡æ¯”ç†¬å¤œæˆ–è®¸æ›´ä¼¤èº«ï¼Œå‡ ç‚¹ç¡æ‰å¥½ï¼Ÿ](https://www.thepaper.cn/newsDetail_forward_14461799)\n  * å…¶ä¸­ä¸€ä¸ªç»“è®ºä¸ºï¼Œå°±å¯æ—¶é—´ä¸å…¨å› æ­»äº¡ç‡çš„å…³è”æ€§å¼ºï¼Œè¿‡æ—©ç¡è§‰å’Œè¿‡æ™šç¡è§‰éƒ½ä¼šå½±å“å¥åº·ï¼Œä½†æ˜¯æ—©ç¡å¢åŠ çš„å…¨å› æ­»äº¡ç‡æ¯”æ™šç¡å¢åŠ çš„æ­»äº¡ç‡é«˜ï¼Œæ—©ç¡å¢åŠ äº†43%çš„æ­»äº¡é£é™©ï¼Œè€Œæ™šç¡å¢åŠ äº†15%çš„æ­»äº¡é£é™©ã€‚\n  * è¿™é¡¹è°ƒæŸ¥ç ”ç©¶ï¼Œè¿˜å­˜åœ¨å¾ˆå¤šå±€é™æ€§ï¼Œæ¯”å¦‚æ²¡æœ‰ç›´æ¥è¯æ˜å°±å¯æ—¶é—´ä¸æ­»äº¡çš„å…³ç³»ï¼Œä»…ä»…è¯´æ˜ç›¸å…³æ€§ï¼Œé€šè¿‡å‚ä¸äººç¾¤è‡ªæˆ‘æŠ¥å‘Šç»Ÿè®¡ç¡çœ æ—¶é—´ï¼Œæ•°æ®ä¸å¤Ÿå®¢è§‚\n\n##### 6.2.8. ä¹…å\n\n* [ä¸­å›½å±…æ°‘è†³é£ŸæŒ‡å—ç§‘å­¦ç ”ç©¶æŠ¥å‘Šï¼ˆ2021å¹´ï¼‰](https://www.chinanutri.cn/yyjkzxpt/yyjkkpzx/yytsg/zgjm/202103/P020210311486742870527.pdf)\n  * ä¹…åå’Œçœ‹ç”µè§†æ—¶é—´ä¸å…¨å› æ­»äº¡ã€å¿ƒè¡€ç®¡ç–¾ç—…ã€ç™Œç—‡å’Œ2å‹ç³–å°¿ç—…å‘ç—…é«˜é£é™©ç›¸å…³ï¼Œæ˜¯ç‹¬ç«‹é£é™©å› ç´ ã€‚ä¹…åæ—¶é—´æ¯å¤©æ¯å¢åŠ 1å°æ—¶ï¼Œå¿ƒè¡€ç®¡ç–¾ç—…å‘ç”Ÿé£é™©å¢åŠ 4%ï¼Œç™Œç—‡å¢åŠ 1%ï¼Œå…¨å› æ­»äº¡é£é™©å¢åŠ 3%ã€‚å…¨å› æ­»äº¡å’ŒCVDæ­»äº¡é£é™©å¢åŠ çš„ä¹…åæ—¶é—´é˜ˆå€¼æ˜¯6\\~8h/dï¼Œçœ‹ç”µè§†æ—¶é—´é˜ˆå€¼æ˜¯3\\~4h/dã€‚\n* [ä¸–å«ç»„ç»‡å…³äºèº«ä½“æ´»åŠ¨å’Œä¹…åè¡Œä¸ºçš„æŒ‡å—](https://apps.who.int/iris/bitstream/handle/10665/337001/9789240014947-chi.pdf)\n\n#### 6.3. ä¸Šä¸‹æ–‡\n\n##### 6.3.1. æƒ…ç»ª\n\n* [æ‚²è§‚æƒ…ç»ªä¸æ›´é«˜çš„å…¨å› æ­»äº¡ç‡å’Œå¿ƒè¡€ç®¡ç–¾ç—…æ­»äº¡ç‡æœ‰å…³ï¼Œä½†ä¹è§‚æƒ…ç»ªå¹¶ä¸èƒ½èµ·åˆ°ä¿æŠ¤ä½œç”¨](https://www.x-mol.com/paper/1288184397379059712/t?recommendPaper=1263704526086578176)\n* [Pessimism is associated with greater all-cause and cardiovascular mortality, but optimism is not protective](https://www.nature.com/articles/s41598-020-69388-y?utm_source=xmol&utm_medium=affiliate&utm_content=meta&utm_campaign=DDCN_1_GL01_metadata_scirep)\n  * åœ¨1993-1995å¹´é—´ï¼Œä¸€é¡¹é’ˆå¯¹50å²ä»¥ä¸Šæ¾³å¤§åˆ©äºšäººå¥åº·çš„åŒèƒèƒç ”ç©¶ä¸­åŒ…æ‹¬äº†ç”Ÿæ´»å–å‘æµ‹è¯•ï¼ˆLOTï¼‰ï¼Œå…¶ä¸­åŒ…å«ä¹è§‚å’Œæ‚²è§‚çš„é¡¹ç›®ã€‚å¹³å‡20å¹´åï¼Œå‚ä¸è€…ä¸æ¥è‡ªæ¾³å¤§åˆ©äºšå›½å®¶æ­»äº¡æŒ‡æ•°çš„æ­»äº¡ä¿¡æ¯ç›¸åŒ¹é…ã€‚åœ¨2,978åå…·æœ‰å¾ˆå¤šå¯ç”¨åˆ†æ•°çš„å‚ä¸è€…ä¸­ï¼Œæœ‰1,068äººæ­»äº¡ã€‚ç”Ÿå­˜åˆ†ææµ‹è¯•äº†å„ç§ä¹è§‚å› ç´ å’Œæ‚²è§‚æƒ…ç»ªåˆ†æ•°ä¸ä»»ä½•åŸå› ï¼Œç™Œç—‡ï¼Œå¿ƒè¡€ç®¡ç–¾ç—…æˆ–å…¶ä»–å·²çŸ¥åŸå› çš„æ­»äº¡ç‡ä¹‹é—´çš„å…³è”ã€‚å¹´é¾„è°ƒæ•´åçš„æ‚²è§‚é‡è¡¨ä¸Šçš„æ ¸å¿ƒä¸å…¨å› å’Œå¿ƒè¡€ç®¡ç–¾ç—…æ­»äº¡ç‡ç›¸å…³ï¼ˆæ¯1ä¸ªæ ‡å‡†å·®å•ä½çš„å±é™©æ¯”ï¼Œ95ï¼…ç½®ä¿¡åŒºé—´å’Œpå€¼1.134ã€1.065â€“1.207ã€8.85Ã—10 â€“5å’Œ1.196ã€1.045â€“1.368ã€0.0093 ï¼‰ï¼Œä½†ä¸ä¼šå› ç™Œç—‡æ­»äº¡ã€‚ä¹è§‚å¾—åˆ†ä¸æ‚²è§‚å¾—åˆ†ä¹‹é—´çš„ç›¸å…³æ€§å¾ˆå¼±ï¼ˆå¹´é¾„è°ƒæ•´åçš„ç­‰çº§ç›¸å…³ç³»æ•°= âˆ’ 0.176ï¼‰ï¼Œä½†ä¸æ€»æ­»äº¡ç‡æˆ–ç‰¹å®šåŸå› æ­»äº¡ç‡æ²¡æœ‰æ˜¾ç€ç›¸å…³æ€§ã€‚åå‘å› æœå…³ç³»ï¼ˆå¼•èµ·æ‚²è§‚æƒ…ç»ªçš„ç–¾ç—…ï¼‰æ˜¯ä¸å¯èƒ½çš„ï¼Œå› ä¸ºåœ¨é‚£ç§æƒ…å†µä¸‹ï¼Œå¿ƒè¡€ç®¡ç–¾ç—…å’Œç™Œç—‡éƒ½ä¼šå¯¼è‡´æ‚²è§‚æƒ…ç»ªã€‚\n\n##### 6.3.2. è´«å¯Œ\n\n* [JAMAå­åˆŠï¼šè´«å¯Œå·®è·çœŸèƒ½å½±å“å¯¿å‘½ï¼Ÿè¿™å¯èƒ½æ˜¯çœŸçš„ï¼](https://www.cn-healthcare.com/articlewm/20210727/content-1246348.html)\n  * è¯¥ç ”ç©¶ä½¿ç”¨1994-1996å¹´ç¬¬ä¸€æ¬¡æ”¶é›†çš„æ•°æ®ï¼Œå¹¶é€šè¿‡ç”Ÿå­˜æ¨¡å‹æ¥åˆ†æå‡€èµ„äº§å’Œé•¿å¯¿ä¹‹é—´çš„å…³è”ã€‚ç»“æœæ˜¾ç¤ºï¼Œå…±æ”¶çº³5414 åå‚ä¸è€…ï¼Œå¹³å‡å¹´é¾„ä¸º 46.7å²ï¼ŒåŒ…æ‹¬ 2766 åå¥³æ€§ã€‚è¾ƒé«˜çš„å‡€èµ„äº§ä¸è¾ƒä½çš„æ­»äº¡é£é™©ç›¸å…³ã€‚ç‰¹åˆ«æ˜¯åœ¨å…„å¼Ÿå§å¦¹å’ŒåŒèƒèƒä¸­ï¼ˆn = 2490ï¼‰ï¼Œåœ¨è¾ƒé«˜çš„å‡€èµ„äº§å’Œè¾ƒä½çš„æ­»äº¡ç‡ä¹‹é—´è§‚å¯Ÿåˆ°ç±»ä¼¼çš„å…³è”ï¼Œè¡¨æ˜æ‹¥æœ‰æ›´å¤šè´¢å¯Œçš„å…„å¼Ÿå§å¦¹æˆ–åŒèƒèƒæ¯”æ‹¥æœ‰æ›´å°‘è´¢å¯Œçš„å…„å¼Ÿå§å¦¹/åŒèƒèƒæ´»å¾—æ›´ä¹…ã€‚\n\n##### 6.3.3. ä½“é‡\n\n* [JAMAå­åˆŠï¼šå‡è‚¥è¦è¶æ—©ï¼Œæ‰èƒ½æœ‰æ•ˆé™ä½æ­»äº¡ç‡é£é™©](https://www.chinacdc.cn/gwxx/202009/t20200904_218959.html)\n  * å¯¹ä½“é‡å‡è½»çš„æ­»äº¡ç‡é£é™©è¯„ä¼°å‘ç°ï¼Œä½“é‡ä»è‚¥èƒ–å‡è½»åˆ°è¶…é‡çš„æˆå¹´äººä¸ç¨³å®šè‚¥èƒ–äººç¾¤ç›¸æ¯”ï¼Œå…¨å› æ­»äº¡ç‡é™ä½äº†54ï¼…ï¼ˆå±é™©æ¯”ä¸º0.46ï¼‰ï¼Œç„¶è€Œä»æˆå¹´åˆæœŸçš„è¶…é‡å‡è½»åˆ°ä¸­å¹´ä»¥å‰çš„æ­£å¸¸ä½“é‡çš„äººç¾¤çš„æ­»äº¡ç‡é£é™©å¹¶æœªé™ä½ï¼ˆé£é™©æ¯”ä¸º1.12ï¼‰ã€‚\n  * ![Table3](https://raw.githubusercontent.com/qhy040404/Image-Resources-Repo/master/zoi200509t3_1596761185.02415.png)\n\n##### 6.3.4. æ–°å† \n\n* [Magnitude, demographics and dynamics of the effect of the first wave of the COVID-19 pandemic on all-cause mortality in 21 industrialized countries](https://www.nature.com/articles/s41591-020-1112-0.pdf)\n  * ç›®å‰æ¥çœ‹ï¼Œæ–°å† æ­»äº¡ç‡ï¼ˆç¾å›½ï¼‰åœ¨1.5%å·¦å³ï¼Œäººå‡é¢„æœŸå¯¿å‘½å‡å°‘äº†2å¹´\n* [å¦‚ä½•çœ‹å¾…ç¾å›½CDCå®£ç§°æ–°å† æ­»äº¡äººæ•°è¢«é«˜ä¼°ï¼Ÿ](https://www.zhihu.com/question/510943670/answer/2308499719)\n* [NVSS deaths](https://www.cdc.gov/nchs/nvss/deaths.htm)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "longevity",
        "wellness",
        "mortality",
        "improving longevity",
        "longevity nutrition",
        "lifestyle insights"
      ],
      "category": "healthcare-and-medical"
    },
    "ahmedjemaa-tech--medical-coding-reproducibility": {
      "owner": "ahmedjemaa-tech",
      "name": "medical-coding-reproducibility",
      "url": "https://github.com/ahmedjemaa-tech/medical-coding-reproducibility",
      "imageUrl": "/freedevtools/mcp/pfp/ahmedjemaa-tech.webp",
      "description": "Automates the process of assigning diagnosis and procedure codes from electronic health records. Utilizes advanced models to improve accuracy and efficiency in medical coding tasks, with tools and datasets from MIMIC-III and MIMIC-IV.",
      "stars": 0,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "",
      "updated_at": "2025-03-29T10:21:50Z",
      "readme_content": "# âš•ï¸Automated Medical Coding on MIMIC-III and MIMIC-IV: A Critical Review and Replicability Study\n\nOfficial source code repository for the SIGIR 2023 paper [Automated Medical Coding on MIMIC-III and MIMIC-IV: A Critical Review and Replicability Study](https://dl.acm.org/doi/10.1145/3539618.3591918)\n\n\n```bibtex\n@inproceedings{edinAutomatedMedicalCoding2023,\n  address = {Taipei, Taiwan},\n  title = {Automated {Medical} {Coding} on {MIMIC}-{III} and {MIMIC}-{IV}: {A} {Critical} {Review} and {Replicability} {Study}},\n  isbn = {978-1-4503-9408-6},\n  shorttitle = {Automated {Medical} {Coding} on {MIMIC}-{III} and {MIMIC}-{IV}},\n  doi = {10.1145/3539618.3591918},\n  booktitle = {Proceedings of the 46th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},\n  publisher = {ACM Press},\n  author = {Edin, Joakim and Junge, Alexander and Havtorn, Jakob D. and Borgholt, Lasse and Maistro, Maria and Ruotsalo, Tuukka and MaalÃ¸e, Lars},\n  year = {2023}\n}\n```\n\n## Update\nWe released a new [paper](https://arxiv.org/pdf/2406.08958) and [repository](https://github.com/JoakimEdin/explainable-medical-coding/tree/main) for explainable medical coding. The new repository offers the following:\n- **Explainability**: Multiple feature attribution methods and metrics for multi-label classification. \n- **Implementation of a modified PLM-ICD**: We have fixed the problem of PLM-ICD occasionally collapsing during training.\n- **Huggingface Datasets**: we implemented MIMIC-III, IV, and MDACE as HuggingFace datasets.\n- **Inference code**: We provide code for inference without needing the training dataset.\nThe new repository no longer supports CNN, Bi-GRU, CAML, LAAT, and MultiResCNN.\n\nAlso, check out [my blog post](https://substack.com/home/post/p-145913061?source=queue) criticizing popular ideas in automated medical coding. I think it will be interesting for most researchers in the field\n\n## Introduction \nAutomatic medical coding is the task of automatically assigning diagnosis and procedure codes based on discharge summaries from electronic health records. This repository contains the code used in the paper Automated medical coding on MIMIC-III and MIMIC-IV: A Critical Review and Replicability Study. The repository contains code for training and evaluating medical coding models and new splits for MIMIC-III and the newly released MIMIC-IV. The following models have been implemented:\n\n| Model | Paper | Original Code |\n| ----- | ----- | ------------- |\n| CNN   |[Explainable Prediction of Medical Codes from Clinical Text](https://aclanthology.org/N18-1100/) | [link](https://github.com/jamesmullenbach/caml-mimic) | \n| Bi-GRU|[Explainable Prediction of Medical Codes from Clinical Text](https://aclanthology.org/N18-1100/) | [link](https://github.com/jamesmullenbach/caml-mimic) | \n|CAML   |[Explainable Prediction of Medical Codes from Clinical Text](https://aclanthology.org/N18-1100/) | [link](https://github.com/jamesmullenbach/caml-mimic) | \n| MultiResCNN | [ICD Coding from Clinical Text Using Multi-Filter Residual Convolutional Neural Network](https://arxiv.org/pdf/1912.00862.pdf) | [link](https://github.com/foxlf823/Multi-Filter-Residual-Convolutional-Neural-Network) |\n| LAAT | [A Label Attention Model for ICD Coding from Clinical Text](https://arxiv.org/abs/2007.06351) | [link](https://github.com/aehrc/LAAT) |\n| PLM-ICD | [PLM-ICD: Automatic ICD Coding with Pretrained Language Models](https://aclanthology.org/2022.clinicalnlp-1.2/) | [link](https://github.com/MiuLab/PLM-ICD) |\n\nThe splits are found in `files/data`. The splits are described in the paper.\n\n## How to reproduce results\n### Setup Conda environment\n1. Create a conda environement `conda create -n coding python=3.10`\n2. Install the packages `pip install . -e`\n\n### Prepare MIMIC-III\nThis code has been developed on MIMIC-III v1.4. \n1. Download the MIMIC-III data into your preferred location `path/to/mimiciii`. Please note that you need to complete training to acces the data. The training is free, but takes a couple of hours.  - [link to data access](https://physionet.org/content/mimiciii/1.4/)\n2. Open the file `src/settings.py`\n3. Change the variable `DOWNLOAD_DIRECTORY_MIMICIII` to the path of your downloaded data `path/to/mimiciii`\n4. If you want to use the MIMIC-III full and MIMIC-III 50 from the [Explainable Prediction of Medical Codes from Clinical Text](https://aclanthology.org/N18-1100/) you need to run `python prepare_data/prepare_mimiciii_mullenbach.py`\n5. If you want to use MIMIC-III clean from our paper you need to run `python prepare_data/prepare_mimiciii.py`\n\n### Prepare MIMIC-IV\nThis code has been developed on MIMIC-IV and MIMIC-IV v2.2. \n1. Download MIMIC-IV and MIMIC-IV-NOTE into your preferred location `path/to/mimiciv` and `path/to/mimiciv-note`. Please note that you need to complete training to acces the data. The training is free, but takes a couple of hours.  - [mimiciv](https://physionet.org/content/mimiciv/2.2/) and [mimiciv-note](https://physionet.org/content/mimic-iv-note/2.2/)\n2. Open the file `src/settings.py`\n3. Change the variable `DOWNLOAD_DIRECTORY_MIMICIV` to the path of your downloaded data `path/to/mimiciv`\n4. Change the variable `DOWNLOAD_DIRECTORY_MIMICIV_NOTE` to the path of your downloaded data `path/to/mimiciv-note`\n5. Run `python prepare_data/prepare_mimiciv.py`\n\n### Before running experiments\n1. Create a weights and biases account. It is possible to run the experiments without wandb.\n2. Download the [model checkpoints](https://drive.google.com/file/d/1hYeJhztAd-JbhqHojY7ZpLtkBcthD8AK/view?usp=share_link) and unzip it. Please note that these model weights can't be used commercially due to the MIMIC License.\n3. If you want to train PLM-ICD, you need to download [RoBERTa-base-PM-M3-Voc](https://dl.fbaipublicfiles.com/biolm/RoBERTa-base-PM-M3-Voc-hf.tar.gz), unzip it and change the `model_path` parameter in `configs/model/plm_icd.yaml` and `configs/text_transform\n/huggingface.yaml` to the path of the download. \n\n### Running experiments\n#### Training\nYou can run any experiment found in `configs/experiment`. Here are some examples:\n   * Train PLM-ICD on MIMIC-III clean on GPU 0: `python main.py experiment=mimiciii_clean/plm_icd gpu=0`\n   * Train CAML on MIMIC-III full on GPU 6: `python main.py experiment=mimiciii_full/caml gpu=6`\n   * Train LAAT on MIMIC-IV ICD-9 full on GPU 6: `python main.py experiment=mimiciv_icd9/laat gpu=6`\n   * Train LAAT on MIMIC-IV ICD-9 full on GPU 6 without weights and biases: `python main.py experiment=mimiciv_icd9/laat gpu=6 callbacks=no_wandb trainer.print_metrics=true`\n   \n#### Evaluation\nIf you just want to evaluate the models using the provided model_checkpoints you need to do set `trainer.epochs=0` and provide the path to the models checkpoint `load_model=path/to/model_checkpoint`. Make sure you the correct model-checkpoint with the correct configs.\n\nExample:\nEvaluate PLM-ICD on MIMIC-IV ICD-10 on GPU 1: `python main.py experiment=mimiciv_icd10/plm_icd gpu=1 load_model=path/to/model_checkpoints/mimiciv_icd10/plm_icd trainer.epochs=0`\n\n## Overview of the repository\n#### configs\nWe use [Hydra](https://hydra.cc/docs/intro/) for configurations. The condigs for every experiment is found in `configs/experiments`. Furthermore, the configuration for the sweeps are found in `configs/sweeps`. We used [Weights and Biases Sweeps](https://docs.wandb.ai/guides/sweeps) for most of our experiments.\n\n#### files\nThis is where the images and data is stored.\n\n#### notebooks\nThe directory only contains one notebook used for the code analysis. The notebook is not aimed to be used by others, but is included for others to validate our data analysis.\n\n#### prepare_data\nThe directory contains all the code for preparing the datasets and generating splits.\n\n#### reports\nThis is the code used to generate the plots and tables used in the paper. The code uses the Weights and Biases API to fetch the experiment results. The code is not usable by others, but was included for the possibility to validate our figures and tables.\n\n#### src\nThis is were the code for running the experiments is found.\n\n#### tests\nThe directory contains the unit tests\n\n## My setup\nI ran the experiments on one RTX 2080 Ti 11GB per experiment. I had 128 GB RAM on my machine.\n\n## âš ï¸ Known issues \n* LAAT and PLM-ICD are unstable. The loss will sometimes diverge during training. The issue seems to be overflow in the softmax function in the label-wise attention. Using batch norm or layer norm before the softmax function might solve the issue. We did not try to fix the issue as we didn't want to change the original method during our reproducibility.\n* The code was only tested on a server with 128 GB RAM. A user with 32 GB RAM reported issues fitting MIMIC-IV into memory.\n* There is an error in the collate function in the Huggingface dataset. The attention mask is being padded with 1s instead of 0s. I have not fixed this issue because I want people to be able to reproduce the results from the paper.\n\n## Acknowledgement\nThank you Sotiris Lamprinidis for providing an efficient implementation of our multi-label stratification algorithm and some data preprocessing helper functions.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "coding",
        "datasets",
        "medical",
        "medical coding",
        "datasets mimic",
        "coding reproducibility"
      ],
      "category": "healthcare-and-medical"
    },
    "ctvidic--whoop-mcp-server": {
      "owner": "ctvidic",
      "name": "whoop-mcp-server",
      "url": "https://github.com/ctvidic/whoop-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/ctvidic.webp",
      "description": "Access Whoop data for insights into cycles, recovery, strain, and workout metrics by querying the Whoop API. Retrieve data based on specific date ranges or calculate averages for strain over time.",
      "stars": 12,
      "forks": 4,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-08-22T15:17:33Z",
      "readme_content": "# Whoop MCP Server\nPython Package License: MIT Python 3.12\n\nA Model Context Protocol (MCP) server that provides access to the Whoop API. It allows language models to query cycles, recovery, strain, and workout data from the Whoop API.\n\n## Available Tools\n\nThe server exposes the following tools:\n\n### Cycle Queries\n- `get_cycle_collection(start_date: str, end_date: str)`: Get cycle data for a specific date range\n- `get_latest_cycle()`: Get the most recent cycle data\n\n### Recovery and Strain\n- `get_recovery_data(start_date: str, end_date: str)`: Get recovery data for a specific date range\n- `get_strain_data(start_date: str, end_date: str)`: Get strain data for a specific date range\n- `get_average_strain(days: int = 7)`: Calculate average strain over specified number of days\n\n### Profile and Authentication\n- `get_profile()`: Get user profile information\n- `check_auth_status()`: Check authentication status with Whoop API\n\nDates should be provided in ISO format (YYYY-MM-DD).\n\n## Usage\n\nYou'll need Whoop credentials to use this server. The server uses email/password authentication with the Whoop API.\n\n### Claude for Desktop\n\nUpdate your `claude_desktop_config.json` (located in `~/Library/Application\\ Support/Claude/claude_desktop_config.json` on macOS and `%APPDATA%/Claude/claude_desktop_config.json` on Windows) to include the following:\n\n```json\n{\n    \"mcpServers\": {\n        \"Whoop\": {\n            \"command\": \"python\",\n            \"args\": [\"/path/to/whoop/src/whoop_server.py\"],\n            \"cwd\": \"/path/to/whoop\",\n            \"env\": {\n                \"WHOOP_EMAIL\": \"your.email@example.com\",\n                \"WHOOP_PASSWORD\": \"your_password\"\n            }\n        }\n    }\n}\n```\n\n### HTTP API Server\n\nThe project also includes an HTTP API server that exposes the same functionality over HTTP endpoints. To run it:\n\n```bash\n./run_whoop_server.sh\n```\n\n## Example Queries\n\nOnce connected, you can ask Claude questions like:\n\n- \"What's my recovery score for today?\"\n- \"Show me my strain data for the past week\"\n- \"What's my average strain over the last 7 days?\"\n- \"Get my latest cycle data\"\n\n## Error Handling\n\nThe server provides human-readable error messages for common issues:\n- Invalid date formats\n- API authentication errors\n- Network connectivity problems\n- Missing or invalid credentials\n\n## Project Structure\n\n```\nwhoop/\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ whoop_server.py      # MCP server implementation\nâ”‚   â””â”€â”€ whoop_http_server.py # HTTP API server implementation\nâ”œâ”€â”€ config/\nâ”‚   â””â”€â”€ .env                 # Environment variables\nâ”œâ”€â”€ requirements.txt         # Python dependencies\nâ””â”€â”€ run_whoop_server.sh     # Script to run HTTP server\n```\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details. ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "whoop",
        "mcp",
        "api",
        "whoop data",
        "whoop api",
        "access whoop"
      ],
      "category": "healthcare-and-medical"
    },
    "eka-care--eka_mcp_server": {
      "owner": "eka-care",
      "name": "eka_mcp_server",
      "url": "https://github.com/eka-care/eka_mcp_server",
      "imageUrl": "/freedevtools/mcp/pfp/eka-care.webp",
      "description": "Provides healthcare professionals with curated medical knowledge and drug information specific to India, enhancing AI responses by grounding them in verified medical data and treatment protocols. Facilitates access to extensive branded drug databases and treatment guidelines to improve clinical decision-making.",
      "stars": 19,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-11T13:27:27Z",
      "readme_content": "# Eka MCP Server\n[![License: MIT](https://img.shields.io/badge/license-MIT-C06524)](https://github.com/eka-care/eka_mcp_server/blob/main/LICENSE)\n[![PyPI - Version](https://img.shields.io/pypi/v/eka_mcp_server.svg)](https://pypi.org/project/eka_mcp_server)\n[![Downloads](https://static.pepy.tech/badge/eka_mcp_server/month)](https://pepy.tech/project/eka_mcp_server)\n\n## Overview\n\nEka Care's Model Context Protocol (MCP) server facilitates interaction with medical knowledge-bases specifically curated for the Indian healthcare context. While advanced models from Claude, OpenAI, and others can perform adequately in medical contexts, their responses often lack grounding in factual information and published references. Additionally, India faces a significant challenge with the absence of centralized repositories for branded medications in the public domain.\n\nThe Eka MCP Server addresses these challenges by providing structured access to curated knowledge-bases through specialized tools:\n\n* **Indian Branded Drug Search**: Enables lookup across 500,000+ branded drugs available in India, returning comprehensive metadata including generic composition and manufacturer information to enhance LLM responses.\n* **Indian Treatment Protocol Search**: Provides contextual access to over 180 treatment protocol documents published by authoritative Indian healthcare institutions such as ICMR and RSSDI.\n\n\nKey Benefits:\n* ğŸ©º Medical Accuracy: Grounds AI responses in verified healthcare information\n* ğŸ”„ Seamless Workflow: Provides critical information without requiring context switching\n* ğŸ›¡ï¸ Reduced Hallucinations: Relies on curated medical data rather than AI's implicit general knowledge\n* ğŸŒ Open Ecosystem: Integrates with the growing MCP open standard\n\n# Get Started\n## Get your developer key from eka.care\n> [!NOTE]  \n> To obtain the `client-id`, and `client-token` reach out to us on ekaconnect@eka.care\n\n\n## Installation and Setup for Claude Desktop\n1. Install UV - https://docs.astral.sh/uv/getting-started/installation/#installation-methods\n2. Install Claude desktop application - https://claude.ai/download\n3. Locate the configuration file:\n   - **macOS**: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n   - **Windows**: `%APPDATA%/Claude/claude_desktop_config.json`\n   \n   In case the file does not exist, create a new file named `claude_desktop_config.json` in the above directory.\n4. Modify/Create the configuration file with the following settings:\n\n```json\n{\n  \"mcpServers\": {\n    \"eka-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"eka_mcp_server\",\n        \"--eka-api-host\",\n        \"https://api.eka.care\",\n        \"--client-id\",\n        \"<client_id>\",\n        \"--client-secret\",\n        \"<client_secret>\"\n      ]\n    }\n  }\n}\n```\n5. Replace the placeholder values:\n   - `<client_id>`: Your client ID\n   - `<client_secret>`: Your client secret\n\n## Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging experience, we recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector uvx eka_mcp_server --eka-api-host https://api.eka.care --client-id <client_id> --client-secret <client_secret>\n```\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n\n## Troubleshooting common issues\n\n### spawn uvx ENOENT\nThis commonly happens when uvx is not installed or the command cannot be discovered.\n![spawn uvx ENOENT screenshot](assets/uvx_debug.png)\n\n\n1. Install uv through this command \n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n2. Find the path of our uvx installation\n```bash\nwhich uvx\n```\nThe output might be something like this\n```\n> /opt/homebrew/bin/uvx\n```\n\nIn your config, update the command to the full path of the `uvx` executable. For example:\n```json\n{\n  \"mcpServers\": {\n    \"eka-mcp-server\": {\n      \"command\": \"/opt/homebrew/bin/uvx\",\n      \"args\": [\n        \"eka_mcp_server\",\n        \"--eka-api-host\",\n        \"https://api.eka.care\",\n        \"--client-id\",\n        \"<client_id>\",\n        \"--client-secret\",\n        \"<client_secret>\"\n      ]\n    } \n  }\n}\n```\n### Latest version of eka_mcp_server is not being picked?\nRun the command below in case the latest version is not being picked.\nThis cleans up the local cache and fetches the latest version.\n```\nuv cache clean eka_mcp_server\n```\n\n\n# Tools\n> EKA MCP server tools are curated by the in-house doctors at eka.care and have been validated on an internal set of questionnaire \n\n## Medications tool suite\n### Indian branded drug search \n<details>\n<summary>Tool definition here</summary>\nhttps://github.com/eka-care/eka_mcp_server/blob/9520c346e19c6ccafe80ca770dea9b824871ef1d/src/eka_mcp_server/constants.py#L1\n</details>\n\nAccess comprehensive information about drugs from a corpus of drugs based on the drug name or generic composition and filtered further through the drug form and volume.\n\n![Indian branded drug search](assets/indian_branded_drug_search.png)\n\nAPIs required for this tool\n   - https://developer.eka.care/api-reference/eka_mcp/medications/search \n\n### Indian Pharmacology details\n<details>\n<summary>Tool definition here</summary>\n</details>\n\nGet details of a generic composition based on the 2011 published guidelines by the National Formulary of India. \n\n\n\n## Indian treatment protocol search\n<details>\n<summary>Tool definition here</summary>\nhttps://github.com/eka-care/eka_mcp_server/blob/9520c346e19c6ccafe80ca770dea9b824871ef1d/src/eka_mcp_server/constants.py#L10\n</details>\n\nStandardized guidelines, procedures, and decision pathways for healthcare professionals are published by medical bodies.\nThey serve as comprehensive roadmaps for clinical care, ensuring consistent and evidence-based treatment approaches.\n\nCurrent Coverage:\n* 175 medical conditions/tags\n* 180 treatment protocols\n* Multiple authoritative publishers\n\n### Indian treatment protocol search workflow\n1. For any given query, the LLM has to decide if the tag is supported or not through [this API](http://developer.eka.care/api-reference/eka_mcp/protocols/tags). During the init of the tool, we fetch the supported conditions.\n2. Then, for the given tag, the LLM has to get the publishers that address that tag through [this API](http://developer.eka.care/api-reference/eka_mcp/protocols/publishers_by_tag).\n3. Finally, with the tag, publisher and query, we fetch the relevant information from the repository of publishers through [this API](http://developer.eka.care/api-reference/eka_mcp/protocols/search).\n\nAPIs required for this tool\n1. http://developer.eka.care/api-reference/eka_mcp/protocols/tags\n2. http://developer.eka.care/api-reference/eka_mcp/protocols/publishers_by_tag\n3. http://developer.eka.care/api-reference/eka_mcp/protocols/search\n\n![Indian treatment protocol search](assets/indian_treatment_protocol_search.png)\n\n## Accuracy Disclaimer\n\nThe Eka MCP Server provides access to medical knowledge bases and drug information intended to support healthcare professionals in India. While we strive for accuracy and reliability, please note:\n\n- The information provided through this service is for informational purposes only and does not constitute medical advice.\n- Healthcare professionals should exercise their own clinical judgment when using this information.\n- Drug information and treatment protocols may change over time, and we make reasonable efforts to keep our databases updated.\n- We cannot guarantee 100% accuracy or completeness of all information, particularly for newly approved medications or recently updated treatment guidelines.\n- Users should verify critical information through official sources before making clinical decisions.\n- Our database of protocols is ever growing, but does not ensure completeness.\n\nEka Care assumes no liability for any errors, omissions, or outcomes resulting from the use of information provided through this service.\n\n\n### Bugs and Issue Reporting\nPlease report any issues or bugs on the GitHub issue tracker.\n\n## FAQ\n**Q: Can I use this without an eka.care account?**\n\nA: No, you need valid API credentials from eka.care to access the medical information.\n\n**Q: Is this service free?**\n\nA: While the MCP server code is open-source, access to eka.care's APIs requires valid credentials.\nFor the initial few days, we are offering free access to the APIs. However, we will be charging for the API usage in the future.\n\n**Q: Which LLMs support MCP natively?**\n\nA: Currently, Anthropic's Claude models have native MCP support and also Cursor and Windsurf applications.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "eka_mcp_server",
        "eka",
        "healthcare",
        "medical eka",
        "care eka_mcp_server",
        "eka_mcp_server provides"
      ],
      "category": "healthcare-and-medical"
    },
    "flexpa--mcp-fhir": {
      "owner": "flexpa",
      "name": "mcp-fhir",
      "url": "https://github.com/flexpa/mcp-fhir",
      "imageUrl": "/freedevtools/mcp/pfp/flexpa.webp",
      "description": "Access and search FHIR resources with standardized formats for healthcare data. Interact with FHIR resources via URIs and utilize search capabilities for efficient data retrieval.",
      "stars": 55,
      "forks": 9,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-01T17:08:53Z",
      "readme_content": "# @flexpa/mcp-fhir\n\n> [!WARNING]\n> This is an experimental demo not intended for production use.\n\nThis is a TypeScript-based MCP server that connects to a FHIR server. It provides core MCP functionality for interacting with FHIR resources by:\n\n- Accessing FHIR resources via URIs\n- Providing search capabilities for FHIR resources\n\n## Features\n\n### Resources\n\n> [!TIP]\n> \"Resources\" here refers to the MCP definition _not_ the FHIR one. MCP Resources are a core primitive in the Model Context Protocol (MCP) that allow servers to expose data and content that can be read by clients and used as context for LLM interactions.\n\n- List and access FHIR resources via `fhir://` URIs\n- Resources are returned in FHIR JSON format\n- Supports all FHIR Resource types available in the FHIR server's CapabilityStatement\n\n### Tools\n- `search_fhir` - Search FHIR resources\n  - Takes `resourceType` and `searchParams` as parameters\n  - Returns FHIR search results\n- `read_fhir` - Read an individual FHIR resource\n  - Takes `uri` as a parameter\n  - Returns the FHIR resource in JSON format\n\n## Configuration\n\nThe server requires the following environment variables:\n- `FHIR_BASE_URL`: The base URL of your FHIR server\n- `FHIR_ACCESS_TOKEN`: A SMART on FHIR access token for authentication\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"fhir\": {\n      \"command\": \"/path/to/@flexpa/mcp-fhir/build/index.js\"\n    },\n    \"env\": {\n      \"FHIR_BASE_URL\": \"<FHIR_BASE_URL>\",\n      \"FHIR_ACCESS_TOKEN\": \"<FHIR_ACCESS_TOKEN>\"\n    }\n  }\n}\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "fhir",
        "retrieval",
        "search",
        "search fhir",
        "fhir resources",
        "fhir access"
      ],
      "category": "healthcare-and-medical"
    },
    "jmandel--health-record-mcp": {
      "owner": "jmandel",
      "name": "health-record-mcp",
      "url": "https://github.com/jmandel/health-record-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/jmandel.webp",
      "description": "Connects AI models to Electronic Health Records (EHRs) using the SMART on FHIR standard to securely extract and analyze patient data, leveraging the Model Context Protocol for seamless access to structured health data and clinical notes.",
      "stars": 63,
      "forks": 21,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-13T17:30:01Z",
      "readme_content": "# EHR Tools with MCP and FHIR\n![EHR Tools Overview](static/overview.png)\n\nhttps://youtu.be/K0t6MRyIqZU?si=Mz4d65DcAD3i2YbO\n\nThis project acts as a specialized server providing tools for Large Language Models (LLMs) and other AI agents to interact with Electronic Health Records (EHRs). It leverages the **SMART on FHIR** standard for secure data access and the **Model Context Protocol (MCP)** to expose the tools.\n\nThink of it as a secure gateway and toolkit enabling AI to safely access and analyze patient data from diverse EHR systems.\n\n## The Core Idea\n\nThe system works in three main stages:\n\n1.  **SMART on FHIR Client (Implemented within this project):** Connects securely to an EHR using the standard SMART App Launch framework. It extracts a wide range of patient information, including both structured data (like conditions, medications, labs) and unstructured clinical notes or attachments.\n2.  **MCP Server (This Project):** Takes the extracted EHR data and makes it available through a set of powerful tools accessible via the Model Context Protocol. These tools allow external systems (like AI models) to query and analyze the data without needing direct access to the EHR itself.\n3.  **AI / LLM Interface (External Consumer):** An AI agent or Large Language Model connects to the MCP Server and uses the provided tools to \"ask questions\" about the patient's record, perform searches, or run custom analyses.\n\n## Available Tools\n\nThe MCP Server offers several tools for interacting with the loaded EHR data:\n\n*   `grep_record`: Performs text or regular expression searches across *all* parts of the fetched record (structured FHIR data + text from notes/attachments). Ideal for finding keywords or specific mentions (e.g., \"diabetes\", \"aspirin\").\n*   `query_record`: Executes read-only SQL `SELECT` queries directly against the structured FHIR data. Useful for precise lookups based on known FHIR resource structures (e.g., finding specific lab results by LOINC code).\n*   `eval_record`: Executes custom JavaScript code directly on the fetched data (FHIR resources + attachments). Offers maximum flexibility for complex calculations, combining data from multiple sources, or custom formatting.\n\nThis setup allows AI tools to leverage comprehensive EHR data through a standardized and secure interface.\n\n*(Developer setup and usage details can be found within the codebase and specific module documentation.)*\n\n---\n\n## Components & Usage\n\nThis project offers different ways to fetch EHR data and expose it via MCP tools:\n\n### 1. Standalone SMART on FHIR Web Client\n\nThis project includes a self-contained web application that allows users to connect to their EHR via SMART on FHIR and fetch their data.\n\n*   **Hosted Version:** You can use a publicly hosted version at: \\\n    [`https://mcp.fhir.me/ehr-connect#deliver-to-opener:$origin`](https://mcp.fhir.me/ehr-connect#deliver-to-opener:$origin) \\\n    (Replace `$origin` with the actual origin of the window that opens this link).\n*   **Filtering Brands (`?brandTags`):** You can filter the list of EHR providers shown on the connection page by adding the `brandTags` query parameter to the URL. Provide a comma-separated list of tags. Only brands matching *all* provided tags (from their configuration in `brandFiles`) will be displayed.\n    It supports both OR (comma-separated) and AND (caret `^` separated) logic, with AND taking precedence.\n    *   `?brandTags=epic,sandbox`: Shows brands tagged with `epic` OR `sandbox`.\n    *   `?brandTags=epic^dev`: Shows brands tagged with both `epic` AND `dev`.\n    *   `?brandTags=epic^dev,sandbox^prod`: Shows brands tagged with (`epic` AND `dev`) OR (`sandbox` AND `prod`).\n    *   If the parameter is omitted, it defaults to showing brands tagged with `prod`.\n    *   Example: `.../ehr-connect?brandTags=hospital^us`: Shows brands tagged with `hospital` AND `us`.\n*   **How it Works:** When opened, this page prompts the user to select their EHR provider. It then initiates the standard SMART App Launch flow, redirecting the user to their EHR's login page. After successful authentication and authorization, the client fetches a comprehensive set of FHIR resources (Patient, Conditions, Observations, Medications, Documents, etc.) and attempts to extract plaintext from any associated attachments (like PDFs, RTF, HTML found in `DocumentReference`).\n*   **Data Output (`ClientFullEHR`):** Once fetching is complete, the client gathers all the data into a `ClientFullEHR` JSON object. This object contains:\n    *   `fhir`: A dictionary where keys are FHIR resource types (e.g., \"Patient\") and values are arrays of the corresponding FHIR resources.\n    *   `attachments`: An array of processed attachment objects, each including metadata (source resource, path, content type) and the content itself (`contentBase64` for raw data, `contentPlaintext` for extracted text).\n*   **Data Delivery:** If opened with the `#deliver-to-opener:$origin` hash, the client will prompt the user for confirmation and then send the `ClientFullEHR` object back to the window that opened it using `window.opener.postMessage(data, targetOrigin)`.\n\n### 2. Local MCP Server via Stdio (`src/cli.ts`)\n\nThis mode is ideal for running the MCP server locally, often used with tools like Cursor or other command-line AI clients.\n\n*   **Two-Step Process:**\n    1.  **Fetch Data to Database:** First, run the command-line interface with the `--create-db` and `--db` flags. This starts a temporary web server and uses the same SMART on FHIR web client logic described above to fetch data. Instead of sending the data via `postMessage`, it saves the `ClientFullEHR` data into a local SQLite database file.\n        ```bash\n        # Example: Fetch data and save to data/my_record.sqlite\n        bun run src/cli.ts --create-db --db ./data/my_record.sqlite\n        ```\n        Follow the prompts (opening a link in your browser) to connect to your EHR.\n    2.  **Run MCP Server:** Once the database file is created, run the CLI again, pointing only to the database file. This loads the data into memory and starts the MCP server, listening for commands on standard input/output.\n        ```bash\n        # Example: Start the MCP server using the saved data\n        bun run src/cli.ts --db ./data/my_record.sqlite\n        ```\n    *   **Configuration (`config.*.json`):** This process relies on a configuration file (e.g., `config.epicsandbox.json`) which defines available EHR brands/endpoints in a `brandFiles` array. Each entry in this array specifies the brand's details, including:\n        *   `url`: Path/URL to the brand definition file (like `static/brands/epic-sandbox.json`).\n        *   `tags`: An array of strings (e.g., `[\"epic\", \"sandbox\"]`) used for categorization or filtering.\n        *   `vendorConfig`: Contains SMART on FHIR client details (`clientId`, `scopes`).\n*   **Client Configuration (e.g., Cursor):** Configure your MCP client to execute this command. **Crucially, use absolute paths** for both `src/cli.ts` and the database file.\n    ```json\n    {\n      \"mcpServers\": {\n        \"local-ehr\": {\n          \"name\": \"Local EHR Search\",\n          \"command\": \"bun\", // Or the absolute path to bun\n          \"args\": [\n              \"/home/user/projects/smart-mcp/src/cli.ts\", // Absolute path to cli.ts\n              \"--db\",\n              \"/home/user/projects/smart-mcp/data/my_record.sqlite\" // Absolute path to DB file\n            ]\n        }\n      }\n    }\n    ```\n\n### 3. Full MCP Server via SSE (`src/sse.ts` / `index.ts`)\n\nThis mode runs a persistent server suitable for scenarios where multiple clients might connect over the network. It uses Server-Sent Events (SSE) for the MCP communication channel.\n\n*   **Authentication:** Client authentication relies on OAuth 2.1, as specified by the Model Context Protocol. The server provides standard endpoints (`/authorize`, `/token`, `/register`, etc.).\n*   **Data Fetch:** When a client initiates an OAuth connection, the server handles the SMART on FHIR flow *itself*, fetches the `ClientFullEHR` data *during* the authorization process, and keeps it in memory (or a persisted session) for the duration of the client's connection.\n*   **Status:** While functional, the MCP specification for OAuth 2.1 client interaction is still evolving. Client support for this authentication method is **extremely limited** at present, making it difficult to test this mode with standard clients outside of specialized developer or debugging tools. This SSE mode should be considered **experimental**.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "models",
        "healthcare",
        "records",
        "health records",
        "health data",
        "health record"
      ],
      "category": "healthcare-and-medical"
    },
    "jpoles1--statpearls-mcp": {
      "owner": "jpoles1",
      "name": "statpearls-mcp",
      "url": "https://github.com/jpoles1/statpearls-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/jpoles1.webp",
      "description": "Fetches and retrieves reliable, peer-reviewed medical information about diseases and conditions from StatPearls, formatted in AI-friendly Markdown for enhanced conversation integration.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-07-09T10:33:41Z",
      "readme_content": "# StatPearls MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@jpoles1/statpearls-mcp)](https://smithery.ai/server/@jpoles1/statpearls-mcp)\n\nA [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) server that fetches disease information from [StatPearls](https://www.ncbi.nlm.nih.gov/books/NBK430685/), a trusted source of peer-reviewed medical content.\n\nGive your AI system a relaible source of medical knowledge for its next conversation.\n\n## Features\n\n- Searches for diseases and medical conditions on StatPearls\n- Retrieve comprehensive, reliable medical information from StatPearls\n- Convert HTML content to well-formatted Markdown to make it AI-friendly\n- Integrates with AI models via the Model Context Protocol\n\n![Image](StatPearlsMCPDemo.gif)\n\n### If you don't already have a Model Context Protocol (MCP) client:\n\nIf you are a casual user, you can use [Claude Desktop](https://modelcontextprotocol.io/quickstart/user) to get started using MCP servers. It is a free and open-source desktop application that allows you to run MCP servers locally and connect to them.\n\nIf you are a power user/developer, I recommend using VSCode with the [RooCode](https://docs.roocode.com/) extension which enables you to connect in [MCP servers](https://docs.roocode.com/features/mcp/what-is-mcp) to your development environment for infinite possibilities!\n\n## Installation\n\nOnce you have an MCP-capable AI client, you can run this server locally.\n\nThe easiest way to get up and running is to download the appropriate executable/binary for your OS from the [releases page](https://github.com/jpoles1/statpearls-mcp/releases). This will give you a self-contained executable that you can run without any additional setup.\n\nPlace this executable in a directory of your choice. Then simply add the following to your `mcp_settings.json` file:\n\n#### For Windows:\n\n```json\n{\n  \"mcpServers\": {\n    ...\n    \"statpearls\": {\n      \"command\": \"{path_to_executable_here}\\\\statpearls-mcp.exe\"\n    },\n    ...\n  }\n}\n\n#### For Mac/Linux:\n\n```json\n{\n  \"mcpServers\": {\n    ...\n    \"statpearls\": {\n      \"command\": \"{path_to_executable_here}/statpearls-mcp\"\n    },\n    ...\n  }\n}\n```\n\n### Installing via Smithery\n\nTo install statpearls-mcp for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@jpoles1/statpearls-mcp):\n\n```bash\nnpx -y @smithery/cli install @jpoles1/statpearls-mcp --client claude\n```\n\n### For Developers:\n\nYou can also run the server from source. This requires [Bun](https://bun.sh/) to be installed on your system.\n  1. Clone the repository\n  2. Install dependencies (`bun install`)\n  3. Compile the server (`bun run build`)\n  4. Now you can add the server to your `mcp_settings.json` file:\n  ```json\n  {\n    \"mcpServers\": {\n      ...\n      \"statpearls\": {\n        \"command\": \"node\",\n        \"args\": [\n          \"{path_to_proj_here}/dist/index.js\"\n        ]\n      },\n      ...\n    }\n  }\n  ```\n\n## Tool Definition\n\nThe server provides a single tool:\n\n- **statpearls_disease_info**: Fetches comprehensive, reliable medical information about diseases from StatPearls.\n\n### Input Schema\n\n```json\n{\n  \"query\": \"diabetes\",\n  \"format_options\": {\n    \"includeToc\": true,\n    \"maxLength\": 50000\n  }\n}\n```\n\n- `query`: Disease or medical condition to search for (required)\n- `format_options`: Optional formatting preferences\n  - `includeToc`: Whether to include a table of contents (default: true)\n  - `maxLength`: Maximum length of the returned content in characters (default: 50000)\n\n### Example Output\n\nThe tool returns formatted Markdown content with:\n\n- Title and source information\n- Table of contents (optional)\n- Structured sections including etiology, epidemiology, pathophysiology, clinical features, diagnosis, treatment, and prognosis (when available)\n\n## Development\n\n### Project Structure\n\n```\nstatpearls-mcp/\nâ”œâ”€â”€ src/                         # Source code\nâ”‚   â”œâ”€â”€ index.ts                 # Main entry point and server setup\nâ”‚   â”œâ”€â”€ test-html-parser.ts      # Test utility for HTML parser\nâ”‚   â”œâ”€â”€ test-statpearls-parser.ts # Test utility for StatPearls parser\nâ”‚   â”œâ”€â”€ testrun.ts               # Test runner utility\nâ”‚   â”œâ”€â”€ tools/                   # Tool definitions and handlers\nâ”‚   â”‚   â””â”€â”€ statpearls.ts        # StatPearls tool definition and handler\nâ”‚   â”œâ”€â”€ services/                # Core functionality services\nâ”‚   â”‚   â”œâ”€â”€ search.ts            # Search functionality\nâ”‚   â”‚   â”œâ”€â”€ content.ts           # Content retrieval and processing\nâ”‚   â”‚   â””â”€â”€ markdown.ts          # HTML to Markdown conversion\nâ”‚   â”œâ”€â”€ types/                   # Type definitions\nâ”‚   â”‚   â”œâ”€â”€ index.ts             # Common type definitions\nâ”‚   â”‚   â””â”€â”€ statpearls.ts        # StatPearls-specific type definitions\nâ”‚   â””â”€â”€ utils/                   # Utility functions\nâ”‚       â”œâ”€â”€ html.ts              # HTML parsing utilities\nâ”‚       â”œâ”€â”€ error.ts             # Error handling utilities\nâ”‚       â””â”€â”€ statpearls-parser.ts # StatPearls content parsing utilities\nâ”œâ”€â”€ scripts/                     # Build and utility scripts\nâ”‚   â”œâ”€â”€ build.ts                 # Build script for creating Node.js compatible bundle\nâ”‚   â”œâ”€â”€ compile.ts               # Script for compiling executables\nâ”‚   â”œâ”€â”€ release.ts               # Script for handling releases\nâ”‚   â””â”€â”€ version.ts               # Script for managing versioning\nâ”œâ”€â”€ dist/                        # Build output directory (not in repository)\nâ”œâ”€â”€ package.json                 # Project configuration and dependencies\nâ”œâ”€â”€ tsconfig.json                # TypeScript configuration\nâ”œâ”€â”€ bun.lock                     # Bun dependency lock file\nâ”œâ”€â”€ README.md                    # Main project documentation\nâ””â”€â”€ RELEASE-PROCESS.md           # Documentation for release process\n```\n\n### Building and Releasing\n\n#### Building\n\nThe build process creates a single JavaScript file that can run with vanilla Node.js:\n\n```bash\n# Production build\nbun run build\n# or\nbun run build:prod\n\n# Development build\nbun run build:dev\n```\n\nThis creates a bundled file at `dist/index.js` that includes all dependencies.\n\n#### Compiling Executables\n\nYou can compile platform-specific executables using Bun's compilation feature:\n\n```bash\n# Compile for all platforms\nbun run compile:all\n\n# Compile for specific platforms\nbun run compile:linux\nbun run compile:windows\nbun run compile:mac\n```\n\nThis creates executable files in the `dist` directory:\n- `statpearls-mcp` (default executable)\n- `statpearls-mcp-linux-x64` (Linux)\n- `statpearls-mcp-windows-x64.exe` (Windows)\n- `statpearls-mcp-darwin-x64` (macOS)\n\n#### Releasing\n\nThe release process handles versioning, building, compiling, and Git operations:\n\n```bash\n# Release a patch version (bug fixes)\nbun run release:patch\n\n# Release a minor version (new features, backward compatible)\nbun run release:minor\n\n# Release a major version (breaking changes)\nbun run release:major\n```\n\nThis process:\n1. Updates the version in package.json\n2. Builds the distribution file\n3. Compiles executables for all platforms\n4. Creates a Git commit with the version number\n5. Creates a Git tag for the version\n6. Pushes the commit and tag to GitHub\n\n#### Versioning\n\nThe project follows semantic versioning. You can check the current version with:\n\n```bash\nbun run version\n```\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "statpearls",
        "jpoles1",
        "medical",
        "medical jpoles1",
        "statpearls formatted",
        "statpearls mcp"
      ],
      "category": "healthcare-and-medical"
    },
    "manolaz--emergency-medicare-planner-mcp-server": {
      "owner": "manolaz",
      "name": "emergency-medicare-planner-mcp-server",
      "url": "https://github.com/manolaz/emergency-medicare-planner-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/manolaz.webp",
      "description": "Connects to Google Maps to locate nearby hospitals and clinics based on patient needs, evaluates medical facilities, and calculates optimal routes for urgent care. Provides real-time availability checks and detailed service information to assist in emergency healthcare decisions.",
      "stars": 4,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-08-13T18:58:25Z",
      "readme_content": "# Emergency Medicare Management MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@manolaz/emergency-medicare-planner-mcp-server)](https://smithery.ai/server/@manolaz/emergency-medicare-planner-mcp-server)\n\n(@manolaz/emergency-medicare-planner-mcp-server)\n\nA powerful Model Context Protocol (MCP) server that integrates with Google Maps to locate and evaluate medical facilities in emergency situations. This server helps users find appropriate hospitals and clinics within 10km radius based on specific medical needs, emergency level, and facility capabilities.\n\nThe system provides real-time routing, availability checks, and detailed information about medical services, helping patients make informed decisions during urgent healthcare situations.\n\n**Key Feature**: Sequential Thinking for Medical Evaluation - Enables step-by-step clinical reasoning for more accurate medical facility matching based on patient symptoms and medical history.\n\n## Installation & Usage\n\n### Installing via Smithery\n\nTo install Emergency Medicare Planner for Claude Desktop automatically:\n\n```bash\nnpx -y @smithery/cli install @manolaz/emergency-medicare-planner-mcp-server --client claude\n```\n\n### Installing Manually\n\n```bash\n# Using npx (recommended)\nnpx @manolaz/emergency-medicare-planner-mcp-server\n\n# With environment variable for Google Maps API\nGOOGLE_MAPS_API_KEY=your_api_key npx @manolaz/emergency-medicare-planner-mcp-server\n```\n\nOr install globally:\n\n```bash\n# Install globally\nnpm install -g @manolaz/emergency-medicare-planner-mcp-server\n\n# Run after global installation\nGOOGLE_MAPS_API_KEY=your_api_key emergency-medicare-planner-mcp-server\n```\n\n## Components\n\n### Tools\n\n- **searchMedicalFacilities**\n  - Search for hospitals, clinics, and medical facilities using Google Places API\n  - Input:\n    - `query` (string): Search query (e.g., \"emergency room\", \"pediatric clinic\")\n    - `location`: Latitude and longitude of patient location\n    - `radius` (optional, default: 10000): Search radius in meters\n    - `specialtyNeeded` (optional): Medical specialty required\n\n- **getMedicalFacilityDetails**\n  - Get detailed information about a specific medical facility\n  - Input:\n    - `placeId` (string): Google Place ID of the medical facility\n  - Output:\n    - Hours of operation, services offered, contact information, etc.\n\n- **calculateRouteToFacility**\n  - Calculate fastest route to a medical facility\n  - Input:\n    - `origin`: Patient's current location\n    - `facilityId`: Place ID of the destination facility\n    - `transportMode` (optional): Travel mode (driving, walking, transit, ambulance)\n    - `avoidTraffic` (optional): Route planning to avoid traffic\n\n- **checkFacilityAvailability**\n  - Check if a facility is currently accepting patients\n  - Input:\n    - `facilityId`: Place ID of the medical facility\n    - `emergencyLevel`: Urgency level of the medical situation\n\n## Configuration\n\n### Usage with Claude Desktop\n\nTo use this server with the Claude Desktop app, add the following configuration to the \"mcpServers\" section of your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"emergency-medicare-planner\": {\n      \"command\": \"npx\",\n      \"args\": [\"@manolaz/emergency-medicare-planner-mcp-server\"],\n      \"env\": {\n        \"GOOGLE_MAPS_API_KEY\": \"your_google_maps_api_key\"\n      }\n    }\n  }\n}\n```\n\nAlternatively, you can use the node command directly if you have the package installed:\n\n```json\n{\n  \"mcpServers\": {\n    \"emergency-medicare-planner\": {\n      \"command\": \"node\",\n      \"args\": [\"path/to/dist/index.js\"],\n      \"env\": {\n        \"GOOGLE_MAPS_API_KEY\": \"your_google_maps_api_key\"\n      }\n    }\n  }\n}\n```\n\n## Development\n\n### Building from Source\n\n1. Clone the repository\n2. Install dependencies:\n\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n\n   ```bash\n   npm run build\n   ```\n\n### Environment Variables\n\n- `GOOGLE_MAPS_API_KEY` (required): Your Google Maps API key with the following APIs enabled:\n  - Places API\n  - Directions API\n  - Geocoding API\n  - Time Zone API\n  - Distance Matrix API\n\n### Testing\n\n```bash\n# Run test suite\nnpm test\n\n# Run with debug logging\nDEBUG=emergency-medicare:* npm start\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. For more details, please see the LICENSE file in the project repository.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "hospitals",
        "healthcare",
        "mcp",
        "emergency healthcare",
        "medical manolaz",
        "medicare planner"
      ],
      "category": "healthcare-and-medical"
    },
    "matthewdcage--pbs-mcp-server": {
      "owner": "matthewdcage",
      "name": "pbs-mcp-server",
      "url": "https://github.com/matthewdcage/pbs-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/matthewdcage.webp",
      "description": "Access up-to-date pharmaceutical data from the Australian PBS, including information on medicines, pricing, and availability. Facilitates seamless integration into AI workflows for real-time healthcare data retrieval.",
      "stars": 1,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-03-12T21:35:38Z",
      "readme_content": "# Pharmaceutical Benefits Scheme (PBS) MCP AI Enabled API Server ![MCP Server](https://badge.mcpx.dev?type=dev 'MCP Dev')\n\nA standalone Model Context Protocol (MCP) server for accessing the Australian Pharmaceutical Benefits Scheme (PBS) API.\n\n## About the Author\n\nThis PBS MCP server was developed by [Matthew Cage], Founder of https://ai-advantage.au, specialist in Automation, AI Engineering and AI integration and healthcare data systems.\n\nCollaborate with me:\nhttps://www.linkedin.com/in/digitalmarketingstrategyexpert/\n\n## Overview\n\nThis project provides a standalone MCP server that allows AI models to access the Australian Pharmaceutical Benefits Scheme (PBS) API, which contains information about medicines, pricing, and availability in Australia.\n\nThe project is built for the Public API, but can easily be adapted to the private API if you have been granted developer access.\n\nThe PBS API provides programmatic access to PBS data, including medicine listings, pricing, and availability. This MCP server makes it easy to integrate PBS data into AI workflows.\n\nThe MCP is available via HTTP and CLI.\n\n*Please be aware of the rate limits for the PBS and adjust your request frequency. I recommend a periodic call to store the information you require from the API and update it on a weekly basis.*\n\n## MCP Server Features ![MCP Server](https://badge.mcpx.dev?type=server&features=tools)\n\nThis MCP server implements the following Model Context Protocol features:\n\n- **Tools**: Provides tools for querying the PBS API endpoints, allowing AI models to access pharmaceutical data\n- **Transport Layers**: Supports both stdio and HTTP/SSE transport layers\n- **Error Handling**: Comprehensive error handling for API rate limits and authentication issues\n- **LLM Integration**: Receives tool calls and prompts directly from LLM components, enabling seamless AI interaction with PBS data\n\n### How It Works\n\nThe MCP Client ![MCP Client](https://badge.mcpx.dev?type=client&features=prompts,tools 'MCP Client'):\n\n1. **Receives Tool Calls**: When an LLM (like Claude) needs pharmaceutical data, it sends a tool call to this server\n2. **Processes Prompts**: Interprets natural language prompts about medication information\n3. **Executes API Queries**: Translates the requests into appropriate PBS API calls\n4. **Returns Structured Data**: Sends back formatted pharmaceutical data that the LLM can use in its responses\n\nThis enables AI assistants to access up-to-date PBS information without needing to have this data in their training.\n\n## Installation\n\n1. Clone this repository:\n   ```bash\n   git clone <repository-url>\n   cd pbs-mcp-standalone\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n   ```bash\n   npm run build\n   ```\n\n## Usage\n\n### Starting the Server ![MCP Server](https://badge.mcpx.dev?type=server&features=tools)\n\nThe PBS MCP server can be run in different modes:\n\n#### Stdio Mode (Default)\n\nThis mode is compatible with the MCP protocol and communicates via standard input/output streams:\n\n```bash\nnpm start\n```\n\nOr use the provided start script:\n\n```bash\n./start.sh\n```\n\n#### HTTP Mode with SSE Support\n\nThis mode starts an HTTP server with Server-Sent Events (SSE) support:\n\n```bash\nnpm run start:http\n```\n\nOr use the provided start script:\n\n```bash\n./start.sh http 3000\n```\n\nWhere `3000` is the port number to listen on.\n\n#### Command-Line Interface\n\nThe PBS MCP server can also be used as a command-line tool:\n\n```bash\nnpm run cli -- <command>\n```\n\nOr use the provided start script:\n\n```bash\n./start.sh cli <command>\n```\n\nFor example:\n\n```bash\n./start.sh cli info\n```\n\n### Using as a Command-Line Tool\n\nTo use this MCP server as a command-line tool:\n\n1. Build the project:\n   ```bash\n   npm run build\n   ```\n\n2. Run the CLI with the desired command:\n   ```bash\n   npm run cli -- <command>\n   ```\n   \n   Or use the start script:\n   ```bash\n   ./start.sh cli <command>\n   ```\n\n### Integrating with MCP Clients ![MCP Client](https://badge.mcpx.dev?type=client)\n\nThis server can be integrated with any MCP-compatible client, such as:\n\n- Local AI Editors and AI/LLM Servers\n- Other AI assistants that support the Model Context Protocol\n- Custom applications using the MCP client libraries\n\n#### Client Configuration Example\n\nHere's an example of how to configure this server with an MCP client:\n\n```json\n{\n  \"mcpServers\": {\n    \"pbs-api\": {\n      \"command\": \"node\",\n      \"args\": [\"path/to/pbs-mcp-standalone/build/index.js\"],\n      \"env\": {\n        \"PBS_API_SUBSCRIPTION_KEY\": \"your-subscription-key-here\"\n      }\n    }\n  }\n}\n```\n\n#### Accessing the Server from a Client\n\nTo access this MCP server from a client:\n\n1. **For Claude Desktop or other MCP-compatible AI assistants**:\n   - Configure the assistant to use this server as an MCP tool provider\n   - The assistant will automatically discover and use the tools provided by this server\n   - The LLM can send natural language prompts about medications that will be processed by the server\n\n2. **For custom applications**:\n   - Use the HTTP API endpoints described below\n   - Connect to the SSE endpoint for real-time tool events\n   - Or spawn the server process and communicate via stdin/stdout\n\n#### Example LLM Prompts\n\nThe server can interpret various prompts from LLMs, such as:\n\n```\n\"Find information about metformin in the PBS\"\n\"What is the PBS code for insulin?\"\n\"List all prescribers who can prescribe antibiotics\"\n\"Get the latest pricing for asthma medications\"\n```\n\nThese natural language prompts are translated into appropriate PBS API calls.\n\n### API Tool Parameters\n\nThe PBS API tool can be used with the following parameters:\n\n```json\n{\n  \"endpoint\": \"prescribers\",\n  \"method\": \"GET\",\n  \"params\": {\n    \"get_latest_schedule_only\": \"true\",\n    \"limit\": \"20\"\n  }\n}\n```\n\n#### Parameters\n\n- `endpoint` (string, required): The specific PBS API endpoint to access (e.g., \"prescribers\", \"item-overview\")\n- `method` (string, optional): HTTP method to use (GET is recommended for most PBS API operations). Default: \"GET\"\n- `params` (object, optional): Query parameters to include in the request\n- `subscriptionKey` (string, optional): Custom subscription key. If not provided, the default public key will be used\n- `timeout` (number, optional): Request timeout in milliseconds. Default: 30000\n\n## HTTP API ![MCP Server](https://badge.mcpx.dev?type=server&features=tools)\n\nWhen running in HTTP mode, the following endpoints are available:\n\n### Health Check\n\n```\nGET /health\n```\n\nReturns the status of the server.\n\n### List Tools\n\n```\nGET /tools\n```\n\nReturns a list of available tools.\n\n### SSE Endpoint\n\n```\nGET /sse\n```\n\nEstablishes an SSE connection and sends tool events.\n\n### Tool Invocation (SSE)\n\n```\nPOST /sse/:toolName\n```\n\nInvokes a tool and sends the result via SSE.\n\n### Tool Invocation (REST)\n\n```\nPOST /api/:toolName\n```\n\nInvokes a tool and returns the result as JSON.\n\n## Command-Line Interface ![MCP Dev](https://badge.mcpx.dev?type=dev)\n\nThe PBS MCP server can be used as a command-line tool with the following commands:\n\n### List Endpoints\n\n```bash\n./start.sh cli list-endpoints\n```\n\nLists all available PBS API endpoints.\n\n### Get API Information\n\n```bash\n./start.sh cli info\n```\n\nReturns information about the PBS API.\n\n### Query Prescribers\n\n```bash\n./start.sh cli prescribers [options]\n```\n\nOptions:\n- `-l, --limit <number>`: Number of results per page (default: 10)\n- `-p, --page <number>`: Page number (default: 1)\n- `-c, --pbs-code <code>`: Filter by PBS code\n- `-s, --schedule-code <code>`: Filter by schedule code\n- `-t, --prescriber-type <type>`: Filter by prescriber type\n- `-f, --fields <fields>`: Specific fields to return\n- `--latest`: Get only the latest schedule\n\n### Query Item Overview\n\n```bash\n./start.sh cli item-overview [options]\n```\n\nOptions:\n- `-l, --limit <number>`: Number of results per page (default: 10)\n- `-p, --page <number>`: Page number (default: 1)\n- `-s, --schedule-code <code>`: Filter by schedule code\n- `-f, --fields <fields>`: Specific fields to return\n- `--latest`: Get only the latest schedule\n\n### Query Any Endpoint\n\n```bash\n./start.sh cli query <endpoint> [options]\n```\n\nOptions:\n- `-m, --method <method>`: HTTP method (default: GET)\n- `-p, --params <json>`: Query parameters as JSON string\n- `-k, --subscription-key <key>`: Custom subscription key\n- `-t, --timeout <milliseconds>`: Request timeout in milliseconds\n\n### Start HTTP Server\n\n```bash\n./start.sh cli serve [options]\n```\n\nOptions:\n- `-p, --port <number>`: Port to listen on (default: 3000)\n\n## Available Endpoints\n\nThe PBS API provides several endpoints for accessing different types of data:\n\n- `/` - Root endpoint, provides API information and changelog\n- `/prescribers` - Information about prescribers\n- `/item-overview` - Detailed information about PBS items\n- `/items` - Basic information about PBS items\n- `/schedules` - Information about PBS schedules\n- `/atc-codes` - Anatomical Therapeutic Chemical (ATC) classification codes\n- `/organisations` - Information about organisations\n- `/restrictions` - Information about restrictions\n- `/parameters` - Information about parameters\n- `/criteria` - Information about criteria\n- `/copayments` - Information about copayments\n- `/fees` - Information about fees\n- `/markup-bands` - Information about markup bands\n- `/programs` - Information about programs\n- `/summary-of-changes` - Summary of changes\n\nFor a complete list of endpoints, see the [PBS API documentation](https://data-api-portal.health.gov.au/api-details#api=pbs-prod-api-public-v3-v3).\n\n## Example Usage\n\n### Get API Information\n\n```json\n{\n  \"endpoint\": \"\"\n}\n```\n\n### Get Prescribers\n\n```json\n{\n  \"endpoint\": \"prescribers\",\n  \"params\": {\n    \"get_latest_schedule_only\": \"true\",\n    \"limit\": \"10\"\n  }\n}\n```\n\n### Get Item Overview with Latest Schedule\n\n```json\n{\n  \"endpoint\": \"item-overview\",\n  \"params\": {\n    \"get_latest_schedule_only\": \"true\",\n    \"limit\": \"5\"\n  }\n}\n```\n\n### Get Prescribers with Specific PBS Code\n\n```json\n{\n  \"endpoint\": \"prescribers\",\n  \"params\": {\n    \"pbs_code\": \"10001J\",\n    \"get_latest_schedule_only\": \"true\"\n  }\n}\n```\n\n## Authentication\n\nThe tool uses a subscription key for accessing the PBS API. You can obtain your own key by registering on the PBS Developer Portal.\n\nFor development purposes, see the `.env.example` file for configuration details.\n\n### Obtaining a PBS API Subscription Key\n\nTo obtain your own PBS API subscription key, follow these steps:\n\n1. **Visit the PBS Data API Portal**: \n   - Go to [https://data-api-portal.health.gov.au/](https://data-api-portal.health.gov.au/)\n\n2. **Create an Account**:\n   - Click on \"Sign Up\" to create a new account\n   - Fill in your details and verify your email address\n\n3. **Subscribe to the PBS API**:\n   - Once logged in, navigate to the \"Products\" section\n   - Select the \"PBS Public API v3\" product\n   - Click \"Subscribe\" to request access to the API\n\n4. **Retrieve Your Subscription Key**:\n   - After your subscription is approved, go to your profile\n   - Navigate to \"Subscriptions\" or \"API Keys\" section\n   - Copy your primary or secondary key\n\n5. **Configure Your Environment**:\n   - Create a `.env` file based on the `.env.example` template\n   - Replace `your-subscription-key-here` with your actual subscription key:\n     ```\n     PBS_API_SUBSCRIPTION_KEY=your-actual-subscription-key\n     ```\n\n**Note**: The PBS Public API is rate-limited to one request per 20 seconds. This limit is shared among all users of the public API. For higher rate limits or access to embargo data (future schedules), you may need to apply for special access through the PBS Developer Program.\n\n## Limitations\n\n- The PBS Public API is rate-limited to one request per 20 seconds (shared among all users)\n- Only the current schedule and those published in the past 12 months are available via the Public API\n- Some endpoints require specific parameters to be provided\n- The API structure and endpoints may change over time\n\n## Additional Resources\n\n- [PBS Website](https://www.pbs.gov.au/)\n- [PBS Data Website](https://data.pbs.gov.au/)\n- [PBS API Documentation](https://data-api-portal.health.gov.au/api-details#api=pbs-prod-api-public-v3-v3)\n- [Model Context Protocol Documentation](https://github.com/modelcontextprotocol/mcp)\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n---\n\n![MCP Server](https://badge.mcpx.dev?type=server&features=tools) ![MCP Client](https://badge.mcpx.dev?type=client) ![MCP Dev](https://badge.mcpx.dev?type=dev) ![MCP Enabled](https://badge.mcpx.dev?status=on) â¤ï¸ \n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "healthcare",
        "pharmaceutical",
        "medical",
        "healthcare data",
        "pharmaceutical data",
        "information medicines"
      ],
      "category": "healthcare-and-medical"
    },
    "mattjoyce--senechal-mcp": {
      "owner": "mattjoyce",
      "name": "senechal-mcp",
      "url": "https://github.com/mattjoyce/senechal-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/mattjoyce.webp",
      "description": "Access and analyze health data from the Senechal API, providing health profiles, trends, and summaries for integration with LLM applications. Offers reusable templates for health data analysis, enhancing data insights and accessibility.",
      "stars": 0,
      "forks": 3,
      "license": "GNU General Public License v3.0",
      "language": "Python",
      "updated_at": "2025-03-08T00:11:02Z",
      "readme_content": "# Senechal MCP Server\n\nA Model Context Protocol (MCP) server that acts as a companion to the Senechal project, providing health data from the Senechal API to LLM applications.\n\n## Overview\n\nThis server provides a standardized interface for LLMs to access health data from the Senechal API. It exposes:\n\n- **Resources**: Health data that can be loaded into an LLM's context\n- **Tools**: Functions that can be called by LLMs to fetch health data\n- **Prompts**: Reusable templates for analyzing health data\n\n## Installation\n\n1. Clone this repository\n2. Create a virtual environment:\n   ```bash\n   python -m venv venv\n   source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n   ```\n3. Install dependencies:\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n## Configuration\n\nCopy the `.env.example` file to `.env` and add your Senechal API key and URL:\n\n```\n# Required: Senechal API Key\nSENECHAL_API_KEY=your_api_key_here\n\n# Required: API base URL\nSENECHAL_API_BASE_URL=https://your-api-host/api/senechal\n```\n\nBoth the API key and API URL are required for the server to function.\n\n### Windows Configuration\n\nWhen running on Windows, be sure to:\n\n1. Use backslashes or properly escaped paths in the configuration\n2. Use the full path to your Python virtual environment in the claude-desktop-config.json:\n\n```json\n{\n    \"mcpServers\": {\n        \"senechal-health\": {\n            \"command\": \"C:\\\\path\\\\to\\\\venv\\\\Scripts\\\\python.exe\",\n            \"args\": [\n                \"C:\\\\path\\\\to\\\\senechal_mcp_server.py\"\n            ],\n            \"env\": {\n                \"SENECHAL_API_KEY\": \"your_api_key_here\"\n            }\n        }\n    }\n}\n```\n\nNote that environment variables in the MCP configuration do not use the `.env` file, so you'll need to set them explicitly in the config.\n\n## Usage\n\n### Testing the Client/Server Setup\n\nThe simplest way to test the setup is to run the example client:\n\n```bash\n# In one terminal, start the server\npython senechal_mcp_server.py\n\n# In another terminal, run the example client\npython example_client.py\n```\n\n### Start the Server\n\n```bash\npython senechal_mcp_server.py\n```\n\n### Development Mode with MCP Inspector\n\n```bash\nmcp dev senechal_mcp_server.py\n```\n\n### Install in Claude Desktop\n\nThe server includes a configuration file for Claude Desktop:\n\n```bash\nmcp install senechal_mcp_server.py\n```\n\nYou can then select \"Senechal Health\" from the tools menu in Claude Desktop.\n\n## Available Resources\n\n- `senechal://health/summary/{period}` - Get health summary for day, week, month, or year\n  - Example: `senechal://health/summary/day?span=7&metrics=all`\n  - Parameters:\n    - `period`: day, week, month, year\n    - `span`: Number of periods (default: 1)\n    - `metrics`: Comma-separated list or \"all\" (default)\n    - `offset`: Number of periods to offset from now (default: 0)\n\n- `senechal://health/profile` - Get the user's health profile\n  - Contains demographics, medications, supplements\n\n- `senechal://health/current` - Get current health measurements\n  - Example: `senechal://health/current?types=1,2,3`\n  - Parameters:\n    - `types`: Optional comma-separated list of measurement type IDs\n\n- `senechal://health/trends` - Get health trends over time\n  - Example: `senechal://health/trends?days=30&types=1,2,3&interval=day`\n  - Parameters:\n    - `days`: Number of days to analyze (default: 30)\n    - `types`: Optional comma-separated list of measurement type IDs\n    - `interval`: Grouping interval - day, week, month (default: day)\n\n- `senechal://health/stats` - Get statistical analysis of health metrics\n  - Example: `senechal://health/stats?days=30&types=1,2,3`\n  - Parameters:\n    - `days`: Analysis period in days (default: 30)\n    - `types`: Optional comma-separated list of measurement type IDs\n\n## Available Tools\n\n- `fetch_health_summary` - Fetch a health summary for a specific period\n  - Parameters:\n    - `period` (required): day, week, month, year\n    - `metrics` (optional): Comma-separated metrics or \"all\" (default)\n    - `span` (optional): Number of periods to return (default: 1)\n    - `offset` (optional): Number of periods to offset (default: 0)\n\n- `fetch_health_profile` - Fetch the user's health profile\n  - No parameters required\n\n- `fetch_current_health` - Fetch the latest health measurements\n  - Parameters:\n    - `types` (optional): List of measurement type IDs to filter by\n\n- `fetch_health_trends` - Fetch health trend data\n  - Parameters:\n    - `days` (optional): Number of days to analyze (default: 30)\n    - `types` (optional): List of measurement type IDs to filter by\n    - `interval` (optional): Grouping interval - day, week, month (default: day)\n\n- `fetch_health_stats` - Fetch statistical analysis of health metrics\n  - Parameters:\n    - `days` (optional): Analysis period in days (default: 30)\n    - `types` (optional): List of measurement type IDs to filter by\n\n## Available Prompts\n\n- `analyze_health_summary` - Prompt to analyze health summaries\n  - Provides a template for identifying abnormal metrics, trends, and suggesting actions\n  - Intended to be used with data from `senechal://health/summary/day?span=7`\n\n- `compare_health_trends` - Prompt to compare health trends over different time periods\n  - Provides a template for comparing trends across different timeframes (7, 30, 90 days)\n  - Intended to be used with data from the health trends endpoint\n\n## Example Interactions\n\n### Loading Health Summary Data\n\n```python\n# In an LLM application, load a week of health summaries\ncontent, mime_type = await session.read_resource(\"senechal://health/summary/day?span=7\")\n```\n\n### Calling Health Data Tools\n\n```python\n# In an LLM conversation\nresult = await session.call_tool(\n    \"fetch_health_trends\", \n    arguments={\n        \"days\": 30, \n        \"interval\": \"day\"\n    }\n)\n\n# More complex example combining tools and resources\nprofile = await session.call_tool(\"fetch_health_profile\")\ntrends = await session.call_tool(\n    \"fetch_health_trends\", \n    arguments={\"days\": 90, \"interval\": \"week\"}\n)\n```\n\n### Using Health Analysis Prompts\n\n```python\n# Get a prompt for analyzing health data\nprompt_result = await session.get_prompt(\"analyze_health_summary\")\nfor message in prompt_result.messages:\n    print(f\"[{message.role}]: {message.content.text}\")\n```\n\nSee the `example_client.py` file for a complete working example.\n\n## API Endpoints\n\nThe Senechal MCP server communicates with the following Senechal API endpoints:\n\n- `/health/summary/{period}` - Get health summaries\n- `/health/profile` - Get health profile\n- `/health/current` - Get current measurements\n- `/health/trends` - Get health trends\n- `/health/stats` - Get health stats",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "healthcare",
        "health",
        "data",
        "health data",
        "senechal api",
        "analyze health"
      ],
      "category": "healthcare-and-medical"
    },
    "pickleton89--mutation-clinical-trial-matching-mcp": {
      "owner": "pickleton89",
      "name": "mutation-clinical-trial-matching-mcp",
      "url": "https://github.com/pickleton89/mutation-clinical-trial-matching-mcp",
      "imageUrl": "/freedevtools/mcp/pfp/pickleton89.webp",
      "description": "Connects to clinicaltrials.gov to retrieve and summarize clinical trials related to specific genetic mutations through natural language queries.",
      "stars": 0,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-07-21T16:03:59Z",
      "readme_content": "# Mutation Clinical Trial Matching MCP\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)\n[![Version 0.2.1](https://img.shields.io/badge/version-0.2.1-blue.svg)](https://github.com/pickleton89/mutation-clinical-trial-matching-mcp/releases)\n[![Tests](https://img.shields.io/badge/tests-114%20tests-green.svg)](https://github.com/pickleton89/mutation-clinical-trial-matching-mcp/actions)\n[![Code Style: Ruff](https://img.shields.io/badge/code%20style-ruff-black.svg)](https://github.com/astral-sh/ruff)\n[![Code Deduplication](https://img.shields.io/badge/code%20deduplication-60%25%20reduction-brightgreen.svg)](https://github.com/pickleton89/mutation-clinical-trial-matching-mcp)\n[![Architecture](https://img.shields.io/badge/architecture-unified%20sync%2Fasync-blue.svg)](https://github.com/pickleton89/mutation-clinical-trial-matching-mcp)\n\nA high-performance **unified** Model Context Protocol (MCP) server that enables Claude Desktop to search for clinical trial matches on clinicaltrials.gov based on genetic mutations. \n\n## Status\n\n**Production Ready** - This project has completed a major architectural transformation, achieving a **unified codebase** with 60% code reduction while maintaining 100% backward compatibility:\n\nâœ… **Repository Quality Excellence**: 99.6% improvement in code quality with modern Python standards (Python 3.11+ compatibility)  \nâœ… **Professional Type Safety**: 69% reduction in type diagnostics with comprehensive typing standards  \nâœ… **Unified Architecture**: Single server supporting both sync and async modes with runtime selection  \nâœ… **Code Deduplication**: 60% reduction (~1,000 lines) through comprehensive 4-phase consolidation  \nâœ… **Legacy Cleanup**: Professional codebase structure with 3,435 lines of deprecated code removed  \nâœ… **Zero Breaking Changes**: Complete backward compatibility with automatic migration guidance via compatibility layer  \nâœ… **Enterprise Features**: Circuit breakers, metrics, retry logic, distributed caching, and monitoring  \nâœ… **High Performance**: Async architecture with 80% performance improvement and concurrent processing  \nâœ… **API Resilience**: Robust error handling with 403 Forbidden error resolution via unified HTTP client  \nâœ… **Comprehensive Testing**: Complete test suite with 114 tests covering unified components  \nâœ… **Modern Tooling**: Uses `uv` for dependency management and follows Python best practices  \nâœ… **Production Monitoring**: Prometheus metrics, cache analytics, and health monitoring dashboards  \n\nThe server is actively used and maintained, with the unified architecture documented in the [changelog](CHANGELOG.md).\n\n## **AI-Collaborative Development**\n\nThis project was developed through **human-AI collaboration**, combining domain expertise with LLM-directed implementation:\n\n- **ğŸ§  Domain Direction**: 20+ years cancer research experience guided architecture and feature requirements\n- **ğŸ¤– AI Implementation**: Code generation, API design, and performance optimization through systematic LLM direction\n- **ğŸ”„ Quality Assurance**: Iterative refinement ensuring professional standards and production reliability\n- **ğŸ“ˆ Development Approach**: Demonstrates how domain experts can effectively leverage AI tools to build bioinformatics platforms\n\n**Methodology**: This AI-collaborative approach combines biological expertise with AI capabilities to accelerate development while maintaining code quality and reliability standards.\n\n## Overview\n\nThis project follows the Agentic Coding principles to create a system that integrates Claude Desktop with the clinicaltrials.gov API. The server allows for natural language queries about genetic mutations and returns summarized information about relevant clinical trials.\n\n```mermaid\nflowchart LR\n    Claude[Claude Desktop] <-->|MCP Protocol| Server[Unified MCP Server]\n    \n    subgraph Detection[Runtime Mode Detection]\n        Auto[Auto-Detect Event Loop]\n        Env[MCP_ASYNC_MODE]\n        Config[Configuration Override]\n    end\n    \n    subgraph Cache[Distributed Cache]\n        Redis[(Redis)]\n        Memory[In-Memory]\n    end\n    \n    subgraph Flow[Unified PocketFlow]\n        QueryNode[Unified Query Node] -->|trials_data| SummarizeNode[Unified Summarize Node]\n    end\n    \n    subgraph Services[Service Abstraction Layer]\n        HttpClient[Unified HTTP Client]\n        TrialsService[Clinical Trials Service]\n        LLMService[LLM Service]\n    end\n    \n    subgraph Monitoring[Enterprise Features]\n        Metrics[Prometheus Metrics]\n        Circuit[Circuit Breaker]\n        Analytics[Cache Analytics]\n    end\n    \n    Server -->|mode selection| Detection\n    Detection -->|sync/async| Flow\n    Server -->|mutation| Flow\n    Flow -->|service calls| Services\n    Services <-->|cache| Cache\n    Services -->|concurrent/sequential requests| API[Clinicaltrials.gov API]\n    API -->|trial data| Services\n    Flow -->|summary| Server\n    Server -->|metrics| Monitoring\n    Server -->|formatted response| Claude\n```\n\nEach node in the flow follows the **Unified PocketFlow Node pattern** with `prep`, `exec`, and `post` methods that automatically handle both sync and async execution modes.\n\n## ğŸš€ Unified Architecture & Code Deduplication Achievement\n\nThis project has completed a comprehensive **4-phase code deduplication effort**, transforming from a duplicated codebase into a unified, maintainable architecture:\n\n### Code Deduplication Results\n\n| **Metric** | **Achievement** |\n|------------|-----------------|\n| **Code Reduction** | **60% reduction** (~1,000 lines eliminated) |\n| **Legacy Cleanup** | **3,435 lines removed** - Professional codebase structure |\n| **Code Quality** | **99.6% improvement** - 1,695 of 1,702 linting errors fixed |\n| **Type Safety** | **69% reduction** in type diagnostics (48 â†’ 15) |\n| **Components Unified** | **4 major consolidations** (Servers, Nodes, Services, HTTP) |\n| **Breaking Changes** | **Zero** - Complete backward compatibility with compatibility layer |\n| **Performance Gain** | **30-40% memory reduction**, **20-30% faster startup** |\n| **Test Coverage** | **114 tests** covering all unified components |\n\n### Before vs After Consolidation\n\n| **Component** | **Before** | **After** | **Reduction** |\n|---------------|------------|-----------|---------------|\n| **Servers** | `primary.py` + `sync_server.py` | `main.py` | **70%** |\n| **Nodes** | `nodes.py` + `async_nodes.py` | `unified_nodes.py` | **85%** |\n| **Services** | `query.py` + `async_query.py` | `service.py` | **95%** |\n| **LLM Client** | `call_llm.py` + `async_call_llm.py` | `llm_service.py` | **95%** |\n\n### Key Architectural Improvements\n\nâœ… **Runtime Mode Selection**: Automatic detection or explicit configuration via `MCP_ASYNC_MODE`  \nâœ… **Single Point of Truth**: Unified business logic across sync/async execution  \nâœ… **Auto-Detection**: Intelligent mode selection based on execution context  \nâœ… **Service Abstraction**: Unified HTTP client and service layer  \nâœ… **Configuration System**: Centralized configuration with environment overrides  \nâœ… **Backward Compatibility Layer**: Complete `utils/node.py` compatibility module for legacy imports  \nâœ… **Migration Support**: Deprecation warnings with clear migration guidance  \n\n## Project Structure\n\nThis project is organized according to the Agentic Coding paradigm:\n\n1. **Requirements** (Human-led):\n   - Search and summarize clinical trials related to specific genetic mutations\n   - Provide mutation information as contextual resources\n   - Integrate seamlessly with Claude Desktop\n\n2. **Flow Design** (Collaborative):\n   - User queries Claude Desktop about a genetic mutation\n   - Claude calls our MCP server tool\n   - Server queries clinicaltrials.gov API\n   - Server processes and summarizes the results\n   - Server returns formatted results to Claude\n\n3. **Utilities** (Collaborative):\n   - `clinicaltrials/query.py`: Handles API calls to clinicaltrials.gov\n   - `utils/call_llm.py`: Utilities for working with Claude\n\n4. **Node Design** (AI-led):\n   - `utils/node.py`: Implements base Node and BatchNode classes with prep/exec/post pattern\n   - `clinicaltrials/nodes.py`: Defines specialized nodes for querying and summarizing\n   - `clinicaltrials_mcp_server.py`: Orchestrates the flow execution\n\n5. **Implementation** (AI-led):\n   - FastMCP SDK for handling the protocol details\n   - Error handling at all levels\n   - Resources for common mutations\n\n## Architecture Components\n\n### Unified MCP Server (`servers/main.py`)\n\nThe main unified server implementing the Model Context Protocol with **runtime mode selection**:\n\n- **Unified Architecture**: Single implementation supporting both sync and async modes\n- **Runtime Mode Selection**: Automatic detection via event loop or explicit `MCP_ASYNC_MODE` configuration\n- **Enterprise Tools**: Health monitoring, metrics collection, cache management (mode-dependent)\n- **Auto-scaling**: Circuit breakers and retry logic for robust API communication\n- **Cache Warming**: Automatically pre-loads common mutations for instant responses (async mode)\n- **API Resilience**: Handles 403 Forbidden errors with unified HTTP client fallback mechanisms\n- **Backward Compatibility**: Legacy servers redirect with deprecation warnings\n\n### Unified Service Layer\n\n**Clinical Trials Service** (`clinicaltrials/service.py`): Unified API client with mode-aware processing\n- **Dual Mode Support**: Same interface for both sync (`query_trials`) and async (`aquery_trials`) calls\n- **Circuit Breaker Integration**: Automatic failure detection and recovery\n- **Distributed Caching**: Redis-backed caching with in-memory fallback\n- **Metrics Collection**: Detailed performance and usage analytics\n- **API Compatibility**: Uses unified HTTP client for reliable clinicaltrials.gov API access\n\n**LLM Service** (`utils/llm_service.py`): Unified LLM interaction client\n- **Mode-Aware Processing**: Supports both sync and async LLM calls\n- **Retry Logic**: Built-in retry mechanisms with exponential backoff\n- **Error Handling**: Comprehensive error handling with structured logging\n\n### Unified Nodes (`clinicaltrials/unified_nodes.py`)\n\nPocketFlow nodes with **automatic sync/async execution**:\n- **QueryTrialsNode**: Unified node with mode detection for API requests\n- **SummarizeTrialsNode**: Unified LLM-powered summarization with retry logic\n- **BatchQueryTrialsNode**: Batch processing with concurrency control (async) or sequential processing (sync)\n- **Auto-Detection**: Nodes automatically determine execution mode at runtime\n\n### Unified Foundation Layer\n\n- **Unified HTTP Client** (`utils/http_client.py`): Single HTTP client supporting both sync and async with connection pooling\n- **Unified Node Framework** (`utils/unified_node.py`): Base classes with automatic mode detection\n- **Shared Utilities** (`utils/shared.py`): Common validation, error handling, and metrics functions\n- **Cache Strategies** (`utils/cache_strategies.py`): Smart cache warming and invalidation (async mode)\n- **Configuration System** (`servers/config.py`): Centralized configuration with environment overrides\n- **Legacy Compatibility** (`servers/legacy_compat.py`): Backward compatibility layer with migration guidance\n\n## Unified Node Pattern Implementation\n\nThis project implements the **enhanced PocketFlow Node pattern** with unified sync/async execution, providing a modular, maintainable approach to building AI workflows:\n\n### Unified Core Node Classes (`utils/unified_node.py`)\n\n- **UnifiedNode**: Base class supporting both sync and async execution with automatic mode detection\n- **UnifiedBatchNode**: Extension for batch processing with concurrency control (async) or sequential processing (sync)\n- **UnifiedFlow**: Orchestrates execution with intelligent mode selection\n\n### Unified Implementation Nodes (`clinicaltrials/unified_nodes.py`)\n\n1. **QueryTrialsNode** (Unified):\n   ```python\n   # Single implementation supporting both modes\n   def prep(self, shared): return shared[\"mutation\"]\n   \n   def exec(self, mutation): \n       return self.trials_service.query_trials(mutation)  # Sync version\n   \n   async def aexec(self, mutation): \n       return await self.trials_service.aquery_trials(mutation)  # Async version\n   \n   def post(self, shared, mutation, result):\n       shared[\"trials_data\"] = result\n       shared[\"studies\"] = result.get(\"studies\", [])\n       return self.get_next_node_id(result)\n   ```\n\n2. **SummarizeTrialsNode** (Unified):\n   ```python\n   # Unified summarization with mode detection\n   def prep(self, shared): return shared[\"studies\"]\n   \n   def exec(self, studies): \n       return self.llm_service.call_llm(prompt)  # Sync version\n   \n   async def aexec(self, studies): \n       return await self.llm_service.acall_llm(prompt)  # Async version\n   \n   def post(self, shared, studies, summary):\n       shared[\"summary\"] = summary\n       return None  # End of flow\n   ```\n\n### Unified Flow Execution\n\nThe unified MCP server creates and runs flows with automatic mode detection:\n\n```python\n# Create unified nodes (mode determined at runtime)\nquery_node = QueryTrialsNode(async_mode=server.async_mode)\nsummarize_node = SummarizeTrialsNode(async_mode=server.async_mode)\n\n# Use PocketFlow chaining syntax\nquery_node >> summarize_node\n\n# Create unified flow\nflow = UnifiedFlow(start_node=query_node, async_mode=server.async_mode)\n\n# Run flow with shared context (automatically sync or async)\nshared = {\"mutation\": mutation}\nif server.async_mode:\n    result = await flow.aexecute(shared)\nelse:\n    result = flow.execute(shared)\n```\n\n### Key Advantages of Unified Pattern\n\nâœ… **Single Implementation**: One codebase supports both sync and async execution  \nâœ… **Auto-Detection**: Nodes automatically determine optimal execution mode  \nâœ… **Runtime Selection**: Mode can be selected at server startup or runtime  \nâœ… **Preserved Interface**: Same `prep`, `exec`, `post` pattern maintained  \nâœ… **Performance Optimization**: Mode-specific optimizations (timeouts, concurrency, batch limits)  \nâœ… **Backward Compatibility**: Legacy node patterns continue working with deprecation warnings  \n\nThis unified pattern eliminates code duplication while preserving the modular, testable nature of the original PocketFlow design. For more details, see the [design document](docs/design.md).\n\n## Usage\n\n1. Install dependencies with uv:\n   ```bash\n   uv sync\n   ```\n\n2. Configure Claude Desktop to use the **unified server**:\n   ```json\n   {\n     \"mcpServers\": {\n       \"mutation-clinical-trials-mcp\": {\n         \"command\": \"uv\",\n         \"args\": [\"run\", \"python\", \"servers/main.py\"],\n         \"description\": \"Unified clinical trials matching server with runtime mode selection\"\n       }\n     }\n   }\n   ```\n\n3. **Optional**: Configure execution mode via environment variables:\n   ```json\n   {\n     \"mcpServers\": {\n       \"mutation-clinical-trials-mcp\": {\n         \"command\": \"uv\",\n         \"args\": [\"run\", \"python\", \"servers/main.py\"],\n         \"env\": {\n           \"MCP_ASYNC_MODE\": \"true\"\n         },\n         \"description\": \"Unified server in explicit async mode\"\n       }\n     }\n   }\n   ```\n\n3. Start Claude Desktop and ask questions like:\n   - \"What clinical trials are available for EGFR L858R mutations?\"\n   - \"Are there any trials for BRAF V600E mutations?\"  \n   - \"Tell me about trials for ALK rearrangements\"\n   - \"Search for multiple mutations: EGFR L858R,BRAF V600E,KRAS G12C\"\n\n4. Use enterprise monitoring tools:\n   - \"Get the server health status\"\n   - \"Show me the cache performance report\"\n   - \"What are the current metrics?\"\n\n---\n\n## Integrating with Claude Desktop \n\nYou can configure this project as a Claude Desktop MCP tool. Use path placeholders in your configuration, and substitute them with your actual paths:\n\n### Recommended Configuration (Unified Server)\n\n```json\n\"mutation-clinical-trials-mcp\": {\n  \"command\": \"{PATH_TO_VENV}/bin/python\",\n  \"args\": [\n    \"{PATH_TO_PROJECT}/servers/main.py\"\n  ],\n  \"description\": \"Unified clinical trials matching server with automatic mode selection.\"\n}\n```\n\n### Legacy Compatibility (Still Supported)\n\n```json\n\"mutation-clinical-trials-mcp-legacy\": {\n  \"command\": \"{PATH_TO_VENV}/bin/python\",\n  \"args\": [\n    \"{PATH_TO_PROJECT}/servers/primary.py\"\n  ],\n  \"description\": \"Legacy async server (redirects to unified server with deprecation warnings).\"\n}\n```\n\n**Path Variables:**\n- `{PATH_TO_VENV}`: Full path to your virtual environment directory.\n- `{PATH_TO_PROJECT}`: Full path to the directory containing your project files.\n\n**Installation Instructions:**\n1. Clone the repository to your local machine.\n2. Install uv if you don't have it already:\n   ```bash\n   curl -LsSf https://astral.sh/uv/install.sh | sh    # macOS/Linux\n   # or\n   iwr -useb https://astral.sh/uv/install.ps1 | iex    # Windows PowerShell\n   ```\n3. Create a virtual environment and install dependencies in one step:\n   ```bash\n   uv sync\n   ```\n4. Activate the virtual environment when needed:\n   ```bash\n   source .venv/bin/activate    # macOS/Linux\n   .venv\\Scripts\\activate       # Windows\n   ```\n5. Determine the full path to your virtual environment and project directory.\n6. Update your configuration with these specific paths.\n\n**Examples:**\n- On macOS/Linux:\n  ```json\n  \"command\": \"/Users/username/projects/mutation_trial_matcher/.venv/bin/python\"\n  ```\n- On Windows:\n  ```json\n  \"command\": \"C:\\\\Users\\\\username\\\\projects\\\\mutation_trial_matcher\\\\.venv\\\\Scripts\\\\python.exe\"\n  ```\n\n**Path Finding Tips:**\n- To find the exact path to your Python interpreter in the virtual environment, run:\n  - `which python` (macOS/Linux)\n  - `where python` (Windows, after activating the venv)\n- For the project path, use the full path to the directory containing `servers/primary.py`.\n\n---\n\n## Future Improvements\n\nFor a comprehensive list of planned enhancements and future work, please see the [future_work.md](docs/future_work.md) document.\n\n\n## Dependencies\n\nThis project relies on the following key dependencies:\n\n- **Python 3.11+** - Base runtime environment (lowered from 3.13+ for broader compatibility)\n- **FastMCP** (`fastmcp>=2.10.2`) - High-performance async MCP framework\n- **PocketFlow** (`pocketflow>=0.0.1`) - Framework for building modular AI workflows with the Node pattern  \n- **Requests** (`requests==2.31.0`) - HTTP library for clinicaltrials.gov API calls (dev dependency for legacy test compatibility)\n- **HTTPX** (`httpx>=0.28.1`) - Async HTTP client for direct Anthropic API calls\n- **Redis** (`redis>=6.2.0`) - Optional distributed caching backend\n- **Python-dotenv** (`python-dotenv==1.1.0`) - Environment variable management\n\n**Enterprise Features:**\n- Prometheus metrics collection and monitoring\n- Circuit breaker patterns for fault tolerance\n- Distributed caching with Redis backend\n- Cache warming strategies for performance optimization\n\nAll dependencies can be installed using `uv sync` as described in the installation instructions.\n\n## Troubleshooting\n\nIf Claude Desktop disconnects from the MCP server:\n- Check logs at: `~/Library/Logs/Claude/mcp-server-mutation-clinical-trials-mcp.log`\n- Restart Claude Desktop  \n- Verify the server is running correctly with `uv run python servers/main.py`\n- Check for deprecation warnings if using legacy servers (`servers/primary.py` or `servers/legacy/sync_server.py`)\n\n**Redis Connection Warnings:**\n- Redis connection errors are expected if Redis is not installed - the server uses in-memory caching as fallback\n- To eliminate warnings: `brew install redis && brew services start redis`\n- The server works perfectly without Redis, just with reduced caching performance\n\n**Cache Warming on Startup:**\n- Server automatically queries 15 common mutations on startup for performance optimization\n- This is normal behavior and improves response times for frequent queries\n- To disable: comment out `asyncio.run(startup_tasks())` in `servers/primary.py`\n\n## Development History\n\nThis project evolved through multiple phases of AI-collaborative development:\n\n**Phase 1** (2024-04-30): Initial prototype using synchronous architecture  \n**Phase 2** (2024-12): Enhanced with comprehensive testing and documentation  \n**Phase 3** (2025-01): Major refactoring for improved organization and maintainability  \n**Phase 4** (2025-01): Full async migration with enterprise features and 80% performance improvement  \n**Phase 5** (2025-07): API resilience improvements and 403 error resolution  \n**Phase 6** (2025-07): **Code Deduplication Project** - Comprehensive 4-phase unification effort  \n**Phase 7** (2025-07): **Repository Quality Excellence** - Professional code standards and legacy cleanup\n\n### Recent Achievements (July 2025)\n\n**Code Deduplication Project**:  \n**Phase 1**: Foundation Layer - Unified HTTP client and shared utilities  \n**Phase 2**: Service Layer Consolidation - Unified LLM and Clinical Trials services  \n**Phase 3**: Node Layer Unification - Enhanced UnifiedNode framework  \n**Phase 4**: Server Consolidation - Complete unified architecture  \n\n**Repository Quality Excellence**:  \n- **Code Quality**: 99.6% improvement (1,695 of 1,702 linting errors fixed)  \n- **Type Safety**: 69% reduction in type diagnostics (48 â†’ 15)  \n- **Professional Cleanup**: 3,435 lines of deprecated code removed  \n- **Compatibility Layer**: Complete backward compatibility with `utils/node.py` compatibility module  \n- **Python Compatibility**: Lowered requirement from Python 3.13+ to 3.11+ for broader adoption\n\n**Results**: 60% code reduction (~1,000 lines eliminated), zero breaking changes, unified sync/async architecture, production-ready code quality\n\n**Current Version (v0.2.1)**: Production-ready unified server with enterprise features, automatic mode selection, professional type safety, and comprehensive backward compatibility. Developed through collaboration with Claude Code, leveraging 20+ years of cancer research domain expertise to guide AI implementation and architectural transformation.\n\n\n## Contributing\n\nWe welcome contributions to improve the Mutation Clinical Trial Matching MCP! Here's how you can get involved:\n\n### Development Setup\n\n1. **Clone the repository**:\n   ```bash\n   git clone https://github.com/pickleton89/mutation-clinical-trial-matching-mcp.git\n   cd mutation-clinical-trial-matching-mcp\n   ```\n\n2. **Install dependencies**:\n   ```bash\n   uv sync\n   ```\n\n3. **Run tests**:\n   ```bash\n   uv run python -m unittest discover tests/\n   ```\n\n### Contribution Guidelines\n\n- **Follow the PocketFlow Node pattern** for new features\n- **Add comprehensive tests** for any new functionality\n- **Update documentation** including relevant docstrings and README sections\n- **Follow Python best practices** and maintain type hints\n- **Run linting and type checking** before submitting PRs\n\n### Areas for Contribution\n\n- **Performance optimizations** for large-scale clinical trial searches\n- **Additional mutation formats** and standardization\n- **Enhanced summarization capabilities** with more detailed filtering\n- **Integration with other clinical databases** beyond ClinicalTrials.gov\n- **UI/UX improvements** for the Claude Desktop integration\n\n### Reporting Issues\n\nPlease use the [GitHub Issues](https://github.com/pickleton89/mutation-clinical-trial-matching-mcp/issues) page to report bugs or request features.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgements\n\nThis project was built using the [PocketFlow-Template-Python](https://github.com/The-Pocket/PocketFlow-Template-Python) as a starting point. Special thanks to the original contributors of that project for providing the foundation and structure that made this implementation possible.\n\nThe project follows the Agentic Coding methodology as outlined in the original template.\n\n---\nâš ï¸ **Disclaimer**\n\nThis project is a prototype and is intended for research and demonstration purposes only. It should not be used to make medical decisions or as a substitute for professional medical advice, diagnosis, or treatment. Due to the limitations of large language models (LLMs), the information provided by this tool may be incomplete, inaccurate, or outdated. Users should exercise caution and consult qualified healthcare professionals before making any decisions based on the outputs of this system.\n\n---\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "clinical",
        "mutations",
        "clinicaltrials",
        "mutation clinical",
        "pickleton89 mutation",
        "medical pickleton89"
      ],
      "category": "healthcare-and-medical"
    },
    "uh-joan--cortellis-mcp-server": {
      "owner": "uh-joan",
      "name": "cortellis-mcp-server",
      "url": "https://github.com/uh-joan/cortellis-mcp-server",
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "description": "Access the Cortellis drug database to search for drugs, retrieve detailed information, and analyze drug development statuses. Provides tools for ontology exploration and financial insights.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ontology",
        "database",
        "cortellis",
        "drug database",
        "cortellis drug",
        "search drugs"
      ],
      "category": "healthcare-and-medical"
    },
    "wodiluluya--Viewers": {
      "owner": "wodiluluya",
      "name": "Viewers",
      "url": "https://github.com/wodiluluya/Viewers",
      "imageUrl": "/freedevtools/mcp/pfp/wodiluluya.webp",
      "description": "View and manipulate medical images directly in the browser with support for DICOMweb protocols. The platform features advanced functionalities like 2D and 3D rendering, measurement tracking, and customizable workflows for enhanced medical imaging capabilities.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2024-09-26T01:18:00Z",
      "readme_content": "<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<div align=\"center\">\n  <h1>OHIF Medical Imaging Viewer</h1>\n  <p><strong>The OHIF Viewer</strong> is a zero-footprint medical image viewer\nprovided by the <a href=\"https://ohif.org/\">Open Health Imaging Foundation (OHIF)</a>. It is a configurable and extensible progressive web application with out-of-the-box support for image archives which support <a href=\"https://www.dicomstandard.org/using/dicomweb/\">DICOMweb</a>.</p>\n</div>\n\n\n<div align=\"center\">\n  <a href=\"https://docs.ohif.org/\"><strong>Read The Docs</strong></a>\n</div>\n<div align=\"center\">\n  <a href=\"https://viewer.ohif.org/\">Live Demo</a> |\n  <a href=\"https://ui.ohif.org/\">Component Library</a>\n</div>\n<div align=\"center\">\n  ğŸ“° <a href=\"https://ohif.org/news/\"><strong>Join OHIF Newsletter</strong></a> ğŸ“°\n</div>\n<div align=\"center\">\n  ğŸ“° <a href=\"https://ohif.org/news/\"><strong>Join OHIF Newsletter</strong></a> ğŸ“°\n</div>\n\n\n\n<hr />\n\n[![NPM version][npm-version-image]][npm-url]\n[![MIT License][license-image]][license-url]\n[![This project is using Percy.io for visual regression testing.][percy-image]](percy-url)\n<!-- [![NPM downloads][npm-downloads-image]][npm-url] -->\n<!-- [![Pulls][docker-pulls-img]][docker-image-url] -->\n<!-- [![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2FOHIF%2FViewers.svg?type=shield)](https://app.fossa.io/projects/git%2Bgithub.com%2FOHIF%2FViewers?ref=badge_shield) -->\n\n<!-- [![Netlify Status][netlify-image]][netlify-url] -->\n<!-- [![CircleCI][circleci-image]][circleci-url] -->\n<!-- [![codecov][codecov-image]][codecov-url] -->\n<!-- [![All Contributors](https://img.shields.io/badge/all_contributors-10-orange.svg?style=flat-square)](#contributors) -->\n<!-- prettier-ignore-end -->\n\n\n|     |  | |\n| :-: | :---  | :--- |\n| <img src=\"https://github.com/OHIF/Viewers/blob/master/platform/docs/docs/assets/img/demo-measurements.webp?raw=true\" alt=\"Measurement tracking\" width=\"350\"/> | Measurement Tracking | [Demo](https://viewer.ohif.org/viewer?StudyInstanceUIDs=1.3.6.1.4.1.25403.345050719074.3824.20170125095438.5) |\n| <img src=\"https://github.com/OHIF/Viewers/blob/master/platform/docs/docs/assets/img/demo-segmentation.webp?raw=true\" alt=\"Segmentations\" width=\"350\"/> | Labelmap Segmentations  | [Demo](https://viewer.ohif.org/viewer?StudyInstanceUIDs=1.3.12.2.1107.5.2.32.35162.30000015050317233592200000046) |\n| <img src=\"https://github.com/OHIF/Viewers/blob/master/platform/docs/docs/assets/img/demo-ptct.webp?raw=true\" alt=\"Hanging Protocols\" width=\"350\"/> | Fusion and Custom Hanging protocols  | [Demo](https://viewer.ohif.org/tmtv?StudyInstanceUIDs=1.3.6.1.4.1.14519.5.2.1.7009.2403.334240657131972136850343327463) |\n| <img src=\"https://github.com/OHIF/Viewers/blob/master/platform/docs/docs/assets/img/demo-volume-rendering.webp?raw=true\" alt=\"Volume Rendering\" width=\"350\"/> | Volume Rendering  | [Demo](https://viewer.ohif.org/viewer?StudyInstanceUIDs=1.3.6.1.4.1.25403.345050719074.3824.20170125095438.5&hangingprotocolId=mprAnd3DVolumeViewport) |\n| <img src=\"https://github.com/OHIF/Viewers/blob/master/platform/docs/docs/assets/img/demo-pdf.webp?raw=true\" alt=\"PDF\" width=\"350\"/> | PDF  | [Demo](https://viewer.ohif.org/viewer?StudyInstanceUIDs=2.25.317377619501274872606137091638706705333) |\n| <img src=\"https://github.com/OHIF/Viewers/blob/master/platform/docs/docs/assets/img/demo-rtstruct.webp?raw=true\" alt=\"RTSTRUCT\" width=\"350\"/> | RT STRUCT  | [Demo](https://viewer.ohif.org/viewer?StudyInstanceUIDs=1.3.6.1.4.1.5962.99.1.2968617883.1314880426.1493322302363.3.0) |\n| <img src=\"https://github.com/OHIF/Viewers/blob/master/platform/docs/docs/assets/img/demo-4d.webp?raw=true\" alt=\"4D\" width=\"350\"/> | 4D  | [Demo](https://viewer.ohif.org/dynamic-volume?StudyInstanceUIDs=2.25.232704420736447710317909004159492840763) |\n| <img src=\"https://github.com/OHIF/Viewers/blob/master/platform/docs/docs/assets/img/demo-video.webp?raw=true\" alt=\"VIDEO\" width=\"350\"/> | Video  | [Demo](https://viewer.ohif.org/viewer?StudyInstanceUIDs=2.25.96975534054447904995905761963464388233) |\n| <img src=\"https://github.com/OHIF/Viewers/blob/master/platform/docs/docs/assets/img/microscopy.webp?raw=true\" alt=\"microscopy\" width=\"350\"/> | Slide Microscopy  | [Demo](https://viewer.ohif.org/microscopy?StudyInstanceUIDs=2.25.141277760791347900862109212450152067508) |\n\n## About\n\nThe OHIF Viewer can retrieve\nand load images from most sources and formats; render sets in 2D, 3D, and\nreconstructed representations; allows for the manipulation, annotation, and\nserialization of observations; supports internationalization, OpenID Connect,\noffline use, hotkeys, and many more features.\n\nAlmost everything offers some degree of customization and configuration. If it\ndoesn't support something you need, we accept pull requests and have an ever\nimproving Extension System.\n\n## Why Choose Us\n\n### Community & Experience\n\nThe OHIF Viewer is a collaborative effort that has served as the basis for many\nactive, production, and FDA Cleared medical imaging viewers. It benefits from\nour extensive community's collective experience, and from the sponsored\ncontributions of individuals, research groups, and commercial organizations.\n\n### Built to Adapt\n\nAfter more than 8-years of integrating with many companies and organizations,\nThe OHIF Viewer has been rebuilt from the ground up to better address the\nvarying workflow and configuration needs of its many users. All of the Viewer's\ncore features are built using it's own extension system. The same extensibility\nthat allows us to offer:\n\n- 2D and 3D medical image viewing\n- Multiplanar Reconstruction (MPR)\n- Maximum Intensity Project (MIP)\n- Whole slide microscopy viewing\n- PDF and Dicom Structured Report rendering\n- Segmentation rendering as labelmaps and contours\n- User Access Control (UAC)\n- Context specific toolbar and side panel content\n- and many others\n\nCan be leveraged by you to customize the viewer for your workflow, and to add\nany new functionality you may need (and wish to maintain privately without\nforking).\n\n### Support\n\n- [Report a Bug ğŸ›](https://github.com/OHIF/Viewers/issues/new?assignees=&labels=Community%3A+Report+%3Abug%3A%2CAwaiting+Reproduction&projects=&template=bug-report.yml&title=%5BBug%5D+)\n- [Request a Feature ğŸš€](https://github.com/OHIF/Viewers/issues/new?assignees=&labels=Community%3A+Request+%3Ahand%3A&projects=&template=feature-request.yml&title=%5BFeature+Request%5D+)\n- [Ask a Question ğŸ¤—](community.ohif.org)\n- [Slack Channel](https://join.slack.com/t/cornerstonejs/shared_invite/zt-1r8xb2zau-dOxlD6jit3TN0Uwf928w9Q)\n\nFor commercial support, academic collaborations, and answers to common\nquestions; please use [Get Support](https://ohif.org/get-support/) to contact\nus.\n\n\n## Developing\n\n### Branches\n\n#### `master` branch - The latest dev (beta) release\n\n- `master` - The latest dev release\n\nThis is typically where the latest development happens. Code that is in the master branch has passed code reviews and automated tests, but it may not be deemed ready for production. This branch usually contains the most recent changes and features being worked on by the development team. It's often the starting point for creating feature branches (where new features are developed) and hotfix branches (for urgent fixes).\n\nEach package is tagged with beta version numbers, and published to npm such as `@ohif/ui@3.6.0-beta.1`\n\n### `release/*` branches - The latest stable releases\nOnce the `master` branch code reaches a stable, release-ready state, we conduct a comprehensive code review and QA testing. Upon approval, we create a new release branch from `master`. These branches represent the latest stable version considered ready for production.\n\nFor example, `release/3.5` is the branch for version 3.5.0, and `release/3.6` is for version 3.6.0. After each release, we wait a few days to ensure no critical bugs. If any are found, we fix them in the release branch and create a new release with a minor version bump, e.g., 3.5.1 in the `release/3.5` branch.\n\nEach package is tagged with version numbers and published to npm, such as `@ohif/ui@3.5.0`. Note that `master` is always ahead of the `release` branch. We publish docker builds for both beta and stable releases.\n\nHere is a schematic representation of our development workflow:\n\n![alt text](platform/docs/docs/assets/img/github-readme-branches-Jun2024.png)\n\n\n\n\n\n### Requirements\n\n- [Yarn 1.17.3+](https://yarnpkg.com/en/docs/install)\n- [Node 18+](https://nodejs.org/en/)\n- Yarn Workspaces should be enabled on your machine:\n  - `yarn config set workspaces-experimental true`\n\n### Getting Started\n\n1. [Fork this repository][how-to-fork]\n2. [Clone your forked repository][how-to-clone]\n   - `git clone https://github.com/YOUR-USERNAME/Viewers.git`\n3. Navigate to the cloned project's directory\n4. Add this repo as a `remote` named `upstream`\n   - `git remote add upstream https://github.com/OHIF/Viewers.git`\n5. `yarn install` to restore dependencies and link projects\n\n#### To Develop\n\n_From this repository's root directory:_\n\n```bash\n# Enable Yarn Workspaces\nyarn config set workspaces-experimental true\n\n# Restore dependencies\nyarn install\n```\n\n## Commands\n\nThese commands are available from the root directory. Each project directory\nalso supports a number of commands that can be found in their respective\n`README.md` and `package.json` files.\n\n| Yarn Commands                | Description                                                   |\n| ---------------------------- | ------------------------------------------------------------- |\n| **Develop**                  |                                                               |\n| `dev` or `start`             | Default development experience for Viewer                     |\n| `test:unit`                  | Jest multi-project test runner; overall coverage              |\n| **Deploy**                   |                                                               |\n| `build`\\*                    | Builds production output for our PWA Viewer                   |  |\n\n\\* - For more information on our different builds, check out our [Deploy\nDocs][deployment-docs]\n\n## Project\n\nThe OHIF Medical Image Viewing Platform is maintained as a\n[`monorepo`][monorepo]. This means that this repository, instead of containing a\nsingle project, contains many projects. If you explore our project structure,\nyou'll see the following:\n\n```bash\n.\nâ”œâ”€â”€ extensions               #\nâ”‚   â”œâ”€â”€ _example             # Skeleton of example extension\nâ”‚   â”œâ”€â”€ default              # basic set of useful functionalities (datasources, panels, etc)\nâ”‚   â”œâ”€â”€ cornerstone       # image rendering and tools w/ Cornerstone3D\nâ”‚   â”œâ”€â”€ cornerstone-dicom-sr # DICOM Structured Report rendering and export\nâ”‚   â”œâ”€â”€ cornerstone-dicom-sr # DICOM Structured Report rendering and export\nâ”‚   â”œâ”€â”€ cornerstone-dicom-seg # DICOM Segmentation rendering and export\nâ”‚   â”œâ”€â”€ cornerstone-dicom-rt # DICOM RTSTRUCT rendering\nâ”‚   â”œâ”€â”€ cornerstone-microscopy # Whole Slide Microscopy rendering\nâ”‚   â”œâ”€â”€ dicom-pdf # PDF rendering\nâ”‚   â”œâ”€â”€ dicom-video # DICOM RESTful Services\nâ”‚   â”œâ”€â”€ measurement-tracking # Longitudinal measurement tracking\nâ”‚   â”œâ”€â”€ tmtv # Total Metabolic Tumor Volume (TMTV) calculation\n|\n\nâ”‚\nâ”œâ”€â”€ modes                    #\nâ”‚   â”œâ”€â”€ _example             # Skeleton of example mode\nâ”‚   â”œâ”€â”€ basic-dev-mode       # Basic development mode\nâ”‚   â”œâ”€â”€ longitudinal         # Longitudinal mode (measurement tracking)\nâ”‚   â”œâ”€â”€ tmtv       # Total Metabolic Tumor Volume (TMTV) calculation mode\nâ”‚   â””â”€â”€ microscopy          # Whole Slide Microscopy mode\nâ”‚\nâ”œâ”€â”€ platform                 #\nâ”‚   â”œâ”€â”€ core                 # Business Logic\nâ”‚   â”œâ”€â”€ i18n                 # Internationalization Support\nâ”‚   â”œâ”€â”€ ui                   # React component library\nâ”‚   â”œâ”€â”€ docs                 # Documentation\nâ”‚   â””â”€â”€ viewer               # Connects platform and extension projects\nâ”‚\nâ”œâ”€â”€ ...                      # misc. shared configuration\nâ”œâ”€â”€ lerna.json               # MonoRepo (Lerna) settings\nâ”œâ”€â”€ package.json             # Shared devDependencies and commands\nâ””â”€â”€ README.md                # This file\n```\n\n## Acknowledgments\n\nTo acknowledge the OHIF Viewer in an academic publication, please cite\n\n> _Open Health Imaging Foundation Viewer: An Extensible Open-Source Framework\n> for Building Web-Based Imaging Applications to Support Cancer Research_\n>\n> Erik Ziegler, Trinity Urban, Danny Brown, James Petts, Steve D. Pieper, Rob\n> Lewis, Chris Hafey, and Gordon J. Harris\n>\n> _JCO Clinical Cancer Informatics_, no. 4 (2020), 336-345, DOI:\n> [10.1200/CCI.19.00131](https://www.doi.org/10.1200/CCI.19.00131)\n>\n> Open-Access on Pubmed Central:\n> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7259879/\n\nor, for v1, please cite:\n\n> _LesionTracker: Extensible Open-Source Zero-Footprint Web Viewer for Cancer\n> Imaging Research and Clinical Trials_\n>\n> Trinity Urban, Erik Ziegler, Rob Lewis, Chris Hafey, Cheryl Sadow, Annick D.\n> Van den Abbeele and Gordon J. Harris\n>\n> _Cancer Research_, November 1 2017 (77) (21) e119-e122 DOI:\n> [10.1158/0008-5472.CAN-17-0334](https://www.doi.org/10.1158/0008-5472.CAN-17-0334)\n\n**Note:** If you use or find this repository helpful, please take the time to\nstar this repository on GitHub. This is an easy way for us to assess adoption\nand it can help us obtain future funding for the project.\n\nThis work is supported primarily by the National Institutes of Health, National\nCancer Institute, Informatics Technology for Cancer Research (ITCR) program,\nunder a\n[grant to Dr. Gordon Harris at Massachusetts General Hospital (U24 CA199460)](https://projectreporter.nih.gov/project_info_description.cfm?aid=8971104).\n\n[NCI Imaging Data Commons (IDC) project](https://imaging.datacommons.cancer.gov/) supported the development of new features and bug fixes marked with [\"IDC:priority\"](https://github.com/OHIF/Viewers/issues?q=is%3Aissue+is%3Aopen+label%3AIDC%3Apriority),\n[\"IDC:candidate\"](https://github.com/OHIF/Viewers/issues?q=is%3Aissue+is%3Aopen+label%3AIDC%3Acandidate) or [\"IDC:collaboration\"](https://github.com/OHIF/Viewers/issues?q=is%3Aissue+is%3Aopen+label%3AIDC%3Acollaboration). NCI Imaging Data Commons is supported by contract number 19X037Q from\nLeidos Biomedical Research under Task Order HHSN26100071 from NCI. [IDC Viewer](https://learn.canceridc.dev/portal/visualization) is a customized version of the OHIF Viewer.\n\nThis project is tested with BrowserStack. Thank you for supporting open-source!\n\n## License\n\nMIT Â© [OHIF](https://github.com/OHIF)\n\n<!--\n  Links\n  -->\n\n<!-- prettier-ignore-start -->\n<!-- Badges -->\n[lerna-image]: https://img.shields.io/badge/maintained%20with-lerna-cc00ff.svg\n[lerna-url]: https://lerna.js.org/\n[netlify-image]: https://api.netlify.com/api/v1/badges/32708787-c9b0-4634-b50f-7ca41952da77/deploy-status\n[netlify-url]: https://app.netlify.com/sites/ohif-dev/deploys\n[all-contributors-image]: https://img.shields.io/badge/all_contributors-0-orange.svg?style=flat-square\n[circleci-image]: https://circleci.com/gh/OHIF/Viewers.svg?style=svg\n[circleci-url]: https://circleci.com/gh/OHIF/Viewers\n[codecov-image]: https://codecov.io/gh/OHIF/Viewers/branch/master/graph/badge.svg\n[codecov-url]: https://codecov.io/gh/OHIF/Viewers/branch/master\n[prettier-image]: https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\n[prettier-url]: https://github.com/prettier/prettier\n[semantic-image]: https://img.shields.io/badge/%20%20%F0%9F%93%A6%F0%9F%9A%80-semantic--release-e10079.svg\n[semantic-url]: https://github.com/semantic-release/semantic-release\n<!-- ROW -->\n[npm-url]: https://npmjs.org/package/@ohif/app\n[npm-downloads-image]: https://img.shields.io/npm/dm/@ohif/app.svg?style=flat-square\n[npm-version-image]: https://img.shields.io/npm/v/@ohif/app.svg?style=flat-square\n[docker-pulls-img]: https://img.shields.io/docker/pulls/ohif/viewer.svg?style=flat-square\n[docker-image-url]: https://hub.docker.com/r/ohif/app\n[license-image]: https://img.shields.io/badge/license-MIT-blue.svg?style=flat-square\n[license-url]: LICENSE\n[percy-image]: https://percy.io/static/images/percy-badge.svg\n[percy-url]: https://percy.io/Open-Health-Imaging-Foundation/OHIF-Viewer\n<!-- Links -->\n[monorepo]: https://en.wikipedia.org/wiki/Monorepo\n[how-to-fork]: https://help.github.com/en/articles/fork-a-repo\n[how-to-clone]: https://help.github.com/en/articles/fork-a-repo#step-2-create-a-local-clone-of-your-fork\n[ohif-architecture]: https://docs.ohif.org/architecture/index.html\n[ohif-extensions]: https://docs.ohif.org/architecture/index.html\n[deployment-docs]: https://docs.ohif.org/deployment/\n[react-url]: https://reactjs.org/\n[pwa-url]: https://developers.google.com/web/progressive-web-apps/\n[ohif-viewer-url]: https://www.npmjs.com/package/@ohif/app\n[configuration-url]: https://docs.ohif.org/configuring/\n[extensions-url]: https://docs.ohif.org/extensions/\n<!-- Platform -->\n[platform-core]: platform/core/README.md\n[core-npm]: https://www.npmjs.com/package/@ohif/core\n[platform-i18n]: platform/i18n/README.md\n[i18n-npm]: https://www.npmjs.com/package/@ohif/i18n\n[platform-ui]: platform/ui/README.md\n[ui-npm]: https://www.npmjs.com/package/@ohif/ui\n[platform-viewer]: platform/app/README.md\n[viewer-npm]: https://www.npmjs.com/package/@ohif/app\n<!-- Extensions -->\n[extension-cornerstone]: extensions/cornerstone/README.md\n[cornerstone-npm]: https://www.npmjs.com/package/@ohif/extension-cornerstone\n[extension-dicom-html]: extensions/dicom-html/README.md\n[html-npm]: https://www.npmjs.com/package/@ohif/extension-dicom-html\n[extension-dicom-microscopy]: extensions/dicom-microscopy/README.md\n[microscopy-npm]: https://www.npmjs.com/package/@ohif/extension-dicom-microscopy\n[extension-dicom-pdf]: extensions/dicom-pdf/README.md\n[pdf-npm]: https://www.npmjs.com/package/@ohif/extension-dicom-pdf\n[extension-vtk]: extensions/vtk/README.md\n[vtk-npm]: https://www.npmjs.com/package/@ohif/extension-vtk\n<!-- prettier-ignore-end -->\n\n[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2FOHIF%2FViewers.svg?type=large)](https://app.fossa.io/projects/git%2Bgithub.com%2FOHIF%2FViewers?ref=badge_large)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "dicomweb",
        "wodiluluya",
        "imaging",
        "medical wodiluluya",
        "wodiluluya viewers",
        "support dicomweb"
      ],
      "category": "healthcare-and-medical"
    },
    "zhaoyouj--mcp-slicer": {
      "owner": "zhaoyouj",
      "name": "mcp-slicer",
      "url": "https://github.com/zhaoyouj/mcp-slicer",
      "imageUrl": "/freedevtools/mcp/pfp/zhaoyouj.webp",
      "description": "Connect and control 3D Slicer through natural language for medical image processing and scene manipulation. Execute Python code directly in the Slicer environment to enhance workflow and automate tasks.",
      "stars": 18,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-04T05:11:32Z",
      "readme_content": "<img src=\"https://github.com/zhaoyouj/mcp-slicer/blob/main/docs/images/logo.jpeg?raw=true\" width=\"160\" alt=\"logo\">\n\n# MCP-Slicer - 3D Slicer Model Context Protocol Integration\n\n[English](README.md) | [ç®€ä½“ä¸­æ–‡](README_zh.md)\n\n[![Python Version](https://img.shields.io/badge/python-3.13%2B-blue.svg)](https://www.python.org/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![PyPI version](https://img.shields.io/pypi/v/mcp-slicer.svg)](https://pypi.org/project/mcp-slicer/)\n\nMCP-Slicer connects 3D Slicer with model clients like Claude Desktop or Cline through the Model Context Protocol (MCP), enabling direct interaction and control of 3D Slicer. This integration allows for medical image processing, scene creation, and manipulation using natural language.\n\n## Features\n\n1. list_nodes: List and filter Slicer MRML nodes and view their properties\n\n2. execute_python_code: Execute Python code in the Slicer environment\n\n## Installation\n\n### Prerequisites\n\n- 3D Slicer 5.8 or newer\n- Python 3.13 or newer\n- uv package manager\n\n**If you're on Mac, please install uv as**\n\n```bash\nbrew install uv\n```\n\n**On Windows**\n\n```bash\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\nand then\n\n```bash\nset Path=C:\\Users\\nntra\\.local\\bin;%Path%\n```\n\nOtherwise installation instructions are on their website: [Install uv](https://docs.astral.sh/uv/getting-started/installation/)\n\n**âš ï¸ Please install UV first**\n\n### Claude for Desktop Integration\n\nGo to Claude > Settings > Developer > Edit Config > claude_desktop_config.json to include the following:\n\n```json\n{\n  \"mcpServers\": {\n    \"slicer\": {\n      \"command\": \"uvx\",\n      \"args\": [\"mcp-slicer\"]\n    }\n  }\n}\n```\n\n### Cline Intergration\n\n```json\n{\n  \"mcpServers\": {\n    \"slicer\": {\n      \"command\": \"uvx\",\n      \"args\": [\"mcp-slicer\"]\n    }\n  }\n}\n```\n\n## Usage\n\n### Check Claude Settings\n\n<img width=\"1045\" alt=\"Image\" src=\"https://github.com/zhaoyouj/mcp-slicer/blob/main/docs/images/claude_check.png?raw=true\" />\nMake sure you see the corresponding slicer tools added to the Claude Desktop App\n\n<img width=\"300\" alt=\"Image\" src=\"https://github.com/zhaoyouj/mcp-slicer/blob/main/docs/images/toolsButton.png?raw=true\" />\n<img width=\"300\" alt=\"Image\" src=\"https://github.com/zhaoyouj/mcp-slicer/blob/main/docs/images/tools_check.png?raw=true\" />\n\n### Open Slicer Web Server\n\n1. Open the Slicer Web Server module,\n2. ensure the required interfaces are checked,\n3. then start the server\n\n<img width=\"1045\" alt=\"Image\" src=\"https://github.com/zhaoyouj/mcp-slicer/blob/main/docs/images/start_slicer_web_server.png?raw=true\" />\n\n## Examples\n\n### - list_nodes\n\n> What Markups nodes are in the Slicer scene now, list their names, what is their length if it is a line, and what is its angle if it is an angle\n\n<img width=\"1045\" alt=\"Image\" src=\"https://github.com/zhaoyouj/mcp-slicer/blob/main/docs/images/example_list_nodes_en.png?raw=true\" />\n\n### - execute python code\n\n> Draw a translucent green cube of 8 cm in the Slicer scene, mark its vertices, and then draw a red sphere inscribed in it.\n\n<img width=\"1045\" alt=\"example_code_execute_en\" src=\"https://github.com/zhaoyouj/mcp-slicer/blob/main/docs/images/example_code_execute_en.png?raw=true\" />\n\n## Technical Details\n\nUtilizes existing Slicer Web Server interfaces. For technical details, please see [Slicer web server user guide](https://slicer.readthedocs.io/en/latest/user_guide/modules/webserver.html)\n\n## Limitations & Security Considerations\n\n- The `execute_python_code` tool allows running arbitrary Python code in 3D Slicer, which is powerful but potentially dangerous.\n\n  **âš ï¸ Not recommended for production use.**\n\n- Complex operations may need to be broken down into smaller steps.\n\n## Contributing\n\nContributions are welcome! Feel free to submit Pull Requests.\n\n## Disclaimer\n\nThis is a third-party integration project, not developed by the 3D Slicer team.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "slicer",
        "python",
        "mcp",
        "mcp slicer",
        "3d slicer",
        "slicer environment"
      ],
      "category": "healthcare-and-medical"
    }
  }
}