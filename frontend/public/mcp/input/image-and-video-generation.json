{
  "category": "image-and-video-generation",
  "categoryDisplay": "Image and Video Generation",
  "description": "",
  "totalRepositories": 135,
  "repositories": {
    "13rac1--videocapture-mcp": {
      "owner": "13rac1",
      "name": "videocapture-mcp",
      "url": "https://github.com/13rac1/videocapture-mcp",
      "imageUrl": "https://github.com/13rac1.png",
      "description": "The Video Still Capture MCP server allows AI models to access and control webcams to take still images and adjust camera settings using OpenCV, without streaming video.",
      "stars": 11,
      "forks": 3,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-20T23:19:39Z",
      "readme_content": "# Video Still Capture MCP\n\n**A Model Context Protocol server for accessing and controlling webcams via OpenCV**\n\n## Overview\n\nVideo Still Capture MCP is a Python implementation of the Model Context Protocol (MCP) that provides AI assistants with the ability to access and control webcams and video sources through OpenCV. This server exposes a set of tools that allow language models to capture images, manipulate camera settings, and manage video connections. There is no video capture.\n\n## Examples\n\nHere are some examples of the Video Still Capture  MCP server in action:\n\n### Orange Example\nLeft: Claude's view of the image | Right: Actual webcam capture\n:-------------------------:|:-------------------------:\n![Claude's view of orange](images/orange-claude.png) | ![Webcam capture of orange](images/orange-webcam.jpg)\n\n### Magnet Example\nLeft: Claude's view of the image | Right: Actual webcam capture\n:-------------------------:|:-------------------------:\n![Claude's view of magnet](images/magnet-claude.png) | ![Webcam capture of magnet](images/magnet-webcam.jpg)\n\n## Installation\n\n### Prerequisites\n\n- Python 3.10+\n- [OpenCV](https://opencv.org/) (`opencv-python`)\n- [MCP Python SDK](https://modelcontextprotocol.io/docs/)\n- [UV](https://astral.sh/uv/) (optional)\n\n### Installation from source\n\n```bash\ngit clone https://github.com/13rac1/videocapture-mcp.git\ncd videocapture-mcp\npip install -e .\n```\n\nRun the MCP server:\n\n```bash\nmcp dev videocapture_mcp.py\n```\n\n## Integrating with Claude for Desktop\n\n### macOS/Linux\n\nEdit your Claude Desktop configuration:\n\n```bash\n# Mac\nnano ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n# Linux\nnano ~/.config/Claude/claude_desktop_config.json \n```\n\nAdd this MCP server configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"VideoCapture \": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"mcp[cli]\",\n        \"--with\",\n        \"numpy\",\n        \"--with\",\n        \"opencv-python\",\n        \"mcp\",\n        \"run\",\n        \"/ABSOLUTE_PATH/videocapture_mcp.py\"\n      ]\n    }\n  }\n}\n```\n\nEnsure you replace `/ABSOLUTE_PATH/videocapture-mcp` with the project's absolute path.\n\n### Windows\n\nEdit your Claude Desktop configuration:\n\n```powershell\nnano $env:AppData\\Claude\\claude_desktop_config.json\n```\n\nAdd this MCP server configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"VideoCapture\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"mcp[cli]\",\n        \"--with\",\n        \"numpy\",\n        \"--with\",\n        \"opencv-python\",\n        \"mcp\",\n        \"run\",\n        \"C:\\ABSOLUTE_PATH\\videocapture-mcp\\videocapture_mcp.py\"\n      ]\n    }\n  }\n}\n```\n\nEnsure you replace `C:\\ABSOLUTE_PATH\\videocapture-mcp` with the project's absolute path.\n\n### Using the Installation Command\n\nAlternatively, you can use the `mcp` CLI to install the server:\n\n```bash\nmcp install videocapture_mcp.py\n```\n\nThis will automatically configure Claude Desktop to use your videocapture MCP server.\n\nOnce integrated, Claude will be able to access your webcam or video source when requested. Simply ask Claude to take a photo or perform any webcam-related task.\n\n## Features\n\n- **Quick Image Capture**: Capture a single image from a webcam without managing connections\n- **Connection Management**: Open, manage, and close camera connections\n- **Video Properties**: Read and adjust camera settings like brightness, contrast, and resolution\n- **Image Processing**: Basic image transformations like horizontal flipping\n\n## Tools Reference\n\n### `quick_capture`\n\nQuickly open a camera, capture a single frame, and close it.\n\n```python\nquick_capture(device_index: int = 0, flip: bool = False) -> Image\n```\n\n- **device_index**: Camera index (0 is usually the default webcam)\n- **flip**: Whether to horizontally flip the image\n- **Returns**: The captured frame as an Image object\n\n### `open_camera`\n\nOpen a connection to a camera device.\n\n```python\nopen_camera(device_index: int = 0, name: Optional[str] = None) -> str\n```\n\n- **device_index**: Camera index (0 is usually the default webcam)\n- **name**: Optional name to identify this camera connection\n- **Returns**: Connection ID for the opened camera\n\n### `capture_frame`\n\nCapture a single frame from the specified video source.\n\n```python\ncapture_frame(connection_id: str, flip: bool = False) -> Image\n```\n\n- **connection_id**: ID of the previously opened video connection\n- **flip**: Whether to horizontally flip the image\n- **Returns**: The captured frame as an Image object\n\n### `get_video_properties`\n\nGet properties of the video source.\n\n```python\nget_video_properties(connection_id: str) -> dict\n```\n\n- **connection_id**: ID of the previously opened video connection\n- **Returns**: Dictionary of video properties (width, height, fps, etc.)\n\n### `set_video_property`\n\nSet a property of the video source.\n\n```python\nset_video_property(connection_id: str, property_name: str, value: float) -> bool\n```\n\n- **connection_id**: ID of the previously opened video connection\n- **property_name**: Name of the property to set (width, height, brightness, etc.)\n- **value**: Value to set\n- **Returns**: True if successful, False otherwise\n\n### `close_connection`\n\nClose a video connection and release resources.\n\n```python\nclose_connection(connection_id: str) -> bool\n```\n\n- **connection_id**: ID of the connection to close\n- **Returns**: True if successful\n\n### `list_active_connections`\n\nList all active video connections.\n\n```python\nlist_active_connections() -> list\n```\n\n- **Returns**: List of active connection IDs\n\n## Example Usage\n\nHere's how an AI assistant might use the Webcam MCP server:\n\n1. **Take a quick photo**:\n   ```\n   I'll take a photo using your webcam.\n   ```\n   (The AI would call `quick_capture()` behind the scenes)\n\n2. **Open a persistent connection**:\n   ```\n   I'll open a connection to your webcam so we can take multiple photos.\n   ```\n   (The AI would call `open_camera()` and store the connection ID)\n\n3. **Adjust camera settings**:\n   ```\n   Let me increase the brightness of the webcam feed.\n   ```\n   (The AI would call `set_video_property()` with the appropriate parameters)\n\n## Advanced Usage\n\n### Resource Management\n\nThe server automatically manages camera resources, ensuring all connections are properly released when the server shuts down. For long-running applications, it's good practice to explicitly close connections when they're no longer needed.\n\n### Multiple Cameras\n\nIf your system has multiple cameras, you can specify the device index when opening a connection:\n\n```python\n# Open the second webcam (index 1)\nconnection_id = open_camera(device_index=1)\n```\n\n## Troubleshooting\n\n- **Camera Not Found**: Ensure your webcam is properly connected and not in use by another application\n- **Permission Issues**: Some systems require explicit permission to access the camera\n- **OpenCV Installation**: If you encounter issues with OpenCV, refer to the [official installation guide](https://docs.opencv.org/master/d5/de5/tutorial_py_setup_in_windows.html)\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.",
      "npm_url": "",
      "npm_downloads": 0
    },
    "396001000--ComfyUI_StoryDiffusion": {
      "owner": "396001000",
      "name": "ComfyUI_StoryDiffusion",
      "url": "https://github.com/396001000/ComfyUI_StoryDiffusion",
      "imageUrl": "https://github.com/null.png",
      "description": "ComfyUI_StoryDiffusion allows users to create visually enhanced stories by integrating advanced image generation features into the ComfyUI platform. It utilizes the StoryDiffusion and MS-Diffusion models for creative storytelling through visuals.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0
    },
    "8bitsats--Grok-MCP": {
      "owner": "8bitsats",
      "name": "Grok-MCP",
      "url": "https://github.com/8bitsats/Grok-MCP",
      "imageUrl": "https://github.com/8bitsats.png",
      "description": "MCP server for generating images using Grok's AI image generation capabilities, accepting text prompts and returning images as URLs or base64-encoded data. Supports multiple image generation requests and error handling, with configuration options for API keys.",
      "stars": 7,
      "forks": 0,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:32:23Z",
      "readme_content": "Grok AI Image Generation MCP Server \n\n\nAI Image Generation MCP Server\n\nA server that connects to the xAI/Grok image generation API\nImplemented proper error handling with lazy API key initialization\nAdded support for multiple image generation (up to 10 images)\nAdded support for different response formats (URL or base64 JSON)\nDocker Support:\n\nAdded a Dockerfile to containerize the MCP server\nConfigured the Dockerfile with a dummy API key that can be overridden at runtime\nSet up proper layer caching for efficient builds\nMCP Tools Available:\n\ngenerate_image: Generate images using the Grok-2-image model\nset_api_key: Set the xAI API key at runtime if not provided via environment variable\nHow to Use\nYou can now generate images with prompts like:\n\n\"Generate an image of a cat in a space suit\"\n\"Create a picture of a futuristic city at night\"\nThe MCP server has been configured in your Claude desktop app, and the implementation handles API key management gracefully, allowing the server to start even without an API key initially set.\n\nIf you want to run the server in Docker, you can build and run it with:\n\ncd /Users/8bit/Documents/Cline/MCP/ai-image-generator\ndocker build -t grokart .\ndocker run -e XAI_API_KEY=your-api-key -p 8080:8080 grokart\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "8bitsats--GROK_MCP": {
      "owner": "8bitsats",
      "name": "GROK_MCP",
      "url": "https://github.com/8bitsats/GROK_MCP",
      "imageUrl": "https://github.com/null.png",
      "description": "Analyze Solana blockchain transactions and addresses, process images through vision capabilities, and answer general queries with contextual understanding.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0
    },
    "agan2023416--workers": {
      "owner": "agan2023416",
      "name": "workers",
      "url": "https://github.com/agan2023416/workers",
      "imageUrl": "https://github.com/agan2023416.png",
      "description": "An MCP server for image generation that interfaces with a Cloudflare Worker to enable asynchronous image creation, real-time status updates, and error handling. It supports type-safe API calls for generating images based on given prompts.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-14T00:28:04Z",
      "readme_content": "# Cloudflare Workers Collection\n\nThis repository contains a collection of specialized Cloudflare Workers and related tools, each designed to provide specific functionality and services.\n\n## Available Projects\n\n### [replicate-2-r2](./replicate-2-r2)\nA worker that integrates Replicate's AI image generation with Cloudflare R2 storage. This worker:\n- Generates images using Replicate's API\n- Stores generated images in Cloudflare R2\n- Provides immediate URL generation\n- Supports webhook notifications\n- Includes MCP server integration for seamless AI tooling\n\nğŸ‘‰ [Learn more about replicate-2-r2](./replicate-2-r2)\n\n### [generate-image](./mcps/generate-image)\nA Model Context Protocol (MCP) server that provides a simple interface to the replicate-2-r2 worker. This server:\n- Interfaces with replicate-2-r2 worker\n- Provides type-safe API calls\n- Handles asynchronous image generation\n- Supports real-time status updates\n\nğŸ‘‰ [Learn more about generate-image](./mcps/generate-image)\n\n### [n8n-image-generator](./mcps/n8n-image-generator) â­ NEW\nA specialized MCP server designed specifically for n8n integration with SSE protocol support. This server:\n- **Perfect n8n Integration**: Works seamlessly with n8n's MCP Client Tool\n- **SSE Protocol Support**: Real-time communication using Server-Sent Events\n- **Multi-Model Support**: Supports Flux, Stable Diffusion, and more AI models\n- **Production Ready**: Built with error handling and monitoring\n- **Zero Worker Changes**: Uses existing replicate-2-r2 worker without modifications\n\nğŸ‘‰ [Learn more about n8n-image-generator](./mcps/n8n-image-generator)\n\n## ğŸš€ Quick Start for n8n Users\n\nIf you want to use AI image generation in n8n workflows, follow these steps:\n\n### 1. Deploy the Worker\n```bash\ncd replicate-2-r2\nnpm install\nnpm run deploy\n```\n\n### 2. Set up the MCP Server\n```bash\ncd mcps/n8n-image-generator\nnpm install\nnpm run build\n```\n\n### 3. Configure Environment\n```bash\nexport CLOUDFLARE_WORKERS_URL=https://your-worker.workers.dev\nexport WORKER_API_TOKEN=your-api-token\nnpm start\n```\n\n### 4. Add to n8n\nIn your n8n workflow:\n1. Add **MCP Client Tool** node\n2. Configure connection to your MCP server\n3. Use `generate_image` tool with your prompt\n\n## Architecture Overview\n\n```mermaid\ngraph TB\n    A[n8n Workflow] -->|SSE/MCP| B[n8n-image-generator MCP Server]\n    B -->|HTTP API| C[replicate-2-r2 Worker]\n    C -->|AI Generation| D[Replicate API]\n    C -->|Storage| E[Cloudflare R2]\n    C -->|Webhook| C\n    \n    style A fill:#e1f5fe\n    style B fill:#f3e5f5\n    style C fill:#e8f5e8\n    style D fill:#fff3e0\n    style E fill:#fce4ec\n```\n\n## Getting Started\n\nEach project is contained in its own directory with its own documentation. To get started:\n\n1. Choose the project you want to use\n2. Navigate to its directory\n3. Follow the setup instructions in its README.md\n\n## Repository Structure\n\n```\ncloudflare-workers/\nâ”œâ”€â”€ README.md\nâ”œâ”€â”€ replicate-2-r2/         # Replicate integration worker\nâ”‚   â”œâ”€â”€ README.md           # Worker-specific documentation\nâ”‚   â”œâ”€â”€ src/                # Source code\nâ”‚   â””â”€â”€ ...                 # Other worker files\nâ””â”€â”€ mcps/                   # MCP servers\n    â”œâ”€â”€ generate-image/     # Original MCP server\n    â”‚   â”œâ”€â”€ README.md       # Server documentation\n    â”‚   â”œâ”€â”€ src/           # Source code\n    â”‚   â””â”€â”€ ...            # Other server files\n    â””â”€â”€ n8n-image-generator/ # â­ NEW: n8n-specific MCP server\n        â”œâ”€â”€ README.md       # Detailed setup guide\n        â”œâ”€â”€ src/           # TypeScript source\n        â””â”€â”€ ...            # Configuration files\n```\n\n## ğŸ”„ Migration from generate-image to n8n-image-generator\n\nIf you're currently using the original `generate-image` MCP server, consider migrating to `n8n-image-generator` for better n8n integration:\n\n### Benefits of n8n-image-generator:\n- âœ… **Better SSE Support**: Designed specifically for n8n's MCP Client Tool\n- âœ… **Enhanced Error Handling**: More robust error messages and logging\n- âœ… **Improved Performance**: Optimized for n8n workflow patterns\n- âœ… **Better Documentation**: Comprehensive setup and usage guides\n- âœ… **Active Development**: Focused on n8n use cases\n\n### Migration Steps:\n1. Install the new MCP server: `cd mcps/n8n-image-generator && npm install`\n2. Update your n8n MCP Client Tool configuration\n3. Test your workflows with the new server\n4. Enjoy improved reliability and performance!\n\nMore projects will be added to this collection in the future. Stay tuned for updates!",
      "npm_url": "",
      "npm_downloads": 0
    },
    "aigc17--Al-StoryLab": {
      "owner": "aigc17",
      "name": "Al-StoryLab",
      "url": "https://github.com/aigc17/Al-StoryLab",
      "imageUrl": "https://github.com/aigc17.png",
      "description": "AI-StoryLab generates interactive stories with accompanying audio effects and provides illustration prompts. It leverages AI services for story creation, voice synthesis, sound effect generation, and suggests relevant audio placements.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "",
      "updated_at": "2025-01-21T02:57:12Z",
      "readme_content": "# AI-StoryLab\n\nAI-StoryLab æ˜¯ä¸€ä¸ªåŸºäº Next.js å¼€å‘çš„æ™ºèƒ½æ•…äº‹åˆ›ä½œå¹³å°ï¼Œå®ƒèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·ç”Ÿæˆæ•…äº‹å¹¶æ·»åŠ éŸ³é¢‘æ•ˆæœï¼Œè®©æ•…äº‹æ›´åŠ ç”ŸåŠ¨æœ‰è¶£ã€‚åŒæ—¶æ”¯æŒç”Ÿæˆé…å¥—çš„ç»˜å›¾æç¤ºè¯ï¼Œæ–¹ä¾¿ç”¨æˆ·ä½¿ç”¨ Midjourneyã€Recraft ç­‰ AI ç»˜å›¾å·¥å…·åˆ›å»ºæ’å›¾ã€‚\n\n## ä¸»è¦åŠŸèƒ½\n\n- **æ•…äº‹ç”Ÿæˆ**ï¼šæ ¹æ®ä¸»é¢˜è‡ªåŠ¨ç”Ÿæˆæ•…äº‹å†…å®¹\n- **è¯­éŸ³åˆæˆ**ï¼šæ”¯æŒä¸­è‹±æ–‡è¯­éŸ³ç”Ÿæˆ\n  - ä¸­æ–‡ï¼šä½¿ç”¨ æµ·èº MiniMax è¯­éŸ³æœåŠ¡\n  - è‹±æ–‡ï¼šä½¿ç”¨ Replicate Kokoro è¯­éŸ³æœåŠ¡\n- **éŸ³æ•ˆç”Ÿæˆ**ï¼šä½¿ç”¨ ElevenLabs ç”Ÿæˆé€¼çœŸçš„éŸ³æ•ˆ\n- **æ™ºèƒ½å»ºè®®**ï¼šè‡ªåŠ¨æ¨èåˆé€‚çš„éŸ³æ•ˆä½ç½®\n- **ç»˜å›¾æç¤ºè¯**ï¼šä¸ºæ•…äº‹åœºæ™¯è‡ªåŠ¨ç”Ÿæˆ AI ç»˜å›¾æç¤ºè¯\n- **å¯¼å‡ºåŠŸèƒ½**ï¼š\n  - å¯¼å‡ºéŸ³æ•ˆä½ç½®æŒ‡å—\n  - å¯¼å‡ºç»˜å›¾æç¤ºè¯\n\n## æŠ€æœ¯æ ˆ\n\n- **æ¡†æ¶**ï¼šNext.js 14\n- **è¯­è¨€**ï¼šTypeScript\n- **æ ·å¼**ï¼šTailwind CSS\n- **UIç»„ä»¶**ï¼šshadcn/ui (åŸºäº Radix UI çš„ç»„ä»¶åº“)\n- **AIæœåŠ¡**ï¼š\n  - DeepSeekï¼šæ•…äº‹ç”Ÿæˆå’Œç»˜å›¾æç¤ºè¯ç”Ÿæˆ\n  - MiniMaxï¼šä¸­æ–‡è¯­éŸ³\n  - Kokoroï¼šè‹±æ–‡è¯­éŸ³\n  - ElevenLabsï¼šéŸ³æ•ˆç”Ÿæˆ\n\n## å¼€å§‹ä½¿ç”¨\n\n1. å…‹éš†é¡¹ç›®\n```bash\ngit clone https://github.com/nicekate/Al-StoryLab.git\ncd Al-StoryLab\n```\n\n2. å®‰è£…ä¾èµ–\n```bash\nnpm install\n```\n\n3. é…ç½®ç¯å¢ƒå˜é‡\nå¤åˆ¶ `.env.example` æ–‡ä»¶å¹¶é‡å‘½åä¸º `.env.local`ï¼Œå¡«å…¥å¿…è¦çš„ API å¯†é’¥ï¼š\n\néœ€è¦åœ¨ä»¥ä¸‹å¹³å°æ³¨å†Œå¹¶è·å– API å¯†é’¥ï¼š\n- DeepSeek API Key ([è·å–åœ°å€](https://api-docs.deepseek.com/zh-cn/))\n- MiniMax API Key å’Œ Group ID ([è·å–åœ°å€](https://platform.minimaxi.com/))\n- ElevenLabs API Key ([è·å–åœ°å€](https://elevenlabs.io))\n- Replicate API Token ([è·å–åœ°å€](https://replicate.com/))\n\nå°†è·å–çš„å¯†é’¥å¡«å…¥ `.env.local`ï¼š\n- DEEPSEEK_API_KEY\n- MINIMAX_API_KEY\n- MINIMAX_GROUP_ID\n- ELEVENLABS_API_KEY\n- REPLICATE_API_TOKEN\n\n4. å¯åŠ¨å¼€å‘æœåŠ¡å™¨\n```bash\nnpm run dev\n```\n\n5. è®¿é—® [http://localhost:3000](http://localhost:3000) å¼€å§‹ä½¿ç”¨\n\n## ä½¿ç”¨æŒ‡å—\n\n### ç”Ÿæˆæ•…äº‹\n1. è¾“å…¥æ•…äº‹ä¸»é¢˜æˆ–ä½¿ç”¨è‡ªåŠ¨ç”Ÿæˆçš„æç¤º\n2. é€‰æ‹©è¯­è¨€ï¼ˆä¸­æ–‡/è‹±æ–‡ï¼‰\n3. ç‚¹å‡»ç”ŸæˆæŒ‰é’®\n\n### æ·»åŠ éŸ³æ•ˆ\n1. ä½¿ç”¨æ™ºèƒ½å»ºè®®ç”ŸæˆéŸ³æ•ˆæç¤ºè¯\n2. é€‰æ‹©åˆé€‚çš„éŸ³æ•ˆä½ç½®\n3. ç‚¹å‡»ç”ŸæˆéŸ³æ•ˆ\n\n### ç”Ÿæˆç»˜å›¾æç¤ºè¯\n1. åœ¨æ•…äº‹ç”Ÿæˆåï¼Œç‚¹å‡»\"ç”Ÿæˆç»˜å›¾æç¤ºè¯\"\n2. ç³»ç»Ÿä¼šä¸ºæ¯ä¸ªå…³é”®åœºæ™¯ç”Ÿæˆ AI ç»˜å›¾æç¤ºè¯\n3. å¯ä»¥ç›´æ¥å¤åˆ¶ä½¿ç”¨æˆ–å¯¼å‡ºä¿å­˜\n\n## è®¸å¯è¯\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0
    },
    "aiyogg--tinypng-mcp-server": {
      "owner": "aiyogg",
      "name": "tinypng-mcp-server",
      "url": "https://github.com/aiyogg/tinypng-mcp-server",
      "imageUrl": "https://github.com/aiyogg.png",
      "description": "Compress images using the TinyPNG API to reduce file size while maintaining quality. Integrate image optimization into various projects seamlessly.",
      "stars": 4,
      "forks": 4,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-04-28T10:03:48Z",
      "readme_content": "## MCP server for TinyPNG\n[![smithery badge](https://smithery.ai/badge/@aiyogg/tinypng-mcp-server)](https://smithery.ai/server/@aiyogg/tinypng-mcp-server) [![MseeP.ai Security Assessment Badge](https://mseep.net/mseep-audited.png)](https://mseep.ai/app/aiyogg-tinypng-mcp-server)\n\n### Usage\n\n### Use `bun` or `node` to run the server\n\n1. Install dependencies and build\n\n```bash\npnpm i\npnpm build\n```\n\n2. Edit the `mcp.json` file\n\n```json\n{\n  \"mcpServers\": {\n    \"tinypng\": {\n      \"command\": \"bun\", // or \"node\"\n      \"args\": [\"/path/to/tinypng-mcp-server/src/index.ts\"], // or \"dist/index.js\"\n      \"env\": {\n        \"TINYPNG_API_KEY\": \"your-tinypng-api-key\"\n      }\n    }\n  }\n}\n```\n\n### Installing via Smithery\n\nTo install TinyPNG MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@aiyogg/tinypng-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @aiyogg/tinypng-mcp-server --client claude\n```\n\n### Tools\n\n1. Compress local image\n\n```js\n{\n  name: 'compress_local_image',\n  description: 'Compress a local image file',\n  inputSchema: {\n    type: 'object',\n    properties: {\n      imagePath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to the image file to compress',\n        example: '/Users/user/Downloads/image.jpg',\n      },\n      outputPath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to save the compressed image file',\n        example: '/Users/user/Downloads/image_compressed.jpg',\n      },\n      outputFormat: {\n        type: 'string',\n        description: 'The format to save the compressed image file',\n        enum: SUPPORTED_IMAGE_TYPES,\n        example: 'image/jpeg',\n      },\n    },\n    required: ['imagePath'],\n  },\n}\n```\n\n2. Compress remote image\n\n```js\n{\n  name: 'compress_remote_image',\n  description: 'Compress a remote image file by giving the URL of the image',\n  inputSchema: {\n    type: 'object',\n    properties: {\n      imageUrl: {\n        type: 'string',\n        description: 'The URL of the image file to compress',\n        example: 'https://example.com/image.jpg',\n      },\n      outputPath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to save the compressed image file',\n        example: '/Users/user/Downloads/image_compressed.jpg',\n      },\n      outputFormat: {\n        type: 'string',\n        description: 'The format to save the compressed image file',\n        enum: SUPPORTED_IMAGE_TYPES,\n        example: 'image/jpeg',\n      },\n    },\n    required: ['imageUrl'],\n  },\n}\n```\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Antipas--4oimage-mcp": {
      "owner": "Antipas",
      "name": "4oimage-mcp",
      "url": "https://github.com/Antipas/4oimage-mcp",
      "imageUrl": "https://github.com/Antipas.png",
      "description": "Generate and edit high-quality images using text prompts. Transform existing images or create new visuals and 3D characters with real-time updates and automatic viewing in the browser.",
      "stars": 4,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-05-26T22:44:07Z",
      "readme_content": "# 4o-image MCP Server\n\nAn MCP server implementation that integrates with 4o-image API, enabling LLMs and other AI systems to generate and edit images through a standardized protocol. Create high-quality art, 3D characters, and custom images using simple text prompts.\n\n<a href=\"https://glama.ai/mcp/servers/@Antipas/4oimage-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@Antipas/4oimage-mcp/badge\" alt=\"mcp-4o-Image-Generator MCP server\" />\n</a>\n\n[![npm version](https://img.shields.io/npm/v/4oimage-mcp.svg)](https://www.npmjs.com/package/4oimage-mcp)\n[![Node.js Version](https://img.shields.io/node/v/4oimage-mcp.svg)](https://nodejs.org)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n## Features\n\n* **Text-to-Image Generation**: Create images from text descriptions with AI\n* **Image Editing**: Transform existing images using text prompts\n* **Real-time Progress Updates**: Get feedback on generation status\n* **Browser Integration**: Automatically open generated images in your default browser\n\n\n## Tools\n\n* **generateImage**\n  * Generate images based on text prompts with optional image editing\n  * Inputs:\n    * `prompt` (string, required): Text description of the desired image\n    * `imageBase64` (string, optional): Base64-encoded image for editing or style transfer\n\n## Configuration\n\n### Getting an API Key\n\n1. Register for an account at [4o-image.app](https://4o-image.app/dashboard/)\n2. Obtain your API key from the user dashboard\n3. Set the API key as an environment variable when running the server\n\n### Usage with Claude Desktop\n\nAdd this to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"4o-image\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"4oimage-mcp\"\n      ],\n      \"env\": {\n        \"API_KEY\": \"YOUR_API_KEY_HERE\"\n      }\n    }\n  }\n}\n```\n\n## Example Usage\n\nHere's an example of using this MCP server with Claude:\n\n```\nGenerate an image of a dog running on the beach at sunset\n```\n\nClaude will use the MCP server to generate the image, which will automatically open in your default browser. You'll also get a direct link to the image in Claude's response.\n\nFor image editing, you can include a base image and prompt Claude to modify it:\n\n```\nEdit this image to make the sky more dramatic with storm clouds\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. You are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License.",
      "npm_url": "",
      "npm_downloads": 0
    },
    "apinetwork--piapi-mcp-server": {
      "owner": "apinetwork",
      "name": "piapi-mcp-server",
      "url": "https://github.com/apinetwork/piapi-mcp-server",
      "imageUrl": "https://github.com/apinetwork.png",
      "description": "Integrates with PiAPI's API to facilitate media content generation using various services like Midjourney, Flux, and more. It connects AI models with tools for seamless content creation directly from applications that support the Model Context Protocol.",
      "stars": 61,
      "forks": 22,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-27T21:10:22Z",
      "readme_content": "# piapi-mcp-server\n\n[![Website](https://img.shields.io/badge/Website-piapi.ai-blue?style=flat-square&logo=internet-explorer)](https://piapi.ai)\n[![Documentation](https://img.shields.io/badge/Documentation-docs-green?style=flat-square&logo=bookstack)](https://piapi.ai/docs)\n[![Discord](https://img.shields.io/badge/Discord-Join%20chat-7289da?style=flat-square&logo=discord)](https://discord.gg/qRRvcGa7Wb)\n\n[![smithery badge](https://smithery.ai/badge/piapi-mcp-server)](https://smithery.ai/server/piapi-mcp-server)\n\nA TypeScript implementation of a Model Context Protocol (MCP) server that integrates with PiAPI's API. PiAPI makes user able to generate media content with Midjourney/Flux/Kling/LumaLabs/Udio/Chrip/Trellis directly from Claude or any other MCP-compatible apps.\n\n<a href=\"https://glama.ai/mcp/servers/ywvke8xruo\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/ywvke8xruo/badge\" alt=\"PiAPI-Server MCP server\" /></a>\n\n## Features (more coming soon)\n\nNote: Time-consuming tools like video generation may not complete due to Claude's timeout limitations\n\n- [x] Base Image toolkit\n- [x] Base Video toolkit\n- [x] Flux Image generation from text/image prompt\n- [x] Hunyuan Video generation from text/image prompt\n- [x] Skyreels Video generation from image prompt\n- [x] Wan Video generation from text/image prompt\n- [x] MMAudio Music generation from video\n- [x] TTS Zero-Shot voice generation\n- [ ] Midjourney Image generation\n  - [x] imagine\n  - [ ] other\n- [x] Kling Video and Effects generation\n- [x] Luma Dream Machine video generation\n- [x] Suno Music generation\n- [ ] Suno Lyrics generation\n- [ ] Udio Music and Lyrics generation\n- [x] Trellis 3D model generation from image\n- [ ] Workflow planning inside LLMs\n\n## Working with Claude Desktop Example\n\n![image](./assets/Claude-desktop.png)\n\n## Prerequisites\n\n- Node.js 16.x or higher\n- npm or yarn\n- A PiAPI API key (get one at [piapi.ai](https://piapi.ai/workspace/key))\n\n## Installation\n\n### Installing via Smithery\n\nTo install PiAPI MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/piapi-mcp-server):\n\n```bash\nnpx -y @smithery/cli install piapi-mcp-server --client claude\n```\n\n### Manual Installation\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/apinetwork/piapi-mcp-server\ncd piapi-mcp-server\n```\n\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Build the project:\n\n```bash\nnpm run build\n```\n\nAfter building, a `dist/index.js` file will be generated. You can then configure this file with Claude Desktop and other applications. For detailed configuration instructions, please refer to the Usage section.\n\n4. (Optional) Test server with MCP Inspector:\n\nFirst, create a `.env` file in the project root directory with your API key:\n\n```bash\nPIAPI_API_KEY=your_api_key_here\n```\n\nThen run the following command to start the MCP Inspector:\n\n```bash\nnpm run inspect\n```\n\nAfter running the command, MCP Inspector will be available at http://localhost:5173 (default port: 5173). Open this URL in your browser to start testing. The default timeout for inspector operations is 10000ms (10 seconds), which may not be sufficient for image generation tasks. It's recommended to increase the timeout when testing image generation or other time-consuming operations. You can adjust the timeout by adding a timeout parameter to the URL, for example: http://localhost:5173?timeout=60000 (sets timeout to 60 seconds)\n\nThe MCP Inspector is a powerful development tool that helps you test and debug your MCP server implementation. Key features include:\n\n- **Interactive Testing**: Test your server's functions directly through a web interface\n- **Real-time Feedback**: See immediate results of your function calls and any errors that occur\n- **Request/Response Inspection**: View detailed information about requests and responses\n- **Function Documentation**: Browse available functions and their parameters\n- **Custom Parameters**: Set custom timeout values and other configuration options\n- **History Tracking**: Keep track of your previous function calls and their results\n\nFor detailed information about using the MCP Inspector and its features, visit the [official MCP documentation](https://modelcontextprotocol.io/docs/tools/inspector).\n\n## Usage\n\n### Connecting to Claude Desktop\n\nAdd this to your Claude Desktop configuration file (`~/Library/Application Support/Claude/claude_desktop_config.json` on macOS or `%APPDATA%\\Claude\\claude_desktop_config.json` on Windows):\n\n```json\n{\n  \"mcpServers\": {\n    \"piapi\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/piapi-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"PIAPI_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\nAfter updating your configuration file, you need to restart Claude for Desktop. Upon restarting, you should see a hammer icon in the bottom right corner of the input box.\nFor more detailed information, visit the [official MCP documentation](https://modelcontextprotocol.io/quickstart/user)\n\n### Connecting to Cursor\n\nNote: Following guide is based on Cursor 0.47.5. Features and behaviors may vary in different versions.\n\nTo configure the MCP server:\n\n1. Navigate to: File > Preferences > Cursor Settings, or use the shortcut key `Ctrl+Shift+J`\n2. Select \"MCP\" tab on the left panel\n3. Click \"Add new global MCP server\" button in the top right\n4. Add your configuration in the opened mcp.json file\n\n```json\n{\n  \"mcpServers\": {\n    \"piapi\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/piapi-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"PIAPI_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n5. After configuration, you'll see a \"piapi\" entry in MCP Servers page\n6. Click the Refresh button on the entry or restart Cursor to connect to the piapi server\n\nTo test the piapi image generation:\n\n1. Open and select \"Agent mode\" in Cursor Chat, or use the shortcut key `Ctrl+I`\n2. Enter a test prompt, for example: \"generate image of a dog\"\n3. The image will be generated based on your prompt using piapi server\n\nTo disable the piapi server:\n\n1. Navigate to the MCP Servers page in Cursor Settings\n2. Find the \"piapi\" entry in the server list\n3. Click the \"Enabled\" toggle button to switch it to \"Disabled\"\n\n## Development\n\n### Project Structure\n\n```\npiapi-mcp-server/\nâ”œâ”€â”€ assets/\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ index.ts        # Main server entry point\nâ”œâ”€â”€ package.json\nâ”œâ”€â”€ tsconfig.json\nâ””â”€â”€ .env.example\n```\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "attarmau--StyleCLIP": {
      "owner": "attarmau",
      "name": "StyleCLIP",
      "url": "https://github.com/attarmau/StyleCLIP",
      "imageUrl": "https://github.com/attarmau.png",
      "description": "A CLIP-based fashion recommendation system that enables users to upload clothing images and receive similar clothing tag recommendations through an interactive web interface. It utilizes YOLO for clothing detection and integrates seamlessly with an MCP framework.",
      "stars": 0,
      "forks": 3,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-19T08:44:33Z",
      "readme_content": "# FastMCP_RecSys\nThis is a CLIP-Based Fashion Recommender with MCP. \n\n### ğŸ“Œ Sample Components for UI\n1. Image upload\n2. Submit button\n3. Display clothing tags + recommendations\n\n# Mockup\nA user uploads a clothing image â†’ YOLO detects clothing â†’ CLIP encodes â†’ Recommend similar\n\n<img width=\"463\" alt=\"Screenshot 2025-04-26 at 10 26 13â€¯AM\" src=\"https://github.com/user-attachments/assets/93c0a75b-4ed1-4fa1-b25d-5137b8eb6af0\" />\n\n\n# Folder Structure\n```\n/project-root\nâ”‚\nâ”œâ”€â”€ /backend\nâ”‚   â”œâ”€â”€ Dockerfile            \nâ”‚   â”œâ”€â”€ /app\nâ”‚   â”œâ”€â”€ /aws\nâ”‚   â”‚   â”‚   â””â”€â”€ rekognition_wrapper.py         # AWS Rekognition logic\nâ”‚   â”‚   â”œâ”€â”€ /utils\nâ”‚   â”‚   â”‚   â””â”€â”€ image_utils.py                 # Bounding box crop utils\nâ”‚   â”‚   â”œâ”€â”€ /controllers\nâ”‚   â”‚   â”‚   â””â”€â”€ clothing_detector.py           # Coordinates Rekognition + cropping\nâ”‚   â”‚   â”œâ”€â”€ /tests\nâ”‚   â”‚   â”‚   â”œâ”€â”€ test_rekognition_wrapper.py\nâ”‚   â”‚   â”‚   â””â”€â”€ test_clothing_tagging.py\nâ”‚   â”‚   â”œâ”€â”€ server.py                    # FastAPI app code\nâ”‚   â”‚   â”œâ”€â”€ /routes\nâ”‚   â”‚   â”‚   â””â”€â”€ clothing_routes.py\nâ”‚   â”‚   â”œâ”€â”€ /controllers\nâ”‚   â”‚   â”‚   â”œâ”€â”€ clothing_controller.py\nâ”‚   â”‚   â”‚   â”œâ”€â”€ clothing_tagging.py\nâ”‚   â”‚   â”‚   â””â”€â”€ tag_extractor.py         # Pending: define core CLIP functionality\nâ”‚   â”‚   â”œâ”€â”€ schemas/\nâ”‚   â”‚   â”‚   â””â”€â”€ clothing_schemas.py\nâ”‚   â”‚   â”œâ”€â”€ config/\nâ”‚   â”‚   â”‚   â”œâ”€â”€ tag_list_en.py           $ Tool for mapping: https://jsoncrack.com/editor\nâ”‚   â”‚   â”‚   â”œâ”€â”€ database.py       \nâ”‚   â”‚   â”‚   â”œâ”€â”€ settings.py       \nâ”‚   â”‚   â”‚   â””â”€â”€ api_keys.py     \nâ”‚   â”‚   â””â”€â”€ requirements.txt      \nâ”‚   â””â”€â”€ .env                      \nâ”‚                      \nâ”œâ”€â”€ /frontend \nâ”‚   â”œâ”€â”€ Dockerfile        \nâ”‚   â”œâ”€â”€ package.json              \nâ”‚   â”œâ”€â”€ package-lock.json         \nâ”‚   â”œâ”€â”€ /public\nâ”‚   â”‚   â””â”€â”€ index.html            \nâ”‚   â”œâ”€â”€ /src\nâ”‚   â”‚   â”œâ”€â”€ /components            \nâ”‚   â”‚   â”‚   â”œâ”€â”€ ImageUpload.jsx    \nâ”‚   â”‚   â”‚   â”œâ”€â”€ DetectedTags.jsx   \nâ”‚   â”‚   â”‚   â””â”€â”€ Recommendations.jsx \nâ”‚   â”‚   â”œâ”€â”€ /utils\nâ”‚   â”‚   â”‚   â””â”€â”€ api.js             \nâ”‚   â”‚   â”œâ”€â”€ App.js                    # Main React component\nâ”‚   â”‚   â”œâ”€â”€ index.js\nâ”‚   â”‚   â”œâ”€â”€ index.css            \nâ”‚   â”‚   â”œâ”€â”€ tailwind.config.js        \nâ”‚   â”‚   â””â”€â”€ postcss.config.js                    \nâ”‚   â””â”€â”€ .env                                \nâ”œâ”€â”€ docker-compose.yml                     \nâ””â”€â”€ README.md \n```\n\n## Quick Start Guide\n### Step 1: Clone the GitHub Project\n### Step 2: Set Up the Python Environment\n```\npython -m venv venv\nsource venv/bin/activate  # On macOS or Linux\nvenv\\Scripts\\activate     # On Windows\n```\n### Step 3: Install Dependencies\n```\npip install -r requirements.txt\n```\n### Step 4: Start the FastAPI Server (Backend)\n```\nuvicorn backend.app.server:app --reload\n```\nOnce the server is running and the database is connected, you should see the following message in the console:\n```\nDatabase connected\nINFO:     Application startup complete.\n```\n<img width=\"750\" alt=\"Screenshot 2025-04-25 at 1 15 45â€¯AM\" src=\"https://github.com/user-attachments/assets/7f3fc403-fb33-4107-a00c-61796a48ecec\" />\n\n### Step 5: Install Dependencies\nDatabase connected\nINFO:     Application startup complete.\n```\nnpm install\n```\n### Step 6: Start the Development Server (Frontend)\n```\nnpm start\n```\nOnce running, the server logs a confirmation and opens the app in your browser: [http://localhost:3000/](http://localhost:3000/)\n\n<img width=\"372\" alt=\"Screenshot 2025-04-25 at 9 08 50â€¯PM\" src=\"https://github.com/user-attachments/assets/794a6dba-9fbb-40f1-9e57-c5c2e2af1013\" />\n\n# Whatâ€™s completed so far:\n1. FastAPI server is up and running (24 Apr)\n2. Database connection is set up (24 Apr)\n3. Backend architecture is functional (24 Apr)\n4. Basic front-end UI for uploading picture (25 Apr)\n## 5. Mock Testing for AWS Rekognition -> bounding box (15 May)\n```\nPYTHONPATH=. pytest backend/app/tests/test_rekognition_wrapper.py\n```\n<img width=\"1067\" alt=\"Screenshot 2025-05-20 at 4 58 14â€¯PM\" src=\"https://github.com/user-attachments/assets/7a25a92d-2aca-42a8-abdd-194dd9d2e8a5\" />\n\n- Tested Rekognition integration logic independently using a mock â†’ verified it correctly extracts bounding boxes only when labels match the garment set\n- Confirmed the folder structure and PYTHONPATH=. works smoothly with pytest from root\n\n## 6. Mock Testing for AWS Rekognition -> CLIP (20 May)\n```\nPYTHONPATH=. pytest backend/app/tests/test_clothing_tagging.py\n```\n<img width=\"1062\" alt=\"Screenshot 2025-05-21 at 9 25 33â€¯AM\" src=\"https://github.com/user-attachments/assets/6c64b658-3414-4115-9e20-520132605cab\" />\n\n- Detecting garments using AWS Rekognition \n\n- Cropping the image around detected bounding boxes\n\n- Tagging the cropped image using CLIP\n\n## 7. Mock Testing for full image tagging pipeline (Image bytes â†’ AWS Rekognition (detect garments) â†’ Crop images â†’ CLIP (predict tags) + Error Handling (25 May)\n| **Negative Test Case**         | **Description**                                                                 |\n| -------------------------------| ------------------------------------------------------------------------------- |\n| No Detection Result            | AWS doesn't detect any garments â€” should return an empty list.                  |\n| Image Not Clothing             | CLIP returns vague or empty tags â€” verify fallback behavior.                    |\n| AWS Returns Exception          | Simulate `rekognition.detect_labels` throwing an error â€” check `try-except`.    |\n| Corrupted Image File           | Simulate a broken (non-JPEG) image â€” verify it raises an error or gives a hint. |\n\n```\nPYTHONPATH=. pytest backend/app/tests/test_clothing_tagging.py\n```\n<img width=\"1072\" alt=\"Screenshot 2025-05-21 at 11 19 47â€¯AM\" src=\"https://github.com/user-attachments/assets/b41f07f4-7926-44a3-8b64-34fe3c6ef049\" />\n\n- detect_garments: simulates AWS Rekognition returning one bounding box: {\"Left\": 0.1, \"Top\": 0.1, \"Width\": 0.5, \"Height\": 0.5}\n- crop_by_bounding_box: simulates the cropping step returning a dummy \"cropped_image\" object\n- get_tags_from_clip: simulates CLIP returning a list of tags: [\"T-shirt\", \"Cotton\", \"Casual\"]\n\n## 8. Run Testing for CLIP Output (30 May)\n```\npython3 -m venv venv\npip install -r requirements.txt\npip install git+https://github.com/openai/CLIP.git\npython -m backend.app.tests.test_tag_extractor\n```\n<img width=\"1111\" alt=\"Screenshot 2025-06-06 at 5 12 13â€¯PM\" src=\"https://github.com/user-attachments/assets/d0b3b288-20f8-482f-9d39-dcccf9a775ee\" />\n\nNext Step:\n1. Evaluate CLIPâ€™s tagging accuracy on sample clothing images\n2. Fine-tune the tagging system for better recommendations\n3. Test the backend integration with real-time user data\n4. Set up monitoring for model performance\n5. Front-end demo\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "awkoy--replicate-flux-mcp": {
      "owner": "awkoy",
      "name": "replicate-flux-mcp",
      "url": "https://github.com/awkoy/replicate-flux-mcp",
      "imageUrl": "https://github.com/awkoy.png",
      "description": "Generate images from text prompts using advanced AI models. Customize parameters for tailored outputs with secure and local processing.",
      "stars": 50,
      "forks": 11,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-14T19:36:15Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/awkoy-replicate-flux-mcp-badge.png)](https://mseep.ai/app/awkoy-replicate-flux-mcp)\n\n# Replicate Flux MCP\n\n![MCP Compatible](https://img.shields.io/badge/MCP-Compatible-blue)\n![License](https://img.shields.io/badge/license-MIT-green)\n![TypeScript](https://img.shields.io/badge/TypeScript-4.9+-blue)\n![Model Context Protocol](https://img.shields.io/badge/MCP-Enabled-purple)\n[![smithery badge](https://smithery.ai/badge/@awkoy/replicate-flux-mcp)](https://smithery.ai/server/@awkoy/replicate-flux-mcp)\n![NPM Downloads](https://img.shields.io/npm/dw/replicate-flux-mcp)\n![Stars](https://img.shields.io/github/stars/awkoy/replicate-flux-mcp)\n\n<a href=\"https://glama.ai/mcp/servers/ss8n1knen8\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/ss8n1knen8/badge\" />\n</a>\n\n**Replicate Flux MCP** is an advanced Model Context Protocol (MCP) server that empowers AI assistants to generate high-quality images and vector graphics. Leveraging [Black Forest Labs' Flux Schnell model](https://replicate.com/black-forest-labs/flux-schnell) for raster images and [Recraft's V3 SVG model](https://replicate.com/recraft-ai/recraft-v3-svg) for vector graphics via the Replicate API.\n\n## ğŸ“‘ Table of Contents\n\n- [Getting Started & Integration](#-getting-started--integration)\n  - [Setup Process](#setup-process)\n  - [Cursor Integration](#cursor-integration)\n  - [Claude Desktop Integration](#claude-desktop-integration)\n  - [Smithery Integration](#smithery-integration)\n  - [Glama.ai Integration](#glamaai-integration)\n- [Features](#-features)\n- [Documentation](#-documentation)\n  - [Available Tools](#available-tools)\n  - [Available Resources](#available-resources)\n- [Development](#-development)\n- [Technical Details](#-technical-details)\n- [Troubleshooting](#-troubleshooting)\n- [Contributing](#-contributing)\n- [License](#-license)\n- [Resources](#-resources)\n- [Examples](#-examples)\n\n## ğŸš€ Getting Started & Integration\n\n### Setup Process\n\n1. **Obtain a Replicate API Token**\n   - Sign up at [Replicate](https://replicate.com/)\n   - Create an API token in your account settings\n\n2. **Choose Your Integration Method**\n   - Follow one of the integration options below based on your preferred MCP client\n\n3. **Ask Your AI Assistant to Generate an Image**\n   - Simply ask naturally: \"Can you generate an image of a serene mountain landscape at sunset?\"\n   - Or be more specific: \"Please create an image showing a peaceful mountain scene with a lake reflecting the sunset colors in the foreground\"\n\n4. **Explore Advanced Features**\n   - Try different parameter settings for customized results\n   - Experiment with SVG generation using `generate_svg`\n   - Use batch image generation or variant generation features\n\n### Cursor Integration\n\n#### Method 1: Using mcp.json\n\n1. Create or edit the `.cursor/mcp.json` file in your project directory:\n\n```json\n{\n  \"mcpServers\": {\n    \"replicate-flux-mcp\": {\n      \"command\": \"env REPLICATE_API_TOKEN=YOUR_TOKEN npx\",\n      \"args\": [\"-y\", \"replicate-flux-mcp\"]\n    }\n  }\n}\n```\n\n2. Replace `YOUR_TOKEN` with your actual Replicate API token\n3. Restart Cursor to apply the changes\n\n#### Method 2: Manual Mode\n\n1. Open Cursor and go to Settings\n2. Navigate to the \"MCP\" or \"Model Context Protocol\" section\n3. Click \"Add Server\" or equivalent\n4. Enter the following command in the appropriate field:\n\n```\nenv REPLICATE_API_TOKEN=YOUR_TOKEN npx -y replicate-flux-mcp\n```\n\n5. Replace `YOUR_TOKEN` with your actual Replicate API token\n6. Save the settings and restart Cursor if necessary\n\n### Claude Desktop Integration\n\n1. Create or edit the `mcp.json` file in your configuration directory:\n\n```json\n{\n  \"mcpServers\": {\n    \"replicate-flux-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"replicate-flux-mcp\"],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"YOUR TOKEN\"\n      }\n    }\n  }\n}\n```\n\n2. Replace `YOUR_TOKEN` with your actual Replicate API token\n3. Restart Claude Desktop to apply the changes\n\n### Smithery Integration\n\nThis MCP server is available as a hosted service on Smithery, allowing you to use it without setting up your own server.\n\n1. Visit [Smithery](https://smithery.ai/) and create an account if you don't have one\n2. Navigate to the [Replicate Flux MCP server page](https://smithery.ai/server/@awkoy/replicate-flux-mcp)\n3. Click \"Add to Workspace\" to add the server to your Smithery workspace\n4. Configure your MCP client (Cursor, Claude Desktop, etc.) to use your Smithery workspace URL\n\nFor more information on using Smithery with your MCP clients, visit the [Smithery documentation](https://smithery.ai/docs).\n\n### Glama.ai Integration\n\nThis MCP server is also available as a hosted service on Glama.ai, providing another option to use it without local setup.\n\n1. Visit [Glama.ai](https://glama.ai/) and create an account if you don't have one\n2. Go to the [Replicate Flux MCP server page](https://glama.ai/mcp/servers/ss8n1knen8)\n3. Click \"Install Server\" to add the server to your workspace\n4. Configure your MCP client to use your Glama.ai workspace\n\nFor more information, visit the [Glama.ai MCP servers documentation](https://glama.ai/mcp/servers).\n\n## ğŸŒŸ Features\n\n- **ğŸ–¼ï¸ High-Quality Image Generation** - Create stunning images using Flux Schnell, a state-of-the-art AI model\n- **ğŸ¨ Vector Graphics Support** - Generate professional SVG vector graphics with Recraft V3 SVG model\n- **ğŸ¤– AI Assistant Integration** - Seamlessly enable AI assistants like Claude to generate visual content\n- **ğŸ›ï¸ Advanced Customization** - Fine-tune generation with controls for aspect ratio, quality, resolution, and more\n- **ğŸ”Œ Universal MCP Compatibility** - Works with all MCP clients including Cursor, Claude Desktop, Cline, and Zed\n- **ğŸ”’ Secure Local Processing** - All requests are processed locally for enhanced privacy and security\n- **ğŸ” Comprehensive History Management** - Track, view, and retrieve your complete generation history\n- **ğŸ“Š Batch Processing** - Generate multiple images from different prompts in a single request\n- **ğŸ”„ Variant Exploration** - Create and compare multiple interpretations of the same concept\n- **âœï¸ Prompt Engineering** - Fine-tune image variations with specialized prompt modifications\n\n## ğŸ“š Documentation\n\n### Available Tools\n\n#### `generate_image`\n\nGenerates an image based on a text prompt using the Flux Schnell model.\n\n```typescript\n{\n  prompt: string;                // Required: Text description of the image to generate\n  seed?: number;                 // Optional: Random seed for reproducible generation\n  go_fast?: boolean;             // Optional: Run faster predictions with optimized model (default: true)\n  megapixels?: \"1\" | \"0.25\";     // Optional: Image resolution (default: \"1\")\n  num_outputs?: number;          // Optional: Number of images to generate (1-4) (default: 1)\n  aspect_ratio?: string;         // Optional: Aspect ratio (e.g., \"16:9\", \"4:3\") (default: \"1:1\")\n  output_format?: string;        // Optional: Output format (\"webp\", \"jpg\", \"png\") (default: \"webp\")\n  output_quality?: number;       // Optional: Image quality (0-100) (default: 80)\n  num_inference_steps?: number;  // Optional: Number of denoising steps (1-4) (default: 4)\n  disable_safety_checker?: boolean; // Optional: Disable safety filter (default: false)\n}\n```\n\n#### `generate_multiple_images`\n\nGenerates multiple images based on an array of prompts using the Flux Schnell model.\n\n```typescript\n{\n  prompts: string[];             // Required: Array of text descriptions for images to generate (1-10 prompts)\n  seed?: number;                 // Optional: Random seed for reproducible generation\n  go_fast?: boolean;             // Optional: Run faster predictions with optimized model (default: true)\n  megapixels?: \"1\" | \"0.25\";     // Optional: Image resolution (default: \"1\")\n  aspect_ratio?: string;         // Optional: Aspect ratio (e.g., \"16:9\", \"4:3\") (default: \"1:1\")\n  output_format?: string;        // Optional: Output format (\"webp\", \"jpg\", \"png\") (default: \"webp\")\n  output_quality?: number;       // Optional: Image quality (0-100) (default: 80)\n  num_inference_steps?: number;  // Optional: Number of denoising steps (1-4) (default: 4)\n  disable_safety_checker?: boolean; // Optional: Disable safety filter (default: false)\n}\n```\n\n#### `generate_image_variants`\n\nGenerates multiple variants of the same image from a single prompt.\n\n```typescript\n{\n  prompt: string;                // Required: Text description for the image to generate variants of\n  num_variants: number;          // Required: Number of image variants to generate (2-10, default: 4)\n  prompt_variations?: string[];  // Optional: List of prompt modifiers to apply to variants (e.g., [\"in watercolor style\", \"in oil painting style\"])\n  variation_mode?: \"append\" | \"replace\"; // Optional: How to apply variations - 'append' adds to base prompt, 'replace' uses variations directly (default: \"append\")\n  seed?: number;                 // Optional: Base random seed. Each variant will use seed+variant_index\n  go_fast?: boolean;             // Optional: Run faster predictions with optimized model (default: true)\n  megapixels?: \"1\" | \"0.25\";     // Optional: Image resolution (default: \"1\")\n  aspect_ratio?: string;         // Optional: Aspect ratio (e.g., \"16:9\", \"4:3\") (default: \"1:1\")\n  output_format?: string;        // Optional: Output format (\"webp\", \"jpg\", \"png\") (default: \"webp\")\n  output_quality?: number;       // Optional: Image quality (0-100) (default: 80)\n  num_inference_steps?: number;  // Optional: Number of denoising steps (1-4) (default: 4)\n  disable_safety_checker?: boolean; // Optional: Disable safety filter (default: false)\n}\n```\n\n#### `generate_svg`\n\nGenerates an SVG vector image based on a text prompt using the Recraft V3 SVG model.\n\n```typescript\n{\n  prompt: string;                // Required: Text description of the SVG to generate\n  size?: string;                 // Optional: Size of the generated SVG (default: \"1024x1024\")\n  style?: string;                // Optional: Style of the generated image (default: \"any\")\n                                // Options: \"any\", \"engraving\", \"line_art\", \"line_circuit\", \"linocut\"\n}\n```\n\n#### `prediction_list`\n\nRetrieves a list of your recent predictions from Replicate.\n\n```typescript\n{\n  limit?: number;  // Optional: Maximum number of predictions to return (1-100) (default: 50)\n}\n```\n\n#### `get_prediction`\n\nGets detailed information about a specific prediction.\n\n```typescript\n{\n  predictionId: string;  // Required: ID of the prediction to retrieve\n}\n```\n\n### Available Resources\n\n#### `imagelist`\n\nBrowse your history of generated images created with the Flux Schnell model.\n\n#### `svglist`\n\nBrowse your history of generated SVG images created with the Recraft V3 SVG model.\n\n#### `predictionlist`\n\nBrowse all your Replicate predictions history.\n\n## ğŸ’» Development\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/awkoy/replicate-flux-mcp.git\ncd replicate-flux-mcp\n```\n\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Start development mode:\n\n```bash\nnpm run dev\n```\n\n4. Build the project:\n\n```bash\nnpm run build\n```\n\n5. Connect to Client:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-generation-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"/Users/{USERNAME}/{PATH_TO}/replicate-flux-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"YOUR REPLICATE API TOKEN\"\n      }\n    }\n  }\n}\n```\n\n## âš™ï¸ Technical Details\n\n### Stack\n\n- **Model Context Protocol SDK** - Core MCP functionality for tool and resource management\n- **Replicate API** - Provides access to state-of-the-art AI image generation models\n- **TypeScript** - Ensures type safety and leverages modern JavaScript features\n- **Zod** - Implements runtime type validation for robust API interactions\n\n### Configuration\n\nThe server can be configured by modifying the `CONFIG` object in `src/config/index.ts`:\n\n```javascript\nconst CONFIG = {\n  serverName: \"replicate-flux-mcp\",\n  serverVersion: \"0.1.2\",\n  imageModelId: \"black-forest-labs/flux-schnell\",\n  svgModelId: \"recraft-ai/recraft-v3-svg\",\n  pollingAttempts: 25,\n  pollingInterval: 2000, // ms\n};\n```\n\n## ğŸ” Troubleshooting\n\n### Common Issues\n\n#### Authentication Error\n- Ensure your `REPLICATE_API_TOKEN` is correctly set in the environment\n- Verify your token is valid by testing it with the Replicate API directly\n\n#### Safety Filter Triggered\n- The model has a built-in safety filter that may block certain prompts\n- Try modifying your prompt to avoid potentially problematic content\n\n#### Timeout Error\n- For larger images or busy servers, you might need to increase `pollingAttempts` or `pollingInterval` in the configuration\n- Default settings should work for most use cases\n\n## ğŸ¤ Contributing\n\nContributions are welcome! Please follow these steps to contribute:\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\nFor feature requests or bug reports, please create a GitHub issue. If you like this project, consider starring the repository!\n\n## ğŸ“„ License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## ğŸ”— Resources\n\n- [Model Context Protocol Documentation](https://modelcontextprotocol.io)\n- [Replicate API Documentation](https://replicate.com/docs)\n- [Flux Schnell Model](https://replicate.com/black-forest-labs/flux-schnell)\n- [Recraft V3 SVG Model](https://replicate.com/recraft-ai/recraft-v3-svg)\n- [MCP TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)\n- [Smithery Documentation](https://smithery.ai/docs)\n- [Glama.ai MCP Servers](https://glama.ai/mcp/servers)\n\n## ğŸ¨ Examples\n\n![Demo](https://github.com/user-attachments/assets/ad6db606-ae3a-48db-a1cc-e1f88847769e)\n\n| Multiple Prompts | Prompt Variants |\n|-----------------|-----------------|\n| ![Multiple prompts example: \"A serene mountain lake at sunset\", \"A bustling city street at night\", \"A peaceful garden in spring\"](https://github.com/user-attachments/assets/e5ac56d2-bfbb-4f33-938c-a3d7bffeee60) | ![Variants example: Base prompt \"A majestic castle\" with modifiers \"in watercolor style\", \"as an oil painting\", \"with gothic architecture\"](https://github.com/user-attachments/assets/8ebe5992-4803-4bf3-a82a-251135b0698a) |\n\nHere are some examples of how to use the tools:\n\n### Batch Image Generation with `generate_multiple_images`\n\nCreate multiple distinct images at once with different prompts:\n\n```json\n{\n  \"prompts\": [\n    \"A red sports car on a mountain road\", \n    \"A blue sports car on a beach\", \n    \"A vintage sports car in a city street\"\n  ]\n}\n```\n\n### Image Variants with `generate_image_variants`\n\nCreate different interpretations of the same concept using seeds:\n\n```json\n{\n  \"prompt\": \"A futuristic city skyline at night\",\n  \"num_variants\": 4,\n  \"seed\": 42\n}\n```\n\nOr explore style variations with prompt modifiers:\n\n```json\n{\n  \"prompt\": \"A character portrait\",\n  \"prompt_variations\": [\n    \"in anime style\", \n    \"in watercolor style\", \n    \"in oil painting style\", \n    \"as a 3D render\"\n  ]\n}\n```\n\n---\n\nMade with â¤ï¸ by Yaroslav Boiko\n\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "awslabs--mcp": {
      "owner": "awslabs",
      "name": "mcp",
      "url": "https://github.com/awslabs/mcp",
      "imageUrl": "https://github.com/awslabs.png",
      "description": "Generates images from text prompts and specific color palettes, utilizing customizable options for dimensions and quality. Supports both text-based and color-guided image generation, allowing for multiple images in a single request.",
      "stars": 6585,
      "forks": 942,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-04T06:19:32Z",
      "readme_content": "# AWS MCP Servers\n\nA suite of specialized MCP servers that help you get the most out of AWS, wherever you use MCP.\n\n[![GitHub](https://img.shields.io/badge/github-awslabs/mcp-blue.svg?style=flat&logo=github)](https://github.com/awslabs/mcp)\n[![License](https://img.shields.io/badge/license-Apache--2.0-brightgreen)](LICENSE)\n[![Codecov](https://img.shields.io/codecov/c/github/awslabs/mcp)](https://app.codecov.io/gh/awslabs/mcp)\n[![OSSF-Scorecard Score](https://img.shields.io/ossf-scorecard/github.com/awslabs/mcp)](https://scorecard.dev/viewer/?uri=github.com/awslabs/mcp)\n\n## Table of Contents\n\n- [AWS MCP Servers](#aws-mcp-servers)\n  - [Table of Contents](#table-of-contents)\n  - [What is the Model Context Protocol (MCP) and how does it work with AWS MCP Servers?](#what-is-the-model-context-protocol-mcp-and-how-does-it-work-with-aws-mcp-servers)\n  - [Server Sent Events Support Removal](#server-sent-events-support-removal)\n  - [Why AWS MCP Servers?](#why-aws-mcp-servers)\n  - [Available MCP Servers: Quick Installation](#available-mcp-servers-quick-installation)\n    - [ğŸš€Getting Started with AWS](#-getting-started-with-aws)\n    - [Browse by What You're Building](#browse-by-what-youre-building)\n      - [ğŸ“š Real-time access to official AWS documentation](#-real-time-access-to-official-aws-documentation)\n      - [ğŸ—ï¸ Infrastructure \\& Deployment](#ï¸-infrastructure--deployment)\n        - [Infrastructure as Code](#infrastructure-as-code)\n        - [Container Platforms](#container-platforms)\n        - [Serverless \\& Functions](#serverless--functions)\n        - [Support](#support)\n      - [ğŸ¤– AI \\& Machine Learning](#-ai--machine-learning)\n      - [ğŸ“Š Data \\& Analytics](#-data--analytics)\n        - [SQL \\& NoSQL Databases](#sql--nosql-databases)\n        - [Search \\& Analytics](#search--analytics)\n        - [Caching \\& Performance](#caching--performance)\n      - [ğŸ› ï¸ Developer Tools \\& Support](#ï¸-developer-tools--support)\n      - [ğŸ“¡ Integration \\& Messaging](#-integration--messaging)\n      - [ğŸ’° Cost \\& Operations](#-cost--operations)\n      - [ğŸ§¬ Healthcare \\& Lifesciences](#-healthcare--lifesciences)\n    - [Browse by How You're Working](#browse-by-how-youre-working)\n      - [ğŸ‘¨â€ğŸ’» Vibe Coding \\& Development](#-vibe-coding--development)\n        - [Core Development Workflow](#core-development-workflow)\n        - [Infrastructure as Code](#infrastructure-as-code-1)\n        - [Application Development](#application-development)\n        - [Container \\& Serverless Development](#container--serverless-development)\n        - [Testing \\& Data](#testing--data)\n        - [Lifesciences Workflow Development](#lifesciences-workflow-development)\n      - [ğŸ’¬ Conversational Assistants](#-conversational-assistants)\n        - [Knowledge \\& Search](#knowledge--search)\n        - [Content Processing \\& Generation](#content-processing--generation)\n        - [Business Services](#business-services)\n      - [ğŸ¤– Autonomous Background Agents](#-autonomous-background-agents)\n        - [Data Operations \\& ETL](#data-operations--etl)\n        - [Caching \\& Performance](#caching--performance-1)\n        - [Workflow \\& Integration](#workflow--integration)\n        - [Operations \\& Monitoring](#operations--monitoring)\n  - [MCP AWS Lambda Handler Module](#mcp-aws-lambda-handler-module)\n  - [When to use Local vs Remote MCP Servers?](#when-to-use-local-vs-remote-mcp-servers)\n    - [Local MCP Servers](#local-mcp-servers)\n    - [Remote MCP Servers](#remote-mcp-servers)\n  - [Use Cases for the Servers](#use-cases-for-the-servers)\n  - [Installation and Setup](#installation-and-setup)\n    - [Running MCP servers in containers](#running-mcp-servers-in-containers)\n    - [Getting Started with Amazon Q Developer CLI](#getting-started-with-amazon-q-developer-cli)\n      - [`~/.aws/amazonq/mcp.json`](#awsamazonqmcpjson)\n    - [Getting Started with Kiro](#getting-started-with-kiro)\n      - [`kiro_mcp_settings.json`](#kiro_mcp_settingsjson)\n    - [Getting Started with Cline and Amazon Bedrock](#getting-started-with-cline-and-amazon-bedrock)\n      - [`cline_mcp_settings.json`](#cline_mcp_settingsjson)\n    - [Getting Started with Cursor](#getting-started-with-cursor)\n      - [`.cursor/mcp.json`](#cursormcpjson)\n    - [Getting Started with Windsurf](#getting-started-with-windsurf)\n      - [`~/.codeium/windsurf/mcp_config.json`](#codeiumwindsurfmcp_configjson)\n    - [Getting Started with VS Code](#getting-started-with-vs-code)\n      - [`.vscode/mcp.json`](#vscodemcpjson)\n    - [Getting Started with Claude Code](#getting-started-with-claude-code)\n      - [`.mcp.json`](#mcpjson)\n  - [Samples](#samples)\n  - [Vibe coding](#vibe-coding)\n  - [Additional Resources](#additional-resources)\n  - [Security](#security)\n  - [Contributing](#contributing)\n  - [Developer guide](#developer-guide)\n  - [License](#license)\n  - [Disclaimer](#disclaimer)\n\n## What is the Model Context Protocol (MCP) and how does it work with AWS MCP Servers?\n\n> The Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools. Whether you're building an AI-powered IDE, enhancing a chat interface, or creating custom AI workflows, MCP provides a standardized way to connect LLMs with the context they need.\n>\n> &mdash; [Model Context Protocol README](https://github.com/modelcontextprotocol#:~:text=The%20Model%20Context,context%20they%20need.)\n\nAn MCP Server is a lightweight program that exposes specific capabilities through the standardized Model Context Protocol. Host applications (such as chatbots, IDEs, and other AI tools) have MCP clients that maintain 1:1 connections with MCP servers. Common MCP clients include agentic AI coding assistants (like Q Developer, Cline, Cursor, Windsurf) as well as chatbot applications like Claude Desktop, with more clients coming soon. MCP servers can access local data sources and remote services to provide additional context that improves the generated outputs from the models.\n\nAWS MCP Servers use this protocol to provide AI applications access to AWS documentation, contextual guidance, and best practices. Through the standardized MCP client-server architecture, AWS capabilities become an intelligent extension of your development environment or AI application.\n\nAWS MCP servers enable enhanced cloud-native development, infrastructure management, and development workflowsâ€”making AI-assisted cloud computing more accessible and efficient.\n\nThe Model Context Protocol is an open source project run by Anthropic, PBC. and open to contributions from the entire community. For more information on MCP, you can find further documentation [here](https://modelcontextprotocol.io/introduction)\n\n## Server Sent Events Support Removal\n\n**Important Notice:** On May 26th, 2025, Server Sent Events (SSE) support was removed from all MCP servers in their latest major versions. This change aligns with the Model Context Protocol specification's [backwards compatibility guidelines](https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#backwards-compatibility).\n\nWe are actively working towards supporting [Streamable HTTP](https://modelcontextprotocol.io/specification/draft/basic/transports#streamable-http), which will provide improved transport capabilities for future versions.\n\nFor applications still requiring SSE support, please use the previous major version of the respective MCP server until you can migrate to alternative transport methods.\n\n### Why AWS MCP Servers?\n\nMCP servers enhance the capabilities of foundation models (FMs) in several key ways:\n\n- **Improved Output Quality**: By providing relevant information directly in the model's context, MCP servers significantly improve model responses for specialized domains like AWS services. This approach reduces hallucinations, provides more accurate technical details, enables more precise code generation, and ensures recommendations align with current AWS best practices and service capabilities.\n\n- **Access to Latest Documentation**: FMs may not have knowledge of recent releases, APIs, or SDKs. MCP servers bridge this gap by pulling in up-to-date documentation, ensuring your AI assistant always works with the latest AWS capabilities.\n\n- **Workflow Automation**: MCP servers convert common workflows into tools that foundation models can use directly. Whether it's CDK, Terraform, or other AWS-specific workflows, these tools enable AI assistants to perform complex tasks with greater accuracy and efficiency.\n\n- **Specialized Domain Knowledge**: MCP servers provide deep, contextual knowledge about AWS services that might not be fully represented in foundation models' training data, enabling more accurate and helpful responses for cloud development tasks.\n\n## Available MCP Servers: Quick Installation\n\nGet started quickly with one-click installation buttons for popular MCP clients. Click the buttons below to install servers directly in Cursor or VS Code:\n\n### ğŸš€ Getting Started with AWS\n\nFor general AWS interactions and comprehensive API support, we recommend starting with:\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS API MCP Server](src/aws-api-mcp-server) | Start here for general AWS interactions! Comprehensive AWS API support with command validation, security controls, and access to all AWS services. Perfect for managing infrastructure, exploring resources, and executing AWS operations through natural language. | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-api-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWFwaS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D)<br/>[![Install VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20API%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-api-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22type%22%3A%22stdio%22%7D) |\n| [AWS Knowledge MCP Server](src/aws-knowledge-mcp-server) | A remote, fully-managed MCP server hosted by AWS that provides access to the latest AWS docs, API references, What's New Posts, Getting Started information, Builder Center, Blog posts, Architectural references, and Well-Architected guidance. | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-knowledge-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWtub3dsZWRnZS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D)<br/>[![Install VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Knowledge%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-knowledge-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n### Browse by What You're Building\n\n#### ğŸ“š Real-time access to official AWS documentation\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS Knowledge MCP Server](src/aws-knowledge-mcp-server) | A remote, fully-managed MCP server hosted by AWS that provides access to the latest AWS docs, API references, What's New Posts, Getting Started information, Builder Center, Blog posts, Architectural references, and Well-Architected guidance. | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-knowledge-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWtub3dsZWRnZS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D)<br/>[![Install VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Knowledge%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-knowledge-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Documentation MCP Server](src/aws-documentation-mcp-server) | Get latest AWS docs and API references | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-documentation-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWRvY3VtZW50YXRpb24tbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiIsIkFXU19ET0NVTUVOVEFUSU9OX1BBUlRJVElPTiI6ImF3cyJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Documentation%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-documentation-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_DOCUMENTATION_PARTITION%22%3A%22aws%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n\n### ğŸ—ï¸ Infrastructure & Deployment\n\nBuild, deploy, and manage cloud infrastructure with Infrastructure as Code best practices.\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS Cloud Control API MCP Server](src/ccapi-mcp-server) | Direct AWS resource management with security scanning and best practices | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.ccapi-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2NhcGktbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Cloud%20Control%20API%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.ccapi-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS CDK MCP Server](src/cdk-mcp-server) | AWS CDK development with security compliance and best practices | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cdk-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2RrLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CDK%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cdk-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Terraform MCP Server](src/terraform-mcp-server) | Terraform workflows with integrated security scanning | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.terraform-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMudGVycmFmb3JtLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Terraform%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.terraform-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS CloudFormation MCP Server](src/cfn-mcp-server) | Direct CloudFormation resource management via Cloud Control API | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cfn-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2ZuLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1uYW1lZC1wcm9maWxlIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CloudFormation%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cfn-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-named-profile%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n#### Container Platforms\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon EKS MCP Server](src/eks-mcp-server) | Kubernetes cluster management and application deployment | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.eks-mcp-server&config=eyJhdXRvQXBwcm92ZSI6W10sImRpc2FibGVkIjpmYWxzZSwiY29tbWFuZCI6InV2eCBhd3NsYWJzLmVrcy1tY3Atc2VydmVyQGxhdGVzdCAtLWFsbG93LXdyaXRlIC0tYWxsb3ctc2Vuc2l0aXZlLWRhdGEtYWNjZXNzIiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwidHJhbnNwb3J0VHlwZSI6InN0ZGlvIn0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=EKS%20MCP%20Server&config=%7B%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%2C%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.eks-mcp-server%40latest%22%2C%22--allow-write%22%2C%22--allow-sensitive-data-access%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22transportType%22%3A%22stdio%22%7D) |\n| [Amazon ECS MCP Server](src/ecs-mcp-server) | Container orchestration and ECS application deployment | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.ecs-mcp-server&config=eyJjb21tYW5kIjoidXZ4IC0tZnJvbSBhd3NsYWJzLWVjcy1tY3Atc2VydmVyIGVjcy1tY3Atc2VydmVyIiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ5b3VyLWF3cy1yZWdpb24iLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIiwiRkFTVE1DUF9MT0dfRklMRSI6Ii9wYXRoL3RvL2Vjcy1tY3Atc2VydmVyLmxvZyIsIkFMTE9XX1dSSVRFIjoiZmFsc2UiLCJBTExPV19TRU5TSVRJVkVfREFUQSI6ImZhbHNlIn19) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=ECS%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22--from%22%2C%22awslabs-ecs-mcp-server%22%2C%22ecs-mcp-server%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22your-aws-region%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22FASTMCP_LOG_FILE%22%3A%22%2Fpath%2Fto%2Fecs-mcp-server.log%22%2C%22ALLOW_WRITE%22%3A%22false%22%2C%22ALLOW_SENSITIVE_DATA%22%3A%22false%22%7D%7D) |\n| [Finch MCP Server](src/finch-mcp-server) | Local container building with ECR integration | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.finch-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZmluY2gtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJkZWZhdWx0IiwiQVdTX1JFR0lPTiI6InVzLXdlc3QtMiIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiSU5GTyJ9LCJ0cmFuc3BvcnRUeXBlIjoic3RkaW8iLCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Finch%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.finch-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22default%22%2C%22AWS_REGION%22%3A%22us-west-2%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22INFO%22%7D%2C%22transportType%22%3A%22stdio%22%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n\n\n#### Serverless & Functions\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS Serverless MCP Server](src/aws-serverless-mcp-server) | Complete serverless application lifecycle with SAM CLI | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-serverless-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLXNlcnZlcmxlc3MtbWNwLXNlcnZlckBsYXRlc3QgLS1hbGxvdy13cml0ZSAtLWFsbG93LXNlbnNpdGl2ZS1kYXRhLWFjY2VzcyIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Serverless%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-serverless-mcp-server%40latest%22%2C%22--allow-write%22%2C%22--allow-sensitive-data-access%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Lambda Tool MCP Server](src/lambda-tool-mcp-server) | Execute Lambda functions as AI tools for private resource access | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.lambda-tool-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMubGFtYmRhLXRvb2wtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZVTkNUSU9OX1BSRUZJWCI6InlvdXItZnVuY3Rpb24tcHJlZml4IiwiRlVOQ1RJT05fTElTVCI6InlvdXItZmlyc3QtZnVuY3Rpb24sIHlvdXItc2Vjb25kLWZ1bmN0aW9uIiwiRlVOQ1RJT05fVEFHX0tFWSI6InlvdXItdGFnLWtleSIsIkZVTkNUSU9OX1RBR19WQUxVRSI6InlvdXItdGFnLXZhbHVlIiwiRlVOQ1RJT05fSU5QVVRfU0NIRU1BX0FSTl9UQUdfS0VZIjoieW91ci1mdW5jdGlvbi10YWctZm9yLWlucHV0LXNjaGVtYSJ9fQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Lambda%20Tool%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.lambda-tool-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FUNCTION_PREFIX%22%3A%22your-function-prefix%22%2C%22FUNCTION_LIST%22%3A%22your-first-function%2C%20your-second-function%22%2C%22FUNCTION_TAG_KEY%22%3A%22your-tag-key%22%2C%22FUNCTION_TAG_VALUE%22%3A%22your-tag-value%22%2C%22FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY%22%3A%22your-function-tag-for-input-schema%22%7D%7D) |\n\n\n#### Support\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS Support MCP Server](src/aws-support-mcp-server) | Help users create and manage AWS Support cases | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs_support_mcp_server&config=eyJjb21tYW5kIjoidXZ4IC1tIGF3c2xhYnMuYXdzLXN1cHBvcnQtbWNwLXNlcnZlckBsYXRlc3QgLS1kZWJ1ZyAtLWxvZy1maWxlIC4vbG9ncy9tY3Bfc3VwcG9ydF9zZXJ2ZXIubG9nIiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSJ9fQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Support%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22-m%22%2C%22awslabs.aws-support-mcp-server%40latest%22%2C%22--debug%22%2C%22--log-file%22%2C%22.%2Flogs%2Fmcp_support_server.log%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%7D%7D) |\n\n### ğŸ¤– AI & Machine Learning\nEnhance AI applications with knowledge retrieval, content generation, and ML capabilities\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon Bedrock Knowledge Bases Retrieval MCP Server ](src/bedrock-kb-retrieval-mcp-server) | Query enterprise knowledge bases with citation support | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.bedrock-kb-retrieval-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYmVkcm9jay1rYi1yZXRyaWV2YWwtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLXByb2ZpbGUtbmFtZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIiwiS0JfSU5DTFVTSU9OX1RBR19LRVkiOiJvcHRpb25hbC10YWcta2V5LXRvLWZpbHRlci1rYnMiLCJCRURST0NLX0tCX1JFUkFOS0lOR19FTkFCTEVEIjoiZmFsc2UifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Bedrock%20KB%20Retrieval%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.bedrock-kb-retrieval-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-profile-name%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22KB_INCLUSION_TAG_KEY%22%3A%22optional-tag-key-to-filter-kbs%22%2C%22BEDROCK_KB_RERANKING_ENABLED%22%3A%22false%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Kendra Index MCP Server](src/amazon-kendra-index-mcp-server) | Enterprise search and RAG enhancement | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-kendra-index-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLWtlbmRyYS1pbmRleC1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiS0VORF9JTkRFWF9JRCI6InlvdXIta2VuZHJhLWluZGV4LWlkIiwiS0VORF9ST0xFX0FSTiI6InlvdXIta2VuZHJhLXJvbGUtYXJuIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Kendra%20Index%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-kendra-index-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%2C%22KEND_INDEX_ID%22%3A%22your-kendra-index-id%22%2C%22KEND_ROLE_ARN%22%3A%22your-kendra-role-arn%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Q Business MCP Server](src/amazon-qbusiness-anonymous-mcp-server) | AI assistant for your ingested content with anonymous access | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-qbusiness-anonymous-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLXFidXNpbmVzcy1hbm9ueW1vdXMtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiUUJVU0lORVNTX0FQUF9JRCI6InlvdXItcWJ1c2luZXNzLWFwcC1pZCIsIlFCVVNJTkVTU19VU0VSX0lEIjoieW91ci11c2VyLWlkIiwiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Q%20Business%20Anonymous%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-qbusiness-anonymous-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22QBUSINESS_APP_ID%22%3A%22your-qbusiness-app-id%22%2C%22QBUSINESS_USER_ID%22%3A%22your-user-id%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Q Index MCP Server](src/amazon-qindex-mcp-server) | Data accessors to search through enterprise's Q index | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-qindex-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLXFpbmRleC1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiUUlOREVYX0lEIjoieW91ci1xaW5kZXgtaWQiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Q%20Index%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-qindex-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%2C%22QINDEX_ID%22%3A%22your-qindex-id%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Nova Canvas MCP Server](src/nova-canvas-mcp-server) | AI image generation using Amazon Nova Canvas | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.nova-canvas-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMubm92YS1jYW52YXMtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Nova%20Canvas%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.nova-canvas-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Rekognition MCP Server (deprecated)](src/amazon-rekognition-mcp-server) | Analyze images using computer vision capabilities | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-rekognition-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLXJla29nbml0aW9uLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Rekognition%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-rekognition-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Bedrock Data Automation MCP Server](src/aws-bedrock-data-automation-mcp-server) | Analyze documents, images, videos, and audio files | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=bedrock-data-automation-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWJlZHJvY2stZGF0YS1hdXRvbWF0aW9uLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJBV1NfQlVDS0VUX05BTUUiOiJ5b3VyLXMzLWJ1Y2tldC1uYW1lIiwiQkFTRV9ESVIiOiIvcGF0aC90by9iYXNlL2RpcmVjdG9yeSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Bedrock%20Data%20Automation%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-bedrock-data-automation-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22AWS_BUCKET_NAME%22%3A%22your-s3-bucket-name%22%2C%22BASE_DIR%22%3A%22%2Fpath%2Fto%2Fbase%2Fdirectory%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Bedrock Custom Model Import MCP Server](src/aws-bedrock-custom-model-import-mcp-server) | Manage custom models in Bedrock for on-demand inference | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=aws-bedrock-custom-model-import-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWJlZHJvY2stY3VzdG9tLW1vZGVsLWltcG9ydC1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiQkVEUk9DS19NT0RFTF9JTVBPUlRfUzNfQlVDS0VUIjoieW91ci1zMy1idWNrZXQtbmFtZSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Bedrock%20Custom%20Model%20Import%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-bedrock-custom-model-import-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22BEDROCK_MODEL_IMPORT_S3_BUCKET%22%3A%22your-s3-bucket-name%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Bedrock AgentCore MCP Server](src/amazon-bedrock-agentcore-mcp-server) | Provides comprehensive documentation access on AgentCore platform services, APIs, and best practices | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-bedrock-agentcore-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLWJlZHJvY2stYWdlbnRjb3JlLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Bedrock%20AgentCore%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-bedrock-agentcore-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n### ğŸ“Š Data & Analytics\n\nWork with databases, caching systems, and data processing workflows.\n\n#### SQL & NoSQL Databases\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon DynamoDB MCP Server](src/dynamodb-mcp-server) | Complete DynamoDB operations and table management | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.dynamodb-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZHluYW1vZGItbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRERCLU1DUC1SRUFET05MWSI6InRydWUiLCJBV1NfUFJPRklMRSI6ImRlZmF1bHQiLCJBV1NfUkVHSU9OIjoidXMtd2VzdC0yIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=DynamoDB%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.dynamodb-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22DDB-MCP-READONLY%22%3A%22true%22%2C%22AWS_PROFILE%22%3A%22default%22%2C%22AWS_REGION%22%3A%22us-west-2%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Aurora PostgreSQL MCP Server](src/postgres-mcp-server) | PostgreSQL database operations via RDS Data API | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.postgres-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMucG9zdGdyZXMtbWNwLXNlcnZlckBsYXRlc3QgLS1jb25uZWN0aW9uLXN0cmluZyBwb3N0Z3Jlc3FsOi8vW3VzZXJuYW1lXTpbcGFzc3dvcmRdQFtob3N0XTpbcG9ydF0vW2RhdGFiYXNlXSIsImVudiI6eyJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdLCJ0cmFuc3BvcnRUeXBlIjoic3RkaW8iLCJhdXRvU3RhcnQiOnRydWV9) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=PostgreSQL%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.postgres-mcp-server%40latest%22%2C%22--connection-string%22%2C%22postgresql%3A%2F%2F%5Busername%5D%3A%5Bpassword%5D%40%5Bhost%5D%3A%5Bport%5D%2F%5Bdatabase%5D%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%2C%22transportType%22%3A%22stdio%22%2C%22autoStart%22%3Atrue%7D) |\n| [Amazon Aurora MySQL MCP Server](src/mysql-mcp-server) | MySQL database operations via RDS Data API | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.mysql-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMubXlzcWwtbWNwLXNlcnZlckBsYXRlc3QgLS1yZXNvdXJjZV9hcm4gW3lvdXIgZGF0YV0gLS1zZWNyZXRfYXJuIFt5b3VyIGRhdGFdIC0tZGF0YWJhc2UgW3lvdXIgZGF0YV0gLS1yZWdpb24gW3lvdXIgZGF0YV0gLS1yZWFkb25seSBUcnVlIiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=MySQL%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.mysql-mcp-server%40latest%22%2C%22--resource_arn%22%2C%22%5Byour%20data%5D%22%2C%22--secret_arn%22%2C%22%5Byour%20data%5D%22%2C%22--database%22%2C%22%5Byour%20data%5D%22%2C%22--region%22%2C%22%5Byour%20data%5D%22%2C%22--readonly%22%2C%22True%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Aurora DSQL MCP Server](src/aurora-dsql-mcp-server) | Distributed SQL with PostgreSQL compatibility | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aurora-dsql-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXVyb3JhLWRzcWwtbWNwLXNlcnZlckBsYXRlc3QgLS1jbHVzdGVyX2VuZHBvaW50IFt5b3VyIGRzcWwgY2x1c3RlciBlbmRwb2ludF0gLS1yZWdpb24gW3lvdXIgZHNxbCBjbHVzdGVyIHJlZ2lvbiwgZS5nLiB1cy1lYXN0LTFdIC0tZGF0YWJhc2VfdXNlciBbeW91ciBkc3FsIHVzZXJuYW1lXSAtLXByb2ZpbGUgZGVmYXVsdCIsImVudiI6eyJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Aurora%20DSQL%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aurora-dsql-mcp-server%40latest%22%2C%22--cluster_endpoint%22%2C%22%5Byour%20dsql%20cluster%20endpoint%5D%22%2C%22--region%22%2C%22%5Byour%20dsql%20cluster%20region%2C%20e.g.%20us-east-1%5D%22%2C%22--database_user%22%2C%22%5Byour%20dsql%20username%5D%22%2C%22--profile%22%2C%22default%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon DocumentDB MCP Server](src/documentdb-mcp-server) | MongoDB-compatible document database operations | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.documentdb-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZG9jdW1lbnRkYi1tY3Atc2VydmVAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IiLCJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=DocumentDB%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.documentdb-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Neptune MCP Server](src/amazon-neptune-mcp-server) | Graph database queries with openCypher and Gremlin | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-neptune-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLW5lcHR1bmUtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiTkVQVFVORV9FTkRQT0lOVCI6Imh0dHBzOi8veW91ci1uZXB0dW5lLWNsdXN0ZXItaWQucmVnaW9uLm5lcHR1bmUuYW1hem9uYXdzLmNvbTo4MTgyIiwiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Neptune%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-neptune-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22NEPTUNE_ENDPOINT%22%3A%22https%3A%2F%2Fyour-neptune-cluster-id.region.neptune.amazonaws.com%3A8182%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Keyspaces MCP Server](src/amazon-keyspaces-mcp-server) | Apache Cassandra-compatible operations | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-keyspaces-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLWtleXNwYWNlcy1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Keyspaces%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-keyspaces-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Timestream for InfluxDB MCP Server](src/timestream-for-influxdb-mcp-server) | Time-series database operations and InfluxDB compatibility | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.timestream-for-influxdb-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMudGltZXN0cmVhbS1mb3ItaW5mbHV4ZGItbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Timestream%20for%20InfluxDB%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.timestream-for-influxdb-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon MSK MCP Server](src/aws-msk-mcp-server) | Managed Kafka cluster operations and streaming | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-msk-mcp-server&config=JTdCJTIyY29tbWFuZCUyMiUzQSUyMnV2eCUyMGF3c2xhYnMuYXdzLW1zay1tY3Atc2VydmVyJTQwbGF0ZXN0JTIwLS1hbGxvdy13cml0ZXMlMjIlMkMlMjJlbnYlMjIlM0ElN0IlMjJGQVNUTUNQX0xPR19MRVZFTCUyMiUzQSUyMkVSUk9SJTIyJTdEJTJDJTIyZGlzYWJsZWQlMjIlM0FmYWxzZSUyQyUyMmF1dG9BcHByb3ZlJTIyJTNBJTVCJTVEJTdE) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20MSK%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-msk-mcp-server%40latest%22%2C%22--allow-writes%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS S3 Tables MCP Server](src/s3-tables-mcp-server) | Manage S3 Tables for optimized analytics | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.s3-tables-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuczMtdGFibGVzLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEifX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=S3%20Tables%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.s3-tables-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%7D) |\n| [Amazon Redshift MCP Server](src/redshift-mcp-server) | Data warehouse operations and analytics queries | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.redshift-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMucmVkc2hpZnQtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJkZWZhdWx0IiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiSU5GTyJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Redshift%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.redshift-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22default%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22INFO%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS IoT SiteWise MCP Server](src/aws-iot-sitewise-mcp-server) | Industrial IoT asset management, data ingestion, and analytics | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-iot-sitewise-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWlvdC1zaXRld2lzZS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20IoT%20SiteWise%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-iot-sitewise-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Search & Analytics\n\n- **[Amazon OpenSearch MCP Server](https://github.com/opensearch-project/opensearch-mcp-server-py)** - OpenSearch powered search, Analytics, and Observability\n\n#### Backend API Providers\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS AppSync MCP Server](src/aws-appsync-mcp-server) | Manage and Interact with application backends powered by AWS AppSync | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-appsync-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWFwcHN5bmMtbWNwLXNlcnZlckBsYXRlc3QgLS1hbGxvdy13cml0ZSIsImVudiI6eyJBV1NfUFJPRklMRSI6ImRlZmF1bHQiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0=) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20AppSync%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-appsync-mcp-server%40latest%22%2C%20%22--allow-write%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22default%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n#### Caching & Performance\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon ElastiCache MCP Server](src/elasticache-mcp-server) | Complete ElastiCache control plane operations | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.elasticache-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZWxhc3RpY2FjaGUtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJkZWZhdWx0IiwiQVdTX1JFR0lPTiI6InVzLXdlc3QtMiIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=ElastiCache%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.elasticache-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22default%22%2C%22AWS_REGION%22%3A%22us-west-2%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon ElastiCache / MemoryDB for Valkey MCP Server](src/valkey-mcp-server) | Advanced data structures and caching with Valkey | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.valkey-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMudmFsa2V5LW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IlZBTEtFWV9IT1NUIjoiMTI3LjAuMC4xIiwiVkFMS0VZX1BPUlQiOiI2Mzc5IiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJhdXRvQXBwcm92ZSI6W10sImRpc2FibGVkIjpmYWxzZX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Valkey%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.valkey-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22VALKEY_HOST%22%3A%22127.0.0.1%22%2C%22VALKEY_PORT%22%3A%226379%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%7D) |\n| [Amazon ElastiCache for Memcached MCP Server](src/memcached-mcp-server) | High-speed caching with Memcached protocol | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.memcached-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMubWVtY2FjaGVkLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IiLCJNRU1DQUNIRURfSE9TVCI6InlvdXItbWVtY2FjaGVkLWhvc3QiLCJNRU1DQUNIRURfUE9SVCI6IjExMjExIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Memcached%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.memcached-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22MEMCACHED_HOST%22%3A%22your-memcached-host%22%2C%22MEMCACHED_PORT%22%3A%2211211%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n\n### ğŸ› ï¸ Developer Tools & Support\nAccelerate development with code analysis, documentation, and testing utilities.\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS IAM MCP Server](src/iam-mcp-server) | Comprehensive IAM user, role, group, and policy management with security best practices | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.iam-mcp-server&config=eyJjb21tYW5kIjoidXZ4IiwiYXJncyI6WyJhd3NsYWJzLmlhbS1tY3Atc2VydmVyQGxhdGVzdCJdLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20IAM%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.iam-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%7D) |\n| [Git Repo Research MCP Server](src/git-repo-research-mcp-server) | Semantic code search and repository analysis | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.git-repo-research-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZ2l0LXJlcG8tcmVzZWFyY2gtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLXByb2ZpbGUtbmFtZSIsIkFXU19SRUdJT04iOiJ1cy13ZXN0LTIiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIiwiR0lUSFVCX1RPS0VOIjoieW91ci1naXRodWItdG9rZW4ifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Git%20Repo%20Research%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.git-repo-research-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-profile-name%22%2C%22AWS_REGION%22%3A%22us-west-2%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22GITHUB_TOKEN%22%3A%22your-github-token%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Code Documentation Generator MCP Server](src/code-doc-gen-mcp-server) | Automated documentation from code analysis | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.code-doc-gen-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY29kZS1kb2MtZ2VuLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Code%20Documentation%20Generator%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.code-doc-gen-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Diagram MCP Server](src/aws-diagram-mcp-server) | Generate architecture diagrams and technical illustrations | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-diagram-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWRpYWdyYW0tbWNwLXNlcnZlciIsImVudiI6eyJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImF1dG9BcHByb3ZlIjpbXSwiZGlzYWJsZWQiOmZhbHNlfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Diagram%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-diagram-mcp-server%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%7D) |\n| [Frontend MCP Server](src/frontend-mcp-server) | React and modern web development guidance | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.frontend-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZnJvbnRlbmQtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Frontend%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.frontend-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Synthetic Data MCP Server](src/syntheticdata-mcp-server) | Generate realistic test data for development and ML | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.syntheticdata-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuc3ludGhldGljZGF0YS1tY3Atc2VydmVyIiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IiLCJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIn0sImF1dG9BcHByb3ZlIjpbXSwiZGlzYWJsZWQiOmZhbHNlfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Synthetic%20Data%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.syntheticdata-mcp-server%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%7D) |\n| [OpenAPI MCP Server](src/openapi-mcp-server) | Dynamic API integration through OpenAPI specifications | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.openapi-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMub3BlbmFwaS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBUElfTkFNRSI6InlvdXItYXBpLW5hbWUiLCJBUElfQkFTRV9VUkwiOiJodHRwczovL2FwaS5leGFtcGxlLmNvbSIsIkFQSV9TUEVDX1VSTCI6Imh0dHBzOi8vYXBpLmV4YW1wbGUuY29tL29wZW5hcGkuanNvbiIsIkxPR19MRVZFTCI6IkVSUk9SIiwiRU5BQkxFX1BST01FVEhFVVMiOiJmYWxzZSIsIkVOQUJMRV9PUEVSQVRJT05fUFJPTVBUUyI6InRydWUiLCJVVklDT1JOX1RJTUVPVVRfR1JBQ0VGVUxfU0hVVERPV04iOiI1LjAiLCJVVklDT1JOX0dSQUNFRlVMX1NIVVRET1dOIjoidHJ1ZSJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=OpenAPI%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.openapi-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22API_NAME%22%3A%22your-api-name%22%2C%22API_BASE_URL%22%3A%22https%3A%2F%2Fapi.example.com%22%2C%22API_SPEC_URL%22%3A%22https%3A%2F%2Fapi.example.com%2Fopenapi.json%22%2C%22LOG_LEVEL%22%3A%22ERROR%22%2C%22ENABLE_PROMETHEUS%22%3A%22false%22%2C%22ENABLE_OPERATION_PROMPTS%22%3A%22true%22%2C%22UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN%22%3A%225.0%22%2C%22UVICORN_GRACEFUL_SHUTDOWN%22%3A%22true%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n\n### ğŸ“¡ Integration & Messaging\n\nConnect systems with messaging, workflows, and location services.\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon SNS / SQS MCP Server](src/amazon-sns-sqs-mcp-server) | Event-driven messaging and queue management | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-sns-sqs-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLXNucy1zcXMtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSJ9fQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20SNS%2FSQS%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-sns-sqs-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%7D) |\n| [Amazon MQ MCP Server](src/amazon-mq-mcp-server) | Message broker management for RabbitMQ and ActiveMQ | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-mq-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLW1xLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20MQ%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-mq-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS MSK MCP Server](src/aws-msk-mcp-server) | Managed Kafka cluster operations and streaming | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-msk-mcp-server&config=JTdCJTIyY29tbWFuZCUyMiUzQSUyMnV2eCUyMGF3c2xhYnMuYXdzLW1zay1tY3Atc2VydmVyJTQwbGF0ZXN0JTIwLS1hbGxvdy13cml0ZXMlMjIlMkMlMjJlbnYlMjIlM0ElN0IlMjJGQVNUTUNQX0xPR19MRVZFTCUyMiUzQSUyMkVSUk9SJTIyJTdEJTJDJTIyZGlzYWJsZWQlMjIlM0FmYWxzZSUyQyUyMmF1dG9BcHByb3ZlJTIyJTNBJTVCJTVEJTdE) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20MSK%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-msk-mcp-server%40latest%22%2C%22--allow-writes%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Step Functions Tool MCP Server](src/stepfunctions-tool-mcp-server) | Execute complex workflows and business processes | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.stepfunctions-tool-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuc3RlcGZ1bmN0aW9ucy10b29sLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJTVEFURV9NQUNISU5FX1BSRUZJWCI6InlvdXItc3RhdGUtbWFjaGluZS1wcmVmaXgiLCJTVEFURV9NQUNISU5FX0xJU1QiOiJ5b3VyLWZpcnN0LXN0YXRlLW1hY2hpbmUsIHlvdXItc2Vjb25kLXN0YXRlLW1hY2hpbmUiLCJTVEFURV9NQUNISU5FX1RBR19LRVkiOiJ5b3VyLXRhZy1rZXkiLCJTVEFURV9NQUNISU5FX1RBR19WQUxVRSI6InlvdXItdGFnLXZhbHVlIiwiU1RBVEVfTUFDSElORV9JTlBVVF9TQ0hFTUFfQVJOX1RBR19LRVkiOiJ5b3VyLXN0YXRlLW1hY2hpbmUtdGFnLWZvci1pbnB1dC1zY2hlbWEifX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Step%20Functions%20Tool%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.stepfunctions-tool-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22STATE_MACHINE_PREFIX%22%3A%22your-state-machine-prefix%22%2C%22STATE_MACHINE_LIST%22%3A%22your-first-state-machine%2C%20your-second-state-machine%22%2C%22STATE_MACHINE_TAG_KEY%22%3A%22your-tag-key%22%2C%22STATE_MACHINE_TAG_VALUE%22%3A%22your-tag-value%22%2C%22STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY%22%3A%22your-state-machine-tag-for-input-schema%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Location Service MCP Server](src/aws-location-mcp-server) | Place search, geocoding, and route optimization | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-location-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWxvY2F0aW9uLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Location%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-location-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [OpenAPI MCP Server](src/openapi-mcp-server) | Dynamic API integration through OpenAPI specifications | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.openapi-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMub3BlbmFwaS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBUElfTkFNRSI6InlvdXItYXBpLW5hbWUiLCJBUElfQkFTRV9VUkwiOiJodHRwczovL2FwaS5leGFtcGxlLmNvbSIsIkFQSV9TUEVDX1VSTCI6Imh0dHBzOi8vYXBpLmV4YW1wbGUuY29tL29wZW5hcGkuanNvbiIsIkxPR19MRVZFTCI6IkVSUk9SIiwiRU5BQkxFX1BST01FVEhFVVMiOiJmYWxzZSIsIkVOQUJMRV9PUEVSQVRJT05fUFJPTVBUUyI6InRydWUiLCJVVklDT1JOX1RJTUVPVVRfR1JBQ0VGVUxfU0hVVERPV04iOiI1LjAiLCJVVklDT1JOX0dSQUNFRlVMX1NIVVRET1dOIjoidHJ1ZSJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=OpenAPI%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.openapi-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22API_NAME%22%3A%22your-api-name%22%2C%22API_BASE_URL%22%3A%22https%3A%2F%2Fapi.example.com%22%2C%22API_SPEC_URL%22%3A%22https%3A%2F%2Fapi.example.com%2Fopenapi.json%22%2C%22LOG_LEVEL%22%3A%22ERROR%22%2C%22ENABLE_PROMETHEUS%22%3A%22false%22%2C%22ENABLE_OPERATION_PROMPTS%22%3A%22true%22%2C%22UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN%22%3A%225.0%22%2C%22UVICORN_GRACEFUL_SHUTDOWN%22%3A%22true%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n### ğŸ’° Cost & Operations\n\nMonitor, optimize, and manage your AWS infrastructure and costs.\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS Pricing MCP Server](src/aws-pricing-mcp-server) | AWS service pricing and cost estimates | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-pricing-mcp-server&config=ewogICAgImNvbW1hbmQiOiAidXZ4IGF3c2xhYnMuYXdzLXByaWNpbmctbWNwLXNlcnZlckBsYXRlc3QiLAogICAgImVudiI6IHsKICAgICAgIkZBU1RNQ1BfTE9HX0xFVkVMIjogIkVSUk9SIiwKICAgICAgIkFXU19QUk9GSUxFIjogInlvdXItYXdzLXByb2ZpbGUiLAogICAgICAiQVdTX1JFR0lPTiI6ICJ1cy1lYXN0LTEiCiAgICB9LAogICAgImRpc2FibGVkIjogZmFsc2UsCiAgICAiYXV0b0FwcHJvdmUiOiBbXQogIH0K) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Pricing%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-pricing-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Cost Explorer MCP Server](src/cost-explorer-mcp-server) | Detailed cost analysis and reporting | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cost-explorer-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY29zdC1leHBsb3Jlci1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Cost%20Explorer%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cost-explorer-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon CloudWatch MCP Server](src/cloudwatch-mcp-server) | Metrics, Alarms, and Logs analysis and operational troubleshooting | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cloudwatch-mcp-server&config=ewogICAgImF1dG9BcHByb3ZlIjogW10sCiAgICAiZGlzYWJsZWQiOiBmYWxzZSwKICAgICJjb21tYW5kIjogInV2eCBhd3NsYWJzLmNsb3Vkd2F0Y2gtbWNwLXNlcnZlckBsYXRlc3QiLAogICAgImVudiI6IHsKICAgICAgIkFXU19QUk9GSUxFIjogIltUaGUgQVdTIFByb2ZpbGUgTmFtZSB0byB1c2UgZm9yIEFXUyBhY2Nlc3NdIiwKICAgICAgIkZBU1RNQ1BfTE9HX0xFVkVMIjogIkVSUk9SIgogICAgfSwKICAgICJ0cmFuc3BvcnRUeXBlIjogInN0ZGlvIgp9) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CloudWatch%20MCP%20Server&config=%7B%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%2C%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cloudwatch-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22%5BThe%20AWS%20Profile%20Name%20to%20use%20for%20AWS%20access%5D%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22transportType%22%3A%22stdio%22%7D) |\n| [Amazon CloudWatch Logs MCP Server (deprecated)](src/cloudwatch-logs-mcp-server) | CloudWatch Logs analysis and monitoring | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cloudwatch-logs-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2xvdWR3YXRjaC1sb2dzLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20CloudWatch%20Logs%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cloudwatch-logs-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Managed Prometheus MCP Server](src/prometheus-mcp-server) | Prometheus-compatible operations | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.prometheus-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMucHJvbWV0aGV1cy1tY3Atc2VydmVyQGxhdGVzdCAtLXVybCBodHRwczovL2Fwcy13b3Jrc3BhY2VzLnVzLWVhc3QtMS5hbWF6b25hd3MuY29tL3dvcmtzcGFjZXMvd3MtPFdvcmtzcGFjZSBJRD4gLS1yZWdpb24gPFlvdXIgQVdTIFJlZ2lvbj4gLS1wcm9maWxlIDxZb3VyIENMSSBQcm9maWxlIFtkZWZhdWx0XSBpZiBubyBwcm9maWxlIGlzIHVzZWQ%2BIiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiREVCVUciLCJBV1NfUFJPRklMRSI6IjxZb3VyIENMSSBQcm9maWxlIFtkZWZhdWx0XSBpZiBubyBwcm9maWxlIGlzIHVzZWQ%2BIn19) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Prometheus%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.prometheus-mcp-server%40latest%22%2C%22--url%22%2C%22https%3A%2F%2Faps-workspaces.us-east-1.amazonaws.com%2Fworkspaces%2Fws-%3CWorkspace%20ID%3E%22%2C%22--region%22%2C%22%3CYour%20AWS%20Region%3E%22%2C%22--profile%22%2C%22%3CYour%20CLI%20Profile%20%5Bdefault%5D%20if%20no%20profile%20is%20used%3E%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22DEBUG%22%2C%22AWS_PROFILE%22%3A%22%3CYour%20CLI%20Profile%20%5Bdefault%5D%20if%20no%20profile%20is%20used%3E%22%7D%7D) |\n| [AWS Billing and Cost Management MCP Server](src/billing-cost-management-mcp-server/) | Billing and cost management | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.billing-cost-management-mcp-server&config=ewogICAgImNvbW1hbmQiOiAidXZ4IGF3c2xhYnMuYmlsbGluZy1jb3N0LW1hbmFnZW1lbnQtbWNwLXNlcnZlckBsYXRlc3QiLAogICAgImVudiI6IHsKICAgICAgIkZBU1RNQ1BfTE9HX0xFVkVMIjogIkVSUk9SIiwKICAgICAgIkFXU19QUk9GSUxFIjogInlvdXItYXdzLXByb2ZpbGUiLAogICAgICAiQVdTX1JFR0lPTiI6ICJ1cy1lYXN0LTEiCiAgICB9LAogICAgImRpc2FibGVkIjogZmFsc2UsCiAgICAiYXV0b0FwcHJvdmUiOiBbXQogIH0K) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Billing%20and%20Cost%20Management%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.billing-cost-management-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n### ğŸ§¬ Healthcare & Lifesciences\nInteract with AWS HealthAI services.\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS HealthOmics MCP Server](src/aws-healthomics-mcp-server) | Generate, run, debug and optimize lifescience workflows | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-healthomics-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWhlYWx0aG9taWNzLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJBV1NfUFJPRklMRSI6InlvdXItcHJvZmlsZSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiV0FSTklORyJ9fQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20HealthOmics%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-healthomics-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%2C%22AWS_PROFILE%22%3A%22your-profile%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22WARNING%22%7D%7D) |\n| [AWS HealthLake MCP Server](src/healthlake-mcp-server) | Create, manage, search, and optimize FHIR healthcare data workflows with comprehensive AWS HealthLake integration, featuring automated resource discovery, advanced search capabilities, patient record management, and seamless import/export operations. | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.healthlake-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuaGVhbHRobGFrZS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiQVdTX1BST0ZJTEUiOiJ5b3VyLXByb2ZpbGUiLCJGQVNUTUNQX0xPR19MRVZFTCI6IldBUk5JTkcifX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=HealthLake%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.healthlake-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%2C%22AWS_PROFILE%22%3A%22your-profile%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22WARNING%22%7D%7D) |\n\n---\n---\n\n### Browse by How You're Working\n\n#### ğŸ‘¨â€ğŸ’» Vibe Coding & Development\n\n*AI coding assistants like Amazon Q Developer CLI, Cline, Cursor, and Claude Code helping you build faster*\n\n##### Core Development Workflow\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS API MCP Server](src/aws-api-mcp-server) | Start here for general AWS interactions! Comprehensive AWS API support with command validation, security controls, and access to all AWS services. Perfect for managing infrastructure, exploring resources, and executing AWS operations through natural language. | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-api-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWFwaS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D)<br/>[![Install VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20API%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-api-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22type%22%3A%22stdio%22%7D) |\n| [Core MCP Server](src/core-mcp-server) | Start here: intelligent planning and MCP server orchestration | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.core-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY29yZS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImF1dG9BcHByb3ZlIjpbXSwiZGlzYWJsZWQiOmZhbHNlfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Core%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.core-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%7D) |\n| [AWS Knowledge MCP Server](src/aws-knowledge-mcp-server) | A remote, fully-managed MCP server hosted by AWS that provides access to the latest AWS docs, API references, What's New Posts, Getting Started information, Builder Center, Blog posts, Architectural references, and Well-Architected guidance. | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-knowledge-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWtub3dsZWRnZS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D)<br/>[![Install VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Knowledge%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-knowledge-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Documentation MCP Server](src/aws-documentation-mcp-server) | Get latest AWS docs and API references | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-documentation-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWRvY3VtZW50YXRpb24tbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiIsIkFXU19ET0NVTUVOVEFUSU9OX1BBUlRJVElPTiI6ImF3cyJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Documentation%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-documentation-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_DOCUMENTATION_PARTITION%22%3A%22aws%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Git Repo Research MCP Server](src/git-repo-research-mcp-server) | Semantic search through codebases and repositories | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.git-repo-research-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZ2l0LXJlcG8tcmVzZWFyY2gtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLXByb2ZpbGUtbmFtZSIsIkFXU19SRUdJT04iOiJ1cy13ZXN0LTIiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIiwiR0lUSFVCX1RPS0VOIjoieW91ci1naXRodWItdG9rZW4ifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Git%20Repo%20Research%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.git-repo-research-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-profile-name%22%2C%22AWS_REGION%22%3A%22us-west-2%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22GITHUB_TOKEN%22%3A%22your-github-token%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Infrastructure as Code\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS CDK MCP Server](src/cdk-mcp-server) | CDK development with security best practices and compliance | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cdk-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2RrLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CDK%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cdk-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Terraform MCP Server](src/terraform-mcp-server) | Terraform with integrated security scanning and best practices | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.terraform-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMudGVycmFmb3JtLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Terraform%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.terraform-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS CloudFormation MCP Server](src/cfn-mcp-server) | Direct AWS resource management through Cloud Control API | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cfn-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2ZuLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1uYW1lZC1wcm9maWxlIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CloudFormation%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cfn-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-named-profile%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Cloud Control API MCP Server](src/ccapi-mcp-server) | Direct AWS resource management with security scanning and best practices | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.ccapi-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2NhcGktbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Cloud%20Control%20API%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.ccapi-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Application Development\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Frontend MCP Server](src/frontend-mcp-server) | React and modern web development patterns with AWS integration | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.frontend-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZnJvbnRlbmQtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Frontend%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.frontend-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Diagram MCP Server](src/aws-diagram-mcp-server) | Generate architecture diagrams as you design | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-diagram-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWRpYWdyYW0tbWNwLXNlcnZlciIsImVudiI6eyJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImF1dG9BcHByb3ZlIjpbXSwiZGlzYWJsZWQiOmZhbHNlfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Diagram%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-diagram-mcp-server%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%7D) |\n| [Code Documentation Generation MCP Server](src/code-doc-gen-mcp-server) | Auto-generate docs from your codebase | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.code-doc-gen-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY29kZS1kb2MtZ2VuLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Code%20Documentation%20Generator%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.code-doc-gen-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [OpenAPI MCP Server](src/openapi-mcp-server) | Dynamic API integration through OpenAPI specifications | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.openapi-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMub3BlbmFwaS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBUElfTkFNRSI6InlvdXItYXBpLW5hbWUiLCJBUElfQkFTRV9VUkwiOiJodHRwczovL2FwaS5leGFtcGxlLmNvbSIsIkFQSV9TUEVDX1VSTCI6Imh0dHBzOi8vYXBpLmV4YW1wbGUuY29tL29wZW5hcGkuanNvbiIsIkxPR19MRVZFTCI6IkVSUk9SIiwiRU5BQkxFX1BST01FVEhFVVMiOiJmYWxzZSIsIkVOQUJMRV9PUEVSQVRJT05fUFJPTVBUUyI6InRydWUiLCJVVklDT1JOX1RJTUVPVVRfR1JBQ0VGVUxfU0hVVERPV04iOiI1LjAiLCJVVklDT1JOX0dSQUNFRlVMX1NIVVRET1dOIjoidHJ1ZSJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=OpenAPI%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.openapi-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22API_NAME%22%3A%22your-api-name%22%2C%22API_BASE_URL%22%3A%22https%3A%2F%2Fapi.example.com%22%2C%22API_SPEC_URL%22%3A%22https%3A%2F%2Fapi.example.com%2Fopenapi.json%22%2C%22LOG_LEVEL%22%3A%22ERROR%22%2C%22ENABLE_PROMETHEUS%22%3A%22false%22%2C%22ENABLE_OPERATION_PROMPTS%22%3A%22true%22%2C%22UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN%22%3A%225.0%22%2C%22UVICORN_GRACEFUL_SHUTDOWN%22%3A%22true%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Container & Serverless Development\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon EKS MCP Server](src/eks-mcp-server) | Kubernetes cluster management and app deployment | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.eks-mcp-server&config=eyJhdXRvQXBwcm92ZSI6W10sImRpc2FibGVkIjpmYWxzZSwiY29tbWFuZCI6InV2eCBhd3NsYWJzLmVrcy1tY3Atc2VydmVyQGxhdGVzdCAtLWFsbG93LXdyaXRlIC0tYWxsb3ctc2Vuc2l0aXZlLWRhdGEtYWNjZXNzIiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwidHJhbnNwb3J0VHlwZSI6InN0ZGlvIn0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=EKS%20MCP%20Server&config=%7B%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%2C%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.eks-mcp-server%40latest%22%2C%22--allow-write%22%2C%22--allow-sensitive-data-access%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22transportType%22%3A%22stdio%22%7D) |\n| [Amazon ECS MCP Server](src/ecs-mcp-server) | Containerize and deploy applications to ECS | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.ecs-mcp-server&config=eyJjb21tYW5kIjoidXZ4IC0tZnJvbSBhd3NsYWJzLWVjcy1tY3Atc2VydmVyIGVjcy1tY3Atc2VydmVyIiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ5b3VyLWF3cy1yZWdpb24iLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIiwiRkFTVE1DUF9MT0dfRklMRSI6Ii9wYXRoL3RvL2Vjcy1tY3Atc2VydmVyLmxvZyIsIkFMTE9XX1dSSVRFIjoiZmFsc2UiLCJBTExPV19TRU5TSVRJVkVfREFUQSI6ImZhbHNlIn19) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=ECS%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22--from%22%2C%22awslabs-ecs-mcp-server%22%2C%22ecs-mcp-server%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22your-aws-region%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22FASTMCP_LOG_FILE%22%3A%22%2Fpath%2Fto%2Fecs-mcp-server.log%22%2C%22ALLOW_WRITE%22%3A%22false%22%2C%22ALLOW_SENSITIVE_DATA%22%3A%22false%22%7D%7D) |\n| [Finch MCP Server](src/finch-mcp-server) | Local container building with ECR push | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.finch-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZmluY2gtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJkZWZhdWx0IiwiQVdTX1JFR0lPTiI6InVzLXdlc3QtMiIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiSU5GTyJ9LCJ0cmFuc3BvcnRUeXBlIjoic3RkaW8iLCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Finch%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.finch-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22default%22%2C%22AWS_REGION%22%3A%22us-west-2%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22INFO%22%7D%2C%22transportType%22%3A%22stdio%22%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Serverless MCP Server](src/aws-serverless-mcp-server) | Full serverless app lifecycle with SAM CLI | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-serverless-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLXNlcnZlcmxlc3MtbWNwLXNlcnZlckBsYXRlc3QgLS1hbGxvdy13cml0ZSAtLWFsbG93LXNlbnNpdGl2ZS1kYXRhLWFjY2VzcyIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Serverless%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-serverless-mcp-server%40latest%22%2C%22--allow-write%22%2C%22--allow-sensitive-data-access%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n\n##### Testing & Data\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Synthetic Data MCP Server](src/syntheticdata-mcp-server) | Generate realistic test data for development and ML | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.syntheticdata-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuc3ludGhldGljZGF0YS1tY3Atc2VydmVyIiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IiLCJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIn0sImF1dG9BcHByb3ZlIjpbXSwiZGlzYWJsZWQiOmZhbHNlfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Synthetic%20Data%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.syntheticdata-mcp-server%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%7D) |\n\n##### Lifesciences Workflow Development\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS HealthOmics MCP Server](src/aws-healthomics-mcp-server) | Generate, run, debug and optimize lifescience workflows | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-healthomics-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWhlYWx0aG9taWNzLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJBV1NfUFJPRklMRSI6InlvdXItcHJvZmlsZSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiV0FSTklORyJ9fQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20HealthOmics%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-healthomics-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%2C%22AWS_PROFILE%22%3A%22your-profile%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22WARNING%22%7D%7D) |\n\n##### Healthcare Data Management\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS HealthLake MCP Server](src/healthlake-mcp-server) | Create, manage, search, and optimize FHIR healthcare data workflows with comprehensive AWS HealthLake integration, featuring automated resource discovery, advanced search capabilities, patient record management, and seamless import/export operations. | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.healthlake-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuaGVhbHRobGFrZS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiQVdTX1BST0ZJTEUiOiJ5b3VyLXByb2ZpbGUiLCJGQVNUTUNQX0xPR19MRVZFTCI6IldBUk5JTkcifX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=HealthLake%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.healthlake-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%2C%22AWS_PROFILE%22%3A%22your-profile%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22WARNING%22%7D%7D) |\n\n\n#### ğŸ’¬ Conversational Assistants\n\n*Customer-facing chatbots, business agents, and interactive Q&A systems*\n\n##### Knowledge & Search\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon Bedrock Knowledge Bases Retrieval MCP Server](src/bedrock-kb-retrieval-mcp-server) | Query enterprise knowledge bases with citation support | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.bedrock-kb-retrieval-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYmVkcm9jay1rYi1yZXRyaWV2YWwtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLXByb2ZpbGUtbmFtZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIiwiS0JfSU5DTFVTSU9OX1RBR19LRVkiOiJvcHRpb25hbC10YWcta2V5LXRvLWZpbHRlci1rYnMiLCJCRURST0NLX0tCX1JFUkFOS0lOR19FTkFCTEVEIjoiZmFsc2UifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Bedrock%20KB%20Retrieval%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.bedrock-kb-retrieval-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-profile-name%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22KB_INCLUSION_TAG_KEY%22%3A%22optional-tag-key-to-filter-kbs%22%2C%22BEDROCK_KB_RERANKING_ENABLED%22%3A%22false%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Kendra Index MCP Server](src/amazon-kendra-index-mcp-server) | Enterprise search and RAG enhancement | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-kendra-index-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLWtlbmRyYS1pbmRleC1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiS0VORF9JTkRFWF9JRCI6InlvdXIta2VuZHJhLWluZGV4LWlkIiwiS0VORF9ST0xFX0FSTiI6InlvdXIta2VuZHJhLXJvbGUtYXJuIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Kendra%20Index%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-kendra-index-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%2C%22KEND_INDEX_ID%22%3A%22your-kendra-index-id%22%2C%22KEND_ROLE_ARN%22%3A%22your-kendra-role-arn%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Q Business MCP Server](src/amazon-qbusiness-anonymous-mcp-server) | AI assistant for your ingested content with anonymous access | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-qbusiness-anonymous-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLXFidXNpbmVzcy1hbm9ueW1vdXMtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiUUJVU0lORVNTX0FQUF9JRCI6InlvdXItcWJ1c2luZXNzLWFwcC1pZCIsIlFCVVNJTkVTU19VU0VSX0lEIjoieW91ci11c2VyLWlkIiwiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Q%20Business%20Anonymous%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-qbusiness-anonymous-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22QBUSINESS_APP_ID%22%3A%22your-qbusiness-app-id%22%2C%22QBUSINESS_USER_ID%22%3A%22your-user-id%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Q Index MCP Server](src/amazon-qindex-mcp-server) | Data accessors to search through enterprise's Q index | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-qindex-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLXFpbmRleC1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiUUlOREVYX0lEIjoieW91ci1xaW5kZXgtaWQiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Q%20Index%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-qindex-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_REGION%22%3A%22us-east-1%22%2C%22QINDEX_ID%22%3A%22your-qindex-id%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Documentation MCP Server](src/aws-documentation-mcp-server) | Get latest AWS docs and API references | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-documentation-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWRvY3VtZW50YXRpb24tbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiIsIkFXU19ET0NVTUVOVEFUSU9OX1BBUlRJVElPTiI6ImF3cyJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Documentation%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-documentation-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_DOCUMENTATION_PARTITION%22%3A%22aws%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Content Processing & Generation\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon Nova Canvas MCP Server](src/nova-canvas-mcp-server) | Generate images from text descriptions and color palettes | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.nova-canvas-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMubm92YS1jYW52YXMtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Nova%20Canvas%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.nova-canvas-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Rekognition MCP Server (deprecated)](src/amazon-rekognition-mcp-server) | Analyze images using computer vision capabilities | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-rekognition-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLXJla29nbml0aW9uLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Rekognition%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-rekognition-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Bedrock Data Automation MCP Server](src/aws-bedrock-data-automation-mcp-server) | Analyze uploaded documents, images, and media | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=bedrock-data-automation-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWJlZHJvY2stZGF0YS1hdXRvbWF0aW9uLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJBV1NfQlVDS0VUX05BTUUiOiJ5b3VyLXMzLWJ1Y2tldC1uYW1lIiwiQkFTRV9ESVIiOiIvcGF0aC90by9iYXNlL2RpcmVjdG9yeSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Bedrock%20Data%20Automation%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-bedrock-data-automation-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22AWS_BUCKET_NAME%22%3A%22your-s3-bucket-name%22%2C%22BASE_DIR%22%3A%22%2Fpath%2Fto%2Fbase%2Fdirectory%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Business Services\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon Location Service MCP Server](src/aws-location-mcp-server) | Location search, geocoding, and business hours | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-location-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWxvY2F0aW9uLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Location%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-location-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Pricing MCP Server](src/aws-pricing-mcp-server) | AWS service pricing and cost estimates | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-pricing-mcp-server&config=ewogICAgImNvbW1hbmQiOiAidXZ4IGF3c2xhYnMuYXdzLXByaWNpbmctbWNwLXNlcnZlckBsYXRlc3QiLAogICAgImVudiI6IHsKICAgICAgIkZBU1RNQ1BfTE9HX0xFVkVMIjogIkVSUk9SIiwKICAgICAgIkFXU19QUk9GSUxFIjogInlvdXItYXdzLXByb2ZpbGUiLAogICAgICAiQVdTX1JFR0lPTiI6ICJ1cy1lYXN0LTEiCiAgICB9LAogICAgImRpc2FibGVkIjogZmFsc2UsCiAgICAiYXV0b0FwcHJvdmUiOiBbXQogIH0K) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Pricing%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-pricing-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Cost Explorer MCP Server](src/cost-explorer-mcp-server) | Detailed cost analysis and spend reports | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cost-explorer-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY29zdC1leHBsb3Jlci1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Cost%20Explorer%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cost-explorer-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n#### ğŸ¤– Autonomous Background Agents\n\n*Headless automation, ETL pipelines, and operational systems*\n\n##### Data Operations & ETL\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS Data Processing MCP Server](src/aws-dataprocessing-mcp-server) | Comprehensive data processing tools and real-time pipeline visibility across AWS Glue and Amazon EMR-EC2 | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-dataprocessing-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXdzLWRhdGFwcm9jZXNzaW5nLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Data%20Processing%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-dataprocessing-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon DynamoDB MCP Server](src/dynamodb-mcp-server) | Complete DynamoDB operations and table management | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.dynamodb-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZHluYW1vZGItbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRERCLU1DUC1SRUFET05MWSI6InRydWUiLCJBV1NfUFJPRklMRSI6ImRlZmF1bHQiLCJBV1NfUkVHSU9OIjoidXMtd2VzdC0yIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=DynamoDB%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.dynamodb-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22DDB-MCP-READONLY%22%3A%22true%22%2C%22AWS_PROFILE%22%3A%22default%22%2C%22AWS_REGION%22%3A%22us-west-2%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Aurora PostgreSQL MCP Server](src/postgres-mcp-server) | PostgreSQL database operations via RDS Data API | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.postgres-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMucG9zdGdyZXMtbWNwLXNlcnZlckBsYXRlc3QgLS1jb25uZWN0aW9uLXN0cmluZyBwb3N0Z3Jlc3FsOi8vW3VzZXJuYW1lXTpbcGFzc3dvcmRdQFtob3N0XTpbcG9ydF0vW2RhdGFiYXNlXSIsImVudiI6eyJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdLCJ0cmFuc3BvcnRUeXBlIjoic3RkaW8iLCJhdXRvU3RhcnQiOnRydWV9) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=PostgreSQL%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.postgres-mcp-server%40latest%22%2C%22--connection-string%22%2C%22postgresql%3A%2F%2F%5Busername%5D%3A%5Bpassword%5D%40%5Bhost%5D%3A%5Bport%5D%2F%5Bdatabase%5D%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%2C%22transportType%22%3A%22stdio%22%2C%22autoStart%22%3Atrue%7D) |\n| [Amazon Aurora MySQL MCP Server](src/mysql-mcp-server) | MySQL database operations via RDS Data API | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.mysql-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMubXlzcWwtbWNwLXNlcnZlckBsYXRlc3QgLS1yZXNvdXJjZV9hcm4gW3lvdXIgZGF0YV0gLS1zZWNyZXRfYXJuIFt5b3VyIGRhdGFdIC0tZGF0YWJhc2UgW3lvdXIgZGF0YV0gLS1yZWdpb24gW3lvdXIgZGF0YV0gLS1yZWFkb25seSBUcnVlIiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=MySQL%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.mysql-mcp-server%40latest%22%2C%22--resource_arn%22%2C%22%5Byour%20data%5D%22%2C%22--secret_arn%22%2C%22%5Byour%20data%5D%22%2C%22--database%22%2C%22%5Byour%20data%5D%22%2C%22--region%22%2C%22%5Byour%20data%5D%22%2C%22--readonly%22%2C%22True%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Aurora DSQL MCP Server](src/aurora-dsql-mcp-server) | Distributed SQL with PostgreSQL compatibility | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aurora-dsql-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYXVyb3JhLWRzcWwtbWNwLXNlcnZlckBsYXRlc3QgLS1jbHVzdGVyX2VuZHBvaW50IFt5b3VyIGRzcWwgY2x1c3RlciBlbmRwb2ludF0gLS1yZWdpb24gW3lvdXIgZHNxbCBjbHVzdGVyIHJlZ2lvbiwgZS5nLiB1cy1lYXN0LTFdIC0tZGF0YWJhc2VfdXNlciBbeW91ciBkc3FsIHVzZXJuYW1lXSAtLXByb2ZpbGUgZGVmYXVsdCIsImVudiI6eyJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Aurora%20DSQL%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aurora-dsql-mcp-server%40latest%22%2C%22--cluster_endpoint%22%2C%22%5Byour%20dsql%20cluster%20endpoint%5D%22%2C%22--region%22%2C%22%5Byour%20dsql%20cluster%20region%2C%20e.g.%20us-east-1%5D%22%2C%22--database_user%22%2C%22%5Byour%20dsql%20username%5D%22%2C%22--profile%22%2C%22default%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon DocumentDB MCP Server](src/documentdb-mcp-server) | MongoDB-compatible document database operations | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.documentdb-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuZG9jdW1lbnRkYi1tY3Atc2VydmVAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IiLCJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=DocumentDB%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.documentdb-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Neptune MCP Server](src/amazon-neptune-mcp-server) | Graph database queries with openCypher and Gremlin | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-neptune-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLW5lcHR1bmUtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiTkVQVFVORV9FTkRQT0lOVCI6Imh0dHBzOi8veW91ci1uZXB0dW5lLWNsdXN0ZXItaWQucmVnaW9uLm5lcHR1bmUuYW1hem9uYXdzLmNvbTo4MTgyIiwiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Neptune%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-neptune-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22NEPTUNE_ENDPOINT%22%3A%22https%3A%2F%2Fyour-neptune-cluster-id.region.neptune.amazonaws.com%3A8182%22%2C%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Keyspaces MCP Server](src/amazon-keyspaces-mcp-server) | Apache Cassandra-compatible operations | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-keyspaces-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLWtleXNwYWNlcy1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20Keyspaces%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-keyspaces-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon Timestream for InfluxDB MCP Server](src/timestream-for-influxdb-mcp-server) | Time-series database operations and InfluxDB compatibility | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.timestream-for-influxdb-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMudGltZXN0cmVhbS1mb3ItaW5mbHV4ZGItbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Timestream%20for%20InfluxDB%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.timestream-for-influxdb-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon MSK MCP Server](src/aws-msk-mcp-server) | Managed Kafka cluster operations and streaming | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-msk-mcp-server&config=JTdCJTIyY29tbWFuZCUyMiUzQSUyMnV2eCUyMGF3c2xhYnMuYXdzLW1zay1tY3Atc2VydmVyJTQwbGF0ZXN0JTIwLS1hbGxvdy13cml0ZXMlMjIlMkMlMjJlbnYlMjIlM0ElN0IlMjJGQVNUTUNQX0xPR19MRVZFTCUyMiUzQSUyMkVSUk9SJTIyJTdEJTJDJTIyZGlzYWJsZWQlMjIlM0FmYWxzZSUyQyUyMmF1dG9BcHByb3ZlJTIyJTNBJTVCJTVEJTdE) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20MSK%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-msk-mcp-server%40latest%22%2C%22--allow-writes%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Caching & Performance\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon ElastiCache / MemoryDB for Valkey MCP Server](src/valkey-mcp-server) | Advanced data structures and caching with Valkey | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.valkey-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMudmFsa2V5LW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IlZBTEtFWV9IT1NUIjoiMTI3LjAuMC4xIiwiVkFMS0VZX1BPUlQiOiI2Mzc5IiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJhdXRvQXBwcm92ZSI6W10sImRpc2FibGVkIjpmYWxzZX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Valkey%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.valkey-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22VALKEY_HOST%22%3A%22127.0.0.1%22%2C%22VALKEY_PORT%22%3A%226379%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%7D) |\n| [Amazon ElastiCache for Memcached MCP Server ](src/memcached-mcp-server) | High-speed caching with Memcached protocol | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.memcached-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMubWVtY2FjaGVkLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IiLCJNRU1DQUNIRURfSE9TVCI6InlvdXItbWVtY2FjaGVkLWhvc3QiLCJNRU1DQUNIRURfUE9SVCI6IjExMjExIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Memcached%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.memcached-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%2C%22MEMCACHED_HOST%22%3A%22your-memcached-host%22%2C%22MEMCACHED_PORT%22%3A%2211211%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Workflow & Integration\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [AWS Lambda Tool MCP Server](src/lambda-tool-mcp-server) | Execute Lambda functions as AI tools for private resource access | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.lambda-tool-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMubGFtYmRhLXRvb2wtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZVTkNUSU9OX1BSRUZJWCI6InlvdXItZnVuY3Rpb24tcHJlZml4IiwiRlVOQ1RJT05fTElTVCI6InlvdXItZmlyc3QtZnVuY3Rpb24sIHlvdXItc2Vjb25kLWZ1bmN0aW9uIiwiRlVOQ1RJT05fVEFHX0tFWSI6InlvdXItdGFnLWtleSIsIkZVTkNUSU9OX1RBR19WQUxVRSI6InlvdXItdGFnLXZhbHVlIiwiRlVOQ1RJT05fSU5QVVRfU0NIRU1BX0FSTl9UQUdfS0VZIjoieW91ci1mdW5jdGlvbi10YWctZm9yLWlucHV0LXNjaGVtYSJ9fQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Lambda%20Tool%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.lambda-tool-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FUNCTION_PREFIX%22%3A%22your-function-prefix%22%2C%22FUNCTION_LIST%22%3A%22your-first-function%2C%20your-second-function%22%2C%22FUNCTION_TAG_KEY%22%3A%22your-tag-key%22%2C%22FUNCTION_TAG_VALUE%22%3A%22your-tag-value%22%2C%22FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY%22%3A%22your-function-tag-for-input-schema%22%7D%7D) |\n| [AWS Step Functions Tool MCP Server](src/stepfunctions-tool-mcp-server) | Execute complex workflows and business processes | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.stepfunctions-tool-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuc3RlcGZ1bmN0aW9ucy10b29sLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJTVEFURV9NQUNISU5FX1BSRUZJWCI6InlvdXItc3RhdGUtbWFjaGluZS1wcmVmaXgiLCJTVEFURV9NQUNISU5FX0xJU1QiOiJ5b3VyLWZpcnN0LXN0YXRlLW1hY2hpbmUsIHlvdXItc2Vjb25kLXN0YXRlLW1hY2hpbmUiLCJTVEFURV9NQUNISU5FX1RBR19LRVkiOiJ5b3VyLXRhZy1rZXkiLCJTVEFURV9NQUNISU5FX1RBR19WQUxVRSI6InlvdXItdGFnLXZhbHVlIiwiU1RBVEVfTUFDSElORV9JTlBVVF9TQ0hFTUFfQVJOX1RBR19LRVkiOiJ5b3VyLXN0YXRlLW1hY2hpbmUtdGFnLWZvci1pbnB1dC1zY2hlbWEifX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Step%20Functions%20Tool%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.stepfunctions-tool-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22STATE_MACHINE_PREFIX%22%3A%22your-state-machine-prefix%22%2C%22STATE_MACHINE_LIST%22%3A%22your-first-state-machine%2C%20your-second-state-machine%22%2C%22STATE_MACHINE_TAG_KEY%22%3A%22your-tag-key%22%2C%22STATE_MACHINE_TAG_VALUE%22%3A%22your-tag-value%22%2C%22STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY%22%3A%22your-state-machine-tag-for-input-schema%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon SNS/SQS MCP Server](src/amazon-sns-sqs-mcp-server) | Event-driven messaging and queue management | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-sns-sqs-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLXNucy1zcXMtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSJ9fQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20SNS%2FSQS%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-sns-sqs-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%7D%7D) |\n| [Amazon MQ MCP Server](src/amazon-mq-mcp-server) | Message broker management for RabbitMQ and ActiveMQ | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.amazon-mq-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLW1xLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20MQ%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.amazon-mq-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS MSK MCP Server](src/aws-msk-mcp-server) | Managed Kafka cluster operations and streaming | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.aws-msk-mcp-server&config=JTdCJTIyY29tbWFuZCUyMiUzQSUyMnV2eCUyMGF3c2xhYnMuYXdzLW1zay1tY3Atc2VydmVyJTQwbGF0ZXN0JTIwLS1hbGxvdy13cml0ZXMlMjIlMkMlMjJlbnYlMjIlM0ElN0IlMjJGQVNUTUNQX0xPR19MRVZFTCUyMiUzQSUyMkVSUk9SJTIyJTdEJTJDJTIyZGlzYWJsZWQlMjIlM0FmYWxzZSUyQyUyMmF1dG9BcHByb3ZlJTIyJTNBJTVCJTVEJTdE) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20MSK%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.aws-msk-mcp-server%40latest%22%2C%22--allow-writes%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n\n##### Operations & Monitoring\n\n| Server Name | Description | Install |\n|-------------|-------------|---------|\n| [Amazon CloudWatch MCP Server](src/cloudwatch-mcp-server) | Metrics, Alarms, and Logs analysis and operational troubleshooting | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cloudwatch-mcp-server&config=ewogICAgImF1dG9BcHByb3ZlIjogW10sCiAgICAiZGlzYWJsZWQiOiBmYWxzZSwKICAgICJjb21tYW5kIjogInV2eCBhd3NsYWJzLmNsb3Vkd2F0Y2gtbWNwLXNlcnZlckBsYXRlc3QiLAogICAgImVudiI6IHsKICAgICAgIkFXU19QUk9GSUxFIjogIltUaGUgQVdTIFByb2ZpbGUgTmFtZSB0byB1c2UgZm9yIEFXUyBhY2Nlc3NdIiwKICAgICAgIkZBU1RNQ1BfTE9HX0xFVkVMIjogIkVSUk9SIgogICAgfSwKICAgICJ0cmFuc3BvcnRUeXBlIjogInN0ZGlvIgp9) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CloudWatch%20MCP%20Server&config=%7B%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%2C%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cloudwatch-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22%5BThe%20AWS%20Profile%20Name%20to%20use%20for%20AWS%20access%5D%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22transportType%22%3A%22stdio%22%7D) |\n| [Amazon CloudWatch Logs MCP Server (deprecated)](src/cloudwatch-logs-mcp-server) | CloudWatch Logs analysis and monitoring | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cloudwatch-logs-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY2xvdWR3YXRjaC1sb2dzLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Amazon%20CloudWatch%20Logs%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cloudwatch-logs-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [Amazon CloudWatch Application Signals MCP Server](src/cloudwatch-appsignals-mcp-server) | Application monitoring and performance insights | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cloudwatch-appsignals-mcp-server&config=eyJhdXRvQXBwcm92ZSI6W10sImRpc2FibGVkIjpmYWxzZSwidGltZW91dCI6NjAsImNvbW1hbmQiOiJ1dnggYXdzbGFicy5jbG91ZHdhdGNoLWFwcHNpZ25hbHMtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJbVGhlIEFXUyBQcm9maWxlIE5hbWUgdG8gdXNlIGZvciBBV1MgYWNjZXNzXSIsIkFXU19SRUdJT04iOiJbVGhlIEFXUyByZWdpb24gdG8gcnVuIGluXSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwidHJhbnNwb3J0VHlwZSI6InN0ZGlvIn0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CloudWatch%20Application%20Signals%20MCP%20Server&config=%7B%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%2C%22timeout%22%3A60%2C%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cloudwatch-appsignals-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22%5BThe%20AWS%20Profile%20Name%20to%20use%20for%20AWS%20access%5D%22%2C%22AWS_REGION%22%3A%22%5BThe%20AWS%20region%20to%20run%20in%5D%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22transportType%22%3A%22stdio%22%7D) |\n| [AWS Cost Explorer MCP Server](src/cost-explorer-mcp-server) | Detailed cost analysis and reporting | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.cost-explorer-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuY29zdC1leHBsb3Jlci1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Cost%20Explorer%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cost-explorer-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS Managed Prometheus MCP Server](src/prometheus-mcp-server) | Prometheus-compatible operations and monitoring | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.prometheus-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMucHJvbWV0aGV1cy1tY3Atc2VydmVyQGxhdGVzdCAtLXVybCBodHRwczovL2Fwcy13b3Jrc3BhY2VzLnVzLWVhc3QtMS5hbWF6b25hd3MuY29tL3dvcmtzcGFjZXMvd3MtPFdvcmtzcGFjZSBJRD4gLS1yZWdpb24gPFlvdXIgQVdTIFJlZ2lvbj4gLS1wcm9maWxlIDxZb3VyIENMSSBQcm9maWxlIFtkZWZhdWx0XSBpZiBubyBwcm9maWxlIGlzIHVzZWQ%2BIiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiREVCVUciLCJBV1NfUFJPRklMRSI6IjxZb3VyIENMSSBQcm9maWxlIFtkZWZhdWx0XSBpZiBubyBwcm9maWxlIGlzIHVzZWQ%2BIn19) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=Prometheus%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.prometheus-mcp-server%40latest%22%2C%22--url%22%2C%22https%3A%2F%2Faps-workspaces.us-east-1.amazonaws.com%2Fworkspaces%2Fws-%3CWorkspace%20ID%3E%22%2C%22--region%22%2C%22%3CYour%20AWS%20Region%3E%22%2C%22--profile%22%2C%22%3CYour%20CLI%20Profile%20%5Bdefault%5D%20if%20no%20profile%20is%20used%3E%22%5D%2C%22env%22%3A%7B%22FASTMCP_LOG_LEVEL%22%3A%22DEBUG%22%2C%22AWS_PROFILE%22%3A%22%3CYour%20CLI%20Profile%20%5Bdefault%5D%20if%20no%20profile%20is%20used%3E%22%7D%7D) |\n| [AWS Well-Architected Security Assessment Tool MCP Server](src/well-architected-security-mcp-server) | Assess AWS environments against the Well-Architected Framework Security Pillar | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://cursor.com/en/install-mcp?name=awslabs.well-architected-security-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMud2VsbC1hcmNoaXRlY3RlZC1zZWN1cml0eS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0K) <br/>[![Install on VS Code](https://img.shields.io/badge/Install-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=AWS%20Well-Architected%20Security%20Assessment%20Tool%20MCP%20Server&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.well-architected-security-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22your-aws-profile%22%2C%22AWS_REGION%22%3A%22us-east-1%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22disabled%22%3Afalse%2C%22autoApprove%22%3A%5B%5D%7D) |\n| [AWS CloudTrail MCP Server](src/cloudtrail-mcp-server/) | CloudTrail events querying and analysis | [![Install](https://img.shields.io/badge/Install-Cursor-blue?style=flat-square&logo=cursor)](https://www.cursor.com/install-mcp?name=awslabs.cloudtrail-mcp-server&config=ewogICAgICAgICJjb21tYW5kIjogImRvY2tlciIsCiAgICAgICAgImFyZ3MiOiBbCiAgICAgICAgICAicnVuIiwKICAgICAgICAgICItLXJtIiwKICAgICAgICAgICItLWludGVyYWN0aXZlIiwKICAgICAgICAgICItZSBBV1NfUFJPRklMRT1bVGhlIEFXUyBQcm9maWxlIE5hbWVdIiwKICAgICAgICAgICJhd3NsYWJzL2Nsb3VkdHJhaWwtbWNwLXNlcnZlcjpsYXRlc3QiCiAgICAgICAgXSwKICAgICAgICAiZW52Ijoge30sCiAgICAgICAgImRpc2FibGVkIjogZmFsc2UsCiAgICAgICAgImF1dG9BcHByb3ZlIjogW10KfQ==) <br/>[![Install on VS Code](https://img.shields.io/badge/Install_on-VS_Code-FF9900?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=CloudTrail%20MCP%20Server&config=%7B%22autoApprove%22%3A%5B%5D%2C%22disabled%22%3Afalse%2C%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22awslabs.cloudtrail-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22AWS_PROFILE%22%3A%22%5BThe%20AWS%20Profile%20Name%20to%20use%20for%20AWS%20access%5D%22%2C%22FASTMCP_LOG_LEVEL%22%3A%22ERROR%22%7D%2C%22transportType%22%3A%22stdio%22%7D) |\n\n## MCP AWS Lambda Handler Module\n\nA Python library for creating serverless HTTP handlers for the Model Context Protocol (MCP) using AWS Lambda. This module provides a flexible framework for building MCP HTTP endpoints with pluggable session management, including built-in DynamoDB support.\n\n**Features:**\n\n- Easy serverless MCP HTTP handler creation using AWS Lambda\n- Pluggable session management system\n- Built-in DynamoDB session backend support\n- Customizable authentication and authorization\n- Example implementations and tests\n\nSee [`src/mcp-lambda-handler/README.md`](src/mcp-lambda-handler/README.md) for full usage, installation, and development instructions.\n\n## When to use Local vs Remote MCP Servers?\n\nAWS MCP servers can be run either locally on your development machine or remotely on the cloud. Here's when to use each approach:\n\n### Local MCP Servers\n- **Development & Testing**: Perfect for local development, testing, and debugging\n- **Offline Work**: Continue working when internet connectivity is limited\n- **Data Privacy**: Keep sensitive data and credentials on your local machine\n- **Low Latency**: Minimal network overhead for faster response times\n- **Resource Control**: Direct control over server resources and configuration\n\n### Remote MCP Servers\n- **Team Collaboration**: Share consistent server configurations across your team\n- **Resource Intensive Tasks**: Offload heavy processing to dedicated cloud resources\n- **Always Available**: Access your MCP servers from anywhere, any device\n- **Automatic Updates**: Get the latest features and security patches automatically\n- **Scalability**: Easily handle varying workloads without local resource constraints\n\n> **Note**: Some MCP servers, like AWS Knowledge MCP, are provided as fully managed services by AWS. These AWS-managed remote servers require no setup or infrastructure management on your part - just connect and start using them.\n\n## Use Cases for the Servers\n\nFor example, you can use the **AWS Documentation MCP Server** to help your AI assistant research and generate up-to-date code for any AWS service, like Amazon Bedrock Inline agents. Alternatively, you could use the **CDK MCP Server** or the **Terraform MCP Server** to have your AI assistant create infrastructure-as-code implementations that use the latest APIs and follow AWS best practices. With the **AWS Pricing MCP Server**, you could ask \"What would be the estimated monthly cost for this CDK project before I deploy it?\" or \"Can you help me understand the potential AWS service expenses for this infrastructure design?\" and receive detailed cost estimations and budget planning insights. The **Valkey MCP Server** enables natural language interaction with Valkey data stores, allowing AI assistants to efficiently manage data operations through a simple conversational interface.\n\n## Installation and Setup\n\nEach server has specific installation instructions with one-click installs for Cursor and VSCode. Generally, you can:\n\n1. Install `uv` from [Astral](https://docs.astral.sh/uv/getting-started/installation/)\n2. Install Python using `uv python install 3.10`\n3. Configure AWS credentials with access to required services\n4. Add the server to your MCP client configuration\n\nExample configuration for Amazon Q CLI MCP (`~/.aws/amazonq/mcp.json`):\n\n### For macOS/Linux\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.core-mcp-server@latest\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n\nSee individual server READMEs for specific requirements and configuration options.\n\n### For Windows\n\nWhen configuring MCP servers on Windows, you'll need to use a slightly different configuration format:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"tool\",\n        \"run\",\n        \"--from\",\n        \"awslabs.core-mcp-server@latest\",\n        \"awslabs.core-mcp-server.exe\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n\nIf you have problems with MCP configuration or want to check if the appropriate parameters are in place, you can try the following:\n\n```shell\n# Run MCP server manually with timeout 15s\n$ timeout 15s uv tool run <MCP Name> <args> 2>&1 || echo \"Command completed or timed out\"\n\n# Example (Aurora MySQL MCP Server)\n$ timeout 15s uv tool run awslabs.mysql-mcp-server --resource_arn <Your Resource ARN> --secret_arn <Your Secret ARN> ... 2>&1 || echo \"Command completed or timed out\"\n\n# If the arguments are not set appropriately, you may see the following message:\nusage: awslabs.mysql-mcp-server [-h] --resource_arn RESOURCE_ARN --secret_arn SECRET_ARN --database DATABASE\n                                --region REGION --readonly READONLY\nawslabs.mysql-mcp-server: error: the following arguments are required: --resource_arn, --secret_arn, --database, --region, --readonly\n```\n\n**Note about performance when using `uvx` *\"@latest\"* suffix:**\n\nUsing the *\"@latest\"* suffix checks and downloads the latest MCP server package from pypi every time you start your MCP clients, but it comes with a cost of increased initial load times. If you want to minimize the initial load time, remove *\"@latest\"* and manage your uv cache yourself using one of these approaches:\n\n- `uv cache clean <tool>`: where {tool} is the mcp server you want to delete from cache and install again (e.g.: \"awslabs.lambda-tool-mcp-server\") (remember to remove the '<>').\n- `uvx <tool>@latest`: this will refresh the tool with the latest version and add it to the uv cache.\n\n### Running MCP servers in containers\n\nDocker images for each MCP server are published to the [public AWS ECR registry](https://gallery.ecr.aws/awslabs-mcp).\n\n*This example uses docker with the \"awslabs.nova-canvas-mcp-server and can be repeated for each MCP server*\n\n- Optionally save sensitive environmental variables in a file:\n\n  ```.env\n  # contents of a .env file with fictitious AWS temporary credentials\n  AWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\n  AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n  AWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\n  ```\n\n- Use the docker options: `--env`, `--env-file`, and `--volume` as needed because the `\"env\": {}` are not available within the container.\n\n  ```json\n  {\n    \"mcpServers\": {\n      \"awslabs.nova-canvas-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"--env\",\n          \"AWS_REGION=us-east-1\",\n          \"--env-file\",\n          \"/full/path/to/.env\",\n          \"--volume\",\n          \"/full/path/to/.aws:/app/.aws\",\n          \"public.ecr.aws/awslabs-mcp/awslabs/nova-canvas-mcp-server:latest\"\n        ],\n        \"env\": {}\n      }\n    }\n  }\n  ```\n\n- For testing local changes you can build and tag the image. You have to update the MCP configuration to use this tag instead of the ECR image.\n\n  ```base\n  cd src/nova-canvas-mcp-server\n  docker build -t awslabs/nova-canvas-mcp-server .\n  ```\n\n### Getting Started with Amazon Q Developer CLI\n\n<details>\n<summary>Install in Amazon Q Developer CLI</summary>\n\nSee [Amazon Q Developer CLI documentation](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-mcp-config-CLI.html) for details.\n\n\n1. **Access MCP Settings**\n   - Open the Q Developer panel and open the **Chat** panel.\n   - Choose the tools icon to access to MCP configuration.\n\n2. **Add MCP Servers**\n   - Choose the plus (+) symbol.\n   - Select the scope: global or local.\n    If you select global scope, the MCP server configuration is stored in ~/.aws/amazonq/mcp.json and available across all your projects. If you select local scope, the configuration is stored in .amazonq/mcp.json within your current project.\n   - Fill in values as applicable.\n\n3. **Manual Configuration**\n   - You can also manually edit the MCP configuration file located at `~/.aws/amazonq/mcp.json` globally or `.amazonq/mcp.json` locally.\n\n#### `~/.aws/amazonq/mcp.json`\n\nFor macOS/Linux:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.core-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n\nFor Windows:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"tool\",\n        \"run\",\n        \"--from\",\n        \"awslabs.core-mcp-server@latest\",\n        \"awslabs.core-mcp-server.exe\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n</details>\n\n\n### Getting Started with Kiro\n\n<details>\n<summary>Install in Kiro</summary>\n\nSee [Kiro Model Context Protocol Documentation](https://kiro.dev/docs/mcp/configuration/) for details.\n\n1. Navigate `Kiro` > `MCP Servers`\n2. Add a new MCP server by clicking the `+ Add` button.\n3. Paste the configuration given below:\n\n#### `kiro_mcp_settings.json`\n\nFor macOS/Linux:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.core-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n\nFor Windows:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"tool\",\n        \"run\",\n        \"--from\",\n        \"awslabs.core-mcp-server@latest\",\n        \"awslabs.core-mcp-server.exe\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n\n</details>\n\n### Getting Started with Cline and Amazon Bedrock\n\n<details>\n<summary>Getting Started with Cline and Amazon Bedrock</summary>\n\n**IMPORTANT:** Following these instructions may incur costs and are subject to the [Amazon Bedrock Pricing](https://aws.amazon.com/bedrock/pricing/). You are responsible for any associated costs. In addition to selecting the desired model in the Cline settings, ensure you have your selected model (e.g. `anthropic.claude-3-7-sonnet`) also enabled in Amazon Bedrock. For more information on this, see [these AWS docs](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access-modify.html) on enabling model access to Amazon Bedrock Foundation Models (FMs).\n\n1. Follow the steps above in the **Installation and Setup** section to install `uv` from [Astral](https://docs.astral.sh/uv/getting-started/installation/), install Python, and configure AWS credentials with the required services.\n\n2. If using Visual Studio Code, install the [Cline VS Code Extension](https://marketplace.visualstudio.com/items?itemName=saoudrizwan.claude-dev) (or equivalent extension for your preferred IDE). Once installed, click the extension to open it. When prompted, select the tier that you wish. In this case, we will be using Amazon Bedrock, so the free tier of Cline is fine as we will be sending requests using the Amazon Bedrock API instead of the Cline API.\n\n<p align=\"center\">\n  <img src=\"./docs/images/root-readme/install-cline-extension.png\" width=\"800\" height=\"400\"  />\n<p>\n\n3. Select the **MCP Servers** button.\n\n<p align=\"center\">\n  <img src=\"./docs/images/root-readme/select-mcp-servers.png\" width=\"500\" height=\"800\"  />\n<p>\n\n4. Select the **Installed** tab, then click **Configure MCP Servers** to open the `cline_mcp_settings.json` file.\n\n <p align=\"center\">\n   <img src=\"./docs/images/root-readme/configure-mcp-servers.png\" width=\"500\" height=\"800\"  />\n <p>\n\n 5. In the `cline_mcp_settings.json` file, add your desired MCP servers in the `mcpServers` object. See the following example that will use some of the current AWS MCP servers that are available in this repository. Ensure you save the file to install the MCP servers.\n\n#### `cline_mcp_settings.json`\n\nFor macOS/Linux:\n\n ```json\n {\n   \"mcpServers\": {\n     \"awslabs.core-mcp-server\": {\n       \"command\": \"uvx\",\n       \"args\": [\"awslabs.core-mcp-server@latest\"],\n       \"env\": {\n         \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n         \"MCP_SETTINGS_PATH\": \"path to your mcp settings file\"\n       }\n     }\n    }\n  }\n ```\n\nFor Windows:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"tool\",\n        \"run\",\n        \"--from\",\n        \"awslabs.core-mcp-server@latest\",\n        \"awslabs.core-mcp-server.exe\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"MCP_SETTINGS_PATH\": \"path to your mcp settings file\"\n      }\n    }\n  }\n}\n```\n\n6. Once installed, you should see a list of your MCP Servers under the MCP Server Installed tab, and they should have a green slider to show that they are enabled. See the following for an example with two of the possible AWS MCP Servers. Click **Done** when finished. You should now see the Cline chat interface.\n\n<p align=\"center\">\n  <img src=\"./docs/images/root-readme/mcp-servers-installed.png\" width=\"500\" height=\"800\"  />\n<p>\n\n<p align=\"center\">\n  <img src=\"./docs/images/root-readme/cline-chat-interface.png\" width=\"500\" height=\"800\"  />\n<p>\n\n7. By default, Cline will be set as the API provider, which has limits for the free tier. Next, let's update the API provider to be AWS Bedrock, so we can use the LLMs through Bedrock, which would have billing go through your connected AWS account.\n\n8. Click the settings gear to open up the Cline settings. Then under **API Provider**, switch this from `Cline` to `AWS Bedrock` and select `AWS Profile` for the authentication type. As a note, the `AWS Credentials` option works as well, however it uses a static credentials (Access Key ID and Secret Access Key) instead of temporary credentials that are automatically redistributed when the token expires, so the temporary credentials with an AWS Profile is the more secure and recommended method.\n\n<p align=\"center\">\n  <img src=\"./docs/images/root-readme/cline-select-bedrock.png\" width=\"500\" height=\"800\"  />\n<p>\n\n9. Fill out the configuration based on the existing AWS Profile you wish to use, select the desired AWS Region, and enable cross-region inference.\n\n<p align=\"center\">\n  <img src=\"./docs/images/root-readme/cline-select-aws-profile.png\" width=\"500\" height=\"800\"  />\n<p>\n\n<p align=\"center\">\n  <img src=\"./docs/images/root-readme/cline-api-provider-filled.png\" width=\"500\" height=\"800\"  />\n<p>\n\n10. Next, scroll down on the settings page until you reach the text box that says Custom Instructions. Paste in the following snippet to ensure the `mcp-core` server is used as the starting point for every prompt:\n\n```\nFor every new project, always look at your MCP servers and use mcp-core as the starting point every time. Also after a task completion include the list of MCP servers used in the operation.\n```\n\n<p align=\"center\">\n  <img src=\"./docs/images/root-readme/cline-custom-instructions.png\" width=\"500\" height=\"800\"  />\n<p>\n\n11. Once the custom prompt is pasted in, click **Done** to return to the chat interface.\n\n12. Now you can begin asking questions and testing out the functionality of your installed AWS MCP Servers. The default option in the chat interface is is `Plan` which will provide the output for you to take manual action on (e.g. providing you a sample configuration that you copy and paste into a file). However, you can optionally toggle this to `Act` which will allow Cline to act on your behalf (e.g. searching for content using a web browser, cloning a repository, executing code, etc). You can optionally toggle on the \"Auto-approve\" section to avoid having to click to approve the suggestions, however we recommend leaving this off during testing, especially if you have the Act toggle selected.\n\n**Note:** For the best results, please prompt Cline to use the desired AWS MCP Server you wish to use. For example, `Using the Terraform MCP Server, do...`\n</details>\n\n### Getting Started with Cursor\n\n<details>\n<summary>Getting Started with Cursor</summary>\n\n1. Follow the steps above in the **Installation and Setup** section to install `uv` from [Astral](https://docs.astral.sh/uv/getting-started/installation/), install Python, and configure AWS credentials with the required services.\n\n2. You can place MCP configuration in two locations, depending on your use case:\n\n  A. **Project Configuration**\n    - For tools specific to a project, create a `.cursor/mcp.json` file in your project directory.\n    - This allows you to define MCP servers that are only available within that specific project.\n\n  B. **Global Configuration**\n    - For tools that you want to use across all projects, create a `~/.cursor/mcp.json` file in your home directory.\n    - This makes MCP servers available in all your Cursor workspaces.\n\n#### `.cursor/mcp.json`\n\nFor macOS/Linux:\n\n```json\n {\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.core-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n\nFor Windows:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"tool\",\n        \"run\",\n        \"--from\",\n        \"awslabs.core-mcp-server@latest\",\n        \"awslabs.core-mcp-server.exe\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n\n3. **Using MCP in Chat** The Composer Agent will automatically use any MCP tools that are listed under Available Tools on the MCP settings page if it determines them to be relevant. To prompt tool usage intentionally, please prompt Cursor to use the desired AWS MCP Server you wish to use. For example, `Using the Terraform MCP Server, do...`\n\n4. **Tool Approval** By default, when Agent wants to use an MCP tool, it will display a message asking for your approval. You can use the arrow next to the tool name to expand the message and see what arguments the Agent is calling the tool with.\n\n</details>\n\n### Getting Started with Windsurf\n\n<details>\n<summary>Getting Started with Windsurf</summary>\n\n1. Follow the steps above in the **Installation and Setup** section to install `uv` from [Astral](https://docs.astral.sh/uv/getting-started/installation/), install Python, and configure AWS credentials with the required services.\n\n2. **Access MCP Settings**\n   - Navigate to Windsurf - Settings > Advanced Settings or use the Command Palette > Open Windsurf Settings Page\n   - Look for the \"Model Context Protocol (MCP) Servers\" section\n\n3. **Add MCP Servers**\n   - Click \"Add Server\" to add a new MCP server\n   - You can choose from available templates like GitHub, Puppeteer, PostgreSQL, etc.\n   - Alternatively, click \"Add custom server\" to configure your own server\n\n4. **Manual Configuration**\n   - You can also manually edit the MCP configuration file located at `~/.codeium/windsurf/mcp_config.json`\n\n#### `~/.codeium/windsurf/mcp_config.json`\n\nFor macOS/Linux:\n\n ```json\n {\n   \"mcpServers\": {\n     \"awslabs.core-mcp-server\": {\n       \"command\": \"uvx\",\n       \"args\": [\"awslabs.core-mcp-server@latest\"],\n       \"env\": {\n         \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n         \"MCP_SETTINGS_PATH\": \"path to your mcp settings file\"\n       }\n     }\n    }\n  }\n ```\n\nFor Windows:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"tool\",\n        \"run\",\n        \"--from\",\n        \"awslabs.core-mcp-server@latest\",\n        \"awslabs.core-mcp-server.exe\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"MCP_SETTINGS_PATH\": \"path to your mcp settings file\"\n      }\n    }\n  }\n}\n```\n\n</details>\n\n### Getting Started with VS Code\n\n<details>\n<summary>Install in VS Code</summary>\n\nConfigure MCP servers in VS Code settings or in `.vscode/mcp.json` (see [VS Code MCP docs](https://code.visualstudio.com/docs/copilot/chat/mcp-servers) for more info.):\n\n#### `.vscode/mcp.json`\n\nFor macOS/Linux:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.core-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n\nFor Windows:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"tool\",\n        \"run\",\n        \"--from\",\n        \"awslabs.core-mcp-server@latest\",\n        \"awslabs.core-mcp-server.exe\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n```\n</details>\n\n### Getting Started with Claude Code\n\n<details>\n<summary>Install in Claude Code</summary>\n\nConfigure MCP servers in Claude Code through the CLI or in `.mcp.json`\n\n1. Follow the steps above in the **Installation and Setup** section to install `uv` from [Astral](https://docs.astral.sh/uv/getting-started/installation/), install Python, and configure AWS credentials with the required services.\n\n2. **Using Claude Code CLI Commands**\n\n   Claude Code CLI commands to add MCP servers:\n\n   ```bash\n   # Add core AWS services\n   claude mcp add aws-api uvx awslabs.aws-api-mcp-server@latest\n   claude mcp add aws-cdk uvx awslabs.cdk-mcp-server@latest\n   claude mcp add aws-docs uvx awslabs.aws-documentation-mcp-server@latest\n   claude mcp add aws-support uvx awslabs.aws-support-mcp-server@latest\n   claude mcp add aws-pricing uvx awslabs.aws-pricing-mcp-server@latest\n\n   # Add AI/ML and Bedrock services\n   claude mcp add bedrock-kb uvx awslabs.bedrock-kb-retrieval-mcp-server@latest\n   claude mcp add nova-canvas uvx awslabs.nova-canvas-mcp-server@latest\n   claude mcp add synthetic-data uvx awslabs.syntheticdata-mcp-server@latest\n\n   # Add data and analytics services\n   claude mcp add aws-dataprocessing uvx awslabs.aws-dataprocessing-mcp-server@latest\n   claude mcp add aurora-dsql uvx awslabs.aurora-dsql-mcp-server@latest\n   claude mcp add valkey uvx awslabs.valkey-mcp-server@latest\n\n   # List installed servers\n   claude mcp list\n   ```\n\n3. **Manual Configuration (Alternative)**\n\n   You can also manually configure MCP servers by creating a `.mcp.json` file in your project root:\n\n#### `.mcp.json`\n\nFor macOS/Linux:\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.cdk-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.cdk-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    },\n    \"awslabs.aws-documentation-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.aws-documentation-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"AWS_DOCUMENTATION_PARTITION\": \"aws\"\n      }\n    }\n  }\n}\n```\n</details>\n\n## Samples\n\nReady-to-use examples of AWS MCP Servers in action are available in the [samples](samples/) directory. These samples provide working code and step-by-step guides to help you get started with each MCP server.\n\n## Vibe coding\n\nYou can use these MCP servers with your AI coding assistant to [vibe code](https://en.wikipedia.org/wiki/Vibe_coding). For tips and tricks on how to improve your vibe coding experience, please refer to our [guide](./VIBE_CODING_TIPS_TRICKS.md).\n\n## Additional Resources\n\n- [Introducing AWS MCP Servers for code assistants](https://aws.amazon.com/blogs/machine-learning/introducing-aws-mcp-servers-for-code-assistants-part-1/)\n- [Vibe coding with AWS MCP Servers | AWS Show & Tell](https://www.youtube.com/watch?v=qXGQQRMrcz0)\n- [Supercharging AWS database development with AWS MCP servers](https://aws.amazon.com/blogs/database/supercharging-aws-database-development-with-aws-mcp-servers/)\n- [AWS costs estimation using Amazon Q CLI and AWS Pricing MCP Server](https://aws.amazon.com/blogs/machine-learning/aws-costs-estimation-using-amazon-q-cli-and-aws-cost-analysis-mcp/)\n- [Introducing AWS Serverless MCP Server: AI-powered development for modern applications](https://aws.amazon.com/blogs/compute/introducing-aws-serverless-mcp-server-ai-powered-development-for-modern-applications/)\n- [Announcing new Model Context Protocol (MCP) Servers for AWS Serverless and Containers](https://aws.amazon.com/about-aws/whats-new/2025/05/new-model-context-protocol-servers-aws-serverless-containers/)\n- [Accelerating application development with the Amazon EKS MCP server](https://aws.amazon.com/blogs/containers/accelerating-application-development-with-the-amazon-eks-model-context-protocol-server/)\n- [Amazon Neptune announces MCP (Model Context Protocol) Server](https://aws.amazon.com/about-aws/whats-new/2025/05/amazon-neptune-mcp-server/)\n- [Terraform MCP Server Vibe Coding](https://youtu.be/i2nBD65md0Y)\n- [How to Generate AWS Architecture Diagrams Using Amazon Q CLI and MCP](https://community.aws/content/2vPiiPiBSdRalaEax2rVDtshpf3/how-to-generate-aws-architecture-diagrams-using-amazon-q-cli-and-mcp)\n- [Harness the power of MCP servers with Amazon Bedrock Agents](https://aws.amazon.com/blogs/machine-learning/harness-the-power-of-mcp-servers-with-amazon-bedrock-agents/)\n- [Unlocking the power of Model Context Protocol (MCP) on AWS](https://aws.amazon.com/blogs/machine-learning/unlocking-the-power-of-model-context-protocol-mcp-on-aws/)\n- [AWS Price List Gets a Natural Language Upgrade: Introducing the AWS Pricing MCP Server](https://aws.amazon.com/blogs/aws-cloud-financial-management/aws-price-list-gets-a-natural-language-upgrade-introducing-the-aws-pricing-mcp-server/)\n- [AWS SheBuilds: AWS Team's Journey from Internal Tools to Open Source AI Infrastructure](https://www.youtube.com/watch?v=DZFgufNCvAo)\n\n## Security\n\nSee [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.\n\n## Contributing\n\nBig shout out to our awesome contributors! Thank you for making this project better!\n\n[![contributors](https://contrib.rocks/image?repo=awslabs/mcp&max=2000)](https://github.com/awslabs/mcp/graphs/contributors)\n\nContributions of all kinds are welcome! Check out our [contributor guide](CONTRIBUTING.md) for more information.\n\n## Developer guide\n\nIf you want to add a new MCP Server to the library, check out our [development guide](DEVELOPER_GUIDE.md) and be sure to follow our [design guidelines](DESIGN_GUIDELINES.md).\n\n## License\n\nThis project is licensed under the Apache-2.0 License.\n\n## Disclaimer\n\nBefore using an MCP Server, you should consider conducting your own independent assessment to ensure that your use would comply with your own specific security and quality control practices and standards, as well as the laws, rules, and regulations that govern you and your content.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "bendusy--pollinations-mcp": {
      "owner": "bendusy",
      "name": "pollinations-mcp",
      "url": "https://github.com/bendusy/pollinations-mcp",
      "imageUrl": "https://github.com/bendusy.png",
      "description": "Connects AI models to Pollinations.ai's services for generating images and text via the MCP protocol. Facilitates seamless interaction with Pollinations.ai's API for image generation, downloading images, and text generation.",
      "stars": 8,
      "forks": 5,
      "license": "Apache License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-09-04T11:40:45Z",
      "readme_content": "# Pollinations MCP æœåŠ¡å™¨\n\n<div align=\"center\">\n  <img src=\"./icon.png\" alt=\"Pollinations MCP æœåŠ¡å™¨å›¾æ ‡\" width=\"200\">\n</div>\n\nè¿™æ˜¯ä¸€ä¸ªåŸºäº[Model Context Protocol (MCP)](https://github.com/microsoft/modelcontextprotocol)çš„æœåŠ¡å™¨å®ç°ï¼Œç”¨äºè¿æ¥[Pollinations.ai](https://pollinations.ai)æœåŠ¡çš„APIæ¥å£ã€‚è¯¥æœåŠ¡å™¨å…è®¸AIæ¨¡å‹é€šè¿‡MCPåè®®è°ƒç”¨Pollinations.aiçš„å›¾åƒå’Œæ–‡æœ¬ç”ŸæˆåŠŸèƒ½ã€‚\n\n## åŠŸèƒ½ç‰¹ç‚¹\n\n- æ”¯æŒé€šè¿‡MCPåè®®ä¸Pollinations.aiæœåŠ¡äº¤äº’\n- æä¾›ä¸‰ä¸ªä¸»è¦å·¥å…·ï¼š\n  - `generate_image`: ä½¿ç”¨Pollinations.aiç”Ÿæˆå›¾åƒå¹¶è¿”å›URLï¼ˆé»˜è®¤æ— æ°´å°ï¼‰\n  - `download_image`: ä¸‹è½½ç”Ÿæˆçš„å›¾åƒåˆ°æœ¬åœ°æ–‡ä»¶\n  - `generate_text`: ä½¿ç”¨Pollinations.aiç”Ÿæˆæ–‡æœ¬\n- åŸºäºTypeScriptå®ç°ï¼Œæ”¯æŒç±»å‹å®‰å…¨\n- ä½¿ç”¨stdioä¼ è¾“æœºåˆ¶ï¼Œä¾¿äºä¸AIæ¨¡å‹é›†æˆ\n\n## å®‰è£…\n\n1. å…‹éš†ä»“åº“ï¼š\n\n```bash\ngit clone https://github.com/bendusy/pollinations-mcp.git\ncd pollinations-mcp\n```\n\n2. å®‰è£…ä¾èµ–ï¼š\n\n```bash\nnpm install\n```\n\n3. æ„å»ºé¡¹ç›®ï¼š\n\n```bash\nnpm run build\n```\n\n## ä½¿ç”¨æ–¹æ³•\n\n### ä½œä¸ºMCPæœåŠ¡å™¨è¿è¡Œ\n\n```bash\nnpm start\n```\n\næœåŠ¡å™¨å°†é€šè¿‡æ ‡å‡†è¾“å…¥/è¾“å‡º(stdio)å¯åŠ¨ï¼Œç­‰å¾…MCPå®¢æˆ·ç«¯è¿æ¥ã€‚\n\n### åœ¨Cursorä¸­ä½¿ç”¨ï¼ˆå½“å‰å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œï¼‰\n\n**æ³¨æ„ï¼š** ç›®å‰åœ¨Cursorä¸­é…ç½®æ­¤æœåŠ¡å™¨å¯èƒ½ä¸ä¼šæˆåŠŸã€‚å¦‚æœæ‚¨éœ€è¦ä½¿ç”¨æ­¤åŠŸèƒ½ï¼Œå»ºè®®ä½¿ç”¨Clineï¼ˆè§ä¸‹æ–‡ï¼‰ã€‚\n\n### åœ¨Clineä¸­ä½¿ç”¨ï¼ˆæ¨èï¼‰\n\n[Cline](https://cline.app)æ˜¯ä¸€ä¸ªæ”¯æŒMCPåè®®çš„AIç»ˆç«¯ï¼Œå¯ä»¥æˆåŠŸä½¿ç”¨æœ¬æœåŠ¡å™¨æä¾›çš„å›¾åƒç”ŸæˆåŠŸèƒ½ã€‚è®¾ç½®æ­¥éª¤å¦‚ä¸‹ï¼š\n\n1. å®‰è£…å¹¶å¯åŠ¨Cline\n2. æ‰“å¼€Clineçš„è®¾ç½®æ–‡ä»¶ï¼Œé€šå¸¸ä½äºï¼š\n   - Windows: `%APPDATA%\\Cline\\config.json`\n   - Mac: `~/Library/Application Support/Cline/config.json`\n   - Linux: `~/.config/Cline/config.json`\n\n3. åœ¨é…ç½®æ–‡ä»¶ä¸­æ‰¾åˆ°æˆ–æ·»åŠ `mcpServers`éƒ¨åˆ†ï¼Œç„¶åæ·»åŠ ä»¥ä¸‹é…ç½®ï¼š\n\n```json\n\"mcpServers\": {\n  \"pollinations-mcp\": {\n    \"command\": \"node\",\n    \"args\": [\n      \"å®Œæ•´è·¯å¾„/åˆ°æ‚¨çš„/pollinations-mcp/dist/index.js\"\n    ],\n    \"disabled\": false,\n    \"autoApprove\": [\n      \"download_image\",\n      \"generate_image\",\n      \"generate_text\"\n    ]\n  }\n}\n```\n\nä¾‹å¦‚ï¼ŒWindowsç³»ç»Ÿä¸Šçš„å®Œæ•´é…ç½®å¯èƒ½å¦‚ä¸‹ï¼š\n\n```json\n\"mcpServers\": {\n  \"pollinations-mcp\": {\n    \"command\": \"node\",\n    \"args\": [\n      \"C:\\\\Users\\\\ç”¨æˆ·å\\\\è·¯å¾„\\\\åˆ°\\\\pollinations-mcp\\\\dist\\\\index.js\"\n    ],\n    \"disabled\": false,\n    \"autoApprove\": [\n      \"download_image\",\n      \"generate_image\",\n      \"generate_text\"\n    ]\n  }\n}\n```\n\n4. ä¿å­˜é…ç½®æ–‡ä»¶å¹¶é‡å¯Cline\n5. ç°åœ¨æ‚¨å¯ä»¥åœ¨Clineä¸­ä½¿ç”¨Pollinationså›¾åƒç”ŸæˆåŠŸèƒ½äº†ï¼Œä¾‹å¦‚ï¼š\n\n```\nä½¿ç”¨Pollinationsç”Ÿæˆå›¾åƒï¼šbeautiful sunset over ocean with palm trees\n```\n\n### ä¸AIæ¨¡å‹é›†æˆ\n\næœ¬æœåŠ¡å™¨è®¾è®¡ç”¨äºä¸æ”¯æŒMCPåè®®çš„AIæ¨¡å‹é›†æˆï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆå›¾åƒã€‚\n\n### æ”¯æŒçš„å·¥å…·\n\n#### generate_image\n\nä½¿ç”¨Pollinations.aiç”Ÿæˆå›¾åƒå¹¶è¿”å›URLã€‚\n\nå‚æ•°ï¼š\n- `prompt` (å¿…éœ€): å›¾åƒæè¿°æç¤ºè¯\n- `width` (å¯é€‰): å›¾åƒå®½åº¦ï¼ˆåƒç´ ï¼‰ï¼Œé»˜è®¤ä¸º1024\n- `height` (å¯é€‰): å›¾åƒé«˜åº¦ï¼ˆåƒç´ ï¼‰ï¼Œé»˜è®¤ä¸º1024\n- `seed` (å¯é€‰): éšæœºç§å­å€¼ï¼ˆç”¨äºç”Ÿæˆä¸€è‡´çš„å›¾åƒï¼‰\n- `model` (å¯é€‰): è¦ä½¿ç”¨çš„æ¨¡å‹ï¼Œé»˜è®¤ä¸º'flux'\n- `nologo` (å¯é€‰): è®¾ç½®ä¸ºtrueå¯å»é™¤æ°´å°ï¼Œé»˜è®¤ä¸ºtrue\n- `enhance` (å¯é€‰): æé«˜å›¾åƒè´¨é‡ï¼ˆåº”ç”¨å¢å¼ºæ»¤é•œï¼‰ï¼Œé»˜è®¤ä¸ºfalse\n- `safe` (å¯é€‰): å¯ç”¨å®‰å…¨è¿‡æ»¤ï¼ˆè¿‡æ»¤ä¸é€‚å†…å®¹ï¼‰ï¼Œé»˜è®¤ä¸ºfalse\n- `private` (å¯é€‰): è®¾ç½®ä¸ºtrueå¯ä½¿å›¾åƒç§æœ‰ï¼ˆä¸åœ¨å…¬å…±feedä¸­æ˜¾ç¤ºï¼‰ï¼Œé»˜è®¤ä¸ºfalse\n\n**æç¤ºè¯æœ€ä½³å®è·µï¼š**\n- å°½é‡ä½¿ç”¨è‹±æ–‡ç¼–å†™æç¤ºè¯ï¼ŒPollinations.aiå¯¹è‹±æ–‡çš„ç†è§£æ›´å¥½\n- ä¿æŒæç¤ºè¯ç®€çŸ­ç²¾ç¡®ï¼Œé¿å…è¿‡é•¿æˆ–æ¨¡ç³Šçš„æè¿°\n- ä½¿ç”¨å…·ä½“çš„å½¢å®¹è¯å’Œåè¯ï¼Œè€ŒéæŠ½è±¡æ¦‚å¿µ\n- ä¾‹å¦‚ï¼š\"beautiful sunset over ocean with palm trees\"æ¯”\"ä¸€å¼ æ—¥è½çš„å›¾ç‰‡\"æ•ˆæœæ›´å¥½\n\n#### download_image\n\nä¸‹è½½Pollinations.aiç”Ÿæˆçš„å›¾åƒåˆ°æœ¬åœ°æ–‡ä»¶ã€‚\n\nå‚æ•°ï¼š\n- `url` (å¿…éœ€): è¦ä¸‹è½½çš„å›¾åƒURL\n- `output_path` (å¯é€‰): ä¿å­˜å›¾åƒçš„è·¯å¾„ï¼ˆåŒ…æ‹¬æ–‡ä»¶åï¼‰ï¼Œé»˜è®¤ä¸º'image.jpg'\n\n#### generate_text\n\nä½¿ç”¨Pollinations.aiç”Ÿæˆæ–‡æœ¬ã€‚\n\nå‚æ•°ï¼š\n- `prompt` (å¿…éœ€): æ–‡æœ¬æç¤ºè¯\n- `model` (å¯é€‰): è¦ä½¿ç”¨çš„æ¨¡å‹ï¼ˆå¦‚openaiã€mistralç­‰ï¼‰ï¼Œé»˜è®¤ä¸º'openai'\n- `seed` (å¯é€‰): éšæœºç§å­å€¼ï¼ˆç”¨äºç”Ÿæˆä¸€è‡´çš„ç»“æœï¼‰\n- `system` (å¯é€‰): ç³»ç»Ÿæç¤ºè¯ï¼ˆè®¾ç½®AIè¡Œä¸ºï¼‰\n- `json` (å¯é€‰): æ˜¯å¦è¿”å›JSONæ ¼å¼çš„å“åº”ï¼Œé»˜è®¤ä¸ºfalse\n- `private` (å¯é€‰): è®¾ç½®ä¸ºtrueå¯ä½¿å“åº”ç§æœ‰ï¼Œé»˜è®¤ä¸ºfalse\n\n## APIå‚è€ƒ\n\næœ¬é¡¹ç›®ä½¿ç”¨Pollinations.aiçš„å®˜æ–¹APIã€‚å®Œæ•´çš„APIæ–‡æ¡£è¯·å‚è€ƒï¼š[Pollinations APIæ–‡æ¡£](https://github.com/pollinations/pollinations/blob/master/APIDOCS.md)\n\n### å›¾åƒç”ŸæˆAPI\n\nåŸºæœ¬æ ¼å¼ï¼š`https://image.pollinations.ai/prompt/{prompt}?{å‚æ•°}`\n\nç¤ºä¾‹ï¼š\n```\nhttps://image.pollinations.ai/prompt/beautiful%20sunset?width=1024&height=1024&nologo=true\n```\n\n### å¯ç”¨çš„å›¾åƒæ¨¡å‹\n\n- `flux` (é»˜è®¤): ä¸»æµæ–‡ç”Ÿå›¾æ¨¡å‹ï¼ŒåŠŸèƒ½å…¨é¢\n- `variation`: å›¾åƒå˜ä½“ç”Ÿæˆ\n- `dreamshaper`: æ¢¦å¹»é£æ ¼\n- `anything`: åŠ¨æ¼«é£æ ¼å›¾åƒ\n- `pixart`: é«˜è´¨é‡æ’å›¾é£æ ¼\n\n### æ–‡æœ¬ç”ŸæˆAPI\n\nåŸºæœ¬æ ¼å¼ï¼š`https://text.pollinations.ai/{prompt}?{å‚æ•°}`\n\nç¤ºä¾‹ï¼š\n```\nhttps://text.pollinations.ai/Tell%20me%20about%20artificial%20intelligence?model=openai\n```\n\n### å¯ç”¨çš„æ–‡æœ¬æ¨¡å‹\n\n- `openai` (é»˜è®¤): OpenAIæ¨¡å‹\n- `mistral`: Mistralæ¨¡å‹\n- `gemini`: Google Geminiæ¨¡å‹\n\n## å¼€å‘\n\n### é¡¹ç›®ç»“æ„\n\n- `src/index.ts`: ä¸»æœåŠ¡å™¨å®ç°\n- `dist/`: ç¼–è¯‘åçš„JavaScriptæ–‡ä»¶\n- `package.json`: é¡¹ç›®é…ç½®å’Œä¾èµ–\n\n### ä¾èµ–\n\n- `@modelcontextprotocol/sdk`: MCPåè®®SDK\n- `axios`: HTTPå®¢æˆ·ç«¯ï¼Œç”¨äºä¸‹è½½å›¾åƒ\n- `typescript`: TypeScriptç¼–è¯‘å™¨\n\n## è®¸å¯\n\næœ¬é¡¹ç›®é‡‡ç”¨ISCè®¸å¯è¯ã€‚è¯¦æƒ…è¯·å‚é˜…[LICENSE](LICENSE)æ–‡ä»¶ã€‚\n\n## ç›¸å…³é“¾æ¥\n\n- [Pollinations.ai](https://pollinations.ai)\n- [Model Context Protocol](https://github.com/microsoft/modelcontextprotocol)",
      "npm_url": "",
      "npm_downloads": 0
    },
    "beordle--tinypng-mcp-server": {
      "owner": "beordle",
      "name": "tinypng-mcp-server",
      "url": "https://github.com/beordle/tinypng-mcp-server",
      "imageUrl": "https://github.com/beordle.png",
      "description": "Compress images efficiently using the TinyPNG API. Supports both local and remote image compression with minimal setup required.",
      "stars": 0,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "",
      "updated_at": "2025-03-31T16:01:05Z",
      "readme_content": "## MCP server for TinyPNG\n\n### Usage\n\n### Use `bun` or `node` to run the server\n\n1. Install dependencies and build\n\n```bash\npnpm i\npnpm build\n```\n\n2. Edit the `mcp.json` file\n\n```json\n{\n  \"mcpServers\": {\n    \"tinypng\": {\n      \"command\": \"bun\", // or \"node\"\n      \"args\": [\"/path/to/tinypng-mcp-server/src/index.ts\"], // or \"dist/index.js\"\n      \"env\": {\n        \"TINYPNG_API_KEY\": \"your-tinypng-api-key\"\n      }\n    }\n  }\n}\n```\n\n### Tools\n\n1. Compress local image\n\n```js\n{\n  name: 'compress_local_image',\n  description: 'Compress a local image file',\n  inputSchema: {\n    type: 'object',\n    properties: {\n      imagePath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to the image file to compress',\n        example: '/Users/user/Downloads/image.jpg',\n      },\n      outputPath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to save the compressed image file',\n        example: '/Users/user/Downloads/image_compressed.jpg',\n      },\n      outputFormat: {\n        type: 'string',\n        description: 'The format to save the compressed image file',\n        enum: SUPPORTED_IMAGE_TYPES,\n        example: 'image/jpeg',\n      },\n    },\n    required: ['imagePath'],\n  },\n}\n```\n\n2. Compress remote image\n\n```js\n{\n  name: 'compress_remote_image',\n  description: 'Compress a remote image file by giving the URL of the image',\n  inputSchema: {\n    type: 'object',\n    properties: {\n      imageUrl: {\n        type: 'string',\n        description: 'The URL of the image file to compress',\n        example: 'https://example.com/image.jpg',\n      },\n      outputPath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to save the compressed image file',\n        example: '/Users/user/Downloads/image_compressed.jpg',\n      },\n      outputFormat: {\n        type: 'string',\n        description: 'The format to save the compressed image file',\n        enum: SUPPORTED_IMAGE_TYPES,\n        example: 'image/jpeg',\n      },\n    },\n    required: ['imageUrl'],\n  },\n}\n```\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "bitscorp-mcp--mcp-ffmpeg": {
      "owner": "bitscorp-mcp",
      "name": "mcp-ffmpeg",
      "url": "https://github.com/bitscorp-mcp/mcp-ffmpeg",
      "imageUrl": "https://github.com/bitscorp-mcp.png",
      "description": "Manipulate video files by resizing them to various resolutions and extracting audio in multiple formats. Interact with video processing capabilities using natural language requests via API calls.",
      "stars": 35,
      "forks": 13,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-28T04:42:34Z",
      "readme_content": "# MCP FFmpeg Video Processor\n[![smithery badge](https://smithery.ai/badge/@bitscorp-mcp/mcp-ffmpeg)](https://smithery.ai/server/@bitscorp-mcp/mcp-ffmpeg)\n\nA Node.js server that uses FFmpeg to manipulate video files. This server provides APIs to:\n\n- Resize videos to different resolutions (360p, 480p, 720p, 1080p)\n- Extract audio from videos in various formats (MP3, AAC, WAV, OGG)\n\n## Prerequisites\n\nBefore running this application, you need to have the following installed:\n\n1. **Node.js** (v14 or higher)\n2. **FFmpeg** - This is required for video processing\n\n### Installing FFmpeg\n\n#### On macOS:\n```bash\nbrew install ffmpeg\n```\n\n#### On Ubuntu/Debian:\n```bash\nsudo apt update\nsudo apt install ffmpeg\n```\n\n#### On Windows:\n1. Download FFmpeg from the [official website](https://ffmpeg.org/download.html)\n2. Extract the files to a folder (e.g., `C:\\ffmpeg`)\n3. Add the `bin` folder to your PATH environment variable\n\n## Installation\n\n1. Clone this repository:\n```bash\ngit clone https://github.com/bitscorp-mcp/mcp-ffmpeg.git\ncd mcp-ffmpeg\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n### Installing via Smithery\n\nTo install mcp-ffmpeg for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@bitscorp-mcp/mcp-ffmpeg):\n\n```bash\nnpx -y @smithery/cli install @bitscorp-mcp/mcp-ffmpeg --client claude\n```\n\n## Running the Server\n\nStart the server with:\n\n```bash\nnpm start\n```\n\nFor development with auto-restart on file changes:\n\n```bash\nnpm run dev\n```\n\n### Installing via Smithery\n\nTo install mcp-ffmpeg for Claude Desktop automatically via [Smithery](https://smithery.ai/server/bitscorp-mcp/mcp-ffmpeg):\n\n```bash\nnpx -y @smithery/cli install @bitscorp-mcp/mcp-ffmpeg --client claude\n```\n\nTo install mcp-ffmpeg for Cursor, go to Settings -> Cursor Settings -> Features -> MCP Servers -> + Add\n\nSelect Type: command and paste the below, using your API key from Adjust\n```\nnpx -y @smithery/cli@latest run @bitscorp/mcp-ffmpeg\n```\n\n## Using with Claude Desktop\n\nThis MCP FFmpeg server can be integrated with Claude Desktop to process videos through natural language requests.\n\n### Running with npx\n\nYou can run the server directly with npx:\n\n```bash\nnpx /path/to/mcp-ffmpeg\n```\n\nOr if you've published the package to npm:\n\n```bash\nnpx mcp-ffmpeg\n```\n\n### Configuring Claude Desktop\n\nTo add this server to Claude Desktop, update your Claude Desktop configuration file:\n\n1. Locate your Claude Desktop config file:\n   - macOS: `~/.config/claude-desktop/config.json` or `~/Library/Application Support/Claude Desktop/config.json`\n   - Windows: `%APPDATA%\\Claude Desktop\\config.json`\n   - Linux: `~/.config/claude-desktop/config.json`\n\n2. Add the FFmpeg MCP server to the `mcpServers` section:\n\n```json\n{\n    \"mcpServers\": {\n        \"ffmpeg\": {\n            \"command\": \"npx\",\n            \"args\": [\n                \"--yes\",\n                \"/absolute/path/to/mcp-ffmpeg\"\n            ]\n        }\n    }\n}\n```\n\nIf you've published the package to npm:\n\n```json\n{\n    \"mcpServers\": {\n        \"ffmpeg\": {\n            \"command\": \"npx\",\n            \"args\": [\n                \"--yes\",\n                \"mcp-ffmpeg\"\n            ]\n        }\n    }\n}\n```\n\n3. Restart Claude Desktop for the changes to take effect.\n\n### Example Prompts for Claude\n\nOnce configured, you can use prompts like:\n\n```\nUsing the ffmpeg MCP server, please resize the video at /path/to/video.mp4 to 720p resolution.\n```\n\n## Notes\n\n- Uploaded videos are stored temporarily in the `uploads` directory\n- Processed videos and audio files are stored in the `output` directory\n- The server has a file size limit of 500MB for uploads\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Bob-lance--grok-mcp": {
      "owner": "Bob-lance",
      "name": "grok-mcp",
      "url": "https://github.com/Bob-lance/grok-mcp",
      "imageUrl": "https://github.com/Bob-lance.png",
      "description": "Connects to Grok AI to generate chat responses, analyze images, and invoke function calls, integrating these features directly into applications using the Model Context Protocol.",
      "stars": 15,
      "forks": 7,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-13T14:48:07Z",
      "readme_content": "# Grok MCP Plugin\n\n<!-- Add badges here -->\n[![npm version](https://img.shields.io/npm/v/grok-mcp.svg?style=flat-square)](https://www.npmjs.com/package/grok-mcp) <!-- Replace with your actual package name if different -->\n[![Smithery Build Status](https://api.smithery.ai/badges/github.com/Bob-lance/grok-mcp/build-status.svg)](https://smithery.ai/Bob-lance/grok-mcp) <!-- Replace with your actual repo path -->\n\nA Model Context Protocol (MCP) plugin that provides seamless access to Grok AI's powerful capabilities directly from Cline.\n\n## Features\n\nThis plugin exposes three powerful tools through the MCP interface:\n\n1. **Chat Completion** - Generate text responses using Grok's language models\n2. **Image Understanding** - Analyze images with Grok's vision capabilities\n3. **Function Calling** - Use Grok to call functions based on user input\n\n## Prerequisites\n\n- Node.js (v16 or higher)\n- A Grok AI API key (obtain from [console.x.ai](https://console.x.ai/))\n- Cline with MCP support\n\n## Installation\n\n1. Clone this repository:\n   ```bash\n   git clone https://github.com/Bob-lance/grok-mcp.git\n   cd grok-mcp\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n   ```bash\n   npm run build\n   ```\n\n4. Add the MCP server to your Cline MCP settings:\n\n   For VSCode Cline extension, edit the file at:\n   ```\n   ~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json\n   ```\n\n   Add the following configuration:\n   ```json\n   {\n     \"mcpServers\": {\n       \"grok-mcp\": {\n         \"command\": \"node\",\n         \"args\": [\"/path/to/grok-mcp/build/index.js\"],\n         \"env\": {\n           \"XAI_API_KEY\": \"your-grok-api-key\"\n         },\n         \"disabled\": false,\n         \"autoApprove\": []\n       }\n     }\n   }\n   ```\n\n   Replace `/path/to/grok-mcp` with the actual path to your installation and `your-grok-api-key` with your Grok AI API key.\n\n## Usage\n\nOnce installed and configured, the Grok MCP plugin provides three tools that can be used in Cline:\n\n### Chat Completion\n\nGenerate text responses using Grok's language models:\n\n```javascript\n<use_mcp_tool>\n<server_name>grok-mcp</server_name>\n<tool_name>chat_completion</tool_name>\n<arguments>\n{\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are a helpful assistant.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Hello, what can you tell me about Grok AI?\"\n    }\n  ],\n  \"temperature\": 0.7\n}\n</arguments>\n</use_mcp_tool>\n```\n\n### Image Understanding\n\nAnalyze images with Grok's vision capabilities:\n\n```javascript\n<use_mcp_tool>\n<server_name>grok-mcp</server_name>\n<tool_name>image_understanding</tool_name>\n<arguments>\n{\n  \"image_url\": \"https://example.com/image.jpg\",\n  \"prompt\": \"What is shown in this image?\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\nYou can also use base64-encoded images:\n\n```javascript\n<use_mcp_tool>\n<server_name>grok-mcp</server_name>\n<tool_name>image_understanding</tool_name>\n<arguments>\n{\n  \"base64_image\": \"base64-encoded-image-data\",\n  \"prompt\": \"What is shown in this image?\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n### Function Calling\n\nUse Grok to call functions based on user input:\n\n```javascript\n<use_mcp_tool>\n<server_name>grok-mcp</server_name>\n<tool_name>function_calling</tool_name>\n<arguments>\n{\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"What's the weather like in San Francisco?\"\n    }\n  ],\n  \"tools\": [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"get_weather\",\n        \"description\": \"Get the current weather in a given location\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"location\": {\n              \"type\": \"string\",\n              \"description\": \"The city and state, e.g. San Francisco, CA\"\n            },\n            \"unit\": {\n              \"type\": \"string\",\n              \"enum\": [\"celsius\", \"fahrenheit\"],\n              \"description\": \"The unit of temperature to use\"\n            }\n          },\n          \"required\": [\"location\"]\n        }\n      }\n    }\n  ]\n}\n</arguments>\n</use_mcp_tool>\n```\n\n## API Reference\n\n### Chat Completion\n\nGenerate a response using Grok AI chat completion.\n\n**Parameters:**\n\n- `messages` (required): Array of message objects with role and content\n- `model` (optional): Grok model to use (defaults to grok-3-mini-beta)\n- `temperature` (optional): Sampling temperature (0-2, defaults to 1)\n- `max_tokens` (optional): Maximum number of tokens to generate (defaults to 16384)\n\n### Image Understanding\n\nAnalyze images using Grok AI vision capabilities.\n\n**Parameters:**\n\n- `prompt` (required): Text prompt to accompany the image\n- `image_url` (optional): URL of the image to analyze\n- `base64_image` (optional): Base64-encoded image data (without the data:image prefix)\n- `model` (optional): Grok vision model to use (defaults to grok-2-vision-latest)\n\nNote: Either `image_url` or `base64_image` must be provided.\n\n### Function Calling\n\nUse Grok AI to call functions based on user input.\n\n**Parameters:**\n\n- `messages` (required): Array of message objects with role and content\n- `tools` (required): Array of tool objects with type, function name, description, and parameters\n- `tool_choice` (optional): Tool choice mode (auto, required, none, defaults to auto)\n- `model` (optional): Grok model to use (defaults to grok-3-mini-beta)\n\n## Development\n\n### Project Structure\n\n- `src/index.ts` - Main server implementation\n- `src/grok-api-client.ts` - Grok API client implementation\n\n### Building\n\n```bash\nnpm run build\n```\n\n### Running\n\n```bash\nXAI_API_KEY=\"your-grok-api-key\" node build/index.js\n```\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgements\n\n- [Model Context Protocol](https://github.com/modelcontextprotocol/mcp)\n- [Grok AI](https://x.ai/)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "bobtista--luma-ai-mcp-server": {
      "owner": "bobtista",
      "name": "luma-ai-mcp-server",
      "url": "https://github.com/bobtista/luma-ai-mcp-server",
      "imageUrl": "https://github.com/bobtista.png",
      "description": "Integrates with Luma AI's Dream Machine API to facilitate the generation and manipulation of AI-generated videos and images. Offers tools for text-to-video generation, image processing, and audio integration to enhance creative projects.",
      "stars": 3,
      "forks": 4,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-07-23T00:09:33Z",
      "readme_content": "# Luma AI MCP Server ğŸ¥\n\nA Model Context Protocol server for Luma AI's Dream Machine API.\n\n## Overview\n\nThis MCP server integrates with Luma AI's Dream Machine API (v1) to provide tools for generating, managing, and manipulating AI-generated videos and images via Large Language Models. It implements the Model Context Protocol (MCP) to enable seamless interaction between AI assistants and Luma's creative tools.\n\n## Features âœ¨\n\n- Text-to-video generation\n- Advanced video generation with keyframes\n- Image-to-video conversion\n- Video extension and interpolation\n- Image generation with reference images\n- Audio addition to videos\n- Video upscaling\n- Credit management\n- Generation tracking and status checking\n\n## Tools ğŸ› ï¸\n\n1. `ping`\n\n   - Check if the Luma API is running\n   - No parameters required\n\n2. `create_generation`\n\n   - Creates a new video generation\n   - Input:\n     - `prompt` (string, required): Text description of the video to generate\n     - `model` (string, optional): Model to use (default: \"ray-2\")\n       - Available models: \"ray-1-6\", \"ray-2\", \"ray-flash-2\"\n     - `resolution` (string, optional): Video resolution (choices: \"540p\", \"720p\", \"1080p\", \"4k\")\n     - `duration` (string, optional): Video duration (only \"5s\" and \"9s\" are currently supported)\n     - `aspect_ratio` (string, optional): Video aspect ratio (e.g., \"16:9\", \"1:1\", \"9:16\", \"4:3\", \"3:4\", \"21:9\", \"9:21\")\n     - `loop` (boolean, optional): Whether to make the video loop\n     - `keyframes` (object, optional): Start and end frames for advanced video generation:\n       - `frame0` and/or `frame1` with either:\n         - `{\"type\": \"image\", \"url\": \"image_url\"}` for image keyframes\n         - `{\"type\": \"generation\", \"id\": \"generation_id\"}` for video keyframes\n\n3. `get_generation`\n\n   - Gets the status of a generation\n   - Input:\n     - `generation_id` (string, required): ID of the generation to check\n   - Output includes:\n     - Generation ID\n     - State (queued, dreaming, completed, failed)\n     - Failure reason (if failed)\n     - Video URL (if completed)\n\n4. `list_generations`\n\n   - Lists all generations\n   - Input:\n     - `limit` (number, optional): Maximum number of generations to return (default: 10)\n     - `offset` (number, optional): Number of generations to skip\n\n5. `delete_generation`\n\n   - Deletes a generation\n   - Input:\n     - `generation_id` (string, required): ID of the generation to delete\n\n6. `upscale_generation`\n\n   - Upscales a video generation to higher resolution\n   - Input:\n     - `generation_id` (string, required): ID of the generation to upscale\n     - `resolution` (string, required): Target resolution for the upscaled video (one of \"540p\", \"720p\", \"1080p\", or \"4k\")\n   - Note:\n     - The generation must be in a completed state to be upscaled\n     - The target resolution must be higher than the original generation's resolution\n     - Each generation can only be upscaled once\n\n7. `add_audio`\n\n   - Adds AI-generated audio to a video generation\n   - Input:\n     - `generation_id` (required): The ID of the generation to add audio to\n     - `prompt` (required): The prompt for the audio generation\n     - `negative_prompt` (optional): The negative prompt for the audio generation\n     - `callback_url` (optional): URL to notify when the audio processing is complete\n\n8. `generate_image`\n\n   - Generates an image from a text prompt with optional reference images\n   - Input:\n     - `prompt` (string, required): Text description of the image to generate\n     - `model` (string, optional): Model to use for image generation (default: \"photon-1\")\n       - Available models: \"photon-1\", \"photon-flash-1\"\n     - `aspect_ratio` (string, optional): Image aspect ratio (same options as video)\n     - `image_ref` (array, optional): Reference images to guide generation\n       - Each ref: `{\"url\": \"image_url\", \"weight\": optional_float}`\n     - `style_ref` (array, optional): Style reference images\n       - Each ref: `{\"url\": \"image_url\", \"weight\": optional_float}`\n     - `character_ref` (object, optional): Character reference images\n       - Format: `{\"identity_name\": {\"images\": [\"url1\", \"url2\", ...]}}`\n     - `modify_image_ref` (object, optional): Image to modify\n       - Format: `{\"url\": \"image_url\", \"weight\": optional_float}`\n\n9. `get_credits`\n\n   - Gets credit information for the current user\n   - No parameters required\n   - Returns available credit balance in USD cents\n\n10. `get_camera_motions`\n    - Gets all supported camera motions\n    - No parameters required\n    - Returns: List of available camera motion strings\n\n## Setup for Claude Desktop ğŸ–¥ï¸\n\n1. Get your Luma API key from [Luma AI](https://lumalabs.ai) (sign up or log in to get your API key)\n\n2. Add this to your Claude Desktop configuration file:\n\n   - On macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - On Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"luma\": {\n         \"command\": \"uv\",\n         \"args\": [\n           \"run\",\n           \"--project\",\n           \"/path/to/your/luma-ai-mcp-server\",\n           \"-m\",\n           \"luma_ai_mcp_server\"\n         ],\n         \"env\": {\n           \"LUMA_API_KEY\": \"your-luma-api-key-here\"\n         }\n       }\n     }\n   }\n   ```\n\n   Replace:\n\n   - `/path/to/your/luma-ai-mcp-server` with the actual path to your server directory\n   - `your-luma-api-key-here` with your actual Luma API key\n\n3. Restart Claude Desktop\n\n4. That's it! You can now use Luma AI tools directly in Claude Desktop conversations.\n\n## Quick Troubleshooting ğŸ› ï¸\n\nIf you're having issues:\n\n1. Check your API key is correct\n2. Make sure the path to the server is correct\n3. View logs with: `tail -n 20 -f ~/Library/Logs/Claude/mcp*.log`\n\n## Advanced Video Generation Types ğŸ¬\n\nThe Luma API supports various types of advanced video generation through keyframes:\n\n1. **Starting from an image**: Provide `frame0` with `type: \"image\"` and an image URL\n2. **Ending with an image**: Provide `frame1` with `type: \"image\"` and an image URL\n3. **Extending a video**: Provide `frame0` with `type: \"generation\"` and a generation ID\n4. **Reverse extending a video**: Provide `frame1` with `type: \"generation\"` and a generation ID\n5. **Interpolating between videos**: Provide both `frame0` and `frame1` with `type: \"generation\"` and generation IDs\n\n## API Limitations and Notes ğŸ“\n\n- **Duration**: Currently, the API only supports durations of \"5s\" or \"9s\"\n- **Resolution**: Valid values are \"540p\", \"720p\", \"1080p\", and \"4k\"\n- **Models**:\n  - Video generation:\n    - \"ray-2\" (default) - Best quality, slower\n    - \"ray-flash-2\" - Faster generation\n    - \"ray-1-6\" - Legacy model\n  - Image generation:\n    - \"photon-1\" (default) - Best quality, slower\n    - \"photon-flash-1\" - Faster generation\n- **Generation types**: Video, image, and advanced (with keyframes)\n- **Aspect Ratios**: \"1:1\" (square), \"16:9\" (landscape), \"9:16\" (portrait), \"4:3\" (standard), \"3:4\" (standard portrait), \"21:9\" (ultrawide), \"9:21\" (ultrawide portrait)\n- **States**: \"queued\", \"dreaming\", \"completed\", \"failed\"\n- **Upscaling**:\n  - Video generations can only be upscaled when they're in a \"complete\" state\n  - Target resolution must be higher than the original generation's resolution\n  - Each generation can only be upscaled once\n- **API Key**: Required in environment variables\n- **API Version**: Uses Dream Machine API v1\n\n## License ğŸ“„\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "breezedeus--CnOCR": {
      "owner": "breezedeus",
      "name": "CnOCR",
      "url": "https://github.com/breezedeus/CnOCR",
      "imageUrl": "https://github.com/breezedeus.png",
      "description": "Enables optical character recognition for Chinese, English, and numbers using pre-trained models or custom training. Provides powerful text recognition capabilities for a variety of applications.",
      "stars": 3659,
      "forks": 528,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-03T14:15:19Z",
      "readme_content": "<div align=\"center\">\n  <img src=\"./docs/figs/cnocr-logo.jpg\" width=\"250px\"/>\n  <div>&nbsp;</div>\n\n[![Discord](https://img.shields.io/discord/1200765964434821260?label=Discord)](https://discord.gg/GgD87WM8Tf)\n[![Downloads](https://static.pepy.tech/personalized-badge/cnocr?period=total&units=international_system&left_color=grey&right_color=orange&left_text=Downloads)](https://pepy.tech/project/cnocr)\n[![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fbreezedeus%2FCnOCR&label=Visitors&countColor=%23f5c791&style=flat&labelStyle=none)](https://visitorbadge.io/status?path=https%3A%2F%2Fgithub.com%2Fbreezedeus%2FCnOCR)\n[![license](https://img.shields.io/github/license/breezedeus/cnocr)](./LICENSE)\n[![Docs](https://readthedocs.org/projects/cnocr/badge/?version=latest)](https://cnocr.readthedocs.io/zh-cn/stable/?badge=latest)\n[![PyPI version](https://badge.fury.io/py/cnocr.svg)](https://badge.fury.io/py/cnocr)\n[![forks](https://img.shields.io/github/forks/breezedeus/cnocr)](https://github.com/breezedeus/cnocr)\n[![stars](https://img.shields.io/github/stars/breezedeus/cnocr)](https://github.com/breezedeus/cnocr)\n![last-releast](https://img.shields.io/github/release-date/breezedeus/cnocr)\n![last-commit](https://img.shields.io/github/last-commit/breezedeus/cnocr)\n[![Twitter](https://img.shields.io/twitter/url?url=https%3A%2F%2Ftwitter.com%2Fbreezedeus)](https://twitter.com/breezedeus)\n\n[ğŸ“– æ–‡æ¡£](https://cnocr.readthedocs.io/zh-cn/stable/) |\n[ğŸ› ï¸ å®‰è£…](https://cnocr.readthedocs.io/zh-cn/stable/install/) |\n[ğŸ§³ å¯ç”¨æ¨¡å‹](https://cnocr.readthedocs.io/zh-cn/stable/models/) |\n[ğŸ•¹ æ¨¡å‹è®­ç»ƒ](https://cnocr.readthedocs.io/zh-cn/stable/train/) |\n[ğŸ›€ğŸ» åœ¨çº¿Demo](https://huggingface.co/spaces/breezedeus/CnOCR-Demo) |\n[ğŸ’¬ äº¤æµç¾¤](https://www.breezedeus.com/article/join-group)\n\n</div>\n\n<div align=\"center\">\n\n[English](./README_en.md) | ä¸­æ–‡\n\n</div>\n\n# CnOCR\n\n<div align=\"center\">\n<strong>Tech should serve the people, not enslave them!</strong>\n<br>\n<strong>è¯·å‹¿å°†æ­¤é¡¹ç›®ç”¨äºæ–‡å­—å®¡æŸ¥ï¼</strong>\n<br>\n---\n</div>\n\n### Update 2025.06.26ï¼šå‘å¸ƒ V2.3.2\n\nä¸»è¦å˜æ›´ï¼š\n\n* é›†æˆ PPOCRv5 æœ€æ–°ç‰ˆ OCR æ¨¡å‹\n  * æ–°å¢æ”¯æŒ PP-OCRv5 è¯†åˆ«æ¨¡å‹ï¼š`ch_PP-OCRv5` å’Œ `ch_PP-OCRv5_server`\n\n\n### [Update 2024.11.30]ï¼šå‘å¸ƒ V2.3.1\n\nä¸»è¦å˜æ›´ï¼š\n\n* åŸºäº RapidOCR é›†æˆ PPOCRv4 æœ€æ–°ç‰ˆ OCR æ¨¡å‹ï¼Œæä¾›æ›´å¤šçš„æ¨¡å‹é€‰æ‹©\n  * æ–°å¢æ”¯æŒ PP-OCRv4  è¯†åˆ«æ¨¡å‹ï¼ŒåŒ…æ‹¬æ ‡å‡†ç‰ˆå’ŒæœåŠ¡å™¨ç‰ˆ\n* ä¿®æ”¹è¯»æ–‡ä»¶å®ç°æ–¹å¼ï¼Œæ”¯æŒ Windows çš„ä¸­æ–‡è·¯å¾„\n* ä¿®å¤Bugï¼šå½“ä½¿ç”¨å¤šä¸ªè¿›ç¨‹æ—¶ï¼Œtransform_func æ— æ³•åºåˆ—åŒ–\n* ä¿®å¤Bugï¼šä¸ albumentations=1.4.* å…¼å®¹\n\n### [Update 2023.12.24]ï¼šå‘å¸ƒ V2.3\n\nä¸»è¦å˜æ›´ï¼š\n\n* é‡æ–°è®­ç»ƒäº†æ‰€æœ‰çš„æ¨¡å‹ï¼Œæ¯”ä¸Šä¸€ç‰ˆç²¾åº¦æ›´é«˜ã€‚\n* æŒ‰ä½¿ç”¨åœºæ™¯æŠŠæ¨¡å‹åˆ†ä¸ºå‡ å¤§ç±»åœºæ™¯ï¼ˆè§ [è¯†åˆ«æ¨¡å‹åˆ—è¡¨](#å¯ä½¿ç”¨çš„è¯†åˆ«æ¨¡å‹)ï¼‰ï¼š\n  * `scene`ï¼šåœºæ™¯å›¾ç‰‡ï¼Œé€‚åˆè¯†åˆ«ä¸€èˆ¬æ‹ç…§å›¾ç‰‡ä¸­çš„æ–‡å­—ã€‚æ­¤ç±»æ¨¡å‹ä»¥ `scene-` å¼€å¤´ï¼Œå¦‚æ¨¡å‹ `scene-densenet_lite_136-gru`ã€‚\n  * `doc`ï¼šæ–‡æ¡£å›¾ç‰‡ï¼Œé€‚åˆè¯†åˆ«è§„åˆ™æ–‡æ¡£çš„æˆªå›¾å›¾ç‰‡ï¼Œå¦‚ä¹¦ç±æ‰«æä»¶ç­‰ã€‚æ­¤ç±»æ¨¡å‹ä»¥ `doc-` å¼€å¤´ï¼Œå¦‚æ¨¡å‹ `doc-densenet_lite_136-gru`ã€‚\n  * `number`ï¼šä»…è¯†åˆ«**çº¯æ•°å­—**ï¼ˆåªèƒ½è¯†åˆ« `0~9` åä¸ªæ•°å­—ï¼‰å›¾ç‰‡ï¼Œé€‚åˆé“¶è¡Œå¡å·ã€èº«ä»½è¯å·ç­‰åœºæ™¯ã€‚æ­¤ç±»æ¨¡å‹ä»¥ `number-` å¼€å¤´ï¼Œå¦‚æ¨¡å‹ `number-densenet_lite_136-gru`ã€‚\n  * `general`: é€šç”¨åœºæ™¯ï¼Œé€‚åˆå›¾ç‰‡æ— æ˜æ˜¾å€¾å‘çš„ä¸€èˆ¬å›¾ç‰‡ã€‚æ­¤ç±»æ¨¡å‹æ— ç‰¹å®šå¼€å¤´ï¼Œä¸æ—§ç‰ˆæ¨¡å‹åç§°ä¿æŒä¸€è‡´ï¼Œå¦‚æ¨¡å‹ `densenet_lite_136-gru`ã€‚\n  > æ³¨æ„ âš ï¸ï¼šä»¥ä¸Šè¯´æ˜ä»…ä¸ºå‚è€ƒï¼Œå…·ä½“é€‰æ‹©æ¨¡å‹æ—¶å»ºè®®ä»¥å®é™…æ•ˆæœä¸ºå‡†ã€‚\n* åŠ å…¥äº†ä¸¤ä¸ªæ›´å¤§çš„ç³»åˆ—æ¨¡å‹ï¼š\n  * `*-densenet_lite_246-gru_base`ï¼šä¼˜å…ˆä¾› **çŸ¥è¯†æ˜Ÿçƒ** [**CnOCR/CnSTDç§äº«ç¾¤**](https://t.zsxq.com/FEYZRJQ) ä¼šå‘˜ä½¿ç”¨ï¼Œä¸€ä¸ªæœˆåä¼šå…è´¹å¼€æºã€‚\n  * `*-densenet_lite_666-gru_large`ï¼šPro æ¨¡å‹ï¼Œè´­ä¹°åå¯ä½¿ç”¨ã€‚\n  \næ›´å¤šç»†èŠ‚è¯·å‚è€ƒï¼š[CnOCR V2.3 æ–°ç‰ˆå‘å¸ƒï¼šæ¨¡å‹æ›´å¥½ã€æ›´å¤šã€æ›´å¤§ | Breezedeus.com](https://www.breezedeus.com/article/cnocr-v2.3-better-more)ã€‚\n\n\n\n[**CnOCR**](https://github.com/breezedeus/cnocr) æ˜¯ **Python 3** ä¸‹çš„**æ–‡å­—è¯†åˆ«**ï¼ˆ**Optical Character Recognition**ï¼Œç®€ç§°**OCR**ï¼‰å·¥å…·åŒ…ï¼Œæ”¯æŒ**ç®€ä½“ä¸­æ–‡**ã€**ç¹ä½“ä¸­æ–‡**ï¼ˆéƒ¨åˆ†æ¨¡å‹ï¼‰ã€**è‹±æ–‡**å’Œ**æ•°å­—**çš„å¸¸è§å­—ç¬¦è¯†åˆ«ï¼Œæ”¯æŒç«–æ’æ–‡å­—çš„è¯†åˆ«ã€‚è‡ªå¸¦äº†**20+ä¸ª** [è®­ç»ƒå¥½çš„æ¨¡å‹](https://cnocr.readthedocs.io/zh-cn/stable/models/)ï¼Œé€‚ç”¨äºä¸åŒåº”ç”¨åœºæ™¯ï¼Œå®‰è£…åå³å¯ç›´æ¥ä½¿ç”¨ã€‚åŒæ—¶ï¼ŒCnOCRä¹Ÿæä¾›ç®€å•çš„[è®­ç»ƒå‘½ä»¤](https://cnocr.readthedocs.io/zh-cn/stable/train/)ä¾›ä½¿ç”¨è€…è®­ç»ƒè‡ªå·±çš„æ¨¡å‹ã€‚æ¬¢è¿æ‰«ç åŠ å°åŠ©æ‰‹ä¸ºå¥½å‹ï¼Œå¤‡æ³¨ `ocr`ï¼Œå°åŠ©æ‰‹ä¼šå®šæœŸç»Ÿä¸€é‚€è¯·å¤§å®¶å…¥ç¾¤ï¼š\n\n<div align=\"center\">\n  <img src=\"https://huggingface.co/datasets/breezedeus/cnocr-wx-qr-code/resolve/main/wx-qr-code.JPG\" alt=\"å¾®ä¿¡ç¾¤äºŒç»´ç \" width=\"300px\"/>\n</div>\n\n\nä½œè€…ä¹Ÿç»´æŠ¤ **çŸ¥è¯†æ˜Ÿçƒ** [**CnOCR/CnSTDç§äº«ç¾¤**](https://t.zsxq.com/FEYZRJQ) ï¼Œè¿™é‡Œé¢çš„æé—®ä¼šè¾ƒå¿«å¾—åˆ°ä½œè€…çš„å›å¤ï¼Œæ¬¢è¿åŠ å…¥ã€‚**çŸ¥è¯†æ˜Ÿçƒä¼šå‘˜** å¯äº«å—ä»¥ä¸‹ç¦åˆ©ï¼š\n\n- å¯å…è´¹ä¸‹è½½éƒ¨åˆ†**æœªå¼€æºçš„ä»˜è´¹æ¨¡å‹**ï¼›\n- è´­ä¹°å…¶ä»–æ‰€æœ‰çš„ä»˜è´¹æ¨¡å‹ä¸€å¾‹å…«æŠ˜ä¼˜åŒ–ï¼›\n- ä½œè€…å¿«é€Ÿå›å¤ä½¿ç”¨è¿‡ç¨‹ä¸­é‡åˆ°çš„å„ç§å›°éš¾ï¼›\n- ä½œè€…æ¯æœˆæä¾›ä¸¤æ¬¡å…è´¹ç‰¹æœ‰æ•°æ®çš„è®­ç»ƒæœåŠ¡ã€‚\n- æ˜Ÿçƒä¼šé™†ç»­å‘å¸ƒä¸€äº›CnOCR/CnSTDç›¸å…³çš„ç§æœ‰èµ„æ–™ï¼›\n- æ˜Ÿçƒä¼šæŒç»­å‘å¸ƒ OCR/STD/CV ç­‰ç›¸å…³çš„æœ€æ–°ç ”ç©¶èµ„æ–™ã€‚\n\n\n\n## è¯¦ç»†æ–‡æ¡£\n\nè§ [CnOCRåœ¨çº¿æ–‡æ¡£](https://cnocr.readthedocs.io/) ã€‚\n\n## ä½¿ç”¨è¯´æ˜\n\n**CnOCR** ä» **V2.2** å¼€å§‹ï¼Œå†…éƒ¨è‡ªåŠ¨è°ƒç”¨æ–‡å­—æ£€æµ‹å¼•æ“ **[CnSTD](https://github.com/breezedeus/cnstd)** è¿›è¡Œæ–‡å­—æ£€æµ‹å’Œå®šä½ã€‚æ‰€ä»¥ **CnOCR** V2.2 ä¸ä»…èƒ½è¯†åˆ«æ’ç‰ˆç®€å•çš„å°åˆ·ä½“æ–‡å­—å›¾ç‰‡ï¼Œå¦‚æˆªå›¾å›¾ç‰‡ï¼Œæ‰«æä»¶ç­‰ï¼Œä¹Ÿèƒ½è¯†åˆ«**ä¸€èˆ¬å›¾ç‰‡ä¸­çš„åœºæ™¯æ–‡å­—**ã€‚\n\nä»¥ä¸‹æ˜¯ä¸€äº›ä¸åŒåœºæ™¯çš„è°ƒç”¨ç¤ºä¾‹ã€‚\n\n\n\n## ä¸åŒåœºæ™¯çš„è°ƒç”¨ç¤ºä¾‹\n\n### å¸¸è§çš„å›¾ç‰‡è¯†åˆ«\n\næ‰€æœ‰å‚æ•°éƒ½ä½¿ç”¨é»˜è®¤å€¼å³å¯ã€‚å¦‚æœå‘ç°æ•ˆæœä¸å¤Ÿå¥½ï¼Œå¤šè°ƒæ•´ä¸‹å„ä¸ªå‚æ•°çœ‹æ•ˆæœï¼Œæœ€ç»ˆå¾€å¾€èƒ½è·å¾—æ¯”è¾ƒç†æƒ³çš„ç²¾åº¦ã€‚\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/huochepiao.jpeg'\nocr = CnOcr()  # æ‰€æœ‰å‚æ•°éƒ½ä½¿ç”¨é»˜è®¤å€¼\nout = ocr.ocr(img_fp)\n\nprint(out)\n```\n\nè¯†åˆ«ç»“æœï¼š\n\n<div align=\"center\">\n  <img src=\"./docs/predict-outputs/huochepiao.jpeg-result.jpg\" alt=\"ç«è½¦ç¥¨è¯†åˆ«\" width=\"800px\"/>\n</div>\n\n\n### æ’ç‰ˆç®€å•çš„å°åˆ·ä½“æˆªå›¾å›¾ç‰‡è¯†åˆ«\n\né’ˆå¯¹ **æ’ç‰ˆç®€å•çš„å°åˆ·ä½“æ–‡å­—å›¾ç‰‡**ï¼Œå¦‚æˆªå›¾å›¾ç‰‡ï¼Œæ‰«æä»¶å›¾ç‰‡ç­‰ï¼Œå¯ä½¿ç”¨ `det_model_name='naive_det'`ï¼Œç›¸å½“äºä¸ä½¿ç”¨æ–‡æœ¬æ£€æµ‹æ¨¡å‹ï¼Œè€Œä½¿ç”¨ç®€å•çš„è§„åˆ™è¿›è¡Œåˆ†è¡Œã€‚\n\n> **Note**\n>\n>  `det_model_name='naive_det'` çš„æ•ˆæœç›¸å½“äº `V2.2` ä¹‹å‰ï¼ˆ`V2.0.*`, `V2.1.*`ï¼‰çš„ CnOCR ç‰ˆæœ¬ã€‚\n\nä½¿ç”¨ `det_model_name='naive_det'` çš„æœ€å¤§ä¼˜åŠ¿æ˜¯**é€Ÿåº¦å¿«**ï¼ŒåŠ£åŠ¿æ˜¯å¯¹å›¾ç‰‡æ¯”è¾ƒæŒ‘å‰”ã€‚å¦‚ä½•åˆ¤æ–­æ˜¯å¦è¯¥ä½¿ç”¨æ­¤æ£€æµ‹æ¨¡å‹å‘¢ï¼Ÿæœ€ç®€å•çš„æ–¹å¼å°±æ˜¯æ‹¿åº”ç”¨å›¾ç‰‡è¯•è¯•æ•ˆæœï¼Œæ•ˆæœå¥½å°±ç”¨ï¼Œä¸å¥½å°±ä¸ç”¨ã€‚\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/multi-line_cn1.png'\nocr = CnOcr(det_model_name='naive_det') \nout = ocr.ocr(img_fp)\n\nprint(out)\n```\n\nè¯†åˆ«ç»“æœï¼š\n\n<div align=\"center\">\n\n| å›¾ç‰‡                                                                      | OCRç»“æœ                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |\n| ![docs/examples/multi-line_cn1.png](./docs/examples/multi-line_cn1.png) | ç½‘ç»œæ”¯ä»˜å¹¶æ— æœ¬è´¨çš„åŒºåˆ«ï¼Œå› ä¸º<br />æ¯ä¸€ä¸ªæ‰‹æœºå·ç å’Œé‚®ä»¶åœ°å€èƒŒå<br />éƒ½ä¼šå¯¹åº”ç€ä¸€ä¸ªè´¦æˆ·--è¿™ä¸ªè´¦<br />æˆ·å¯ä»¥æ˜¯ä¿¡ç”¨å¡è´¦æˆ·ã€å€Ÿè®°å¡è´¦<br />æˆ·ï¼Œä¹ŸåŒ…æ‹¬é‚®å±€æ±‡æ¬¾ã€æ‰‹æœºä»£<br />æ”¶ã€ç”µè¯ä»£æ”¶ã€é¢„ä»˜è´¹å¡å’Œç‚¹å¡<br />ç­‰å¤šç§å½¢å¼ã€‚ |\n\n</div>\n\n\n### ç«–æ’æ–‡å­—è¯†åˆ«\n\né‡‡ç”¨æ¥è‡ª [**PaddleOCR**](https://github.com/PaddlePaddle/PaddleOCR)ï¼ˆä¹‹åç®€ç§° **ppocr**ï¼‰çš„ä¸­æ–‡è¯†åˆ«æ¨¡å‹ `rec_model_name='ch_PP-OCRv3'` è¿›è¡Œè¯†åˆ«ã€‚\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/shupai.png'\nocr = CnOcr(rec_model_name='ch_PP-OCRv3')\nout = ocr.ocr(img_fp)\n\nprint(out)\n```\n\nè¯†åˆ«ç»“æœï¼š\n<div align=\"center\">\n  <img src=\"./docs/predict-outputs/shupai.png-result.jpg\" alt=\"ç«–æ’æ–‡å­—è¯†åˆ«\" width=\"800px\"/>\n</div>\n\n\n### è‹±æ–‡è¯†åˆ«\n\nè™½ç„¶ä¸­æ–‡æ£€æµ‹å’Œè¯†åˆ«æ¨¡å‹ä¹Ÿèƒ½è¯†åˆ«è‹±æ–‡ï¼Œä½†**ä¸“ä¸ºè‹±æ–‡æ–‡å­—è®­ç»ƒçš„æ£€æµ‹å™¨å’Œè¯†åˆ«å™¨å¾€å¾€ç²¾åº¦æ›´é«˜**ã€‚å¦‚æœæ˜¯çº¯è‹±æ–‡çš„åº”ç”¨åœºæ™¯ï¼Œå»ºè®®ä½¿ç”¨æ¥è‡ª **ppocr** çš„è‹±æ–‡æ£€æµ‹æ¨¡å‹ `det_model_name='en_PP-OCRv3_det'`ï¼Œ å’Œè‹±æ–‡è¯†åˆ«æ¨¡å‹ `rec_model_name='en_PP-OCRv3'` ã€‚\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/en_book1.jpeg'\nocr = CnOcr(det_model_name='en_PP-OCRv3_det', rec_model_name='en_PP-OCRv3')\nout = ocr.ocr(img_fp)\n\nprint(out)\n```\n\nè¯†åˆ«ç»“æœï¼š\n\n<div align=\"center\">\n  <img src=\"./docs/predict-outputs/en_book1.jpeg-result.jpg\" alt=\"è‹±æ–‡è¯†åˆ«\" width=\"600px\"/>\n</div>\n\n\n### ç¹ä½“ä¸­æ–‡è¯†åˆ«\n\né‡‡ç”¨æ¥è‡ªppocrçš„ç¹ä½“è¯†åˆ«æ¨¡å‹ `rec_model_name='chinese_cht_PP-OCRv3'` è¿›è¡Œè¯†åˆ«ã€‚\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/fanti.jpg'\nocr = CnOcr(rec_model_name='chinese_cht_PP-OCRv3')  # è¯†åˆ«æ¨¡å‹ä½¿ç”¨ç¹ä½“è¯†åˆ«æ¨¡å‹\nout = ocr.ocr(img_fp)\n\nprint(out)\n```\n\nä½¿ç”¨æ­¤æ¨¡å‹æ—¶è¯·æ³¨æ„ä»¥ä¸‹é—®é¢˜ï¼š\n\n* è¯†åˆ«ç²¾åº¦ä¸€èˆ¬ï¼Œä¸æ˜¯å¾ˆå¥½ï¼›\n\n* é™¤äº†ç¹ä½“å­—ï¼Œå¯¹æ ‡ç‚¹ã€è‹±æ–‡ã€æ•°å­—çš„è¯†åˆ«éƒ½ä¸å¥½ï¼›\n\n* æ­¤æ¨¡å‹ä¸æ”¯æŒç«–æ’æ–‡å­—çš„è¯†åˆ«ã€‚\n\nè¯†åˆ«ç»“æœï¼š\n<div align=\"center\">\n  <img src=\"./docs/predict-outputs/fanti.jpg-result.jpg\" alt=\"ç¹ä½“ä¸­æ–‡è¯†åˆ«\" width=\"700px\"/>\n</div>\n\n\n### å•è¡Œæ–‡å­—çš„å›¾ç‰‡è¯†åˆ«\n\nå¦‚æœæ˜ç¡®çŸ¥é“å¾…è¯†åˆ«çš„å›¾ç‰‡æ˜¯å•è¡Œæ–‡å­—å›¾ç‰‡ï¼ˆå¦‚ä¸‹å›¾ï¼‰ï¼Œå¯ä»¥ä½¿ç”¨ç±»å‡½æ•° `CnOcr.ocr_for_single_line()` è¿›è¡Œè¯†åˆ«ã€‚è¿™æ ·å°±çœæ‰äº†æ–‡å­—æ£€æµ‹çš„æ—¶é—´ï¼Œé€Ÿåº¦ä¼šå¿«ä¸€å€ä»¥ä¸Šã€‚\n\n<div align=\"center\">\n  <img src=\"./docs/examples/helloworld.jpg\" alt=\"å•è¡Œæ–‡æœ¬è¯†åˆ«\" width=\"300px\"/>\n</div>\nè°ƒç”¨ä»£ç å¦‚ä¸‹ï¼š\n\n```python\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/helloworld.jpg'\nocr = CnOcr()\nout = ocr.ocr_for_single_line(img_fp)\nprint(out)\n```\n\n\n\n### æ›´å¤šåº”ç”¨ç¤ºä¾‹\n\n* **æ ¸é…¸ç–«è‹—æˆªå›¾è¯†åˆ«**\n<div align=\"center\">\n  <img src=\"./docs/predict-outputs/jiankangbao.jpeg-result.jpg\" alt=\"æ ¸é…¸ç–«è‹—æˆªå›¾è¯†åˆ«\" width=\"500px\"/>\n</div>\n\n* **èº«ä»½è¯è¯†åˆ«**\n<div align=\"center\">\n  <img src=\"./docs/predict-outputs/aobama.webp-result.jpg\" alt=\"èº«ä»½è¯è¯†åˆ«\" width=\"700px\"/>\n</div>\n\n* **é¥­åº—å°ç¥¨è¯†åˆ«**\n<div align=\"center\">\n  <img src=\"./docs/predict-outputs/fapiao.jpeg-result.jpg\" alt=\"é¥­åº—å°ç¥¨è¯†åˆ«\" width=\"500px\"/>\n</div>\n  \n\n  \n\n## å®‰è£…\n\nå—¯ï¼Œé¡ºåˆ©çš„è¯ä¸€è¡Œå‘½ä»¤å³å¯ã€‚\n\n```bash\n$ pip install cnocr[ort-cpu]\n```\n\nå¦‚æœæ˜¯ **GPU** ç¯å¢ƒä½¿ç”¨ ONNX æ¨¡å‹ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡Œå®‰è£…ï¼š\n\n```bash\n$ pip install cnocr[ort-gpu]\n```\n\n\n\nå¦‚æœè¦è®­ç»ƒè‡ªå·±çš„æ¨¡å‹ï¼Œï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š\n\n```bash\n$ pip install cnocr[dev]\n```\n\n\n\nå®‰è£…é€Ÿåº¦æ…¢çš„è¯ï¼Œå¯ä»¥æŒ‡å®šå›½å†…çš„å®‰è£…æºï¼Œå¦‚ä½¿ç”¨é˜¿é‡Œäº‘çš„å®‰è£…æºï¼š\n\n```bash\n$ pip install cnocr[ort-cpu] -i https://mirrors.aliyun.com/pypi/simple\n```\n\n> **Note** \n>\n> è¯·ä½¿ç”¨ **Python3**ï¼ˆ3.7.\\*~3.10.\\*ä¹‹é—´çš„ç‰ˆæœ¬åº”è¯¥éƒ½è¡Œï¼‰ï¼Œæ²¡æµ‹è¿‡Python2ä¸‹æ˜¯å¦okã€‚\n\næ›´å¤šè¯´æ˜å¯è§ [å®‰è£…æ–‡æ¡£](https://cnocr.readthedocs.io/zh-cn/stable/install/)ã€‚\n\n> **Warning** \n>\n> å¦‚æœç”µè„‘ä¸­ä»æœªå®‰è£…è¿‡ `PyTorch`ï¼Œ`OpenCV` pythonåŒ…ï¼Œåˆæ¬¡å®‰è£…å¯èƒ½ä¼šé‡åˆ°é—®é¢˜ï¼Œä½†ä¸€èˆ¬éƒ½æ˜¯å¸¸è§é—®é¢˜ï¼Œå¯ä»¥è‡ªè¡Œç™¾åº¦/Googleè§£å†³ã€‚\n\n\n\n### Docker Image\n\nå¯ä»¥ä» [Docker Hub](https://hub.docker.com/u/breezedeus) ç›´æ¥æ‹‰å–å·²å®‰è£…å¥½ CnOCR çš„é•œåƒä½¿ç”¨ã€‚\n\n```bash\n$ docker pull breezedeus/cnocr:latest\n```\n\næ›´å¤šè¯´æ˜å¯è§ [å®‰è£…æ–‡æ¡£](https://cnocr.readthedocs.io/zh-cn/stable/install/)ã€‚\n\n\n\n## HTTPæœåŠ¡\n\nCnOCR **V2.2.1** åŠ å…¥äº†åŸºäº FastAPI çš„HTTPæœåŠ¡ã€‚å¼€å¯æœåŠ¡éœ€è¦å®‰è£…å‡ ä¸ªé¢å¤–çš„åŒ…ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š\n\n```bash\npip install cnocr[serve]\n```\n\n\n\nå®‰è£…å®Œæˆåï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å¯åŠ¨HTTPæœåŠ¡ï¼ˆ**`-p`** åé¢çš„æ•°å­—æ˜¯**ç«¯å£**ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è‡ªè¡Œè°ƒæ•´ï¼‰ï¼š\n\n```bash\ncnocr serve -p 8501\n```\n\n\n\næœåŠ¡å¼€å¯åï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹å¼è°ƒç”¨æœåŠ¡ã€‚\n\n\n\n### å‘½ä»¤è¡Œ\n\næ¯”å¦‚å¾…è¯†åˆ«æ–‡ä»¶ä¸º `docs/examples/huochepiao.jpeg`ï¼Œå¦‚ä¸‹ä½¿ç”¨ curl è°ƒç”¨æœåŠ¡ï¼š\n\n```bash\n> curl -F image=@docs/examples/huochepiao.jpeg http://0.0.0.0:8501/ocr\n```\n\n\n\n### Python\n\nä½¿ç”¨å¦‚ä¸‹æ–¹å¼è°ƒç”¨æœåŠ¡ï¼š\n\n```python\nimport requests\n\nimage_fp = 'docs/examples/huochepiao.jpeg'\nr = requests.post(\n    'http://0.0.0.0:8501/ocr', files={'image': (image_fp, open(image_fp, 'rb'), 'image/png')},\n)\nocr_out = r.json()['results']\nprint(ocr_out)\n```\n\n\n\nå…·ä½“ä¹Ÿå¯å‚è€ƒæ–‡ä»¶ [scripts/screenshot_daemon_with_server.py](scripts/screenshot_daemon_with_server.py) ã€‚ \n\n\n\n### å…¶ä»–è¯­è¨€\n\nè¯·å‚ç…§ curl çš„è°ƒç”¨æ–¹å¼è‡ªè¡Œå®ç°ã€‚\n\n\n\n\n\n## å¯ä½¿ç”¨çš„æ¨¡å‹\n\n### å¯ä½¿ç”¨çš„æ£€æµ‹æ¨¡å‹\n\nå…·ä½“å‚è€ƒ [CnSTDçš„ä¸‹è½½è¯´æ˜](https://github.com/breezedeus/CnSTD?tab=readme-ov-file#%E5%B7%B2%E6%9C%89std%E6%A8%A1%E5%9E%8B)ã€‚\n\n| `det_model_name`                                             | PyTorch ç‰ˆæœ¬ | ONNX ç‰ˆæœ¬ | æ¨¡å‹åŸå§‹æ¥æº | æ¨¡å‹æ–‡ä»¶å¤§å° | æ”¯æŒè¯­è¨€                       | æ˜¯å¦æ”¯æŒç«–æ’æ–‡å­—è¯†åˆ« |\n| ------------------------------------------------------------ | ------------ | --------- | ------------ | ------------ | ------------------------------ | -------------------- |\n| db_shufflenet_v2                                             | âˆš            | X         | cnocr        | 18 M         | ç®€ä½“ä¸­æ–‡ã€ç¹ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­— | âˆš                    |\n| **db_shufflenet_v2_small**                                   | âˆš            | X         | cnocr        | 12 M         | ç®€ä½“ä¸­æ–‡ã€ç¹ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­— | âˆš                    |\n| db_mobilenet_v3                                              | âˆš            | X         | cnocr        | 16 M         | ç®€ä½“ä¸­æ–‡ã€ç¹ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­— | âˆš                    |\n| db_mobilenet_v3_small                                        | âˆš            | X         | cnocr        | 7.9 M        | ç®€ä½“ä¸­æ–‡ã€ç¹ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­— | âˆš                    |\n| db_resnet34                                                  | âˆš            | X         | cnocr        | 86 M         | ç®€ä½“ä¸­æ–‡ã€ç¹ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­— | âˆš                    |\n| db_resnet18                                                  | âˆš            | X         | cnocr        | 47 M         | ç®€ä½“ä¸­æ–‡ã€ç¹ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­— | âˆš                    |\n| ch_PP-OCRv5_det                                              | X            | âˆš         | ppocr        | 4.6 M        | ç®€ä½“ä¸­æ–‡ã€ç¹ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­— | âˆš                    |\n| ch_PP-OCRv5_det_server                                       | X            | âˆš         | ppocr        | 84 M        | ç®€ä½“ä¸­æ–‡ã€ç¹ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­— | âˆš                    |\n| ch_PP-OCRv4_det                                              | X            | âˆš         | ppocr        | 4.5 M        | ç®€ä½“ä¸­æ–‡ã€ç¹ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­— | âˆš                    |\n| ch_PP-OCRv4_det_server                                       | X            | âˆš         | ppocr        | 108 M        | ç®€ä½“ä¸­æ–‡ã€ç¹ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­— | âˆš                    |\n| ch_PP-OCRv3_det                                              | X            | âˆš         | ppocr        | 2.3 M        | ç®€ä½“ä¸­æ–‡ã€ç¹ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­— | âˆš                    |\n| **en_PP-OCRv3_det**                                          | X            | âˆš         | ppocr        | 2.3 M        | **è‹±æ–‡**ã€æ•°å­—                 | âˆš                    |\n\n\n\n### å¯ä½¿ç”¨çš„è¯†åˆ«æ¨¡å‹\n\nç›¸æ¯”äº CnOCR V2.2.* ç‰ˆæœ¬ï¼Œ**V2.3** ä¸­çš„å¤§éƒ¨åˆ†æ¨¡å‹éƒ½ç»è¿‡äº†é‡æ–°è®­ç»ƒå’Œç²¾è°ƒï¼Œç²¾åº¦æ¯”æ—§ç‰ˆæ¨¡å‹æ›´é«˜ã€‚åŒæ—¶ï¼ŒåŠ å…¥äº†ä¸¤ä¸ªå‚æ•°é‡æ›´å¤šçš„æ¨¡å‹ç³»åˆ—ï¼š\n\n  * `*-densenet_lite_246-gru_base`ï¼šä¼˜å…ˆä¾› **çŸ¥è¯†æ˜Ÿçƒ** [**CnOCR/CnSTDç§äº«ç¾¤**](https://t.zsxq.com/FEYZRJQ) ä¼šå‘˜ä½¿ç”¨ï¼Œåç»­ä¼šå…è´¹å¼€æºã€‚\n  * `*-densenet_lite_666-gru_large`ï¼š**Pro æ¨¡å‹**ï¼Œè´­ä¹°åå¯ä½¿ç”¨ã€‚è´­ä¹°é“¾æ¥è§æ–‡æ¡£ï¼š\n\n**V2.3** ä¸­çš„æ¨¡å‹æŒ‰ä½¿ç”¨åœºæ™¯å¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ å¤§ç±»ï¼š\n\n* `scene`ï¼šåœºæ™¯å›¾ç‰‡ï¼Œé€‚åˆè¯†åˆ«ä¸€èˆ¬æ‹ç…§å›¾ç‰‡ä¸­çš„æ–‡å­—ã€‚æ­¤ç±»æ¨¡å‹ä»¥ `scene-` å¼€å¤´ï¼Œå¦‚æ¨¡å‹ `scene-densenet_lite_136-gru`ã€‚\n* `doc`ï¼šæ–‡æ¡£å›¾ç‰‡ï¼Œé€‚åˆè¯†åˆ«è§„åˆ™æ–‡æ¡£çš„æˆªå›¾å›¾ç‰‡ï¼Œå¦‚ä¹¦ç±æ‰«æä»¶ç­‰ã€‚æ­¤ç±»æ¨¡å‹ä»¥ `doc-` å¼€å¤´ï¼Œå¦‚æ¨¡å‹ `doc-densenet_lite_136-gru`ã€‚\n* `number`ï¼šä»…è¯†åˆ«**çº¯æ•°å­—**ï¼ˆåªèƒ½è¯†åˆ« `0~9` åä¸ªæ•°å­—ï¼‰å›¾ç‰‡ï¼Œé€‚åˆé“¶è¡Œå¡å·ã€èº«ä»½è¯å·ç­‰åœºæ™¯ã€‚æ­¤ç±»æ¨¡å‹ä»¥ `number-` å¼€å¤´ï¼Œå¦‚æ¨¡å‹ `number-densenet_lite_136-gru`ã€‚\n* `general`: é€šç”¨åœºæ™¯ï¼Œé€‚åˆå›¾ç‰‡æ— æ˜æ˜¾å€¾å‘çš„ä¸€èˆ¬å›¾ç‰‡ã€‚æ­¤ç±»æ¨¡å‹æ— ç‰¹å®šå¼€å¤´ï¼Œä¸æ—§ç‰ˆæ¨¡å‹åç§°ä¿æŒä¸€è‡´ï¼Œå¦‚æ¨¡å‹ `densenet_lite_136-gru`ã€‚\n\n> æ³¨æ„ âš ï¸ï¼šä»¥ä¸Šè¯´æ˜ä»…ä¾›å‚è€ƒï¼Œå…·ä½“é€‰æ‹©æ¨¡å‹æ—¶å»ºè®®ä»¥å®é™…æ•ˆæœä¸ºå‡†ã€‚\n\næ›´å¤šè¯´æ˜è§ï¼š[å¯ç”¨æ¨¡å‹](https://cnocr.readthedocs.io/zh-cn/stable/models/)ã€‚\n\n| `rec_model_name`                                             | PyTorch ç‰ˆæœ¬ | ONNX ç‰ˆæœ¬ | æ¨¡å‹åŸå§‹æ¥æº | æ¨¡å‹æ–‡ä»¶å¤§å° | æ”¯æŒè¯­è¨€                            | æ˜¯å¦æ”¯æŒç«–æ’æ–‡å­—è¯†åˆ« |\n| ------------------------------------------------------------ | ------------ | --------- | ------------ | ------------ | ----------------------------------- | -------------------- |\n| **densenet_lite_136-gru** ğŸ†•                                  | âˆš            | âˆš         | cnocr        | 12 M         | ç®€ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—                | X                    |\n| **scene-densenet_lite_136-gru** ğŸ†•                            | âˆš            | âˆš         | cnocr        | 12 M         | ç®€ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—                | X                    |\n| **doc-densenet_lite_136-gru** ğŸ†•                              | âˆš            | âˆš         | cnocr        | 12 M         | ç®€ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—                | X                    |\n| **densenet_lite_246-gru_base** ğŸ†• <br /> ([æ˜Ÿçƒä¼šå‘˜](https://t.zsxq.com/FEYZRJQ)ä¸“äº«) | âˆš            | âˆš         | cnocr        | 25 M         | ç®€ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—                | X                    |\n| **scene-densenet_lite_246-gru_base** ğŸ†• <br /> ([æ˜Ÿçƒä¼šå‘˜](https://t.zsxq.com/FEYZRJQ)ä¸“äº«) | âˆš            | âˆš         | cnocr        | 25 M         | ç®€ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—                | X                    |\n| **doc-densenet_lite_246-gru_base** ğŸ†• <br /> ([æ˜Ÿçƒä¼šå‘˜](https://t.zsxq.com/FEYZRJQ)ä¸“äº«) | âˆš            | âˆš         | cnocr        | 25 M         | ç®€ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—                | X                    |\n| **densenet_lite_666-gru_large** ğŸ†• <br />ï¼ˆè´­ä¹°é“¾æ¥ï¼š[Bç«™](https://mall.bilibili.com/neul-next/detailuniversal/detail.html?isMerchant=1&page=detailuniversal_detail&saleType=10&itemsId=11884138&loadingShow=1&noTitleBar=1&msource=merchant_share)ã€[Lemon Squeezy](https://ocr.lemonsqueezy.com/)ï¼‰ | âˆš            | âˆš         | cnocr        | 82 M         | ç®€ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—                | X                    |\n| **scene-densenet_lite_666-gru_large** ğŸ†• <br />ï¼ˆè´­ä¹°é“¾æ¥ï¼š[Bç«™](https://mall.bilibili.com/neul-next/detailuniversal/detail.html?isMerchant=1&page=detailuniversal_detail&saleType=10&itemsId=11883935&loadingShow=1&noTitleBar=1&msource=merchant_share)ã€[Lemon Squeezy](https://ocr.lemonsqueezy.com/)ï¼‰ | âˆš            | âˆš         | cnocr        | 82 M         | ç®€ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—                | X                    |\n| **doc-densenet_lite_666-gru_large** ğŸ†• <br />ï¼ˆè´­ä¹°é“¾æ¥ï¼š[Bç«™](https://mall.bilibili.com/neul-next/detailuniversal/detail.html?isMerchant=1&page=detailuniversal_detail&saleType=10&itemsId=11883965&loadingShow=1&noTitleBar=1&msource=merchant_share)ã€[Lemon Squeezy](https://ocr.lemonsqueezy.com/)ï¼‰ | âˆš            | âˆš         | cnocr        | 82 M         | ç®€ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—                | X                    |\n| **number-densenet_lite_136-fc** ğŸ†•                            | âˆš            | âˆš         | cnocr        | 2.7 M        | **çº¯æ•°å­—**ï¼ˆä»…åŒ…å« `0~9` åä¸ªæ•°å­—ï¼‰ | X                    |\n| **number-densenet_lite_136-gru**  ğŸ†• <br /> ([æ˜Ÿçƒä¼šå‘˜](https://t.zsxq.com/FEYZRJQ)ä¸“äº«) | âˆš            | âˆš         | cnocr        | 5.5 M        | **çº¯æ•°å­—**ï¼ˆä»…åŒ…å« `0~9` åä¸ªæ•°å­—ï¼‰ | X                    |\n| **number-densenet_lite_666-gru_large** ğŸ†• <br />ï¼ˆè´­ä¹°é“¾æ¥ï¼š[Bç«™](https://mall.bilibili.com/neul-next/detailuniversal/detail.html?isMerchant=1&page=detailuniversal_detail&saleType=10&itemsId=11884155&loadingShow=1&noTitleBar=1&msource=merchant_share)ã€[Lemon Squeezy](https://ocr.lemonsqueezy.com/)ï¼‰ | âˆš            | âˆš         | cnocr        | 55 M         | **çº¯æ•°å­—**ï¼ˆä»…åŒ…å« `0~9` åä¸ªæ•°å­—ï¼‰ | X                    |\n| ch_PP-OCRv5                                                  | X            | âˆš         | ppocr        | 16 M         | ç®€ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—                | âˆš                    |\n| ch_PP-OCRv5_server                                           | X            | âˆš         | ppocr        | 81 M         | ç®€ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—                | âˆš                    |\n| ch_PP-OCRv4                                                  | X            | âˆš         | ppocr        | 10 M         | ç®€ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—                | âˆš                    |\n| ch_PP-OCRv4_server                                           | X            | âˆš         | ppocr        | 86 M         | ç®€ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—                | âˆš                    |\n| ch_PP-OCRv3                                                  | X            | âˆš         | ppocr        | 10 M         | ç®€ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—                | âˆš                    |\n| ch_ppocr_mobile_v2.0                                         | X            | âˆš         | ppocr        | 4.2 M        | ç®€ä½“ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—                | âˆš                    |\n| en_PP-OCRv4                                                  | X            | âˆš         | ppocr        | 8.6 M        | **è‹±æ–‡**ã€æ•°å­—                      | âˆš                    |\n| en_PP-OCRv3                                                  | X            | âˆš         | ppocr        | 8.5 M        | **è‹±æ–‡**ã€æ•°å­—                      | âˆš                    |\n| en_number_mobile_v2.0                                        | X            | âˆš         | ppocr        | 1.8 M        | **è‹±æ–‡**ã€æ•°å­—                      | âˆš                    |\n| chinese_cht_PP-OCRv3                                         | X            | âˆš         | ppocr        | 11 M         | **ç¹ä½“ä¸­æ–‡**ã€è‹±æ–‡ã€æ•°å­—            | X                    |\n| japan_PP-OCRv3                                               | X            | âˆš         | ppocr        | 9.6 M         | **æ—¥æ–‡**ã€è‹±æ–‡ã€æ•°å­—                | âˆš                    |\n| korean_PP-OCRv3                                              | X            | âˆš         | ppocr        | 9.4 M         | **éŸ©æ–‡**ã€è‹±æ–‡ã€æ•°å­—                | âˆš                    |\n| latin_PP-OCRv3                                               | X            | âˆš         | ppocr        | 8.6 M         | **æ‹‰ä¸æ–‡**ã€è‹±æ–‡ã€æ•°å­—              | âˆš                    |\n| arabic_PP-OCRv3                                              | X            | âˆš         | ppocr        | 8.6 M         | **é˜¿æ‹‰ä¼¯æ–‡**ã€è‹±æ–‡ã€æ•°å­—            | âˆš                    |\n\n\n\n## æœªæ¥å·¥ä½œ\n\n* [x] æ”¯æŒå›¾ç‰‡åŒ…å«å¤šè¡Œæ–‡å­— (`Done`)\n* [x] crnnæ¨¡å‹æ”¯æŒå¯å˜é•¿é¢„æµ‹ï¼Œæå‡çµæ´»æ€§ (since `V1.0.0`)\n* [x] å®Œå–„æµ‹è¯•ç”¨ä¾‹ (`Doing`)\n* [x] ä¿®bugsï¼ˆç›®å‰ä»£ç è¿˜æ¯”è¾ƒå‡Œä¹±ã€‚ã€‚ï¼‰ (`Doing`)\n* [x] æ”¯æŒ`ç©ºæ ¼`è¯†åˆ«ï¼ˆsince `V1.1.0`ï¼‰\n* [x] å°è¯•æ–°æ¨¡å‹ï¼Œå¦‚ DenseNetï¼Œè¿›ä¸€æ­¥æå‡è¯†åˆ«å‡†ç¡®ç‡ï¼ˆsince `V1.1.0`ï¼‰\n* [x] ä¼˜åŒ–è®­ç»ƒé›†ï¼Œå»æ‰ä¸åˆç†çš„æ ·æœ¬ï¼›åœ¨æ­¤åŸºç¡€ä¸Šï¼Œé‡æ–°è®­ç»ƒå„ä¸ªæ¨¡å‹\n* [x] ç”± MXNet æ”¹ä¸º PyTorch æ¶æ„ï¼ˆsince `V2.0.0`ï¼‰\n* [x] åŸºäº PyTorch è®­ç»ƒæ›´é«˜æ•ˆçš„æ¨¡å‹\n* [x] æ”¯æŒåˆ—æ ¼å¼çš„æ–‡å­—è¯†åˆ«\n* [x] æ‰“é€šä¸ [CnSTD](https://github.com/breezedeus/cnstd) çš„æ— ç¼è¡”æ¥ï¼ˆsince `V2.2`ï¼‰\n* [ ] æ¨¡å‹ç²¾åº¦è¿›ä¸€æ­¥ä¼˜åŒ–\n* [ ] æ”¯æŒæ›´å¤šçš„åº”ç”¨åœºæ™¯\n\n\n\n## ç»™ä½œè€…æ¥æ¯å’–å•¡\n\nå¼€æºä¸æ˜“ï¼Œå¦‚æœæ­¤é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œå¯ä»¥è€ƒè™‘ [ç»™ä½œè€…åŠ ç‚¹æ²¹ğŸ¥¤ï¼Œé¼“é¼“æ°”ğŸ’ªğŸ»](https://cnocr.readthedocs.io/zh-cn/stable/buymeacoffee/) ã€‚\n\n---\n\nå®˜æ–¹ä»£ç åº“ï¼š[https://github.com/breezedeus/cnocr](https://github.com/breezedeus/cnocr)ã€‚\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "burningion--video-editing-mcp": {
      "owner": "burningion",
      "name": "video-editing-mcp",
      "url": "https://github.com/burningion/video-editing-mcp",
      "imageUrl": "https://github.com/burningion.png",
      "description": "Upload, edit, search, and generate videos using large language models and Video Jungle's tools. The server enables interaction with videos through a custom URI scheme for managing individual videos and projects.",
      "stars": 214,
      "forks": 29,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-25T07:41:40Z",
      "readme_content": "# Video Editor MCP server\n\n[![Video Jungle MCP Server](./assets/create-edit.png)](https://www.video-jungle.com)\n\nSee a demo here: [https://www.youtube.com/watch?v=KG6TMLD8GmA](https://www.youtube.com/watch?v=KG6TMLD8GmA)\n\nUpload, edit, search, and generate videos from everyone's favorite LLM and [Video Jungle](https://www.video-jungle.com/).\n\nYou'll need to sign up for an account at [Video Jungle](https://app.video-jungle.com/register) in order to use this tool, and add your API key.\n\n[![PyPI version](https://badge.fury.io/py/video-editor-mcp.svg)](https://badge.fury.io/py/video-editor-mcp)\n\n## Components\n\n### Resources\n\nThe server implements an interface to upload, generate, and edit videos with:\n- Custom vj:// URI scheme for accessing individual videos and projects\n- Each project resource has a name, description\n- Search results are returned with metadata about what is in the video, and when, allowing for edit generation directly\n\n### Prompts\n\nComing soon.\n\n### Tools\n\nThe server implements a few tools:\n- add-video\n  - Add a Video File for analysis from a URL. Returns an vj:// URI to reference the Video file\n- create-videojungle-project\n  - Creates a Video Jungle project to contain generative scripts, analyzed videos, and images for video edit generation\n- edit-locally\n  - Creates an OpenTimelineIO project and downloads it to your machine to open in a Davinci Resolve Studio instance (Resolve Studio _must_ already be running before calling this tool.) \n- generate-edit-from-videos\n  - Generates a rendered video edit from a set of video files\n- generate-edit-from-single-video\n  - Generate an edit from a single input video file\n- get-project-assets\n  - Get assets within a project for video edit generation.\n- search-videos\n  - Returns video matches based upon embeddings and keywords\n- update-video-edit\n  - Live update a video edit's information. If Video Jungle is open, edit will be updated in real time.\n\n### Using Tools in Practice\n\nIn order to use the tools, you'll need to sign up for Video Jungle and add your API key.\n\n**add-video**\n\nHere's an example prompt to invoke the `add-video` tool:\n\n```\ncan you download the video at https://www.youtube.com/shorts/RumgYaH5XYw and name it fly traps?\n```\n\nThis will download a video from a URL, add it to your library, and analyze it for retrieval later. Analysis is multi-modal, so both audio and visual components can be queried against.\n\n**search-videos**\n\nOnce you've got a video downloaded and analyzed, you can then do queries on it using the `search-videos` tool:\n\n```\ncan you search my videos for fly traps?\n```\n\nSearch results contain relevant metadata for generating a video edit according to details discovered in the initial analysis.\n\n**search-local-videos**\n\nYou must set the environment variable `LOAD_PHOTOS_DB=1` in order to use this tool, as it will make Claude prompt to access your files on your local machine.\n\nOnce that's done, you can search through your Photos app for videos that exist on your phone, using Apple's tags.\n\nIn my case, when I search for \"Skateboard\", I get 1903 video files.\n\n```\ncan you search my local video files for Skateboard?\n```\n\n**generate-edit-from-videos**\n\nFinally, you can use these search results to generate an edit:\n\n```\ncan you create an edit of all the times the video says \"fly trap\"?\n```\n\n(Currently), the video edits tool relies on the context within the current chat. \n\n**generate-edit-from-single-video**\n\nFinally, you can cut down an edit from a single, existing video:\n\n```\ncan you create an edit of all the times this video says the word \"fly trap\"?\n```\n\n## Configuration\n\nYou must login to [Video Jungle settings](https://app.video-jungle.com/profile/settings), and get your [API key](https://app.video-jungle.com/profile/settings). Then, use this to start Video Jungle MCP:\n\n```bash\n$ uv run video-editor-mcp YOURAPIKEY\n```\n\nTo allow this MCP server to search your Photos app on MacOS:\n\n```\n$ LOAD_PHOTOS_DB=1 uv run video-editor-mcp YOURAPIKEY\n```\n## Quickstart\n\n### Install\n\n#### Installing via Smithery\n\nTo install Video Editor for Claude Desktop automatically via [Smithery](https://smithery.ai/server/video-editor-mcp):\n\n```bash\nnpx -y @smithery/cli install video-editor-mcp --client claude\n```\n\n#### Claude Desktop\n\nYou'll need to adjust your `claude_desktop_config.json` manually:\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n<details>\n<details>\n  <summary>Published Server Configuration</summary>\n  \n ```json\n  \"mcpServers\": {\n    \"video-editor-mcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"video-editor-mcp\",\n        \"YOURAPIKEY\"\n      ]\n    }\n  }\n  ```\n</details>\n  <summary>Development/Unpublished Servers Configuration</summary>\n  \n ```json\n  \"mcpServers\": {\n    \"video-editor-mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/YOURDIRECTORY/video-editor-mcp\",\n        \"run\",\n        \"video-editor-mcp\",\n        \"YOURAPIKEY\"\n      ]\n    }\n  }\n  ```\n\n  With local Photos app access enabled (search your Photos app):\n\n  ```json\n    \"video-jungle-mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/<PATH_TO>/video-jungle-mcp\",\n        \"run\",\n        \"video-editor-mcp\",\n        \"<YOURAPIKEY>\"\n      ],\n     \"env\": {\n\t      \"LOAD_PHOTOS_DB\": \"1\"\n      }\n    },\n  ```\n\n</details>\n\nBe sure to replace the directories with the directories you've placed the repository in on **your** computer.\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### MCP Server Registry\n\n```\nmcp-name: io.github.burningion/video-editing-mcp\n```\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n(Be sure to replace `YOURDIRECTORY` and `YOURAPIKEY` with the directory this repo is in, and your Video Jungle API key, found in the settings page.)\n\n```bash\nnpx @modelcontextprotocol/inspector uv run --directory /Users/YOURDIRECTORY/video-editor-mcp video-editor-mcp YOURAPIKEY\n```\n\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n\nAdditionally, I've added logging to `app.log` in the project directory. You can add logging to diagnose API calls via a:\n\n```\nlogging.info(\"this is a test log\")\n```\n\nA reasonable way to follow along as you're workin on the project is to open a terminal session and do a:\n\n```bash\n$ tail -n 90 -f app.log\n```\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "c-rick--jimeng-mcp": {
      "owner": "c-rick",
      "name": "jimeng-mcp",
      "url": "https://github.com/c-rick/jimeng-mcp",
      "imageUrl": "https://github.com/c-rick.png",
      "description": "Integrates with the Jimeng AI service to generate images from text prompts. Supports customization of image parameters such as size, quality, and negative prompts without the need for third-party APIs.",
      "stars": 40,
      "forks": 12,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-18T10:20:11Z",
      "readme_content": "# Jimeng MCP æœåŠ¡å™¨\n\n\nä½¿ç”¨TypeScriptå®ç°çš„Model Context Protocol (MCP) æœåŠ¡å™¨é¡¹ç›®ï¼Œé›†æˆäº†å³æ¢¦AIå›¾åƒç”ŸæˆæœåŠ¡ï¼Œé€šè¿‡é€†å‘å·¥ç¨‹ç›´æ¥è°ƒç”¨å³æ¢¦å®˜æ–¹APIã€‚\n\n\n## åŠŸèƒ½\n\n- åŸºäºTypeScriptæ„å»º\n- ä½¿ç”¨tsupä½œä¸ºæ„å»ºå·¥å…·\n- å®ç°äº†MCPåè®®ï¼Œæ”¯æŒæ ‡å‡†çš„stdioé€šä¿¡\n- ç›´æ¥è°ƒç”¨å³æ¢¦AIå›¾åƒç”ŸæˆæœåŠ¡ï¼Œæ— éœ€ç¬¬ä¸‰æ–¹API\n- æä¾›å¤šç§å³æ¢¦æ¨¡å‹çš„å›¾åƒç”Ÿæˆå·¥å…·\n- æ”¯æŒå¤šç§å›¾åƒå‚æ•°è°ƒæ•´ï¼Œå¦‚å°ºå¯¸ã€ç²¾ç»†åº¦ã€è´Ÿé¢æç¤ºè¯ç­‰\n- æ”¯æŒå›¾ç‰‡æ··åˆ/å‚è€ƒå›¾ç”Ÿæˆï¼ˆé€šè¿‡filePathå‚æ•°ï¼Œæ”¯æŒæœ¬åœ°å›¾ç‰‡å’Œç½‘ç»œå›¾ç‰‡ï¼‰\n- æ”¯æŒè§†é¢‘ç”Ÿæˆï¼Œæ”¯æŒæ·»åŠ å‚è€ƒå›¾ç‰‡ï¼ˆé¦–å°¾å¸§é€šè¿‡filePathå‚æ•°è®¾ç½®ï¼‰\n\n## å®‰è£…\n\n### é€šè¿‡Smitheryå®‰è£…\n\nè¦é€šè¿‡ [Smithery](https://smithery.ai/server/@c-rick/jimeng-mcp) è‡ªåŠ¨ä¸ºClaude Desktopå®‰è£…jimeng-mcpï¼Œè¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š\n\n```bash\nnpx -y @smithery/cli install @c-rick/jimeng-mcp --client claude\n```\n\n### æ‰‹åŠ¨å®‰è£…\n```bash\n# ä½¿ç”¨yarnå®‰è£…ä¾èµ–\nyarn install\n\n# æˆ–ä½¿ç”¨npmå®‰è£…ä¾èµ–\nnpm install\n```\n\n## ç¯å¢ƒé…ç½®\n\nåœ¨MCPå®¢æˆ·ç«¯é…ç½®ï¼ˆå¦‚Claude Desktopï¼‰ä¸­è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š\n\nè¿›å…¥[Smitheryæ‰˜ç®¡é¡¹ç›®](https://smithery.ai/server/@c-rick/jimeng-mcp)ï¼Œç‚¹å‡»json, å¡«å…¥JIMENG_API_TOKENï¼Œ ç‚¹å‡»connect, ç”Ÿæˆä¸‹é¢mcpServers config json\n\n```json\n{\n  \"mcpServers\": {\n    \"jimeng-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@smithery/cli@latest\",\n        \"run\",\n        \"@c-rick/jimeng-mcp\",\n        \"--key\",\n        \"[Smitheryç”Ÿæˆ]\",\n        \"--profile\",\n        \"[Smitheryç”Ÿæˆ]\"\n      ]\n    }\n  }\n}\n```\n\n### è·å–JIMENG_API_TOKEN\n\n1. è®¿é—® [å³æ¢¦AIå®˜ç½‘](https://jimeng.jianying.com) å¹¶ç™»å½•è´¦å·\n2. æŒ‰F12æ‰“å¼€æµè§ˆå™¨å¼€å‘è€…å·¥å…·\n3. åœ¨Application > Cookiesä¸­æ‰¾åˆ°`sessionid`çš„å€¼\n4. å°†æ‰¾åˆ°çš„sessionidå€¼é…ç½®ä¸ºJIMENG_API_TOKENç¯å¢ƒå˜é‡\n\n## å¼€å‘\n\n```bash\n# å¼€å‘æ¨¡å¼è¿è¡Œ\nyarn dev\n\n# ä½¿ç”¨nodemonå¼€å‘å¹¶è‡ªåŠ¨é‡å¯\nyarn start:dev\n```\n\n## æ„å»º\n\n```bash\n# æ„å»ºé¡¹ç›®\nyarn build\n```\n\n## è¿è¡Œ\n\n```bash\n# å¯åŠ¨æœåŠ¡å™¨\nyarn start\n\n# æµ‹è¯•MCPæœåŠ¡å™¨\nyarn test\n```\n\n## Claude Desktop é…ç½®ç¤ºä¾‹\n\nä»¥ä¸‹æ˜¯åœ¨Claude Desktopä¸­é…ç½®æ­¤MCPæœåŠ¡å™¨çš„å®Œæ•´ç¤ºä¾‹:\n\n```json\n{\n  \"mcpServers\": {\n    \"jimeng\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/jimeng-mcp/lib/index.js\"],\n      \"env\": {\n        \"JIMENG_API_TOKEN\": \"your_jimeng_session_id_here\"\n      }\n    }\n  }\n}\n```\n\n## å³æ¢¦AIå›¾åƒç”Ÿæˆ\n\næœ¬MCPæœåŠ¡å™¨ç›´æ¥è°ƒç”¨å³æ¢¦AIå›¾åƒç”ŸæˆAPIï¼Œæä¾›å›¾åƒç”Ÿæˆå·¥å…·ï¼š\n\n`generateImage` - æäº¤å›¾åƒç”Ÿæˆè¯·æ±‚å¹¶è¿”å›å›¾åƒURLåˆ—è¡¨\n- å‚æ•°ï¼š\n  - `prompt`ï¼šç”Ÿæˆå›¾åƒçš„æ–‡æœ¬æè¿°ï¼ˆå¿…å¡«ï¼‰\n  - `filePath`ï¼šæœ¬åœ°å›¾ç‰‡è·¯å¾„æˆ–å›¾ç‰‡URLï¼ˆå¯é€‰ï¼Œè‹¥å¡«å†™åˆ™ä¸ºå›¾ç‰‡æ··åˆ/å‚è€ƒå›¾ç”ŸæˆåŠŸèƒ½ï¼‰\n  - `model`ï¼šæ¨¡å‹åç§°ï¼Œå¯é€‰å€¼: jimeng-3.0, jimeng-2.1, jimeng-2.0-pro, jimeng-2.0, jimeng-1.4, jimeng-xl-proï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºjimeng-2.1ï¼Œå›¾ç‰‡æ··åˆæ—¶è‡ªåŠ¨åˆ‡æ¢ä¸ºjimeng-2.0-proï¼‰\n  - `width`ï¼šå›¾åƒå®½åº¦ï¼Œé»˜è®¤å€¼ï¼š1024ï¼ˆå¯é€‰ï¼‰\n  - `height`ï¼šå›¾åƒé«˜åº¦ï¼Œé»˜è®¤å€¼ï¼š1024ï¼ˆå¯é€‰ï¼‰\n  - `sample_strength`ï¼šç²¾ç»†åº¦ï¼Œé»˜è®¤å€¼ï¼š0.5ï¼ŒèŒƒå›´0-1ï¼ˆå¯é€‰ï¼‰\n  - `negative_prompt`ï¼šåå‘æç¤ºè¯ï¼Œå‘Šè¯‰æ¨¡å‹ä¸è¦ç”Ÿæˆä»€ä¹ˆå†…å®¹ï¼ˆå¯é€‰ï¼‰\n\n> **æ³¨æ„ï¼š**\n> - `filePath` æ”¯æŒæœ¬åœ°ç»å¯¹/ç›¸å¯¹è·¯å¾„å’Œå›¾ç‰‡URLã€‚\n> - è‹¥æŒ‡å®š `filePath`ï¼Œå°†è‡ªåŠ¨è¿›å…¥å›¾ç‰‡æ··åˆ/å‚è€ƒå›¾ç”Ÿæˆæ¨¡å¼ï¼Œåº•å±‚æ¨¡å‹è‡ªåŠ¨åˆ‡æ¢ä¸º `jimeng-2.0-pro`ã€‚\n> - ç½‘ç»œå›¾ç‰‡éœ€ä¿è¯å¯å…¬å¼€è®¿é—®ã€‚\n\n### å›¾ç‰‡æ··åˆ/å‚è€ƒå›¾ç”ŸæˆåŠŸèƒ½\n\nå¦‚éœ€åŸºäºå›¾ç‰‡è¿›è¡Œæ··åˆç”Ÿæˆï¼Œåªéœ€ä¼ å…¥`filePath`å‚æ•°ï¼ˆæ”¯æŒæœ¬åœ°è·¯å¾„æˆ–å›¾ç‰‡URLï¼‰ï¼Œå³å¯å®ç°å›¾ç‰‡é£æ ¼èåˆã€å‚è€ƒå›¾ç”Ÿæˆç­‰é«˜çº§ç©æ³•ã€‚\n\n#### ç¤ºä¾‹ï¼š\n\n```javascript\n// å‚è€ƒå›¾ç‰‡æ··åˆç”Ÿæˆ\nclient.callTool({\n  name: \"generateImage\",\n  arguments: {\n    prompt: \"æ¢µé«˜é£æ ¼çš„çŒ«\",\n    filePath: \"./test.png\", // æœ¬åœ°å›¾ç‰‡è·¯å¾„\n    sample_strength: 0.6\n  }\n});\n```\n\næˆ–\n\n```javascript\n// ä½¿ç”¨ç½‘ç»œå›¾ç‰‡ä½œä¸ºå‚è€ƒ\nclient.callTool({\n  name: \"generateImage\",\n  arguments: {\n    prompt: \"æœªæ¥åŸå¸‚\",\n    filePath: \"https://example.com/your-image.png\"\n  }\n});\n```\n\n### æ”¯æŒçš„æ¨¡å‹\n\næœåŠ¡å™¨æ”¯æŒä»¥ä¸‹å³æ¢¦AIæ¨¡å‹ï¼š\n\n- å›¾ç‰‡æ¨¡å‹\n- `jimeng-3.1`ï¼šå³æ¢¦ç¬¬ä¸‰ä»£æ¨¡å‹ï¼Œä¸°å¯Œçš„ç¾å­¦å¤šæ ·æ€§ï¼Œç”»é¢æ›´é²œæ˜ç”ŸåŠ¨ ï¼ˆé»˜è®¤ï¼‰\n- `jimeng-3.0`ï¼šå³æ¢¦ç¬¬ä¸‰ä»£æ¨¡å‹ï¼Œæ•ˆæœæ›´å¥½ï¼Œæ”¯æŒæ›´å¼ºçš„å›¾åƒç”Ÿæˆèƒ½åŠ›\n- `jimeng-2.1`ï¼šå³æ¢¦2.1ç‰ˆæœ¬æ¨¡å‹ï¼Œé»˜è®¤æ¨¡å‹\n- `jimeng-2.0-pro`ï¼šå³æ¢¦2.0 Proç‰ˆæœ¬\n- `jimeng-2.0`ï¼šå³æ¢¦2.0æ ‡å‡†ç‰ˆæœ¬\n- `jimeng-1.4`ï¼šå³æ¢¦1.4ç‰ˆæœ¬\n- `jimeng-xl-pro`ï¼šå³æ¢¦XL Proç‰¹æ®Šç‰ˆæœ¬\n- è§†é¢‘æ¨¡å‹\n- `jimeng-video-3.0-pro`ï¼šå³æ¢¦è§†é¢‘3.0 Proæ¨¡å‹ï¼Œé€‚åˆé«˜è´¨é‡è§†é¢‘ç”Ÿæˆ\n- `jimeng-video-3.0`ï¼šå³æ¢¦è§†é¢‘3.0æ ‡å‡†æ¨¡å‹ï¼Œä¸»åŠ›è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼ˆé»˜è®¤ï¼‰\n- `jimeng-video-2.0-pro`ï¼šå³æ¢¦è§†é¢‘2.0 Proæ¨¡å‹ï¼Œå…¼å®¹æ€§å¥½ï¼Œé€‚åˆå¤šåœºæ™¯\n- `jimeng-video-2.0`ï¼šå³æ¢¦è§†é¢‘2.0æ ‡å‡†æ¨¡å‹ï¼Œé€‚åˆåŸºç¡€è§†é¢‘ç”Ÿæˆ\n\n### æŠ€æœ¯å®ç°\n\n- ç›´æ¥è°ƒç”¨å³æ¢¦å®˜æ–¹APIï¼Œæ— éœ€ç¬¬ä¸‰æ–¹æœåŠ¡\n- é€†å‘å·¥ç¨‹APIè°ƒç”¨æµç¨‹ï¼Œå®ç°å®Œæ•´çš„å›¾åƒç”Ÿæˆè¿‡ç¨‹\n- æ”¯æŒç§¯åˆ†è‡ªåŠ¨é¢†å–å’Œä½¿ç”¨\n- åŸºäºé¢å‘å¯¹è±¡è®¾è®¡ï¼Œå°†APIå®ç°å°è£…ä¸ºç±»\n- è¿”å›é«˜è´¨é‡å›¾åƒURLåˆ—è¡¨\n- æ”¯æŒå›¾ç‰‡ä¸Šä¼ ï¼Œè‡ªåŠ¨å¤„ç†æœ¬åœ°/ç½‘ç»œå›¾ç‰‡ï¼Œè‡ªåŠ¨åˆ‡æ¢æ··åˆæ¨¡å‹\n- å›¾ç‰‡æ··åˆæ—¶è‡ªåŠ¨ä¸Šä¼ å›¾ç‰‡åˆ°å³æ¢¦äº‘ç«¯ï¼Œæµç¨‹å…¨è‡ªåŠ¨\n\n### ä½¿ç”¨ç¤ºä¾‹\n\né€šè¿‡MCPåè®®è°ƒç”¨å›¾åƒç”ŸæˆåŠŸèƒ½ï¼š\n\n```javascript\n// ç”Ÿæˆå›¾åƒï¼ˆæ–‡æœ¬ç”Ÿæˆï¼‰\nclient.callTool({\n  name: \"generateImage\",\n  arguments: {\n    prompt: \"ä¸€åªå¯çˆ±çš„çŒ«å’ªåœ¨è‰åœ°ä¸Š\",\n    model: \"jimeng-3.0\",\n    width: 1024,\n    height: 1024,\n    sample_strength: 0.7,\n    negative_prompt: \"æ¨¡ç³Šï¼Œæ‰­æ›²ï¼Œä½è´¨é‡\"\n  }\n});\n\n// ç”Ÿæˆå›¾åƒï¼ˆå›¾ç‰‡æ··åˆ/å‚è€ƒå›¾ç”Ÿæˆï¼‰\nclient.callTool({\n  name: \"generateImage\",\n  arguments: {\n    prompt: \"æœªæ¥åŸå¸‚\",\n    filePath: \"https://example.com/your-image.png\"\n  }\n});\n```\n\n## å“åº”æ ¼å¼\n\nAPIå°†è¿”å›ç”Ÿæˆçš„å›¾åƒURLæ•°ç»„ï¼Œå¯ä»¥ç›´æ¥åœ¨å„ç±»å®¢æˆ·ç«¯ä¸­æ˜¾ç¤ºï¼š\n\n```javascript\n[\n  \"https://example.com/generated-image-1.jpg\",\n  \"https://example.com/generated-image-2.jpg\",\n  \"https://example.com/generated-image-3.jpg\",\n  \"https://example.com/generated-image-4.jpg\"\n]\n```\n\n## èµ„æº\n\næœåŠ¡å™¨è¿˜æä¾›äº†ä»¥ä¸‹ä¿¡æ¯èµ„æºï¼š\n\n- `greeting://{name}` - æä¾›ä¸ªæ€§åŒ–é—®å€™\n- `info://server` - æä¾›æœåŠ¡å™¨åŸºæœ¬ä¿¡æ¯\n- `jimeng-ai://info` - æä¾›å³æ¢¦AIå›¾åƒç”ŸæˆæœåŠ¡çš„ä½¿ç”¨è¯´æ˜\n\n## Cursoræˆ–Claudeä½¿ç”¨æç¤º\n\nåœ¨Cursoræˆ–Claudeä¸­ï¼Œä½ å¯ä»¥è¿™æ ·ä½¿ç”¨Jimengå›¾åƒç”ŸæˆæœåŠ¡ï¼š\n\n1. ç¡®ä¿å·²ç»é…ç½®äº†MCPæœåŠ¡å™¨\n2. æç¤ºClaude/Cursorç”Ÿæˆå›¾åƒï¼Œä¾‹å¦‚ï¼š\n   ```\n   è¯·ç”Ÿæˆä¸€å¼ å†™å®é£æ ¼çš„æ—¥è½ä¸‹çš„å±±è„‰å›¾ç‰‡\n   ```\n3. Claude/Cursorä¼šè°ƒç”¨Jimeng MCPæœåŠ¡å™¨ç”Ÿæˆå›¾åƒå¹¶æ˜¾ç¤º\n\n## å¸¸è§é—®é¢˜\n\n1. **å›¾åƒç”Ÿæˆå¤±è´¥**\n   - æ£€æŸ¥JIMENG_API_TOKENæ˜¯å¦æ­£ç¡®é…ç½®\n   - ç™»å½•å³æ¢¦å®˜ç½‘æ£€æŸ¥è´¦å·ç§¯åˆ†æ˜¯å¦å……è¶³\n   - å°è¯•æ›´æ¢æç¤ºè¯ï¼Œé¿å…æ•æ„Ÿå†…å®¹\n   - è‹¥ä¸ºå›¾ç‰‡æ··åˆï¼Œæ£€æŸ¥filePathè·¯å¾„/URLæ˜¯å¦æœ‰æ•ˆã€å›¾ç‰‡æ˜¯å¦å¯è®¿é—®\n   - ç½‘ç»œå›¾ç‰‡å»ºè®®ä½¿ç”¨httpsç›´é“¾ï¼Œé¿å…é˜²ç›—é“¾/æƒé™é—®é¢˜\n\n2. **æœåŠ¡å™¨æ— æ³•å¯åŠ¨**\n   - ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–\n   - ç¡®ä¿ç¯å¢ƒå˜é‡æ­£ç¡®è®¾ç½®\n   - æ£€æŸ¥Node.jsç‰ˆæœ¬æ˜¯å¦ä¸º14.0æˆ–æ›´é«˜\n\n## è®¸å¯è¯\n\nMIT \n\n## å³æ¢¦AIè§†é¢‘ç”Ÿæˆ\n\næœ¬MCPæœåŠ¡å™¨é›†æˆäº†å³æ¢¦AIè§†é¢‘ç”ŸæˆAPIï¼Œæä¾›è§†é¢‘ç”Ÿæˆå·¥å…·ï¼š\n\n`generateVideo` - æäº¤è§†é¢‘ç”Ÿæˆè¯·æ±‚å¹¶è¿”å›è§†é¢‘URL\n- å‚æ•°ï¼š\n  - `prompt`ï¼šç”Ÿæˆè§†é¢‘çš„æ–‡æœ¬æè¿°ï¼ˆå¿…å¡«ï¼‰\n  - `filePath`ï¼šé¦–å¸§å’Œå°¾å¸§å›¾ç‰‡è·¯å¾„ï¼Œæ”¯æŒæ•°ç»„ï¼Œæœ€å¤š2ä¸ªå…ƒç´ ï¼Œåˆ†åˆ«ä¸ºé¦–å¸§å’Œå°¾å¸§ï¼ˆå¯é€‰ï¼‰\n  - `model`ï¼šæ¨¡å‹åç§°ï¼Œé»˜è®¤jimeng-video-3.0ï¼ˆå¯é€‰ï¼‰\n  - `resolution`ï¼šåˆ†è¾¨ç‡ï¼Œå¯é€‰720pæˆ–1080pï¼Œé»˜è®¤720pï¼ˆå¯é€‰ï¼‰\n  - `width`ï¼šè§†é¢‘å®½åº¦ï¼Œé»˜è®¤å€¼ï¼š1024ï¼ˆå¯é€‰ï¼‰\n  - `height`ï¼šè§†é¢‘é«˜åº¦ï¼Œé»˜è®¤å€¼ï¼š1024ï¼ˆå¯é€‰ï¼‰\n  - `refresh_token`ï¼šå³æ¢¦APIä»¤ç‰Œï¼ˆå¯é€‰ï¼Œé€šå¸¸ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰\n  - `req_key`ï¼šè‡ªå®šä¹‰å‚æ•°ï¼Œå…¼å®¹æ—§æ¥å£ï¼ˆå¯é€‰ï¼‰\n\n> **æ³¨æ„ï¼š**\n> - `filePath` æ”¯æŒæœ¬åœ°ç»å¯¹/ç›¸å¯¹è·¯å¾„å’Œå›¾ç‰‡URLã€‚\n> - è‹¥æŒ‡å®š `filePath`ï¼Œå¯å®ç°é¦–å¸§/å°¾å¸§å®šåˆ¶çš„è§†é¢‘ç”Ÿæˆã€‚\n> - ç½‘ç»œå›¾ç‰‡éœ€ä¿è¯å¯å…¬å¼€è®¿é—®ã€‚\n\n### ä½¿ç”¨ç¤ºä¾‹\n\né€šè¿‡MCPåè®®è°ƒç”¨è§†é¢‘ç”ŸæˆåŠŸèƒ½ï¼š\n\n```javascript\n// ç”Ÿæˆè§†é¢‘ï¼ˆæ–‡æœ¬ç”Ÿæˆï¼‰\nclient.callTool({\n  name: \"generateVideo\",\n  arguments: {\n    prompt: \"ä¸€åªå°ç‹—åœ¨è‰åœ°ä¸Šå¥”è·‘ï¼Œé˜³å…‰æ˜åªšï¼Œé«˜æ¸…\",\n    model: \"jimeng-video-3.0\",\n    resolution: \"720p\",\n    width: 1024,\n    height: 1024\n  }\n});\n\n// ç”Ÿæˆè§†é¢‘ï¼ˆé¦–å¸§/å°¾å¸§å®šåˆ¶ï¼‰\nclient.callTool({\n  name: \"generateVideo\",\n  arguments: {\n    prompt: \"åŸå¸‚å¤œæ™¯å»¶æ—¶æ‘„å½±\",\n    filePath: [\"./first.png\", \"./last.png\"],\n    resolution: \"1080p\"\n  }\n});\n```\n\n## è§†é¢‘å“åº”æ ¼å¼\n\nAPIå°†è¿”å›ç”Ÿæˆçš„è§†é¢‘URLå­—ç¬¦ä¸²ï¼Œå¯ä»¥ç›´æ¥åœ¨å„ç±»å®¢æˆ·ç«¯ä¸­æ’­æ”¾ï¼š\n\n```javascript\n\"https://example.com/generated-video.mp4\"\n``` \n\n\n## æ”¯æŒapiæœåŠ¡å¯åŠ¨\n\nå¦‚éœ€ä»¥APIæœåŠ¡æ–¹å¼å¯åŠ¨ï¼ˆé€‚åˆHTTPæ¥å£è°ƒç”¨ï¼‰ï¼š\n\n```bash\ncp .env.example .env   # å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿\n# æ ¹æ®éœ€è¦ç¼–è¾‘.envï¼Œå¡«å†™JIMENG_API_TOKENç­‰é…ç½®\n\n# å¯åŠ¨APIæœåŠ¡\nyarn start:api\n```\n\nAPIæœåŠ¡å¯åŠ¨åå°†ç›‘å¬é…ç½®ç«¯å£ï¼Œæ”¯æŒé€šè¿‡HTTPæ¥å£è°ƒç”¨å³æ¢¦AIå›¾åƒå’Œè§†é¢‘ç”ŸæˆåŠŸèƒ½ã€‚ \n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "bytefer--mcp-flux-schnell": {
      "owner": "bytefer",
      "name": "mcp-flux-schnell",
      "url": "https://github.com/bytefer/mcp-flux-schnell",
      "imageUrl": "https://github.com/bytefer.png",
      "description": "Generate images from text descriptions using the Flux Schnell model through an MCP interface. This server connects with Cloudflare's Flux Schnell worker API to deliver image generation capabilities.",
      "stars": 5,
      "forks": 3,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-04-20T04:32:23Z",
      "readme_content": "# mcp-flux-schnell MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@bytefer/mcp-flux-schnell)](https://smithery.ai/server/@bytefer/mcp-flux-schnell)\n\nA TypeScript-based MCP server that implements a text-to-image generation tool using the Flux Schnell model. This server integrates with Cloudflare's Flux Schnell worker API to provide image generation capabilities through MCP.\n\n- [Creating your own Flux Schnell MCP Server is so easy! â€” Part 1](https://medium.com/@bytefer/creating-your-own-flux-schnell-mcp-server-is-so-easy-part-1-4b9a5b3fb14f)\n- [Creating your own Flux Schnell MCP Server is so easy! â€” Part 2](https://medium.com/@bytefer/creating-your-own-flux-schnell-mcp-server-is-so-easy-part-2-bd711836a493)\n\n## Features\n\n### Tools\n- `generate_image` - Generate images from text descriptions\n  - Takes a text prompt as input (1-2048 characters)\n  - Returns the path to the generated image file\n\n## Environment Variables\n\nThe following environment variables must be configured:\n\n- `FLUX_API_URL` - The URL of the Flux Schnell API endpoint\n- `FLUX_API_TOKEN` - Your authentication token for the Flux Schnell API\n- `WORKING_DIR` (optional) - Directory where generated images will be saved (defaults to current working directory)\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n# or\npnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n# or\npnpm build\n```\n\n## Installation\n\n### Installing via Smithery\n\nTo install Flux Schnell Image Generator for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@bytefer/mcp-flux-schnell):\n\n```bash\nnpx -y @smithery/cli install @bytefer/mcp-flux-schnell --client claude\n```\n\n### Cursor Configuration\n\nThere are two ways to configure the MCP server in Cursor:\n\n#### Project Configuration\n\nFor tools specific to a project, create a `.cursor/mcp.json` file in your project directory:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-flux-schnell\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-flux-schnell/build/index.js\"],\n      \"env\": {\n        \"FLUX_API_URL\": \"your flux api url\",\n        \"FLUX_API_TOKEN\": \"your flux api token\",\n        \"WORKING_DIR\": \"your working directory\"\n      }\n    }\n  }\n}\n```\n\nThis configuration will only be available within the specific project.\n\n#### Global Configuration\n\nFor tools that you want to use across all projects, create a `~/.cursor/mcp.json` file in your home directory with the same configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-flux-schnell\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-flux-schnell/build/index.js\"],\n      \"env\": {\n        \"FLUX_API_URL\": \"your flux api url\",\n        \"FLUX_API_TOKEN\": \"your flux api token\",\n        \"WORKING_DIR\": \"your working directory\"\n      }\n    }\n  }\n}\n```\n\nThis makes the MCP server available in all your Cursor workspaces.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "catalystneuro--mcp_read_images": {
      "owner": "catalystneuro",
      "name": "mcp_read_images",
      "url": "https://github.com/catalystneuro/mcp_read_images",
      "imageUrl": "https://github.com/catalystneuro.png",
      "description": "Analyze images using OpenRouter vision models like Claude-3.5-sonnet and Claude-3-opus through a simple API interface.",
      "stars": 8,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-07-14T12:27:13Z",
      "readme_content": "# MCP Read Images\n\nAn MCP server for analyzing images using OpenRouter vision models. This server provides a simple interface to analyze images using various vision models like Claude-3.5-sonnet and Claude-3-opus through the OpenRouter API.\n\n## Installation\n\n```bash\nnpm install @catalystneuro/mcp_read_images\n```\n\n## Configuration\n\nThe server requires an OpenRouter API key. You can get one from [OpenRouter](https://openrouter.ai/keys).\n\nAdd the server to your MCP settings file (usually located at `~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json` for VSCode):\n\n```json\n{\n  \"mcpServers\": {\n    \"read_images\": {\n      \"command\": \"read_images\",\n      \"env\": {\n        \"OPENROUTER_API_KEY\": \"your-api-key-here\",\n        \"OPENROUTER_MODEL\": \"anthropic/claude-3.5-sonnet\"  // optional, defaults to claude-3.5-sonnet\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n## Usage\n\nThe server provides a single tool `analyze_image` that can be used to analyze images:\n\n```typescript\n// Basic usage with default model\nuse_mcp_tool({\n  server_name: \"read_images\",\n  tool_name: \"analyze_image\",\n  arguments: {\n    image_path: \"/path/to/image.jpg\",\n    question: \"What do you see in this image?\"  // optional\n  }\n});\n\n// Using a specific model for this call\nuse_mcp_tool({\n  server_name: \"read_images\",\n  tool_name: \"analyze_image\",\n  arguments: {\n    image_path: \"/path/to/image.jpg\",\n    question: \"What do you see in this image?\",\n    model: \"anthropic/claude-3-opus-20240229\"  // overrides default and settings\n  }\n});\n```\n\n### Model Selection\n\nThe model is selected in the following order of precedence:\n1. Model specified in the tool call (`model` argument)\n2. Model specified in MCP settings (`OPENROUTER_MODEL` environment variable)\n3. Default model (anthropic/claude-3.5-sonnet)\n\n### Supported Models\n\nThe following OpenRouter models have been tested:\n- anthropic/claude-3.5-sonnet\n- anthropic/claude-3-opus-20240229\n\n## Features\n\n- Automatic image resizing and optimization\n- Configurable model selection\n- Support for custom questions about images\n- Detailed error messages\n- Automatic JPEG conversion and quality optimization\n\n## Error Handling\n\nThe server handles various error cases:\n- Invalid image paths\n- Missing API keys\n- Network errors\n- Invalid model selections\n- Image processing errors\n\nEach error will return a descriptive message to help diagnose the issue.\n\n## Development\n\nTo build from source:\n\n```bash\ngit clone https://github.com/catalystneuro/mcp_read_images.git\ncd mcp_read_images\nnpm install\nnpm run build\n```\n\n## License\n\nMIT License. See [LICENSE](LICENSE) for details.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "CaullenOmdahl--pexels-mcp-server": {
      "owner": "CaullenOmdahl",
      "name": "pexels-mcp-server",
      "url": "https://github.com/CaullenOmdahl/pexels-mcp-server",
      "imageUrl": "https://github.com/CaullenOmdahl.png",
      "description": "Access and retrieve photos, videos, and collections from Pexels using a standardized protocol. Supports search by various criteria and provides detailed information about media content.",
      "stars": 4,
      "forks": 6,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-07-30T15:07:46Z",
      "readme_content": "# Pexels MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@CaullenOmdahl/pexels-mcp-server)](https://smithery.ai/server/@CaullenOmdahl/pexels-mcp-server)\n\nA Model Context Protocol (MCP) server that provides access to the Pexels API, allowing AI models to search for and retrieve photos, videos, and collections from Pexels.\n\n## Features\n\n- Search for photos and videos by query, orientation, size, and color\n- Access curated and popular content from Pexels\n- Browse Pexels collections\n- Get detailed information about specific photos and videos\n- Access content via tools or direct URI resources\n\n## Requirements\n\n- Node.js 18 or higher\n- A Pexels API key (get one at [https://www.pexels.com/api/](https://www.pexels.com/api/))\n\n## Local Development\n\n1. Clone the repository\n2. Install dependencies\n   ```bash\n   pnpm install\n   ```\n3. Build the project\n   ```bash\n   pnpm build\n   ```\n4. Run in development mode\n   ```bash\n   PEXELS_API_KEY=your_api_key pnpm dev\n   ```\n\n## Deploying to Smithery\n\nThis MCP server is ready to be deployed to Smithery. Follow these steps:\n\n1. Add the server to Smithery or claim an existing server\n2. Go to the Deployments tab (only visible to authenticated owners)\n3. Deploy the server\n4. When configuring the deployment, provide your Pexels API key in the configuration settings\n\n## API Usage\n\nThe server provides the following tools:\n\n### Photo Tools\n\n- `searchPhotos`: Search for photos by query (use descriptive keywords for relevant results, e.g., 'Thai hotel reception', 'red sports car driving', not just 'hotel' or 'car'; combine with parameters like `orientation`, `size`, `color`, and `locale` for refined results), with optional filters for orientation, size, color, locale (e.g., 'en-US', 'es-ES'), page, and results per page. Returns metadata including photo IDs and URLs, plus current API rate limit status.\n- `downloadPhoto`: Fetches a specific photo by its ID and desired size (optional, defaults to 'original'). Available sizes: 'original', 'large2x', 'large', 'medium', 'small', 'portrait', 'landscape', 'tiny'. Returns a direct download link for the requested image size, suggested filename (including size), and attribution information. The AI client should use its available local tools (like `curl` or PowerShell's `Invoke-WebRequest`) to download the photo using the provided link.\n- `getCuratedPhotos`: Retrieve a curated set of photos from Pexels, optionally paginated.\n- `getPhoto`: Retrieve detailed information about a specific photo by its ID.\n\n### Video Tools\n\n- `searchVideos`: Search for videos by query (use descriptive keywords for relevant results, e.g., 'drone footage beach sunset', 'time lapse city traffic', not just 'beach' or 'city'; combine with parameters like `orientation` and `size` for refined results), with optional filters for orientation, size, locale (e.g., 'en-US', 'es-ES'), page, and results per page. Returns metadata including video IDs and URLs, plus current API rate limit status.\n- `getPopularVideos`: Retrieve a list of popular videos from Pexels, with optional filters for dimensions, duration, page, and results per page.\n- `getVideo`: Retrieve detailed information about a specific video by its ID.\n- `downloadVideo`: Fetches a specific video by its ID and preferred quality (hd/sd). Returns a direct download link, suggested filename, and attribution information. The AI client should use its available local tools (like `curl` or PowerShell's `Invoke-WebRequest`) to download the video using the provided link.\n\n### Collection Tools\n\n- `getFeaturedCollections`: Retrieve a list of featured collections from Pexels, optionally paginated.\n- ~~`getMyCollections`~~: (Commented out in code) Requires OAuth 2.0 authentication, not supported by this server.\n- `getCollectionMedia`: Retrieve media items (photos or videos) from a specific collection by collection ID, with optional filters for type, sort order, page, and results per page.\n\n### Resources\n\nThe server provides the following URI-addressable resources:\n\n- `pexels-photo://{id}`: Access a specific photo by ID\n- `pexels-video://{id}`: Access a specific video by ID\n- `pexels-collection://{id}`: Access a specific collection by ID\n\n## Error Handling\n\nThe server attempts to provide informative error messages for common issues like invalid API keys, rate limits, or missing resources. Successful responses also include the current Pexels API rate limit status (remaining requests, reset time) in the output.\n\n## Attribution Requirements\n\nWhen using the Pexels API, you must follow their attribution requirements:\n\n- Always show a prominent link to Pexels (e.g., \"Photos provided by Pexels\")\n- Always credit photographers (e.g., \"Photo by John Doe on Pexels\")\n\n## License\n\nISC",
      "npm_url": "",
      "npm_downloads": 0
    },
    "champierre--image-mcp-server": {
      "owner": "champierre",
      "name": "image-mcp-server",
      "url": "https://github.com/champierre/image-mcp-server",
      "imageUrl": "https://github.com/champierre.png",
      "description": "Analyzes images by accepting URLs or local file paths, providing detailed insights through advanced image recognition powered by the GPT-4o-mini model. Validates image URLs and supports loading images from local files and Base64 encoding.",
      "stars": 6,
      "forks": 5,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-08-09T18:23:14Z",
      "readme_content": "# image-mcp-server\n\n[æ—¥æœ¬èªã® README](README.ja.md)\n\n<a href=\"https://glama.ai/mcp/servers/@champierre/image-mcp-server\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@champierre/image-mcp-server/badge\" alt=\"Image Analysis MCP Server\" />\n</a>\n\n[![smithery badge](https://smithery.ai/badge/@champierre/image-mcp-server)](https://smithery.ai/server/@champierre/image-mcp-server)\nAn MCP server that receives image URLs or local file paths and analyzes image content using the GPT-4o-mini model.\n\n## Features\n\n- Receives image URLs or local file paths as input and provides detailed analysis of the image content\n- High-precision image recognition and description using the GPT-4o-mini model\n- Image URL validity checking\n- Image loading from local files and Base64 encoding\n\n## Installation\n\n### Installing via Smithery\n\nTo install Image Analysis Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@champierre/image-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @champierre/image-mcp-server --client claude\n```\n\n### Manual Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/champierre/image-mcp-server.git # or your forked repository\ncd image-mcp-server\n\n# Install dependencies\nnpm install\n\n# Compile TypeScript\nnpm run build\n```\n\n## Configuration\n\nTo use this server, you need an OpenAI API key. Set the following environment variable:\n\n```\nOPENAI_API_KEY=your_openai_api_key\n```\n\n## MCP Server Configuration\n\nTo use with tools like Cline, add the following settings to your MCP server configuration file:\n\n### For Cline\n\nAdd the following to `cline_mcp_settings.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-analysis\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/image-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your_openai_api_key\"\n      }\n    }\n  }\n}\n```\n\n### For Claude Desktop App\n\nAdd the following to `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-analysis\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/image-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your_openai_api_key\"\n      }\n    }\n  }\n}\n```\n\n## Usage\n\nOnce the MCP server is configured, the following tools become available:\n\n- `analyze_image`: Receives an image URL and analyzes its content.\n- `analyze_image_from_path`: Receives a local file path and analyzes its content.\n\n### Usage Examples\n\n**Analyzing from URL:**\n\n```\nPlease analyze this image URL: https://example.com/image.jpg\n```\n\n**Analyzing from local file path:**\n\n```\nPlease analyze this image: /path/to/your/image.jpg\n```\n\n### Note: Specifying Local File Paths\n\nWhen using the `analyze_image_from_path` tool, the AI assistant (client) must specify a **valid file path in the environment where this server is running**.\n\n- **If the server is running on WSL:**\n  - If the AI assistant has a Windows path (e.g., `C:\\...`), it needs to convert it to a WSL path (e.g., `/mnt/c/...`) before passing it to the tool.\n  - If the AI assistant has a WSL path, it can pass it as is.\n- **If the server is running on Windows:**\n  - If the AI assistant has a WSL path (e.g., `/home/user/...`), it needs to convert it to a UNC path (e.g., `\\\\wsl$\\Distro\\...`) before passing it to the tool.\n  - If the AI assistant has a Windows path, it can pass it as is.\n\n**Path conversion is the responsibility of the AI assistant (or its execution environment).** The server will try to interpret the received path as is.\n\n### Note: Type Errors During Build\n\nWhen running `npm run build`, you may see an error (TS7016) about missing TypeScript type definitions for the `mime-types` module.\n\n```\nsrc/index.ts:16:23 - error TS7016: Could not find a declaration file for module 'mime-types'. ...\n```\n\nThis is a type checking error, and since the JavaScript compilation itself succeeds, it **does not affect the server's execution**. If you want to resolve this error, install the type definition file as a development dependency.\n\n```bash\nnpm install --save-dev @types/mime-types\n# or\nyarn add --dev @types/mime-types\n```\n\n## Development\n\n```bash\n# Run in development mode\nnpm run dev\n```\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "chenyeju295--mcp_generate_images": {
      "owner": "chenyeju295",
      "name": "mcp_generate_images",
      "url": "https://github.com/chenyeju295/mcp_generate_images",
      "imageUrl": "https://github.com/chenyeju295.png",
      "description": "An image generation service that integrates with Cursor IDE, offering features such as customizable image aspect ratios, high-quality image generation, and batch processing capabilities.",
      "stars": 21,
      "forks": 3,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-08-29T07:27:23Z",
      "readme_content": "# AI å›¾åƒç”ŸæˆæœåŠ¡\n\nåŸºäºç«å±±å¼•æ“ï¼ˆæŠ–éŸ³è±†åŒ…ï¼‰çš„å›¾åƒç”ŸæˆæœåŠ¡ï¼Œä¸“é—¨è®¾è®¡ç”¨äºä¸ Cursor MCP æœåŠ¡é›†æˆã€‚æ”¯æŒè‡ªå®šä¹‰å›¾ç‰‡å®½é«˜æ¯”ã€ä¿å­˜è·¯å¾„ç­‰åŠŸèƒ½ï¼Œæä¾›é«˜è´¨é‡å›¾åƒç”Ÿæˆèƒ½åŠ›ã€‚\n\n## åŠŸèƒ½ç‰¹ç‚¹\n\n- æ”¯æŒé«˜è´¨é‡å›¾åƒç”Ÿæˆ\n- å¤šç§å¸¸è§å®½é«˜æ¯”æ”¯æŒï¼ˆ1:1ã€4:3ã€16:9ã€3:4ã€9:16ï¼‰\n- ç«å±±å¼•æ“è±†åŒ…æ¨¡å‹ï¼ˆdoubao-seedream-3-0-t2i-250415ï¼‰\n- è‡ªåŠ¨é‡è¯•å’Œè¯¦ç»†é”™è¯¯å¤„ç†\n- å®Œæ•´çš„è·¯å¾„å’Œæƒé™éªŒè¯\n- è¯¦ç»†çš„é”™è¯¯æç¤ºå’Œæ—¥å¿—\n- å¼‚æ­¥å¤„ç†æ”¯æŒ\n\n## ç¯å¢ƒå‡†å¤‡\n\n### 1. Python ç¯å¢ƒ\n\n- Python 3.10+\n- ä¸‹è½½åœ°å€ï¼š <https://www.python.org/downloads/>\n\n- æ¨èä½¿ç”¨ pyenv ç®¡ç† Python ç‰ˆæœ¬ï¼š\n\n```bash\n# macOS å®‰è£… pyenv\nbrew install pyenv\n\n# å®‰è£… Python\npyenv install 3.13.2\npyenv global 3.13.2\n```\n\n### 2. Nodejs ç¯å¢ƒ\n\n- ä¸‹è½½åœ°å€ï¼š <https://nodejs.org/zh-cn>  \n\n### 3. uv åŒ…ç®¡ç†å·¥å…·\n\nuv æ˜¯ä¸€ä¸ªå¿«é€Ÿçš„ Python åŒ…ç®¡ç†å™¨ï¼Œéœ€è¦å…ˆå®‰è£…ï¼š\n\n```bash\n# macOS å®‰è£… uv\nbrew install uv\n\n# æˆ–è€…ä½¿ç”¨ pip å®‰è£…\npip install uv\n```\n\n### 4. ç«å±±å¼•æ“ API å¯†é’¥\n\n1. è®¿é—® [ç«å±±å¼•æ“æ–¹èˆŸå¤§æ¨¡å‹æœåŠ¡](https://console.volcengine.com/ark)\n2. æ³¨å†Œ/ç™»å½•è´¦å·\n3. åˆ›å»ºæ–°çš„ API å¯†é’¥\n4. å¤åˆ¶å¯†é’¥å¹¶ä¿å­˜ï¼Œæ ¼å¼å¦‚ï¼š`YOUR_API_KEY`\n\n### 5. Cursor\n\n- ä¸‹è½½å¹¶å®‰è£… [Cursor IDE](https://cursor.sh/)\n- ç¡®ä¿ Cursor å·²æ­£ç¡®é…ç½® Python ç¯å¢ƒ\n\n## å®‰è£…é…ç½®\n\n### 1. å…‹éš†é¡¹ç›®\n\n```bash\ngit clone https://github.com/chenyeju295/mcp_generate_images.git\ncd mcp_generate_images\n```\n\n### 2. å®‰è£…ä¾èµ–(cd åˆ°mcp_generate_images å®‰è£…)\n \n```bash\npython3 -m pip install fastmcp requests 'volcengine-python-sdk[ark]'\n```\n\næˆ–è€…ä½¿ç”¨requirements.txtæ–‡ä»¶ï¼š\n\n```bash\npip install -r requirements.txt\n```\n\nå‡ºç°è¯ä¹¦é—®é¢˜å¯ä»¥ä½¿ç”¨ï¼š\n\n```bash\npython3 -m pip install fastmcp requests 'volcengine-python-sdk[ark]' --trusted-host pypi.org --trusted-host files.pythonhosted.org --upgrade --force-reinstall --no-cache-dir\n```\n\ntips: éœ€ç¡®ä¿å®‰è£…æˆåŠŸï¼Œå¦åˆ™é…ç½®MCP æœåŠ¡ä¼šæŠ¥çº¢ã€‚\n\n### 3. é…ç½® API å¯†é’¥\n\nè®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆæ¨èæ–¹å¼ï¼‰ï¼š\n\n```bash\nexport ARK_API_KEY=your_api_key_here\n```\n\næˆ–è€…åœ¨ ~/.bashrc æˆ– ~/.zshrc ä¸­æ·»åŠ ï¼š\n\n```bash\necho 'export ARK_API_KEY=your_api_key_here' >> ~/.zshrc\nsource ~/.zshrc\n```\n\néªŒè¯ç¯å¢ƒå˜é‡å·²è®¾ç½®ï¼š\n\n```bash\necho $ARK_API_KEY\n```\n\n### 4. é…ç½®æœåŠ¡\n\nåœ¨ `mcp_server.py` ä¸­å¯ä»¥ä¿®æ”¹ä»¥ä¸‹é…ç½®ï¼š\n\n```python\nCONFIG = {\n    \"api\": {\n        \"base_url\": \"https://ark.cn-beijing.volces.com/api/v3\",\n        \"model\": \"doubao-seedream-3-0-t2i-250415\",\n        \"timeout\": 120,\n        \"max_retries\": 3,\n        \"retry_delay\": 5\n    },\n    \"image\": {\n        \"max_width\": 1024,   \n        \"max_height\": 1024, \n        \"default_width\": 1024,\n        \"default_height\": 1024,\n        \"max_batch_size\": 1\n    },\n    \"output\": {\n        \"base_folder\": \"ä½ çš„é»˜è®¤ä¿å­˜è·¯å¾„\",\n        \"allowed_extensions\": [\".png\", \".jpg\", \".jpeg\"],\n        \"default_extension\": \".png\"\n    }\n}\n```\n\n## è¿è¡ŒæœåŠ¡\n\nå¼€å‘æ¨¡å¼è¿è¡Œï¼ˆå¸¦è°ƒè¯•ç•Œé¢ï¼‰ï¼š\n\n```bash\nuv run --with fastmcp fastmcp dev /Users/username/Documents/mcp_generate_images/mcp_server.py\n```\n\n## åœ¨ Cursor ä¸­ä½¿ç”¨\n \n### 1. åœ¨ Cursor ä¸­å¼•å…¥ MCP æœåŠ¡\n\nåœ¨ Cursor çš„ MCP é…ç½®ä¸­æ·»åŠ ï¼š\n\n```json\n{\n  \"mcpServers\": {\n    \"generate_images\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"fastmcp\",\n        \"fastmcp\",\n        \"run\",\n        \"/Users/chenyeju/Documents/github/mcp_generate_images/mcp_server.py\"\n      ]\n    } \n  }\n}\n```\n\n### 3. æœåŠ¡è¿è¡ŒæˆåŠŸç¤ºä¾‹\n\n![image.png](./images/image.png)\n\n### 4. åœ¨ Cursor Composer çš„ agent æ¨¡å¼ä¸‹ä½¿ç”¨\n\n![image.png](./images/image_2.png)\n\n## å‚æ•°è¯´æ˜\n\nå›¾åƒç”Ÿæˆå·¥å…·æ”¯æŒä»¥ä¸‹å‚æ•°ï¼š\n\n| å‚æ•°å | ç±»å‹ | å¿…å¡« | è¯´æ˜ |\n|-------|------|------|------|\n| prompt | å­—ç¬¦ä¸² | æ˜¯ | å›¾ç‰‡ç”Ÿæˆæç¤ºè¯ï¼Œå»ºè®®ä¸è¶…è¿‡500å­—ç¬¦ |\n| file_name | å­—ç¬¦ä¸² | æ˜¯ | ä¿å­˜çš„æ–‡ä»¶å(ä¸å«è·¯å¾„ï¼Œå¦‚æœæ²¡æœ‰åç¼€åˆ™é»˜è®¤ä½¿ç”¨.png) |\n| save_folder | å­—ç¬¦ä¸² | æ˜¯ | ä¿å­˜ç›®å½•çš„ç»å¯¹è·¯å¾„ |\n| aspect_ratio | å­—ç¬¦ä¸² | å¦ | å›¾ç‰‡çš„å®½é«˜æ¯”ï¼Œæ”¯æŒ '1:1', '4:3', '16:9', '3:4', '9:16'ã€‚é»˜è®¤ä¸º'1:1' |\n\n\n## ä½¿ç”¨ç¤ºä¾‹\n\n```\nç”Ÿæˆä¸€å¼ å®½é«˜æ¯”ä¸º16:9çš„é£æ™¯å›¾ç‰‡ï¼š\n\ngenerate_image(\n  prompt=\"A beautiful mountain landscape with sunset\", \n  file_name=\"landscape.png\", \n  save_folder=\"/Users/username/Documents/images\", \n  aspect_ratio=\"16:9\"\n)\n```\n\n## ä½¿ç”¨æ³¨æ„äº‹é¡¹\n\n1. **æ¨¡å‹**ï¼šä½¿ç”¨ç«å±±å¼•æ“è±†åŒ…æ¨¡å‹ï¼ˆdoubao-seedream-3-0-t2i-250415ï¼‰ï¼Œæ”¯æŒæœ€å¤§1024x1024çš„å°ºå¯¸ã€‚\n2. **é•¿å®½æ¯”**ï¼šå»ºè®®ä½¿ç”¨1:1çš„å®½é«˜æ¯”ï¼ˆæ­£æ–¹å½¢å›¾ç‰‡ï¼‰ï¼Œä¾‹å¦‚512x512æˆ–1024x1024ï¼Œä»¥è·å¾—æœ€ä½³æ•ˆæœå’Œç”Ÿæˆé€Ÿåº¦ã€‚\n3. **æç¤ºè¯**ï¼šç®€æ´æ˜äº†çš„æç¤ºè¯é€šå¸¸èƒ½è·å¾—æ›´å¥½çš„ç»“æœï¼Œå°½é‡ä¸è¶…è¿‡500å­—ç¬¦ã€‚æ”¯æŒä¸­æ–‡æç¤ºè¯ã€‚\n4. **è¶…æ—¶é—®é¢˜**ï¼šå¯¹äºå¤æ‚æç¤ºè¯æˆ–éæ­£æ–¹å½¢å›¾ç‰‡ï¼Œç”Ÿæˆå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ï¼Œæœ‰æ—¶ä¼šå¯¼è‡´è¶…æ—¶é”™è¯¯ã€‚\n5. **APIé™åˆ¶**ï¼šç«å±±å¼•æ“APIæ¯æ¬¡åªç”Ÿæˆä¸€å¼ å›¾ç‰‡ï¼Œç›¸æ¯”ä¹‹å‰çš„æ‰¹é‡ç”Ÿæˆæœ‰æ‰€ä¸åŒã€‚\n\n## é”™è¯¯æ’æŸ¥\n\nå¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š\n\n1. æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ\n2. ä¿å­˜è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼ˆå¿…é¡»æ˜¯ç»å¯¹è·¯å¾„ï¼‰\n3. ç›®å½•æƒé™æ˜¯å¦æ­£ç¡®\n4. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n5. API å¯†é’¥æ˜¯å¦æœ‰æ•ˆ\n6. Python ç¯å¢ƒæ˜¯å¦æ­£ç¡®é…ç½®\n7. uv æ˜¯å¦æ­£ç¡®å®‰è£…\n8. ä¾èµ–åŒ…æ˜¯å¦å®Œæ•´å®‰è£…\n\n## å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ\n\n| é”™è¯¯ä¿¡æ¯ | å¯èƒ½åŸå›  | è§£å†³æ–¹æ¡ˆ |\n|---------|---------|---------|\n| \"æœªèƒ½ç”Ÿæˆå›¾ç‰‡: API è¯·æ±‚è¶…æ—¶\" | ç½‘ç»œé—®é¢˜æˆ–è¯·æ±‚è€—æ—¶è¿‡é•¿ | ä½¿ç”¨æ›´ç®€å•çš„æç¤ºè¯ï¼Œæ£€æŸ¥ç½‘ç»œè¿æ¥ |\n| \"æœªèƒ½ç”Ÿæˆå›¾ç‰‡: API è°ƒç”¨é¢‘ç‡å—é™\" | ç«å±±å¼•æ“APIé¢‘ç‡é™åˆ¶ | ç­‰å¾…å‡ åˆ†é’Ÿåå†è¯• |\n| \"æœªèƒ½ç”Ÿæˆå›¾ç‰‡: API è®¤è¯å¤±è´¥\" | APIå¯†é’¥æ— æ•ˆ | æ£€æŸ¥å¹¶æ›´æ–°ç«å±±å¼•æ“APIå¯†é’¥ |\n| \"æ²¡æœ‰æƒé™ä¿å­˜å›¾ç‰‡åˆ°...\" | ç›®å½•æƒé™é—®é¢˜ | ç¡®ä¿ç›®å½•å­˜åœ¨ä¸”æœ‰å†™å…¥æƒé™ |\n| \"ä¸æ”¯æŒçš„å®½é«˜æ¯”\" | ä½¿ç”¨äº†ä¸æ”¯æŒçš„å®½é«˜æ¯” | ä½¿ç”¨æ”¯æŒçš„å®½é«˜æ¯”ï¼š'1:1', '4:3', '16:9', '3:4', '9:16' |\n| \"Failed to download generated images\" | å›¾ç‰‡ä¸‹è½½å¤±è´¥ | æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œç¡®ä¿èƒ½è®¿é—®ç«å±±å¼•æ“çš„å›¾ç‰‡URL | \n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "ckz--flux-img-mcp": {
      "owner": "ckz",
      "name": "flux-img-mcp",
      "url": "https://github.com/ckz/flux-img-mcp",
      "imageUrl": "https://github.com/ckz.png",
      "description": "Utilize advanced AI models to generate images from textual prompts, enabling users to convert their ideas into visual art. This server facilitates effortless image creation through simple command inputs.",
      "stars": 1,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-03-12T05:08:24Z",
      "readme_content": "# Flux Image MCP Server\n\nThis MCP server provides image generation capabilities using the Flux Schnell model on Replicate.\n\n## Installation\n\n0. Install the MCP SDK globally:\n```bash\nnpm install -g @modelcontextprotocol/sdk@latest\n```\n\n1. Clone this repository to your MCP servers directory:\n```bash\ncd ~/Documents/Cline/MCP\ngit clone https://github.com/yourusername/flux-img-mcp.git\ncd flux-img-mcp\nnpm install\n```\n\n\n\n2. Build the server:\n```bash\nnpm run build\n```\n\n3. Add the server configuration to your MCP settings file (either global or workspace):\n\n```json\n{\n  \"mcpServers\": {\n    \"flux-img\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/flux-img-mcp/build/index.js\"],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": []\n    }\n  }\n}\n```\n\n## Configuration\n\nThe server requires the following environment variable:\n\n- `REPLICATE_API_TOKEN`: Your Replicate API token. You can get this from your [Replicate account settings](https://replicate.com/account).\n\n## Usage\n\nOnce installed and configured, the server provides the following tool:\n\n### generate_image\n\nGenerates an image using the Flux Schnell model based on a text prompt.\n\nParameters:\n- `prompt` (string, required): Text description of the desired image\n\nExample usage:\n```typescript\n<use_mcp_tool>\n<server_name>flux-img</server_name>\n<tool_name>generate_image</tool_name>\n<arguments>\n{\n  \"prompt\": \"A beautiful sunset over mountains\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\nThe tool will return a JSON response containing:\n- `status`: The status of the generation request\n- `output`: The URL of the generated image (if successful)\n- `error`: Any error message (if failed)\n\n## Development\n\nTo make changes to the server:\n\n1. Modify the source code in `src/index.ts`\n2. Rebuild the server: `npm run build`\n3. Restart the MCP server for changes to take effect\n\n## Error Handling\n\nThe server includes comprehensive error handling for:\n- Missing API token\n- Invalid parameters\n- API request failures\n- Network issues\n\n## Security\n\n- Never commit your Replicate API token to version control\n- Always provide the token through environment variables\n- The server validates all input parameters before making API requests\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "ckz--flux-schnell-mcp": {
      "owner": "ckz",
      "name": "flux-schnell-mcp",
      "url": "https://github.com/ckz/flux-schnell-mcp",
      "imageUrl": "https://github.com/ckz.png",
      "description": "Generate images from text prompts using the Replicate API, enabling users to create customized visuals based on detailed descriptions. The server manages the communication with the API and handles errors effectively.",
      "stars": 3,
      "forks": 6,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-04-12T09:44:48Z",
      "readme_content": "# Flux Schnell MCP Server\n\nä¸€ä¸ªåŸºäºMCPï¼ˆModel Context Protocolï¼‰çš„æœåŠ¡å™¨ï¼Œç”¨äºé€šè¿‡Replicate APIè°ƒç”¨Flux Schnellæ¨¡å‹ç”Ÿæˆå›¾ç‰‡ã€‚\n\n## åŠŸèƒ½ç‰¹ç‚¹\n\n- æä¾›`generate_image`å·¥å…·ç”¨äºç”Ÿæˆå›¾ç‰‡\n- æ”¯æŒè‡ªå®šä¹‰æ–‡æœ¬æç¤ºè¯\n- è‡ªåŠ¨å¤„ç†ä¸Replicate APIçš„é€šä¿¡\n- å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œå“åº”\n\n## å‰ç½®è¦æ±‚\n\n1. Node.js (v14æˆ–æ›´é«˜ç‰ˆæœ¬)\n2. Replicate API Token\n3. MCPå…¼å®¹çš„ç¯å¢ƒï¼ˆå¦‚Claude Desktopï¼‰\n\n## è·å–Replicate API Token\n\n1. è®¿é—® [Replicateå®˜ç½‘](https://replicate.com/) å¹¶æ³¨å†Œè´¦å·\n2. ç™»å½•åè®¿é—® [API Tokensé¡µé¢](https://replicate.com/account/api-tokens)\n3. ç‚¹å‡»\"Create API token\"åˆ›å»ºæ–°çš„token\n4. å¤åˆ¶ç”Ÿæˆçš„tokenï¼ˆæ ¼å¼å¦‚ï¼šr8_xxxxxxï¼‰\n\n## å®‰è£…\n\n1. å…‹éš†é¡¹ç›®å¹¶å®‰è£…ä¾èµ–ï¼š\n```bash\ngit clone [repository-url]\ncd flux-schnell-mcp\nnpm install\n```\n\n2. æ„å»ºæœåŠ¡å™¨ï¼š\n```bash\nnpm run build\n```\n\n## é…ç½®\n\n### Claude Desktopé…ç½®\n\n1. æ‰“å¼€é…ç½®æ–‡ä»¶ï¼š\n   - MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n2. æ·»åŠ æœåŠ¡å™¨é…ç½®ï¼š\n```json\n{\n  \"mcpServers\": {\n    \"flux-schnell\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/flux-schnell-mcp/build/index.js\"],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": []\n    }\n  }\n}\n```\n\n### VSCode Rooé…ç½®\n\n1. æ‰“å¼€é…ç½®æ–‡ä»¶ï¼š\n   - Linux: `~/.vscode-remote/data/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`\n   - MacOS: `~/Library/Application Support/Code/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`\n   - Windows: `%APPDATA%/Code/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`\n\n2. æ·»åŠ ä¸ä¸Šè¿°ç›¸åŒçš„æœåŠ¡å™¨é…ç½®ã€‚\n\n## ä½¿ç”¨æ–¹æ³•\n\næœåŠ¡å™¨æä¾›äº†ä¸€ä¸ªåä¸º`generate_image`çš„å·¥å…·ï¼Œå¯ä»¥é€šè¿‡MCPè°ƒç”¨ï¼š\n\n```typescript\n<use_mcp_tool>\n<server_name>flux-schnell</server_name>\n<tool_name>generate_image</tool_name>\n<arguments>\n{\n  \"prompt\": \"a beautiful sunset over the ocean, digital art style\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n### å‚æ•°è¯´æ˜\n\n- `prompt`: ç”¨äºç”Ÿæˆå›¾ç‰‡çš„æ–‡æœ¬æè¿°ï¼ˆå¿…å¡«ï¼‰\n  - å»ºè®®ä½¿ç”¨è¯¦ç»†çš„æè¿°æ¥è·å¾—æ›´å¥½çš„ç”Ÿæˆç»“æœ\n  - å¯ä»¥åŒ…å«é£æ ¼ã€åœºæ™¯ã€ç»†èŠ‚ç­‰ä¿¡æ¯\n\n### å“åº”æ ¼å¼\n\næœåŠ¡å™¨å°†è¿”å›Replicate APIçš„å®Œæ•´å“åº”ï¼ŒåŒ…å«ç”Ÿæˆçš„å›¾ç‰‡URLå’Œå…¶ä»–å…ƒæ•°æ®ã€‚\n\n## è°ƒè¯•\n\nç”±äºMCPæœåŠ¡å™¨é€šè¿‡stdioé€šä¿¡ï¼Œè°ƒè¯•å¯èƒ½æ¯”è¾ƒå›°éš¾ã€‚æ¨èä½¿ç”¨[MCP Inspector](https://github.com/modelcontextprotocol/inspector)ï¼š\n\n```bash\nnpm run inspector\n```\n\nInspectorå°†æä¾›ä¸€ä¸ªURLï¼Œå¯ä»¥åœ¨æµè§ˆå™¨ä¸­è®¿é—®è°ƒè¯•å·¥å…·ã€‚\n\n## æ³¨æ„äº‹é¡¹\n\n1. è¯·å¦¥å–„ä¿ç®¡æ‚¨çš„Replicate API Tokenï¼Œä¸è¦å°†å…¶åˆ†äº«ç»™ä»–äºº\n2. ç¡®ä¿åœ¨é…ç½®æ–‡ä»¶ä¸­ä½¿ç”¨æ­£ç¡®çš„æ–‡ä»¶è·¯å¾„\n3. ç”Ÿæˆå›¾ç‰‡å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…å“åº”\n4. å¦‚é‡åˆ°é”™è¯¯ï¼Œè¯·æ£€æŸ¥API Tokenæ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "CLOUDWERX-DEV--DiffuGen": {
      "owner": "CLOUDWERX-DEV",
      "name": "DiffuGen",
      "url": "https://github.com/CLOUDWERX-DEV/DiffuGen",
      "imageUrl": "https://github.com/CLOUDWERX-DEV.png",
      "description": "Seamlessly generate AI images directly within development environments by leveraging local Stable Diffusion models and precise control over parameters. Integrate with MCP-compatible IDEs to facilitate creative development without disruption.",
      "stars": 15,
      "forks": 6,
      "license": "MIT License",
      "language": "Shell",
      "updated_at": "2025-08-25T15:46:42Z",
      "readme_content": "# DiffuGen - Advanced Local Image Generator with MCP Integration\n\n<p align=\"center\">\n  <img src=\"diffugen.png\" alt=\"DiffuGen Logo\" width=\"400\"/>\n</p>\n\n<p align=\"center\">\n  <em>Your AI art studio embedded directly in code. Generate, iterate, and perfect visual concepts through this powerful MCP server for Cursor, Windsurf, and other compatible IDEs, utilizing cutting-edge Flux and Stable Diffusion models without disrupting your development process.</em>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/CLOUDWERX-DEV/diffugen/stargazers\"><img src=\"https://img.shields.io/github/stars/CLOUDWERX-DEV/diffugen\" alt=\"Stars Badge\"/></a>\n  <a href=\"https://github.com/CLOUDWERX-DEV/diffugen/network/members\"><img src=\"https://img.shields.io/github/forks/CLOUDWERX-DEV/diffugen\" alt=\"Forks Badge\"/></a>\n  <a href=\"https://github.com/CLOUDWERX-DEV/diffugen/issues\"><img src=\"https://img.shields.io/github/issues/CLOUDWERX-DEV/diffugen\" alt=\"Issues Badge\"/></a>\n  <a href=\"https://github.com/CLOUDWERX-DEV/diffugen/blob/master/LICENSE\"><img src=\"https://img.shields.io/github/license/CLOUDWERX-DEV/diffugen\" alt=\"License Badge\"/></a>\n</p>\n\n> â­ **New**: Now includes OpenAPI server support and OpenWebUI OpenAPI Tools (OWUI Version 0.60.0 Required) integration for seamless image generation and display in chat interfaces! The OpenAPI is seperate from the MCP server and allowss for initigrations into your own projects!\n\n## ğŸ“ƒ Table of Contents\n\n- [Introduction](#-introduction)\n- [Understanding MCP and DiffuGen](#-understanding-mcp-and-diffugen)\n- [Features](#-features)\n- [System Requirements](#-system-requirements)\n- [Installation](#-installation)\n- [IDE Setup Instructions](#-ide-setup-instructions)\n- [Usage](#-usage)\n  - [OpenAPI Server Usage](#openapi-server-usage)\n  - [Default Parameters by Model](#default-parameters-by-model)\n  - [Asking a LLM to Generate Images](#asking-a-llm-to-generate-images)\n  - [Parameter Reference](#parameter-reference)\n  - [Model-Specific Parameter Recommendations](#model-specific-parameter-recommendations)\n  - [Default Parameter Changes](#default-parameter-changes)\n  - [Command Line Usage Notes](#command-line-usage-notes)\n- [Configuration](#ï¸-configuration)\n  - [Configuration Approach](#configuration-approach)\n  - [Environment Variable Overrides](#environment-variable-overrides)\n  - [Setting IDE-Specific Configurations](#setting-ide-specific-configurations)\n  - [Key Configuration Elements](#key-configuration-elements)\n  - [IDE-Specific Options](#ide-specific-options)\n  - [Customizing Default Parameters](#customizing-default-parameters)\n  - [Updating Configuration Files](#updating-configuration-files)\n- [Advanced Usage](#-advanced-usage)\n  - [Using the OpenAPI Server](#using-the-openapi-server)\n- [License](#-license)\n- [Acknowledgments](#-acknowledgments)\n- [Contact](#-contact)\n\n## ğŸš€ Introduction\n\nDiffuGen is a powerful MCP-based image generation system that brings cutting-edge AI models directly into your development workflow. It seamlessly integrates both Flux models (Flux Schnell, Flux Dev) and Stable Diffusion variants (SDXL, SD3, SD1.5) into a unified interface, allowing you to leverage the unique strengths of each model family without switching tools. With comprehensive parameter control and multi-GPU support, DiffuGen scales from rapid concept sketches on modest hardware to production-quality visuals on high-performance systems.\n\nBuilt on top of the highly optimized [stable-diffusion.cpp](https://github.com/leejet/stable-diffusion.cpp) implementation, DiffuGen offers exceptional performance even on modest hardware while maintaining high-quality output.\n\n## ğŸ§  Understanding MCP and DiffuGen\n\n### What is MCP?\n\nMCP (Model Context Protocol) is a protocol that enables LLMs (Large Language Models) to access custom tools and services. In simple terms, an MCP client (like Cursor, Windsurf, Roo Code, or Cline) can make requests to MCP servers to access tools that they provide.\n\n### DiffuGen as an MCP Server\n\nDiffuGen functions as an MCP server that provides text-to-image generation capabilities. It implements the MCP protocol to allow compatible IDEs to send generation requests and receive generated images.\n\nThe server exposes two main tools:\n1. `generate_stable_diffusion_image`: Generate with Stable Diffusion models\n2. `generate_flux_image`: Generate with Flux models\n\n### Technical Architecture\n\nDiffuGen consists of several key components:\n\n- **setup-diffugen.sh**: The complete install utility and model downloader and manager\n- **diffugen.py**: The core Python script that implements the MCP server functionality and defines the generation tools\n- **diffugen.sh**: A shell script launcher that sets up the environment and launches the Python server\n- **diffugen.json**: Template configuration file for MCP integration with various IDEs (to be copied into IDE's MCP configuration)\n- **stable-diffusion.cpp**: The optimized C++ implementation of Stable Diffusion used for actual image generation\n\nThe system works by:\n1. Receiving prompt and parameter data from an MCP client\n2. Processing the request through the Python server\n3. Calling the stable-diffusion.cpp binary with appropriate parameters\n4. Saving the generated image to a configured output directory\n5. Returning the path and metadata of the generated image to the client\n\n### About stable-diffusion.cpp\n\n[stable-diffusion.cpp](https://github.com/leejet/stable-diffusion.cpp) is a highly optimized C++ implementation of the Stable Diffusion algorithm. Compared to the Python reference implementation, it offers:\n\n- Significantly faster inference speed (up to 3-4x faster)\n- Lower memory usage (works on GPUs with as little as 4GB VRAM)\n- Optimized CUDA kernels for NVIDIA GPUs\n- Support for various sampling methods and model formats\n- Support for model quantization for better performance\n- No Python dependencies for the core generation process\n\nThis allows DiffuGen to provide high-quality image generation with exceptional performance, even on modest hardware setups.\n\n## âœ¨ Features\n\n- **Multiple Model Support**: Generate images using various models including Flux Schnell, Flux Dev, SDXL, SD3, and SD1.5\n- **MCP Integration**: Seamlessly integrates with IDEs that support MCP (Cursor, Windsurf, Roo Code, Cline, etc.)\n- **OpenAPI Server**: Additional REST API interface for direct HTTP access to image generation capabilities\n- **Cross-Platform**: Works on Linux, macOS, and Windows (via native or WSL)\n- **Parameter Control**: Fine-tune your generations with controls for:\n  - Image dimensions (width/height)\n  - Sampling steps\n  - CFG scale\n  - Seed values\n  - Negative prompts (for SD models only, Flux does not support negative prompts.)\n  - Sampling methods\n- **CUDA Acceleration**: Utilizes GPU acceleration for faster image generation\n- **Natural Language Interface**: Generate images using simple natural language commands\n- **Smart Error Recovery**: Robust error handling with operation-aware recovery procedures\n- **User-Friendly Setup**: Interactive setup script with improved interrupt handling\n- **Resource Tracking**: Session-aware resource management for efficient cleanup\n- **Customizable Interface**: Support for custom ANSI art logos and visual enhancements\n\n## ğŸ’» System Requirements\n\n### Minimum Requirements:\n\n- **CPU**: 4-core processor (Intel i5/AMD Ryzen 5 or equivalent)\n- **RAM**: 8GB system memory\n- **Storage**: 5GB free disk space (SSD preferred for faster model loading)\n- **Python**: 3.8 or newer\n- **GPU**: Integrated graphics or entry-level dedicated GPU (optional)\n- **Network**: Broadband connection for model downloads (5+ Mbps)\n\n### Recommended Requirements:\n\n- **CPU**: 8+ core processor (Intel i7/i9 or AMD Ryzen 7/9)\n- **RAM**: 16GB+ system memory\n- **GPU**: NVIDIA GPU with 6GB+ VRAM (RTX 2060 or better for optimal performance)\n- **Storage**: 20GB+ free SSD space\n- **Python**: 3.10 or newer (3.11 offers best performance)\n- **Network**: High-speed connection (20+ Mbps) for efficient model downloads\n\n## ğŸ“¥ Installation\n\n### Automatic Installation (Recommended)\n\nThe easiest way to install DiffuGen is using the provided setup script:\n\n```bash\ngit clone https://github.com/CLOUDWERX-DEV/diffugen.git\ncd DiffuGen\nchmod +x diffugen.sh\nchmod +x setup_diffugen.sh\n./setup_diffugen.sh\n```\n\nFollow the interactive prompts to complete the installation.\n\nThe setup script will:\n- Install necessary dependencies\n- Clone and build stable-diffusion.cpp\n- Set up a Python virtual environment\n- Download selected models (Note: Some models require Clip\\VAE Models as well)\n- Configure file paths for your system\n\n### Manual Installation\n\nIf you prefer to install manually, follow these steps:\n\n1. Clone the repositories:\n\n```bash\ngit clone https://github.com/CLOUDWERX-DEV/diffugen.git\ncd DiffuGen\ngit clone --recursive https://github.com/leejet/stable-diffusion.cpp\n```\n\n2. Build stable-diffusion.cpp:\n\n```bash\ncd stable-diffusion.cpp\nmkdir -p build && cd build\n```\n\nWith CUDA:\n```bash\ncmake .. -DCMAKE_BUILD_TYPE=Release -DSD_CUDA=ON\nmake -j$(nproc)\ncd ../..\n```\n\nWithout CUDA:\n```bash\ncmake .. -DCMAKE_BUILD_TYPE=Release\nmake -j$(nproc)\ncd ../..\n```\n\n3. Create and activate a Python virtual environment:\n\n```bash\npython3 -m venv diffugen_env\nsource diffugen_env/bin/activate  # On Windows: diffugen_env\\Scripts\\activate\npip install -r requirements.txt\n```\n\n4. Download required models (structure shown below):\n\n```\nstable-diffusion.cpp/models/\nâ”œâ”€â”€ ae.sft                           # VAE model\nâ”œâ”€â”€ clip_l.safetensors               # CLIP model\nâ”œâ”€â”€ flux/\nâ”‚   â”œâ”€â”€ flux1-schnell-q8_0.gguf     # Flux Schnell model (default)\nâ”‚   â””â”€â”€ flux1-dev-q8_0.gguf          # Flux Dev model\nâ”œâ”€â”€ sd3-medium.safetensors           # SD3 model\nâ”œâ”€â”€ sdxl-1.0-base.safetensors        # SDXL model\nâ”œâ”€â”€ sdxl_vae-fp16-fix.safetensors    # SDXL VAE\nâ”œâ”€â”€ t5xxl_fp16.safetensors           # T5 model\nâ””â”€â”€ v1-5-pruned-emaonly.safetensors  # SD1.5 model\n```\n\nYou can download the models from the following sources:\n\n```bash\n# Create model directories\nmkdir -p stable-diffusion.cpp/models/flux\n\n# Flux models\n# Flux Schnell - Fast generation model (Q8 Quantized,requires t5xxl, clip-l, vae)\ncurl -L https://huggingface.co/leejet/FLUX.1-schnell-gguf/resolve/main/flux1-schnell-q8_0.gguf -o stable-diffusion.cpp/models/flux/flux1-schnell-q8_0.gguf\n\n# Flux Dev - Development model with better quality (Q8 QUantized, requires t5xxl, clip-l, vae)\ncurl -L https://huggingface.co/leejet/FLUX.1-dev-gguf/resolve/main/flux1-dev-q8_0.gguf -o stable-diffusion.cpp/models/flux/flux1-dev-q8_0.gguf\n\n# Required models for Flux\n# T5XXL Text Encoder\ncurl -L https://huggingface.co/Sanami/flux1-dev-gguf/resolve/main/t5xxl_fp16.safetensors -o stable-diffusion.cpp/models/t5xxl_fp16.safetensors\n\n# CLIP-L Text Encoder\ncurl -L https://huggingface.co/Sanami/flux1-dev-gguf/resolve/main/clip_l.safetensors -o stable-diffusion.cpp/models/clip_l.safetensors\n\n# VAE for image decoding\ncurl -L https://huggingface.co/pretentioushorsefly/flux-models/resolve/main/models/vae/ae.safetensors -o stable-diffusion.cpp/models/ae.sft\n\n# Stable Diffusion models\n# SDXL 1.0 Base Model (requires sdxl-vae)\ncurl -L https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors -o stable-diffusion.cpp/models/sd_xl_base_1.0.safetensors\n\n# SDXL VAE (required for SDXL)\ncurl -L https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/sdxl_vae-fp16-fix.safetensors -o stable-diffusion.cpp/models/sdxl_vae-fp16-fix.safetensors\n\n# Stable Diffusion 1.5 (standalone)\ncurl -L https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors -o stable-diffusion.cpp/models/v1-5-pruned-emaonly.safetensors\n\n# Stable Diffusion 3 Medium (standalone)\ncurl -L https://huggingface.co/leo009/stable-diffusion-3-medium/resolve/main/sd3_medium_incl_clips_t5xxlfp16.safetensors -o stable-diffusion.cpp/models/sd3_medium_incl_clips_t5xxlfp16.safetensors\n```\n\nNote: Model download may take a long time depending on your internet connection. The SDXL model is approximately 6GB, SD3 is about 13GB, SD1.5 is around 4GB, and Flux models are 8-13GB each.\n\n5. Update file paths in configuration:\n\nSet shell script as Executable\n\n```\nchmod +x diffugen.sh\n```\n\n**Configuration Approach**:\nDiffuGen uses a single configuration file (`diffugen.json`) as the source of truth for all settings. The workflow is:\n\n1. Edit `diffugen.json` in the DiffuGen root directory with your desired settings\n2. Run option 5 in `setup_diffugen.sh` to automatically update paths in this file\n3. Copy the content of `diffugen.json` to your IDE's MCP configuration file\n\nThe file contains all necessary settings:\n- File paths (command, SD_CPP_PATH, models_dir, output_dir)\n- Default model parameters (steps, cfg_scale, sampling_method)\n- VRAM usage settings\n- Metadata for IDE integration\n\n```json\n{\n  \"mcpServers\": {\n    \"diffugen\": {\n      \"command\": \"/home/cloudwerxlab/Desktop/Servers/MCP/Tools/DiffuGen/diffugen.sh\",\n      \"args\": [],\n      \"env\": {\n        \"CUDA_VISIBLE_DEVICES\": \"0\",\n        \"SD_CPP_PATH\": \"path/to/stable-diffusion.cpp\",\n        \"default_model\": \"flux-schnell\"\n      },\n      \"resources\": {\n        \"models_dir\": \"path/to/stable-diffusion.cpp/models\",\n        \"output_dir\": \"path/to/outputs\",\n        \"vram_usage\": \"adaptive\"\n      },\n      \"metadata\": {\n        \"name\": \"DiffuGen\",\n        \"version\": \"1.0\",\n        \"description\": \"Your AI art studio embedded directly in code. Generate, iterate, and perfect visual concepts through this powerful MCP server for Cursor, Windsurf, and other compatible IDEs, utilizing cutting-edge Flux and Stable Diffusion models without disrupting your development process.\",\n        \"author\": \"CLOUDWERX LAB\",\n        \"homepage\": \"https://github.com/CLOUDWERX-DEV/diffugen\",\n        \"usage\": \"Generate images using two primary methods:\\n1. Standard generation: 'generate an image of [description]' with optional parameters:\\n   - model: Choose from flux-schnell (default), flux-dev, sdxl, sd3, sd15\\n   - dimensions: width and height (default: 512x512)\\n   - steps: Number of diffusion steps (default: 20, lower for faster generation)\\n   - cfg_scale: Guidance scale (default: 7.0, lower for more creative freedom)\\n   - seed: For reproducible results (-1 for random)\\n   - sampling_method: euler, euler_a (default), heun, dpm2, dpm++2s_a, dpm++2m, dpm++2mv2, lcm\\n   - negative_prompt: Specify elements to avoid in the image\\n2. Quick Flux generation: 'generate a flux image of [description]' for faster results with fewer steps (default: 4)\"\n      },\n      \"cursorOptions\": {\n        \"autoApprove\": true,\n        \"category\": \"Image Generation\",\n        \"icon\": \"ğŸ–¼ï¸\",\n        \"displayName\": \"DiffuGen\"\n      },\n      \"windsurfOptions\": {\n        \"displayName\": \"DiffuGen\",\n        \"icon\": \"ğŸ–¼ï¸\",\n        \"category\": \"Creative Tools\"\n      },\n      \"default_params\": {\n        \"steps\": {\n          \"flux-schnell\": 8,\n          \"flux-dev\": 20,\n          \"sdxl\": 20,\n          \"sd3\": 20,\n          \"sd15\": 20\n        },\n        \"cfg_scale\": {\n          \"flux-schnell\": 1.0,\n          \"flux-dev\": 1.0,\n          \"sdxl\": 7.0,\n          \"sd3\": 7.0, \n          \"sd15\": 7.0\n        },\n        \"sampling_method\": {\n          \"flux-schnell\": \"euler\",\n          \"flux-dev\": \"euler\",\n          \"sdxl\": \"euler\",\n          \"sd3\": \"euler\",\n          \"sd15\": \"euler\"\n        }\n      }\n    }\n  }\n}\n```\n\n## ğŸ”§ IDE Setup Instructions\n\n### Setting up with Cursor\n\n1. Download and install [Cursor](https://cursor.sh)\n2. Go to Cursor Settings > MCP and click \"Add new global MCP server\"\n3. **Copy the contents of your DiffuGen's `diffugen.json` file** and paste it into `~/.cursor/mcp.json`\n4. Refresh MCP Servers in Settings > MCP\n5. Use DiffuGen by opening the AI chat panel (Ctrl+K or Cmd+K) and requesting image generation\n\n### Setting up with Windsurf\n\n1. Download and install [Windsurf](https://codeium.com/windsurf)\n2. Navigate to Windsurf > Settings > Advanced Settings or Command Palette > Open Windsurf Settings Page\n3. Scroll down to the Cascade section and click \"Add Server\" > \"Add custom server +\"\n4. **Copy the contents of your DiffuGen's `diffugen.json` file** and paste into `~/.codeium/windsurf/mcp_config.json`\n5. Use DiffuGen through the Cascade chat interface\n\n### Setting up with Roo Code\n\n1. Download and install [Roo Code](https://roo.ai)\n2. Locate the MCP configuration file for Roo Code\n3. **Copy the contents of your DiffuGen's `diffugen.json` file** into Roo Code's MCP configuration\n4. Use DiffuGen through the AI assistant feature\n\n### Setting up with Cline\n\n1. Download and install [Cline](https://cline.live)\n2. **Copy the contents of your DiffuGen's `diffugen.json` file** into Cline's MCP settings\n3. Use DiffuGen through the AI chat or command interface\n\n### Setting up with Claude in Anthropic Console\n\nClaude can use DiffuGen if you've set it up as an MCP server on your system. When asking Claude to generate images, be specific about using DiffuGen and provide the parameters you want to use.\n\n## ğŸ® Usage\n\nTo start the DiffuGen server manually:\n\n```bash\ncd /path/to/diffugen\n./diffugen.sh\n```\n\nOr using Python directly:\n\n```bash\ncd /path/to/diffugen\npython -m diffugen\n```\n\nYou should see: `DiffuGen ready` when the server is successfully started.\n\n### OpenAPI Server Usage\n\nThe OpenAPI server provides a REST API interface for direct HTTP access to DiffuGen's image generation capabilities. This is in addition to the MCP integration and can be useful for:\n- Direct HTTP API access\n- Integration with other tools that don't support MCP\n- Custom applications that need programmatic access\n\nFor detailed setup instructions and advanced configuration options, see the [OpenAPI Integration Guide](OPENAPI_SETUP.md).\n\nTo start the OpenAPI server:\n```bash\npython diffugen_openapi.py\n```\n\nThe server can be configured to use a different host or port if needed. By default, it runs on:\n- Host: 0.0.0.0\n- Port: 8080\n\nThe server will be available at http://0.0.0.0:8080 with interactive documentation at http://0.0.0.0:8080/docs.\n\nGenerated images are saved to the `/output` directory by default. If this directory is not accessible, the server will automatically create an `output` directory in the current working directory. Images are served through the `/images` endpoint.\n\n#### OpenWebUI Integration\n\n1. Open OpenWebUI Settings (gear icon)\n2. Navigate to the \"Tools\" section\n3. Click the \"+\" button to add a new tool server\n4. Enter the following details:\n   - URL: http://0.0.0.0:5199\n   - API Key: (leave empty)\n5. Click \"Save\"\n\nOnce added, DiffuGen will appear in the available tools list when clicking the tools icon in the chat interface. The following endpoints will be available:\n- `generate_stable_image_generate_stable_post`: Generate with Stable Diffusion\n- `generate_flux_image_endpoint_generate_flux_post`: Generate with Flux Models\n- `list_models_models_get`: List Available Models\n\nExample using curl:\n```bash\ncurl -X POST \"http://0.0.0.0:5199/generate/flux\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"prompt\": \"A beautiful sunset\", \"model\": \"flux-schnell\"}'\n```\n\nExample using Python requests:\n```python\nimport requests\n\nresponse = requests.post(\n    \"http://0.0.0.0:5199/generate/flux\",\n    json={\n        \"prompt\": \"A beautiful sunset\",\n        \"model\": \"flux-schnell\"\n    }\n)\nresult = response.json()\n```\n\n### Default Parameters by Model\n\nEach model has specific default parameters optimized for best results:\n\n| Model | Default Steps | Default CFG Scale | Best For |\n|-------|--------------|-----------------|----------|\n| flux-schnell | 8 | 1.0 | Fast drafts, conceptual images |\n| flux-dev | 20 | 1.0 | Better quality flux generations |\n| sdxl | 20 | 7.0 | High-quality detailed images |\n| sd3 | 20 | 7.0 | Latest generation with good quality |\n| sd15 | 20 | 7.0 | Classic baseline model |\n\nThese default parameters can be customized by adding a `default_params` section to your IDE's MCP configuration file:\n\n```json\n\"default_params\": {\n  \"steps\": {\n    \"flux-schnell\": 12,  // Customize steps for better quality\n    \"sdxl\": 30           // Increase steps for more detailed SDXL images\n  },\n  \"cfg_scale\": {\n    \"sd15\": 9.0          // Higher cfg_scale for stronger prompt adherence\n  }\n}\n```\n\nYou only need to specify the parameters you want to override - any unspecified values will use the built-in defaults.\n\n> **Note**: For model-specific command line examples and recommendations, see [Model-Specific Parameter Recommendations](#model-specific-parameter-recommendations) section.\n\n### Asking a LLM to Generate Images\n\nHere are examples of how to ask an AI assistant to generate images with DiffuGen:\n\n#### Basic Requests:\n\n```\nGenerate an image of a cat playing with yarn\n```\n\n```\nCreate a picture of a futuristic cityscape with flying cars\n```\n\n#### With Model Specification:\n\n```\nGenerate an image of a medieval castle using the sdxl model\n```\n\n```\nCreate a flux image of a sunset over mountains\n```\n\n#### With Advanced Parameters:\n\n```\nGenerate an image of a cyberpunk street scene, model=flux-dev, width=768, height=512, steps=25, cfg_scale=1.0, seed=42\n```\n\n```\nCreate an illustration of a fantasy character with model=sd15, width=512, height=768, steps=30, cfg_scale=7.5, sampling_method=dpm++2m, negative_prompt=blurry, low quality, distorted\n```\n\n### Parameter Reference\n\nDiffuGen can be used from the command line with the following basic syntax:\n\n```bash\n./diffugen.sh \"Your prompt here\" [options]\n```\n\nExample:\n```bash\n./diffugen.sh \"A futuristic cityscape with flying cars\"\n```\n\nThis command generates an image using default parameters (flux-schnell model, 512x512 resolution, etc.) and saves it to the configured output directory.\n\nBelow are the parameters that can be used with DiffuGen (applicable to both MCP interface and command line):\n\n| Parameter | Description | Default | Valid Values | Command Line Flag |\n|-----------|-------------|---------|-------------|-------------------|\n| model | The model to use for generation | flux-schnell/sd15 | flux-schnell, flux-dev, sdxl, sd3, sd15 | --model |\n| width | Image width in pixels | 512 | 256-2048 | --width |\n| height | Image height in pixels | 512 | 256-2048 | --height |\n| steps | Number of diffusion steps | model-specific | 1-100 | --steps |\n| cfg_scale | Classifier-free guidance scale | model-specific | 0.1-30.0 | --cfg-scale |\n| seed | Random seed for reproducibility | -1 (random) | -1 or any integer | --seed |\n| sampling_method | Diffusion sampling method | euler | euler, euler_a, heun, dpm2, dpm++2s_a, dpm++2m, dpm++2mv2, lcm | --sampling-method |\n| negative_prompt | Elements to avoid in the image | \"\" (empty) | Any text string | --negative-prompt |\n| output_dir | Directory to save images | Config-defined | Valid path | --output-dir |\n\nThese parameters can be specified when asking an AI assistant to generate images or when using the command line interface. Parameters are passed in different formats depending on the interface:\n\n- **In MCP/AI Assistant**: `parameter=value` (e.g., `model=sdxl, width=768, height=512`)\n- **In Command Line**: `--parameter value` (e.g., `--model sdxl --width 768 --height 512`)\n\nThe default values are chosen to provide good results out-of-the-box with minimal waiting time. For higher quality images, consider increasing steps or switching to models like sdxl.\n\n### Model-Specific Parameter Recommendations\n\n> **Note**: These recommendations build on the [Default Parameters by Model](#default-parameters-by-model) section and provide practical examples.\n\nFor best results when using specific models via command line:\n\n#### Flux Models (flux-schnell, flux-dev)\n```bash\n# Flux-Schnell (fastest)\n./diffugen.sh \"Vibrant colorful abstract painting\" \\\n  --model flux-schnell \\\n  --cfg-scale 1.0 \\\n  --sampling-method euler \\\n  --steps 8\n\n# Flux-Dev (better quality)\n./diffugen.sh \"Detailed fantasy landscape with mountains and castles\" \\\n  --model flux-dev \\\n  --cfg-scale 1.0 \\\n  --sampling-method euler \\\n  --steps 20\n```\n\n#### Standard SD Models (sdxl, sd3, sd15)\n```bash\n# SDXL (highest quality)\n./diffugen.sh \"Hyperrealistic portrait of a Celtic warrior\" \\\n  --model sdxl \\\n  --cfg-scale 7.0 \\\n  --sampling-method dpm++2m \\\n  --steps 30\n\n# SD15 (classic model)\n./diffugen.sh \"Photorealistic landscape at sunset\" \\\n  --model sd15 \\\n  --cfg-scale 7.0 \\\n  --sampling-method euler_a \\\n  --steps 20\n```\n\n### Default Parameter Changes\n\nThe command-line interface of DiffuGen uses the following defaults if not otherwise specified in configuration:\n\n- Default Model: If not specified, function-appropriate models are used (flux-schnell for Flux functions, sd15 for SD functions)\n- Default Sampling Method: `euler` (best for Flux models)\n- Default CFG Scale: `1.0` for Flux models, `7.0` for standard SD models\n- Default Steps: `8` for flux-schnell, `20` for other models\n- Default Dimensions: 512x512 pixels\n\nWhen using the command line, you don't need to specify these parameters unless you want to override the defaults. If you frequently use specific parameters, consider adding them to your configuration file rather than specifying them on each command line.\n\n### Command Line Usage Notes\n\n- Generated images are saved to the configured output directory with filenames based on timestamp and parameters\n- You can generate multiple images in sequence by running the command multiple times\n- For batch processing, consider creating a shell script that calls DiffuGen with different parameters\n- To see all available command-line options, run `./diffugen.sh --help`\n- The same engine powers both the MCP interface and command-line tool, so quality and capabilities are identical\n\n## âš™ï¸ Configuration\n\n### Configuration Approach\n\nDiffuGen uses a single configuration approach centered around the `diffugen.json` file:\n\n1. **Primary Configuration File**: `diffugen.json` in the DiffuGen root directory is the single source of truth for all settings\n2. **IDE Integration**: Copy the contents of `diffugen.json` to your IDE's MCP configuration file\n3. **Environment Variables**: For advanced usage, you can override settings with environment variables\n\n### Environment Variable Overrides\n\nFor advanced usage, you can override settings using environment variables:\n\n- `SD_CPP_PATH`: Override the path to stable-diffusion.cpp\n- `DIFFUGEN_OUTPUT_DIR`: Override the output directory\n- `DIFFUGEN_DEFAULT_MODEL`: Override the default model\n- `DIFFUGEN_VRAM_USAGE`: Override VRAM usage settings\n- `CUDA_VISIBLE_DEVICES`: Control which GPUs are used for generation\n\n### Setting IDE-Specific Configurations\n\nDiffuGen allows you to have different configurations for different IDEs by using environment variables in each IDE's MCP configuration. This lets you maintain a single base `diffugen.json` while customizing parameters per IDE.\n\nThe configuration priority works as follows:\n1. Environment variables (highest priority)\n2. Settings from local `diffugen.json` file (base configuration)\n\n**Example: Different Output Directories for Different IDEs**\n\nFor Cursor (in `~/.cursor/mcp.json`):\n```json\n\"env\": {\n  \"CUDA_VISIBLE_DEVICES\": \"0\",\n  \"SD_CPP_PATH\": \"/path/to/stable-diffusion.cpp\",\n  \"DIFFUGEN_OUTPUT_DIR\": \"/cursor/specific/output/directory\",\n  \"default_model\": \"flux-schnell\"\n}\n```\n\nFor Windsurf (in `~/.codeium/windsurf/mcp_config.json`):\n```json\n\"env\": {\n  \"CUDA_VISIBLE_DEVICES\": \"0\",\n  \"SD_CPP_PATH\": \"/path/to/stable-diffusion.cpp\",\n  \"DIFFUGEN_OUTPUT_DIR\": \"/windsurf/specific/output/directory\",\n  \"default_model\": \"sdxl\"\n}\n```\n\n**Example: Different Default Models and VRAM Settings**\n\n```json\n\"env\": {\n  \"CUDA_VISIBLE_DEVICES\": \"0\",\n  \"SD_CPP_PATH\": \"/path/to/stable-diffusion.cpp\",\n  \"default_model\": \"flux-dev\", \n  \"DIFFUGEN_VRAM_USAGE\": \"maximum\"\n}\n```\n\nThis approach lets you customize DiffuGen's behavior per IDE while still using the same underlying installation.\n\n### Key Configuration Elements\n\n#### Command and Arguments\n\n- **command**: Full path to the `diffugen.sh` script (must be absolute path)\n- **args**: Additional command-line arguments to pass to the script (usually left empty)\n\n#### Environment Variables\n\n- **CUDA_VISIBLE_DEVICES**: Controls which GPUs are used for generation\n  - `\"0\"`: Use only the first GPU\n  - `\"1\"`: Use only the second GPU\n  - `\"0,1\"`: Use both first and second GPUs\n  - `\"-1\"`: Disable CUDA and use CPU only\n\n- **SD_CPP_PATH**: Path to the stable-diffusion.cpp installation directory\n  - This is used to locate the stable-diffusion.cpp binary and models\n\n- **default_model**: The default model to use when none is specified\n\n#### Resource Configuration\n\n- **models_dir**: Directory containing the model files\n  - Should point to the `models` directory inside your stable-diffusion.cpp installation\n\n- **output_dir**: Directory where generated images will be saved\n  - Must be writable by the user running DiffuGen\n\n- **vram_usage**: Controls VRAM usage strategy\n  - `\"adaptive\"`: Automatically adjust memory usage based on available VRAM\n  - `\"minimal\"`: Use minimal VRAM at the cost of speed\n  - `\"balanced\"`: Balance memory usage and speed (default)\n  - `\"maximum\"`: Use maximum available VRAM for best performance\n\n### IDE-Specific Options\n\nEach IDE has specific options you can customize in the `diffugen.json` file:\n\n#### Cursor Options\n\n```json\n\"cursorOptions\": {\n  \"autoApprove\": true,\n  \"category\": \"Image Generation\",\n  \"icon\": \"ğŸ–¼ï¸\",\n  \"displayName\": \"DiffuGen\"\n}\n```\n\n#### Windsurf Options\n\n```json\n\"windsurfOptions\": {\n  \"displayName\": \"DiffuGen\",\n  \"icon\": \"ğŸ–¼ï¸\",\n  \"category\": \"Creative Tools\"\n}\n```\n\n### Customizing Default Parameters\n\nYou can customize default parameters for each model in the `default_params` section:\n\n```json\n\"default_params\": {\n  \"steps\": {\n    \"flux-schnell\": 12,\n    \"sdxl\": 30\n  },\n  \"cfg_scale\": {\n    \"sd15\": 9.0\n  },\n  \"sampling_method\": {\n    \"flux-schnell\": \"euler\",\n    \"sdxl\": \"dpm++2m\"\n  }\n}\n```\n\n### Updating Configuration Files\n\nWhen using the automatic setup script, a properly configured `diffugen.json` file is created with the correct paths for your system when you run option 5. To integrate DiffuGen with your IDE:\n\n1. Run option 5 in `setup_diffugen.sh` to update paths in `diffugen.json`\n2. Copy the entire contents of the generated `diffugen.json` file\n3. Paste it into your IDE's MCP configuration file (e.g., `~/.cursor/mcp.json`)\n4. Restart your IDE to apply changes\n\nThe key advantage of this approach is a single source of truth for configuration, making it easier to maintain and update your DiffuGen setup.\n\n## ğŸ“ƒ Advanced Usage\n\nThe DiffuGen Python module can be imported and used programmatically in your own Python scripts:\n\n```python\nfrom diffugen import generate_image\n\n# Generate an image programmatically\nresult = generate_image(\n    prompt=\"A starry night over a quiet village\",\n    model=\"sdxl\",\n    width=1024,\n    height=768,\n    steps=30,\n    cfg_scale=7.0,\n    seed=42,\n    sampling_method=\"dpm++2m\",\n    negative_prompt=\"blurry, low quality\"\n)\n\nprint(f\"Image saved to: {result['file_path']}\")\n```\n\n### Using the OpenAPI Server\n\nYou can also use the OpenAPI server programmatically in your applications:\n\n```python\nimport requests\n\ndef generate_image_via_api(prompt, model=\"flux-schnell\", width=512, height=512):\n    response = requests.post(\n        \"http://0.0.0.0:5199/generate/flux\",\n        json={\n            \"prompt\": prompt,\n            \"model\": model,\n            \"width\": width,\n            \"height\": height\n        }\n    )\n    return response.json()\n\n# Example usage\nresult = generate_image_via_api(\n    prompt=\"A magical forest at night\",\n    model=\"flux-schnell\",\n    width=768,\n    height=512\n)\nprint(f\"Generated image: {result['file_path']}\")\n```\n\n## ğŸ” Troubleshooting\n\n### Common Issues and Solutions\n\n1. **Missing models or incorrect paths**\n   - Ensure all model files are downloaded and placed in the correct directories\n   - Check that paths in the configuration file are correctly set\n   - Verify file permissions allow read access to model files\n\n2. **CUDA/GPU issues**\n   - Make sure your NVIDIA drivers are up-to-date\n   - Set `CUDA_VISIBLE_DEVICES` to target a specific GPU\n   - If running out of VRAM, try using a smaller model or reducing dimensions\n\n3. **Image quality issues**\n   - Increase steps for better quality (at the cost of generation time)\n   - Adjust CFG scale: higher for more prompt adherence, lower for creativity\n   - Try different sampling methods (dpm++2m often provides good results)\n   - Use more detailed prompts with specific style descriptions\n\n4. **File permission errors**\n   - Ensure the output directory is writable by the user running DiffuGen\n   - Check that all scripts have execution permissions (`chmod +x diffugen.sh`)\n\n### Getting Help\n\nIf you encounter issues not covered here, you can:\n- Check the GitHub repository for issues and solutions\n- Run with debug logging enabled: `DEBUG=1 ./diffugen.sh \"your prompt\"`\n- Contact the developers via GitHub issues\n\n## ğŸŒŸ Contributing\n\nContributions to DiffuGen are welcome! To contribute:\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes\n4. Submit a pull request\n\nPlease ensure your code follows the project's coding standards and includes appropriate tests.\n\n## ğŸ“„ License\n\nThis project is licensed under the Apache License - see the LICENSE file for details.\n\n* All models are licensed under their respective distribution and are not in any way licensed or provided by CLOUDWERX.DEV\n* HuggingFace.co is used to download models and is not affiliated in any way with CLOUDWERX.DEV\n\n## ğŸ™ Acknowledgments\n\n- [stable-diffusion.cpp](https://github.com/leejet/stable-diffusion.cpp) for the optimized C++ implementation\n- [Stability AI](https://stability.ai/) for Stable Diffusion models\n- [Black Forest Labs](https://blackforestlabs.ai/) for their Flux Models\n- [Hugging Face](https://huggingface.co/) for the download links\n- All contributors to the MCP protocol\n\n## ğŸ“¬ Contact\n\n- GitHub: [CLOUDWERX-DEV](https://github.com/CLOUDWERX-DEV)\n- Website: [cloudwerx.dev](http://cloudwerx.dev)\n- Mail: [sysop@cloudwerx.dev](mailto:sysop@cloudwerx.dev)\n- Discord: [Join our server](https://discord.gg/SvZFuufNTQ)\n\n```\n                   ______   __   ___   ___         _______              \n                  |   _  \\ |__|.'  _|.'  _|.--.--.|   _   |.-----.-----.\n                  |.  |   \\|  ||   _||   _||  |  ||.  |___||  -__|     |\n                  |.  |    \\__||__|  |__|  |_____||.  |   ||_____|__|__|\n                  |:  1    /                      |:  1   |             \n                  |::.. . /                       |::.. . |             \n                  `------'                        `-------'             \n```\n\n<p align=\"center\">\n  Made with â¤ï¸ by CLOUDWERX LAB\n</p> \n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "CLOUDWERX-DEV--gpt-image-1-mcp": {
      "owner": "CLOUDWERX-DEV",
      "name": "gpt-image-1-mcp",
      "url": "https://github.com/CLOUDWERX-DEV/gpt-image-1-mcp",
      "imageUrl": "https://github.com/CLOUDWERX-DEV.png",
      "description": "Enables AI assistants to generate and edit images from text prompts, supporting both creation and modification of images using specified masks. Integrates with various MCP clients and provides flexible workflows for image handling, including automatic file saving and comprehensive error reporting.",
      "stars": 16,
      "forks": 5,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-15T19:40:52Z",
      "readme_content": "<p align=\"center\">\n  <img src=\"logo.png\" alt=\"GPT Image 1 MCP Logo\" width=\"200\"/>\n</p>\n\n<h1 align=\"center\">@cloudwerxlab/gpt-image-1-mcp</h1>\n\n<p align=\"center\">\n  <a href=\"https://www.npmjs.com/package/@cloudwerxlab/gpt-image-1-mcp\"><img src=\"https://img.shields.io/npm/v/@cloudwerxlab/gpt-image-1-mcp.svg\" alt=\"npm version\"></a>\n  <a href=\"https://www.npmjs.com/package/@cloudwerxlab/gpt-image-1-mcp\"><img src=\"https://img.shields.io/npm/dm/@cloudwerxlab/gpt-image-1-mcp.svg\" alt=\"npm downloads\"></a>\n  <a href=\"https://github.com/CLOUDWERX-DEV/gpt-image-1-mcp/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/CLOUDWERX-DEV/gpt-image-1-mcp.svg\" alt=\"license\"></a>\n  <a href=\"https://nodejs.org/\"><img src=\"https://img.shields.io/node/v/@cloudwerxlab/gpt-image-1-mcp.svg\" alt=\"node version\"></a>\n  <a href=\"https://cloudwerx.dev\"><img src=\"https://img.shields.io/badge/website-cloudwerx.dev-blue\" alt=\"Website\"></a>\n</p>\n\n<p align=\"center\">\n  A Model Context Protocol (MCP) server for generating and editing images using the OpenAI <code>gpt-image-1</code> model.\n</p>\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/OpenAI-GPT--Image--1-6E46AE\" alt=\"OpenAI GPT-Image-1\">\n  <img src=\"https://img.shields.io/badge/MCP-Compatible-00A3E0\" alt=\"MCP Compatible\">\n</p>\n\n## ğŸš€ Quick Start\n\n<div align=\"center\">\n  <a href=\"https://www.npmjs.com/package/@cloudwerxlab/gpt-image-1-mcp\"><img src=\"https://img.shields.io/badge/NPX-Ready-red.svg\" alt=\"NPX Ready\"></a>\n</div>\n\n<p align=\"center\">Run this MCP server directly using NPX without installing it. <a href=\"https://www.npmjs.com/package/@cloudwerxlab/gpt-image-1-mcp\">View on npm</a>.</p>\n\n```bash\nnpx -y @cloudwerxlab/gpt-image-1-mcp\n```\n\n<p align=\"center\">The <code>-y</code> flag automatically answers \"yes\" to any prompts that might appear during the installation process.</p>\n\n### ğŸ“‹ Prerequisites\n\n<table>\n  <tr>\n    <td width=\"50%\" align=\"center\">\n      <img src=\"https://img.shields.io/badge/Node.js-v14+-339933?logo=node.js&logoColor=white\" alt=\"Node.js v14+\">\n      <p>Node.js (v14 or higher)</p>\n    </td>\n    <td width=\"50%\" align=\"center\">\n      <img src=\"https://img.shields.io/badge/OpenAI-API_Key-412991?logo=openai&logoColor=white\" alt=\"OpenAI API Key\">\n      <p>OpenAI API key with access to gpt-image-1</p>\n    </td>\n  </tr>\n</table>\n\n### ğŸ”‘ Environment Variables\n\n<table>\n  <tr>\n    <th>Variable</th>\n    <th>Required</th>\n    <th>Description</th>\n  </tr>\n  <tr>\n    <td><code>OPENAI_API_KEY</code></td>\n    <td>âœ… Yes</td>\n    <td>Your OpenAI API key with access to the gpt-image-1 model</td>\n  </tr>\n  <tr>\n    <td><code>GPT_IMAGE_OUTPUT_DIR</code></td>\n    <td>âŒ No</td>\n    <td>Custom directory for saving generated images (defaults to user's Pictures folder under <code>gpt-image-1</code> subfolder)</td>\n  </tr>\n</table>\n\n### ğŸ’» Example Usage with NPX\n\n<table>\n  <tr>\n    <th>Operating System</th>\n    <th>Command Line Example</th>\n  </tr>\n  <tr>\n    <td><strong>Linux/macOS</strong></td>\n    <td>\n\n```bash\n# Set your OpenAI API key\nexport OPENAI_API_KEY=sk-your-openai-api-key\n\n# Optional: Set custom output directory\nexport GPT_IMAGE_OUTPUT_DIR=/home/username/Pictures/ai-generated-images\n\n# Run the server with NPX\nnpx -y @cloudwerxlab/gpt-image-1-mcp\n```\n  </tr>\n  <tr>\n    <td><strong>Windows (PowerShell)</strong></td>\n    <td>\n\n```powershell\n# Set your OpenAI API key\n$env:OPENAI_API_KEY = \"sk-your-openai-api-key\"\n\n# Optional: Set custom output directory\n$env:GPT_IMAGE_OUTPUT_DIR = \"C:\\Users\\username\\Pictures\\ai-generated-images\"\n\n# Run the server with NPX\nnpx -y @cloudwerxlab/gpt-image-1-mcp\n```\n  </tr>\n  <tr>\n    <td><strong>Windows (Command Prompt)</strong></td>\n    <td>\n\n```cmd\n:: Set your OpenAI API key\nset OPENAI_API_KEY=sk-your-openai-api-key\n\n:: Optional: Set custom output directory\nset GPT_IMAGE_OUTPUT_DIR=C:\\Users\\username\\Pictures\\ai-generated-images\n\n:: Run the server with NPX\nnpx -y @cloudwerxlab/gpt-image-1-mcp\n```\n  </tr>\n</table>\n\n## ğŸ”Œ Integration with MCP Clients\n\n<div align=\"center\">\n  <img src=\"https://img.shields.io/badge/VS_Code-MCP_Extension-007ACC?logo=visual-studio-code&logoColor=white\" alt=\"VS Code MCP Extension\">\n  <img src=\"https://img.shields.io/badge/Roo-Compatible-FF6B6B\" alt=\"Roo Compatible\">\n  <img src=\"https://img.shields.io/badge/Cursor-Compatible-4C2889\" alt=\"Cursor Compatible\">\n  <img src=\"https://img.shields.io/badge/Augment-Compatible-6464FF\" alt=\"Augment Compatible\">\n  <img src=\"https://img.shields.io/badge/Windsurf-Compatible-00B4D8\" alt=\"Windsurf Compatible\">\n</div>\n\n### ğŸ› ï¸ Setting Up in an MCP Client\n\n<table>\n  <tr>\n    <td>\n      <h4>Step 1: Locate Settings File</h4>\n      <ul>\n        <li>For <strong>Roo</strong>: <code>c:\\Users\\&lt;username&gt;\\AppData\\Roaming\\Code\\User\\globalStorage\\rooveterinaryinc.roo-cline\\settings\\mcp_settings.json</code></li>\n        <li>For <strong>VS Code MCP Extension</strong>: Check your extension documentation for the settings file location</li>\n        <li>For <strong>Cursor</strong>: <code>~/.config/cursor/mcp_settings.json</code> (Linux/macOS) or <code>%APPDATA%\\Cursor\\mcp_settings.json</code> (Windows)</li>\n        <li>For <strong>Augment</strong>: <code>~/.config/augment/mcp_settings.json</code> (Linux/macOS) or <code>%APPDATA%\\Augment\\mcp_settings.json</code> (Windows)</li>\n        <li>For <strong>Windsurf</strong>: <code>~/.config/windsurf/mcp_settings.json</code> (Linux/macOS) or <code>%APPDATA%\\Windsurf\\mcp_settings.json</code> (Windows)</li>\n      </ul>\n    </td>\n  </tr>\n  <tr>\n    <td>\n      <h4>Step 2: Add Configuration</h4>\n      <p>Add the following configuration to the <code>mcpServers</code> object:</p>\n    </td>\n  </tr>\n</table>\n\n```json\n{\n  \"mcpServers\": {\n    \"gpt-image-1\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@cloudwerxlab/gpt-image-1-mcp\"\n      ],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"PASTE YOUR OPEN-AI KEY HERE\",\n        \"GPT_IMAGE_OUTPUT_DIR\": \"OPTIONAL: PATH TO SAVE GENERATED IMAGES\"\n      }\n    }\n  }\n}\n```\n\n#### Example Configurations for Different Operating Systems\n\n<table>\n  <tr>\n    <th>Operating System</th>\n    <th>Example Configuration</th>\n  </tr>\n  <tr>\n    <td><strong>Windows</strong></td>\n    <td>\n\n```json\n{\n  \"mcpServers\": {\n    \"gpt-image-1\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@cloudwerxlab/gpt-image-1-mcp\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"sk-your-openai-api-key\",\n        \"GPT_IMAGE_OUTPUT_DIR\": \"C:\\\\Users\\\\username\\\\Pictures\\\\ai-generated-images\"\n      }\n    }\n  }\n}\n```\n  </tr>\n  <tr>\n    <td><strong>Linux/macOS</strong></td>\n    <td>\n\n```json\n{\n  \"mcpServers\": {\n    \"gpt-image-1\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@cloudwerxlab/gpt-image-1-mcp\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"sk-your-openai-api-key\",\n        \"GPT_IMAGE_OUTPUT_DIR\": \"/home/username/Pictures/ai-generated-images\"\n      }\n    }\n  }\n}\n```\n  </tr>\n</table>\n\n> **Note**: For Windows paths, use double backslashes (`\\\\`) to escape the backslash character in JSON. For Linux/macOS, use forward slashes (`/`).\n\n## âœ¨ Features\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td align=\"center\">\n        <h3>ğŸ¨ Core Tools</h3>\n        <ul>\n          <li><code>create_image</code>: Generate new images from text prompts</li>\n          <li><code>create_image_edit</code>: Edit existing images with text prompts and masks</li>\n        </ul>\n      </td>\n      <td align=\"center\">\n        <h3>ğŸš€ Key Benefits</h3>\n        <ul>\n          <li>Simple integration with MCP clients</li>\n          <li>Full access to OpenAI's gpt-image-1 capabilities</li>\n          <li>Streamlined workflow for AI image generation</li>\n        </ul>\n      </td>\n    </tr>\n  </table>\n</div>\n\n### ğŸ’¡ Enhanced Capabilities\n\n<table>\n  <tr>\n    <td>\n      <h4>ğŸ“Š Output & Formatting</h4>\n      <ul>\n        <li>âœ… <strong>Beautifully Formatted Output</strong>: Responses include emojis and detailed information</li>\n        <li>âœ… <strong>Automatic Image Saving</strong>: All generated images saved to disk for easy access</li>\n        <li>âœ… <strong>Detailed Token Usage</strong>: View token consumption for each request</li>\n      </ul>\n    </td>\n    <td>\n      <h4>âš™ï¸ Configuration & Handling</h4>\n      <ul>\n        <li>âœ… <strong>Configurable Output Directory</strong>: Customize where images are saved</li>\n        <li>âœ… <strong>File Path Support</strong>: Edit images using file paths instead of base64 encoding</li>\n        <li>âœ… <strong>Comprehensive Error Handling</strong>: Detailed error reporting with specific error codes, descriptions, and troubleshooting suggestions</li>\n      </ul>\n    </td>\n  </tr>\n</table>\n\n## ğŸ”„ How It Works\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <th align=\"center\">ğŸ–¼ï¸ Image Generation</th>\n      <th align=\"center\">âœï¸ Image Editing</th>\n    </tr>\n    <tr>\n      <td>\n        <ol>\n          <li>Server receives prompt and parameters</li>\n          <li>Calls OpenAI API using gpt-image-1 model</li>\n          <li>API returns base64-encoded images</li>\n          <li>Server saves images to configured directory</li>\n          <li>Returns formatted response with paths and metadata</li>\n        </ol>\n      </td>\n      <td>\n        <ol>\n          <li>Server receives image, prompt, and optional mask</li>\n          <li>For file paths, reads and prepares files for API</li>\n          <li>Uses direct curl command for proper MIME handling</li>\n          <li>API returns base64-encoded edited images</li>\n          <li>Server saves images to configured directory</li>\n          <li>Returns formatted response with paths and metadata</li>\n        </ol>\n      </td>\n    </tr>\n  </table>\n</div>\n\n### ğŸ“ Output Directory Behavior\n\n<table>\n  <tr>\n    <td width=\"50%\">\n      <h4>ğŸ“‚ Storage Location</h4>\n      <ul>\n        <li>ğŸ”¹ <strong>Default Location</strong>: User's Pictures folder under <code>gpt-image-1</code> subfolder (e.g., <code>C:\\Users\\username\\Pictures\\gpt-image-1</code> on Windows)</li>\n        <li>ğŸ”¹ <strong>Custom Location</strong>: Set via <code>GPT_IMAGE_OUTPUT_DIR</code> environment variable</li>\n        <li>ğŸ”¹ <strong>Fallback Location</strong>: <code>./generated-images</code> (if Pictures folder can't be determined)</li>\n      </ul>\n    </td>\n    <td width=\"50%\">\n      <h4>ğŸ—‚ï¸ File Management</h4>\n      <ul>\n        <li>ğŸ”¹ <strong>Directory Creation</strong>: Automatically creates output directory if it doesn't exist</li>\n        <li>ğŸ”¹ <strong>File Naming</strong>: Images saved with timestamped filenames (e.g., <code>image-2023-05-05T12-34-56-789Z.png</code>)</li>\n        <li>ğŸ”¹ <strong>Cross-Platform</strong>: Works on Windows, macOS, and Linux with appropriate Pictures folder detection</li>\n      </ul>\n    </td>\n  </tr>\n</table>\n\n## Installation & Usage\n\n### NPM Package\n\nThis package is available on npm: [@cloudwerxlab/gpt-image-1-mcp](https://www.npmjs.com/package/@cloudwerxlab/gpt-image-1-mcp)\n\nYou can install it globally:\n\n```bash\nnpm install -g @cloudwerxlab/gpt-image-1-mcp\n```\n\nOr run it directly with npx as shown in the Quick Start section.\n\n### Tool: `create_image`\n\nGenerates a new image based on a text prompt.\n\n#### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `prompt` | string | Yes | The text description of the image to generate (max 32,000 chars) |\n| `size` | string | No | Image size: \"1024x1024\" (default), \"1536x1024\", or \"1024x1536\" |\n| `quality` | string | No | Image quality: \"high\" (default), \"medium\", or \"low\" |\n| `n` | integer | No | Number of images to generate (1-10, default: 1) |\n| `background` | string | No | Background style: \"transparent\", \"opaque\", or \"auto\" (default) |\n| `output_format` | string | No | Output format: \"png\" (default), \"jpeg\", or \"webp\" |\n| `output_compression` | integer | No | Compression level (0-100, default: 0) |\n| `user` | string | No | User identifier for OpenAI usage tracking |\n| `moderation` | string | No | Moderation level: \"low\" or \"auto\" (default) |\n\n#### Example\n\n```xml\n<use_mcp_tool>\n<server_name>gpt-image-1</server_name>\n<tool_name>create_image</tool_name>\n<arguments>\n{\n  \"prompt\": \"A futuristic city skyline at sunset, digital art\",\n  \"size\": \"1024x1024\",\n  \"quality\": \"high\",\n  \"n\": 1,\n  \"background\": \"auto\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n#### Response\n\nThe tool returns:\n- A formatted text message with details about the generated image(s)\n- The image(s) as base64-encoded data\n- Metadata including token usage and file paths\n\n### Tool: `create_image_edit`\n\nEdits an existing image based on a text prompt and optional mask.\n\n#### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `image` | string, object, or array | Yes | The image(s) to edit (base64 string or file path object) |\n| `prompt` | string | Yes | The text description of the desired edit (max 32,000 chars) |\n| `mask` | string or object | No | The mask that defines areas to edit (base64 string or file path object) |\n| `size` | string | No | Image size: \"1024x1024\" (default), \"1536x1024\", or \"1024x1536\" |\n| `quality` | string | No | Image quality: \"high\" (default), \"medium\", or \"low\" |\n| `n` | integer | No | Number of images to generate (1-10, default: 1) |\n| `background` | string | No | Background style: \"transparent\", \"opaque\", or \"auto\" (default) |\n| `user` | string | No | User identifier for OpenAI usage tracking |\n\n#### Example with Base64 Encoded Image\n\n```xml\n<use_mcp_tool>\n<server_name>gpt-image-1</server_name>\n<tool_name>create_image_edit</tool_name>\n<arguments>\n{\n  \"image\": \"BASE64_ENCODED_IMAGE_STRING\",\n  \"prompt\": \"Add a small robot in the corner\",\n  \"mask\": \"BASE64_ENCODED_MASK_STRING\",\n  \"quality\": \"high\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n#### Example with File Path\n\n```xml\n<use_mcp_tool>\n<server_name>gpt-image-1</server_name>\n<tool_name>create_image_edit</tool_name>\n<arguments>\n{\n  \"image\": {\n    \"filePath\": \"C:/path/to/your/image.png\"\n  },\n  \"prompt\": \"Add a small robot in the corner\",\n  \"mask\": {\n    \"filePath\": \"C:/path/to/your/mask.png\"\n  },\n  \"quality\": \"high\"\n}\n</arguments>\n</use_mcp_tool>\n```\n\n#### Response\n\nThe tool returns:\n- A formatted text message with details about the edited image(s)\n- The edited image(s) as base64-encoded data\n- Metadata including token usage and file paths\n\n## ğŸ”§ Troubleshooting\n\n<div align=\"center\">\n  <img src=\"https://img.shields.io/badge/Support-Available-brightgreen\" alt=\"Support Available\">\n</div>\n\n### ğŸš¨ Common Issues\n\n<table>\n  <tr>\n    <th align=\"center\">Issue</th>\n    <th align=\"center\">Solution</th>\n  </tr>\n  <tr>\n    <td>\n      <h4>ğŸ–¼ï¸ MIME Type Errors</h4>\n      <p>Errors related to image format or MIME type handling</p>\n    </td>\n    <td>\n      <p>Ensure image files have the correct extension (.png, .jpg, etc.) that matches their actual format. The server uses file extensions to determine MIME types.</p>\n    </td>\n  </tr>\n  <tr>\n    <td>\n      <h4>ğŸ”‘ API Key Issues</h4>\n      <p>Authentication errors with OpenAI API</p>\n    </td>\n    <td>\n      <p>Verify your OpenAI API key is correct and has access to the gpt-image-1 model. Check for any spaces or special characters that might have been accidentally included.</p>\n    </td>\n  </tr>\n  <tr>\n    <td>\n      <h4>ğŸ› ï¸ Build Errors</h4>\n      <p>Issues when building from source</p>\n    </td>\n    <td>\n      <p>Ensure you have the correct TypeScript version installed (v5.3.3 or compatible) and that your <code>tsconfig.json</code> is properly configured. Run <code>npm install</code> to ensure all dependencies are installed.</p>\n    </td>\n  </tr>\n  <tr>\n    <td>\n      <h4>ğŸ“ Output Directory Issues</h4>\n      <p>Problems with saving generated images</p>\n    </td>\n    <td>\n      <p>Check if the process has write permissions to the configured output directory. Try using an absolute path for <code>GPT_IMAGE_OUTPUT_DIR</code> if relative paths aren't working.</p>\n    </td>\n  </tr>\n</table>\n\n### ğŸ” Error Handling and Reporting\n\nThe MCP server includes comprehensive error handling that provides detailed information when something goes wrong. When an error occurs:\n\n1. **Error Format**: All errors are returned with:\n   - A clear error message describing what went wrong\n   - The specific error code or type\n   - Additional context about the error when available\n\n2. **AI Assistant Behavior**: When using this MCP server with AI assistants:\n   - The AI will always report the full error message to help with troubleshooting\n   - The AI will explain the likely cause of the error in plain language\n   - The AI will suggest specific steps to resolve the issue\n\n## ğŸ“„ License\n\n<div align=\"center\">\n  <a href=\"LICENSE\"><img src=\"https://img.shields.io/badge/License-MIT-blue.svg\" alt=\"MIT License\"></a>\n</div>\n\n<p align=\"center\">\n  This project is licensed under the MIT License - see the <a href=\"LICENSE\">LICENSE</a> file for details.\n</p>\n\n<details>\n  <summary>License Summary</summary>\n\n  <p>The MIT License is a permissive license that is short and to the point. It lets people do anything with your code with proper attribution and without warranty.</p>\n\n  <p><strong>You are free to:</strong></p>\n  <ul>\n    <li>Use the software commercially</li>\n    <li>Modify the software</li>\n    <li>Distribute the software</li>\n    <li>Use and modify the software privately</li>\n  </ul>\n\n  <p><strong>Under the following terms:</strong></p>\n  <ul>\n    <li>Include the original copyright notice and the license notice in all copies or substantial uses of the work</li>\n  </ul>\n\n  <p><strong>Limitations:</strong></p>\n  <ul>\n    <li>The authors provide no warranty with the software and are not liable for any damages</li>\n  </ul>\n</details>\n\n## ğŸ™ Acknowledgments\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td align=\"center\">\n        <a href=\"https://openai.com/\">\n          <img src=\"https://img.shields.io/badge/OpenAI-412991?logo=openai&logoColor=white\" alt=\"OpenAI\">\n          <p>For providing the gpt-image-1 model</p>\n        </a>\n      </td>\n      <td align=\"center\">\n        <a href=\"https://github.com/model-context-protocol/mcp\">\n          <img src=\"https://img.shields.io/badge/MCP-Protocol-00A3E0\" alt=\"MCP Protocol\">\n          <p>For the protocol specification</p>\n        </a>\n      </td>\n    </tr>\n  </table>\n</div>\n\n<div align=\"center\">\n  <p>\n    <a href=\"https://github.com/CLOUDWERX-DEV/gpt-image-1-mcp/issues\">Report Bug</a> â€¢\n    <a href=\"https://github.com/CLOUDWERX-DEV/gpt-image-1-mcp/issues\">Request Feature</a> â€¢\n    <a href=\"https://cloudwerx.dev\">Visit Our Website</a>\n  </p>\n</div>\n\n<div align=\"center\">\n  <p>\n    Developed with â¤ï¸ by <a href=\"https://cloudwerx.dev\">CLOUDWERX</a>\n  </p>\n</div>\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "coderjun--shaka-packager-mcp-server": {
      "owner": "coderjun",
      "name": "shaka-packager-mcp-server",
      "url": "https://github.com/coderjun/shaka-packager-mcp-server",
      "imageUrl": "https://github.com/coderjun.png",
      "description": "Supports advanced video transcoding, packaging, and analysis using Shaka Packager. Facilitates format conversion, DRM application, and content preparation for streaming, featuring intelligent path handling and error management.",
      "stars": 3,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-06-19T18:32:59Z",
      "readme_content": "# Shaka Packager MCP Server\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Python Version](https://img.shields.io/badge/python-3.10%2B-blue)](https://www.python.org/downloads/)\n[![Status: Alpha](https://img.shields.io/badge/Status-Alpha%20%7C%20Experimental-red)](https://github.com/coderjun/shaka-packager-mcp)\n\n> **âš ï¸ EXPERIMENTAL STATUS DISCLAIMER**\n> \n> This project is in early alpha stage and is highly experimental. It is not recommended for production use. It is also likely **MESSY!**\n> \n> **Current limitations:**\n> - You may run into inconsistent behavior\n> - Advanced features (packaging, conversion, etc.) are still under active development\n> - Path translation between Docker and host environments may require manual configuration\n> - Expect frequent breaking changes and potential instability\n>\n> Please report any issues you encounter to help improve the project.\n\nAn MCP (Model Context Protocol) server that integrates [Shaka Packager](https://shaka-project.github.io/shaka-packager/) with Claude AI applications for video transcoding, packaging, and analysis.\n\nThis server works with the [Filesystem MCP Server](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem) to enable Claude Desktop to access and process video files on your computer, turning Claude into a powerful assistant for media processing tasks.\n\n## Features\n\n- **Video Analysis**: Analyze video files to extract detailed stream information, codecs, bitrates, and more\n- **Media Packaging**: Convert videos for streaming in HLS and DASH formats with support for VOD and live streaming\n- **Advanced Options**: \n  - Apply DRM encryption (Widevine, PlayReady, FairPlay)\n  - Configure ad insertion markers\n  - Convert between formats (MP4, TS, etc.)\n- **Intelligent Path Handling**: Automatically translates paths between Docker and host environments\n- **Robust Error Management**: Provides meaningful error analysis with suggestions for resolution\n- **Command Assistance**: Helps correctly format Shaka Packager commands for optimal results\n- **Interactive Documentation**: Built-in help and examples to guide users through complex operations\n- **Detailed Outputs**: Comprehensive summaries and execution details for all operations\n\n## Prerequisites\n\n- Python 3.10 or higher\n- Shaka Packager installed and available in your PATH\n  - [Download from GitHub](https://github.com/shaka-project/shaka-packager/releases)\n  - Or build from source following [these instructions](https://shaka-project.github.io/shaka-packager/html/build_instructions.html)\n- An MCP-compatible client (like Claude Desktop)\n\n## Installation\n\n### Using pip or uv (coming soon)\n\nInstall the package with pip:\n\n```bash\npip install shaka-packager-mcp\n```\n\nOr with uv:\n\n```bash\nuv pip install shaka-packager-mcp\n```\n\n### From source (recommended)\n\n```bash\ngit clone https://github.com/coderjun/shaka-packager-mcp.git\ncd shaka-packager-mcp\npip install -e .\n```\n\nOr with uv:\n\n```bash\ngit clone https://github.com/coderjun/shaka-packager-mcp.git\ncd shaka-packager-mcp\nuv pip install -e .\n```\n\n## Claude Desktop Integration\n\nSince Claude Desktop doesn't directly support uploading video files, we'll use a two-server approach:\n1. A simplified **filesystem MCP server** to access video files on your computer\n2. The **Shaka Packager MCP server** to analyze and process those videos\n\n### Step 1: Set Up the MCP Filesystem Server\n\nUse the official MCP filesystem server to allow Claude to access your video files:\n\n1. Install the official filesystem server with Docker:\n   ```bash\n   docker pull mcp/filesystem\n   ```\n\n2. Alternatively, you can build it from source following the instructions in the [Filesystem MCP Server repository](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem)\n\n### Step 2: Find the Configuration File\n\nLocate your Claude Desktop configuration file:\n\n- **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\nIf the file doesn't exist, create it.\n\n### Step 3: Add Both Servers to the Configuration\n\nAdd the following configuration, making sure to use absolute paths:\n\n```json\n{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"--mount\", \"type=bind,src=/PATH/TO/VIDEOS/DIRECTORY,dst=/projects/video-drop\",\n        \"mcp/filesystem\",\n        \"/projects\"\n      ]\n    },\n    \"shaka-packager\": {\n      \"command\": \"/ABSOLUTE/PATH/TO/uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"mcp[cli]\",\n        \"/ABSOLUTE/PATH/TO/shaka_packager_mcp.py\"\n      ],\n      \"env\": {\n        \"VIDEO_PATH\": \"/PATH/TO/VIDEOS/DIRECTORY\",\n        \"SHAKA_PACKAGER_PATH\": \"/PATH/TO/PACKAGER\"\n      }\n    }\n  }\n}\n```\n\nReplace:\n- `/PATH/TO/VIDEOS/DIRECTORY` with the path to the directory containing your video files\n- `/ABSOLUTE/PATH/TO/uv` with the full path to your uv executable\n- `/ABSOLUTE/PATH/TO/shaka_packager_mcp.py` with the full path to the script file\n- `/PATH/TO/PACKAGER` with the full path to your Shaka Packager executable\n\nFor example:\n\n```json\n{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"--mount\", \"type=bind,src=/Users/username/Videos,dst=/projects/video-drop\",\n        \"mcp/filesystem\",\n        \"/projects\"\n      ]\n    },\n    \"shaka-packager\": {\n      \"command\": \"/Users/username/.local/bin/uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"mcp[cli]\",\n        \"/Users/username/Development/shaka-packager-mcp/shaka_packager_mcp.py\"\n      ],\n      \"env\": {\n        \"VIDEO_PATH\": \"/Users/username/Videos\",\n        \"SHAKA_PACKAGER_PATH\": \"/Users/username/.shaka/packager\"\n      }\n    }\n  }\n}\n```\n\n### Step 4: Restart Claude Desktop\n\nAfter editing the configuration file, restart Claude Desktop to apply the changes.\n\n### How to Use the Two-Server Approach\n\n1. First, browse your video files using the simplified filesystem server:\n   - Ask Claude to \"List the files in my video directory\"\n   - Navigate to the video file you want to analyze or process\n\n2. Once you've found your video file, use its path with the Shaka Packager tools:\n   - For analysis: \"Please analyze this video: /Users/username/Videos/example.mp4\"\n   - For processing: \"Please package this video for HLS: /Users/username/Videos/example.mp4\"\n\n### Troubleshooting\n\nIf you encounter any issues:\n\n1. Make sure both servers are properly configured with absolute paths\n2. Verify that Shaka Packager is installed and accessible\n3. Ensure the directory specified for the filesystem server exists and contains videos\n4. Check Claude Desktop logs for errors at:\n   - macOS: `~/Library/Logs/Claude/mcp*.log`\n   - Windows: `%APPDATA%\\Claude\\logs\\mcp*.log`\n\n## Usage\n\nOnce both the Filesystem MCP server and the Shaka Packager MCP server are running in Claude Desktop:\n\n1. **Access your video files**:\n   ```\n   Please show me the files in my Videos directory\n   ```\n\n2. **Navigate to your video file**:\n   ```\n   Please show me the files in the Movies subdirectory\n   ```\n\n3. **Copy the file:// URI path of the video** you want to process\n\n4. **Use the Shaka Packager tools with the file path**:\n   ```\n   Please analyze this video: file:///Users/username/Videos/my_video.mp4\n   ```\n   or\n   ```\n   Please package this video for HLS and DASH streaming: file:///Users/username/Videos/my_video.mp4\n   ```\n\n5. The server will execute the appropriate Shaka Packager command and provide a detailed summary of the results\n\nYou can also use direct file paths if you know the exact location of your video files:\n```\nPlease analyze this video: /Users/username/Videos/my_video.mp4\n```\n\n## Tools\n\nThe server provides these tools:\n\n1. **analyze_video**: Examines a video file and provides detailed stream information with intelligent error handling\n2. **run_shaka_packager**: Executes any Shaka Packager command with custom arguments and proper path handling\n3. **get_shaka_options**: Retrieves available command options and version information\n4. **get_shaka_documentation**: Provides comprehensive documentation and examples for using Shaka Packager\n\n## Prompts\n\nThe server includes these prompt templates:\n\n- MP4 to TS conversion\n- VOD packaging in HLS and DASH\n- Live streaming packaging\n- Content encryption\n- Ad insertion preparation\n- Video analysis\n- Command format reminder\n- Error interpretation guidance\n\n## Configuration\n\nThe server can be configured using environment variables:\n\n- `SHAKA_PACKAGER_PATH`: Path to the Shaka Packager executable (highly recommended for Claude Desktop)\n- `VIDEO_PATH`: Path to your local video directory (used for translating paths between Docker and host)\n- `DOCKER_PATH`: Docker container mount path (default: \"/projects/video-drop\")\n- `TEMP_DIR`: Custom temporary directory for file uploads\n- `LOG_LEVEL`: Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n- `COMMAND_TIMEOUT`: Timeout in seconds for Shaka Packager commands (default: 300)\n\nYou can set these in:\n1. Your Claude Desktop configuration file (preferred for `SHAKA_PACKAGER_PATH` and `VIDEO_PATH`)\n2. Your environment variables\n3. A `.env` file in the same directory as the script\n\nExample `.env` file:\n```\nSHAKA_PACKAGER_PATH=/usr/local/bin/packager\nVIDEO_PATH=/Users/yourusername/Videos\nLOG_LEVEL=DEBUG\n```\n\n## Development\n\n### Setting up a development environment\n\n```bash\n# Clone the repository\ngit clone https://github.com/coderjun/shaka-packager-mcp.git\ncd shaka-packager-mcp\n\n# Install development dependencies with pip\npip install -e \".[dev]\"\n\n# Or with uv\nuv pip install -e \".[dev]\"\n```\n\n### Running tests\n\n```bash\npytest\n```\n\n### Code formatting\n\n```bash\nblack .\nisort .\n```\n\n### Understanding the Code Structure\n\nThe main components of the Shaka Packager MCP server are:\n\n- `shaka_packager_mcp.py`: Main server implementation with MCP tools and prompts\n- `tests/`: Test suite for verifying functionality\n\nThis server is designed to work with the official MCP filesystem server for accessing video files.\n\n### Key Features in the Implementation\n\n- **Robust path handling**: Automatically translates paths between Docker and host environments\n- **Smart error handling**: Provides meaningful error messages and suggestions\n- **Command syntax assistance**: Helps correctly format Shaka Packager commands\n- **Documentation integration**: Provides comprehensive documentation and examples\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Getting Help\n\nFeel free to use an AI code copilot, the author does.\n\nIf you encounter any issues or have questions:\n\n1. Check the troubleshooting section in this README\n2. Review the [Shaka Packager documentation](https://shaka-project.github.io/shaka-packager/html/index.html)\n3. Use the `get_shaka_documentation` tool for interactive help within Claude\n4. [Open an issue](https://github.com/coderjun/shaka-packager-mcp/issues) on GitHub\n\n## Acknowledgements\n\n- [Shaka Packager](https://github.com/shaka-project/shaka-packager) for the powerful video processing capabilities\n- [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) for the communication framework\n- [Claude](https://claude.ai) for the AI assistant capabilities\n- [Anthropic](https://www.anthropic.com/) for developing Claude and the MCP standard",
      "npm_url": "",
      "npm_downloads": 0
    },
    "dangtanloc--ComfyUI": {
      "owner": "dangtanloc",
      "name": "ComfyUI",
      "url": "https://github.com/dangtanloc/ComfyUI",
      "imageUrl": "https://github.com/dangtanloc.png",
      "description": "A visual graph-based interface for designing and executing advanced stable diffusion pipelines, enabling users to create complex workflows without coding. It features smart memory management and asynchronous processing, supporting both GPU and CPU usage for offline functionality.",
      "stars": 0,
      "forks": 0,
      "license": "GNU General Public License v3.0",
      "language": "",
      "updated_at": "2024-10-10T06:48:42Z",
      "readme_content": "<div align=\"center\">\n\n# ComfyUI\n**The most powerful and modular diffusion model GUI and backend.**\n\n\n[![Website][website-shield]][website-url]\n[![Dynamic JSON Badge][discord-shield]][discord-url]\n[![Matrix][matrix-shield]][matrix-url]\n<br>\n[![][github-release-shield]][github-release-link]\n[![][github-release-date-shield]][github-release-link]\n[![][github-downloads-shield]][github-downloads-link]\n[![][github-downloads-latest-shield]][github-downloads-link]\n\n[matrix-shield]: https://img.shields.io/badge/Matrix-000000?style=flat&logo=matrix&logoColor=white\n[matrix-url]: https://app.element.io/#/room/%23comfyui_space%3Amatrix.org\n[website-shield]: https://img.shields.io/badge/ComfyOrg-4285F4?style=flat\n[website-url]: https://www.comfy.org/\n<!-- Workaround to display total user from https://github.com/badges/shields/issues/4500#issuecomment-2060079995 -->\n[discord-shield]: https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2Fcomfyorg%3Fwith_counts%3Dtrue&query=%24.approximate_member_count&logo=discord&logoColor=white&label=Discord&color=green&suffix=%20total\n[discord-url]: https://www.comfy.org/discord\n\n[github-release-shield]: https://img.shields.io/github/v/release/comfyanonymous/ComfyUI?style=flat&sort=semver\n[github-release-link]: https://github.com/comfyanonymous/ComfyUI/releases\n[github-release-date-shield]: https://img.shields.io/github/release-date/comfyanonymous/ComfyUI?style=flat\n[github-downloads-shield]: https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/total?style=flat\n[github-downloads-latest-shield]: https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/latest/total?style=flat&label=downloads%40latest\n[github-downloads-link]: https://github.com/comfyanonymous/ComfyUI/releases\n\n![ComfyUI Screenshot](comfyui_screenshot.png)\n</div>\n\nThis ui will let you design and execute advanced stable diffusion pipelines using a graph/nodes/flowchart based interface. For some workflow examples and see what ComfyUI can do you can check out:\n### [ComfyUI Examples](https://comfyanonymous.github.io/ComfyUI_examples/)\n\n### [Installing ComfyUI](#installing)\n\n## Features\n- Nodes/graph/flowchart interface to experiment and create complex Stable Diffusion workflows without needing to code anything.\n- Fully supports SD1.x, SD2.x, [SDXL](https://comfyanonymous.github.io/ComfyUI_examples/sdxl/), [Stable Video Diffusion](https://comfyanonymous.github.io/ComfyUI_examples/video/), [Stable Cascade](https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/), [SD3](https://comfyanonymous.github.io/ComfyUI_examples/sd3/) and [Stable Audio](https://comfyanonymous.github.io/ComfyUI_examples/audio/)\n- [Flux](https://comfyanonymous.github.io/ComfyUI_examples/flux/)\n- Asynchronous Queue system\n- Many optimizations: Only re-executes the parts of the workflow that changes between executions.\n- Smart memory management: can automatically run models on GPUs with as low as 1GB vram.\n- Works even if you don't have a GPU with: ```--cpu``` (slow)\n- Can load ckpt, safetensors and diffusers models/checkpoints. Standalone VAEs and CLIP models.\n- Embeddings/Textual inversion\n- [Loras (regular, locon and loha)](https://comfyanonymous.github.io/ComfyUI_examples/lora/)\n- [Hypernetworks](https://comfyanonymous.github.io/ComfyUI_examples/hypernetworks/)\n- Loading full workflows (with seeds) from generated PNG, WebP and FLAC files.\n- Saving/Loading workflows as Json files.\n- Nodes interface can be used to create complex workflows like one for [Hires fix](https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/) or much more advanced ones.\n- [Area Composition](https://comfyanonymous.github.io/ComfyUI_examples/area_composition/)\n- [Inpainting](https://comfyanonymous.github.io/ComfyUI_examples/inpaint/) with both regular and inpainting models.\n- [ControlNet and T2I-Adapter](https://comfyanonymous.github.io/ComfyUI_examples/controlnet/)\n- [Upscale Models (ESRGAN, ESRGAN variants, SwinIR, Swin2SR, etc...)](https://comfyanonymous.github.io/ComfyUI_examples/upscale_models/)\n- [unCLIP Models](https://comfyanonymous.github.io/ComfyUI_examples/unclip/)\n- [GLIGEN](https://comfyanonymous.github.io/ComfyUI_examples/gligen/)\n- [Model Merging](https://comfyanonymous.github.io/ComfyUI_examples/model_merging/)\n- [LCM models and Loras](https://comfyanonymous.github.io/ComfyUI_examples/lcm/)\n- [SDXL Turbo](https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/)\n- [AuraFlow](https://comfyanonymous.github.io/ComfyUI_examples/aura_flow/)\n- [HunyuanDiT](https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_dit/)\n- Latent previews with [TAESD](#how-to-show-high-quality-previews)\n- Starts up very fast.\n- Works fully offline: will never download anything.\n- [Config file](extra_model_paths.yaml.example) to set the search paths for models.\n\nWorkflow examples can be found on the [Examples page](https://comfyanonymous.github.io/ComfyUI_examples/)\n\n## Shortcuts\n\n| Keybind                            | Explanation                                                                                                        |\n|------------------------------------|--------------------------------------------------------------------------------------------------------------------|\n| Ctrl + Enter                       | Queue up current graph for generation                                                                              |\n| Ctrl + Shift + Enter               | Queue up current graph as first for generation                                                                     |\n| Ctrl + Alt + Enter                 | Cancel current generation                                                                                          |\n| Ctrl + Z/Ctrl + Y                  | Undo/Redo                                                                                                          |\n| Ctrl + S                           | Save workflow                                                                                                      |\n| Ctrl + O                           | Load workflow                                                                                                      |\n| Ctrl + A                           | Select all nodes                                                                                                   |\n| Alt + C                            | Collapse/uncollapse selected nodes                                                                                 |\n| Ctrl + M                           | Mute/unmute selected nodes                                                                                         |\n| Ctrl + B                           | Bypass selected nodes (acts like the node was removed from the graph and the wires reconnected through)            |\n| Delete/Backspace                   | Delete selected nodes                                                                                              |\n| Ctrl + Backspace                   | Delete the current graph                                                                                           |\n| Space                              | Move the canvas around when held and moving the cursor                                                             |\n| Ctrl/Shift + Click                 | Add clicked node to selection                                                                                      |\n| Ctrl + C/Ctrl + V                  | Copy and paste selected nodes (without maintaining connections to outputs of unselected nodes)                     |\n| Ctrl + C/Ctrl + Shift + V          | Copy and paste selected nodes (maintaining connections from outputs of unselected nodes to inputs of pasted nodes) |\n| Shift + Drag                       | Move multiple selected nodes at the same time                                                                      |\n| Ctrl + D                           | Load default graph                                                                                                 |\n| Alt + `+`                          | Canvas Zoom in                                                                                                     |\n| Alt + `-`                          | Canvas Zoom out                                                                                                    |\n| Ctrl + Shift + LMB + Vertical drag | Canvas Zoom in/out                                                                                                 |\n| P                                  | Pin/Unpin selected nodes                                                                                           |\n| Ctrl + G                           | Group selected nodes                                                                                               |\n| Q                                  | Toggle visibility of the queue                                                                                     |\n| H                                  | Toggle visibility of history                                                                                       |\n| R                                  | Refresh graph                                                                                                      |\n| Double-Click LMB                   | Open node quick search palette                                                                                     |\n| Shift + Drag                       | Move multiple wires at once                                                                                        |\n| Ctrl + Alt + LMB                   | Disconnect all wires from clicked slot                                                                             |\n\nCtrl can also be replaced with Cmd instead for macOS users\n\n# Installing\n\n## Windows\n\nThere is a portable standalone build for Windows that should work for running on Nvidia GPUs or for running on your CPU only on the [releases page](https://github.com/comfyanonymous/ComfyUI/releases).\n\n### [Direct link to download](https://github.com/comfyanonymous/ComfyUI/releases/latest/download/ComfyUI_windows_portable_nvidia.7z)\n\nSimply download, extract with [7-Zip](https://7-zip.org) and run. Make sure you put your Stable Diffusion checkpoints/models (the huge ckpt/safetensors files) in: ComfyUI\\models\\checkpoints\n\nIf you have trouble extracting it, right click the file -> properties -> unblock\n\n#### How do I share models between another UI and ComfyUI?\n\nSee the [Config file](extra_model_paths.yaml.example) to set the search paths for models. In the standalone windows build you can find this file in the ComfyUI directory. Rename this file to extra_model_paths.yaml and edit it with your favorite text editor.\n\n## Jupyter Notebook\n\nTo run it on services like paperspace, kaggle or colab you can use my [Jupyter Notebook](notebooks/comfyui_colab.ipynb)\n\n## Manual Install (Windows, Linux)\n\nGit clone this repo.\n\nPut your SD checkpoints (the huge ckpt/safetensors files) in: models/checkpoints\n\nPut your VAE in: models/vae\n\n\n### AMD GPUs (Linux only)\nAMD users can install rocm and pytorch with pip if you don't have it already installed, this is the command to install the stable version:\n\n```pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.1```\n\nThis is the command to install the nightly with ROCm 6.2 which might have some performance improvements:\n\n```pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm6.2```\n\n### NVIDIA\n\nNvidia users should install stable pytorch using this command:\n\n```pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu124```\n\nThis is the command to install pytorch nightly instead which might have performance improvements:\n\n```pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu124```\n\n#### Troubleshooting\n\nIf you get the \"Torch not compiled with CUDA enabled\" error, uninstall torch with:\n\n```pip uninstall torch```\n\nAnd install it again with the command above.\n\n### Dependencies\n\nInstall the dependencies by opening your terminal inside the ComfyUI folder and:\n\n```pip install -r requirements.txt```\n\nAfter this you should have everything installed and can proceed to running ComfyUI.\n\n### Others:\n\n#### Intel GPUs\n\nIntel GPU support is available for all Intel GPUs supported by Intel's Extension for Pytorch (IPEX) with the support requirements listed in the [Installation](https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=gpu) page. Choose your platform and method of install and follow the instructions. The steps are as follows:\n\n1. Start by installing the drivers or kernel listed or newer in the Installation page of IPEX linked above for Windows and Linux if needed.\n1. Follow the instructions to install [Intel's oneAPI Basekit](https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html) for your platform.\n1. Install the packages for IPEX using the instructions provided in the Installation page for your platform.\n1. Follow the [ComfyUI manual installation](#manual-install-windows-linux) instructions for Windows and Linux and run ComfyUI normally as described above after everything is installed.\n\nAdditional discussion and help can be found [here](https://github.com/comfyanonymous/ComfyUI/discussions/476).\n\n#### Apple Mac silicon\n\nYou can install ComfyUI in Apple Mac silicon (M1 or M2) with any recent macOS version.\n\n1. Install pytorch nightly. For instructions, read the [Accelerated PyTorch training on Mac](https://developer.apple.com/metal/pytorch/) Apple Developer guide (make sure to install the latest pytorch nightly).\n1. Follow the [ComfyUI manual installation](#manual-install-windows-linux) instructions for Windows and Linux.\n1. Install the ComfyUI [dependencies](#dependencies). If you have another Stable Diffusion UI [you might be able to reuse the dependencies](#i-already-have-another-ui-for-stable-diffusion-installed-do-i-really-have-to-install-all-of-these-dependencies).\n1. Launch ComfyUI by running `python main.py`\n\n> **Note**: Remember to add your models, VAE, LoRAs etc. to the corresponding Comfy folders, as discussed in [ComfyUI manual installation](#manual-install-windows-linux).\n\n#### DirectML (AMD Cards on Windows)\n\n```pip install torch-directml``` Then you can launch ComfyUI with: ```python main.py --directml```\n\n# Running\n\n```python main.py```\n\n### For AMD cards not officially supported by ROCm\n\nTry running it with this command if you have issues:\n\nFor 6700, 6600 and maybe other RDNA2 or older: ```HSA_OVERRIDE_GFX_VERSION=10.3.0 python main.py```\n\nFor AMD 7600 and maybe other RDNA3 cards: ```HSA_OVERRIDE_GFX_VERSION=11.0.0 python main.py```\n\n# Notes\n\nOnly parts of the graph that have an output with all the correct inputs will be executed.\n\nOnly parts of the graph that change from each execution to the next will be executed, if you submit the same graph twice only the first will be executed. If you change the last part of the graph only the part you changed and the part that depends on it will be executed.\n\nDragging a generated png on the webpage or loading one will give you the full workflow including seeds that were used to create it.\n\nYou can use () to change emphasis of a word or phrase like: (good code:1.2) or (bad code:0.8). The default emphasis for () is 1.1. To use () characters in your actual prompt escape them like \\\\( or \\\\).\n\nYou can use {day|night}, for wildcard/dynamic prompts. With this syntax \"{wild|card|test}\" will be randomly replaced by either \"wild\", \"card\" or \"test\" by the frontend every time you queue the prompt. To use {} characters in your actual prompt escape them like: \\\\{ or \\\\}.\n\nDynamic prompts also support C-style comments, like `// comment` or `/* comment */`.\n\nTo use a textual inversion concepts/embeddings in a text prompt put them in the models/embeddings directory and use them in the CLIPTextEncode node like this (you can omit the .pt extension):\n\n```embedding:embedding_filename.pt```\n\n\n## How to show high-quality previews?\n\nUse ```--preview-method auto``` to enable previews.\n\nThe default installation includes a fast latent preview method that's low-resolution. To enable higher-quality previews with [TAESD](https://github.com/madebyollin/taesd), download the [taesd_decoder.pth, taesdxl_decoder.pth, taesd3_decoder.pth and taef1_decoder.pth](https://github.com/madebyollin/taesd/) and place them in the `models/vae_approx` folder. Once they're installed, restart ComfyUI and launch it with `--preview-method taesd` to enable high-quality previews.\n\n## How to use TLS/SSL?\nGenerate a self-signed certificate (not appropriate for shared/production use) and key by running the command: `openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -sha256 -days 3650 -nodes -subj \"/C=XX/ST=StateName/L=CityName/O=CompanyName/OU=CompanySectionName/CN=CommonNameOrHostname\"`\n\nUse `--tls-keyfile key.pem --tls-certfile cert.pem` to enable TLS/SSL, the app will now be accessible with `https://...` instead of `http://...`.\n\n> Note: Windows users can use [alexisrolland/docker-openssl](https://github.com/alexisrolland/docker-openssl) or one of the [3rd party binary distributions](https://wiki.openssl.org/index.php/Binaries) to run the command example above. \n<br/><br/>If you use a container, note that the volume mount `-v` can be a relative path so `... -v \".\\:/openssl-certs\" ...` would create the key & cert files in the current directory of your command prompt or powershell terminal.\n\n## Support and dev channel\n\n[Matrix space: #comfyui_space:matrix.org](https://app.element.io/#/room/%23comfyui_space%3Amatrix.org) (it's like discord but open source).\n\nSee also: [https://www.comfy.org/](https://www.comfy.org/)\n\n## Frontend Development\n\nAs of August 15, 2024, we have transitioned to a new frontend, which is now hosted in a separate repository: [ComfyUI Frontend](https://github.com/Comfy-Org/ComfyUI_frontend). This repository now hosts the compiled JS (from TS/Vue) under the `web/` directory.\n\n### Reporting Issues and Requesting Features\n\nFor any bugs, issues, or feature requests related to the frontend, please use the [ComfyUI Frontend repository](https://github.com/Comfy-Org/ComfyUI_frontend). This will help us manage and address frontend-specific concerns more efficiently.\n\n### Using the Latest Frontend\n\nThe new frontend is now the default for ComfyUI. However, please note:\n\n1. The frontend in the main ComfyUI repository is updated weekly.\n2. Daily releases are available in the separate frontend repository.\n\nTo use the most up-to-date frontend version:\n\n1. For the latest daily release, launch ComfyUI with this command line argument:\n\n   ```\n   --front-end-version Comfy-Org/ComfyUI_frontend@latest\n   ```\n\n2. For a specific version, replace `latest` with the desired version number:\n\n   ```\n   --front-end-version Comfy-Org/ComfyUI_frontend@1.2.2\n   ```\n\nThis approach allows you to easily switch between the stable weekly release and the cutting-edge daily updates, or even specific versions for testing purposes.\n\n### Accessing the Legacy Frontend\n\nIf you need to use the legacy frontend for any reason, you can access it using the following command line argument:\n\n```\n--front-end-version Comfy-Org/ComfyUI_legacy_frontend@latest\n```\n\nThis will use a snapshot of the legacy frontend preserved in the [ComfyUI Legacy Frontend repository](https://github.com/Comfy-Org/ComfyUI_legacy_frontend).\n\n# QA\n\n### Which GPU should I buy for this?\n\n[See this page for some recommendations](https://github.com/comfyanonymous/ComfyUI/wiki/Which-GPU-should-I-buy-for-ComfyUI)\n\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "dasheck0--face-generator": {
      "owner": "dasheck0",
      "name": "face-generator",
      "url": "https://github.com/dasheck0/face-generator",
      "imageUrl": "https://github.com/dasheck0.png",
      "description": "Generate realistic human face images with customizable shapes, sizes, and backgrounds. Supports batch generation for multiple images and offers transparent backgrounds for non-square outputs.",
      "stars": 5,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:32:05Z",
      "readme_content": "# Face Generator MCP Server: Generate Human Faces with Ease\n\n[![Smithery badge](https://smithery.ai/badge/@dasheck0/face-generator)](https://smithery.ai/server/@dasheck0/face-generator)\n\n<a href=\"https://glama.ai/mcp/servers/0v6oomxing\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/0v6oomxing/badge\" alt=\"Face Generator Server MCP server\" />\n</a>\n\n## Features\nThis project provides a Model Context Protocol (MCP) server for generating human face images using https://thispersondoesnotexist.com. Think of it as a tool that lets other applications, like Cline, generate realistic-looking faces on demand.\n\nThis guide is designed for beginners, so we'll walk through everything step-by-step. We'll cover:\n\n1.  **Prerequisites:** What you need before you start.\n2.  **Installation and Setup:** Getting everything up and running.\n3.  **Running the Server:** Starting the server.\n4.  **Integrating with Cline:** Connecting this server to the Cline VS Code extension.\n5.  **Troubleshooting:** Common problems and solutions.\n6.  **Tool Parameters:** A list of the parameters you can use with the `generate_face` tool.\n\n## 1. Prerequisites\n\nBefore you begin, you'll need a few things:\n\n*   **Node.js and npm:** Node.js is a JavaScript runtime that lets you run JavaScript code outside of a web browser. npm (Node Package Manager) is included with Node.js and is used to install packages (libraries of code).\n    *   [Download Node.js](https://nodejs.org/en/download/). **Choose the LTS (Long Term Support) version.** This is the most stable version. Follow the installation instructions for your operating system. Make sure to include npm in the installation (it's usually included by default).\n    *   **Verify Installation:** After installing Node.js, open a new terminal (command prompt on Windows, Terminal on macOS/Linux) and type:\n        ```bash\n        node -v\n        npm -v\n        ```\n        You should see version numbers for both Node.js and npm. If you see an error, Node.js might not be installed correctly, or it might not be in your system's PATH. (See Troubleshooting below).\n\n## 2. Installation and Setup\n\nLet's get the project code and set it up:\n\n1.  **Clone the Repository:**\n    *   **Using Git (command line):**\n        1.  Open a terminal (command prompt or Terminal).\n        2.  Navigate to the directory where you want to store the project. For example, to put it on your Desktop:\n            ```bash\n            cd Desktop\n            ```\n        3.  Clone the repository:\n            ```bash\n            git clone https://github.com/Moe/mcp-face-generator\n            ```\n        4.  Change into the project directory:\n            ```bash\n            cd mcp-face-generator\n            ```\n    *   **Using GitHub Desktop:**\n        1.  Open GitHub Desktop.\n        2.  Click \"File\" -> \"Clone Repository...\".\n        3.  In the \"URL\" tab, paste the repository URL.\n        4.  Choose a local path (where you want to save the project on your computer).\n        5.  Click \"Clone\".\n\n2.  **Install Dependencies:** This downloads all the necessary libraries the project needs. In the terminal, inside the project directory, run:\n    ```bash\n    npm install\n    ```\n    This might take a few minutes.\n\n3.  **Build the Project:** This compiles the code into an executable format.\n    ```bash\n    npm run build\n    ```\n\n## 3. Running the Server\n\nYou can run the server in two main ways:\n\n*   **Standalone Mode:** This runs the server directly, and it will output messages to the terminal.\n*   **Development/Debug Mode:** This runs the server with the MCP Inspector. You can open the URL that it outputs in your browser and start playing around.\n\n### 3.1 Standalone Mode\n\nTo run the server in standalone mode, use the following command in the terminal (from the project directory):\n\n```bash\nnpm run start\n```\n\nYou should see messages in the terminal indicating that the server is running. It will listen for connections from MCP clients. The server will keep running until you stop it (usually with Ctrl+C).\n\n### 3.2 Development/Debug Mode (with Inspector)\n\nThis mode is useful for debugging.\n\n1.  **Start the server in debug mode:**\n    ```bash\n    npm run dev\n    ```\n    This will start the server and output a message like: `ğŸ” MCP Inspector is up and running at http://localhost:5173 ğŸš€`. This is the URL you'll use to open the MCP inspector in your Browser.\n\n## 4. Integrating with Cline\n\nCline is a VS Code extension that uses MCP servers to provide language support. Here's how to connect this face generator server to Cline:\n\n1.  **Install Cline:** If you haven't already, install the \"Cline\" extension in VS Code.\n\n2.  **Open Cline Settings:**\n    *   Open the VS Code settings (File -> Preferences -> Settings, or Ctrl+,).\n    *   Search for \"Cline MCP Settings\".\n    *   Click \"Edit in settings.json\". This will open the `cline_mcp_settings.json` file.\n\n3.  **Add the Server Configuration:** You'll need to add an entry to the `servers` array in the `cline_mcp_settings.json` file. Here's an example:\n\n    ```json\n    {\n      \"mcpServers\": {\n        \"face-generator\": {\n          \"command\": \"node\",\n          \"args\": [\n            \"C:/PATH_TO/mcp-face-generator/build/index.js\"\n          ],\n          \"disabled\": false,\n          \"autoApprove\": []\n        }\n      }\n    }\n    ```\n    *   Replace `\"C:/PATH_TO/mcp-face-generator/build/index.js\"` with the actual path to the `index.js` file in your project directory.  Use forward slashes (/) or double backslashes (\\\\\\\\) for the path on Windows.\n\n4.  **Test the Connection:**\n    *   Cline should automatically connect to the server. You will see the Server appear in the \"MCP Servers\" Panel (in the Cline extension, you'll find different buttons on the top.)\n    *   Ask Cline to generate a face and it should mention the MCP Server and should try to use the corresponding tools\n\n## 5. Troubleshooting\n\n*   **`node -v` or `npm -v` gives an error:**\n    *   Make sure Node.js is installed correctly. Try reinstalling it.\n    *   Ensure that the Node.js installation directory is in your system's PATH environment variable. On Windows, you can edit environment variables through the System Properties (search for \"environment variables\" in the Start Menu).\n*   **`npm install` fails:**\n    *   Make sure you have an internet connection.\n    *   Try deleting the `node_modules` folder and running `npm install` again.\n    *   If you're behind a proxy, you might need to configure npm to use the proxy. Search online for \"npm proxy settings\".\n*   **Cline doesn't connect to the server:**\n    *   Double-check the settings in `cline_mcp_settings.json`. It *must* be the correct path to the `index.js` file.\n    *   Make sure the server is running (use `npm run start` to check).\n    *   Restart VS Code.\n\n## 6. Tool Parameters\n\nThe `generate_face` tool accepts the following parameters:\n\n*   `outputDir`: (required) Directory to save the images\n*   `fileName`: Optional file name (defaults to timestamp)\n*   `count`: Number of images to generate (default: 1)\n*   `width`: Image width in pixels (default: 256)\n*   `height`: Image height in pixels (default: 256)\n*   `shape`: Image shape (square|circle|rounded, default: square)\n*   `borderRadius`: Border radius for rounded shape (default: 32)\n*   `returnImageContent`: Return image as base64 encoded content instead of file path (default: false)\n\n## Example\n\n```json\n{\n  \"outputDir\": \"./output\",\n  \"count\": 3,\n  \"width\": 512,\n  \"height\": 512,\n  \"shape\": \"circle\",\n  \"returnImageContent\": true\n}\n```\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "deepfates--mcp-replicate": {
      "owner": "deepfates",
      "name": "mcp-replicate",
      "url": "https://github.com/deepfates/mcp-replicate",
      "imageUrl": "https://github.com/deepfates.png",
      "description": "Access Replicate models to run predictions through a tool-based interface, facilitating interactions with various AI models hosted on Replicate's platform.",
      "stars": 84,
      "forks": 19,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-24T19:15:13Z",
      "readme_content": "# Replicate MCP Server\n\nA [Model Context Protocol](https://github.com/mcp-sdk/mcp) server implementation for Replicate. Run Replicate models through a simple tool-based interface.\n\n## NOT IN ACTIVE DEVELOPMENT\n\nThis repo was an experiment in MCP tooling for Replicate. The company now offers an [official MCP server](https://replicate.com/docs/reference/mcp). This repo will stay up for those who find it useful or want to fork it, but it's not in active development and issues won't be addressed. Contributions might be folded in but no promises. Enjoy at your own risk.\n\n## Quickstart\n\n1. Install the server:\n\n```bash\nnpm install -g mcp-replicate\n```\n\n2. Get your Replicate API token:\n\n   - Go to [Replicate API tokens page](https://replicate.com/account/api-tokens)\n   - Create a new token if you don't have one\n   - Copy the token for the next step\n\n3. Configure Claude Desktop:\n   - Open Claude Desktop Settings (<kbd>âŒ˜</kbd><kbd>,</kbd>)\n   - Select the \"Developer\" section in the sidebar\n   - Click \"Edit Config\" to open the configuration file\n   - Add the following configuration, replacing `your_token_here` with your actual Replicate API token:\n\n```json\n{\n  \"mcpServers\": {\n    \"replicate\": {\n      \"command\": \"mcp-replicate\",\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your_token_here\"\n      }\n    }\n  }\n}\n```\n\n4. Start Claude Desktop. You should see a ğŸ”¨ hammer icon in the bottom right corner of new chat windows, indicating the tools are available.\n\n(You can also use any other MCP client, such as Cursor, Cline, or Continue.)\n\n## Alternative Installation Methods\n\n### Install from source\n\n```bash\ngit clone https://github.com/deepfates/mcp-replicate\ncd mcp-replicate\nnpm install\nnpm run build\nnpm start\n```\n\n### Run with npx\n\n```bash\nnpx mcp-replicate\n```\n\n## Features\n\n### Models\n\n- Search models using semantic search\n- Browse models and collections\n- Get detailed model information and versions\n\n### Predictions\n\n- Create predictions with text or structured input\n- Track prediction status\n- Cancel running predictions\n- List your recent predictions\n\n### Image Handling\n\n- View generated images in your browser\n- Manage image cache for better performance\n\n## Configuration\n\nThe server needs a Replicate API token to work. You can get one at [Replicate](https://replicate.com/account/api-tokens).\n\nThere are two ways to provide the token:\n\n### 1. In Claude Desktop Config (Recommended)\n\nAdd it to your Claude Desktop configuration as shown in the Quickstart section:\n\n```json\n{\n  \"mcpServers\": {\n    \"replicate\": {\n      \"command\": \"mcp-replicate\",\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your_token_here\"\n      }\n    }\n  }\n}\n```\n\n### 2. As Environment Variable\n\nAlternatively, you can set it as an environment variable if you're using another MCP client:\n\n```bash\nexport REPLICATE_API_TOKEN=your_token_here\n```\n\n## Available Tools\n\n### Model Tools\n\n- `search_models`: Find models using semantic search\n- `list_models`: Browse available models\n- `get_model`: Get details about a specific model\n- `list_collections`: Browse model collections\n- `get_collection`: Get details about a specific collection\n\n### Prediction Tools\n\n- `create_prediction`: Run a model with your inputs\n- `create_and_poll_prediction`: Run a model with your inputs and wait until it's completed\n- `get_prediction`: Check a prediction's status\n- `cancel_prediction`: Stop a running prediction\n- `list_predictions`: See your recent predictions\n\n### Image Tools\n\n- `view_image`: Open an image in your browser\n- `clear_image_cache`: Clean up cached images\n- `get_image_cache_stats`: Check cache usage\n\n## Troubleshooting\n\n### Server is running but tools aren't showing up\n\n1. Check that Claude Desktop is properly configured with the MCP server settings\n2. Ensure your Replicate API token is set correctly\n3. Try restarting both the server and Claude Desktop\n4. Check the server logs for any error messages\n\n### Tools are visible but not working\n\n1. Verify your Replicate API token is valid\n2. Check your internet connection\n3. Look for any error messages in the server output\n\n## Development\n\n1. Install dependencies:\n\n```bash\nnpm install\n```\n\n2. Start development server (with auto-reload):\n\n```bash\nnpm run dev\n```\n\n3. Check code style:\n\n```bash\nnpm run lint\n```\n\n4. Format code:\n\n```bash\nnpm run format\n```\n\n## Requirements\n\n- Node.js >= 18.0.0\n- TypeScript >= 5.0.0\n- [Claude Desktop](https://claude.ai/download) for using the tools\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "douglarek--unsplash-mcp-server": {
      "owner": "douglarek",
      "name": "unsplash-mcp-server",
      "url": "https://github.com/douglarek/unsplash-mcp-server",
      "imageUrl": "https://github.com/douglarek.png",
      "description": "Access a vast library of high-quality images from Unsplash through a simplified API integration. Fetch stunning images on demand to enhance visual content in applications.",
      "stars": 10,
      "forks": 2,
      "license": "MIT License",
      "language": "Go",
      "updated_at": "2025-08-25T02:26:41Z",
      "readme_content": "# Unsplash MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@douglarek/unsplash-mcp-server)](https://smithery.ai/server/@douglarek/unsplash-mcp-server)\n\nA rewrite of the [Unsplash MCP Server](https://github.com/hellokaton/unsplash-mcp-server) using the [mark3labs/mcp-go](https://github.com/mark3labs/mcp-go) library.\n\n## Usage\n\nBefore building, you must install go 1.24+ first.\n\n```bash\ngit clone https://github.com/douglarek/unsplash-mcp-server.git\ncd unsplash-mcp-server\nmake build\n```\n\n### Cursor Editor Integration\n\nTo use this server in Cursor, you can add the following to your `mcp.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"unsplash\": {\n      \"command\": \"<source_dir>/cmd/server/unsplash-mcp-server\",\n      \"args\": [],\n      \"env\": {\n        \"UNSPLASH_ACCESS_KEY\": \"<your_unsplash_access_key>\"\n      }\n    }\n  }\n}\n```\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Dreamboat-Rachel--MCP-Server-For-Local": {
      "owner": "Dreamboat-Rachel",
      "name": "MCP-Server-For-Local",
      "url": "https://github.com/Dreamboat-Rachel/MCP-Server-For-Local",
      "imageUrl": "https://github.com/Dreamboat-Rachel.png",
      "description": "Connect AI models to real-time data and tools with features such as weather querying, Google search automation, camera control, and image generation. The server supports modular expansion and custom API integration for tailored functionalities.",
      "stars": 14,
      "forks": 2,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-21T02:08:22Z",
      "readme_content": "# MCP Server for Local\n\nä¸€ä¸ªåŸºäº MCP (Multi-Component Platform) çš„æœ¬åœ°ä»£ç†æœåŠ¡å™¨å’Œå®¢æˆ·ç«¯å®ç°ï¼Œæä¾›å¤šç§ AI å·¥å…·è°ƒç”¨èƒ½åŠ›ã€‚\n\n## åŠŸèƒ½ç‰¹ç‚¹\n\n### æ ¸å¿ƒåŠŸèƒ½\n- **å¤©æ°”æŸ¥è¯¢**ï¼šå®æ—¶è·å–å…¨çƒä»»æ„ä½ç½®çš„å¤©æ°”ä¿¡æ¯ï¼Œæ”¯æŒæ¸©åº¦ã€æ¹¿åº¦ã€é£é€Ÿç­‰è¯¦ç»†æ•°æ®\n- **è°·æ­Œæœç´¢**ï¼šæ™ºèƒ½æ£€ç´¢äº’è”ç½‘ä¿¡æ¯ï¼Œæ”¯æŒå¤šè¯­è¨€å’Œé«˜çº§æœç´¢è¯­æ³•\n- **æ‘„åƒå¤´æ§åˆ¶**ï¼šæ”¯æŒæ‹ç…§ã€è§†é¢‘æµå’Œå¾®è¡¨æƒ…åˆ†æï¼Œå¯ç”¨äºæƒ…ç»ªè¯†åˆ«\n- **å›¾ç‰‡ç”Ÿæˆ**ï¼šé›†æˆ ComfyUIï¼Œæ”¯æŒæ–‡æœ¬åˆ°å›¾åƒçš„ AI ç”Ÿæˆ\n- **æ™ºèƒ½å¯¹è¯**ï¼šåŸºäº DashScope çš„ AI å¯¹è¯èƒ½åŠ›ï¼Œæ”¯æŒä¸Šä¸‹æ–‡ç†è§£å’Œå¤šè½®å¯¹è¯\n\n### æŠ€æœ¯ç‰¹æ€§\n- è·¨å¹³å°æ”¯æŒï¼ˆWindows å’Œ Linuxï¼‰\n- æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•æ–°åŠŸèƒ½\n- å®Œæ•´çš„æ—¥å¿—ç³»ç»Ÿï¼Œä¾¿äºè°ƒè¯•å’Œç›‘æ§\n- æ”¯æŒè‡ªå®šä¹‰å·¥å…·å’Œ API é›†æˆ\n- é«˜æ€§èƒ½å¹¶å‘å¤„ç†èƒ½åŠ›\n\n## ç¯å¢ƒé…ç½®\n\n### ç³»ç»Ÿè¦æ±‚\n- Python 3.8+\n- Node.js (å¯é€‰ï¼Œç”¨äºè¿è¡Œ JavaScript æœåŠ¡å™¨)\n- Chrome æµè§ˆå™¨ï¼ˆç”¨äºè°·æ­Œæœç´¢åŠŸèƒ½ï¼‰\n- æ‘„åƒå¤´ï¼ˆç”¨äºæ‹ç…§åŠŸèƒ½ï¼‰\n- è‡³å°‘ 4GB å†…å­˜\n- æ”¯æŒ CUDA çš„æ˜¾å¡ï¼ˆå¯é€‰ï¼Œç”¨äºåŠ é€Ÿ AI è®¡ç®—ï¼‰\n\n### å®‰è£…æ­¥éª¤\n\n1. å…‹éš†ä»“åº“ï¼š\n```bash\ngit clone https://github.com/yourusername/mcp-server-for-local.git\ncd mcp-server-for-local\n```\n\n2. åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼š\n```bash\n# Windows\npython -m venv .venv\n.venv\\Scripts\\activate\n\n# Linux\npython3 -m venv .venv\nsource .venv/bin/activate\n```\n\n3. å®‰è£…ä¾èµ–ï¼š\n```bash\n# ä½¿ç”¨ uv å®‰è£…ä¾èµ–\nuv pip install -r requirements.txt\n\n# å¦‚æœé‡åˆ°ç½‘ç»œé—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨å›½å†…é•œåƒ\nuv pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple\n```\n\n4. é…ç½®ç¯å¢ƒå˜é‡ï¼š\n```bash\n# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿\ncp .env.example .env\n\n# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè®¾ç½®ä½ çš„é…ç½®\n```\n\n### ç¯å¢ƒå˜é‡é…ç½®\nç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œè®¾ç½®ä»¥ä¸‹é…ç½®ï¼š\n\n- `DASHSCOPE_API_KEY`: DashScope API å¯†é’¥ï¼ˆå¿…å¡«ï¼‰\n- `MODEL`: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆé»˜è®¤ï¼šqwen-maxï¼‰\n- `CONFIG_FILE`: æœåŠ¡å™¨é…ç½®æ–‡ä»¶è·¯å¾„\n- `GAODE_API_KEY`: é«˜å¾·åœ°å›¾ API å¯†é’¥ï¼ˆç”¨äºå¤©æ°”æŸ¥è¯¢ï¼‰\n- `CHROME_PATH`: Chrome æµè§ˆå™¨è·¯å¾„\n- `CHROMEDRIVER_PATH`: ChromeDriver è·¯å¾„\n- `BASE_URL`: ComfyUI æœåŠ¡å™¨åœ°å€\n- `SERVERS_DIR`: æœåŠ¡å™¨è„šæœ¬ç›®å½•\n- `LOG_LEVEL`: æ—¥å¿—çº§åˆ«ï¼ˆå¯é€‰ï¼šDEBUG, INFO, WARNING, ERRORï¼‰\n\n## ä½¿ç”¨æ–¹æ³•\n\n### åŸºæœ¬ä½¿ç”¨\n\n1. è¿›å…¥é¡¹ç›®ç›®å½•ï¼š\n```bash\ncd src/mcp\n```\n\n2. è¿è¡Œå®¢æˆ·ç«¯ï¼š\n```bash\nuv run .\\client\\mcp_client.py .\\proxy\\proxy_server.py\n```\n\n3. åœ¨å®¢æˆ·ç«¯ä¸­è¾“å…¥å‘½ä»¤ï¼Œä¾‹å¦‚ï¼š\n- \"åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"\n- \"åœ¨è°·æ­Œä¸Šæœç´¢ Python æ•™ç¨‹\"\n- \"æ‹ç…§\"\n- \"ç”Ÿæˆä¸€å¼ çŒ«çš„å›¾ç‰‡\"\n\n### é«˜çº§åŠŸèƒ½\n\n1. **è‡ªå®šä¹‰å·¥å…·**ï¼š\n   - åœ¨ `src/mcp/tools` ç›®å½•ä¸‹æ·»åŠ æ–°çš„å·¥å…·ç±»\n   - å®ç°å¿…è¦çš„æ¥å£æ–¹æ³•\n   - åœ¨é…ç½®æ–‡ä»¶ä¸­æ³¨å†Œæ–°å·¥å…·\n\n2. **API æ‰©å±•**ï¼š\n   - æ”¯æŒæ·»åŠ æ–°çš„ API æœåŠ¡\n   - å¯é…ç½® API å¯†é’¥å’Œç«¯ç‚¹\n   - æ”¯æŒè‡ªå®šä¹‰è¯·æ±‚å’Œå“åº”å¤„ç†\n\n3. **æ—¥å¿—ç®¡ç†**ï¼š\n   - æ”¯æŒå¤šçº§åˆ«æ—¥å¿—è®°å½•\n   - å¯é…ç½®æ—¥å¿—è¾“å‡ºä½ç½®\n   - æ”¯æŒæ—¥å¿—è½®è½¬å’Œå½’æ¡£\n\n## å¸¸è§é—®é¢˜\n\n### å®‰è£…é—®é¢˜\n\n1. ä¾èµ–å®‰è£…å¤±è´¥ï¼š\n```bash\n# å°è¯•æ¸…ç†ç¼“å­˜åé‡æ–°å®‰è£…\nuv pip cache purge\nuv pip install -r requirements.txt\n```\n\n2. è™šæ‹Ÿç¯å¢ƒé—®é¢˜ï¼š\n```bash\n# å¦‚æœæ¿€æ´»å¤±è´¥ï¼Œå°è¯•é‡æ–°åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ\nrm -rf .venv\npython -m venv .venv\n```\n\n### è¿è¡Œé—®é¢˜\n\n1. æƒé™é—®é¢˜ï¼š\n```bash\n# Linux\nchmod +x src/mcp/proxy/proxy_server.py\nchmod +x src/mcp/client/mcp_client.py\n```\n\n2. Chrome ç›¸å…³é—®é¢˜ï¼š\n- ç¡®ä¿ Chrome å’Œ ChromeDriver ç‰ˆæœ¬åŒ¹é…\n- æ£€æŸ¥ Chrome è·¯å¾„æ˜¯å¦æ­£ç¡®\n- ç¡®ä¿æœ‰è¶³å¤Ÿçš„æƒé™è¿è¡Œ Chrome\n- å¦‚æœé‡åˆ°é©±åŠ¨é—®é¢˜ï¼Œå¯ä»¥æ‰‹åŠ¨ä¸‹è½½å¯¹åº”ç‰ˆæœ¬çš„ ChromeDriver\n\n3. API å¯†é’¥é—®é¢˜ï¼š\n- æ£€æŸ¥ `.env` æ–‡ä»¶ä¸­çš„ API å¯†é’¥æ˜¯å¦æ­£ç¡®\n- ç¡®ä¿ API å¯†é’¥æœ‰è¶³å¤Ÿçš„é…é¢\n- æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n\n## å¼€å‘æŒ‡å—\n\n### é¡¹ç›®ç»“æ„\n```\nsrc/mcp/\nâ”œâ”€â”€ client/          # å®¢æˆ·ç«¯ä»£ç \nâ”œâ”€â”€ proxy/           # ä»£ç†æœåŠ¡å™¨ä»£ç \nâ”œâ”€â”€ tools/           # å·¥å…·å®ç°\nâ”œâ”€â”€ utils/           # å·¥å…·å‡½æ•°\nâ””â”€â”€ config/          # é…ç½®æ–‡ä»¶\n```\n\n### æ·»åŠ æ–°åŠŸèƒ½\n1. åœ¨ `tools` ç›®å½•ä¸‹åˆ›å»ºæ–°çš„å·¥å…·ç±»\n2. å®ç°å¿…è¦çš„æ¥å£æ–¹æ³•\n3. åœ¨é…ç½®æ–‡ä»¶ä¸­æ³¨å†Œæ–°å·¥å…·\n4. ç¼–å†™æµ‹è¯•ç”¨ä¾‹\n5. æ›´æ–°æ–‡æ¡£\n\n## è´¡çŒ®æŒ‡å—\n\næ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼åœ¨æäº¤ä¹‹å‰ï¼Œè¯·ç¡®ä¿ï¼š\n1. ä»£ç ç¬¦åˆé¡¹ç›®è§„èŒƒ\n2. æ·»åŠ äº†å¿…è¦çš„æµ‹è¯•\n3. æ›´æ–°äº†ç›¸å…³æ–‡æ¡£\n4. é€šè¿‡äº†æ‰€æœ‰æµ‹è¯•\n\n## è®¸å¯è¯\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "drumnation--unsplash-smart-mcp-server": {
      "owner": "drumnation",
      "name": "unsplash-smart-mcp-server",
      "url": "https://github.com/drumnation/unsplash-smart-mcp-server",
      "imageUrl": "https://github.com/drumnation.png",
      "description": "Connects AI models to Unsplash for searching and delivering stock photos with context-aware selection and automatic attribution management.",
      "stars": 47,
      "forks": 6,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-02T20:15:22Z",
      "readme_content": "# ğŸ–¼ï¸ Unsplash Smart MCP Server\n\n> **Empower your AI agents with stunning visuals, zero hassle.**\n\nA powerful FastMCP server that enables AI agents to seamlessly search, recommend, and deliver professional stock photos from Unsplash with intelligent context awareness and automated attribution management.\n\n![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)\n![Node.js Version](https://img.shields.io/badge/node-%3E%3D18.x-brightgreen)\n![TypeScript Ready](https://img.shields.io/badge/TypeScript-Ready-blue)\n[![smithery badge](https://smithery.ai/badge/@drumnation/unsplash-smart-mcp-server)](https://smithery.ai/server/@drumnation/unsplash-smart-mcp-server)\n[![npm version](https://img.shields.io/npm/v/@drumnation/unsplash-smart-mcp-server.svg)](https://www.npmjs.com/package/@drumnation/unsplash-smart-mcp-server)\n\n## ğŸš€ Why Choose This Unsplash Integration\n\nIn the landscape of visual content integration, our Unsplash Smart MCP Server stands out as the **definitive solution** for AI-powered image acquisition:\n\n- **ğŸ§  AI-Agent Optimized**: Purpose-built for AI agents like Claude in Cursor, streamlining image requests with natural language\n- **ğŸ” Context-Aware Image Selection**: Interprets vague requests intelligently, delivering relevant images even from abstract prompts\n- **âš¡ Single Tool Efficiency**: Eliminates tool spam with a unified `stock_photo` tool that handles the entire image workflow\n- **ğŸ“Š Resource Optimization**: URL-first approach conserves bandwidth and storage while maintaining flexibility\n- **âœ… Automatic Attribution**: Built-in compliance with Unsplash's Terms of Service with zero developer effort\n- **ğŸ“ Project-Aware Organization**: Intelligently organizes images based on your project structure (Next.js, React, Vue, etc.)\n- **ğŸ§© Seamless Integration**: Designed for minimal setup and maximum compatibility with your existing workflow\n\n## âœ¨ Features Beyond Comparison\n\n### For AI Agent Developers\n\n- **Smart Contextual Search**: Find the perfect image through natural language requests\n- **Automatic Subject Selection**: AI determines optimal image subjects from your purpose description\n- **Intent-Driven Results**: Get images that match not just keywords, but the underlying intent\n- **Seamless Agent Integration**: Works out-of-the-box with Claude in Cursor and other MCP-compatible agents\n\n### For Project Efficiency\n\n- **Two-Step Workflow**: Get URLs for controlled downloads, avoiding permission issues and unnecessary storage\n- **Project-Aware File Management**: Auto-organizes images based on framework conventions\n- **Intelligent Directory Creation**: Creates appropriate folder structures based on your project type\n- **Progressive Enhancement**: Works with any project size, from quick prototypes to enterprise applications\n\n### For Compliance Peace of Mind\n\n- **Complete Attribution Management**:\n  - Local attribution database tracks all image usage\n  - Automatic embedding of photographer metadata in images (EXIF, IPTC, XMP)\n  - One-click generation of attribution pages in multiple formats\n  - Comprehensive API for attribution data\n\n## ğŸ› ï¸ Installation\n\n### Prerequisites\n\n- Node.js 18.x or higher\n- An Unsplash API access key ([get one here](https://unsplash.com/developers))\n\n### Local Installation (Recommended)\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/drumnation/unsplash-smart-mcp-server.git\ncd unsplash-smart-mcp-server\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Configure your Cursor MCP settings:\n   - macOS: Edit `~/.cursor/mcp.json`\n   - Windows: Edit `%USERPROFILE%\\.cursor\\mcp.json`\n   - Linux: Edit `~/.cursor/mcp.json`\n\n4. Add the following configuration:\n```json\n{\n  \"servers\": {\n    \"unsplash\": {\n      \"command\": \"npx\",\n      \"args\": [\"tsx\", \"src/server.ts\"],\n      \"cwd\": \"/absolute/path/to/unsplash-smart-mcp-server\",\n      \"env\": {\n        \"UNSPLASH_ACCESS_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n5. Replace:\n   - `/absolute/path/to/unsplash-smart-mcp-server` with the actual path where you cloned the repo\n   - `your_api_key_here` with your Unsplash API key\n\n6. Save the file and restart Cursor.\n\n> **Important:** Unlike many MCP servers, this server requires direct process piping and cannot be accessed via TCP ports or through npm directly due to how it handles FastMCP's I/O interactions. The local installation method is the most reliable approach.\n\n### Cursor CLI Alternative\n\nIf you prefer using Cursor's CLI:\n\n```bash\nclaude mcp add unsplash npx tsx /path/to/unsplash-smart-mcp-server/src/server.ts --cwd /path/to/unsplash-smart-mcp-server\nclaude mcp config set unsplash UNSPLASH_ACCESS_KEY=your_api_key_here\n```\n\nReplace the paths and API key with your actual values.\n\n### Via Docker (Most Reliable Method)\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/drumnation/unsplash-smart-mcp-server.git\ncd unsplash-smart-mcp-server\n```\n\n2. Create a `docker-compose.yml` file:\n```yaml\nservices:\n  unsplash-mcp:\n    build: .\n    image: unsplash-mcp-server\n    restart: always\n    stdin_open: true\n    tty: true\n    environment:\n      - UNSPLASH_ACCESS_KEY=your_api_key_here\n```\n\n3. Build and start the container:\n```bash\ndocker-compose up -d\n```\n\n4. Configure your Cursor MCP settings:\n   - macOS: Edit `~/.cursor/mcp.json`\n   - Windows: Edit `%USERPROFILE%\\.cursor\\mcp.json`\n   - Linux: Edit `~/.cursor/mcp.json`\n\n5. Add the following configuration:\n```json\n{\n  \"servers\": {\n    \"unsplash\": {\n      \"command\": \"docker\",\n      \"args\": [\"exec\", \"-i\", \"unsplash-mcp-unsplash-mcp-1\", \"tsx\", \"src/server.ts\"],\n      \"env\": {}\n    }\n  }\n}\n```\n\n6. Save the file and restart Cursor.\n\nThis setup will:\n- Start the server automatically when Docker starts\n- Restart the server if it crashes\n- Run in the background without terminal windows\n- Provide a reliable connection to Cursor\n\n### Via Smithery (Cloud Deployment)\n\nIf you prefer cloud deployment, you can use Smithery:\n\n1. Install the server in Cursor via Smithery:\n\n```bash\nnpx @smithery/cli install @drumnation/unsplash-smart-mcp-server --client cursor --key your_api_key_here\n```\n\n2. Alternatively, you can log in to [Smithery.ai](https://smithery.ai) and deploy it through their web interface.\n\n> **Note for Windows users:** Smithery deployment includes special handling for Windows compatibility.\n\nFor detailed instructions and troubleshooting, see the [Smithery Deployment Guide](./docs/smithery-deployment.md).\n\n## ğŸ§© Integration with AI Agents\n\n### Step-by-Step Guide for Claude in Cursor\n\nOur Unsplash Smart MCP Server is designed to make image acquisition through AI agents effortless and intuitive:\n\n1. **Initiate a request**: Simply ask Claude for an image in natural language\n2. **AI interpretation**: Claude understands your needs and calls the `stock_photo` tool with optimized parameters\n3. **Smart image selection**: The server interprets context and finds the most relevant images\n4. **Presentation of options**: Claude presents you with the best matches and download commands\n5. **Seamless download**: Execute the suggested commands to place images exactly where you need them\n6. **Automatic attribution**: All attribution data is stored and can be accessed whenever needed\n\nThis process eliminates the traditional workflow of:\n1. ~~Searching Unsplash manually~~\n2. ~~Scrolling through hundreds of results~~\n3. ~~Downloading images to random locations~~\n4. ~~Moving files to the correct project folders~~\n5. ~~Manually tracking attribution data~~\n6. ~~Creating attribution pages~~\n\n### Example Prompts for AI Agents\n\nAsk Claude in Cursor for images using natural language prompts like these:\n\n```\n\"Find a professional image for a tech startup landing page hero section\"\n```\n\n## ğŸªŸ Windows Compatibility\n\nIf you're using Windows and experiencing the \"Client closed\" error when running the MCP server in Cursor, follow these special configuration steps:\n\n### Windows-specific MCP Configuration\n\nCreate a file named `mcp.json` in your `.cursor` directory (typically at `%USERPROFILE%\\.cursor\\mcp.json`) with one of these configurations:\n\n#### Option 1: Direct Node Execution (Recommended)\n\n```json\n{\n  \"mcpServers\": {\n    \"stock_photo\": {\n      \"command\": \"node\",\n      \"args\": [\"./node_modules/.bin/tsx\", \"path/to/unsplash-mcp/src/server.ts\"],\n      \"disabled\": false,\n      \"env\": {\n        \"UNSPLASH_ACCESS_KEY\": \"your_api_key_here\"\n      },\n      \"shell\": false\n    }\n  }\n}\n```\n\n#### Option 2: PowerShell Approach\n\n```json\n{\n  \"mcpServers\": {\n    \"stock_photo\": {\n      \"command\": \"powershell\",\n      \"args\": [\"-Command\", \"npx tsx path/to/unsplash-mcp/src/server.ts\"],\n      \"disabled\": false,\n      \"env\": {\n        \"UNSPLASH_ACCESS_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\nFor complete documentation on Windows compatibility, see [Windows Compatibility Guide](./docs/windows-compatibility.md).\n\n## ğŸ› ï¸ API Reference\n\n### URL-First Approach: The Smart Choice\n\nOur architecture uses a URL-first approach rather than direct image embedding for several critical reasons:\n\n1. **Storage Efficiency**: Prevents AI agents from unnecessarily storing large binary data in their context\n2. **Bandwidth Conservation**: Reduces data transfer between services, improving response times\n3. **Placement Flexibility**: Allows developers to download images exactly where they're needed\n4. **Permission Management**: Avoids filesystem permission issues in restricted environments\n5. **Workflow Integration**: Seamlessly integrates with existing development pipelines\n\nThis strategy enables AI agents to intelligently suggest the optimal download location based on project context, without being constrained by their own environment limitations.\n\n### Minimizing Tool Spam and API Calls\n\nUnlike other solutions that require multiple tool calls for searching, filtering, downloading, and attributing images, our server:\n\n- **Unifies the entire image workflow** into a single `stock_photo` tool\n- **Optimizes result retrieval** by requesting more images upfront to enable better filtering\n- **Eliminates ping-pong interactions** between the agent and services\n- **Reduces agent token usage** by streamlining request and response formats\n\nThis design significantly reduces the number of API calls and tool invocations, leading to faster results and lower operational costs.\n\n## ğŸ”„ Automatic Attribution and Compliance\n\n### Unsplash Terms of Service: Effortless Compliance\n\nUsing images from Unsplash requires adherence to their [Terms of Service](https://unsplash.com/license). Our server handles this automatically:\n\n1. **Attribution Data Capture**: Every image download automatically stores photographer information\n2. **Metadata Embedding**: Photographer details are embedded directly into image files\n3. **Attribution Database**: A local database maintains a record of all image usage\n4. **Attribution Generators**: Built-in tools create HTML and React attribution components\n5. **API Access**: Simple endpoints to retrieve attribution data for any project\n\nBy using our Unsplash Smart MCP Server, you are automatically compliant with Unsplash's requirements without any additional effort.\n\n### Attribution Management System\n\nThe server includes a comprehensive attribution management system:\n\n```javascript\n// Retrieve attribution data for your project\nconst attributions = await fetch('http://localhost:3000/api/unsplash', {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({\n    method: 'get_attributions',\n    params: {\n      format: 'json',  // Options: json, html, react\n      projectPath: '/path/to/your/project'\n    }\n  })\n}).then(res => res.json());\n\n// attributions contains complete data about every image used\n```\n\nThe API can generate three types of attribution files:\n\n1. **JSON**: Structured data for custom implementations\n2. **HTML**: Ready-to-use HTML page for website footer or credits section\n3. **React**: Drop-in React component for modern web applications\n\n## ğŸ’¼ Developer Workflow Integration\n\n### Real-World Use Cases\n\nOur Unsplash Smart MCP Server seamlessly integrates into your development workflow:\n\n#### UI Development\n- Instantly populate mockups with relevant placeholder images\n- Maintain consistent image dimensions across components\n- Organize images logically within your project structure\n\n#### Documentation\n- Enhance technical documentation with explanatory visuals\n- Create visually appealing tutorials and guides\n- Maintain proper attribution for all visual assets\n\n#### Content Creation\n- Quickly find images for blog posts and articles\n- Generate visuals for social media content\n- Access consistent imagery for product marketing\n\n#### Application Development\n- Populate e-commerce sites with product imagery\n- Create visually rich user experiences\n- Maintain separate image collections for different sections\n\n### Framework-Specific Organization\n\nImages are automatically organized based on your project type:\n\n| Framework | Default Image Path | Alternate Paths |\n|-----------|-------------------|----------------|\n| Next.js   | `/public/images/` | `/public/assets/images/` |\n| React     | `/src/assets/images/` | `/assets/images/` |\n| Vue       | `/src/assets/images/` | `/public/images/` |\n| Angular   | `/src/assets/images/` | `/assets/images/` |\n| Generic   | `/assets/images/` | `~/Downloads/stock-photos/` |\n\n## ğŸ¥‡ Competitive Differentiation\n\n### Why Choose Our Unsplash Integration?\n\n| Feature | Unsplash Smart MCP Server | Alternatives |\n|---------|--------------|--------------|\n| **AI Agent Integration** | âœ… Purpose-built for AI agent workflow | âŒ Typically requires manual parameter setting |\n| **Context Awareness** | âœ… Interprets vague requests intelligently | âŒ Relies on exact keyword matching |\n| **Tool Efficiency** | âœ… Single tool handles entire workflow | âŒ Often requires multiple separate tools |\n| **Attribution Management** | âœ… Comprehensive system with multiple formats | âŒ Manual tracking or basic text output |\n| **Project Organization** | âœ… Framework-aware folder structures | âŒ Generic downloads to a single location |\n| **Installation Complexity** | âœ… Simple one-line command | âŒ Often requires multiple configuration steps |\n| **Response Format** | âœ… AI-optimized with relevant context | âŒ Generic JSON requiring further processing |\n| **Download Flexibility** | âœ… URL-first with intelligent suggestions | âŒ Either direct downloads or just URLs |\n\n## âš™ï¸ Configuration\n\n### Environment Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| `UNSPLASH_ACCESS_KEY` | Your Unsplash API access key | - |\n| `PORT` | Port for the server to listen on | `3000` |\n| `HOST` | Host for the server | `localhost` |\n| `ATTRIBUTION_DB_PATH` | Path to store attribution database | `~/.unsplash-mcp` |\n\n### Tool Parameters\n\n#### stock_photo\n\n| Parameter | Type | Description | Default |\n|-----------|------|-------------|---------|\n| `query` | string | What to search for (AI will choose if not specified) | - |\n| `purpose` | string | Where the image will be used (e.g., hero, background) | - |\n| `count` | number | Number of images to return | `1` |\n| `orientation` | string | Preferred orientation (any, landscape, portrait, square) | `any` |\n| `width` | number | Target width in pixels | - |\n| `height` | number | Target height in pixels | - |\n| `minWidth` | number | Minimum width for filtering results | - |\n| `minHeight` | number | Minimum height for filtering results | - |\n| `outputDir` | string | Directory to save photos | `~/Downloads/stock-photos` |\n| `projectType` | string | Project type for folder structure (next, react, vue, angular) | - |\n| `category` | string | Category for organizing images (e.g., heroes, backgrounds) | - |\n| `downloadMode` | string | Whether to download images or return URLs | `urls_only` |\n\n#### get_attributions\n\n| Parameter | Type | Description | Default |\n|-----------|------|-------------|---------|\n| `format` | string | Output format (json, html, react) | `json` |\n| `projectPath` | string | Filter attributions to a specific project path | - |\n| `outputPath` | string | Where to save attribution files | - |\n\n## ğŸ”§ Troubleshooting\n\n### Common Issues and Solutions\n\n| Issue | Solution |\n|-------|----------|\n| **Connection Refused** | Ensure the server is running on the configured port |\n| **Authentication Error** | Verify your Unsplash API key is correctly set |\n| **No Images Found** | Try broader search terms or check your search query |\n| **Download Permission Issues** | Use `downloadMode: 'urls_only'` and manual download commands |\n| **Docker Container Exits Prematurely** | Ensure you're using `CMD [\"npm\", \"start\"]` in your Dockerfile instead of directly running the TypeScript file with tsx. This ensures the server stays running in a Docker environment. |\n| **Timeout Errors** | The default MCP timeout is 60 seconds, which may be insufficient for downloading larger images or processing multiple images. For image-heavy operations: 1) Process fewer images per request, 2) Use smaller image dimensions, 3) Consider using `urls_only` mode instead of auto-download, 4) Check network connectivity |\n| **Attribution Not Found** | Verify the image was downloaded through the MCP server |\n| **Unhandled MCP Errors** | If you see `\"McpError: MCP error -32001: Request timed out\"` errors, your request is likely taking too long. Break it into smaller operations or use the URLs-only approach |\n\n## ğŸ¤ Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n### Development Workflow\n\n1. Clone the repository\n2. Install dependencies with `npm install`\n3. Create a `.env` file with your Unsplash API key\n4. Run in development mode with `npm run dev`\n5. Run tests with `npm test`\n\n## ğŸ—ºï¸ Roadmap\n\nHere's what we're planning for future releases:\n\n- **Image Editing Capabilities**: Basic resizing, cropping, and adjustment tools\n- **Advanced Search Filters**: More granular control over image selection\n- **Batch Processing**: Handle multiple image requests efficiently\n- **Custom Collections**: Save and manage groups of images for projects\n- **Team Collaboration**: Share attribution and image collections\n- **Usage Analytics**: Track image usage across projects\n- **Additional Image Sources**: Integration with other stock photo providers\n- **Improved Timeout Handling**: Enhanced timeout configuration and recovery mechanisms\n\n## ğŸ“„ License\n\nMIT License\n\n## ğŸ“š Attribution Requirements\n\nWhen using images from Unsplash, you must comply with the [Unsplash License](https://unsplash.com/license):\n\n- Attribution is not required but appreciated\n- You cannot sell unaltered copies of the photos\n- You cannot compile photos from Unsplash to create a competing service\n\nOur server's attribution system makes it easy to provide proper credit to photographers.\n\n## ğŸ“ Contact\n\nFor issues or questions, please [open an issue](https://github.com/drumnation/unsplash-smart-mcp-server/issues) on GitHub.\n\n## ğŸ§° Development and Testing\n\n### Running the Server Locally\n\n```bash\n# Clone the repository\ngit clone https://github.com/drumnation/unsplash-smart-mcp-server.git\ncd unsplash-smart-mcp-server\n\n# Install dependencies\nnpm install\n\n# Set up your environment variables\ncp .env.example .env\n# Edit .env to add your UNSPLASH_ACCESS_KEY\n\n# Start the development server\nnpm run dev\n```\n\n### Testing\n\nThe package includes a comprehensive test suite:\n\n```bash\n# Run core tests\nnpm test\n\n# Run all tests and get a summary report\nnpm run test:all\n```\n\nThe test suite includes:\n- Unit and integration tests\n- Manual tool testing\n- Docker container tests\n- Smithery.ai integration tests\n\nFor detailed information about testing, see [docs/testing.md](docs/testing.md).\n\n---\n\n<p align=\"center\">\n  <strong>Empower your AI agents with the perfect images, every time.</strong><br>\n  Built with â¤ï¸ for developers and AI enthusiasts.\n</p>\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "dvejsada--mcp_media_generator": {
      "owner": "dvejsada",
      "name": "mcp_media_generator",
      "url": "https://github.com/dvejsada/mcp_media_generator",
      "imageUrl": "https://github.com/dvejsada.png",
      "description": "Create images using the Amazon Nova Canvas model and videos using the Amazon Nova Reel model. Connects to existing tools for media generation and storage.",
      "stars": 3,
      "forks": 3,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-16T11:26:11Z",
      "readme_content": "# What is it?\n\nA [Model Context Protocol](https://modelcontextprotocol.io/) Server running over SSE\n\n# What it offers?\n\nTools to create images using Amazon Nova Canvas model and videos using Amazon Nova Reel model.\n\n# What do I need?\n\n- Amazon Bedrock account with access to Amazon Nova Canvas and Amazon Nova Reel models.\n- Amazon S3 bucket to store the video\n- MCP Client, such is Claude Desktop or [LibreChat](https://github.com/danny-avila/LibreChat)\n\n# How to run this?\n\nUsing Docker with precompiled image as per docker-compose.yml. App is listening on port 8961.\n\n## How to add to LibreChat\n\nIn your librechat.yaml file, add the following section:\n\n```yaml\nmcpServers:\n  media-creator:\n    type: sse # type can optionally be omitted\n    url: URL of your docker container # e.g. http://localhost:8961/sse\n```\n\n## How to use in LibreChat\n\nAfter the server is added to LibreChat as per above, restart LibreChat to connect to MCP server and discover tools. Then, create an agent and add the respective tools to agent.\n\nWhen the agent is created, you may ask the agent to create image or video which should invoke the provided tools.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "el-el-san--vidu-mcp-server": {
      "owner": "el-el-san",
      "name": "vidu-mcp-server",
      "url": "https://github.com/el-el-san/vidu-mcp-server",
      "imageUrl": "https://github.com/el-el-san.png",
      "description": "Generate videos from static images using advanced AI models, while monitoring the status of video generation tasks and uploading images for processing.",
      "stars": 3,
      "forks": 2,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-09T11:11:26Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/el-el-san-vidu-mcp-server-badge.png)](https://mseep.ai/app/el-el-san-vidu-mcp-server)\n\n# Vidu MCP Server\n[![smithery badge](https://smithery.ai/badge/@el-el-san/vidu-mcp-server)](https://smithery.ai/server/@el-el-san/vidu-mcp-server)\n\nViduå‹•ç”»ç”ŸæˆAPIã¨é€£æºã™ã‚‹ãŸã‚ã®Model Context Protocol (MCP) ã‚µãƒ¼ãƒãƒ¼ã§ã™ã€‚Viduã®å¼·åŠ›ãªAIãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€ç”»åƒã‹ã‚‰å‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹ãƒ„ãƒ¼ãƒ«ã‚’æä¾›ã—ã¾ã™ã€‚\n\n## æ©Ÿèƒ½\n\n- **ç”»åƒã‹ã‚‰å‹•ç”»ã¸ã®å¤‰æ›**: ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªè¨­å®šã§é™æ­¢ç”»ã‹ã‚‰å‹•ç”»ã‚’ç”Ÿæˆ\n  - è¤‡æ•°ãƒ¢ãƒ‡ãƒ«å¯¾å¿œ: viduq1ã€vidu1.5ã€vidu2.0\n  - ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®æ™‚é–“ãƒ»è§£åƒåº¦åˆ¶ç´„\n  - 4ç§’å‹•ç”»å‘ã‘ã®BGMå¯¾å¿œ\n  - éåŒæœŸé€šçŸ¥ç”¨ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯URLå¯¾å¿œ\n- **ç”ŸæˆçŠ¶æ³ã®ç¢ºèª**: ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆä½¿ç”¨é‡æƒ…å ±ä»˜ãã§å‹•ç”»ç”Ÿæˆã‚¿ã‚¹ã‚¯ã®é€²æ—ã‚’ç›£è¦–\n- **ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: Vidu APIã§ä½¿ç”¨ã™ã‚‹ç”»åƒã‚’ç°¡å˜ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆæœ€å¤§10MBï¼‰\n\n## å‰ææ¡ä»¶\n\n- Node.js (v14ä»¥ä¸Š)\n- Vidu APIã‚­ãƒ¼ï¼ˆ[Viduã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ](https://vidu.com)ã‹ã‚‰å–å¾—å¯èƒ½ï¼‰\n- TypeScriptï¼ˆé–‹ç™ºç”¨ï¼‰\n\n## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n\n### SmitheryçµŒç”±ã§ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n\n[Smithery](https://smithery.ai/server/@el-el-san/vidu-mcp-server)ã‚’ä½¿ç”¨ã—ã¦Claude Desktopç”¨ã®Vidu Video Generation Serverã‚’è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:\n\n```bash\nnpx -y @smithery/cli install @el-el-san/vidu-mcp-server --client claude\n```\n\n### Gemini CLIè¨­å®š\n\nGemini CLIã§ä½¿ç”¨ã™ã‚‹ã«ã¯ã€`~/.gemini/settings.json`ã«ã‚µãƒ¼ãƒãƒ¼è¨­å®šã‚’è¿½åŠ ã—ã¦ãã ã•ã„:\n\n```json\n{\n  \"mcpServers\": {\n    \"vidu\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"your_path/vidu-mcp-server/build/index.js\"\n      ],\n      \"env\": {\n        \"VIDU_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n**æ³¨æ„**: `your_path`ã‚’å®Ÿéš›ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã«ã€`your_api_key_here`ã‚’ã‚ãªãŸã®Vidu APIã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„ã€‚\n\n### æ‰‹å‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n1. ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³:\n```bash\ngit clone https://github.com/el-el-san/vidu-mcp-server.git\ncd vidu-mcp-server\n```\n\n2. ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:\n```bash\nnpm install\n```\n\n3. `.env.template`ã‚’åŸºã«`.env`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€Vidu APIã‚­ãƒ¼ã‚’è¿½åŠ :\n```\nVIDU_API_KEY=your_api_key_here\n```\n\n## ä½¿ç”¨æ–¹æ³•\n\n### Gemini CLIç”¨\n\n1. TypeScriptã‚³ãƒ¼ãƒ‰ã‚’ãƒ“ãƒ«ãƒ‰:\n```bash\nnpm run build\n```\n\n2. Gemini CLIè¨­å®šã§è¨­å®šï¼ˆä¸Šè¨˜ã®Gemini CLIè¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‚ç…§ï¼‰\n\n3. Gemini CLIã‚’å†èµ·å‹•ã—ã¦MCPã‚’èª­ã¿è¾¼ã¿\n\n## ãƒ„ãƒ¼ãƒ«\n\n### 1. ç”»åƒã‹ã‚‰å‹•ç”»ã¸ã®å¤‰æ›\n\nã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§é™æ­¢ç”»ã‚’å‹•ç”»ã«å¤‰æ›ã—ã¾ã™ã€‚\n\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\n- `image_url` (å¿…é ˆ): å‹•ç”»ã«å¤‰æ›ã™ã‚‹ç”»åƒã®URL\n- `prompt` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³): å‹•ç”»ç”Ÿæˆç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæœ€å¤§1500æ–‡å­—ï¼‰\n- `duration` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³): å‡ºåŠ›å‹•ç”»ã®æ™‚é–“ï¼ˆç§’ï¼‰ï¼ˆãƒ¢ãƒ‡ãƒ«å›ºæœ‰ï¼‰\n  - **viduq1**: 5ç§’ã®ã¿\n  - **vidu1.5/vidu2.0**: 4ç§’ã¾ãŸã¯8ç§’ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ4ç§’ï¼‰\n- `model` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³): ç”Ÿæˆç”¨ãƒ¢ãƒ‡ãƒ«åï¼ˆ\"viduq1\", \"vidu1.5\", \"vidu2.0\", ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ \"vidu2.0\"ï¼‰\n- `resolution` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³): å‡ºåŠ›å‹•ç”»ã®è§£åƒåº¦ï¼ˆãƒ¢ãƒ‡ãƒ«/æ™‚é–“å›ºæœ‰ï¼‰\n  - **viduq1 (5s)**: 1080pã®ã¿\n  - **vidu1.5/vidu2.0 (4s)**: \"360p\", \"720p\", \"1080p\"ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ \"360p\"ï¼‰\n  - **vidu1.5/vidu2.0 (8s)**: \"720p\"ã®ã¿\n- `movement_amplitude` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³): ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å‹•ãã®æŒ¯å¹…ï¼ˆ\"auto\", \"small\", \"medium\", \"large\", ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ \"auto\"ï¼‰\n- `seed` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³): å†ç¾æ€§ã®ãŸã‚ã®ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰\n- `bgm` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³): å‹•ç”»ã«BGMã‚’è¿½åŠ ï¼ˆboolean, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ false, 4ç§’å‹•ç”»ã®ã¿ï¼‰\n- `callback_url` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³): ç”ŸæˆçŠ¶æ³å¤‰æ›´æ™‚ã®éåŒæœŸé€šçŸ¥ç”¨URL\n\nãƒªã‚¯ã‚¨ã‚¹ãƒˆä¾‹:\n```json\n{\n  \"image_url\": \"https://example.com/image.jpg\",\n  \"prompt\": \"å±±ã‚’èƒŒæ™¯ã«ã—ãŸé™ã‹ãªæ¹–\",\n  \"duration\": 8,\n  \"model\": \"vidu2.0\",\n  \"resolution\": \"720p\",\n  \"movement_amplitude\": \"medium\",\n  \"seed\": 12345,\n  \"bgm\": false\n}\n```\n\n### 2. ç”ŸæˆçŠ¶æ³ã®ç¢ºèª\n\nå®Ÿè¡Œä¸­ã®å‹•ç”»ç”Ÿæˆã‚¿ã‚¹ã‚¯ã®çŠ¶æ³ã‚’ç¢ºèªã—ã¾ã™ã€‚\n\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\n- `task_id` (å¿…é ˆ): ç”»åƒã‹ã‚‰å‹•ç”»ã¸ã®å¤‰æ›ãƒ„ãƒ¼ãƒ«ã§è¿”ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ID\n\nãƒªã‚¯ã‚¨ã‚¹ãƒˆä¾‹:\n```json\n{\n  \"task_id\": \"12345abcde\"\n}\n```\n\n### 3. ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n\nVidu APIã§ä½¿ç”¨ã™ã‚‹ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\n- `image_path` (å¿…é ˆ): ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹\n- `image_type` (å¿…é ˆ): ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ï¼ˆ\"png\", \"webp\", \"jpeg\", \"jpg\"ï¼‰\n\nãƒªã‚¯ã‚¨ã‚¹ãƒˆä¾‹:\n```json\n{\n  \"image_path\": \"/path/to/your/image.jpg\",\n  \"image_type\": \"jpg\"\n}\n```\n\n## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°\n\n- **APIã‚­ãƒ¼ã®å•é¡Œ**: Vidu APIã‚­ãƒ¼ãŒ`.env`ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ‰‹å‹•è¨­å®šã®å ´åˆï¼‰ã¾ãŸã¯Gemini CLIè¨­å®šï¼ˆGemini CLIè¨­å®šã®å ´åˆï¼‰ã§æ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„\n- **ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼**: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒæœ‰åŠ¹ã§ã€ã‚µã‚¤ã‚ºåˆ¶é™å†…ï¼ˆupload-imageãƒ„ãƒ¼ãƒ«ã¯10MBã€ç›´æ¥URLç”»åƒã¯æœ€å¤§50MBï¼‰ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„\n- **æ¥ç¶šå•é¡Œ**: ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã‚¢ã‚¯ã‚»ã‚¹ãŒã‚ã‚Šã€Vidu APIã‚µãƒ¼ãƒãƒ¼ã«åˆ°é”ã§ãã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„\n- **Gemini CLIã®å•é¡Œ**: \n  - Gemini CLIã§è¨­å®šã™ã‚‹å‰ã«ã‚µãƒ¼ãƒãƒ¼ãŒãƒ“ãƒ«ãƒ‰ã•ã‚Œã¦ã„ã‚‹ï¼ˆ`npm run build`ï¼‰ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„\n  - settings.jsonã®ãƒ‘ã‚¹ãŒæ­£ã—ã„`build/index.js`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„\n  - è¨­å®šå¤‰æ›´å¾Œã«Gemini CLIã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„\n  - ã‚µãƒ¼ãƒãƒ¼è¨­å®šã§`\"disabled\": false`ã«è¨­å®šã—ã¦ãã ã•ã„\n\n\n\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Emmanuel97423--video_maker": {
      "owner": "Emmanuel97423",
      "name": "video_maker",
      "url": "https://github.com/Emmanuel97423/video_maker",
      "imageUrl": "https://github.com/Emmanuel97423.png",
      "description": "Create and manage video projects using an intuitive interface built with Next.js, facilitating video content creation and project management through streamlined workflows and powerful features.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-04-01T18:44:57Z",
      "readme_content": "pmThis is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).\n\n## Getting Started\n\nFirst, run the development server:\n\n```bash\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n# or\nbun dev\n```\n\nOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result.\n\nYou can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.\n\nThis project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.\n\n## Learn More\n\nTo learn more about Next.js, take a look at the following resources:\n\n- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.\n- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.\n\nYou can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!\n\n## Deploy on Vercel\n\nThe easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.\n\nCheck out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "evalstate--mcp-webcam": {
      "owner": "evalstate",
      "name": "mcp-webcam",
      "url": "https://github.com/evalstate/mcp-webcam",
      "imageUrl": "https://github.com/evalstate.png",
      "description": "Streams live images from a webcam to an MCP Client, supporting both capturing frames and taking screenshots.",
      "stars": 90,
      "forks": 10,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T23:37:10Z",
      "readme_content": "# â­â­ mcp-webcam 0.2.0 - the 50 Star Update â­â­ \n\nIn celebration of getting 52 GitHub stars, `mcp-webcam 0.2.0` is here! Now supports streamable-http!! No installation required! - try it now at [`https://webcam.fast-agent.ai/`](https://webcam.fast-agent.ai/). You can specify your own UserID by adding `?user=<YOUR_USER_ID>` after the URL. Note this shared instance is for fun, not security - see below for instructions how to run your own copy locally.\n\nIn streamable-http mode multiple clients can connect simultaneously, and you can choose which is used for Sampling.\n\n![mcp_webcam_020_thumb](https://github.com/user-attachments/assets/041e3091-71e5-4aa1-9170-ee20177485ef)\n\nIf we get to 100 stars I'll add another feature ğŸ˜Š.\n\n## Multi-user Mode\n\nWhen run in Streaming mode, if you set an MCP_HOST environment variable the host name is used as a prefix in URL construction, and 5 character UserIDs are automatically generated when the User lands on the webpage. \n\n![image](https://github.com/user-attachments/assets/30d06cc2-59b6-485b-989d-7030b39c287d)\n\n\n## mcp-webcam\n\nMCP Server that provides access to your WebCam. Provides `capture` and `screenshot` tools to take an image from the Webcam, or take a screenshot. The current image is also available as a Resource.\n\n### MCP Sampling\n\n`mcp-webcam` supports \"sampling\"! Press the \"Sample\" button to send a sampling request to the Client along with your entered message. \n\n> [!TIP]\n> Claude Desktop does not currently support Sampling. If you want a Client that can handle multi-modal sampling request, try https://github.com/evalstate/fast-agent/ or VSCode (more details below).\n\n## Installation and Running\n\n### NPX\n\nInstall a recent version of [NodeJS](https://nodejs.org/en/download) for your platform. The NPM package is `@llmindset/mcp-webcam`. \n\nTo start in **STDIO** mode: `npx @llmindset/mcp-webcam`. This starts the `mcp-webcam` UI on port 3333. Point your browser at `http://localhost:3333` to get started.\n\nTo change the port: `npx @llmindset/mcp-webcam 9999`. This starts `mcp-webcam` the UI on port 9999.\n\nFor **Streaming HTTP** mode: `npx @llmindset/mcp-webcam --streaming`. This will make the UI available at `http://localhost:3333` and the MCP Server available at `http://localhost:3333/mcp`.\n\n### Docker\n\nYou can run `mcp-webcam` using Docker. By default, it starts in **streaming mode**:\n\n```bash\ndocker run -p 3333:3333 ghcr.io/evalstate/mcp-webcam:latest\n```\n\n#### Environment Variables\n\n- `MCP_TRANSPORT_MODE` - Set to `stdio` for STDIO mode, defaults to `streaming`\n- `PORT` - The port to run on (default: `3333`)\n- `BIND_HOST` - Network interface to bind the server to (default: `localhost`)\n- `MCP_HOST` - Public-facing URL for user instructions and MCP client connections (default: `http://localhost:3333`)\n\n#### Examples\n\n```bash\n# STDIO mode\ndocker run -p 3333:3333 -e MCP_TRANSPORT_MODE=stdio ghcr.io/evalstate/mcp-webcam:latest\n\n# Custom port\ndocker run -p 8080:8080 -e PORT=8080 ghcr.io/evalstate/mcp-webcam:latest\n\n# For cloud deployments with custom domain (e.g., Hugging Face Spaces)\ndocker run -p 3333:3333 -e MCP_HOST=https://evalstate-mcp-webcam.hf.space ghcr.io/evalstate/mcp-webcam:latest\n\n# Complete cloud deployment example\ndocker run -p 3333:3333 -e MCP_HOST=https://your-domain.com ghcr.io/evalstate/mcp-webcam:latest\n```\n\n## Clients\n\nIf you want a Client that supports sampling try:\n\n### fast-agent\n\nStart the `mcp-webcam` in streaming mode, install [`uv`](https://docs.astral.sh/uv/) and connect with:\n\n`uvx fast-agent-mcp go --url http://localhost:3333/mcp`\n\n`fast-agent` currently uses Haiku as its default model, so set an `ANTHROPIC_API_KEY`. If you want to use a different model, you can add `--model` on the command line. More instructions for installation and configuration are available here: https://fast-agent.ai/models/.\n\nTo start the server in STDIO mode, add the following to your `fastagent.config.yaml`\n\n```yaml\nwebcam_local:\n   command: \"npx\"\n   args: [\"@llmindset/mcp-webcam\"]\n```\n\n### VSCode\n\nVSCode versions 1.101.0 and above support MCP Sampling. Simply start `mcp-webcam` in streaming mode, and add `http://localhost:3333/mcp` as an MCP Server to get started.\n\n### Claude Desktop\n\nClaude Desktop does **NOT** support Sampling. To run `mcp-webcam` from Claude Desktop, add the following to the `mcpServers` section of your `claude_desktop_config.json` file:\n\n```json\n    \"webcam\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-webcam\"\n      ]\n    }\n```\n\nStart Claude Desktop, and connect to `http://localhost:3333`. You can then ask Claude to `get the latest picture from my webcam`, or `Claude, take a look at what I'm holding` or `what colour top am i wearing?`. You can \"freeze\" the current image and that will be returned to Claude rather than a live capture. \n\nYou can ask for Screenshots - navigate to the browser so that you can guide the capture area when the request comes in. Screenshots are automatically resized to be manageable for Claude (useful if you have a 4K Screen). The button is there to allow testing of your platform specific Screenshot UX - it doesn't do anything other than prepare you for a Claude intiated request. NB this does not **not** work on Safari as it requires human initiation.\n\n## Other notes\n\nThat's it really. \n\nThis MCP Server was built to demonstrate exposing a User Interface on an MCP Server, and serving live resources back to Claude Desktop.\n\nThis project might prove useful if you want to build a local, interactive MCP Server.\n\nThanks to  https://github.com/tadasant for help with testing and setup. \n\nPlease read the article at [https://llmindset.co.uk/posts/2025/01/resouce-handling-mcp](https://llmindset.co.uk/posts/2025/01/mcp-files-resources-part1/) for more details about handling files and resources in LLM / MCP Chat Applications, and why you might want to do this.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "evalstate--mcp-hfspace": {
      "owner": "evalstate",
      "name": "mcp-hfspace",
      "url": "https://github.com/evalstate/mcp-hfspace",
      "imageUrl": "https://github.com/evalstate.png",
      "description": "Connects to Hugging Face Spaces to access various AI models for tasks including image generation, text-to-speech, speech-to-text, and chat functionalities, requiring minimal setup.",
      "stars": 360,
      "forks": 57,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T22:31:58Z",
      "readme_content": "# mcp-hfspace MCP Server ğŸ¤—\n\n> [!TIP]\n>\n> You can access and configure Hugging Face MCP services directly at https://hf.co/mcp, including Gradio spaces.\n>\n> This project has been superceded by the official [Hugging Face MCP Server](https://github.com/evalstate/hf-mcp-server) and [Gradio MCP Endpoints](https://huggingface.co/blog/gradio-mcp).\n> \n> Alternatively you can run hf-mcp-server locally as a STDIO Server, or with robust support for SSE, Streaming HTTP and Streaming HTTP JSON Mode. This also runs a local UI for selecting tools and endpoints and supports `ToolListChangedNotifications` too.\n\n## hf.co/mcp\n\n![image](https://github.com/user-attachments/assets/9cbf407b-2330-4330-8274-e47305a555b9)\n\n## mcp-hfspace\n\nRead the introduction here [llmindset.co.uk/resources/mcp-hfspace/](https://llmindset.co.uk/resources/mcp-hfspace/)\n\nConnect to [Hugging Face Spaces](https://huggingface.co/spaces) with minimal setup needed - simply add your spaces and go!\n\nBy default, it connects to `black-forest-labs/FLUX.1-schnell` providing Image Generation capabilities to Claude Desktop.\n\n\n\n\n![Default Setup](./images/2024-12-09-flower.png)\n\n\n## Gradio MCP Support\n\n> [!TIP]\n> Gradio 5.28 now has integrated MCP Support via SSE: https://huggingface.co/blog/gradio-mcp. Check out whether your target Space is MCP Enabled!\n\n## Installation\n\nNPM Package is `@llmindset/mcp-hfspace`.\n\nInstall a recent version of [NodeJS](https://nodejs.org/en/download) for your platform, then add the following to the `mcpServers` section of your `claude_desktop_config.json` file:\n\n```json\n    \"mcp-hfspace\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\"\n      ]\n    }\n```\n\nPlease make sure you are using Claude Desktop 0.78 or greater.\n\nThis will get you started with an Image Generator.\n\n### Basic setup\n\nSupply a list of HuggingFace spaces in the arguments. mcp-hfspace will find the most appropriate endpoint and automatically configure it for usage. An example `claude_desktop_config.json` is supplied [below](#installation).\n\nBy default the current working directory is used for file upload/download. On Windows this is a read/write folder at `\\users\\<username>\\AppData\\Roaming\\Claude\\<version.number\\`, and on MacOS it is the is the read-only root: `/`.\n\nIt is recommended to override this and set a Working Directory for handling the upload and download of images and other file-based content. Specify either the `--work-dir=/your_directory` argument or `MCP_HF_WORK_DIR` environment variable.\n\nAn example configuration for using a modern image generator, vision model and text to speech, with a working directory set is below:\n\n```json\n    \"mcp-hfspace\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\",\n        \"--work-dir=/Users/evalstate/mcp-store\",\n        \"shuttleai/shuttle-jaguar\",\n        \"styletts2/styletts2\",\n        \"Qwen/QVQ-72B-preview\"\n      ]\n    }\n```\n\nTo use private spaces, supply your Hugging Face Token with either the `--hf-token=hf_...` argument or `HF_TOKEN` environment variable.\n\nIt's possible to run multiple server instances to use different working directories and tokens if needed.\n\n## File Handling and Claude Desktop Mode\n\nBy default, the Server operates in _Claude Desktop Mode_. In this mode, Images are returned in the tool responses, while other files are saved in the working folder, their file path is returned as a message. This will usually give the best experience if using Claude Desktop as the client.\n\nURLs can also be supplied as inputs: the content gets passed to the Space.\n\nThere is an \"Available Resources\" prompt that gives Claude the available files and mime types from your working directory. This is currently the best way to manage files.\n\n### Example 1 - Image Generation (Download Image / Claude Vision)\n\nWe'll use Claude to compare images created by `shuttleai/shuttle-3.1-aesthetic` and `FLUX.1-schnell`. The images gets saved to the Work Directory, as well as included in Claude's context window - so Claude can use its vision capabilities.\n\n![Image Generation Comparison](./images/2024-12-05-flux-shuttle.png)\n\n### Example 2 - Vision Model (Upload Image)\n\nWe'll use `merve/paligemma2-vqav2` [space link](https://huggingface.co/spaces/merve/paligemma2-vqav2) to query an image. In this case, we specify the filename which is available in the Working Directory: we don't want to upload the Image directly to Claude's context window. So, we can prompt Claude:\n\n`use paligemma to find out who is in \"test_gemma.jpg\"` -> `Text Output: david bowie`\n![Vision - File Upload](./images/2024-12-09-bowie.png)\n\n_If you are uploading something to Claude's context use the Paperclip Attachment button, otherwise specify the filename for the Server to send directly._\n\nWe can also supply a URL. For example : `use paligemma to detect humans in https://e3.365dm.com/24/12/1600x900/skynews-taylor-swift-eras-tour_6771083.jpg?20241209000914` -> `One person is detected in the image - Taylor Swift on stage.`\n\n### Example 3 - Text-to-Speech (Download Audio)\n\nIn _Claude Desktop Mode_, the audio file is saved in the WORK_DIR, and Claude is notified of the creation. If not in desktop mode, the file is returned as a base64 encoded resource to the Client (useful if it supports embedded Audio attachments).\n\n![Voice Production](./images/2024-12-08-mcp-parler.png)\n\n### Example 4 - Speech-to-Text (Upload Audio)\n\nHere, we use `hf-audio/whisper-large-v3-turbo` to transcribe some audio, and make it available to Claude.\n\n![Audio Transcribe](./images/2024-12-09-transcribe.png)\n\n### Example 5 - Image-to-Image\n\nIn this example, we specify the filename for `microsoft/OmniParser` to use, and get returned an annotated Image and 2 separate pieces of text: descriptions and coordinates. The prompt used was `use omniparser to analyse ./screenshot.png` and `use the analysis to produce an artifact that reproduces that screen`. `DawnC/Pawmatch` is also good at this.\n\n![Omniparser and Artifact](./images/2024-12-08-mcp-omni-artifact.png)\n\n### Example 6 - Chat\n\nIn this example, Claude sets a number of reasoning puzzles for Qwen, and asks follow-up questions for clarification.\n\n![Qwen Reasoning Test](./images/2024-12-09-qwen-reason.png)\n\n### Specifying API Endpoint\n\nIf you need, you can specify a specific API Endpoint by adding it to the spacename. So rather than passing in `Qwen/Qwen2.5-72B-Instruct` you would use `Qwen/Qwen2.5-72B-Instruct/model_chat`.\n\n### Claude Desktop Mode\n\nThis can be disabled with the option --desktop-mode=false or the environment variable CLAUDE_DESKTOP_MODE=false. In this case, content as returned as an embedded Base64 encoded Resource.\n\n## Recommended Spaces\n\nSome recommended spaces to try:\n\n### Image Generation\n\n- shuttleai/shuttle-3.1-aesthetic\n- black-forest-labs/FLUX.1-schnell\n- yanze/PuLID-FLUX\n- gokaygokay/Inspyrenet-Rembg (Background Removal)\n- diyism/Datou1111-shou_xin - [Beautiful Pencil Drawings](https://x.com/ClementDelangue/status/1867318931502895358)\n\n### Chat\n\n- Qwen/Qwen2.5-72B-Instruct\n- prithivMLmods/Mistral-7B-Instruct-v0.3\n\n### Text-to-speech / Audio Generation\n\n- fantaxy/Sound-AI-SFX\n- parler-tts/parler_tts\n\n### Speech-to-text\n\n- hf-audio/whisper-large-v3-turbo\n- (the openai models use unnamed parameters so will not work)\n\n### Text-to-music\n\n- haoheliu/audioldm2-text2audio-text2music\n\n### Vision Tasks\n\n- microsoft/OmniParser\n- merve/paligemma2-vqav2\n- merve/paligemma-doc\n- DawnC/PawMatchAI\n- DawnC/PawMatchAI/on_find_match_click - for interactive dog recommendations\n\n## Other Features\n\n### Prompts\n\nPrompts for each Space are generated, and provide an opportunity to input. Bear in mind that often Spaces aren't configured with particularly helpful labels etc. Claude is actually very good at figuring this out, and the Tool description is quite rich (but not visible in Claude Desktop).\n\n### Resources\n\nA list of files in the WORK_DIR is returned, and as a convenience returns the name as \"Use the file...\" text. If you want to add something to Claude's context, use the paperclip - otherwise specify the filename for the MCP Server. Claude does not support transmitting resources from within Context.\n\n### Private Spaces\n\nPrivate Spaces are supported with a HuggingFace token. The Token is used to download and save generated content.\n\n### Using Claude Desktop\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-hfspace\": {\n      \"command\": \"npx\"\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\",\n        \"--work-dir=~/mcp-files/ or x:/temp/mcp-files/\",\n        \"--HF_TOKEN=HF_{optional token}\"\n        \"Qwen/Qwen2-72B-Instruct\",\n        \"black-forest-labs/FLUX.1-schnell\",\n        \"space/example/specific-endpint\"\n        (... and so on)\n        ]\n    }\n  }\n}\n```\n\n## Known Issues and Limitations\n\n### mcp-hfspace\n\n- Endpoints with unnamed parameters are unsupported for the moment.\n- Full translation from some complex Python types to suitable MCP formats.\n\n### Claude Desktop\n\n- Claude Desktop 0.75 doesn't seem to respond to errors from the MCP Server, timing out instead. For persistent issues, use the MCP Inspector to get a better look at diagnosing what's going wrong. If something suddenly stops working, it's probably due to exhausting your HuggingFace ZeroGPU quota - try again after a short period, or set up your own Space for hosting.\n- Claude Desktop seems to use a hard timeout value of 60s, and doesn't appear to use Progress Notifications to manage UX or keep-alive. If you are using ZeroGPU spaces, large/heavy jobs may timeout. Check the WORK_DIR for results though; the MCP Server will still capture and save the result if it was produced.\n- Claude Desktops reporting of Server Status, logging etc. isn't great - use [@modelcontextprotocol/inspector](https://github.com/modelcontextprotocol/inspector) to help diagnose issues.\n\n### HuggingFace Spaces\n\n- If ZeroGPU quotas or queues are too long, try duplicating the space. If your job takes less than sixty seconds, you can usually change the function decorator `@spaces.GPU(duration=20)` in `app.py` to request less quota when running the job.\n- Passing HF_TOKEN will make ZeroGPU quotas apply to your (Pro) HF account\n- If you have a private space, and dedicated hardware your HF_TOKEN will give you direct access to that - no quota's apply. I recommend this if you are using for any kind of Production task.\n\n## Third Party MCP Services\n\n<a href=\"https://glama.ai/mcp/servers/s57c80wvgq\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/s57c80wvgq/badge\" alt=\"mcp-hfspace MCP server\" /></a>\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "falahgs--flux-imagegen-mcp-server": {
      "owner": "falahgs",
      "name": "flux-imagegen-mcp-server",
      "url": "https://github.com/falahgs/flux-imagegen-mcp-server",
      "imageUrl": "https://github.com/falahgs.png",
      "description": "Generates and manipulates images using advanced AI models, offering functionalities such as image URL generation, direct image creation from text prompts, and management of multiple image generation models.",
      "stars": 3,
      "forks": 5,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-18T19:58:34Z",
      "readme_content": "# Flux ImageGen MCP Server\r\n\r\nA specialized Model Context Protocol (MCP) server for image generation and manipulation, powered by Pollinations AI.\r\n\r\n## Developer\r\n- **Author**: Falah.G.Salieh\r\n- **Copyright**: Â© 2025 All rights reserved\r\n\r\n## Overview\r\n\r\nImageGen MCP Server is a streamlined server implementation that provides powerful image generation capabilities through the Model Context Protocol (MCP). This server specializes in three core functionalities:\r\n\r\n1. Image URL Generation\r\n2. Direct Image Generation\r\n3. Model Listing and Management\r\n\r\n## Features\r\n\r\n- ğŸ–¼ï¸ **Image Generation**: Create stunning images from text prompts\r\n- ğŸ¨ **Multiple Models**: Support for various image generation models\r\n- ğŸ”§ **Flexible Configuration**: Easy to set up and customize\r\n- ğŸš€ **High Performance**: Optimized for quick response times\r\n- ğŸ”„ **MCP Compatible**: Fully compliant with Model Context Protocol\r\n\r\n## Installation\r\n\r\n```bash\r\n# Clone the repository\r\ngit clone https://github.com/yourusername/flux-imagegen-mcp-server.git\r\n\r\n# Install dependencies\r\nnpm install\r\n```\r\n\r\n## Configuration\r\n\r\n### Claude Desktop Configuration\r\n\r\nTo use this server with Claude Desktop, update your configuration file at:\r\n`C:\\Users\\[YourUsername]\\AppData\\Roaming\\Claude\\claude_desktop_config.json`\r\n\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"mcpollinations\": {\r\n      \"command\": \"cmd\",\r\n      \"args\": [\r\n        \"/c\",\r\n        \"node\",\r\n        \"PATH_TO_YOUR_SERVER\\\\server.js\"\r\n      ],\r\n      \"tools\": [\r\n        \"generateImageUrl\",\r\n        \"generateImage\",\r\n        \"listImageModels\"\r\n      ]\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nReplace `PATH_TO_YOUR_SERVER` with your actual server path.\r\n\r\n## Available Tools\r\n\r\n### 1. Generate Image URL (`generateImageUrl`)\r\nGenerates a URL for an image based on a text prompt.\r\n\r\n```javascript\r\n{\r\n  \"prompt\": \"A beautiful sunset over mountains\",\r\n  \"model\": \"flux\",  // optional, defaults to 'flux'\r\n  \"width\": 1024,    // optional\r\n  \"height\": 1024,   // optional\r\n  \"enhance\": true,  // optional\r\n  \"safe\": false     // optional\r\n}\r\n```\r\n\r\n### 2. Generate Image (`generateImage`)\r\nGenerates and saves an image directly from a text prompt.\r\n\r\n```javascript\r\n{\r\n  \"prompt\": \"A serene lake reflecting mountains\",\r\n  \"model\": \"flux\",\r\n  \"width\": 1024,\r\n  \"height\": 1024,\r\n  \"enhance\": true,\r\n  \"safe\": false,\r\n  \"outputPath\": \"./output\",\r\n  \"fileName\": \"mountain_lake\",\r\n  \"format\": \"png\"\r\n}\r\n```\r\n\r\n### 3. List Image Models (`listImageModels`)\r\nReturns a list of available image generation models.\r\n\r\n```javascript\r\n// Example response:\r\n{\r\n  \"models\": [\r\n    {\r\n      \"id\": \"flux\",\r\n      \"name\": \"Flux\",\r\n      \"description\": \"Default image generation model\"\r\n    },\r\n    // ... other models\r\n  ]\r\n}\r\n```\r\n## Running the Server\r\n\r\n```bash\r\n# Start the server\r\nnode server.js\r\n```\r\n\r\n## Environment Requirements\r\n\r\n- Node.js >= 16.0.0\r\n- NPM >= 7.0.0\r\n- Windows/Linux/MacOS compatible\r\n\r\n## Development\r\n\r\nTo contribute or modify the server:\r\n\r\n1. Fork the repository\r\n2. Create your feature branch\r\n3. Make your changes\r\n4. Submit a pull request\r\n\r\n## Error Handling\r\n\r\nThe server provides detailed error messages for common issues:\r\n\r\n```javascript\r\n{\r\n  \"error\": {\r\n    \"code\": \"ERROR_CODE\",\r\n    \"message\": \"Human-readable error message\",\r\n    \"details\": { /* Additional error details */ }\r\n  }\r\n}\r\n```\r\n\r\n## Examples\r\n\r\n### Basic Image Generation\r\n```javascript\r\n// Generate an image URL\r\nconst response = await generateImageUrl({\r\n  prompt: \"A futuristic city at night\",\r\n  model: \"flux\",\r\n  width: 1024,\r\n  height: 1024\r\n});\r\n\r\n// Generate and save an image\r\nconst image = await generateImage({\r\n  prompt: \"A peaceful garden with butterflies\",\r\n  outputPath: \"./images\",\r\n  fileName: \"garden_scene\"\r\n});\r\n```\r\n\r\n### Download Image Example\r\n```javascript\r\n// Download an image from URL\r\nconst downloadResult = await downloadImage({\r\n  imageUrl: \"https://example.com/image.jpg\",\r\n  fileName: \"downloaded-image\",\r\n  format: \"png\"\r\n});\r\n```\r\n\r\n## Support\r\n\r\nFor issues and feature requests, please create an issue in the repository or contact the developer:\r\n- Email: [Your contact email]\r\n- GitHub: [Your GitHub profile]\r\n\r\n## License\r\n\r\nThis project is licensed under the MIT License - see the LICENSE file for details.\r\n\r\n---\r\nMade with â¤ï¸ by Falah.G.Salieh\r\nÂ© 2025 All rights reserved\r\n\r\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "falahgs--imagen-3.0-generate-google-mcp-server": {
      "owner": "falahgs",
      "name": "imagen-3.0-generate-google-mcp-server",
      "url": "https://github.com/falahgs/imagen-3.0-generate-google-mcp-server",
      "imageUrl": "https://github.com/falahgs.png",
      "description": "Generates high-quality images using Google's Imagen 3.0 model via the Gemini API, manages image files with intelligent naming, and creates HTML previews for local viewing. Integrates seamlessly with MCP-compatible hosts for enhanced AI capabilities.",
      "stars": 3,
      "forks": 8,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-10T13:44:15Z",
      "readme_content": "# Gemini Imagen 3.0 MCP Server\r\n\r\n![License](https://img.shields.io/badge/license-MIT-blue.svg)\r\n![Node](https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen)\r\n![TypeScript](https://img.shields.io/badge/typescript-%5E5.3.3-blue)\r\n\r\nA professional Model Context Protocol (MCP) server implementation that harnesses Google's Imagen 3.0 model through the Gemini API for high-quality image generation. Built with TypeScript and designed for seamless integration with Claude Desktop and other MCP-compatible hosts.\r\n\r\n## ğŸŒŸ Features\r\n\r\n- Leverage Google's state-of-the-art Imagen 3.0 model via Gemini API\r\n- Generate up to 4 high-quality images per request\r\n- Automatic file management with intelligent naming\r\n- HTML preview generation with file:// protocol support\r\n- Built on MCP protocol for AI agent compatibility\r\n- TypeScript implementation with robust error handling\r\n\r\n## ğŸš€ Quick Start\r\n\r\n### Prerequisites\r\n\r\n- Node.js 18 or higher\r\n- Google Gemini API key\r\n- Claude Desktop or another MCP-compatible host\r\n\r\n### Installation\r\n\r\n1. Clone the repository:\r\n```bash\r\ngit clone https://github.com/yourusername/gemini-imagen-mcp-server.git\r\ncd gemini-imagen-mcp-server\r\n```\r\n\r\n2. Install dependencies:\r\n```bash\r\nnpm install\r\n```\r\n\r\n3. Build the TypeScript code:\r\n```bash\r\nnpm run build\r\n```\r\n\r\n## âš™ï¸ Configuration\r\n\r\n1. Configure Claude Desktop by adding to `claude_desktop_config.json`:\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"gemini-image-gen\": {\r\n      \"command\": \"node\",\r\n      \"args\": [\"./build/index.js\"],\r\n      \"cwd\": \"<path-to-project-directory>\",\r\n      \"env\": {\r\n        \"GEMINI_API_KEY\": \"your-gemini-api-key\"\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n2. Replace placeholders:\r\n   - `<path-to-project-directory>`: Your project path\r\n   - `your-gemini-api-key`: Your Gemini API key\r\n\r\n## ğŸ› ï¸ Available Tools\r\n\r\n### 1. generate_images\r\nGenerates images using Google's Imagen 3.0 model.\r\n\r\nParameters:\r\n- `prompt` (required): Text description of the image to generate\r\n- `numberOfImages` (optional): Number of images (1-4, default: 1)\r\n\r\nFile Management:\r\n- Images are automatically saved in `G:\\image-gen3-google-mcp-server\\images`\r\n- Filenames follow the pattern: `{sanitized-prompt}-{timestamp}-{index}.png`\r\n- Timestamps ensure unique filenames\r\n- Prompts are sanitized for safe filesystem usage\r\n\r\nExample:\r\n```\r\nGenerate an image of a futuristic city at night\r\n```\r\n\r\n### 2. create_image_html\r\nCreates HTML preview tags for generated images.\r\n\r\nParameters:\r\n- `imagePaths` (required): Array of image file paths\r\n- `width` (optional): Image width in pixels (default: 512)\r\n- `height` (optional): Image height in pixels (default: 512)\r\n\r\nReturns HTML tags with absolute file:// URLs for local viewing.\r\n\r\nExample:\r\n```\r\nCreate HTML tags for the generated images with width=400\r\n```\r\n\r\n## ğŸ”§ Development\r\n\r\n```bash\r\n# Install dependencies\r\nnpm install\r\n\r\n# Build TypeScript\r\nnpm run build\r\n\r\n# Run tests (when available)\r\nnpm test\r\n```\r\n\r\n## ğŸ¤ Contributing\r\n\r\nContributions are welcome! Please feel free to submit a Pull Request. For major changes:\r\n\r\n1. Fork the repository\r\n2. Create your feature branch (`git checkout -b feature/AmazingFeature`)\r\n3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)\r\n4. Push to the branch (`git push origin feature/AmazingFeature`)\r\n5. Open a Pull Request\r\n\r\n## ğŸ“ Error Handling\r\n\r\nThe server implements two main error codes:\r\n- `tool_not_found` (1): When the requested tool is not available\r\n- `execution_error` (2): When image generation or HTML creation fails\r\n\r\n## ğŸ“„ License\r\n\r\nMIT License - see the [LICENSE](LICENSE) file for details.\r\n\r\n## âœ¨ Author\r\n\r\n**Falah G. Salieh**\r\n- Copyright Â© 2025\r\n- GitHub: [@yourgithubhandle](https://github.com/yourgithubhandle)\r\n- Email: [your.email@example.com](mailto:your.email@example.com)\r\n\r\n## ğŸ™ Acknowledgments\r\n\r\n- Google Gemini API and Imagen 3.0 model\r\n- Model Context Protocol (MCP) by Anthropic\r\n- Claude Desktop team for MCP host implementation\r\n\r\n## ğŸ“Œ Tags\r\n\r\n`#MCP` `#Gemini` `#Imagen3` `#AI` `#ImageGeneration` `#TypeScript` `#NodeJS` `#GoogleAI` `#ClaudeDesktop`\r\n\r\n---\r\nMade with â¤ï¸ by Falah G. Salieh ",
      "npm_url": "",
      "npm_downloads": 0
    },
    "falahgs--mcp-3d-style-cartoon-gen-server": {
      "owner": "falahgs",
      "name": "mcp-3d-style-cartoon-gen-server",
      "url": "https://github.com/falahgs/mcp-3d-style-cartoon-gen-server",
      "imageUrl": "https://github.com/falahgs.png",
      "description": "Generates high-quality 3D-style cartoon images from text prompts using Google's Gemini AI, with child-friendly designs for engaging visuals. Offers secure file system operations for managing files, including reading and writing capabilities.",
      "stars": 3,
      "forks": 2,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-11T21:40:56Z",
      "readme_content": "# MCP Combined Server: 3D Cartoon Generator & File System Tools\n\nA professional-grade server that provides two major capabilities: \n1. High-quality 3D-style cartoon image generation using Google's Gemini AI\n2. Secure file system operations for reading, writing, and managing files\n\n![3D Cartoon Generator Demo](./video/mcp-3d-style-server.gif)\n\n## ğŸŒŸ Features\n\n### Image Generation\n- **3D Cartoon Generation**: Creates high-quality 3D-style cartoon images\n- **Child-Friendly Design**: Focuses on colorful, playful, and engaging visuals\n- **Instant Preview**: Automatically opens generated images in your default browser\n- **Local Storage**: Saves images and previews in an organized output directory\n\n### File System Operations\n- **Secure File Access**: Path validation and security checks\n- **Read/Write Files**: Read and write text file contents\n- **Directory Operations**: List, create, and navigate directories\n- **File Search**: Find files matching patterns\n\n### System Features\n- **Professional Configuration**: Robust error handling and controlled logging\n- **Cross-Platform Support**: Intelligent file path handling for Windows, macOS, and Linux\n- **Smart OS Detection**: Automatically finds the best save location for each operating system\n- **Security Controls**: Restricted directory access through configuration\n\n## ğŸ› ï¸ Technical Stack\n\n- **Core Framework**: Model Context Protocol (MCP) SDK\n- **AI Integration**: Google Generative AI (Gemini)\n- **Runtime**: Node.js v14+\n- **Language**: TypeScript\n- **Package Manager**: npm\n\n## ğŸ“‹ Prerequisites\n\n- Node.js (v14 or higher)\n- Google Gemini API key\n- TypeScript\n\n## âš™ï¸ Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/falahgs/mcp-3d-style-cartoon-gen-server.git\ncd mcp-3d-style-cartoon-gen-server\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Configure environment:\nCreate a `.env` file in the root directory:\n```env\nGEMINI_API_KEY=your_api_key_here\nALLOWED_DIRECTORIES=/path/to/allowed/dir1,/path/to/allowed/dir2\n```\n\n4. Build the project:\n```bash\nnpm run build\n```\n\n## ğŸ”§ Configuring Claude Desktop with MCP Server\n\nTo integrate this combined server with Claude Desktop:\n\n1. Locate the Configuration File:\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Linux: `~/.config/Claude/claude_desktop_config.json`\n\n2. Add the following configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-3d-cartoon-generator\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"path/to/your/build/index.js\"\n      ],\n      \"env\": {\n        \"GEMINI_API_KEY\": \"your_gemini_api_key_here\",\n        \"IS_REMOTE\": \"true\",\n        \"SAVE_TO_DESKTOP\": \"true\",\n        \"DETECT_OS_PATHS\": \"true\",\n        \"ALLOWED_DIRECTORIES\": \"C:\\\\Users\\\\YourUsername\\\\Desktop,C:\\\\Users\\\\YourUsername\\\\Documents\",\n        \"DEBUG\": \"false\"\n      }\n    }\n  }\n}\n```\n\n### Windows PowerShell Helper Script\n\nFor Windows users, you can use the included `fix_claude_config.ps1` script to automatically configure Claude Desktop:\n\n1. Edit the script to update the path to your server build and your Gemini API key\n2. Run the script in PowerShell:\n```powershell\npowershell -ExecutionPolicy Bypass -File .\\fix_claude_config.ps1\n```\n\nThis will create or update the configuration file with proper encoding and settings.\n\n## ğŸš€ Available Tools\n\n### 1. Image Generation Tool\n\n```json\n{\n  \"name\": \"generate_3d_cartoon\",\n  \"description\": \"Generates a 3D style cartoon image for kids based on the given prompt\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"prompt\": {\n        \"type\": \"string\",\n        \"description\": \"The prompt describing the 3D cartoon image to generate\"\n      },\n      \"fileName\": {\n        \"type\": \"string\",\n        \"description\": \"The name of the output file (without extension)\"\n      }\n    },\n    \"required\": [\"prompt\", \"fileName\"]\n  }\n}\n```\n\n### 2. File System Tools\n\n#### Read File\n```json\n{\n  \"name\": \"read_file\",\n  \"description\": \"Read the contents of a file\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"path\": {\n        \"type\": \"string\",\n        \"description\": \"Path to the file to read\"\n      }\n    },\n    \"required\": [\"path\"]\n  }\n}\n```\n\n#### Write File\n```json\n{\n  \"name\": \"write_file\",\n  \"description\": \"Write content to a file\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"path\": {\n        \"type\": \"string\",\n        \"description\": \"Path to the file to write\"\n      },\n      \"content\": {\n        \"type\": \"string\",\n        \"description\": \"Content to write to the file\"\n      }\n    },\n    \"required\": [\"path\", \"content\"]\n  }\n}\n```\n\n#### List Directory\n```json\n{\n  \"name\": \"list_directory\",\n  \"description\": \"List the contents of a directory\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"path\": {\n        \"type\": \"string\",\n        \"description\": \"Path to the directory to list\"\n      }\n    },\n    \"required\": [\"path\"]\n  }\n}\n```\n\n#### Create Directory\n```json\n{\n  \"name\": \"create_directory\",\n  \"description\": \"Create a new directory\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"path\": {\n        \"type\": \"string\",\n        \"description\": \"Path to the directory to create\"\n      }\n    },\n    \"required\": [\"path\"]\n  }\n}\n```\n\n#### Search Files\n```json\n{\n  \"name\": \"search_files\",\n  \"description\": \"Search for files matching a pattern\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"path\": {\n        \"type\": \"string\",\n        \"description\": \"Base directory to search from\"\n      },\n      \"pattern\": {\n        \"type\": \"string\",\n        \"description\": \"Search pattern (glob format)\"\n      },\n      \"excludePatterns\": {\n        \"type\": \"array\",\n        \"items\": {\n          \"type\": \"string\"\n        },\n        \"description\": \"Patterns to exclude from search (glob format)\"\n      }\n    },\n    \"required\": [\"path\", \"pattern\"]\n  }\n}\n```\n\n## ğŸ“„ Example Usage\n\n### Image Generation Examples\n\n```javascript\n// Generate a 3D cartoon\n{\n  \"name\": \"generate_3d_cartoon\",\n  \"arguments\": {\n    \"prompt\": \"A friendly robot playing with a cat\",\n    \"fileName\": \"robot_cat_play\"\n  }\n}\n```\n\n### File System Examples\n\n```javascript\n// Read a file\n{\n  \"name\": \"read_file\",\n  \"arguments\": {\n    \"path\": \"C:/Users/YourUsername/Documents/example.txt\"\n  }\n}\n\n// Write a file\n{\n  \"name\": \"write_file\",\n  \"arguments\": {\n    \"path\": \"C:/Users/YourUsername/Documents/new-file.txt\",\n    \"content\": \"This is the content of the file.\"\n  }\n}\n\n// List directory contents\n{\n  \"name\": \"list_directory\",\n  \"arguments\": {\n    \"path\": \"C:/Users/YourUsername/Documents\"\n  }\n}\n\n// Create a directory\n{\n  \"name\": \"create_directory\",\n  \"arguments\": {\n    \"path\": \"C:/Users/YourUsername/Documents/new-folder\"\n  }\n}\n\n// Search for files\n{\n  \"name\": \"search_files\",\n  \"arguments\": {\n    \"path\": \"C:/Users/YourUsername/Documents\",\n    \"pattern\": \"*.txt\",\n    \"excludePatterns\": [\"temp*\", \"*.tmp\"]\n  }\n}\n```\n\n## ğŸ”’ Security Features\n\nThe server implements several security measures:\n\n1. **Path Validation**: All file paths are validated to ensure they are within allowed directories.\n2. **Allowed Directories**: Only directories explicitly set in the `ALLOWED_DIRECTORIES` environment variable can be accessed.\n3. **Symlink Protection**: Prevents access to directories outside the allowed scope via symlinks.\n4. **Controlled Logging**: Debug logs are disabled by default to prevent information leakage.\n\n## âš™ï¸ Configuration Options\n\n### Environment Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| `GEMINI_API_KEY` | Google Gemini API key for image generation | (Required) |\n| `ALLOWED_DIRECTORIES` | Comma-separated list of allowed file system paths | User's home dir, current dir |\n| `IS_REMOTE` | Run in remote mode without browser opening | false |\n| `SAVE_TO_DESKTOP` | Force saving to desktop directory | false |\n| `DETECT_OS_PATHS` | Enable OS-specific path detection | true |\n| `DEBUG` | Enable verbose debug logging | false |\n\n## ğŸ› ï¸ Troubleshooting\n\n### Common Issues:\n\n1. **JSON Parsing Errors in Claude**:\n   - Ensure `DEBUG` is set to \"false\" to prevent logs from interfering with JSON communication\n   - Check for proper JSON formatting in the Claude configuration\n\n2. **File Access Denied**:\n   - Verify that the paths you're trying to access are included in `ALLOWED_DIRECTORIES`\n   - Check file permissions on the target files/directories\n\n3. **Images Not Saving**:\n   - Set `SAVE_TO_DESKTOP` to \"true\" to ensure images save to the desktop\n   - Check desktop path detection in the server logs (enable DEBUG temporarily)\n\n## ğŸ“„ License\n\n[MIT License](LICENSE)\n\n## ğŸ¤ Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request. ",
      "npm_url": "",
      "npm_downloads": 0
    },
    "falahgs--MCP-Storybook-Image-Generator": {
      "owner": "falahgs",
      "name": "MCP-Storybook-Image-Generator",
      "url": "https://github.com/falahgs/MCP-Storybook-Image-Generator",
      "imageUrl": "https://github.com/falahgs.png",
      "description": "Generates high-quality storybook images and matching children's stories using Google's Gemini AI, offering multiple art styles such as 3D cartoon, watercolor, and pixel art. It allows instant previewing of creations and saves them locally in an organized manner.",
      "stars": 3,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-12T03:16:03Z",
      "readme_content": "# MCP Storybook Image Generator\n\nA professional-grade server that generates beautiful storybook images with matching children's stories using Google's Gemini AI.\n\n## ğŸ¬ Demo\n\n![Storybook Generator Demo](video/1.gif)\n\n## ğŸŒŸ Features\n\n- **Storybook Image Generation**: Creates high-quality images in various art styles for children's stories\n- **Automatic Story Creation**: Generates engaging children's stories to match the images\n- **Multiple Art Styles**: Choose from 3D cartoon, watercolor, pixel art, hand drawn, or claymation styles\n- **Instant Preview**: Automatically opens generated images and stories in your browser\n- **Local Storage**: Saves images and stories in an organized output directory\n\n## ğŸ› ï¸ Technical Stack\n\n- **Core Framework**: Model Context Protocol (MCP) SDK\n- **AI Integration**: Google Generative AI (Gemini)\n- **Runtime**: Node.js v14+\n- **Language**: TypeScript\n- **Package Manager**: npm\n\n## ğŸ“‹ Prerequisites\n\n- Node.js (v14 or higher)\n- Google Gemini API key\n- TypeScript\n\n## âš™ï¸ Installation\n\n1. Install dependencies:\n```bash\nnpm install\n```\n\n3. Configure environment:\nCreate a `.env` file in the root directory:\n```env\nGEMINI_API_KEY=your_api_key_here\n```\n\n4. Build the project:\n```bash\nnpm run build\n```\n\n## ğŸš€ Using the CLI\n\nYou can use the storybook generator directly from the command line:\n\n```bash\n# Using npx (after publishing to npm)\nnpx mcp-storybook-image-generator --api-key your_api_key_here --save-to-desktop\n\n# Or run locally\nnode build/cli.js --api-key your_api_key_here --save-to-desktop\n```\n\n### Command Line Options\n\n| Option | Description |\n|--------|-------------|\n| `--api-key <key>` | Set your Gemini API key |\n| `--save-to-desktop` | Save generated files to desktop |\n| `--debug` | Enable debug logging |\n| `--help` | Show help information |\n\n## ğŸ”§ Configuring Claude Desktop with MCP Server\n\nTo integrate this server with Claude Desktop:\n\n1. Locate the Claude Desktop Configuration File:\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Linux: `~/.config/Claude/claude_desktop_config.json`\n\n2. Add the following configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"storybook-generator\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-storybook-image-generator@latest\",\n        \"--api-key\",\n        \"your_gemini_api_key_here\"\n      ],\n      \"env\": {\n        \"SAVE_TO_DESKTOP\": \"true\",\n        \"DEBUG\": \"false\"\n      }\n    }\n  }\n}\n```\n\n## ğŸš€ Available Tool\n\n### Storybook Image Generator Tool\n\n```json\n{\n  \"name\": \"generate_storybook_image\",\n  \"description\": \"Generates a 3D style cartoon image with a children's story based on the given prompt\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"prompt\": {\n        \"type\": \"string\",\n        \"description\": \"The prompt describing the storybook scene to generate\"\n      },\n      \"fileName\": {\n        \"type\": \"string\",\n        \"description\": \"Base name for the output files (without extension)\"\n      },\n      \"artStyle\": {\n        \"type\": \"string\",\n        \"description\": \"The art style for the image (default: '3d cartoon')\",\n        \"enum\": [\"3d cartoon\", \"watercolor\", \"pixel art\", \"hand drawn\", \"claymation\"]\n      }\n    },\n    \"required\": [\"prompt\", \"fileName\"]\n  }\n}\n```\n\n## ğŸ“„ Example Usage\n\n### Storybook Generation Examples\n\n```javascript\n// Generate a storybook with a 3D cartoon style\n{\n  \"name\": \"generate_storybook_image\",\n  \"arguments\": {\n    \"prompt\": \"A friendly dragon teaching kids how to fly\",\n    \"fileName\": \"dragon_flight_lesson\",\n    \"artStyle\": \"3d cartoon\"\n  }\n}\n\n// Generate a storybook with a watercolor style\n{\n  \"name\": \"generate_storybook_image\",\n  \"arguments\": {\n    \"prompt\": \"A rabbit and turtle having a tea party in the forest\",\n    \"fileName\": \"forest_tea_party\",\n    \"artStyle\": \"watercolor\"\n  }\n}\n\n// Generate a storybook with pixel art style\n{\n  \"name\": \"generate_storybook_image\",\n  \"arguments\": {\n    \"prompt\": \"A space adventure with a kid astronaut meeting friendly aliens\",\n    \"fileName\": \"space_adventure\",\n    \"artStyle\": \"pixel art\"\n  }\n}\n```\n\n## âš™ï¸ Configuration Options\n\n### Environment Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| `GEMINI_API_KEY` | Google Gemini API key for AI generation | (Required) |\n| `SAVE_TO_DESKTOP` | Force saving to desktop directory | false |\n| `DEBUG` | Enable verbose debug logging | false |\n\n## ğŸ“ Output Files\n\nFor each storybook generation request, the server produces:\n\n1. **PNG Image**: The generated illustration matching your prompt in the requested art style\n2. **Text File**: The matching children's story in plain text format\n3. **HTML Preview**: A combined view showing both the image and story together\n\nThese files are saved to either:\n- Your desktop in a folder called \"storybook-images\" (if `SAVE_TO_DESKTOP=true`)\n- The server's directory in a folder called \"storybook-images\"\n\n## ğŸ¤ Contributing\n\nContributions, issues, and feature requests are welcome! Feel free to check issues page.\n\n## ğŸ“„ License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "felores--placid-mcp-server": {
      "owner": "felores",
      "name": "placid-mcp-server",
      "url": "https://github.com/felores/placid-mcp-server",
      "imageUrl": "https://github.com/felores.png",
      "description": "Integrates with Placid.app to list available templates and generate images and videos using dynamic content. Provides secure API token management and robust error handling.",
      "stars": 14,
      "forks": 7,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-02T13:59:52Z",
      "readme_content": "# Placid.app MCP Server\n[![smithery badge](https://smithery.ai/badge/@felores/placid-mcp-server)](https://smithery.ai/server/@felores/placid-mcp-server)\n\nAn MCP server implementation for integrating with Placid.app's API. This server provides tools for listing templates and generating images and videos through the Model Context Protocol.\n\n<a href=\"https://glama.ai/mcp/servers/xeklsydon0\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/xeklsydon0/badge\" />\n</a>\n\n## Features\n\n- List available Placid templates with filtering options\n- Generate images and videos using templates and dynamic content\n- Secure API token management\n- Error handling and validation\n- Type-safe implementation\n\n## Requirements: Node.js\n\n1. Install Node.js (version 18 or higher) and npm from [nodejs.org](https://nodejs.org/)\n2. Verify installation:\n   ```bash\n   node --version\n   npm --version\n   ```\n\n## Installation\n\n### Quick Start (Recommended)\n\nThe easiest way to get started is using Smithery, which will automatically configure everything for you:\n\n```bash\nnpx -y @smithery/cli install @felores/placid-mcp-server --client claude\n```\n\n### Manual Configuration\n\nIf you prefer to configure manually, add this to your Claude Desktop or Cline settings:\n\n```json\n{\n  \"mcpServers\": {\n    \"placid\": {\n      \"command\": \"npx\",\n      \"args\": [\"@felores/placid-mcp-server\"],\n      \"env\": {\n        \"PLACID_API_TOKEN\": \"your-api-token\"\n      }\n    }\n  }\n}\n```\n\n## Getting Your Placid API Token\n\n1. Log in to your [Placid.app](https://placid.app/) account\n2. Go to Settings > API\n3. Click on \"Create API Token\"\n4. Give your token a name (e.g., \"MCP Server\")\n5. Copy the generated token\n6. Add the token to your configuration as shown above\n\n## Development\n\n```bash\n# Run in development mode with hot reload\nnpm run dev\n\n# Run tests\nnpm test\n```\n\n## Tools\n\n### placid_list_templates\nLists available Placid templates with filtering options. Each template includes its title, ID, preview image URL, available layers, and tags.\n\n#### Parameters\n- `collection_id` (optional): Filter templates by collection ID\n- `custom_data` (optional): Filter by custom reference data\n- `tags` (optional): Array of tags to filter templates by\n\n#### Response\nReturns an array of templates, each containing:\n- `uuid`: Unique identifier for the template\n- `title`: Template name\n- `thumbnail`: Preview image URL (if available)\n- `layers`: Array of available layers with their names and types\n- `tags`: Array of template tags\n\n### placid_generate_video\nGenerate videos by combining Placid templates with dynamic content like videos, images, and text. For longer videos (>60 seconds processing time), you'll receive a job ID to check status in your Placid dashboard.\n\n#### Parameters\n- `template_id` (required): UUID of the template to use\n- `layers` (required): Object containing dynamic content for template layers\n  - For video layers: `{ \"layerName\": { \"video\": \"https://video-url.com\" } }`\n  - For image layers: `{ \"layerName\": { \"image\": \"https://image-url.com\" } }`\n  - For text layers: `{ \"layerName\": { \"text\": \"Your content\" } }`\n- `audio` (optional): URL to an mp3 audio file\n- `audio_duration` (optional): Set to 'auto' to trim audio to video length\n- `audio_trim_start` (optional): Timestamp of trim start point (e.g. '00:00:45' or '00:00:45.25')\n- `audio_trim_end` (optional): Timestamp of trim end point (e.g. '00:00:55' or '00:00:55.25')\n\n#### Response\nReturns an object containing:\n- `status`: Current status (\"finished\", \"queued\", or \"error\")\n- `video_url`: URL to download the generated video (when status is \"finished\")\n- `job_id`: ID for checking status in Placid dashboard (for longer videos)\n\n#### Example Usage for LLM models\n```json\n{\n  \"template_id\": \"template-uuid\",\n  \"layers\": {\n    \"MEDIA\": { \"video\": \"https://example.com/video.mp4\" },\n    \"PHOTO\": { \"image\": \"https://example.com/photo.jpg\" },\n    \"LOGO\": { \"image\": \"https://example.com/logo.png\" },\n    \"HEADLINE\": { \"text\": \"My Video Title\" }\n  },\n  \"audio\": \"https://example.com/background.mp3\",\n  \"audio_duration\": \"auto\"\n}\n```\n\n### placid_generate_image\nGenerate static images by combining Placid templates with dynamic content like text and images.\n\n#### Parameters\n- `template_id` (required): UUID of the template to use\n- `layers` (required): Object containing dynamic content for template layers\n  - For text layers: `{ \"layerName\": { \"text\": \"Your content\" } }`\n  - For image layers: `{ \"layerName\": { \"image\": \"https://image-url.com\" } }`\n\n#### Response\nReturns an object containing:\n- `status`: \"finished\" when complete\n- `image_url`: URL to download the generated image\n\n#### Example Usage for LLM models\n```json\n{\n  \"template_id\": \"template-uuid\",\n  \"layers\": {\n    \"headline\": { \"text\": \"Welcome to My App\" },\n    \"background\": { \"image\": \"https://example.com/bg.jpg\" }\n  }\n}\n```\n\n## Documentation\n\nFor more detailed information about the Placid API, visit the [Placid API Documentation](https://placid.app/docs/api/).\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "fengin--image-gen-server": {
      "owner": "fengin",
      "name": "image-gen-server",
      "url": "https://github.com/fengin/image-gen-server",
      "imageUrl": "https://github.com/fengin.png",
      "description": "Generate images from text descriptions and save them, seamlessly integrated with Cursor IDE. Users can create multiple image outputs simultaneously and specify custom save paths.",
      "stars": 205,
      "forks": 25,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-28T14:14:49Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/fengin-image-gen-server-badge.png)](https://mseep.ai/app/fengin-image-gen-server)\n\n# Image-Gen-Server\n\n<div align=\"center\">\n  <img src=\"images/logo_0.png\" alt=\"Image-Gen-Server Logo\" width=\"100%\">\n</div>\n\n[![smithery badge](https://smithery.ai/badge/@fengin/image-gen-server)](https://smithery.ai/server/@fengin/image-gen-server)\n\nåŸºäºå³æ¢¦AIçš„å›¾åƒç”ŸæˆæœåŠ¡ï¼Œä¸“é—¨è®¾è®¡ç”¨äºä¸Cursor IDEé›†æˆã€‚å®ƒæ¥æ”¶æ¥è‡ªCursorçš„æ–‡æœ¬æè¿°ï¼Œç”Ÿæˆç›¸åº”çš„å›¾åƒï¼Œå¹¶æä¾›å›¾ç‰‡ä¸‹è½½å’Œä¿å­˜åŠŸèƒ½ã€‚\n\næ­¤æ’ä»¶çš„å¼€å‘è¿‡ç¨‹å¯ä»¥çœ‹æˆ‘çš„ç½‘ç«™ï¼š[å¼€å‘ä¸€ä¸ªMCP Serverä¸Cursoré›†æˆï¼Œç»™Cursoræ’ä¸Šç¿…è†€ï¼](https://aibook.ren/archives/mcp-server-for-cursor)\n\næ›´å¤šAIçŸ¥è¯†ï¼Œè§AIå…¨ä¹¦(https://aibook.ren)\n\n<div align=\"center\">\n  <img src=\"images/example.png\" alt=\"Image-Gen-Server Logo\" width=\"100%\">\n</div>\n\n## ç‰¹æ€§\n\n- ä¸Cursor IDEå®Œç¾é›†æˆ\n- æ”¯æŒæ–‡æœ¬åˆ°å›¾åƒçš„ç”Ÿæˆ\n- è‡ªåŠ¨ä¿å­˜ç”Ÿæˆçš„å›¾åƒ\n- æ”¯æŒè‡ªå®šä¹‰ä¿å­˜è·¯å¾„\n- ä¸€æ¬¡ç”Ÿæˆå››å¼ å›¾ï¼Œä¾›æ›´å¤šé€‰æ‹©\n\n## å®‰è£…\n\n### Installing via Smithery\n\nTo install Image-Gen-Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@fengin/image-gen-server):\n\n```bash\nnpx -y @smithery/cli install @fengin/image-gen-server --client claude\n```\n\n1. ç¯å¢ƒå‡†å¤‡ï¼ŒMCPæ¯”è¾ƒæ–°çš„ä¸œè¥¿ï¼Œä¾èµ–ç¯å¢ƒç‰ˆæœ¬éƒ½æ¯”è¾ƒæ–°\n- python 3.10+\n\n- å®‰è£…npm\n\n- å®‰è£…nodejsï¼ˆå®æµ‹v15 v16éƒ½ä¸è¡Œï¼Œå¼€å‘ç¯å¢ƒéªŒè¯v20å¯ä»¥ï¼Œå…¶ä»–æœªéªŒè¯ï¼‰\n\n- å®‰è£… pip install uv\n\n- å¦‚æœè¦è°ƒè¯•ï¼Œè¿˜éœ€è¦å®‰è£…è¿™ä¸ªï¼šnpm install -g @modelcontextprotocol/inspector@0.4.0\n2. å…‹éš†é¡¹ç›®\n   \n   ```bash\n   git clone https://github.com/fengin/image-gen-server.git\n   cd image-gen-server\n   ```\n\n3. å®‰è£…ä¾èµ–\n   \n   ```bash\n   pip install -r requirements.txt\n   pip install uv\n   ```\n\n4. è®¾ç½®å³æ¢¦Tokenå’Œå›¾ç‰‡é»˜è®¤ä¿å­˜åœ°å€\n   ä¿®æ”¹server.pyæ–‡ä»¶é‡Œé¢è¿™ä¸¤ä¸ªé…ç½®\n   \n   ```bash\n   # APIé…ç½®\n   JIMENG_API_TOKEN = \"057f7addf85dxxxxxxxxxxxxx\" # ä½ ç™»å½•å³æ¢¦è·å¾—çš„session_idï¼Œæ”¯æŒå¤šä¸ªï¼Œåœ¨åé¢ç”¨é€—å·åˆ†éš”   \n   IMG_SAVA_FOLDER = \"D:/code/image-gen-server/images\" # å›¾ç‰‡é»˜è®¤ä¿å­˜è·¯å¾„\n   ```\n\nÂ Â Â Â \n\n## Cursoré›†æˆ\n\n<div align=\"center\">\n  <img src=\"images/cursor_config.png\" alt=\"Image-Gen-Server Logo\" width=\"100%\">\n</div>\n\n1. æ‰“å¼€Cursorè®¾ç½®\n   \n   - ç‚¹å‡»å·¦ä¸‹è§’çš„è®¾ç½®å›¾æ ‡\n   - é€‰æ‹© Features > MCP Servers\n   - ç‚¹å‡» \"Add new MCP server\"\n\n2. å¡«å†™æœåŠ¡å™¨é…ç½®\n   \n   - Name: `image-gen-server`ï¼ˆæˆ–å…¶ä»–ä½ å–œæ¬¢çš„åç§°ï¼‰\n   \n   - Type: `command`\n   \n   - Command: \n     \n     ```bash\n     uv run --with fastmcp fastmcp run D:\\code\\image-gen-service\\server.py\n     ```\n     \n     æ³¨æ„ï¼šå°†è·¯å¾„æ›¿æ¢ä¸ºä½ çš„å®é™…é¡¹ç›®è·¯å¾„\n     \n     - Windowsç¤ºä¾‹: ` uv run --with fastmcp fastmcp run D:/code/image-gen-service/server.py`\n     - macOS/Linuxç¤ºä¾‹: ` uv run --with fastmcp fastmcp run /Users/username/code/image-gen-server/server.py`\n     \n     windowsè·¯å¾„é—®é¢˜æ¯”è¾ƒå¤šï¼ŒD:/code/image-gen-server/server.py å„ç§æ–œæ éƒ½è¯•ä¸‹\n     \n     å¡«å†™å®Œåï¼Œä¼šå¼¹å‡ºä¸€ä¸ªé»‘çª—å£ï¼Œç„¶åä½ å°±å¯ä»¥å«Cursorç»™ä½ ç”Ÿæˆéœ€è¦çš„å›¾ç‰‡äº†ï¼Œç›®å‰é»‘çª—å£ä¼šä¸€ç›´è¿è¡Œï¼Œç›®å‰è¿˜æ²¡åŠæ³•è§£å†³å¼¹å‡ºè¿™ä¸ªçš„é—®é¢˜\n\n## ä½¿ç”¨æ–¹æ³•\n\nåœ¨Cursorä¸­ï¼Œä½ è¦è®©cursorç”Ÿæˆå›¾ç‰‡ï¼Œåœ¨agentæ¨¡å¼ä¸‹ï¼Œä½ æç¤ºå®ƒäº†è§£ä¸‹å›¾ç‰‡å·¥å…·ä½¿ç”¨æ–¹æ³•ï¼Œç„¶åç›´æ¥æä½ è¦ç”Ÿæˆçš„å›¾ç‰‡è¦æ±‚ï¼Œä¿å­˜ä½ç½®å°±è¡Œäº†\n\n## è·å–å³æ¢¦Token\n\n1. è®¿é—® [å³æ¢¦](https://jimeng.jianying.com/)\n2. ç™»å½•è´¦å·\n3. æŒ‰F12æ‰“å¼€å¼€å‘è€…å·¥å…·\n4. åœ¨Application > Cookiesä¸­æ‰¾åˆ°`sessionid`\n5. å°†æ‰¾åˆ°çš„sessionidè®¾ç½®åˆ°server.pyçš„JIMENG_API_TOKENä¸­\n\n## å·¥å…·å‡½æ•°è¯´æ˜\n\n### generate_image\n\n```python\nasync def generate_image(prompt: str, file_name: str, save_folder: str = None, sample_strength: float = 0.5, width: int = 1024, height: int = 1024) -> list[types.TextContent | types.ImageContent | types.EmbeddedResource]:\n    \"\"\"æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆå›¾ç‰‡\n\n    Args:\n        prompt: å›¾ç‰‡çš„æ–‡æœ¬promptæè¿°\n        file_name: ç”Ÿæˆå›¾ç‰‡çš„æ–‡ä»¶å(ä¸å«è·¯å¾„ï¼Œå¦‚æœæ²¡æœ‰åç¼€åˆ™é»˜è®¤ä½¿ç”¨.jpg)\n        save_folder: å›¾ç‰‡ä¿å­˜ç»å¯¹åœ°å€ç›®å½•(å¯é€‰,é»˜è®¤ä½¿ç”¨IMG_SAVA_FOLDER)\n        sample_strength: ç”Ÿæˆå›¾ç‰‡çš„ç²¾ç»†åº¦(å¯é€‰,èŒƒå›´0-1,é»˜è®¤0.5)\n        width: ç”Ÿæˆå›¾ç‰‡çš„å®½åº¦(å¯é€‰,é»˜è®¤1024)\n        height: ç”Ÿæˆå›¾ç‰‡çš„é«˜åº¦(å¯é€‰,é»˜è®¤1024)\n\n    Returns:\n        List: åŒ…å«ç”Ÿæˆç»“æœçš„JSONå­—ç¬¦ä¸²\n    \"\"\"\n```\n\n### æŠ€æœ¯å®ç°\n\n1. server.pyé‡‡ç”¨äº†fastmcpå®ç°äº†mcp severçš„èƒ½åŠ›ï¼Œæä¾›ç»™cursor/claudeä½¿ç”¨\n\n   2.sever.pyè°ƒç”¨äº†proxy.jimengæ¨¡å—é€†å‘ä¸å³æ¢¦AIè¿›è¡Œäº¤äº’ã€‚\nproxy.jimengé€†å‘æ¨¡å—ä¹Ÿå¯ä»¥å•ç‹¬installä½¿ç”¨ï¼Œä¸»è¦æä¾›äº†ä»¥ä¸‹ä¸»è¦åŠŸèƒ½ï¼š\n\n- å›¾åƒç”Ÿæˆï¼ˆgenerate_imagesï¼‰\n- åŒæ­¥å¯¹è¯è¡¥å…¨ï¼ˆcreate_completionï¼‰\n- æµå¼å¯¹è¯è¡¥å…¨ï¼ˆcreate_completion_streamï¼‰\n- å¤šè´¦å·tokenæ”¯æŒ\n- å®Œæ•´çš„é”™è¯¯å¤„ç†\n\næ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒ`proxy/jimeng/README.md`ã€‚\n\n### ä½¿ç”¨ç¤ºä¾‹\n\n```cmd\n# cursor agentæ¨¡å¼ä¸‹\n#ä¾‹å­ä¸€\næ ¹æ®æä¾›è¿‡ä½ çš„é¡¹ç›®éœ€æ±‚ï¼Œå¸®æˆ‘ç”Ÿæˆä¸€å¼ äº§å“logoï¼Œæ”¾åœ¨é¡¹ç›®ç›®å½•imagesä¸‹é¢\n\n#ä¾‹å­äºŒ\næ ¹æ®é¡¹ç›®éœ€æ±‚ï¼Œå¸®æˆ‘åˆ¶ä½œç½‘ç«™çš„é¦–é¡µï¼Œå¤´éƒ¨éœ€è¦æœ‰bannerå›¾ç‰‡ã€‚\n```\n\n## è®¸å¯è¯\n\nMIT License \nä½œè€…ï¼šå‡Œå°\n\n## æ•…éšœæ’é™¤\n\n1.é…ç½®å®Œåè·³å‡ºé»‘çª—å£ï¼Œå¾ˆå¿«æ¶ˆå¤±ï¼Œå·¥å…·çŠ¶æ€å˜æˆNo tools found\n\n  åŸå› ï¼šæ²¡æœ‰æ­£å¸¸å¯åŠ¨ï¼Œä¸€èˆ¬æœ‰ä»¥ä¸‹åŸå› \n\n- é…ç½®å‘½ä»¤ä¸å¯¹ï¼Œæ£€æŸ¥å‘½ä»¤æ˜¯å¦æ­£ç¡®ï¼Œä¸€èˆ¬æ˜¯server.pyè·¯å¾„ä¸å¯¹ï¼Œæˆ–è€…è·¯å¾„ä¸­åŒ…å«ä¸­æ–‡ï¼Œæˆ–è€…æ­£åæ–œæ ä¸å¯¹\n- ä¾èµ–çš„ç¯å¢ƒæ²¡å‡†å¤‡å¥½\n- ä¾èµ–è¿è¡Œçš„ç»ˆç«¯ä¸å¯¹ï¼Œåƒæˆ‘windowsçš„ï¼Œç»ˆç«¯æœ‰git bashï¼Œcmdï¼Œpowershellï¼Œwslç­‰ï¼Œè¿™äº›ç»ˆç«¯éƒ½è¯•ä¸‹ï¼Œcursoré…ç½®æˆ‘è¿™é»˜è®¤ç»ˆç«¯æ˜¯cmdï¼Œå¦‚æœä½ åœ¨è¿™å¯¹åº”ç»ˆç«¯è¿è¡ŒæŠ¥é”™ï¼Œä¸€èˆ¬æ˜¯ç¯å¢ƒæ²¡è£…å¥½ï¼Œå®‰è£…ç¯å¢ƒå°±å¯ä»¥\n\n2.æ­£å¸¸è¿è¡Œåï¼Œæƒ³çœ‹è°ƒç”¨æ—¥å¿—ï¼Œæˆ–è€…è°ƒè¯•æ€ä¹ˆå¼„\n\n  å‘½ä»¤æ”¹æˆä»¥ä¸‹ï¼š\n\n```\nuv run --with fastmcp fastmcp dev D:/code/image-gen-service/server.py\n```\n\n\n  å³æŠŠæœ€åä¸€ä¸ªrun æ”¹æˆ devã€‚\n\n  æˆ–è€…æ‰¾ä¸ªç»ˆç«¯è¿è¡Œä»¥ä¸‹å‘½ä»¤è¿›å…¥è°ƒè¯•æ¨¡å¼ï¼š\n\n```\nfastmcp dev D:/code/image-gen-service/server.py\n```\n\nä¼šæœ‰ä¸€ä¸ªè°ƒè¯•åœ°å€è¾“å‡ºï¼šhttp://localhost:5173/ï¼Œä½ å¯ä»¥æµè§ˆå™¨æ‰“å¼€è¿™åœ°å€MCP Inspectorè¿›è¡Œè°ƒè¯•ï¼Œå…·ä½“MCP Inspectoræ€ä¹ˆä½¿ç”¨ï¼Œå¯ä»¥çœ‹å®˜æ–¹æ–‡æ¡£\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "felores--cloudinary-mcp-server": {
      "owner": "felores",
      "name": "cloudinary-mcp-server",
      "url": "https://github.com/felores/cloudinary-mcp-server",
      "imageUrl": "https://github.com/felores.png",
      "description": "Upload images and videos to Cloudinary via MCP clients. Integrates with Claude Desktop for media management.",
      "stars": 9,
      "forks": 8,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-12T10:23:47Z",
      "readme_content": "# Cloudinary MCP Server\n\nThis MCP server provides tools for uploading images and videos to Cloudinary through Claude Desktop and compatible MCP clients.\n\n<a href=\"https://glama.ai/mcp/servers/zjiw1ry8ly\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/zjiw1ry8ly/badge\" alt=\"Cloudinary Server MCP server\" /></a>\n\n## Installation\n\n### Requirements: Node.js\n\n1. Install Node.js (version 18 or higher) and npm from [nodejs.org](https://nodejs.org/)\n2. Verify installation:\n   ```bash\n   node --version\n   npm --version\n   ```\n\n### Install using npx (Recommended)\n1. Navigate to the Claude configuration directory:\n\n   - Windows: `C:\\Users\\NAME\\AppData\\Roaming\\Claude`\n   - macOS: `~/Library/Application Support/Claude/`\n   \n   You can also find these directories inside the Claude Desktop app: Claude Desktop > Settings > Developer > Edit Config\n\n2. Add the following configuration to your MCP settings file:\n\n```json\n{\n  \"mcpServers\": {\n    \"cloudinary\": {\n      \"command\": \"npx\",\n      \"args\": [\"@felores/cloudinary-mcp-server@latest\"],\n      \"env\": {\n        \"CLOUDINARY_CLOUD_NAME\": \"your_cloud_name\",\n        \"CLOUDINARY_API_KEY\": \"your_api_key\",\n        \"CLOUDINARY_API_SECRET\": \"your_api_secret\"\n      }\n    }\n  }\n}\n```\n\n3. Make sure to replace the environment variables with your Cloudinary credentials from the [Cloudinary Console](https://console.cloudinary.com/settings/api-keys).\n\n### Developer Installation\nIf you want to modify the server or contribute to development:\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/felores/cloudinary-mcp-server.git\ncd cloudinary-mcp-server\n```\n\n2. Install dependencies and build:\n```bash\nnpm install\nnpm run build\n```\n\n## Setup Instructions\n\n1. First, ensure you have a Cloudinary account and get your credentials from the [Cloudinary Console](https://console.cloudinary.com/settings/api-keys):\n   - Cloud Name\n   - API Key\n   - API Secret\n\n2. Add the server configuration to your Claude/Cline MCP settings file:\n\n```json\n{\n  \"mcpServers\": {\n    \"cloudinary\": {\n      \"command\": \"node\",\n      \"args\": [\"c:/path/to/cloudinary-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"CLOUDINARY_CLOUD_NAME\": \"your_cloud_name\",\n        \"CLOUDINARY_API_KEY\": \"your_api_key\",\n        \"CLOUDINARY_API_SECRET\": \"your_api_secret\"\n      }\n    }\n  }\n}\n```\n\nFor Claude desktop app, edit the configuration file at the appropriate location for your OS.\n\n3. Install dependencies and build the server:\n```bash\nnpm install\nnpm run build\n```\n\n## Available Tools\n\n### upload\n\nUpload images and videos to Cloudinary.\n\nParameters:\n- `file` (required): Path to file, URL, or base64 data URI to upload\n- `resource_type` (optional): Type of resource ('image', 'video', or 'raw')\n- `public_id` (optional): Custom public ID for the uploaded asset\n- `overwrite` (optional): Whether to overwrite existing assets with the same public ID\n- `tags` (optional): Array of tags to assign to the uploaded asset\n\nExample usage in Claude/Cline:\n```typescript\nuse_mcp_tool({\n  server_name: \"cloudinary\",\n  tool_name: \"upload\",\n  arguments: {\n    file: \"path/to/image.jpg\",\n    resource_type: \"image\",\n    public_id: \"my-custom-id\"\n  }\n});\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Garoth--dalle-mcp": {
      "owner": "Garoth",
      "name": "dalle-mcp",
      "url": "https://github.com/Garoth/dalle-mcp",
      "imageUrl": "https://github.com/Garoth.png",
      "description": "Generate images from text prompts using OpenAI's DALL-E API. Edit existing images and create variations of them while ensuring API key validation for secure access.",
      "stars": 10,
      "forks": 8,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-14T03:51:46Z",
      "readme_content": "# DALL-E MCP Server\n\n<img src=\"assets/dall-e-logo.png\" alt=\"DALL-E MCP Logo\" width=\"256\" height=\"256\">\n\nAn MCP (Model Context Protocol) server for generating images using OpenAI's DALL-E API.\n\n## Features\n\n- Generate images using DALL-E 2 or DALL-E 3\n- Edit existing images (DALL-E 2 only)\n- Create variations of existing images (DALL-E 2 only)\n- Validate OpenAI API key\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/Garoth/dalle-mcp.git\ncd dalle-mcp\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Important Note for Cline Users\n\nWhen using this DALL-E MCP server with Cline, it's recommended to save generated images in your current workspace directory by setting the `saveDir` parameter to match your current working directory. This ensures Cline can properly locate and display the generated images in your conversation.\n\nExample usage with Cline:\n```json\n{\n  \"prompt\": \"A tropical beach at sunset\",\n  \"saveDir\": \"/path/to/current/workspace\"\n}\n```\n\n\n## Usage\n\n### Running the Server\n\n```bash\n# Run the server\nnode build/index.js\n```\n\n### Configuration for Cline\n\nAdd the dall-e server to your Cline MCP settings file inside VSCode's settings (ex. ~/.config/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json):\n\n```json\n{\n  \"mcpServers\": {\n    \"dalle-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/dalle-mcp-server/build/index.js\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-api-key-here\",\n        \"SAVE_DIR\": \"/path/to/save/directory\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\nMake sure to:\n1. Replace `/path/to/dalle-mcp-server/build/index.js` with the actual path to the built index.js file\n2. Replace `your-api-key-here` with your OpenAI API key\n\n### Available Tools\n\n#### generate_image\n\nGenerate an image using DALL-E based on a text prompt.\n\n```json\n{\n  \"prompt\": \"A futuristic city with flying cars and neon lights\",\n  \"model\": \"dall-e-3\",\n  \"size\": \"1024x1024\",\n  \"quality\": \"standard\",\n  \"style\": \"vivid\",\n  \"n\": 1,\n  \"saveDir\": \"/path/to/save/directory\",\n  \"fileName\": \"futuristic-city\"\n}\n```\n\nParameters:\n- `prompt` (required): Text description of the desired image\n- `model` (optional): DALL-E model to use (\"dall-e-2\" or \"dall-e-3\", default: \"dall-e-3\")\n- `size` (optional): Size of the generated image (default: \"1024x1024\")\n  - DALL-E 3: \"1024x1024\", \"1792x1024\", or \"1024x1792\"\n  - DALL-E 2: \"256x256\", \"512x512\", or \"1024x1024\"\n- `quality` (optional): Quality of the generated image, DALL-E 3 only (\"standard\" or \"hd\", default: \"standard\")\n- `style` (optional): Style of the generated image, DALL-E 3 only (\"vivid\" or \"natural\", default: \"vivid\")\n- `n` (optional): Number of images to generate (1-10, default: 1)\n- `saveDir` (optional): Directory to save the generated images (default: current directory or SAVE_DIR from .env). **For Cline users:** Setting this to your current workspace directory is recommended for proper image display.\n- `fileName` (optional): Base filename for the generated images without extension (default: \"dalle-{timestamp}\")\n\n#### edit_image\n\nEdit an existing image using DALL-E based on a text prompt.\n\n> **âš ï¸ Known Issue (March 18, 2025):** The DALL-E 2 image edit API currently has a bug where it sometimes ignores the prompt and returns the original image without any edits, even when using proper RGBA format images and masks. This issue has been reported in the [OpenAI community forum](https://community.openai.com/t/dall-e-2-image-edit-issue/668376/7). If you experience this issue, try using the `create_variation` tool instead, which seems to work more reliably.\n\n```json\n{\n  \"prompt\": \"Add a red hat\",\n  \"imagePath\": \"/path/to/image.png\",\n  \"mask\": \"/path/to/mask.png\",\n  \"model\": \"dall-e-2\",\n  \"size\": \"1024x1024\",\n  \"n\": 1,\n  \"saveDir\": \"/path/to/save/directory\",\n  \"fileName\": \"edited-image\"\n}\n```\n\nParameters:\n- `prompt` (required): Text description of the desired edits\n- `imagePath` (required): Path to the image to edit\n- `mask` (optional): Path to the mask image (white areas will be edited, black areas preserved)\n- `model` (optional): DALL-E model to use (currently only \"dall-e-2\" supports editing, default: \"dall-e-2\")\n- `size` (optional): Size of the generated image (default: \"1024x1024\")\n- `n` (optional): Number of images to generate (1-10, default: 1)\n- `saveDir` (optional): Directory to save the edited images (default: current directory or SAVE_DIR from .env). **For Cline users:** Setting this to your current workspace directory is recommended for proper image display.\n- `fileName` (optional): Base filename for the edited images without extension (default: \"dalle-edit-{timestamp}\")\n\n#### create_variation\n\nCreate variations of an existing image using DALL-E.\n\n```json\n{\n  \"imagePath\": \"/path/to/image.png\",\n  \"model\": \"dall-e-2\",\n  \"size\": \"1024x1024\",\n  \"n\": 4,\n  \"saveDir\": \"/path/to/save/directory\",\n  \"fileName\": \"image-variation\"\n}\n```\n\nParameters:\n- `imagePath` (required): Path to the image to create variations of\n- `model` (optional): DALL-E model to use (currently only \"dall-e-2\" supports variations, default: \"dall-e-2\")\n- `size` (optional): Size of the generated image (default: \"1024x1024\")\n- `n` (optional): Number of variations to generate (1-10, default: 1)\n- `saveDir` (optional): Directory to save the variation images (default: current directory or SAVE_DIR from .env). **For Cline users:** Setting this to your current workspace directory is recommended for proper image display.\n- `fileName` (optional): Base filename for the variation images without extension (default: \"dalle-variation-{timestamp}\")\n\n#### validate_key\n\nValidate the OpenAI API key.\n\n```json\n{}\n```\n\nNo parameters required.\n\n## Development\n\n## Testing Configuration\n\n**Note: The following .env configuration is ONLY needed for running tests, not for normal operation.**\n\nIf you're developing or running tests for this project, create a `.env` file in the root directory with your OpenAI API key:\n\n```\n# Required for TESTS ONLY: OpenAI API Key\nOPENAI_API_KEY=your-api-key-here\n\n# Optional: Default save directory for test images\n# If not specified, images will be saved to the current directory\n# SAVE_DIR=/path/to/save/directory\n```\n\nFor normal operation with Cline, configure your API key in the MCP settings JSON as described in the \"Adding to MCP Settings\" section above.\n\nYou can get your API key from [OpenAI's API Keys page](https://platform.openai.com/api-keys).\n\n### Running Tests\n\n```bash\n# Run basic tests\nnpm test\n\n# Run all tests including edit and variation tests\nnpm run test:all\n\n# Run tests in watch mode\nnpm run test:watch\n\n# Run specific test by name\nnpm run test:name \"should validate API key\"\n```\n\nNote: Tests use real API calls and may incur charges on your OpenAI account.\n\n### Generating Test Images\n\nThe project includes a script to generate test images for development and testing:\n\n```bash\n# Generate a test image in the assets directory\nnpm run generate-test-image\n  ```\n\nThis will create a simple test image in the `assets` directory that can be used for testing the edit and variation features.\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "GMKR--mcp-imagegen": {
      "owner": "GMKR",
      "name": "mcp-imagegen",
      "url": "https://github.com/GMKR/mcp-imagegen",
      "imageUrl": "https://github.com/GMKR.png",
      "description": "Generate images from text prompts using advanced AI models. Supports both local and SSE endpoint configurations with specific provider requirements.",
      "stars": 4,
      "forks": 3,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-06-18T01:58:09Z",
      "readme_content": "# MCP Image Generator\n\nA Model Context Protocol (MCP) server for generating images using Together AI's image generation models. This MCP Server can be run locally or using an SSE endpoint. \nThe MCP Image Generator required a provider, only \"Replicate\" and \"Together\" are supported currently. You need to set the `TOGETHER_API_KEY` or `REPLICATE_API_TOKEN` environment variables. and set the `PROVIDER` environment variable to \"replicate\" or \"together\"/\n\n## SSE Endpoint (Docker environment)\n\n### Clone the repository\n\n```bash\ngit clone https://github.com/gmkr/mcp-imagegen.git\ncd mcp-imagegen\n```\n\n### Build and run Docker container\n\n```bash\ndocker build -f Dockerfile.server -t mcp-imagegen .\ndocker run -p 3000:3000 mcp-imagegen\n```\n\n### Configuring with MCP Client\n```\n{\n  \"mcpServers\": {\n    \"imagegenerator\": {\n      \"url\": \"http://localhost:3000/sse\",\n      \"env\": {\n        \"PROVIDER\": \"replicate\",\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\"\n      }\n    }\n  }\n}\n```\nAdjust the `url` to the endpoint of the MCP server you want to use.  `provider` can be \"replicate\" or \"together\".\n\n## Running locally using stdio\n\n### Prerequisites\n\n- Node.js\n- Together AI API key or Replicate API token\n\n### Installation\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/gmkr/mcp-imagegen.git\n   cd mcp-imagegen\n   ```\n\n2. Install dependencies:\n   ```bash\n   pnpm install\n   ```\n### Configuration\nCreate a configuration file for your MCP client. Here's an example configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"imagegenerator\": {\n      \"command\": \"pnpx\",\n      \"args\": [\n        \"-y\",\n        \"tsx\",\n        \"/path/to/mcp-imagegen/src/index.ts\"\n      ],\n      \"env\": {\n        \"PROVIDER\": \"replicate\",\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\"\n      }\n    }\n  }\n}\n```\n\nReplace `/path/to/mcp-imagegen` with the absolute path to your cloned repository and `your-replicate-api-token` with your actual Replicate API token.\n\n## Usage\n\nThe MCP Image Generator provides a tool called `generate_image` that can be used to generate images based on text prompts.\n\n### Tool: generate_image\n\nGenerates an image based on the provided prompt.\n\n**Parameters:**\n- `prompt` (string): The text prompt to generate an image for\n- `width` (number, optional): The width of the image to generate (default: 512)\n- `height` (number, optional): The height of the image to generate (default: 512)\n- `numberOfImages` (number, optional): The number of images to generate (default: 1)\n\n## Environment Variables\n- `PROVIDER`: The provider to use for image generation (default: \"replicate\")\n- `REPLICATE_API_TOKEN`: Your Replicate API token\n- `TOGETHER_API_KEY`: Your Together AI API key\n- `MODEL_NAME`: The model to use for image generation (default: \"black-forest-labs/flux-schnell\")\n\n## License\n\nMIT \n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "GongRzhe--Image-Generation-MCP-Server": {
      "owner": "GongRzhe",
      "name": "Image-Generation-MCP-Server",
      "url": "https://github.com/GongRzhe/Image-Generation-MCP-Server",
      "imageUrl": "https://github.com/GongRzhe.png",
      "description": "Generate images from text prompts using the Replicate Flux model, enabling the creation of unique visuals tailored to specific specifications.",
      "stars": 40,
      "forks": 8,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-30T20:18:52Z",
      "readme_content": "# Image Generation MCP Server\n![](https://badge.mcpx.dev?type=server 'MCP Server')\n\n[![smithery badge](https://smithery.ai/badge/@GongRzhe/Image-Generation-MCP-Server)](https://smithery.ai/server/@GongRzhe/Image-Generation-MCP-Server)\n\nThis MCP server provides image generation capabilities using the Replicate Flux model.\n\n## Installation\n\n### Installing via Smithery\n\nTo install Image Generation MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@GongRzhe/Image-Generation-MCP-Server):\n\n```bash\nnpx -y @smithery/cli install @GongRzhe/Image-Generation-MCP-Server --client claude\n```\n\n### Option 1: NPX Method (No Local Setup Required)\nYou can use the package directly from npm without installing it locally:\n\n```bash\n# No installation needed - npx will handle it\n```\n\n### Option 2: Local Installation\nIf you prefer a local installation:\n\n```bash\n# Global installation\nnpm install -g @gongrzhe/image-gen-server\n\n# Or local installation\nnpm install @gongrzhe/image-gen-server\n```\n\n## Setup\n\n### Configure Claude Desktop\n\nEdit your Claude Desktop configuration file:\n\n- On MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- On Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n#### Option 1: NPX Configuration (Recommended)\nThis method runs the server directly from npm without needing local files:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-gen\": {\n      \"command\": \"npx\",\n      \"args\": [\"@gongrzhe/image-gen-server\"],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\",\n        \"MODEL\": \"alternative-model-name\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n#### Option 2: Local Installation Configuration\nIf you installed the package locally:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-gen\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/image-gen-server/build/index.js\"],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\",\n        \"MODEL\": \"alternative-model-name\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n### Get Your Replicate API Token\n\n1. Sign up/login at https://replicate.com\n2. Go to https://replicate.com/account/api-tokens\n3. Create a new API token\n4. Copy the token and replace `your-replicate-api-token` in the MCP settings\n\n![image](https://github.com/user-attachments/assets/583afa78-1a08-4eb5-9a37-decb95bd50c4)\n\n### Environment Variables\n\n- `REPLICATE_API_TOKEN` (required): Your Replicate API token for authentication\n- `MODEL` (optional): The Replicate model to use for image generation. Defaults to \"black-forest-labs/flux-schnell\"\n\n### Configuration Parameters\n\n- `disabled`: Controls whether the server is enabled (`false`) or disabled (`true`)\n- `autoApprove`: Array of tool names that can be executed without user confirmation. Empty array means all tool calls require confirmation.\n\n## Available Tools\n\n### generate_image\n\nGenerates images using the Flux model based on text prompts.\n\n![image](https://github.com/user-attachments/assets/766921ce-ca8e-4d68-866d-8c7b55b2e09d)\n\n![out-0 (1)](https://github.com/user-attachments/assets/83549b2e-525a-4ff9-825c-83ba74459575)\n\n#### Parameters\n\n- `prompt` (required): Text description of the image to generate\n- `seed` (optional): Random seed for reproducible generation\n- `aspect_ratio` (optional): Image aspect ratio (default: \"1:1\")\n- `output_format` (optional): Output format - \"webp\", \"jpg\", or \"png\" (default: \"webp\")\n- `num_outputs` (optional): Number of images to generate (1-4, default: 1)\n\n#### Example Usage\n\n```typescript\nconst result = await use_mcp_tool({\n  server_name: \"image-gen\",\n  tool_name: \"generate_image\",\n  arguments: {\n    prompt: \"A beautiful sunset over mountains\",\n    aspect_ratio: \"16:9\",\n    output_format: \"png\",\n    num_outputs: 1\n  }\n});\n```\n\nThe tool returns an array of URLs to the generated images.\n\n## ğŸ“œ License\n\nThis project is licensed under the MIT License.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Hajime-Y--deep-research-mcp": {
      "owner": "Hajime-Y",
      "name": "deep-research-mcp",
      "url": "https://github.com/Hajime-Y/deep-research-mcp",
      "imageUrl": "https://github.com/Hajime-Y.png",
      "description": "Provides advanced web search capabilities, document analysis, and image processing. Extracts information from various sources including PDFs and YouTube transcripts efficiently.",
      "stars": 12,
      "forks": 1,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-06T18:57:01Z",
      "readme_content": "# Deep Research MCP Server\n\nDeep Research is an agent-based tool that provides web search and advanced research capabilities. It leverages HuggingFace's `smolagents` and is implemented as an MCP server.\n\nThis project is based on [HuggingFace's open_deep_research example](https://github.com/huggingface/smolagents/tree/main/examples/open_deep_research).\n\n## Features\n\n- Web search and information gathering\n- PDF and document analysis\n- Image analysis and description\n- YouTube transcript retrieval\n- Archive site search\n\n## Requirements\n\n- Python 3.11 or higher\n- `uv` package manager\n- The following API keys:\n  - OpenAI API key\n  - HuggingFace token\n  - SerpAPI key\n\n## Installation\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/Hajime-Y/deep-research-mcp.git\ncd deep-research-mcp\n```\n\n2. Create a virtual environment and install dependencies:\n\n```bash\nuv venv\nsource .venv/bin/activate # For Linux or Mac\n# .venv\\Scripts\\activate # For Windows\nuv sync\n```\n\n## Environment Variables\n\nCreate a `.env` file in the root directory of the project and set the following environment variables:\n\n```\nOPENAI_API_KEY=your_openai_api_key\nHF_TOKEN=your_huggingface_token\nSERPER_API_KEY=your_serper_api_key\n```\n\nYou can obtain a SERPER_API_KEY by signing up at [Serper.dev](https://serper.dev/signup).\n\n## Usage\n\nStart the MCP server:\n\n```bash\nuv run deep_research.py\n```\n\nThis will launch the `deep_research` agent as an MCP server.\n\n## Docker Usage\n\nYou can also run this MCP server in a Docker container:\n\n```bash\n# Build the Docker image\ndocker build -t deep-research-mcp .\n\n# Run with required API keys\ndocker run -p 8080:8080 \\\n  -e OPENAI_API_KEY=your_openai_api_key \\\n  -e HF_TOKEN=your_huggingface_token \\\n  -e SERPER_API_KEY=your_serper_api_key \\\n  deep-research-mcp\n```\n\n### Registering with MCP Clients\n\nTo register this Docker container as an MCP server in different clients:\n\n#### Claude Desktop\n\nAdd the following to your Claude Desktop configuration file (typically located at `~/.config/Claude/claude_desktop_config.json` on Linux, `~/Library/Application Support/Claude/claude_desktop_config.json` on macOS, or `%APPDATA%\\Claude\\claude_desktop_config.json` on Windows):\n\n```json\n{\n  \"mcpServers\": {\n    \"deep-research-mcp\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \n        \"-i\", \n        \"--rm\", \n        \"-e\", \"OPENAI_API_KEY=your_openai_api_key\",\n        \"-e\", \"HF_TOKEN=your_huggingface_token\", \n        \"-e\", \"SERPER_API_KEY=your_serper_api_key\",\n        \"deep-research-mcp\"\n      ]\n    }\n  }\n}\n```\n\n#### Cursor IDE\n\nFor Cursor IDE, add the following configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"deep-research-mcp\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \n        \"-i\", \n        \"--rm\", \n        \"-e\", \"OPENAI_API_KEY=your_openai_api_key\",\n        \"-e\", \"HF_TOKEN=your_huggingface_token\", \n        \"-e\", \"SERPER_API_KEY=your_serper_api_key\",\n        \"deep-research-mcp\"\n      ]\n    }\n  }\n}\n```\n\n#### Using with Remote MCP Server\n\nIf you're running the MCP server on a remote machine or exposing it as a service, you can use the URL-based configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"deep-research-mcp\": {\n      \"url\": \"http://your-server-address:8080/mcp\",\n      \"type\": \"sse\"\n    }\n  }\n}\n```\n\n## Key Components\n\n- `deep_research.py`: Entry point for the MCP server\n- `create_agent.py`: Agent creation and configuration\n- `scripts/`: Various tools and utilities\n  - `text_web_browser.py`: Text-based web browser\n  - `text_inspector_tool.py`: File inspection tool\n  - `visual_qa.py`: Image analysis tool\n  - `mdconvert.py`: Converts various file formats to Markdown\n\n## License\n\nThis project is provided under the Apache License 2.0.\n\n## Acknowledgements\n\nThis project uses code from HuggingFace's `smolagents` and Microsoft's `autogen` projects.",
      "npm_url": "",
      "npm_downloads": 0
    },
    "hamflx--imagen3-mcp": {
      "owner": "hamflx",
      "name": "imagen3-mcp",
      "url": "https://github.com/hamflx/imagen3-mcp",
      "imageUrl": "https://github.com/hamflx.png",
      "description": "Generate high-quality images using Google's Imagen 3.0 model through an MCP interface, facilitating integration with tools like Cherry Studio or Cursor. Supports configurable deployment options using a Google Gemini API key.",
      "stars": 43,
      "forks": 7,
      "license": "No License",
      "language": "Rust",
      "updated_at": "2025-09-20T19:36:59Z",
      "readme_content": "# Imagen3-MCP\n\n[English Version](#imagen3-mcp-english)\n\nåŸºäº Google çš„ Imagen 3.0 çš„å›¾åƒç”Ÿæˆå·¥å…·ï¼Œé€šè¿‡ MCPï¼ˆModel Control Protocolï¼‰æä¾›æœåŠ¡ã€‚\n\n## æ•ˆæœ\n\nç”»ä¸€åªå¥”è·‘çš„æ°å…‹ç½—ç´ çŠ¬ï¼Œé•¿ç„¦é•œå¤´ï¼Œé˜³å…‰é€è¿‡ç‹—ç‹—çš„æ¯›å‘ï¼Œç…§ç‰‡çº§ç”»è´¨\n\n![å¥”è·‘çš„æ°å…‹ç½—ç´ çŠ¬](./docs/Snipaste_2025-04-26_15-18-15.png)\n\nç”»ä¸€ä¸ªç§‘æŠ€æ„Ÿåè¶³çš„è‹¹æœ\n\n![ç§‘æŠ€æ„Ÿåè¶³çš„è‹¹æœ](./docs/Snipaste_2025-04-26_15-18-02.png)\n\n## å®‰è£…è¦æ±‚\n\n- æœ‰æ•ˆçš„ [Google Gemini API å¯†é’¥](https://aistudio.google.com/apikey)\n\n## å®‰è£…æ­¥éª¤â€”â€”Cherry Studio\n\n1. ä» [GitHub Releases](https://github.com/hamflx/imagen3-mcp/releases) ä¸‹è½½æœ€æ–°ç‰ˆæœ¬çš„å¯æ‰§è¡Œæ–‡ä»¶\n2. å°†ä¸‹è½½çš„å¯æ‰§è¡Œæ–‡ä»¶æ”¾ç½®åœ¨ç³»ç»Ÿä¸­çš„ä»»æ„ä½ç½®ï¼Œä¾‹å¦‚ `C:\\bin\\imagen3-mcp.exe`\n3. åœ¨ Cherry Studio ä¸­é…ç½®ï¼š\n   - Command å­—æ®µå¡«å†™å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ `C:\\bin\\imagen3-mcp.exe`\n   - ç¯å¢ƒå˜é‡ `GEMINI_API_KEY` ä¸­å¡«å†™ä½ çš„ Gemini API å¯†é’¥\n   - [å¯é€‰] ç¯å¢ƒå˜é‡ `BASE_URL` ä¸­å¡«å†™ä»£ç†åœ°å€ï¼Œä¾‹å¦‚ `https://lingxi-proxy.hamflx.dev/api/provider/google`ï¼ˆè¿™ä¸ªåœ°å€å¯ä»¥è§£å†³ GFW çš„é—®é¢˜ï¼Œä½†æ˜¯è§£å†³ä¸äº† Google å¯¹ IP çš„é™åˆ¶é—®é¢˜ï¼Œå› æ­¤è¿˜æ˜¯å¾—æŒ‚æ¢¯å­ï¼‰ã€‚\n   - [å¯é€‰] ç¯å¢ƒå˜é‡ `SERVER_LISTEN_ADDR`ï¼šè®¾ç½®æœåŠ¡å™¨ç›‘å¬çš„ IP åœ°å€ï¼ˆé»˜è®¤ä¸º `127.0.0.1`ï¼‰ã€‚\n   - [å¯é€‰] ç¯å¢ƒå˜é‡ `SERVER_PORT`ï¼šè®¾ç½®æœåŠ¡å™¨ç›‘å¬çš„ç«¯å£å’Œå›¾ç‰‡ URL ä½¿ç”¨çš„ç«¯å£ï¼ˆé»˜è®¤ä¸º `9981`ï¼‰ã€‚\n   - [å¯é€‰] ç¯å¢ƒå˜é‡ `IMAGE_RESOURCE_SERVER_ADDR`ï¼šè®¾ç½®å›¾ç‰‡ URL ä¸­ä½¿ç”¨çš„æœåŠ¡å™¨åœ°å€ï¼ˆé»˜è®¤ä¸º `127.0.0.1`ï¼‰ã€‚è¿™åœ¨æœåŠ¡å™¨è¿è¡Œåœ¨å®¹å™¨æˆ–è¿œç¨‹æœºå™¨ä¸Šæ—¶å¾ˆæœ‰ç”¨ã€‚\n\n![é…ç½®](./docs/config.png)\n\n## å®‰è£…æ­¥éª¤â€”â€”Cursor\n\n```json\n{\n  \"mcpServers\": {\n    \"imagen3\": {\n      \"command\": \"C:\\\\bin\\\\imagen3-mcp.exe\",\n      \"env\": {\n        \"GEMINI_API_KEY\": \"<GEMINI_API_KEY>\"\n        // Optional environment variables:\n        // \"BASE_URL\": \"<PROXY_URL>\",\n        // \"SERVER_LISTEN_ADDR\": \"0.0.0.0\", // Example: Listen on all interfaces\n        // \"SERVER_PORT\": \"9981\",\n        // \"IMAGE_RESOURCE_SERVER_ADDR\": \"your.domain.com\" // Example: Use a domain name for image URLs\n      }\n    }\n  }\n}\n```\n\n## è®¸å¯è¯\n\nMIT\n\n---\n\n# Imagen3-MCP (English)\n\nAn image generation tool based on Google's Imagen 3.0, providing services through MCP (Model Control Protocol).\n\n## Examples\n\nA running Jack Russell Terrier, telephoto lens, sunlight filtering through the dog's fur, photorealistic quality\n\n![Running Jack Russell Terrier](./docs/Snipaste_2025-04-26_15-18-15.png)\n\nA high-tech apple\n\n![High-tech apple](./docs/Snipaste_2025-04-26_15-18-02.png)\n\n## Requirements\n\n- Valid [Google Gemini API key](https://aistudio.google.com/apikey)\n\n## Installation Stepsâ€”Cherry Studio\n\n1. Download the latest executable from [GitHub Releases](https://github.com/hamflx/imagen3-mcp/releases)\n2. Place the downloaded executable anywhere in your system, e.g., `C:\\bin\\imagen3-mcp.exe`\n3. Configure in Cherry Studio:\n   - Fill in the Command field with the executable path, e.g., `C:\\bin\\imagen3-mcp.exe`\n   - Enter your Gemini API key in the `GEMINI_API_KEY` environment variable\n   - [Optional] Enter a proxy URL in the `BASE_URL` environment variable, e.g., `https://your-proxy.com`.\n   - [Optional] Set the `SERVER_LISTEN_ADDR` environment variable: The IP address the server listens on (defaults to `127.0.0.1`).\n   - [Optional] Set the `SERVER_PORT` environment variable: The port the server listens on and uses for image URLs (defaults to `9981`).\n   - [Optional] Set the `IMAGE_RESOURCE_SERVER_ADDR` environment variable: The server address used in the image URLs (defaults to `127.0.0.1`). Useful if the server runs in a container or remote machine.\n\n![Configuration](./docs/config.png)\n\n## Installation Stepsâ€”Cursor\n\n```json\n{\n  \"mcpServers\": {\n    \"imagen3\": {\n      \"command\": \"C:\\\\bin\\\\imagen3-mcp.exe\",\n      \"env\": {\n        \"GEMINI_API_KEY\": \"<GEMINI_API_KEY>\"\n        // Optional environment variables:\n        // \"BASE_URL\": \"<PROXY_URL>\",\n        // \"SERVER_LISTEN_ADDR\": \"0.0.0.0\", // Example: Listen on all interfaces\n        // \"SERVER_PORT\": \"9981\",\n        // \"IMAGE_RESOURCE_SERVER_ADDR\": \"your.domain.com\" // Example: Use a domain name for image URLs\n      }\n    }\n  }\n}\n```\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "hellokaton--unsplash-mcp-server": {
      "owner": "hellokaton",
      "name": "unsplash-mcp-server",
      "url": "https://github.com/hellokaton/unsplash-mcp-server",
      "imageUrl": "https://github.com/hellokaton.png",
      "description": "Connects to Unsplash's image library to perform advanced searches and apply filters on keywords for rich, high-quality image retrieval.",
      "stars": 174,
      "forks": 19,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T22:30:58Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/hellokaton-unsplash-mcp-server-badge.png)](https://mseep.ai/app/hellokaton-unsplash-mcp-server)\n\n# Unsplash MCP Server\n\nEnglish | [ç®€ä½“ä¸­æ–‡](README_zh.md)\n\n> A simple MCP server for seamless Unsplash image integration and search capabilities.\n\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![smithery badge](https://smithery.ai/badge/@hellokaton/unsplash-mcp-server)](https://smithery.ai/server/@hellokaton/unsplash-mcp-server)\n\n## ğŸ“‹ Overview\n\nUnsplash MCP Server is used for searching rich, high-quality images. It's ideal for developers who want to integrate Unsplash functionality into their own applications.\n\n## âœ¨ Features\n\n- **Advanced Image Search**: Search Unsplash's extensive photo library with filters for:\n  - Keyword relevance\n  - Color schemes\n  - Orientation options\n  - Custom sorting and pagination\n\n## ğŸ”‘ Obtaining Unsplash Access Key\n\nBefore installing this server, you'll need to obtain an Unsplash API Access Key:\n\n1. Create a developer account at [Unsplash](https://unsplash.com/developers)\n2. Register a new application\n3. Get your Access Key from the application details page\n4. Use this key in the configuration steps below\n\nFor more details, refer to the [official Unsplash API documentation](https://unsplash.com/documentation).\n\n## ğŸš€ Installation\n\nTo install Unsplash Image Integration Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@hellokaton/unsplash-mcp-server):\n\n### IDE Setup\n\n**Cursor IDE**\n\n```bash\nnpx -y @smithery/cli@latest install @hellokaton/unsplash-mcp-server --client cursor --key 7558c683-****-****\n```\n\n**Windsurf**\n\n```bash\nnpx -y @smithery/cli@latest install @hellokaton/unsplash-mcp-server --client windsurf --key 7558c683-****-****\n```\n\n**Cline**\n\n```bash\nnpx -y @smithery/cli@latest install @hellokaton/unsplash-mcp-server --client cline --key 7558c683-****-****\n```\n\n### Manual Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/hellokaton/unsplash-mcp-server.git\n\n# Navigate to project directory\ncd unsplash-mcp-server\n\n# Create virtual environment\nuv venv\n\n# Install dependencies\nuv pip install .\n```\n\n**Cursor Editor Integration**\n\nAdd the following configuration to your Cursor editor's `settings.json`:\n\nâš ï¸ **Note:** Please adjust the following configuration according to your actual installation:\n\n- If `uv` is not in your system PATH, use an absolute path (e.g., `/path/to/uv`)\n- `./server.py` should be modified to the actual location of your server script (can use absolute path or path relative to workspace)\n\n<img src=\"screenshots/Snipaste_1.png\" alt=\"Cursor Configuration Screenshot\" />\n\n```json\n{\n  \"mcpServers\": {\n    \"unsplash\": {\n      \"command\": \"uv\",\n      \"args\": [\"run\", \"--with\", \"fastmcp\", \"fastmcp\", \"run\", \"./server.py\"],\n      \"env\": {\n        \"UNSPLASH_ACCESS_KEY\": \"${YOUR_ACCESS_KEY}\"\n      }\n    }\n  }\n}\n```\n\n### Using in Cursor\n\n<img src=\"screenshots/Snipaste_2.png\" alt=\"Unsplash MCP in Cursor\" />\n\n## ğŸ› ï¸ Available Tools\n\n### Search Photos\n\n```json\n{\n  \"tool\": \"search_photos\",\n  \"query\": \"mountain\",\n  \"per_page\": 5,\n  \"orientation\": \"landscape\"\n}\n```\n\n## ğŸ”„ Other Implementations\n\n- Golang: [unsplash-mcp-server](https://github.com/douglarek/unsplash-mcp-server)\n- Java: [unsplash-mcp-server](https://github.com/JavaProgrammerLB/unsplash-mcp-server)\n\n## ğŸ“„ License\n\n[MIT License](LICENSE)\n\n## ğŸ“¬ Contact\n\n- [Twitter/X](https://x.com/hellokaton)\n- [GitHub Issues](https://github.com/hellokaton/unsplash-mcp-server/issues)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "htessaro--mcp-test-deploy-2": {
      "owner": "htessaro",
      "name": "mcp-test-deploy-2",
      "url": "https://github.com/htessaro/mcp-test-deploy-2",
      "imageUrl": "https://github.com/htessaro.png",
      "description": "Access a wide array of cat images and detailed breed information through a TypeScript SDK, enabling image uploads, retrieval of breed data, and user interactions such as favoriting or voting on images.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-04-28T17:24:43Z",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0
    },
    "huangmiuXyz--jimeng-mcp": {
      "owner": "huangmiuXyz",
      "name": "jimeng-mcp",
      "url": "https://github.com/huangmiuXyz/jimeng-mcp",
      "imageUrl": "https://github.com/huangmiuXyz.png",
      "description": "Integrate AI-powered image generation capabilities into applications using the Jimeng AI model. Generate high-quality images through a simple MCP interface for advanced AI image synthesis.",
      "stars": 2,
      "forks": 2,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-06-20T02:13:23Z",
      "readme_content": "{\n  \"mcpServers\": {\n    \"jimeng\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"jimeng\",\n        \"-y\"\n      ],\n      \"env\": {\n        \"VOLCENGINE_ACCESS_KEY\": \"your_access_key_here\",\n        \"VOLCENGINE_SECRET_KEY\": \"your_secret_key_here\"\n      }\n    }\n  }\n}\n\nhttps://console.volcengine.com/iam/keymanage/ è·å–Access Key IDå’ŒSecret Access Key\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "husniadil--mcp-image-placeholder": {
      "owner": "husniadil",
      "name": "mcp-image-placeholder",
      "url": "https://github.com/husniadil/mcp-image-placeholder",
      "imageUrl": "https://github.com/husniadil.png",
      "description": "Generates placeholder images from multiple providers, supporting both simple and real images as placeholders. Validates input parameters and returns image URLs for immediate use.",
      "stars": 8,
      "forks": 3,
      "license": "MIT License",
      "language": "HTML",
      "updated_at": "2025-06-17T08:32:20Z",
      "readme_content": "# MCP Image Placeholder Server\n\nThis is a Model Context Protocol (MCP) server that provides a tool for generating placeholder images from different providers.\n\n## Features\n\n- Generates placeholder images from supported providers\n- Supports two image providers:\n  - [`placehold`](https://placehold.co/): Provides simple placeholder images\n  - [`lorem-picsum`](https://picsum.photos/): Provides real images as placeholder images\n- Validates input parameters\n- Returns image URLs for immediate use\n\n## Requirements\n\n- Python 3.9+\n- `uv` package manager\n\n## Installation\n\n1. Clone this repository\n2. [Set up the configuration for MCP server](#configuration)\n\n## Usage\n\nThe server exposes one tool:\n\n### `image_placeholder`\n\nGenerate a placeholder image URL based on specified parameters.\n\n**Parameters:**\n- `provider`: The image provider to use (`placehold` or `lorem-picsum`)\n- `width`: The width of the image (1-10000)\n- `height`: The height of the image (1-10000)\n\n**Returns:**\n- URL string of the generated image\n\n**Example Usage:**\n```python\n# Generate a 300x200 placeholder image\nurl = image_placeholder(provider=\"placehold\", width=300, height=200)\n\n# Generate a 500px square lorem-picsum image\nurl = image_placeholder(provider=\"lorem-picsum\", width=500)\n```\n\n## Configuration\n\n### To connect this server to Claude for Desktop:\n\n1. Add the following to your `claude_desktop_config.json`:\n   ```json\n   {\n       \"mcpServers\": {\n           \"image-placeholder\": {\n               \"command\": \"uv\",\n               \"args\": [\n                   \"--directory\",\n                   \"/ABSOLUTE/PATH/TO/PROJECT\",\n                   \"run\",\n                   \"main.py\"\n               ]\n           }\n       }\n   }\n   ```\n2. Restart Claude for Desktop\n\n### To connect this server to Cursor:\n\n1. Open Cursor Settings\n2. Head to the `Features` section\n3. Scroll down to the `MCP Servers` section\n4. Click on the `Add new MCP server` button\n5. Enter the following information:\n   - Name: `image-placeholder`\n   - Type: `command`\n   - Server URL: `uv --directory /ABSOLUTE/PATH/TO/PROJECT run main.py`\n6. Click on the `Add â†µ` button\n\n\n## Troubleshooting\n\nIf the tool is not detected, use absolute path of the `uv` command, e.g.\n```\n/ABSOLUTE/PATH/TO/uv --directory /ABSOLUTE/PATH/TO/PROJECT run main.py\n```\n\n## Example Usage and Output (Cursor)\n\nPrompt:\n```\nCreate a new directory named \"example\" and a file named output.html.\n\nThen create a single modern looking page using tailwindcss: https://unpkg.com/@tailwindcss/browser@4\n\nShow a nice header, content, and footer, showing a photo gallery.\n\nSave this into output.html\n```\n\n![Screenshot of Cursor Agent](example/cursor-agent.png)\n\nOutput:\n[Example Output (Cursor)](example/output.html)\n\n## License\n\n[MIT License](LICENSE)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Hzzy2O--flux-cloudfare-mcp": {
      "owner": "Hzzy2O",
      "name": "flux-cloudfare-mcp",
      "url": "https://github.com/Hzzy2O/flux-cloudfare-mcp",
      "imageUrl": "https://github.com/Hzzy2O.png",
      "description": "Provides high-quality image generation via the Flux model through a Cloudflare Worker API, enabling seamless integration into applications with customizable parameters for image output.",
      "stars": 0,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-03-17T01:14:19Z",
      "readme_content": "# Flux Cloudflare MCP\n\n![MCP Compatible](https://img.shields.io/badge/MCP-Compatible-blue)\n![License](https://img.shields.io/badge/license-MIT-green)\n![TypeScript](https://img.shields.io/badge/TypeScript-4.9+-blue)\n![Model Context Protocol](https://img.shields.io/badge/MCP-Enabled-purple)\n\nA powerful Model Context Protocol (MCP) server that provides AI assistants with the ability to generate images using [Black Forest Labs' Flux model](https://developer.cloudflare.com/ai-gateway/models/flux-1/) via a Cloudflare Worker API.\n\n[Installation](#installation) â€¢ [Features](#features) â€¢ [Usage](#usage) â€¢ [Documentation](#documentation) â€¢ [Contributing](#contributing)\n\n---\n\n## ğŸŒŸ Features\n\n- **ğŸ–¼ï¸ High-Quality Image Generation**: Access to Flux, a state-of-the-art image generation model\n- **ğŸ¤– Seamless AI Integration**: Enable AI assistants like Claude to generate images directly\n- **ğŸ›ï¸ Customizable Parameters**: Control aspect ratio, inference steps, and more\n- **ğŸ”Œ MCP Compatible**: Works with any MCP client (Cursor, Claude Desktop, Cline, Zed, etc.)\n- **ğŸ”’ Local Processing**: All requests are processed securely through the Cloudflare Worker\n- **ğŸ’¬ Chat Completions**: Get text completions using the same API\n\n## ğŸ“¦ Installation\n\n### Direct Usage with NPX\n\n```bash\nFLUX_API_TOKEN=your_token FLUX_API_URL=your_api_url npx -y flux-cloudflare-mcp\n```\n\n### From Source\n\n```bash\n# Clone the repository\ngit clone https://github.com/Hzzy2O/flux-cloudflare-mcp.git\ncd flux-cloudflare-mcp\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## ğŸš€ Setting Up Your Flux API\n\nThis MCP server requires a Flux API endpoint to function. You have two options for setting up the API:\n\n### Option 1: Deploy using snakeying/flux-api-worker (Recommended)\n\n[snakeying/flux-api-worker](https://github.com/snakeying/flux-api-worker) provides a simple and efficient Cloudflare Worker for accessing the Flux model:\n\n1. Fork the [flux-api-worker repository](https://github.com/snakeying/flux-api-worker)\n2. Deploy it to Cloudflare Workers:\n   - Create a new Worker in your Cloudflare dashboard\n   - Connect it to your forked repository\n   - Set up the required environment variables:\n     - `API_KEY`: Your chosen API key for authentication\n     - `CF_ACCOUNT_ID`: Your Cloudflare account ID\n     - `CF_API_TOKEN`: Your Cloudflare API token with Workers AI access\n     - `FLUX_MODEL`: The Flux model to use (default: \"@cf/black-forest-labs/flux-1-schnell\")\n3. Once deployed, your API will be available at `https://your-worker-name.your-subdomain.workers.dev`\n4. Use this URL as your `FLUX_API_URL` and your chosen API key as `FLUX_API_TOKEN`\n\n### Option 2: Deploy using aigem/cf-flux-remix\n\nFor a more feature-rich implementation with a web UI, you can use [aigem/cf-flux-remix](https://github.com/aigem/cf-flux-remix):\n\n1. Follow the installation instructions in the [cf-flux-remix repository](https://github.com/aigem/cf-flux-remix)\n2. Once deployed, your API will be available at your deployed URL\n3. Use this URL as your `FLUX_API_URL` and your configured API key as `FLUX_API_TOKEN`\n\n## ğŸ“š Documentation\n\n### Available Tools\n\n#### `generate_image`\n\nGenerates an image based on a text prompt using the Flux model.\n\n```typescript\n{\n  prompt: string;                // Required: Text description of the image to generate\n  num_inference_steps?: number;  // Optional: Number of denoising steps (1-4) (default: 4)\n  aspect_ratio?: string;         // Optional: Aspect ratio (e.g., \"16:9\", \"4:3\") (default: \"1:1\")\n}\n```\n\n## ğŸ”§ Usage\n\n### Cursor Integration\n\n#### Method 1: Using mcp.json\n\n1. Create or edit the `.cursor/mcp.json` file in your project directory:\n\n```json\n{\n  \"mcpServers\": {\n    \"flux-cloudflare-mcp\": {\n      \"command\": \"env FLUX_API_TOKEN=YOUR_TOKEN FLUX_API_URL=YOUR_API_URL npx\",\n      \"args\": [\"-y\", \"flux-cloudflare-mcp\"]\n    }\n  }\n}\n```\n\n2. Replace `YOUR_TOKEN` with your actual Flux API token and `YOUR_API_URL` with your API URL\n3. Restart Cursor to apply the changes\n\n#### Method 2: Using Cursor MCP Settings\n\n1. Open Cursor and go to Settings\n2. Navigate to the \"MCP\" or \"Model Context Protocol\" section\n3. Click \"Add Server\" or equivalent\n4. Enter the following command in the appropriate field:\n\n```\nenv FLUX_API_TOKEN=YOUR_TOKEN FLUX_API_URL=YOUR_API_URL npx -y flux-cloudflare-mcp\n```\n\n5. Replace `YOUR_TOKEN` with your actual Flux API token and `YOUR_API_URL` with your API URL\n6. Save the settings and restart Cursor if necessary\n\n### Claude Desktop Integration\nenv FLUX_API_TOKEN=YOUR_TOKEN FLUX_API_URL=YOUR_API_URL npx -y flux-cloudflare-mcp\n\n```json\n{\n  \"mcpServers\": {\n    \"flux-cloudflare-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"flux-cloudflare-mcp\"],\n      \"env\": {\n        \"FLUX_API_TOKEN\": \"YOUR_TOKEN\",\n        \"FLUX_API_URL\": \"YOUR_API_URL\"\n      }\n    }\n  }\n}\n```\n\n## ğŸ’» Local Development\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/Hzzy2O/flux-cloudflare-mcp.git\ncd flux-cloudflare-mcp\n```\n\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Build the project:\n\n```bash\nnpm run build\n```\n\n## ğŸ›  Technical Stack\n\n* Model Context Protocol SDK - Core MCP functionality\n* Cloudflare Workers - Serverless API for image generation\n* TypeScript - Type safety and modern JavaScript features\n* Zod - Runtime type validation\n\n## âš™ï¸ Configuration\n\nThe server requires the following environment variables:\n\n- `FLUX_API_TOKEN`: Your API token for authentication with the Flux API\n- `FLUX_API_URL`: The URL of your deployed Flux API (from snakeying/flux-api-worker or aigem/cf-flux-remix)\n\n## ğŸ” Troubleshooting\n\n### Common Issues\n\n#### Authentication Error\n- Ensure your `FLUX_API_TOKEN` is correctly set in the environment\n- Verify your token is valid by testing it with the Flux API directly\n\n#### API Connection Issues\n- Check that your Flux API (Cloudflare Worker) is running and accessible\n- Ensure your network allows connections to Cloudflare Workers\n\n#### Safety Filter Triggered\n- The model has a built-in safety filter that may block certain prompts\n- Try modifying your prompt to avoid potentially problematic content\n\n## ğŸ¤ Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## ğŸ“„ License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## ğŸ”— Resources\n\n- [Model Context Protocol Documentation](https://modelcontextprotocol.io)\n- [Cloudflare Workers Documentation](https://developers.cloudflare.com/workers/)\n- [Flux Model Documentation](https://developer.cloudflare.com/ai-gateway/models/flux-1/)\n- [MCP TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)\n- [snakeying/flux-api-worker](https://github.com/snakeying/flux-api-worker) - Simple Flux API implementation\n- [aigem/cf-flux-remix](https://github.com/aigem/cf-flux-remix) - Feature-rich Flux API with web UI\n\n[![smithery badge](https://smithery.ai/badge/@Hzzy2O/flux-cloudfare-mcp)](https://smithery.ai/server/@Hzzy2O/flux-cloudfare-mcp)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "IA-Programming--mcp-images": {
      "owner": "IA-Programming",
      "name": "mcp-images",
      "url": "https://github.com/IA-Programming/mcp-images",
      "imageUrl": "https://github.com/IA-Programming.png",
      "description": "Fetch and process images from URLs and local file paths, handling automatic compression and MIME type retrieval. Images are returned as base64-encoded strings to facilitate integration and support parallel processing with robust error handling.",
      "stars": 13,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-24T05:36:12Z",
      "readme_content": "# MCP Server - Image\nA Model Context Protocol (MCP) server that provides tools for fetching and processing images from URLs, local file paths, and numpy arrays. The server includes a tool called fetch_images that returns images as base64-encoded strings along with their MIME types.\n\n## Support Us\n\nIf you find this project helpful and would like to support future projects, consider buying us a coffee! Your support helps us continue building innovative AI solutions.\n\n<a href=\"https://www.buymeacoffee.com/blazzmocompany\"><img src=\"https://img.buymeacoffee.com/button-api/?text=Buy me a coffee&emoji=&slug=blazzmocompany&button_colour=40DCA5&font_colour=ffffff&font_family=Cookie&outline_colour=000000&coffee_colour=FFDD00\"></a>\n\nYour contributions go a long way in fueling our passion for creating intelligent and user-friendly applications.\n\n## Table of Contents\n- [Features](#features)\n- [Prerequisites](#prerequisites)\n- [Installation](#installation)\n- [Running the Server](#running-the-server)\n  - [Direct Method](#1-direct-method)\n  - [Configure for Windsurf/Cursor](#2-configure-for-windsurfcursor)\n- [Available Tools](#available-tools)\n  - [Usage Examples](#usage-examples)\n- [Debugging](#debugging)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Features\n- Fetch images from URLs (http/https)\n- Load images from local file paths\n- Specialized handling for large local images\n- Automatic image compression for large images (>1MB)\n- Parallel processing of multiple images\n- Proper MIME type mapping for different file extensions\n- Comprehensive error handling and logging\n## Prerequisites\n- Python 3.10+\n- uv package manager (recommended)\n## Installation\n1. Clone this repository\n2. Create and activate a virtual environment using uv:\n```bash\nuv venv\n# On Windows:\n.venv\\Scripts\\activate\n# On Unix/MacOS:\nsource .venv/bin/activate\n```\n3. Install dependencies using uv:\n```bash\nuv pip install -r requirements.txt\n```\n## Running the Server\nThere are two ways to run the MCP server:\n\n### 1. Direct Method\nTo start the MCP server directly:\n\n```bash\nuv run python mcp_image.py\n```\n### 2. Configure for Windsurf/Cursor\n#### Windsurf\nTo add this MCP server to Windsurf:\n\n1. Edit the configuration file at ~/.codeium/windsurf/mcp_config.json\n2. Add the following configuration:\n```json\n{\n  \"mcpServers\": {\n    \"image\": {\n      \"command\": \"uv\",\n        \"args\": [\"--directory\", \"/path/to/mcp-image\", \"run\", \"mcp_image.py\"]\n    }\n  }\n}\n```\n#### Cursor\nTo add this MCP server to Cursor:\n\n1. Open Cursor and go to *Settings* (Navbar â†’ Cursor Settings)\n2. Navigate to *Features* â†’ *MCP Servers*\n3. Click on + Add New MCP Server\n4. Enter the following configuration:\n```json\n{\n  \"mcpServers\": {\n    \"image\": {\n      \"command\": \"uv\",\n      \"args\": [\"--directory\", \"/path/to/mcp-image\", \"run\", \"mcp_image.py\"]\n    }\n  }\n}\n```\n\n## Available Tools\nThe server provides the following tools:\n\n[fetch_images](mcp_image.py#L318): Fetch and process images from URLs or local file paths\nParameters:\nimage_sources: List of URLs or file paths to images\nReturns:\nList of processed images with base64 encoding and MIME types\n\n### Usage Examples\nYou can now use commands like:\n\n- \"Fetch these images: [list of URLs or file paths]\"\n- \"Load and process this local image: [file_path]\"\n\n#### Examples\n```\n# URL-only test\n[\n  \"https://upload.wikimedia.org/wikipedia/commons/thumb/7/70/Chocolate_%28blue_background%29.jpg/400px-Chocolate_%28blue_background%29.jpg\",\n  \"https://imgs.search.brave.com/Sz7BdlhBoOmU4wZjnUkvgestdwmzOzrfc3GsiMr27Ik/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly9pbWdj/ZG4uc3RhYmxlZGlm/ZnVzaW9ud2ViLmNv/bS8yMDI0LzEwLzE4/LzJmOTY3NTViLTM0/YmQtNDczNi1iNDRh/LWJlMTVmNGM5MDBm/My5qcGc\",\n  \"https://shigacare.fukushi.shiga.jp/mumeixxx/img/main.png\"\n]\n\n# Mixed URL and local file test\n[\n  \"https://upload.wikimedia.org/wikipedia/commons/thumb/7/70/Chocolate_%28blue_background%29.jpg/400px-Chocolate_%28blue_background%29.jpg\",\n  \"C:\\\\Users\\\\username\\\\Pictures\\\\image1.jpg\",\n  \"https://imgs.search.brave.com/Sz7BdlhBoOmU4wZjnUkvgestdwmzOzrfc3GsiMr27Ik/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly9pbWdj/ZG4uc3RhYmxlZGlm/ZnVzaW9ud2ViLmNv/bS8yMDI0LzEwLzE4/LzJmOTY3NTViLTM0/YmQtNDczNi1iNDRh/LWJlMTVmNGM5MDBm/My5qcGc\",\n  \"C:\\\\Users\\\\username\\\\Pictures\\\\image2.jpg\"\n]\n```\n\n## Debugging\nIf you encounter any issues:\n\n1. Check that all dependencies are installed correctly\n2. Verify that the server is running and listening for connections\n3. For local image loading issues, ensure the file paths are correct and accessible\n4. For \"Unsupported image type\" errors, verify the content type handling\n5. Look for any error messages in the server output\n## Contributing\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.",
      "npm_url": "",
      "npm_downloads": 0
    },
    "ifmelate--mcp-image-extractor": {
      "owner": "ifmelate",
      "name": "mcp-image-extractor",
      "url": "https://github.com/ifmelate/mcp-image-extractor",
      "imageUrl": "https://github.com/ifmelate.png",
      "description": "Extracts images from local files and URLs, processing them into base64 format for analysis by large language models (LLMs). Suitable for analyzing image-based data, such as screenshots from tests.",
      "stars": 14,
      "forks": 4,
      "license": "MIT License",
      "language": "HTML",
      "updated_at": "2025-09-21T00:31:03Z",
      "readme_content": "# MCP Image Extractor\n\nMCP server for extracting and converting images to base64 for LLM analysis.\n\nThis MCP server provides tools for AI assistants to:\n- Extract images from local files\n- Extract images from URLs\n- Process base64-encoded images\n\n<a href=\"https://glama.ai/mcp/servers/@ifmelate/mcp-image-extractor\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@ifmelate/mcp-image-extractor/badge\" alt=\"Image Extractor MCP server\" />\n</a>\n\nHow it looks in Cursor:\n\n<img width=\"687\" alt=\"image\" src=\"https://github.com/user-attachments/assets/8954dbbd-7e7a-4f27-82a7-b251bd3c5af2\" />\n\nSuitable cases:\n- analyze playwright test results: screenshots\n\n## Installation\n\n### Recommended: Using npx in mcp.json (Easiest)\n\nThe recommended way to install this MCP server is using npx directly in your `.cursor/mcp.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-extractor\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-image-extractor\"\n      ]\n    }\n  }\n}\n```\n\nThis approach:\n- Automatically installs the latest version\n- Does not require global installation\n- Works reliably across different environments\n\n### Alternative: Local Path Installation\n\nIf you prefer to use a local installation of the package, you can clone the repository and point to the built files:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-extractor\": {\n      \"command\": \"node\",\n      \"args\": [\"/full/path/to/mcp-image-extractor/dist/index.js\"],\n      \"disabled\": false\n    }\n  }\n}\n```\n\n### Manual Installation\n\n```bash\n# Clone and install \ngit clone https://github.com/ifmelate/mcp-image-extractor.git\ncd mcp-image-extractor\nnpm install\nnpm run build\nnpm link\n```\n\nThis will make the `mcp-image-extractor` command available globally.\n\nThen configure in `.cursor/mcp.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-extractor\": {\n      \"command\": \"mcp-image-extractor\",\n      \"disabled\": false\n    }\n  }\n}\n```\n\n> **Troubleshooting for Cursor Users**: If you see \"Failed to create client\" error, try the local path installation method above or ensure you're using the correct path to the executable.\n\n## Available Tools\n\n### extract_image_from_file\n\nExtracts an image from a local file and converts it to base64.\n\nParameters:\n- `file_path` (required): Path to the local image file\n\n**Note:** All images are automatically resized to optimal dimensions (max 512x512) for LLM analysis to limit the size of the base64 output and optimize context window usage.\n\n### extract_image_from_url\n\nExtracts an image from a URL and converts it to base64.\n\nParameters:\n- `url` (required): URL of the image to extract\n\n**Note:** All images are automatically resized to optimal dimensions (max 512x512) for LLM analysis to limit the size of the base64 output and optimize context window usage.\n\n### extract_image_from_base64\n\nProcesses a base64-encoded image for LLM analysis.\n\nParameters:\n- `base64` (required): Base64-encoded image data\n- `mime_type` (optional, default: \"image/png\"): MIME type of the image\n\n**Note:** All images are automatically resized to optimal dimensions (max 512x512) for LLM analysis to limit the size of the base64 output and optimize context window usage.\n\n## Example Usage\n\nHere's an example of how to use the tools from Claude:\n\n```\nPlease extract the image from this local file: images/photo.jpg\n```\n\nClaude will automatically use the `extract_image_from_file` tool to load and analyze the image content.\n\n```\nPlease extract the image from this URL: https://example.com/image.jpg\n```\n\nClaude will automatically use the `extract_image_from_url` tool to fetch and analyze the image content.\n\n## Docker\n\nBuild and run with Docker:\n\n```bash\ndocker build -t mcp-image-extractor .\ndocker run -p 8000:8000 mcp-image-extractor\n```\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0
    },
    "IncomeStreamSurfer--chatgpt-native-image-gen-mcp": {
      "owner": "IncomeStreamSurfer",
      "name": "chatgpt-native-image-gen-mcp",
      "url": "https://github.com/IncomeStreamSurfer/chatgpt-native-image-gen-mcp",
      "imageUrl": "https://github.com/IncomeStreamSurfer.png",
      "description": "Generates and edits images using OpenAI's advanced image generation model based on text prompts. Supports image inpainting and variations, with customizable filenames for automated saving.",
      "stars": 15,
      "forks": 3,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-03T22:33:09Z",
      "readme_content": "# OpenAI Image Generation MCP Server\n\nThis project implements an MCP (Model Context Protocol) server that provides tools for generating and editing images using OpenAI's `gpt-image-1` model via the official Python SDK.\n\n## Features\n\nThis MCP server provides the following tools:\n\n*   **`generate_image`**: Generates an image using OpenAI's `gpt-image-1` model based on a text prompt and saves it.\n    *   **Input Schema:**\n        ```json\n        {\n          \"type\": \"object\",\n          \"properties\": {\n            \"prompt\": { \"type\": \"string\", \"description\": \"The text description of the desired image(s).\" },\n            \"model\": { \"type\": \"string\", \"default\": \"gpt-image-1\", \"description\": \"The model to use (currently 'gpt-image-1').\" },\n            \"n\": { \"type\": [\"integer\", \"null\"], \"default\": 1, \"description\": \"The number of images to generate (Default: 1).\" },\n            \"size\": { \"type\": [\"string\", \"null\"], \"enum\": [\"1024x1024\", \"1536x1024\", \"1024x1536\", \"auto\"], \"default\": \"auto\", \"description\": \"Image dimensions ('1024x1024', '1536x1024', '1024x1536', 'auto'). Default: 'auto'.\" },\n            \"quality\": { \"type\": [\"string\", \"null\"], \"enum\": [\"low\", \"medium\", \"high\", \"auto\"], \"default\": \"auto\", \"description\": \"Rendering quality ('low', 'medium', 'high', 'auto'). Default: 'auto'.\" },\n            \"user\": { \"type\": [\"string\", \"null\"], \"default\": null, \"description\": \"An optional unique identifier representing your end-user.\" },\n            \"save_filename\": { \"type\": [\"string\", \"null\"], \"default\": null, \"description\": \"Optional filename (without extension). If None, a default name based on the prompt and timestamp is used.\" }\n          },\n          \"required\": [\"prompt\"]\n        }\n        ```\n    *   **Output:** `{\"status\": \"success\", \"saved_path\": \"path/to/image.png\"}` or error dictionary.\n\n*   **`edit_image`**: Edits an image or creates variations using OpenAI's `gpt-image-1` model and saves it. Can use multiple input images as reference or perform inpainting with a mask.\n    *   **Input Schema:**\n        ```json\n        {\n          \"type\": \"object\",\n          \"properties\": {\n            \"prompt\": { \"type\": \"string\", \"description\": \"The text description of the desired final image or edit.\" },\n            \"image_paths\": { \"type\": \"array\", \"items\": { \"type\": \"string\" }, \"description\": \"A list of file paths to the input image(s). Must be PNG. < 25MB.\" },\n            \"mask_path\": { \"type\": [\"string\", \"null\"], \"default\": null, \"description\": \"Optional file path to the mask image (PNG with alpha channel) for inpainting. Must be same size as input image(s). < 25MB.\" },\n            \"model\": { \"type\": \"string\", \"default\": \"gpt-image-1\", \"description\": \"The model to use (currently 'gpt-image-1').\" },\n            \"n\": { \"type\": [\"integer\", \"null\"], \"default\": 1, \"description\": \"The number of images to generate (Default: 1).\" },\n            \"size\": { \"type\": [\"string\", \"null\"], \"enum\": [\"1024x1024\", \"1536x1024\", \"1024x1536\", \"auto\"], \"default\": \"auto\", \"description\": \"Image dimensions ('1024x1024', '1536x1024', '1024x1536', 'auto'). Default: 'auto'.\" },\n            \"quality\": { \"type\": [\"string\", \"null\"], \"enum\": [\"low\", \"medium\", \"high\", \"auto\"], \"default\": \"auto\", \"description\": \"Rendering quality ('low', 'medium', 'high', 'auto'). Default: 'auto'.\" },\n            \"user\": { \"type\": [\"string\", \"null\"], \"default\": null, \"description\": \"An optional unique identifier representing your end-user.\" },\n            \"save_filename\": { \"type\": [\"string\", \"null\"], \"default\": null, \"description\": \"Optional filename (without extension). If None, a default name based on the prompt and timestamp is used.\" }\n          },\n          \"required\": [\"prompt\", \"image_paths\"]\n        }\n        ```\n    *   **Output:** `{\"status\": \"success\", \"saved_path\": \"path/to/image.png\"}` or error dictionary.\n\n## Prerequisites\n\n*   Python (3.8 or later recommended)\n*   pip (Python package installer)\n*   An OpenAI API Key (set directly in the script or via the `OPENAI_API_KEY` environment variable - **using environment variables is strongly recommended for security**).\n*   An MCP client environment (like the one used by Cline) capable of managing and launching MCP servers.\n\n## Installation\n\n1.  **Clone the repository:**\n    ```bash\n    git clone https://github.com/IncomeStreamSurfer/chatgpt-native-image-gen-mcp.git\n    cd chatgpt-native-image-gen-mcp\n    ```\n2.  **Set up a virtual environment (Recommended):**\n    ```bash\n    python -m venv venv\n    source venv/bin/activate  # On Windows use `venv\\Scripts\\activate`\n    ```\n3.  **Install dependencies:**\n    ```bash\n    pip install -r requirements.txt\n    ```\n4.  **(Optional but Recommended) Set Environment Variable:**\n    Set the `OPENAI_API_KEY` environment variable with your OpenAI key instead of hardcoding it in the script. How you set this depends on your operating system.\n\n## Configuration (for Cline MCP Client)\n\nTo make this server available to your AI assistant (like Cline), add its configuration to your MCP settings file (e.g., `cline_mcp_settings.json`).\n\nFind the `mcpServers` object in your settings file and add the following entry:\n\n```json\n{\n  \"mcpServers\": {\n    // ... other server configurations ...\n\n    \"openai-image-gen-mcp\": {\n      \"autoApprove\": [\n        \"generate_image\",\n        \"edit_image\"\n      ],\n      \"disabled\": false,\n      \"timeout\": 180, // Increased timeout for potentially long image generation\n      \"command\": \"python\", // Or path to python executable if not in PATH\n      \"args\": [\n        // IMPORTANT: Replace this path with the actual absolute path\n        // to the openai_image_mcp.py file on your system\n        \"C:/path/to/your/cloned/repo/chatgpt-native-image-gen-mcp/openai_image_mcp.py\"\n      ],\n      \"env\": {\n        // If using environment variables for the API key:\n        // \"OPENAI_API_KEY\": \"YOUR_API_KEY_HERE\"\n      },\n      \"transportType\": \"stdio\"\n    }\n\n    // ... other server configurations ...\n  }\n}\n```\n\n**Important:** Replace `C:/path/to/your/cloned/repo/` with the correct absolute path to where you cloned this repository on your machine. Ensure the path separator is correct for your operating system (e.g., use backslashes `\\` on Windows). If you set the API key via environment variable, you can remove it from the script and potentially add it to the `env` section here if your MCP client supports it.\n\n## Running the Server\n\nYou don't typically need to run the server manually. The MCP client (like Cline) will automatically start the server using the `command` and `args` specified in the configuration file when one of its tools is called for the first time.\n\nIf you want to test it manually (ensure dependencies are installed and API key is available):\n```bash\npython openai_image_mcp.py\n```\n\n## Usage\n\nThe AI assistant interacts with the server using the `generate_image` and `edit_image` tools. Images are saved within an `ai-images` subdirectory created where the `openai_image_mcp.py` script is located. The tools return the absolute path to the saved image upon success.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "InhiblabCore--mcp-image-compression": {
      "owner": "InhiblabCore",
      "name": "mcp-image-compression",
      "url": "https://github.com/InhiblabCore/mcp-image-compression",
      "imageUrl": "https://github.com/InhiblabCore.png",
      "description": "Optimizes images by compressing various formats for faster loading and improved user experience, while offering features like offline usage and batch processing. Supports smart compression to balance file size and visual quality based on image content.",
      "stars": 26,
      "forks": 6,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-08-22T03:13:54Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/inhiblabcore-mcp-image-compression-badge.png)](https://mseep.ai/app/inhiblabcore-mcp-image-compression)\n\n# mcp-image-compression\n\n## Project Overview\n\nmcp-image-compression is a high-performance image compression microservice based on MCP (Modal Context Protocol) architecture. This service focuses on providing fast and high-quality image compression capabilities to help developers optimize image resources for websites and applications, improving loading speed and user experience.\n\n## Features\n\n- **Multi-format support**: Compress mainstream image formats including JPEG, PNG, WebP, AVIF\n- **Offline Usage**: No need to connect to the internet to use\n- **Smart compression**: Automatically select optimal compression parameters based on image content\n- **Batch processing**: Support parallel compression of multiple images for improved efficiency\n- **Quality control**: Customizable compression quality to balance file size and visual quality\n\n## TOOLS\n\n1. `image_compression`\n   - Image compression\n   - Inputs:\n     - `urls` (strings): URLs of images to compress\n     - `quality` (int): Quality of compression (0-100)\n     - `format` (string): Format of compressed image (e.g. \"jpeg\", \"png\", \"webp\", \"avif\")\n   - Returns: Compressed images url\n\n## Setup\n\n### NPX\n\n```json\n{\n  \"mcpServers\": {\n    \"Image compression\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@inhiblab-core/mcp-image-compression\"\n      ],\n      \"env\": {\n        \"IMAGE_COMPRESSION_DOWNLOAD_DIR\": \"<YOUR_DIR>\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n## Build\n\n```bash\ndocker build -t mcp-image-compression .\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "jaokuohsuan--draw-things-mcp-cursor": {
      "owner": "jaokuohsuan",
      "name": "draw-things-mcp-cursor",
      "url": "https://github.com/jaokuohsuan/draw-things-mcp-cursor",
      "imageUrl": "https://github.com/jaokuohsuan.png",
      "description": "Generates images based on text prompts using AI, integrating seamlessly within workflows. The server utilizes the Draw Things API to transform user-defined prompts into visual creations.",
      "stars": 12,
      "forks": 4,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-08-16T06:00:20Z",
      "readme_content": "# Draw Things MCP\n\nDraw Things API integration for Cursor using Model Context Protocol (MCP).\n\n## Prerequisites\n\n- Node.js >= 14.0.0\n- Draw Things API running on http://127.0.0.1:7888\n\n## Installation\n\n```bash\n# Install globally\nnpm install -g draw-things-mcp-cursor\n\n# Or run directly\nnpx draw-things-mcp-cursor\n```\n\n## Cursor Integration\n\nTo set up this tool in Cursor, see the detailed guide in [cursor-setup.md](./cursor-setup.md).\n\nQuick setup:\n\n1. Create or edit `~/.cursor/claude_desktop_config.json`:\n```json\n{\n  \"mcpServers\": {\n    \"draw-things\": {\n      \"command\": \"draw-things-mcp-cursor\",\n      \"args\": []\n    }\n  }\n}\n```\n\n2. Restart Cursor\n3. Use in Cursor: `generateImage({\"prompt\": \"a cute cat\"})`\n\n## CLI Usage\n\n### Generate Image\n\n```bash\necho '{\"prompt\": \"your prompt here\"}' | npx draw-things-mcp-cursor\n```\n\n### Parameters\n\n- `prompt`: The text prompt for image generation (required)\n- `negative_prompt`: The negative prompt for image generation\n- `width`: Image width (default: 360)\n- `height`: Image height (default: 360)\n- `steps`: Number of steps for generation (default: 8)\n- `model`: Model to use for generation (default: \"flux_1_schnell_q5p.ckpt\")\n- `sampler`: Sampling method (default: \"DPM++ 2M AYS\")\n\nExample:\n\n```bash\necho '{\n  \"prompt\": \"a happy smiling dog, professional photography\",\n  \"negative_prompt\": \"ugly, deformed, blurry\",\n  \"width\": 360,\n  \"height\": 360,\n  \"steps\": 4\n}' | npx draw-things-mcp-cursor\n```\n\n### MCP Tool Integration\n\nWhen used as an MCP tool in Cursor, the tool will be registered as `generateImage` with the following parameters:\n\n```typescript\n{\n  prompt: string;       // Required - The prompt to generate the image from\n  negative_prompt?: string;  // Optional - The negative prompt\n  width?: number;       // Optional - Image width (default: 360)\n  height?: number;      // Optional - Image height (default: 360)\n  model?: string;       // Optional - Model name\n  steps?: number;       // Optional - Number of steps (default: 8)\n}\n```\n\nThe generated images will be saved in the `images` directory with a filename format of:\n`<sanitized_prompt>_<timestamp>.png`\n\n## Response Format\n\nSuccess:\n```json\n{\n  \"type\": \"success\",\n  \"content\": [{\n    \"type\": \"image\",\n    \"data\": \"base64 encoded image data\",\n    \"mimeType\": \"image/png\"\n  }],\n  \"metadata\": {\n    \"parameters\": { ... }\n  }\n}\n```\n\nError:\n```json\n{\n  \"type\": \"error\",\n  \"error\": \"error message\",\n  \"code\": 500\n}\n```\n\n## Troubleshooting\n\nIf you encounter issues:\n\n- Ensure Draw Things API is running at http://127.0.0.1:7888\n- Check log files in `~/.cursor/logs` if using with Cursor\n- Make sure src/index.js has execution permissions: `chmod +x src/index.js`\n\n## License\n\nMIT ",
      "npm_url": "",
      "npm_downloads": 0
    },
    "jbrower95--mcp-asset-gen": {
      "owner": "jbrower95",
      "name": "mcp-asset-gen",
      "url": "https://github.com/jbrower95/mcp-asset-gen",
      "imageUrl": "https://github.com/jbrower95.png",
      "description": "Generate high-quality image assets for game or web development by providing descriptive prompts. Streamline asset creation workflows with automated image generation through AI.",
      "stars": 3,
      "forks": 5,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-08-05T20:41:33Z",
      "readme_content": "# mcp-asset-gen\n[![npm version](https://badge.fury.io/js/mcp-asset-gen.svg)](https://badge.fury.io/js/mcp-asset-gen)\n\n\nThis tool allows Claude to speak to OpenAI, and use `gpt-image-1` to generate image assets. This can be pretty useful for game or web development, when you need to print individual assets.\n\n# Requirements\n\n- Node \n- An OpenAI [API Key](https://platform.openai.com/settings/organization/api-keys)\n    - Note that this requires an organization, with ID verification at the moment.\n\n# Installation\n\n1. Get an API KEY from the [OpenAI website](https://platform.openai.com/settings/organization/api-keys).\n\n2. Export it in your shell as API_KEY.\n\n```bash\nexport API_KEY=sk-proj-....\n```\n\n3. Then, paste this into that same shell:\n\n```bash\njq --arg apiKey \"$API_KEY\" \\\n'.mcpServers = (.mcpServers // {}) | \n .mcpServers[\"mcp-asset-gen\"] = {\n   type: \"stdio\",\n   command: \"npx\",\n   args: [\"mcp-asset-gen\"],\n   env: { API_KEY: $apiKey }\n }' ~/.claude.json > ~/.claude.tmp && mv ~/.claude.tmp ~/.claude.json\n```\n\n4. You're done! Ask Claude to generate you an image for something, and you'll see\n\n```\n> generate a small logo image that i could use for my arcade game\n\n I'll generate a logo for your arcade game. Please provide a more specific description of what you'd like to see in the logo (colors, style,\n  game theme, etc.) for better results.\n\n> It should look like an old school pacman machine (liek a wooden arcade machine)\n\nâº mcp-asset-gen:generateImag(outputPathAbsolute: \"/Users/jbrower/projects/mcp-asset-gen/arcade-logo.png\", prompt: \"An old school wooden arcadeâ€¦\n   (MCP)                    machine logo in the style of Pacman, with retro colors and pixelated elements, top-down view of the cabinet,\n                            nostalgic arcade gaming feel, vibrant colors against dark background\", quality: \"high\", size: \"1024x1024\")\nÂ Â â¿ Â The image is now available at /Users/jbrower/projects/mcp-asset-gen/arcade-logo.png.\n\nâº Generated arcade logo saved to /Users/jbrower/projects/mcp-asset-gen/arcade-logo.png\n```\n\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "JeremyNixon--mcp-fetch": {
      "owner": "JeremyNixon",
      "name": "mcp-fetch",
      "url": "https://github.com/JeremyNixon/mcp-fetch",
      "imageUrl": "https://github.com/JeremyNixon.png",
      "description": "Fetches web content and processes images for integration with AI models, streamlining the retrieval and handling of online content in various applications.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-03-15T18:56:32Z",
      "readme_content": "# MCP Fetch\n\n[![smithery badge](https://smithery.ai/badge/@kazuph/mcp-fetch)](https://smithery.ai/server/@kazuph/mcp-fetch)\n\nModel Context Protocol server for fetching web content and processing images. This allows Claude Desktop (or any MCP client) to fetch web content and handle images appropriately.\n\n## Quick Start (For Users)\n\nTo use this tool with Claude Desktop, simply add the following to your Claude Desktop configuration (`~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"tools\": {\n    \"fetch\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@kazuph/mcp-fetch\"]\n    }\n  }\n}\n```\n\nThis will automatically download and run the latest version of the tool when needed.\n\n### Required Setup\n\n1. Enable Accessibility for Claude:\n   - Open System Settings\n   - Go to Privacy & Security > Accessibility\n   - Click the \"+\" button\n   - Add Claude from your Applications folder\n   - Turn ON the toggle for Claude\n\nThis accessibility setting is required for automated clipboard operations (Cmd+V) to work properly.\n\n## For Developers\n\nThe following sections are for those who want to develop or modify the tool.\n\n## Prerequisites\n\n- Node.js 18+\n- macOS (for clipboard operations)\n- Claude Desktop (install from https://claude.ai/desktop)\n- tsx (install via `npm install -g tsx`)\n\n## Installation\n\n### Installing via Smithery\n\nTo install MCP Fetch for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@kazuph/mcp-fetch):\n\n```bash\nnpx -y @smithery/cli install @kazuph/mcp-fetch --client claude\n```\n\n### Manual Installation\n```bash\ngit clone https://github.com/kazuph/mcp-fetch.git\ncd mcp-fetch\nnpm install\nnpm run build\n```\n\n## Image Processing Specifications\n\nWhen processing images from web content, the following limits are applied:\n\n- Maximum 6 images per group\n- Maximum height of 8000 pixels per group\n- Maximum size of 30MB per group\n\nIf content exceeds these limits, images will be automatically split into multiple groups, and you'll need to paste (Cmd+V) multiple times.\n\n## Configuration\n\n1. Make sure Claude Desktop is installed and running.\n\n2. Install tsx globally if you haven't:\n```bash\nnpm install -g tsx\n# or\npnpm add -g tsx\n```\n\n3. Modify your Claude Desktop config located at:\n`~/Library/Application Support/Claude/claude_desktop_config.json`\n\nYou can easily find this through the Claude Desktop menu:\n1. Open Claude Desktop\n2. Click Claude on the Mac menu bar\n3. Click \"Settings\"\n4. Click \"Developer\"\n\nAdd the following to your MCP client's configuration:\n\n```json\n{\n  \"tools\": {\n    \"fetch\": {\n      \"args\": [\"tsx\", \"/path/to/mcp-fetch/index.ts\"]\n    }\n  }\n}\n```\n\n## Available Tools\n\n- `fetch`: Retrieves URLs from the Internet and extracts their content as markdown. Images are automatically processed and prepared for clipboard operations.\n\n## Notes\n\n- This tool is designed for macOS only due to its dependency on macOS-specific clipboard operations.\n- Images are processed using Sharp for optimal performance and quality.\n- When multiple images are found, they are merged vertically with consideration for size limits.\n- Animated GIFs are automatically handled by extracting their first frame.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "jezweb--openai-mcp": {
      "owner": "jezweb",
      "name": "openai-mcp",
      "url": "https://github.com/jezweb/openai-mcp",
      "imageUrl": "https://github.com/jezweb.png",
      "description": "Connect to OpenAI's DALL-E API for image generation with support for various options, enabling seamless integration into MCP-compatible AI assistants like Roo Code.",
      "stars": 1,
      "forks": 3,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-04-24T08:28:31Z",
      "readme_content": "# OpenAI MCP - DALL-E API Integration for Roo Code\n\nThis project provides a Model Context Protocol (MCP) server for connecting to OpenAI's DALL-E API for image generation with full support for all available options. It's specifically designed to work with Roo Code and other MCP-compatible AI assistants.\n\n## Overview\n\nThis MCP server provides a tool for DALL-E image generation with comprehensive support for all DALL-E API options. It allows AI assistants like Roo Code to generate images through the Model Context Protocol (MCP) with fine-grained control over the generation process.\n\n## Project Structure\n\n- `src/` - Source code for the MCP server\n  - `dalle.ts` - Implementation of the DALL-E API integration with all options\n  - `index.ts` - Main server file with the DALL-E tool and input schema\n  - `install.ts` - Installation script for Roo Code and Claude Desktop\n- `build/` - Compiled JavaScript files\n- `dalle-test.html` - HTML page to display the generated image and document available options\n- `test-dalle.js` - Direct test script for the DALL-E API with examples of different options\n\n## Setup Instructions for Roo Code\n\n### Installation\n\n1. Install the package globally:\n   ```\n   npm install -g openai-mcp\n   ```\n\n2. Run the setup command to configure Roo Code:\n   ```\n   openai-mcp install\n   ```\n\n3. Set your OpenAI API key in Roo Code settings:\n   - Open Roo Code\n   - Go to Settings\n   - Add the following environment variable to the MCP server configuration:\n     ```json\n     \"openai-mcp\": {\n       \"env\": {\n         \"OPENAI_API_KEY\": \"your-openai-api-key\"\n       }\n     }\n     ```\n\n4. Restart Roo Code",
      "npm_url": "",
      "npm_downloads": 0
    },
    "jhacksman--OpenSCAD-MCP-Server": {
      "owner": "jhacksman",
      "name": "OpenSCAD-MCP-Server",
      "url": "https://github.com/jhacksman/OpenSCAD-MCP-Server",
      "imageUrl": "https://github.com/jhacksman.png",
      "description": "Generates 3D models from text descriptions or images, focusing on parametric model creation through multi-view reconstruction and integration with OpenSCAD. Facilitates remote processing and includes an image approval workflow for model generation.",
      "stars": 84,
      "forks": 17,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-03T04:21:59Z",
      "readme_content": "# OpenSCAD MCP Server\n\nA Model Context Protocol (MCP) server that enables users to generate 3D models from text descriptions or images, with a focus on creating parametric 3D models using multi-view reconstruction and OpenSCAD.\n\n## Features\n\n- **AI Image Generation**: Generate images from text descriptions using Google Gemini or Venice.ai APIs\n- **Multi-View Image Generation**: Create multiple views of the same 3D object for reconstruction\n- **Image Approval Workflow**: Review and approve/deny generated images before reconstruction\n- **3D Reconstruction**: Convert approved multi-view images into 3D models using CUDA Multi-View Stereo\n- **Remote Processing**: Process computationally intensive tasks on remote servers within your LAN\n- **OpenSCAD Integration**: Generate parametric 3D models using OpenSCAD\n- **Parametric Export**: Export models in formats that preserve parametric properties (CSG, AMF, 3MF, SCAD)\n- **3D Printer Discovery**: Optional network printer discovery and direct printing\n\n## Architecture\n\nThe server is built using the Python MCP SDK and follows a modular architecture:\n\n```\nopenscad-mcp-server/\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ main.py                  # Main application\nâ”‚   â”œâ”€â”€ main_remote.py           # Remote CUDA MVS server\nâ”‚   â”œâ”€â”€ ai/                      # AI integrations\nâ”‚   â”‚   â”œâ”€â”€ gemini_api.py        # Google Gemini API for image generation\nâ”‚   â”‚   â””â”€â”€ venice_api.py        # Venice.ai API for image generation (optional)\nâ”‚   â”œâ”€â”€ models/                  # 3D model generation\nâ”‚   â”‚   â”œâ”€â”€ cuda_mvs.py          # CUDA Multi-View Stereo integration\nâ”‚   â”‚   â””â”€â”€ code_generator.py    # OpenSCAD code generation\nâ”‚   â”œâ”€â”€ workflow/                # Workflow components\nâ”‚   â”‚   â”œâ”€â”€ image_approval.py    # Image approval mechanism\nâ”‚   â”‚   â””â”€â”€ multi_view_to_model_pipeline.py  # Complete pipeline\nâ”‚   â”œâ”€â”€ remote/                  # Remote processing\nâ”‚   â”‚   â”œâ”€â”€ cuda_mvs_client.py   # Client for remote CUDA MVS processing\nâ”‚   â”‚   â”œâ”€â”€ cuda_mvs_server.py   # Server for remote CUDA MVS processing\nâ”‚   â”‚   â”œâ”€â”€ connection_manager.py # Remote connection management\nâ”‚   â”‚   â””â”€â”€ error_handling.py    # Error handling for remote processing\nâ”‚   â”œâ”€â”€ openscad_wrapper/        # OpenSCAD CLI wrapper\nâ”‚   â”œâ”€â”€ visualization/           # Preview generation and web interface\nâ”‚   â”œâ”€â”€ utils/                   # Utility functions\nâ”‚   â””â”€â”€ printer_discovery/       # 3D printer discovery\nâ”œâ”€â”€ scad/                        # Generated OpenSCAD files\nâ”œâ”€â”€ output/                      # Output files (models, previews)\nâ”‚   â”œâ”€â”€ images/                  # Generated images\nâ”‚   â”œâ”€â”€ multi_view/              # Multi-view images\nâ”‚   â”œâ”€â”€ approved_images/         # Approved images for reconstruction\nâ”‚   â””â”€â”€ models/                  # Generated 3D models\nâ”œâ”€â”€ templates/                   # Web interface templates\nâ””â”€â”€ static/                      # Static files for web interface\n```\n\n## Installation\n\n1. Clone the repository:\n   ```\n   git clone https://github.com/jhacksman/OpenSCAD-MCP-Server.git\n   cd OpenSCAD-MCP-Server\n   ```\n\n2. Create a virtual environment:\n   ```\n   python -m venv venv\n   source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n   ```\n\n3. Install dependencies:\n   ```\n   pip install -r requirements.txt\n   ```\n\n4. Install OpenSCAD:\n   - Ubuntu/Debian: `sudo apt-get install openscad`\n   - macOS: `brew install openscad`\n   - Windows: Download from [openscad.org](https://openscad.org/downloads.html)\n\n5. Install CUDA Multi-View Stereo:\n   ```\n   git clone https://github.com/fixstars/cuda-multi-view-stereo.git\n   cd cuda-multi-view-stereo\n   mkdir build && cd build\n   cmake ..\n   make\n   ```\n\n6. Set up API keys:\n   - Create a `.env` file in the root directory\n   - Add your API keys:\n     ```\n     GEMINI_API_KEY=your-gemini-api-key\n     VENICE_API_KEY=your-venice-api-key  # Optional\n     REMOTE_CUDA_MVS_API_KEY=your-remote-api-key  # For remote processing\n     ```\n\n## Remote Processing Setup\n\nThe server supports remote processing of computationally intensive tasks, particularly CUDA Multi-View Stereo reconstruction. This allows you to offload processing to more powerful machines within your LAN.\n\n### Server Setup (on the machine with CUDA GPU)\n\n1. Install CUDA Multi-View Stereo on the server machine:\n   ```\n   git clone https://github.com/fixstars/cuda-multi-view-stereo.git\n   cd cuda-multi-view-stereo\n   mkdir build && cd build\n   cmake ..\n   make\n   ```\n\n2. Start the remote CUDA MVS server:\n   ```\n   python src/main_remote.py\n   ```\n\n3. The server will automatically advertise itself on the local network using Zeroconf.\n\n### Client Configuration\n\n1. Configure remote processing in your `.env` file:\n   ```\n   REMOTE_CUDA_MVS_ENABLED=True\n   REMOTE_CUDA_MVS_USE_LAN_DISCOVERY=True\n   REMOTE_CUDA_MVS_API_KEY=your-shared-secret-key\n   ```\n\n2. Alternatively, you can specify a server URL directly:\n   ```\n   REMOTE_CUDA_MVS_ENABLED=True\n   REMOTE_CUDA_MVS_USE_LAN_DISCOVERY=False\n   REMOTE_CUDA_MVS_SERVER_URL=http://server-ip:8765\n   REMOTE_CUDA_MVS_API_KEY=your-shared-secret-key\n   ```\n\n### Remote Processing Features\n\n- **Automatic Server Discovery**: Find CUDA MVS servers on your local network\n- **Job Management**: Upload images, track job status, and download results\n- **Fault Tolerance**: Automatic retries, circuit breaker pattern, and error tracking\n- **Authentication**: Secure API key authentication for all remote operations\n- **Health Monitoring**: Continuous server health checks and status reporting\n\n## Usage\n\n1. Start the server:\n   ```\n   python src/main.py\n   ```\n\n2. The server will start on http://localhost:8000\n\n3. Use the MCP tools to interact with the server:\n\n   - **generate_image_gemini**: Generate an image using Google Gemini API\n     ```json\n     {\n       \"prompt\": \"A low-poly rabbit with black background\",\n       \"model\": \"gemini-2.0-flash-exp-image-generation\"\n     }\n     ```\n\n   - **generate_multi_view_images**: Generate multiple views of the same 3D object\n     ```json\n     {\n       \"prompt\": \"A low-poly rabbit\",\n       \"num_views\": 4\n     }\n     ```\n\n   - **create_3d_model_from_images**: Create a 3D model from approved multi-view images\n     ```json\n     {\n       \"image_ids\": [\"view_1\", \"view_2\", \"view_3\", \"view_4\"],\n       \"output_name\": \"rabbit_model\"\n     }\n     ```\n\n   - **create_3d_model_from_text**: Complete pipeline from text to 3D model\n     ```json\n     {\n       \"prompt\": \"A low-poly rabbit\",\n       \"num_views\": 4\n     }\n     ```\n\n   - **export_model**: Export a model to a specific format\n     ```json\n     {\n       \"model_id\": \"your-model-id\",\n       \"format\": \"obj\"  // or \"stl\", \"ply\", \"scad\", etc.\n     }\n     ```\n\n   - **discover_remote_cuda_mvs_servers**: Find CUDA MVS servers on your network\n     ```json\n     {\n       \"timeout\": 5\n     }\n     ```\n\n   - **get_remote_job_status**: Check the status of a remote processing job\n     ```json\n     {\n       \"server_id\": \"server-id\",\n       \"job_id\": \"job-id\"\n     }\n     ```\n\n   - **download_remote_model_result**: Download a completed model from a remote server\n     ```json\n     {\n       \"server_id\": \"server-id\",\n       \"job_id\": \"job-id\",\n       \"output_name\": \"model-name\"\n     }\n     ```\n\n   - **discover_printers**: Discover 3D printers on the network\n     ```json\n     {}\n     ```\n\n   - **print_model**: Print a model on a connected printer\n     ```json\n     {\n       \"model_id\": \"your-model-id\",\n       \"printer_id\": \"your-printer-id\"\n     }\n     ```\n\n## Image Generation Options\n\nThe server supports multiple image generation options:\n\n1. **Google Gemini API** (Default): Uses the Gemini 2.0 Flash Experimental model for high-quality image generation\n   - Supports multi-view generation with consistent style\n   - Requires a Google Gemini API key\n\n2. **Venice.ai API** (Optional): Alternative image generation service\n   - Supports various models including flux-dev and fluently-xl\n   - Requires a Venice.ai API key\n\n3. **User-Provided Images**: Skip image generation and use your own images\n   - Upload images directly to the server\n   - Useful for working with existing photographs or renders\n\n## Multi-View Workflow\n\nThe server implements a multi-view workflow for 3D reconstruction:\n\n1. **Image Generation**: Generate multiple views of the same 3D object\n2. **Image Approval**: Review and approve/deny each generated image\n3. **3D Reconstruction**: Convert approved images into a 3D model using CUDA MVS\n   - Can be processed locally or on a remote server within your LAN\n4. **Model Refinement**: Optionally refine the model using OpenSCAD\n\n## Remote Processing Workflow\n\nThe remote processing workflow allows you to offload computationally intensive tasks to more powerful machines:\n\n1. **Server Discovery**: Automatically discover CUDA MVS servers on your network\n2. **Image Upload**: Upload approved multi-view images to the remote server\n3. **Job Processing**: Process the images on the remote server using CUDA MVS\n4. **Status Tracking**: Monitor the job status and progress\n5. **Result Download**: Download the completed 3D model when processing is finished\n\n## Supported Export Formats\n\nThe server supports exporting models in various formats:\n\n- **OBJ**: Wavefront OBJ format (standard 3D model format)\n- **STL**: Standard Triangle Language (for 3D printing)\n- **PLY**: Polygon File Format (for point clouds and meshes)\n- **SCAD**: OpenSCAD source code (for parametric models)\n- **CSG**: OpenSCAD CSG format (preserves all parametric properties)\n- **AMF**: Additive Manufacturing File Format (preserves some metadata)\n- **3MF**: 3D Manufacturing Format (modern replacement for STL with metadata)\n\n## Web Interface\n\nThe server provides a web interface for:\n\n- Generating and approving multi-view images\n- Previewing 3D models from different angles\n- Downloading models in various formats\n\nAccess the interface at http://localhost:8000/ui/\n\n## License\n\nMIT\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "JigsawStack--jigsawstack-mcp-server": {
      "owner": "JigsawStack",
      "name": "jigsawstack-mcp-server",
      "url": "https://github.com/JigsawStack/jigsawstack-mcp-server",
      "imageUrl": "https://github.com/JigsawStack.png",
      "description": "Generate images from text using advanced AI models. The server facilitates the integration and management of image generation tools within an MCP framework.",
      "stars": 23,
      "forks": 5,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-22T15:15:38Z",
      "readme_content": "# JigsawStack MCP Server\n\n## Introduction\nJigsawStack MCP (Model Context Protocol) Server is a versatile platform designed to facilitate the integration and management of various tools. Each directory within the server represents a distinct tool that can be utilized for different purposes by an LLM. The server is built using Node.js and Express.js, and each tool is encapsulated within its own directory, making it easy to add, remove, or update tools without affecting the overall system.\n\nStart by obtaining your JIGSAWSTACK_API_KEY from the our website. You will need this key to access the JigsawStack services. You can get your API key by signing up for a free account at [JigsawStack](https://jigsawstack.com/dashboard).\n\nYou can also install our MCPs via [Smithery AI](https://smithery.ai/?q=jigsawstack)\n\n## Installation\n\n### Prerequisites\n- Ensure you have `git` installed on your system.\n- Ensure you have `node.js` and `npm` installed.\n- Alternatively, you can use `yarn` instead of `npm`. as a package manager.\n\n### Steps to Setup the repository:\n1. Clone the repository:\n    ```sh\n    git clone https://github.com/yourusername/jigsawstack-mcp-server.git\n    ```\n2. Navigate to the project directory:\n    ```sh\n    cd jigsawstack-mcp-server\n    ```\n3. Install the necessary dependencies:\n    ```sh\n    npm install or yarn install\n    ```\n\n## What is MCP?\nMCP stands for Model Context Protocol. It is a framework that allows users to integrate LLMs and manage various tools and components exposing external data in a modular fashion. Here each tool is encapsulated within its own directory, making it easy to add, remove, or update tools without affecting the overall system.\n\n## Using JigsawStack MCP Server\nThere are four tools available in the MCP Server. Each tool is contained within its own directory and has its own set of instructions for use.\n\n### Running a tool\nTo run a tool,\n1. cd into the tool directory and follow the instructions.\n2. Export the JIGSAWSTACK_API_KEY environment variable with your JIGSAWSTACK API key.\n    ```sh\n    export JIGSAWSTACK_API_KEY=your_api_key\n    ```\n3. Start the server:\n    ```sh\n    npm start\n    ```\n4. Access the server through your web browser at `http://localhost:3000`.\n\n### Directory Structure\n- `/ai-web-scraper`: Let AI scrape the internet for you!\n- `/ai-web-search`: Search powered by AI capable of handling complex queries.\n- `/image-generation`: Generate images using prompts, to receive a base64 string of the image.\n\n## Contact\nFor any questions or issues, please contact us at hello@jigsawstack.com.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "jmanhype--mcp-flux-studio": {
      "owner": "jmanhype",
      "name": "mcp-flux-studio",
      "url": "https://github.com/jmanhype/mcp-flux-studio",
      "imageUrl": "https://github.com/jmanhype.png",
      "description": "Integrates advanced image generation capabilities from Flux into AI coding assistants, enabling seamless text-to-image generation and manipulation within development environments.",
      "stars": 20,
      "forks": 6,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-11T12:07:21Z",
      "readme_content": "# MCP Flux Studio\n\n[![smithery badge](https://smithery.ai/badge/@jmanhype/mcp-flux-studio)](https://smithery.ai/server/@jmanhype/mcp-flux-studio)\n\nA powerful Model Context Protocol (MCP) server that brings Flux's advanced image generation capabilities to your AI coding assistants. This server enables direct integration of Flux's image generation, manipulation, and control features into Cursor and Windsurf (Codeium) IDEs.\n\n## Overview\n\nMCP Flux Studio bridges the gap between AI coding assistants and Flux's powerful image generation API, allowing seamless integration of image generation capabilities directly into your development workflow.\n\n### Features\n\n- **Image Generation**\n  - Text-to-image generation with precise control\n  - Multiple model support (flux.1.1-pro, flux.1-pro, flux.1-dev, flux.1.1-ultra)\n  - Customizable aspect ratios and dimensions\n\n- **Image Manipulation**\n  - Image-to-image transformation\n  - Inpainting with customizable masks\n  - Resolution upscaling and enhancement\n\n- **Advanced Controls**\n  - Edge-based generation (canny)\n  - Depth-aware generation\n  - Pose-guided generation\n\n- **IDE Integration**\n  - Full support for Cursor (v0.45.7+)\n  - Compatible with Windsurf/Codeium Cascade (Wave 3+)\n  - Seamless tool invocation through AI assistants\n\n## Quick Start\n\n1. **Prerequisites**\n   - Node.js 18+\n   - Python 3.12+\n   - Flux API key\n   - Compatible IDE (Cursor or Windsurf)\n\n2. **Installation**\n\n### Installing via Smithery\n\nTo install Flux Studio for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@jmanhype/mcp-flux-studio):\n\n```bash\nnpx -y @smithery/cli install @jmanhype/mcp-flux-studio --client claude\n```\n\n### Manual Installation\n   ```bash\n   git clone https://github.com/jmanhype/mcp-flux-studio.git\n   cd mcp-flux-studio\n   npm install\n   npm run build\n   ```\n\n3. **Basic Configuration**\n   ```env\n   BFL_API_KEY=your_flux_api_key\n   FLUX_PATH=/path/to/flux/installation\n   ```\n\nFor detailed setup instructions, including IDE-specific configuration and troubleshooting, see our [Installation Guide](docs/INSTALLATION.md).\n\n## Documentation\n\n- [Installation Guide](docs/INSTALLATION.md) - Comprehensive setup instructions\n- [API Documentation](docs/API.md) - Detailed tool documentation\n- [Example Usage](examples/tool-examples.md) - Real-world usage examples\n- [Contributing Guidelines](docs/CONTRIBUTING.md) - How to contribute\n\n## IDE Integration\n\n### Cursor (v0.45.7+)\n\nMCP Flux Studio integrates seamlessly with Cursor's AI assistant:\n\n1. **Configuration**\n   - Configure via Settings > Features > MCP\n   - Supports both stdio and SSE connections\n   - Environment variables can be set via wrapper scripts\n\n2. **Usage**\n   - Tools automatically available to Cursor's AI assistant\n   - Tool invocations require user approval\n   - Real-time feedback on generation progress\n\n### Windsurf/Codeium (Wave 3+)\n\nIntegration with Windsurf's Cascade AI:\n\n1. **Configuration**\n   - Edit `~/.codeium/windsurf/mcp_config.json`\n   - Supports process-based tool execution\n   - Environment variables configured in JSON\n\n2. **Usage**\n   - Access tools through Cascade's MCP toolbar\n   - Automatic tool discovery and loading\n   - Integrated with Cascade's AI capabilities\n\nFor detailed IDE-specific setup instructions, see the [Installation Guide](docs/INSTALLATION.md).\n\n## Usage\n\nThe server provides the following tools:\n\n### generate\nGenerate an image from a text prompt.\n```json\n{\n  \"prompt\": \"A photorealistic cat\",\n  \"model\": \"flux.1.1-pro\",\n  \"aspect_ratio\": \"1:1\",\n  \"output\": \"generated.jpg\"\n}\n```\n\n### img2img\nGenerate an image using another image as reference.\n```json\n{\n  \"image\": \"input.jpg\",\n  \"prompt\": \"Convert to oil painting\",\n  \"model\": \"flux.1.1-pro\",\n  \"strength\": 0.85,\n  \"output\": \"output.jpg\",\n  \"name\": \"oil_painting\"\n}\n```\n\n### inpaint\nInpaint an image using a mask.\n```json\n{\n  \"image\": \"input.jpg\",\n  \"prompt\": \"Add flowers\",\n  \"mask_shape\": \"circle\",\n  \"position\": \"center\",\n  \"output\": \"inpainted.jpg\"\n}\n```\n\n### control\nGenerate an image using structural control.\n```json\n{\n  \"type\": \"canny\",\n  \"image\": \"control.jpg\",\n  \"prompt\": \"A realistic photo\",\n  \"output\": \"controlled.jpg\"\n}\n```\n\n## Development\n\n### Project Structure\n\n```\nflux-mcp-server/\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ index.ts          # Main server implementation\nâ”‚   â””â”€â”€ types.ts          # TypeScript type definitions\nâ”œâ”€â”€ tests/\nâ”‚   â””â”€â”€ server.test.ts    # Server tests\nâ”œâ”€â”€ docs/\nâ”‚   â”œâ”€â”€ API.md           # API documentation\nâ”‚   â””â”€â”€ CONTRIBUTING.md  # Contribution guidelines\nâ”œâ”€â”€ examples/\nâ”‚   â”œâ”€â”€ generate.json    # Example tool usage\nâ”‚   â””â”€â”€ config.json      # Example configuration\nâ”œâ”€â”€ package.json\nâ”œâ”€â”€ tsconfig.json\nâ””â”€â”€ README.md\n```\n\n### Running Tests\n\n```bash\nnpm test\n```\n\n### Building\n\n```bash\nnpm run build\n```\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](docs/CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\n- [Model Context Protocol](https://github.com/modelcontextprotocol/mcp) - The protocol specification\n- [Flux API](https://flux.ai) - The underlying image generation API\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "joshmouch--mcp-image-generator": {
      "owner": "joshmouch",
      "name": "mcp-image-generator",
      "url": "https://github.com/joshmouch/mcp-image-generator",
      "imageUrl": "https://github.com/null.png",
      "description": "Generate, edit, and create variations of images using OpenAI's DALL-E API, supporting multiple DALL-E models with customizable parameters. Validate OpenAI API keys for seamless operation.",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0
    },
    "jyjune--mcp_vms": {
      "owner": "jyjune",
      "name": "mcp_vms",
      "url": "https://github.com/jyjune/mcp_vms",
      "imageUrl": "https://github.com/jyjune.png",
      "description": "Connects to CCTV recording software to retrieve live and recorded video streams, manage video channel information, and control VMS features like PTZ camera presets and playback dialogs.",
      "stars": 10,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T17:24:47Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/jyjune-mcp-vms-badge.png)](https://mseep.ai/app/jyjune-mcp-vms)\n\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/jyjune/mcp_vms)](https://archestra.ai/mcp-catalog/jyjune__mcp_vms)\n\n# MCP Server - VMS Integration\n\nA Model Context Protocol (MCP) server designed to connect to a CCTV recording program (VMS) to retrieve recorded and live video streams. It also provides tools to control the VMS software, such as showing live or playback dialogs for specific channels at specified times.\n\n![diagram](https://github.com/jyjune/mcp_vms/blob/main/mcp_vms_diagram.png?raw=true)\n\n## Features\n\n- Retrieve video channel information, including connection and recording status.\n- Fetch recording dates and times for specific channels.\n- Fetch live or recorded images from video channels.\n- Show live video streams or playback dialogs for specific channels and timestamps.\n- Control PTZ (Pan-Tilt-Zoom) cameras by moving them to preset positions.\n- Comprehensive error handling and logging.\n\n## Prerequisites\n\n- Python 3.12+\n- `vmspy` library (for VMS integration)\n- `Pillow` library (for image processing)\n\n## MCP-server Configuration\n\nIf you want to use `mcp-vms` with Claude desktop, you need to set up the `claude_desktop_config.json` file as follows:\n\n```json\n{\n  \"mcpServers\": {\n\t\"vms\": {\n\t  \"command\": \"uv\",\n\t  \"args\": [\n\t\t\"--directory\",\n\t\t\"X:\\\\path\\\\to\\\\mcp-vms\",\n\t\t\"run\",\n\t\t\"mcp_vms.py\"\n\t  ]\n\t}\n  }\n}\n```\n\n## VMS Connection Configuration\n\nThe server uses the following default configuration for connecting to the VMS:\n- mcp_vms_config.py\n```python\nvms_config = {\n    'img_width': 320,\n    'img_height': 240,\n    'pixel_format': 'RGB',\n    'url': '127.0.0.1',\n    'port': 3300,\n    'access_id': 'admin',\n    'access_pw': 'admin',\n}\n```\n\n## Installation\n\n### 1. Install UV Package Manager\nRun the following command in PowerShell to install `UV`:\n\n```shell\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\nFor alternative installation methods, see the [official UV documentation](https://docs.astral.sh/uv/getting-started/installation/).\n\n### 2.Install VMS Server\n   Download and install the VMS server from:  \n   [http://surveillance-logic.com/en/download.html](http://surveillance-logic.com/en/download.html)\n   (Required before using this MCP server)\n\n### 3.Install Python Dependencies\n   Download the vmspy library:  \n   [vmspy1.4-python3.12-x64.zip](https://sourceforge.net/projects/security-vms/files/vmspy1.4-python3.12-x64.zip/download)\n   Extract the contents into your `mcp_vms` directory\n\nThe mcp-vms directory should look like this:\n\n```shell\nmcp-vms/\nâ”œâ”€â”€ .gitignore\nâ”œâ”€â”€ .python-version\nâ”œâ”€â”€ LICENSE\nâ”œâ”€â”€ README.md\nâ”œâ”€â”€ pyproject.toml\nâ”œâ”€â”€ uv.lock\nâ”œâ”€â”€ mcp_vms.py            # Main server implementation\nâ”œâ”€â”€ mcp_vms_config.py     # VMS connection configuration\nâ”œâ”€â”€ vmspy.pyd             # VMS Python library\nâ”œâ”€â”€ avcodec-61.dll        # FFmpeg libraries\nâ”œâ”€â”€ avutil-59.dll\nâ”œâ”€â”€ swresample-5.dll\nâ”œâ”€â”€ swscale-8.dll\n```\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/7027c4cd-a9c1-43dd-9e74-771fc7cc42da)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "kazuph--mcp-screenshot": {
      "owner": "kazuph",
      "name": "mcp-screenshot",
      "url": "https://github.com/kazuph/mcp-screenshot",
      "imageUrl": "https://github.com/kazuph.png",
      "description": "Captures screenshots and performs OCR text recognition on macOS. Supports both Japanese and English text, offering multiple output formats.",
      "stars": 21,
      "forks": 6,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:32:03Z",
      "readme_content": "# MCP Screenshot\n\nAn MCP server that captures screenshots and performs OCR text recognition.\n\n<a href=\"https://glama.ai/mcp/servers/vcnmmaejv8\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/vcnmmaejv8/badge\" alt=\"mcp-screenshot MCP server\" /></a>\n\n## Features\n\n- Screenshot capture (left half, right half, full screen)\n- OCR text recognition (supports Japanese and English)\n- Multiple output formats (JSON, Markdown, vertical, horizontal)\n\n## OCR Engines\n\nThis server uses two OCR engines:\n\n1. [yomitoku](https://github.com/kazuph/yomitoku)\n   - Primary OCR engine\n   - High-accuracy Japanese text recognition\n   - Runs as an API server\n\n2. [Tesseract.js](https://github.com/naptha/tesseract.js)\n   - Fallback OCR engine\n   - Used when yomitoku is unavailable\n   - Supports both Japanese and English recognition\n\n## Installation\n\n```bash\nnpx -y @kazuph/mcp-screenshot\n```\n\n## Claude Desktop Configuration\n\nAdd the following configuration to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"screenshot\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@kazuph/mcp-screenshot\"],\n      \"env\": {\n        \"OCR_API_URL\": \"http://localhost:8000\"  // yomitoku API base URL\n      }\n    }\n  }\n}\n```\n\n## Environment Variables\n\n| Variable Name | Description | Default Value |\n|--------------|-------------|---------------|\n| OCR_API_URL | yomitoku API base URL | http://localhost:8000 |\n\n## Usage Example\n\nYou can use it by instructing Claude like this:\n\n```\nPlease take a screenshot of the left half of the screen and recognize the text in it.\n```\n\n## Tool Specification\n\n### capture\n\nTakes a screenshot and performs OCR.\n\nOptions:\n- `region`: Screenshot area ('left'/'right'/'full', default: 'left')\n- `format`: Output format ('json'/'markdown'/'vertical'/'horizontal', default: 'markdown')\n\n## License\n\nMIT\n\n## Author\n\nkazuph\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "kazuph--mcp-fetch": {
      "owner": "kazuph",
      "name": "mcp-fetch",
      "url": "https://github.com/kazuph/mcp-fetch",
      "imageUrl": "https://github.com/kazuph.png",
      "description": "Fetch web content and process images to facilitate efficient interaction with online resources. Supports integration with MCP clients like Claude Desktop for seamless content management.",
      "stars": 30,
      "forks": 18,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-29T16:56:16Z",
      "readme_content": "# MCP Fetch\n\nModel Context Protocol server for fetching web content and processing images. This allows Claude Desktop (or any MCP client) to fetch web content and handle images appropriately.\n\n<a href=\"https://glama.ai/mcp/servers/5mknfdhyrg\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/5mknfdhyrg/badge\" alt=\"@kazuph/mcp-fetch MCP server\" /></a>\n\n## Quick Start (For Users)\n\nTo use this tool with Claude Desktop, simply add the following to your Claude Desktop configuration (`~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"tools\": {\n    \"imageFetch\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@kazuph/mcp-fetch\"]\n    }\n  }\n}\n```\n\nThis will automatically download and run the latest version of the tool when needed.\n\n### Required Setup\n\n1. Enable Accessibility for Claude:\n   - Open System Settings\n   - Go to Privacy & Security > Accessibility\n   - Click the \"+\" button\n   - Add Claude from your Applications folder\n   - Turn ON the toggle for Claude\n\nThis accessibility setting is required for automated clipboard operations (Cmd+V) to work properly.\n\n## Features\n\n- **Web Content Extraction**: Automatically extracts and formats web content as markdown\n- **Article Title Extraction**: Extracts and displays the title of the article\n- **Image Processing**: Optional processing of images from web pages with optimization (disabled by default, enable with `enableFetchImages: true`)\n- **File Saving**: Images are automatically saved to `~/Downloads/mcp-fetch/YYYY-MM-DD/` directory when processed\n- **Dual Output**: Both file saving and optional Base64 encoding for AI display\n- **Pagination Support**: Supports pagination for both text and images\n- **JPEG Optimization**: Automatically optimizes images as JPEG for better performance\n- **GIF Support**: Extracts first frame from animated GIFs\n\n## For Developers\n\nThe following sections are for those who want to develop or modify the tool.\n\n## Prerequisites\n\n- Node.js 18+\n- macOS (for clipboard operations)\n- Claude Desktop (install from https://claude.ai/desktop)\n- tsx (install via `npm install -g tsx`)\n\n## Installation\n\n```bash\ngit clone https://github.com/kazuph/mcp-fetch.git\ncd mcp-fetch\nnpm install\nnpm run build\n```\n\n## Image Processing Specifications\n\nWhen processing images from web content, the following optimizations are applied:\n\n- Images are converted to JPEG format with quality control\n- Maximum width limited to 1200px by default\n- Maximum height limited to 1600px by default\n- Chroma subsampling (4:2:0) for better compression\n- MozJPEG optimization for smaller file sizes\n\n## Configuration\n\n1. Make sure Claude Desktop is installed and running.\n\n2. Install tsx globally if you haven't:\n```bash\nnpm install -g tsx\n# or\npnpm add -g tsx\n```\n\n3. Modify your Claude Desktop config located at:\n`~/Library/Application Support/Claude/claude_desktop_config.json`\n\nYou can easily find this through the Claude Desktop menu:\n1. Open Claude Desktop\n2. Click Claude on the Mac menu bar\n3. Click \"Settings\"\n4. Click \"Developer\"\n\nAdd the following to your MCP client's configuration:\n\n```json\n{\n  \"tools\": {\n    \"imageFetch\": {\n      \"args\": [\"tsx\", \"/path/to/mcp-fetch/index.ts\"]\n    }\n  }\n}\n```\n\n## Available Parameters\n\n- `url` (required): The URL to fetch\n- `maxLength` (default: 20000): Maximum length of content to return\n- `startIndex` (default: 0): Starting position in content\n- `imageStartIndex` (default: 0): Starting position for image collection\n- `raw` (default: false): Return raw content instead of processed markdown\n- `imageMaxCount` (default: 3): Maximum number of images to process per request\n- `imageMaxHeight` (default: 4000): Maximum height of merged image\n- `imageMaxWidth` (default: 1000): Maximum width of merged image\n- `imageQuality` (default: 80): JPEG quality (1-100)\n- `enableFetchImages` (default: false): Enable fetching and processing of images. FOR CLAUDE USERS ONLY: YOU ARE ALLOWED TO ENABLE THIS FEATURE!!! CLAUDE CAN FETCH AND PROCESS IMAGES!!! ENJOY THIS CAPABILITY!!!!!\n- `allowCrossOriginImages` (default: true): When true, also fetch images hosted on different origins from the page\n- `saveImages` (default: true): Save processed images to local files\n- `returnBase64` (default: false): Return base64 encoded images for AI display\n- `ignoreRobotsTxt` (default: false): Ignore robots.txt restrictions\n\n### Security Hardening (v1.5.1)\n\n- Only `http://` and `https://` URLs are allowed for page and image fetches\n- Blocks private/loopback/link-local IPs and local hostnames (e.g., `localhost`, `.local`)\n- Manual redirect handling with validation (max 3 hops)\n- Request timeouts (default 12s, configurable via `MCP_FETCH_TIMEOUT_MS`)\n- Response size limits: HTML up to 2MB, images up to 10MB (tunable via env)\n\nEnvironment variables:\n\n- `MCP_FETCH_TIMEOUT_MS` (default: 12000)\n- `MCP_FETCH_MAX_REDIRECTS` (default: 3)\n- `MCP_FETCH_MAX_HTML_BYTES` (default: 2000000)\n- `MCP_FETCH_MAX_IMAGE_BYTES` (default: 10000000)\n\n## Examples\n\n### Basic Content Fetching (No Images)\n```json\n{\n  \"url\": \"https://example.com\"\n}\n```\n\n### Fetching with Images (File Saving Only)\n```json\n{\n  \"url\": \"https://example.com\",\n  \"enableFetchImages\": true,\n  \"imageMaxCount\": 3\n}\n```\n\n### Fetching with Images for AI Display\n```json\n{\n  \"url\": \"https://example.com\",\n  \"enableFetchImages\": true,\n  \"returnBase64\": true,\n  \"imageMaxCount\": 3\n}\n```\n\n### Paginating Through Images\n```json\n{\n  \"url\": \"https://example.com\",\n  \"enableFetchImages\": true,\n  \"imageStartIndex\": 3,\n  \"imageMaxCount\": 3\n}\n```\n\n## Notes\n\n- This tool is designed for macOS only due to its dependency on macOS-specific clipboard operations.\n- Images are processed using Sharp for optimal performance and quality.\n- When multiple images are found, they are merged vertically with consideration for size limits.\n- Animated GIFs are automatically handled by extracting their first frame.\n- **File Saving**: Images are automatically saved to `~/Downloads/mcp-fetch/YYYY-MM-DD/` with filename format `hostname_HHMMSS_index.jpg`\n- **Tool Name**: The tool name has been changed from `fetch` to `imageFetch` to avoid conflicts with native fetch functions.\n\n## Changelog\n\n### v1.2.0\n- **BREAKING CHANGE**: Tool name changed from `fetch` to `imageFetch` to avoid conflicts\n- **NEW**: Automatic file saving - Images are now saved to `~/Downloads/mcp-fetch/YYYY-MM-DD/` by default\n- **NEW**: Added `saveImages` parameter (default: true) to control file saving\n- **NEW**: Added `returnBase64` parameter (default: false) for AI image display\n- **BEHAVIOR CHANGE**: Default behavior now saves files instead of only returning base64\n- Improved AI assistant integration with clear instructions for base64 option\n- Enhanced file organization with date-based directories and structured naming\n\n### v1.1.3\n- Changed default behavior: Images are not fetched by default (`enableFetchImages: false`)\n- Removed `disableImages` in favor of `enableFetchImages` parameter\n\n### v1.1.0\n- Added article title extraction feature\n- Improved response formatting to include article titles\n- Fixed type issues with MCP response content\n\n### v1.0.0\n- Initial release\n- Web content extraction\n- Image processing and optimization\n- Pagination support\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Kira-Pgr--PromptShopMCP": {
      "owner": "Kira-Pgr",
      "name": "PromptShopMCP",
      "url": "https://github.com/Kira-Pgr/PromptShopMCP",
      "imageUrl": "https://github.com/Kira-Pgr.png",
      "description": "Transforms images based on natural language commands, enabling users to edit photos by describing desired changes such as adding accessories or modifying backgrounds.",
      "stars": 14,
      "forks": 7,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T20:38:19Z",
      "readme_content": "# PromptShopMCP\n\n![](https://badge.mcpx.dev?type=server 'MCP Server')  \n\nEnglish | [ä¸­æ–‡](README_ZH.md)   \n\n\nA powerful MCP (Model Context Protocol) server that transforms images using simple text commands. Edit photos like a professional designer - just describe what you want in natural language!\n## Demo\nOriginal Image  \n<img src=\"https://github.com/user-attachments/assets/a987b4c4-3bba-4a52-a2a8-9f088868d857\" width=\"300\"/>  \n\nPrompt: **add a coat to the dog**  \n<img src=\"https://github.com/user-attachments/assets/6de3cdd1-a3b9-422b-95dd-12e2172f6f1d\" width=\"300\"/>  \n\nPrompt: **Add a hat to it**  \n<img src=\"https://github.com/user-attachments/assets/047289ca-f3d0-4d16-acf7-09d5af641c68\" width=\"300\"/>  \n \n\n##  Features\n\n- **Image Generation**: Create images from text prompts using Google's Gemini models\n- **Image Modification**: Transform existing images based on text instructions\n- **Background Removal**: Remove backgrounds from images using the remove.bg API\n- **Image Hosting**: Share generated images via FreeImage.host\n- **Resource Management**: Track and manage generated and uploaded images\n\n## Requirements\n\n- Python 3.11 or higher\n- Required API keys:\n  - Google Gemini API key [Get key](https://aistudio.google.com/apikey)\n  - FreeImage.host API key [Get key](https://freeimage.host/page/api)\n  - Remove.bg API key [Get key](https://www.remove.bg/dashboard#api-key)\n\n##  Installation\n\n1. Clone this repository:\n   ```sh\n   git https://github.com/Kira-Pgr/Image-Toolkit-MCP-Server.git\n   cd Image-Toolkit-MCP-Server\n   ```\n\n2. Install UV (if not already installed):\n   ```sh\n   # On macOS and Linux.\n   curl -LsSf https://astral.sh/uv/install.sh | sh\n   # On Windows.\n   powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n   # With pip.\n   pip install uv\n   ```\n\n3. Install dependencies using UV:\n   ```sh\n   uv venv --python=python3.11\n   source .venv/bin/activate #or .venv/Scripts/activate on Windows\n   uv pip install -r requirements.txt\n   ```\n\n##  Usage\n\n1. **Claude Desktop Integration**: Add the following configuration to your `claude_desktop_config.json` file to run the server directly from Claude Desktop:\n   ```json\n   \"PromptShopMCP\": {\n     \"command\": \"uv\",\n     \"args\": [\n       \"--directory\",\n       \"/project/dir/\",\n       \"run\",\n       \"mcp\",\n       \"run\",\n       \"/project/dir/server.py\"\n     ],\n     \"env\": {\n       \"GEMINI_API_KEY\": \"key\",\n       \"FREEIMAGE_API_KEY\": \"key\",\n       \"REMOVEBG_API_KEY\": \"key\"\n     }\n   }\n   ```\n   Note: Replace the placeholder `\"key\"` values with your actual API keys.\n2. **Cursor Integration**:    \n   **Linux/macOS**:\n  Modify the `cursor.sh` file to set your API keys and project directory.   \n  * In cursor settings, go to the \"MCP\" tab, click on `Add new MCP server`,   \n  * Name the server whatever you want, and set the command to `sh /absolute/path/to/cursor.sh`.   \n  * Wait for the server to start, and you can see the server and available tools.   \n  * Then when you use the agent, it would automatically detect whether use the tools.   \n  <img width=\"1240\" alt=\"image\" src=\"https://github.com/user-attachments/assets/b41016fe-a0f8-4029-8f5d-82f25c606a65\" />\n  \n  **Windows**: \n  Modify the `cursor.bat` file to set your API keys and project directory.   \n  * In cursor settings, go to the \"MCP\" tab, click on `Add new MCP server`,   \n  * Name the server whatever you want, and set the command to `cmd /c C:\\absolute\\path\\to\\cursor.bat`.   \n  * Wait for the server to start, and you can see the server and available tools.   \n  * Then when you use the agent, it would automatically detect whether use the tools.   \n\n\n\n\n## Acknowledgements\n\n- [Google Gemini](https://aistudio.google.com/): For the image generation capabilities\n- [Remove.bg](https://www.remove.bg/): For background removal services\n- [FreeImage.host](https://freeimage.host/): For image hosting services\n- [MCP](https://modelcontextprotocol.io/introduction): For the Model Context Protocol\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "kshern--image-tools-mcp": {
      "owner": "kshern",
      "name": "image-tools-mcp",
      "url": "https://github.com/kshern/image-tools-mcp",
      "imageUrl": "https://github.com/kshern.png",
      "description": "Retrieve image dimensions, compress images, and convert images to various formats using local files or URLs. Supports image processing with detailed output on dimensions, types, and compression information.",
      "stars": 6,
      "forks": 3,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:32:19Z",
      "readme_content": "# Image Tools MCP\n\n[![smithery badge](https://smithery.ai/badge/@kshern/image-tools-mcp)](https://smithery.ai/server/@kshern/image-tools-mcp)\n\nA Model Context Protocol (MCP) service for retrieving image dimensions and compressing images, supporting both URL and local file sources.\n\n_[ä¸­æ–‡æ–‡æ¡£](./README_zh.md)_\n\n## Features\n\n- Retrieve image dimensions from URLs\n- Get image dimensions from local files\n- Compress images from URLs using TinyPNG API\n- Compress local images using TinyPNG API\n- Convert images to different formats (webp, jpeg/jpg, png)\n- Returns width, height, type, MIME type, and compression information\n\n### Example Results\n\n![Example Result 1](./public/image_gemini_1.jpg)\n![Example Result 2](./public/image_gemini_2.jpg)\n\n![Example Result 1](./public/image_1.png)\n![Example Result 2](./public/image_2.png)\n\ndownload from figma url and compress\n![Example Result 3](./public/image_figma_url.png)\n\n## Usage\n\n### Using as an MCP Service\n\nThis service provides five tool functions:\n\n1. `get_image_size` - Get dimensions of remote images\n2. `get_local_image_size` - Get dimensions of local images\n3. `compress_image_from_url` - Compress remote images using TinyPNG API\n4. `compress_local_image` - Compress local images using TinyPNG API\n5. `figma` - Fetch image links from Figma API and compress them using TinyPNG API\n\n### Client Integration\n\nTo use this MCP service, you need to connect to it from an MCP client. Here are examples of how to integrate with different clients:\n\n#### Usage\n\n```json\n{\n  \"mcpServers\": {\n    \"image-tools\": {\n      \"command\": \"npx\",\n      \"args\": [\"image-tools-mcp\"],\n      \"env\": {\n        \"TINIFY_API_KEY\": \"<YOUR_TINIFY_API_KEY>\",\n        \"FIGMA_API_TOKEN\": \"<YOUR_FIGMA_API_TOKEN>\"\n      }\n    }\n  }\n}\n```\n\n#### Using with MCP Client Library\n\n````typescript\nimport { McpClient } from \"@modelcontextprotocol/client\";\n\n// Initialize the client\nconst client = new McpClient({\n  transport: \"stdio\" // or other transport options\n});\n\n// Connect to the server\nawait client.connect();\n\n// Get image dimensions from URL\nconst urlResult = await client.callTool(\"get_image_size\", {\n  options: {\n    imageUrl: \"https://example.com/image.jpg\"\n  }\n});\nconsole.log(JSON.parse(urlResult.content[0].text));\n// Output: { width: 800, height: 600, type: \"jpg\", mime: \"image/jpeg\" }\n\n// Get image dimensions from local file\nconst localResult = await client.callTool(\"get_local_image_size\", {\n  options: {\n    imagePath: \"D:/path/to/image.png\"\n  }\n});\nconsole.log(JSON.parse(localResult.content[0].text));\n// Output: { width: 1024, height: 768, type: \"png\", mime: \"image/png\", path: \"D:/path/to/image.png\" }\n\n// Compress image from URL\nconst compressUrlResult = await client.callTool(\"compress_image_from_url\", {\n  options: {\n    imageUrl: \"https://example.com/image.jpg\",\n    outputFormat: \"webp\" // Optional: convert to webp, jpeg/jpg, or png\n  }\n});\nconsole.log(JSON.parse(compressUrlResult.content[0].text));\n// Output: { originalSize: 102400, compressedSize: 51200, compressionRatio: \"50.00%\", tempFilePath: \"/tmp/compressed_1615456789.webp\", format: \"webp\" }\n\n// Compress local image\nconst compressLocalResult = await client.callTool(\"compress_local_image\", {\n  options: {\n    imagePath: \"D:/path/to/image.png\",\n    outputPath: \"D:/path/to/compressed.webp\", // Optional\n    outputFormat: \"image/webp\" // Optional: convert to image/webp, image/jpeg, or image/png\n  }\n});\nconsole.log(JSON.parse(compressLocalResult.content[0].text));\n// Output: { originalSize: 102400, compressedSize: 51200, compressionRatio: \"50.00%\", outputPath: \"D:/path/to/compressed.webp\", format: \"webp\" }\n\n// Fetch image links from Figma API\n\nconst figmaResult = await client.callTool(\"figma\", {\n  options: {\n    figmaUrl: \"https://www.figma.com/file/XXXXXXX\"\n  }\n});\nconsole.log(JSON.parse(figmaResult.content[0].text));\n// Output: { imageLinks: [\"https://example.com/image1.jpg\", \"https://example.com/image2.jpg\"] }\n\n### Tool Schemas\n\n#### get_image_size\n\n```typescript\n{\n  options: {\n    imageUrl: string // URL of the image to retrieve dimensions for\n  }\n}\n````\n\n#### get_local_image_size\n\n```typescript\n{\n  options: {\n    imagePath: string; // Absolute path to the local image file\n  }\n}\n```\n\n#### compress_image_from_url\n\n```typescript\n{\n  options: {\n    imageUrl: string // URL of the image to compress\n    outputFormat?: \"image/webp\" | \"image/jpeg\" | \"image/jpg\" | \"image/png\" // Optional output format\n  }\n}\n```\n\n#### compress_local_image\n\n```typescript\n{\n  options: {\n    imagePath: string // Absolute path to the local image file\n    outputPath?: string // Optional absolute path for the compressed output image\n    outputFormat?: \"image/webp\" | \"image/jpeg\" | \"image/jpg\" | \"image/png\" // Optional output format\n  }\n}\n```\n\n#### figma\n\n```typescript\n{\n  options: {\n    figmaUrl: string; // URL of the Figma file to fetch image links from\n  }\n}\n```\n\n## Changelog\n\n- **2025-05-12:** Updated Figma API to support additional parameters, including 2x image scaling.\n\n## Technical Implementation\n\nThis project is built on the following libraries:\n\n- [probe-image-size](https://github.com/nodeca/probe-image-size) - For image dimension detection\n- [tinify](https://github.com/tinify/tinify-nodejs) - For image compression via the TinyPNG API\n- [figma-api](https://github.com/figma/api) - For fetching image links from Figma API\n\n## Environment Variables\n\n- `TINIFY_API_KEY` - Required for image compression functionality. Get your API key from [TinyPNG](https://tinypng.com/developers)\n  - When not provided, the compression tools (`compress_image_from_url` and `compress_local_image`) will not be registered\n- `FIGMA_API_TOKEN` - Required for fetching image links from Figma API. Get your API token from [Figma](https://www.figma.com/developers)\n  - When not provided, the Figma tool (`figma`) will not be registered\n\nNote: The basic image dimension tools (`get_image_size` and `get_local_image_size`) are always available regardless of API keys.\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "lalanikarim--comfy-mcp-server": {
      "owner": "lalanikarim",
      "name": "comfy-mcp-server",
      "url": "https://github.com/lalanikarim/comfy-mcp-server",
      "imageUrl": "https://github.com/lalanikarim.png",
      "description": "Generates images based on user prompts by interacting with a remote Comfy server. Utilizes the FastMCP framework to manage image generation workflows.",
      "stars": 31,
      "forks": 12,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-01T17:04:48Z",
      "readme_content": "# Comfy MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@lalanikarim/comfy-mcp-server)](https://smithery.ai/server/@lalanikarim/comfy-mcp-server)\n\n> A server using FastMCP framework to generate images based on prompts via a remote Comfy server.\n\n## Overview\n\nThis script sets up a server using the FastMCP framework to generate images based on prompts using a specified workflow. It interacts with a remote Comfy server to submit prompts and retrieve generated images.\n\n## Prerequisites\n\n- [uv](https://docs.astral.sh/uv/) package and project manager for Python.\n- Workflow file exported from Comfy UI. This code includes a sample `Flux-Dev-ComfyUI-Workflow.json` which is only used here as reference. You will need to export from your workflow and set the environment variables accordingly.\n\nYou can install the required packages for local development:\n\n```bash\nuvx mcp[cli]\n```\n\n## Configuration\n\nSet the following environment variables:\n\n- `COMFY_URL` to point to your Comfy server URL.\n- `COMFY_WORKFLOW_JSON_FILE` to point to the absolute path of the API export json file for the comfyui workflow.\n- `PROMPT_NODE_ID` to the id of the text prompt node.\n- `OUTPUT_NODE_ID` to the id of the output node with the final image.\n- `OUTPUT_MODE` to either `url` or `file` to select desired output.\n\nOptionally, if you have an [Ollama](https://ollama.com) server running, you can connect to it for prompt generation.\n\n- `OLLAMA_API_BASE` to the url where ollama is running.\n- `PROMPT_LLM` to the name of the model hosted on ollama for prompt generation.\n\nExample:\n\n```bash\nexport COMFY_URL=http://your-comfy-server-url:port\nexport COMFY_WORKFLOW_JSON_FILE=/path/to/the/comfyui_workflow_export.json\nexport PROMPT_NODE_ID=6 # use the correct node id here\nexport OUTPUT_NODE_ID=9 # use the correct node id here\nexport OUTPUT_MODE=file\n```\n\n## Usage\n\nComfy MCP Server can be launched by the following command:\n\n```bash\nuvx comfy-mcp-server\n```\n\n### Example Claude Desktop Config\n\n```json\n{\n  \"mcpServers\": {\n    \"Comfy MCP Server\": {\n      \"command\": \"/path/to/uvx\",\n      \"args\": [\n        \"comfy-mcp-server\"\n      ],\n      \"env\": {\n        \"COMFY_URL\": \"http://your-comfy-server-url:port\",\n        \"COMFY_WORKFLOW_JSON_FILE\": \"/path/to/the/comfyui_workflow_export.json\",\n        \"PROMPT_NODE_ID\": \"6\",\n        \"OUTPUT_NODE_ID\": \"9\",\n        \"OUTPUT_MODE\": \"file\",\n      }\n    }\n  }\n}\n\n```\n\n## Functionality\n\n### `generate_image(prompt: str, ctx: Context) -> Image | str`\n\nThis function generates an image using a specified prompt. It follows these steps:\n\n1. Checks if all the environment variable are set.\n2. Loads a prompt template from a JSON file.\n3. Submits the prompt to the Comfy server.\n4. Polls the server for the status of the prompt processing.\n5. Retrieves and returns the generated image once it's ready.\n\n### `generate_prompt(topic: str, ctx: Context) -> str`\n\nThis function generates a comprehensive image generation prompt from specified topic.\n\n## Dependencies\n\n- `mcp`: For setting up the FastMCP server.\n- `json`: For handling JSON data.\n- `urllib`: For making HTTP requests.\n- `time`: For adding delays in polling.\n- `os`: For accessing environment variables.\n- `langchain`: For creating simple LLM Prompt chain to generate image generation prompt from topic.\n- `langchain-ollama`: For ollama specific modules for LangChain.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](https://github.com/lalanikarim/comfy-mcp-server/blob/main/LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "laosu888--tupianyasuo": {
      "owner": "laosu888",
      "name": "tupianyasuo",
      "url": "https://github.com/laosu888/tupianyasuo",
      "imageUrl": "https://github.com/laosu888.png",
      "description": "A front-end image compression tool supporting various formats like PNG and JPG, enabling users to customize compression ratios and preview results in real-time. The application allows users to download optimized images with comparisons of file sizes before and after compression.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2024-12-25T19:15:50Z",
      "readme_content": "# å›¾ç‰‡å‹ç¼©å·¥å…·\n\nä¸€ä¸ªç®€å•æ˜“ç”¨çš„åœ¨çº¿å›¾ç‰‡å‹ç¼©å·¥å…·ï¼Œå…·æœ‰ç²¾ç¾çš„è‹¹æœé£æ ¼ç•Œé¢è®¾è®¡ã€‚\n\n## åŠŸèƒ½ç‰¹ç‚¹\n\n- æ”¯æŒPNGã€JPGç­‰æ ¼å¼å›¾ç‰‡ä¸Šä¼ \n- æ”¯æŒè‡ªå®šä¹‰å‹ç¼©æ¯”ä¾‹\n- å®æ—¶é¢„è§ˆå‹ç¼©å‰åçš„å›¾ç‰‡æ•ˆæœ\n- æ˜¾ç¤ºå‹ç¼©å‰åæ–‡ä»¶å¤§å°å¯¹æ¯”\n- æ”¯æŒå‹ç¼©åå›¾ç‰‡ä¸‹è½½\n- çº¯å‰ç«¯å®ç°ï¼Œæ— éœ€åç«¯æœåŠ¡\n\n## é¡¹ç›®ç»“æ„\n\n```\nâ”œâ”€â”€ index.html          # ä¸»é¡µé¢\nâ”œâ”€â”€ css/               \nâ”‚   â””â”€â”€ style.css      # æ ·å¼æ–‡ä»¶\nâ”œâ”€â”€ js/\nâ”‚   â””â”€â”€ main.js        # ä¸»è¦åŠŸèƒ½å®ç°\nâ””â”€â”€ assets/\n    â””â”€â”€ icons/         # SVGå›¾æ ‡\n```\n\n## æŠ€æœ¯æ ˆ\n\n- HTML5\n- CSS3 (Flexbox & Grid)\n- Vanilla JavaScript\n- æµè§ˆå™¨åŸç”Ÿå›¾ç‰‡å‹ç¼©API ",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Letz-AI--letzai-mcp": {
      "owner": "Letz-AI",
      "name": "letzai-mcp",
      "url": "https://github.com/Letz-AI/letzai-mcp",
      "imageUrl": "https://github.com/Letz-AI.png",
      "description": "Create and upscale images based on prompts using the LetzAI MCP. This server integrates with the Claude Desktop App for seamless image generation.",
      "stars": 1,
      "forks": 2,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-03-25T17:46:55Z",
      "readme_content": "# LetzAI MCP Setup Guide\n\nThis guide will walk you through the process of setting up and using the LetzAI MCP (Model Context Protocol) for image generation.\n\n## Prerequisites\n\nBefore you begin, ensure that you have the following:\n\n- **Node.js** installed on your system. You can download it from [Node.js official site](https://nodejs.org/).\n- **Claude Desktop App** installed. If you don't have it, download it from [Claude Desktop App](https://claude.app).\n- **LetzAI API Key**. You can obtain it by visiting [LetzAI API](https://letz.ai/docs/api).\n\n## Setup Steps\n\n### 1. Download the Git Folder\n\nDownload the repository containing the LetzAI MCP project and place it in a location outside of your Downloads folder. For example:\n\n```\nC:\\\\Users\\\\username\\\\desktop\n```\n\nAlternatively, you can use `git clone` to clone the repository:\n\n```bash\ngit clone <repository-url> C:\\\\Users\\\\username\\\\desktop\n```\n\n### 2. Install Dependencies\n\nNavigate to the project folder using your terminal or command prompt:\n\n```bash\ncd C:\\\\Users\\\\username\\\\desktop\n```\n\nRun the following command to install all required dependencies:\n\n```bash\nnpm install\n```\n\n### 3. Compile the Project\n\nAfter installing the dependencies, compile the TypeScript files into JavaScript using the following command:\n\n```bash\nnpx tsc\n```\n\nThis will generate the compiled JavaScript files in the `build` folder.\n\n### 4. Restart Claude App\n\nAfter running `npx tsc`, you must **restart** the Claude Desktop App for it to recognize the updated MCP configuration and compiled files.\n\n### 5. Set Up MCP Configuration in Claude Desktop App\n\n![open settings](settingsOpen.png)\n\n1. **Open the Claude Desktop App**.\n2. **Click on the Menu Icon** in the top-left corner.\n3. From the dropdown, select **File**.\n4. Navigate to **Settings**.\n5. Under the **Developer** section, you will see an option for **Edit Config**.\n   ![view developer settings](developerSettings.png)\n6. Click on **Edit Config** â€” this will open the configuration folder.\n7. Locate the file `claude_desktop_config.json` and edit it as needed.\n\n#### Windows Configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"letzai\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"C:\\\\ABSOLUTE\\\\PATH\\\\TO\\\\PARENT\\\\FOLDER\\\\letzai-mcp\\\\build\\\\index.js\"\n      ],\n      \"env\": {\n        \"LETZAI_API_KEY\": \"<Your LetzAI API Key>\"\n      }\n    }\n  }\n}\n```\n\n#### Ubuntu Configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"letzai\": {\n      \"command\": \"node\",\n      \"args\": [\"/ABSOLUTE/PATH/TO/PARENT/FOLDER/letzai-mcp/build/index.js\"],\n      \"env\": {\n        \"LETZAI_API_KEY\": \"<Your LetzAI API Key>\"\n      }\n    }\n  }\n}\n```\n\n#### macOS Configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"letzai\": {\n      \"command\": \"node\",\n      \"args\": [\"/ABSOLUTE/PATH/TO/PARENT/FOLDER/letzai-mcp/build/index.js\"],\n      \"env\": {\n        \"LETZAI_API_KEY\": \"<Your LetzAI API Key>\"\n      }\n    }\n  }\n}\n```\n\n### Configuration Explanation\n\n- **command**: The command to run the application. We use `node` to run the JavaScript file generated by TypeScript.\n- **args**: This is the path to the compiled `index.js` file. Make sure the path is correct according to where your files are located after compilation. If you've placed the folder at `C:\\\\Users\\\\username\\\\desktop\\\\letzai-mcp`, the path will be:\n\n```\n\nC:\\\\Users\\\\username\\\\desktop\\\\letzai-mcp\\\\build\\\\index.js\n\n```\n\n### 6. Run the MCP Server\n\nNow that everything is set up, you can start using the LetzAI MCP in the Claude Desktop App. The server should be ready for image generation tasks once the app is running with the correct API key in the environment.\n\n**Important:** After making changes to the configuration, you **must restart Claude** for the changes to take effect.\n\n### 7. Testing the New MCP in Claude\n\n![claude prompt ui after installtion](claudeInterface.png)\nClick on the hammer icon to view the installed MCP tools.\n![claude mcp tools](mcpToolsInfo.png)\n\nOnce you've set up the MCP in the Claude Desktop App, you can test it by running the following prompt:\n\n- **Create image with LetzAI using prompt: \"photo of @mischstrotz drinking a beer, dressed as a knight\"**\n\nThis will create the image based on the provided prompt, using the model @mischstrotz from LetzAI. Claude will open the image in your preferred browser.\n\n- **Upscale this image with strength 1: [https://letz.ai/image/d6a67077-f156-46d7-a1a2-1dc49e83dd91](https://images.letz.ai/5ed74083-f9d1-4897-b8e3-c8f1596af767/d6a67077-f156-46d7-a1a2-1dc49e83dd91/high_quality_photo_of_mischstrotz_holding_a_beer_s20250322080513.jpg)**\n\nThis will upscale the image using the strength parameter 1. You can pass entire URLs, or just the LetzAI Image IDs e.g. d6a67077-f156-46d7-a1a2-1dc49e83dd91\n\n## Troubleshooting\n\n- **Node.js not found**: Ensure that Node.js is installed and added to your system's PATH environment variable.\n- **Invalid API Key**: Double-check that you have correctly added your API key under the `LETZAI_API_KEY` variable in the Claude Desktop App settings.\n- **File Path Issues**: Make sure that the path to the `index.js` file is correct. If you're unsure about the path, use the absolute path to the file.\n\nFor more detailed documentation and support, visit [LetzAI Docs](https://letz.ai/docs/api).\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "LoganLxb--LoganLxb": {
      "owner": "LoganLxb",
      "name": "LoganLxb",
      "url": "https://github.com/LoganLxb/LoganLxb",
      "imageUrl": "https://github.com/LoganLxb.png",
      "description": "Logan provides tools and applications aimed at enhancing user interaction in mixed reality environments through augmented and virtual reality technologies. It focuses on facilitating the development of immersive digital experiences and applications.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2024-10-08T18:42:17Z",
      "readme_content": "<h2 align=\"center\">Hi there ğŸ‘‹</h2>\n<!--\n**LoganLxb/LoganLxb** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.\n-->\n\n## ğŸ–¥ï¸ Logan\n\nI'm a developers experienced in creating and developing the future thanks to AR,VR and Mixed reality.\n\n- ğŸ”­ Iâ€™m currently working on democratizing mixed reality with Glassear\n- ğŸŒ± Iâ€™m currently learning computer vision, python and c#\n\n## ğŸ’¬ Ask me about ...\n* Unity development\n* Mobile / headmounted Augmented Reality\n* Virtual Reality\n* Image detection\n\n##  ğŸ‘€ Find me\n- ğŸ“« How to reach me: logan@xrexp.io\n\n[![Top Langs](https://github-readme-stats.vercel.app/api/top-langs/?username=LoganLxb&layout=compact&theme=gruvbox)](https://github.com/LoganLxb/github-readme-stats)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Lucker631--mcp-templateio": {
      "owner": "Lucker631",
      "name": "mcp-templateio",
      "url": "https://github.com/Lucker631/mcp-templateio",
      "imageUrl": "https://github.com/Lucker631.png",
      "description": "Generates customized visuals by creating images based on templates using the Templated.io API. Supports dynamic graphics creation through user-provided text and image URLs.",
      "stars": 0,
      "forks": 4,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-07-10T15:36:42Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/lucker631-mcp-templateio-badge.png)](https://mseep.ai/app/lucker631-mcp-templateio)\n\n# MCP TemplateIO - Image Generation Tool\n\nA Model Context Protocol (MCP) server built with mcp-framework that provides an image generation tool using Templated.io.\n\n## Overview\n\nThis template provides a starting point for building MCP servers with custom tools. It includes an example tool and instructions on how to add more tools, develop them, and publish them to npm. This README will guide you through the process of setting up, developing, and deploying your own MCP server.\n\n## Quick Start\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Project Structure\n\n```\nmcp-templateio/\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ tools/        # MCP Tools\nâ”‚   â”‚   â”œâ”€â”€ ExampleTool.ts\nâ”‚   â”‚   â””â”€â”€ TemplatedImageTool.ts # Image generation tool\nâ”‚   â””â”€â”€ index.ts      # Server entry point\nâ”œâ”€â”€ package.json\nâ””â”€â”€ tsconfig.json\n```\n\n## Available Tools\n\n### Templated Image Generator\n\nThis tool generates an image based on a template, given text and image URLs, using the Templated.io API.\n\n**Input Parameters:**\n\n- `templateId`: ID of the Templated.io template to use\n- `photoBgImageUrl`: URL for the image to place in the \"photo-bg\" layer.\n- `bgYellowImageUrl`: URL for the image to place in the \"bg-yellow\" layer.\n- `buildText`: Text content for the \"build\" text layer.\n\n## Tool Development\n\nExample tool structure:\n\n```typescript\nimport { MCPTool } from \"mcp-framework\";\nimport { z } from \"zod\";\n\ninterface MyToolInput {\n  message: string;\n}\n\nclass MyTool extends MCPTool<MyToolInput> {\n  name = \"my_tool\";\n  description = \"Describes what your tool does\";\n\n  schema = {\n    message: {\n      type: z.string(),\n      description: \"Description of this input parameter\",\n    },\n  };\n\n  async execute(input: MyToolInput) {\n    // Your tool logic here\n    return `Processed: ${input.message}`;\n  }\n}\n\nexport default MyTool;\n```\n\n## Adding Components\n\nThe project comes with an example tool in `src/tools/ExampleTool.ts` and the `TemplatedImageTool.ts`. You can add more tools using the CLI:\n\n```bash\n# Add a new tool\nmcp add tool my-tool\n\n# Example tools you might create:\nmcp add tool data-processor\nmcp add tool api-client\nmcp add tool file-handler\n```\n\n## Publishing to npm\n\n1. Update your package.json:\n\n   - Ensure `name` is unique and follows npm naming conventions\n   - Set appropriate `version`\n   - Add `description`, `author`, `license`, etc.\n   - Check `bin` points to the correct entry file\n\n2. Build and test locally:\n\n   ```bash\n   npm run build\n   npm link\n   mcp-templateio  # Test your CLI locally\n   ```\n\n3. Login to npm (create account if necessary):\n\n   ```bash\n   npm login\n   ```\n\n4. Publish your package:\n   ```bash\n   npm publish\n   ```\n\nAfter publishing, users can add it to their claude desktop client (read below) or run it with npx\n\n## Using with Claude Desktop\n\n### Local Development\n\nAdd this configuration to your Claude Desktop config file:\n\n**MacOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n**Windows**: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-templateio\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/mcp-templateio/dist/index.js\"]\n    }\n  }\n}\n```\n\n### After Publishing\n\nGET YOUR API KEY HERE: https://app.templated.io/api-integration?template=4ae9a86b-4ecd-44ee-aebd-7c5a49c16969\n\nAdd this configuration to your Claude Desktop config file:\n\n**MacOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n**Windows**: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-templateio\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"C:\\\\Users\\\\alex0\\\\Documents\\\\AA_CodeAndScripts\\\\modelcontextprotocol\\\\mcp-templateio\\\\dist\\\\index.js\"\n      ],\n      \"env\": {\"TEMPLATED_API_KEY\":\"YOUR-API-KEY-HERE\"}\n    },\n  }\n}\n```\n\n## Building and Testing\n\n1. Make changes to your tools\n2. Run `npm run build` to compile\n3. The server will automatically load your tools on startup\n\n## Learn More\n\n- [MCP Framework Github](https://github.com/QuantGeekDev/mcp-framework)\n- [MCP Framework Docs](https://mcp-framework.com)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "luojunhui1--ImageOnC": {
      "owner": "luojunhui1",
      "name": "ImageOnC",
      "url": "https://github.com/luojunhui1/ImageOnC",
      "imageUrl": "https://github.com/luojunhui1.png",
      "description": "Implement vehicle license plate recognition using C/C++ on FPGA, utilizing OpenCV for image display and Eigen for optimized matrix operations. The project includes code for training neural networks and processing license plate images.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "C++",
      "updated_at": "2024-05-17T18:19:28Z",
      "readme_content": "# ImageOnC\n## 1.ä»‹ç»\næœ¬ä»“åº“ä¸ºå®ç°åœ¨FPGAä¸Šçš„è½¦ç‰Œè¯†åˆ«è€Œåˆ›å»ºï¼Œä½†æœ¬ä»“åº“åªä¿æœ‰C/C++éƒ¨åˆ†çš„ä»£ç ï¼Œå¹¶æœªä¿å­˜ä½¿ç”¨HLSå·¥å…·åçš„ä»£ç ã€‚è¦ç‰¹åˆ«è¯´æ˜çš„æ˜¯ï¼Œæœ¬é¡¹ç›®ä¸­çš„ä»£ç å‡ç”¨Cå®ç°ï¼Œå…¶ä¸­å‡ºç°çš„C++ä¸»è¦ä¸ºä¾¿äºOpenCVè¿›è¡Œå›¾åƒæ˜¾ç¤ºæˆ–è€…Eigenåº“åŠ é€ŸçŸ©é˜µè¿ç®—ï¼Œä½†å‡å¯åˆ é™¤æˆ–æ”¹æˆCä¸­çš„æ•°ç»„è€Œä¸å½±å“å…¶æ­£å¸¸åŠŸèƒ½ã€‚\n## 2.æ–‡ä»¶ç»„æˆ\n```\n.\nâ”œâ”€â”€ build\nâ”œâ”€â”€ cmake-build-debug\nâ”œâ”€â”€ CMakeLists.txt\nâ”œâ”€â”€ database\nâ”œâ”€â”€ Fit.cpp\nâ”œâ”€â”€ Han\nâ”œâ”€â”€ include\nâ”œâ”€â”€ Letters\nâ”œâ”€â”€ main.cpp\nâ”œâ”€â”€ paramLetters.txt\nâ”œâ”€â”€ param.txt\nâ”œâ”€â”€ README.md\nâ””â”€â”€ Train.cpp\n```\n\nå…¶ä¸­buildå’Œcmake-build-debugæ–‡ä»¶å‡ä¸ºç¼–è¯‘æ‰§è¡Œè¿‡ç¨‹äº§ç”Ÿçš„æ–‡ä»¶ï¼›CMakeLists.txtç”¨äºæŒ‡å¯¼ç¼–è¯‘æ–¹å¼ï¼›databaseä¸ºè½¦ç‰Œå›¾ç‰‡æ–‡ä»¶å¤¹ï¼›Fit.cppåŸä½œæµ‹è¯•ç½‘ç»œå‡†ç¡®æ€§ï¼Œä½†å…¶å†…å®¹åœ¨æµ‹è¯•åè¢«æ•´åˆåˆ°main.cppä¸­ï¼Œæ•…è¯¥æ–‡ä»¶æ— å®é™…æ„ä¹‰ï¼›Hanæ–‡ä»¶å¤¹ä¿å­˜äº†ç”¨äºè®­ç»ƒæ±‰å­—è¯†åˆ«çš„å›¾åƒï¼›Lettersä¸­åˆ™ä¿å­˜äº†ç”¨äºè®­ç»ƒå­—æ¯å’Œæ•°å­—è¯†åˆ«çš„ä»£ç ï¼›main.cppä¸ºæ‰§è¡Œçš„è¯†åˆ«è½¦ç‰Œçš„ä¸»å‡½æ•°ï¼›Train.cppç”¨äºè®­ç»ƒç¥ç»ç½‘ç»œï¼›param.txtåŠparamLetters.txtåˆ™ä¿å­˜äº†ç½‘ç»œå‚æ•°ï¼›includeæ–‡ä»¶ä¸­ä¿å­˜äº†ä¸€å†™è‡ªå®šä¹‰çš„åŠŸèƒ½å‡½æ•°ï¼Œå…¶æ–‡ä»¶æ ‘å¦‚ä¸‹ï¼š\n```\n.\nâ”œâ”€â”€ Config.h\nâ”œâ”€â”€ Eigen\nâ”œâ”€â”€ FileProcess.h\nâ”œâ”€â”€ ModelTrans.h\nâ”œâ”€â”€ Net.h\nâ”œâ”€â”€ Process.h\nâ”œâ”€â”€ SaveLoad.h\nâ””â”€â”€ unsupported\n```\n**Config.h**: ç”¨äºçº¦å®šç½‘ç»œå‚æ•°å’Œä¸€äº›å…¨å±€å˜é‡ï¼Œä¾¿äºé¡¹ç›®ä»£ç ç»„ç»‡\n\n**Eigen**: Eigenåº“ä»£ç \n\n**unsupported**: Eigenåº“ä»£ç ,åŸä¸ºä½¿ç”¨Tensorç±»è¡¨ç¤ºé«˜ç»´çŸ©é˜µï¼Œä½†Tensorä½¿ç”¨ä¸ä¾¿ï¼Œå®é™…æœªä½¿ç”¨\n\n**FileProcess**: ç”¨äºç³»ç»Ÿæ–‡ä»¶æ“ä½œï¼Œä¸»è¦æ˜¯æŸ¥è¯¢æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å¹¶éå†\n\n**ModelTrans**: ç”¨äºä»å›¾åƒçš„æ•°æ®çŸ©é˜µä¸­è¯»å–BGRå›¾åƒå¹¶å°†å…¶åˆ†å‰²ã€ä¿å­˜\n\n**Net.h**: ç¥ç»ç½‘ç»œçš„å®šä¹‰ã€è®­ç»ƒåŠä½¿ç”¨éƒ¨åˆ†\n\n**SaveLoad**: ç”¨äºä»å›¾åƒè·¯å¾„è¯»å–bmpå›¾åƒå¹¶åˆ†é€šé“ä¿å­˜å›¾åƒæ•°æ®éƒ¨åˆ†\n\n## 3. å®é™…æ•ˆæœ\næ•°æ®é›†æ¯”è¾ƒç®€å•ï¼Œèƒ½åšåˆ°100%ã€‚\n\n\n\n\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "luoshui-coder--image-generator-mcp-server": {
      "owner": "luoshui-coder",
      "name": "image-generator-mcp-server",
      "url": "https://github.com/luoshui-coder/image-generator-mcp-server",
      "imageUrl": "https://github.com/luoshui-coder.png",
      "description": "Generates images based on prompts using OpenAI's DALL-E model, saving them in a specified directory on the user's desktop.",
      "stars": 1,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2025-03-14T04:57:37Z",
      "readme_content": "# image-generator MCP Server\n\nAn mcp server that generates images based on image prompts\n\nThis is a TypeScript-based MCP server that implements image generation using **OPENAI**'s `dall-e-3` image generation model.\n\n## Features\n\n### Tools\n- `generate_image` - Generate an image for given prompt\n  - Takes `prompt` as a required parameter\n  - Takes `imageName` as a required parameter to save the generated image in a `generated-images` directory on your desktop\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"command\": \"image-generator\",\n      \"env\": {\n        \"OPENAI_API_KEY\": \"<your-openai-api-key>\"\n    }\n  }\n}\n```\nMake sure to replace `<your-openai-api-key>` with your actual **OPENAI** Api Key.\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "m-mcp--flux-schnell-server": {
      "owner": "m-mcp",
      "name": "flux-schnell-server",
      "url": "https://github.com/m-mcp/flux-schnell-server",
      "imageUrl": "https://github.com/m-mcp.png",
      "description": "Provides an MCP protocol-based API for generating images from text prompts with customizable dimensions and reproducible results using a specified random seed. Supports asynchronous streaming responses and integration with Hugging Face model services.",
      "stars": 1,
      "forks": 2,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-29T09:05:08Z",
      "readme_content": "# Flux Schnell Server\n\n[![smithery badge](https://smithery.ai/badge/@m-mcp/flux-schnell-server)](https://smithery.ai/server/@m-mcp/flux-schnell-server)\n\nåŸºäº[Flux Schnell](https://huggingface.co/spaces/black-forest-labs/flux-1-schnell)æ¨¡å‹çš„MCPå›¾åƒç”ŸæˆæœåŠ¡å™¨ã€‚\n\n## åŠŸèƒ½ç‰¹ç‚¹\n\n- æä¾›åŸºäºMCPåè®®çš„å›¾åƒç”ŸæˆAPI\n- æ”¯æŒè‡ªå®šä¹‰å›¾ç‰‡å°ºå¯¸ï¼ˆå®½åº¦å’Œé«˜åº¦ï¼‰\n- æ”¯æŒè®¾ç½®éšæœºç§å­ä»¥å¤ç°ç‰¹å®šç”Ÿæˆç»“æœ\n- æ”¯æŒå¼‚æ­¥æµå¼å“åº”\n- æä¾›HTTPæ¥å£è°ƒç”¨Hugging Faceçš„æ¨¡å‹æœåŠ¡\n\n## å®‰è£…è¦æ±‚\n\n- Python >= 3.10\n- ä¾èµ–åŒ…ï¼š\n  - httpx >= 0.28.1\n  - mcp[cli] >= 1.3.0\n\n## ä½¿ç”¨æ–¹æ³•\n### å¼€å‘ç¯å¢ƒè®¾ç½®\n\n1. åˆ›å»ºå¹¶æ¿€æ´» Python è™šæ‹Ÿç¯å¢ƒ\n```bash\nuv venv && source .venv/bin/activate  # Unix/macOS\n# æˆ–\n.venv\\Scripts\\activate  # Windows\n```\n\n2. å®‰è£…å¼€å‘ä¾èµ–\n```bash\nuv sync  # ä»¥å¯ç¼–è¾‘æ¨¡å¼å®‰è£…é¡¹ç›®\n```\n\n### è°ƒè¯•æ–¹æ³•\n\n1. å¯ç”¨è°ƒè¯•\n```bash\nmcp dev main.py\næˆ–è€…\nnpx -y @modelcontextprotocol/inspector uv run main.py\n```\n\n2. è°ƒç”¨å›¾åƒç”Ÿæˆå·¥å…·ï¼š\n```python\n# ç¤ºä¾‹ä»£ç \nasync def test_main():\n    img_url = await image_generation(\n        prompt=\"your prompt here\",\n        image_width=512,  # å¯é€‰ï¼Œé»˜è®¤512\n        image_height=512, # å¯é€‰ï¼Œé»˜è®¤512\n        seed=3           # å¯é€‰ï¼Œé»˜è®¤3\n    )\n    print(img_url)\n```\n\n## APIå‚æ•°è¯´æ˜\n\n- `prompt` (str): å›¾åƒç”Ÿæˆæç¤ºè¯\n- `image_width` (int, optional): ç”Ÿæˆå›¾ç‰‡å®½åº¦ï¼Œé»˜è®¤512\n- `image_height` (int, optional): ç”Ÿæˆå›¾ç‰‡é«˜åº¦ï¼Œé»˜è®¤512\n- `seed` (int, optional): éšæœºç§å­ï¼Œé»˜è®¤3\n\n## ç¤ºä¾‹\n\n### æ˜¥å¤©çš„ç”Ÿæœº\n\n![æ˜¥å¤©çš„ç”Ÿæœº](https://black-forest-labs-flux-1-schnell.hf.space/file=/tmp/gradio/45d6489d73142fa77851d8985bb1010572433d6a/image.webp)\n\n> æ˜¥å¤©æ¥äº†ï¼Œå¤§åœ°è‹é†’ï¼Œä¸‡ç‰©å¤è‹ã€‚èŠ±å„¿ç«ç›¸å¼€æ”¾ï¼Œå«©ç»¿çš„å¶å­åœ¨å¾®é£ä¸­è½»è½»æ‘‡æ›³ã€‚ç©ºæ°”ä¸­å¼¥æ¼«ç€æ³¥åœŸçš„èŠ¬èŠ³å’ŒèŠ±å„¿çš„é¦™æ°”ã€‚å°é¸Ÿåœ¨æå¤´æ¬¢å¿«åœ°æ­Œå”±ï¼Œè´è¶åœ¨èŠ±ä¸›ä¸­ç¿©ç¿©èµ·èˆã€‚é˜³å…‰æ´’åœ¨å¤§åœ°ä¸Šï¼Œæ¸©æš–è€Œæ˜äº®ã€‚æ˜¥å¤©çš„ç”Ÿæœºå‹ƒå‹ƒï¼Œè®©äººå¿ƒæ—·ç¥æ€¡ã€‚\n\nè¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†ä½¿ç”¨æœåŠ¡ç”Ÿæˆçš„å›¾ç‰‡æ•ˆæœã€‚æ‚¨å¯ä»¥åœ¨demoç›®å½•ä¸­æ‰¾åˆ°å®Œæ•´çš„ç½‘é¡µå±•ç¤ºä»£ç ã€‚\n\nç”Ÿæˆçš„å›¾ç‰‡URLå¯ä»¥ç›´æ¥ç”¨äºï¼š\n1. ç½‘é¡µå›¾ç‰‡å±•ç¤º\n2. ç¤¾äº¤åª’ä½“åˆ†äº«\n3. åº”ç”¨ç¨‹åºç•Œé¢\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "madhusudan-kulkarni--mcp-fal-ai-image": {
      "owner": "madhusudan-kulkarni",
      "name": "mcp-fal-ai-image",
      "url": "https://github.com/madhusudan-kulkarni/mcp-fal-ai-image",
      "imageUrl": "https://github.com/madhusudan-kulkarni.png",
      "description": "Generate images from text prompts using various fal.ai models through the Model Context Protocol (MCP), enabling seamless integration with AI IDEs. Save generated images locally with customizable output paths and robust error handling.",
      "stars": 2,
      "forks": 1,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-07-25T04:25:20Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/madhusudan-kulkarni-mcp-fal-ai-image-badge.png)](https://mseep.ai/app/madhusudan-kulkarni-mcp-fal-ai-image)\n\n[![npm version](https://img.shields.io/npm/v/mcp-fal-ai-image.svg)](https://www.npmjs.com/package/mcp-fal-ai-image) [![Node.js Version](https://img.shields.io/node/v/mcp-fal-ai-image)](https://nodejs.org/) [![TypeScript](https://img.shields.io/badge/TypeScript-5.8-blue.svg)](https://www.typescriptlang.org/) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)\n\n# MCP fal.ai Image Server\n\nEffortlessly generate images from text prompts using [fal.ai](https://fal.ai) and the Model Context Protocol (MCP). Integrates directly with AI IDEs like Cursor and Windsurf.\n\n## When and Why to Use\n\nThis tool is designed for:\n- Developers and designers who want to generate images from text prompts without leaving their IDE.\n- Rapid prototyping of UI concepts, marketing assets, or creative ideas.\n- Content creators needing unique visuals for blogs, presentations, or social media.\n- AI researchers and tinkerers experimenting with the latest fal.ai models.\n- Automating workflows that require programmatic image generation via MCP.\n\nKey features:\n- Supports any valid fal.ai model and all major image parameters.\n- Works out of the box with Node.js and a fal.ai API key.\n- Saves images locally with accessible file paths.\n- Simple configuration and robust error handling.\n\n## Quick Start\n\n1. **Requirements:** Node.js 18+, [fal.ai API key](https://fal.ai)\n2. **Configure MCP:**\n   ```json\n   {\n     \"mcpServers\": {\n       \"fal-ai-image\": {\n         \"command\": \"npx\",\n         \"args\": [\"-y\", \"mcp-fal-ai-image\"],\n         \"env\": { \"FAL_KEY\": \"YOUR-FAL-AI-API-KEY\" }\n       }\n     }\n   }\n   ```\n3. **Run:** Use the `generate-image` tool from your IDE.\n\n> **ğŸ’¡ Typical Workflow:**\n> Describe the image you want (e.g., â€œgenerate a landscape with flying cars using model fal-ai/kolors, 2 images, landscape_16_9â€) and get instant results in your IDE.\n\n### ğŸ—¨ï¸ Example Prompts\n\n- `generate an image of a red apple`\n- `generate an image of a red apple using model fal-ai/kolors`\n- `generate 3 images of a glowing red apple in a futuristic city using model fal-ai/recraft-v3, square_hd, 40 inference steps, guidance scale 4.0, safety checker on`\n\n**Supported parameters:** prompt, model ID (any fal.ai model), number of images, image size, inference steps, guidance scale, safety checker.\n\nImages are saved locally; file paths are shown in the response. For model IDs, see [fal.ai/models](https://fal.ai/models).\n\n## Troubleshooting\n\n- `FAL_KEY environment variable is not set`: Set your fal.ai API key as above.\n- `npx` not found: Install Node.js 18+ and npm.\n\n<details>\n<summary>Advanced: Example MCP Request/Response</summary>\n\n```json\n{\n  \"tool\": \"generate-image\",\n  \"args\": {\n    \"prompt\": \"A futuristic cityscape at sunset\",\n    \"model\": \"fal-ai/kolors\"\n  }\n}\n\n// Example response\n{\n  \"images\": [\n    { \"url\": \"file:///path/to/generated_image1.png\" },\n    { \"url\": \"file:///path/to/generated_image2.png\" }\n  ]\n}\n```\n\n</details>\n\n## ğŸ“ Image Output Directory\n\nGenerated images are saved to your local system:\n\n- **By default:** `~/Downloads/fal_ai` (on Linux/macOS; uses XDG standard if available)\n- **Custom location:** Set the environment variable `FAL_IMAGES_OUTPUT_DIR` to your desired folder. Images will be saved in `<your-folder>/fal_ai`.\n\nThe full file path for each image is included in the tool's response.\n\n## âš ï¸ Error Handling & Troubleshooting\n\n- If you specify a model ID that is not supported by fal.ai, you will receive an error from the backend. Double-check for typos or visit [fal.ai/models](https://fal.ai/models) to confirm the model ID.\n- For the latest list of models and their capabilities, refer to the [fal.ai model catalog](https://fal.ai/models) or [API docs](https://fal.ai/docs/api).\n- For other errors, consult your MCP client logs or open an issue on GitHub.\n\n## ğŸ¤ Contributing\n\nContributions and suggestions are welcome! Please open issues or pull requests on [GitHub](https://github.com/madhusudan-kulkarni/mcp-fal-ai-image).\n\n## ğŸ”’ Security\n\n- Your API key is only used locally to authenticate with fal.ai.\n- No user data is stored or transmitted except as required by fal.ai API.\n\n## ğŸ”— Links\n\n- [NPM](https://www.npmjs.com/package/mcp-fal-ai-image)\n- [GitHub](https://github.com/madhusudan-kulkarni/mcp-fal-ai-image)\n- [fal.ai](https://fal.ai)\n\n## ğŸ›¡ License\n\nMIT License Â© 2025 Madhusudan Kulkarni\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "manascb1344--together-mcp-server": {
      "owner": "manascb1344",
      "name": "together-mcp-server",
      "url": "https://github.com/manascb1344/together-mcp-server",
      "imageUrl": "https://github.com/manascb1344.png",
      "description": "Generate high-quality images using the Flux.1 Schnell model by specifying customizable parameters such as width and height, while ensuring clear error handling for prompt validation and API interactions.",
      "stars": 9,
      "forks": 5,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-07-30T19:28:08Z",
      "readme_content": "# Image Generation MCP Server\n\nA Model Context Protocol (MCP) server that enables seamless generation of high-quality images using the Flux.1 Schnell model via Together AI. This server provides a standardized interface to specify image generation parameters.\n<div align=\"center\">\n  \n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/manascb1344/together-mcp-server)\n\n</div>\n\n<div align=\"center\">\n\n<a href=\"https://glama.ai/mcp/servers/y6qfizhsja\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/y6qfizhsja/badge\" alt=\"Image Generation Server MCP server\" />\n</a>\n</div>\n\n## Features\n\n- High-quality image generation powered by the Flux.1 Schnell model\n- Support for customizable dimensions (width and height)\n- Clear error handling for prompt validation and API issues\n- Easy integration with MCP-compatible clients\n- Optional image saving to disk in PNG format\n\n## Installation\n\n```bash\nnpm install together-mcp\n```\n\nOr run directly:\n\n```bash\nnpx together-mcp@latest\n```\n\n### Configuration\n\nAdd to your MCP server configuration:\n\n<summary>Configuration Example</summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"together-image-gen\": {\n      \"command\": \"npx\",\n      \"args\": [\"together-mcp@latest -y\"],\n      \"env\": {\n        \"TOGETHER_API_KEY\": \"<API KEY>\"\n      }\n    }\n  }\n}\n```\n\n## Usage\n\nThe server provides one tool: `generate_image`\n\n### Using generate_image\n\nThis tool has only one required parameter - the prompt. All other parameters are optional and use sensible defaults if not provided.\n\n#### Parameters\n\n```typescript\n{\n  // Required\n  prompt: string;          // Text description of the image to generate\n\n  // Optional with defaults\n  model?: string;          // Default: \"black-forest-labs/FLUX.1-schnell-Free\"\n  width?: number;          // Default: 1024 (min: 128, max: 2048)\n  height?: number;         // Default: 768 (min: 128, max: 2048)\n  steps?: number;          // Default: 1 (min: 1, max: 100)\n  n?: number;             // Default: 1 (max: 4)\n  response_format?: string; // Default: \"b64_json\" (options: [\"b64_json\", \"url\"])\n  image_path?: string;     // Optional: Path to save the generated image as PNG\n}\n```\n\n#### Minimal Request Example\n\nOnly the prompt is required:\n\n```json\n{\n  \"name\": \"generate_image\",\n  \"arguments\": {\n    \"prompt\": \"A serene mountain landscape at sunset\"\n  }\n}\n```\n\n#### Full Request Example with Image Saving\n\nOverride any defaults and specify a path to save the image:\n\n```json\n{\n  \"name\": \"generate_image\",\n  \"arguments\": {\n    \"prompt\": \"A serene mountain landscape at sunset\",\n    \"width\": 1024,\n    \"height\": 768,\n    \"steps\": 20,\n    \"n\": 1,\n    \"response_format\": \"b64_json\",\n    \"model\": \"black-forest-labs/FLUX.1-schnell-Free\",\n    \"image_path\": \"/path/to/save/image.png\"\n  }\n}\n```\n\n#### Response Format\n\nThe response will be a JSON object containing:\n\n```json\n{\n  \"id\": string,        // Generation ID\n  \"model\": string,     // Model used\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"timings\": {\n        \"inference\": number  // Time taken for inference\n      },\n      \"index\": number,      // Image index\n      \"b64_json\": string    // Base64 encoded image data (if response_format is \"b64_json\")\n      // OR\n      \"url\": string        // URL to generated image (if response_format is \"url\")\n    }\n  ]\n}\n```\n\nIf image_path was provided and the save was successful, the response will include confirmation of the save location.\n\n### Default Values\n\nIf not specified in the request, these defaults are used:\n\n- model: \"black-forest-labs/FLUX.1-schnell-Free\"\n- width: 1024\n- height: 768\n- steps: 1\n- n: 1\n- response_format: \"b64_json\"\n\n### Important Notes\n\n1. Only the `prompt` parameter is required\n2. All optional parameters use defaults if not provided\n3. When provided, parameters must meet their constraints (e.g., width/height ranges)\n4. Base64 responses can be large - use URL format for larger images\n5. When saving images, ensure the specified directory exists and is writable\n\n## Prerequisites\n\n- Node.js >= 16\n- Together AI API key\n  1. Sign in at [api.together.xyz](https://api.together.xyz/)\n  2. Navigate to [API Keys settings](https://api.together.xyz/settings/api-keys)\n  3. Click \"Create\" to generate a new API key\n  4. Copy the generated key for use in your MCP configuration\n\n## Dependencies\n\n```json\n{\n  \"@modelcontextprotocol/sdk\": \"0.6.0\",\n  \"axios\": \"^1.6.7\"\n}\n```\n\n## Development\n\nClone and build the project:\n\n```bash\ngit clone https://github.com/manascb1344/together-mcp-server\ncd together-mcp-server\nnpm install\nnpm run build\n```\n\n### Available Scripts\n\n- `npm run build` - Build the TypeScript project\n- `npm run watch` - Watch for changes and rebuild\n- `npm run inspector` - Run MCP inspector\n\n## Contributing\n\nContributions are welcome! Please follow these steps:\n\n1. Fork the repository\n2. Create a new branch (`feature/my-new-feature`)\n3. Commit your changes\n4. Push the branch to your fork\n5. Open a Pull Request\n\nFeature requests and bug reports can be submitted via GitHub Issues. Please check existing issues before creating a new one.\n\nFor significant changes, please open an issue first to discuss your proposed changes.\n\n## License\n\nThis project is licensed under the MIT License. See the LICENSE file for details.",
      "npm_url": "",
      "npm_downloads": 0
    },
    "maoxiaoke--mcp-media-processor": {
      "owner": "maoxiaoke",
      "name": "mcp-media-processor",
      "url": "https://github.com/maoxiaoke/mcp-media-processor",
      "imageUrl": "https://github.com/maoxiaoke.png",
      "description": "A Node.js server for executing various media processing tasks, including video and image manipulation. It supports operations like video conversion, image effects, and media compression.",
      "stars": 24,
      "forks": 5,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-16T09:41:08Z",
      "readme_content": "# MCP Media Processing Server\n\n[![smithery badge](https://smithery.ai/badge/@maoxiaoke/mcp-media-processor)](https://smithery.ai/server/@maoxiaoke/mcp-media-processor)\n\nA Node.js server implementing Model Context Protocol (MCP) for media processing operations, providing powerful video and image manipulation capabilities.\n\n## Features\n\n* Video processing and conversion\n* Image processing and manipulation\n* Media compression\n* Video trimming and editing\n* Image effects and watermarking\n\n## Prerequisites\n\nBefore using this server, make sure you have the following dependencies installed on your system:\n\n* **FFmpeg**: Required for video processing operations\n  * macOS: `brew install ffmpeg`\n  * Ubuntu/Debian: `sudo apt-get install ffmpeg`\n  * Windows: Download from [FFmpeg official website](https://ffmpeg.org/download.html)\n\n* **ImageMagick**: Required for image processing operations\n  * macOS: `brew install imagemagick`\n  * Ubuntu/Debian: `sudo apt-get install imagemagick`\n  * Windows: Download from [ImageMagick official website](https://imagemagick.org/script/download.php)\n\n## How to use\n\nAdd this to your `claude_desktop_config.json`:\n\n### NPX\n\n```json\n{\n  \"mcpServers\": {\n    \"mediaProcessor\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-media-processor@latest\"\n      ]\n    }\n  }\n}\n```\n\n## API\n\n### Tools\n\n#### Video Operations\n\n* **execute-ffmpeg**\n  * Execute any FFmpeg command with custom options\n  * Inputs:\n    * `inputPath` (string): Absolute path to input video file\n    * `options` (string[]): Array of FFmpeg command options\n    * `outputPath` (string, optional): Absolute path for output file\n    * `outputFilename` (string, optional): Output filename\n\n* **convert-video**\n  * Convert video to different format\n  * Inputs:\n    * `inputPath` (string): Absolute path to input video file\n    * `outputFormat` (string): Desired output format (e.g., mp4, mkv, avi)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **compress-video**\n  * Compress video file\n  * Inputs:\n    * `inputPath` (string): Absolute path to input video file\n    * `quality` (number, optional): Compression quality (1-51, lower is better quality)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **trim-video**\n  * Trim video to specified duration\n  * Inputs:\n    * `inputPath` (string): Absolute path to input video file\n    * `startTime` (string): Start time in format HH:MM:SS\n    * `duration` (string): Duration in format HH:MM:SS\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n#### Image Operations\n\n* **compress-image**\n  * Compress PNG image using ImageMagick\n  * Inputs:\n    * `inputPath` (string): Absolute path to input PNG image\n    * `quality` (number, optional): Compression quality (1-100)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **convert-image**\n  * Convert image to different format\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `outputFormat` (string): Desired output format (e.g., jpg, png, webp, gif)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **resize-image**\n  * Resize image to specified dimensions\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `width` (number, optional): Target width in pixels\n    * `height` (number, optional): Target height in pixels\n    * `maintainAspectRatio` (boolean, optional): Whether to maintain aspect ratio\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **rotate-image**\n  * Rotate image by specified degrees\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `degrees` (number): Rotation angle in degrees\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **add-watermark**\n  * Add watermark to image\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `watermarkPath` (string): Absolute path to watermark image file\n    * `position` (string, optional): Position of watermark (default: \"southeast\")\n    * `opacity` (number, optional): Watermark opacity (0-100)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **apply-effect**\n  * Apply visual effect to image\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `effect` (string): Effect to apply (blur, sharpen, edge, emboss, grayscale, sepia, negate)\n    * `intensity` (number, optional): Effect intensity (0-100)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "mario-andreschak--mcp-veo2": {
      "owner": "mario-andreschak",
      "name": "mcp-veo2",
      "url": "https://github.com/mario-andreschak/mcp-veo2",
      "imageUrl": "https://github.com/mario-andreschak.png",
      "description": "Generates high-quality videos from text prompts or images using Google's Veo2 model and provides access to these generated videos through MCP resources.",
      "stars": 30,
      "forks": 17,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T22:32:31Z",
      "readme_content": "# MCP Video Generation with Veo2\n\n[![smithery badge](https://smithery.ai/badge/@mario-andreschak/mcp-video-generation-veo2)](https://smithery.ai/server/@mario-andreschak/mcp-video-generation-veo2)\n\nThis project implements a Model Context Protocol (MCP) server that exposes Google's Veo2 video generation capabilities. It allows clients to generate videos from text prompts or images, and access the generated videos through MCP resources.\n\n<a href=\"https://glama.ai/mcp/servers/@mario-andreschak/mcp-veo2\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@mario-andreschak/mcp-veo2/badge\" alt=\"Video Generation with Veo2 MCP server\" />\n</a>\n\n## Features\n\n- Generate **videos from text** prompts\n- Generate **videos from images**\n- Access generated videos through MCP resources\n- Example video generation templates\n- Support for both stdio and SSE transports\n\n## Example Images\n![1dec9c71-07dc-4a6e-9e17-8da355d72ba1](https://github.com/user-attachments/assets/ba987d14-dd46-49ac-9b31-1ce398e86c6f)\n\n\n## Example Image to Video\n[Image to Video - from Grok generated puppy](https://github.com/mario-andreschak/mcp-veo2/raw/refs/heads/main/example-files/2a6a0807-d323-4424-a48a-e40a82b883bb.mp4)\n\n[Image to Video - from real cat](https://github.com/mario-andreschak/mcp-veo2/raw/refs/heads/main/example-files/55b9f28b-61a6-423e-bb86-f3791c639177.mp4)\n\n\n## Prerequisites\n\n- Node.js 18 or higher\n- Google API key with access to Gemini API and Veo2 model (= You need to set up a credit card with your API key! -> Go to aistudio.google.com )\n\n## Installation\n\n### Installing in [FLUJO](https://github.com/mario-andreschak/FLUJO/)\n1. Click Add Server\n2. Copy & Paste Github URL into FLUJO\n3. Click Parse, Clone, Install, Build and Save.\n\n### Installing via Smithery\n\nTo install mcp-video-generation-veo2 for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@mario-andreschak/mcp-veo2):\n\n```bash\nnpx -y @smithery/cli install @mario-andreschak/mcp-veo2 --client claude\n```\n\n### Manual Installation\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/yourusername/mcp-video-generation-veo2.git\n   cd mcp-video-generation-veo2\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Create a `.env` file with your Google API key:\n   ```bash\n   cp .env.example .env\n   # Edit .env and add your Google API key\n   ```\n\n   The `.env` file supports the following variables:\n   - `GOOGLE_API_KEY`: Your Google API key (required)\n   - `PORT`: Server port (default: 3000)\n   - `STORAGE_DIR`: Directory for storing generated videos (default: ./generated-videos)\n   - `LOG_LEVEL`: Logging level (default: fatal)\n     - Available levels: verbose, debug, info, warn, error, fatal, none\n     - For development, set to `debug` or `info` for more detailed logs\n     - For production, keep as `fatal` to minimize console output\n\n4. Build the project:\n   ```bash\n   npm run build\n   ```\n\n## Usage\n\n### Starting the Server\n\nYou can start the server with either stdio or SSE transport:\n\n#### stdio Transport (Default)\n\n```bash\nnpm start\n# or\nnpm start stdio\n```\n\n#### SSE Transport\n\n```bash\nnpm start sse\n```\n\nThis will start the server on port 3000 (or the port specified in your `.env` file).\n\n### MCP Tools\n\nThe server exposes the following MCP tools:\n\n#### generateVideoFromText\n\nGenerates a video from a text prompt.\n\nParameters:\n- `prompt` (string): The text prompt for video generation\n- `config` (object, optional): Configuration options\n  - `aspectRatio` (string, optional): \"16:9\" or \"9:16\"\n  - `personGeneration` (string, optional): \"dont_allow\" or \"allow_adult\"\n  - `numberOfVideos` (number, optional): 1 or 2\n  - `durationSeconds` (number, optional): Between 5 and 8\n  - `enhancePrompt` (boolean, optional): Whether to enhance the prompt\n  - `negativePrompt` (string, optional): Text describing what not to generate\n\nExample:\n```json\n{\n  \"prompt\": \"Panning wide shot of a serene forest with sunlight filtering through the trees, cinematic quality\",\n  \"config\": {\n    \"aspectRatio\": \"16:9\",\n    \"personGeneration\": \"dont_allow\",\n    \"durationSeconds\": 8\n  }\n}\n```\n\n#### generateVideoFromImage\n\nGenerates a video from an image.\n\nParameters:\n- `image` (string): Base64-encoded image data\n- `prompt` (string, optional): Text prompt to guide the video generation\n- `config` (object, optional): Configuration options (same as above, but personGeneration only supports \"dont_allow\")\n\n#### listGeneratedVideos\n\nLists all generated videos.\n\n### MCP Resources\n\nThe server exposes the following MCP resources:\n\n#### videos://{id}\n\nAccess a generated video by its ID.\n\n#### videos://templates\n\nAccess example video generation templates.\n\n## Development\n\n### Project Structure\n\n- `src/`: Source code\n  - `index.ts`: Main entry point\n  - `server.ts`: MCP server configuration\n  - `config.ts`: Configuration handling\n  - `tools/`: MCP tool implementations\n  - `resources/`: MCP resource implementations\n  - `services/`: External service integrations\n  - `utils/`: Utility functions\n\n### Building\n\n```bash\nnpm run build\n```\n\n### Development Mode\n\n```bash\nnpm run dev\n```\n\n## License\n\nMIT",
      "npm_url": "",
      "npm_downloads": 0
    },
    "mario-andreschak--mcp-image-recognition": {
      "owner": "mario-andreschak",
      "name": "mcp-image-recognition",
      "url": "https://github.com/mario-andreschak/mcp-image-recognition",
      "imageUrl": "https://github.com/mario-andreschak.png",
      "description": "Leverages image recognition capabilities to analyze and describe images using advanced vision APIs. Supports multiple formats and allows for optional text extraction from images.",
      "stars": 26,
      "forks": 8,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T22:32:16Z",
      "readme_content": "# MCP Image Recognition Server\n\nAn MCP server that provides image recognition capabilities using Anthropic and OpenAI vision APIs. Version 0.1.2.\n\n## Features\n\n- Image description using Anthropic Claude Vision or OpenAI GPT-4 Vision\n- Support for multiple image formats (JPEG, PNG, GIF, WebP)\n- Configurable primary and fallback providers\n- Base64 and file-based image input support\n- Optional text extraction using Tesseract OCR\n\n## Requirements\n\n- Python 3.8 or higher\n- Tesseract OCR (optional) - Required for text extraction feature\n  - Windows: Download and install from [UB-Mannheim/tesseract](https://github.com/UB-Mannheim/tesseract/wiki)\n  - Linux: `sudo apt-get install tesseract-ocr`\n  - macOS: `brew install tesseract`\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/mario-andreschak/mcp-image-recognition.git\ncd mcp-image-recognition\n```\n\n2. Create and configure your environment file:\n```bash\ncp .env.example .env\n# Edit .env with your API keys and preferences\n```\n\n3. Build the project:\n```bash\nbuild.bat\n```\n\n## Usage\n\n### Running the Server\nSpawn the server using python:\n```bash\npython -m image_recognition_server.server\n```\n\nStart the server using batch instead:\n```bash\nrun.bat server\n```\n\nStart the server in development mode with the MCP Inspector:\n```bash\nrun.bat debug\n```\n\n### Available Tools\n\n1. `describe_image`\n   - Input: Base64-encoded image data and MIME type\n   - Output: Detailed description of the image\n\n2. `describe_image_from_file`\n   - Input: Path to an image file\n   - Output: Detailed description of the image\n\n### Environment Configuration\n\n- `ANTHROPIC_API_KEY`: Your Anthropic API key.\n- `OPENAI_API_KEY`: Your OpenAI API key.\n- `VISION_PROVIDER`: Primary vision provider (`anthropic` or `openai`).\n- `FALLBACK_PROVIDER`: Optional fallback provider.\n- `LOG_LEVEL`: Logging level (DEBUG, INFO, WARNING, ERROR).\n- `ENABLE_OCR`: Enable Tesseract OCR text extraction (`true` or `false`).\n- `TESSERACT_CMD`: Optional custom path to Tesseract executable.\n- `OPENAI_MODEL`: OpenAI Model (default: `gpt-4o-mini`). Can use OpenRouter format for other models (e.g., `anthropic/claude-3.5-sonnet:beta`).\n- `OPENAI_BASE_URL`: Optional custom base URL for the OpenAI API.  Set to `https://openrouter.ai/api/v1` for OpenRouter.\n- `OPENAI_TIMEOUT`: Optional custom timeout (in seconds) for the OpenAI API.\n\n### Using OpenRouter\n\nOpenRouter allows you to access various models using the OpenAI API format. To use OpenRouter, follow these steps:\n\n1.  Obtain an OpenAI API key from OpenRouter.\n2.  Set `OPENAI_API_KEY` in your `.env` file to your OpenRouter API key.\n3.  Set `OPENAI_BASE_URL` to `https://openrouter.ai/api/v1`.\n4.  Set `OPENAI_MODEL` to the desired model using the OpenRouter format (e.g., `anthropic/claude-3.5-sonnet:beta`).\n5. Set `VISION_PROVIDER` to `openai`.\n\n### Default Models\n\n- Anthropic: `claude-3.5-sonnet-beta`\n- OpenAI: `gpt-4o-mini`\n- OpenRouter: Use the `anthropic/claude-3.5-sonnet:beta` format in `OPENAI_MODEL`.\n\n## Development\n\n### Running Tests\n\nRun all tests:\n```bash\nrun.bat test\n```\n\nRun specific test suite:\n```bash\nrun.bat test server\nrun.bat test anthropic\nrun.bat test openai\n```\n\n### Docker Support\n\nBuild the Docker image:\n```bash\ndocker build -t mcp-image-recognition .\n```\n\nRun the container:\n```bash\ndocker run -it --env-file .env mcp-image-recognition\n```\n\n## License\n\nMIT License - see LICENSE file for details.\n\n## Release History\n\n- **0.1.2** (2025-02-20): Improved OCR error handling and added comprehensive test coverage for OCR functionality\n- **0.1.1** (2025-02-19): Added Tesseract OCR support for text extraction from images (optional feature)\n- **0.1.0** (2025-02-19): Initial release with Anthropic and OpenAI vision support\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "MichaelYangjson--mcp-ghibli-video": {
      "owner": "MichaelYangjson",
      "name": "mcp-ghibli-video",
      "url": "https://github.com/MichaelYangjson/mcp-ghibli-video",
      "imageUrl": "https://github.com/MichaelYangjson.png",
      "description": "Transforms static images into animated videos using AI technology. Users can manage video generation tasks and check API credits through a straightforward interface.",
      "stars": 4,
      "forks": 5,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-29T13:57:06Z",
      "readme_content": "# mcp-server-ghibli MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@MichaelYangjson/mcp-ghibli-video)](https://smithery.ai/server/@MichaelYangjson/mcp-ghibli-video)\n\nA TypeScript-based MCP server that provides AI image and video generation capabilities through a simple interface.\n\n> **Note**: This server requires an API key from [GPT4O Image Generator](https://www.gpt4oimg.com/). Please visit the website to obtain your API key before using this service.\n\n## Features\n\n### Tools\n\n#### 1. Image to Video Conversion\n\n- `image_to_video` - Convert static images into animated videos\n  - Required parameters:\n    - `image`: Base64 encoded image or image URL\n    - `api_key`: Authentication key\n  - Optional parameters:\n    - `prompt`: Text prompt to guide video generation (default: \"in the style of ghibli\")\n    - `aspect_ratio`: Output video aspect ratio (default: \"9:16\")\n    - `negative_prompt`: Negative prompt to guide generation (default: \"bad prompt\")\n\n#### 2. Points Management\n\n- `get_points` - Check remaining API credits\n  - Required parameters:\n    - `api_key`: Authentication key\n\n#### 3. Task Management\n\n- `get_task_result` - Check the status of a video generation task\n  - Required parameters:\n    - `taskId`: Task ID returned from image_to_video\n    - `api_key`: Authentication key\n\n## Development\n\nInstall dependencies:\n\n```bash\nnpm install\n```\n\nBuild the server:\n\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-ghibli-video\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@openmcprouter/mcp-server-ghibli-video\"],\n      \"env\": {\n        \"Ghibli_API_URL\": \"https://www.gpt4oimg.com\"\n      }\n    }\n  }\n}\n```\n\n### Installing via Smithery\n\nTo install mcp-server-ghibli MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@MichaelYangjson/mcp-ghibli-video):\n\n```bash\nnpx -y @smithery/cli install @MichaelYangjson/mcp-ghibli-video --client claude\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "mikeyny--ai-image-gen-mcp": {
      "owner": "mikeyny",
      "name": "ai-image-gen-mcp",
      "url": "https://github.com/mikeyny/ai-image-gen-mcp",
      "imageUrl": "https://github.com/mikeyny.png",
      "description": "Generate images from text prompts using Replicate's flux-schnell model, with configurable image parameters and the ability to save generated images to a specified directory.",
      "stars": 126,
      "forks": 15,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-11T02:43:44Z",
      "readme_content": "# Image Generation MCP Server\n\nAn [MCP (Model Context Protocol)](https://modelcontextprotocol.io/) server implementation for generating images using Replicate's [`black-forest-labs/flux-schnell`](https://replicate.com/black-forest-labs/flux-schnell) model.\n\nIdeally to be used with Cursor's MCP feature, but can be used with any MCP client.\n\n## Features\n\n- Generate images from text prompts\n- Configurable image parameters (resolution, aspect ratio, quality)\n- Save generated images to specified directory\n- Full MCP protocol compliance\n- Error handling and validation\n\n## Prerequisites\n\n- Node.js 16+\n- Replicate API token\n- TypeScript SDK for MCP\n\n## Setup\n\n1. Clone the repository\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n3. Add your Replicate API token directly in the code at `src/imageService.ts` by updating the `apiToken` constant:\n   ```bash\n   // No environment variables are used since they can't be easily set in cursor\n   const apiToken = \"your-replicate-api-token-here\";\n   ```\n\n   > **Note:** If using with Claude, you can create a `.env` file in the root directory and set your API token there:\n   ```bash\n   REPLICATE_API_TOKEN=your-replicate-api-token-here\n   ```\n\n   Then build the project:\n   ```bash\n   npm run build\n   ```\n\n## Usage\n\nTo use with cursor:\n1. Go to Settings\n2. Select Features\n3. Scroll down to \"MCP Servers\"\n4. Click \"Add new MCP Server\"\n5. Set Type to \"Command\"\n6. Set Command to: `node ./path/to/dist/server.js`\n\n## API Parameters\n\n| Parameter           | Type    | Required | Default | Description                                     |\n|--------------------|---------|----------|---------|------------------------------------------------|\n| `prompt`           | string  | Yes      | -       | Text prompt for image generation               |\n| `output_dir`       | string  | Yes      | -       | Server directory path to save generated images |\n| `go_fast`          | boolean | No       | false   | Enable faster generation mode                  |\n| `megapixels`       | string  | No       | \"1\"     | Resolution quality (\"1\", \"2\", \"4\")            |\n| `num_outputs`      | number  | No       | 1       | Number of images to generate (1-4)            |\n| `aspect_ratio`     | string  | No       | \"1:1\"   | Aspect ratio (\"1:1\", \"4:3\", \"16:9\")          |\n| `output_format`    | string  | No       | \"webp\"  | Image format (\"webp\", \"png\", \"jpeg\")         |\n| `output_quality`   | number  | No       | 80      | Compression quality (1-100)                   |\n| `num_inference_steps`| number| No       | 4       | Number of denoising steps (4-20)             |\n\n## Example Request\n\n```json\n{\n  \"prompt\": \"black forest gateau cake spelling out 'FLUX SCHNELL'\",\n  \"output_dir\": \"/var/output/images\",\n  \"filename\": \"black_forest_cake\",\n  \"output_format\": \"webp\"\n  \"go_fast\": true,\n  \"megapixels\": \"1\",\n  \"num_outputs\": 2,\n  \"aspect_ratio\": \"1:1\"\n}\n```\n\n## Example Response\n\n```json\n{\n  \"image_paths\": [\n    \"/var/output/images/output_0.webp\",\n    \"/var/output/images/output_1.webp\"\n  ],\n  \"metadata\": {\n    \"model\": \"black-forest-labs/flux-schnell\",\n    \"inference_time_ms\": 2847\n  }\n}\n```\n\n## Error Handling\n\nThe server handles the following error types:\n\n- Validation errors (invalid parameters)\n- API errors (Replicate API issues)\n- Server errors (filesystem, permissions)\n- Unknown errors (unexpected issues)\n\nEach error response includes:\n- Error code\n- Human-readable message\n- Detailed error information\n\n## License\n\nISC ",
      "npm_url": "",
      "npm_downloads": 0
    },
    "MiniMax-AI--MiniMax-MCP-JS": {
      "owner": "MiniMax-AI",
      "name": "MiniMax-MCP-JS",
      "url": "https://github.com/MiniMax-AI/MiniMax-MCP-JS",
      "imageUrl": "https://github.com/MiniMax-AI.png",
      "description": "Integrates with MiniMax's AI capabilities to facilitate interaction with multimedia generation tools, including image generation, video generation, text-to-speech, and voice cloning. Supports a flexible and configurable JavaScript/TypeScript framework for versatile deployment scenarios.",
      "stars": 84,
      "forks": 29,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-28T15:24:03Z",
      "readme_content": "![export](https://github.com/MiniMax-AI/MiniMax-01/raw/main/figures/MiniMaxLogo-Light.png)\n\n<div align=\"center\">\n\n# MiniMax MCP JS\n\nJavaScript/TypeScript implementation of MiniMax MCP, providing image generation, video generation, text-to-speech, and more.\n\n<div style=\"line-height: 1.5;\">\n  <a href=\"https://www.minimax.io\" target=\"_blank\" style=\"margin: 2px; color: var(--fgColor-default);\">\n    <img alt=\"Homepage\" src=\"https://img.shields.io/badge/_Homepage-MiniMax-FF4040?style=flat-square&labelColor=2C3E50&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDkwLjE2IDQxMS43Ij48ZGVmcz48c3R5bGU+LmNscy0xe2ZpbGw6I2ZmZjt9PC9zdHlsZT48L2RlZnM+PHBhdGggY2xhc3M9ImNscy0xIiBkPSJNMjMzLjQ1LDQwLjgxYTE3LjU1LDE3LjU1LDAsMSwwLTM1LjEsMFYzMzEuNTZhNDAuODIsNDAuODIsMCwwLDEtODEuNjMsMFYxNDVhMTcuNTUsMTcuNTUsMCwxLDAtMzUuMDksMHY3OS4wNmE0MC44Miw0MC44MiwwLDAsMS04MS42MywwVjE5NS40MmExMS42MywxMS42MywwLDAsMSwyMy4yNiwwdjI4LjY2YTE3LjU1LDE3LjU1LDAsMCwwLDM1LjEsMFYxNDVBNDAuODIsNDAuODIsMCwwLDEsMTQwLDE0NVYzMzEuNTZhMTcuNTUsMTcuNTUsMCwwLDAsMzUuMSwwVjIxNy41aDBWNDAuODFhNDAuODEsNDAuODEsMCwxLDEsODEuNjIsMFYyODEuNTZhMTEuNjMsMTEuNjMsMCwxLDEtMjMuMjYsMFptMjE1LjksNjMuNEE0MC44Niw0MC44NiwwLDAsMCw0MDguNTMsMTQ1VjMwMC44NWExNy41NSwxNy41NSwwLDAsMS0zNS4wOSwwdi0yNjBhNDAuODIsNDAuODIsMCwwLDAtODEuNjMsMFYzNzAuODlhMTcuNTUsMTcuNTUsMCwwLDEtMzUuMSwwVjMzMGExMS42MywxMS42MywwLDEsMC0yMy4yNiwwdjQwLjg2YTQwLjgxLDQwLjgxLDAsMCwwLDgxLjYyLDBWNDAuODFhMTcuNTUsMTcuNTUsMCwwLDEsMzUuMSwwdjI2MGE0MC44Miw0MC44MiwwLDAsMCw4MS42MywwVjE0NWExNy41NSwxNy41NSwwLDEsMSwzNS4xLDBWMjgxLjU2YTExLjYzLDExLjYzLDAsMCwwLDIzLjI2LDBWMTQ1QTQwLjg1LDQwLjg1LDAsMCwwLDQ0OS4zNSwxMDQuMjFaIi8+PC9zdmc+&logoWidth=20\" style=\"display: inline-block; vertical-align: middle;\"/>\n  </a>\n  <a href=\"https://arxiv.org/abs/2501.08313\" target=\"_blank\" style=\"margin: 2px;\">\n    <img alt=\"Paper\" src=\"https://img.shields.io/badge/ğŸ“–_Paper-MiniMax--01-FF4040?style=flat-square&labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/>\n  </a>\n  <a href=\"https://chat.minimax.io/\" target=\"_blank\" style=\"margin: 2px;\">\n    <img alt=\"Chat\" src=\"https://img.shields.io/badge/_MiniMax_Chat-FF4040?style=flat-square&labelColor=2C3E50&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDkwLjE2IDQxMS43Ij48ZGVmcz48c3R5bGU+LmNscy0xe2ZpbGw6I2ZmZjt9PC9zdHlsZT48L2RlZnM+PHBhdGggY2xhc3M9ImNscy0xIiBkPSJNMjMzLjQ1LDQwLjgxYTE3LjU1LDE3LjU1LDAsMSwwLTM1LjEsMFYzMzEuNTZhNDAuODIsNDAuODIsMCwwLDEtODEuNjMsMFYxNDVhMTcuNTUsMTcuNTUsMCwxLDAtMzUuMDksMHY3OS4wNmE0MC44Miw0MC44MiwwLDAsMS04MS42MywwVjE5NS40MmExMS42MywxMS42MywwLDAsMSwyMy4yNiwwdjI4LjY2YTE3LjU1LDE3LjU1LDAsMCwwLDM1LjEsMFYxNDVBNDAuODIsNDAuODIsMCwwLDEsMTQwLDE0NVYzMzEuNTZhMTcuNTUsMTcuNTUsMCwwLDAsMzUuMSwwVjIxNy41aDBWNDAuODFhNDAuODEsNDAuODEsMCwxLDEsODEuNjIsMFYyODEuNTZhMTEuNjMsMTEuNjMsMCwxLDEtMjMuMjYsMFptMjE1LjksNjMuNEE0MC44Niw0MC44NiwwLDAsMCw0MDguNTMsMTQ1VjMwMC44NWExNy41NSwxNy41NSwwLDAsMS0zNS4wOSwwdi0yNjBhNDAuODIsNDAuODIsMCwwLDAtODEuNjMsMFYzNzAuODlhMTcuNTUsMTcuNTUsMCwwLDEtMzUuMSwwVjMzMGExMS42MywxMS42MywwLDEsMC0yMy4yNiwwdjQwLjg2YTQwLjgxLDQwLjgxLDAsMCwwLDgxLjYyLDBWNDAuODFhMTcuNTUsMTcuNTUsMCwwLDEsMzUuMSwwdjI2MGE0MC44Miw0MC44MiwwLDAsMCw4MS42MywwVjE0NWExNy41NSwxNy41NSwwLDEsMSwzNS4xLDBWMjgxLjU2YTExLjYzLDExLjYzLDAsMCwwLDIzLjI2LDBWMTQ1QTQwLjg1LDQwLjg1LDAsMCwwLDQ0OS4zNSwxMDQuMjFaIi8+PC9zdmc+&logoWidth=20\" style=\"display: inline-block; vertical-align: middle;\"/>\n  </a>\n  <a href=\"https://www.minimax.io/platform\" style=\"margin: 2px;\">\n    <img alt=\"API\" src=\"https://img.shields.io/badge/âš¡_API-Platform-FF4040?style=flat-square&labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/>\n  </a>\n</div>\n\n<div style=\"line-height: 1.5;\">\n  <a href=\"https://huggingface.co/MiniMaxAI\" target=\"_blank\" style=\"margin: 2px;\">\n    <img alt=\"Hugging Face\" src=\"https://img.shields.io/badge/ğŸ¤—_Hugging_Face-MiniMax-FF4040?style=flat-square&labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/>\n  </a>\n  <a href=\"https://github.com/MiniMax-AI/MiniMax-AI.github.io/blob/main/images/wechat-qrcode.jpeg\" target=\"_blank\" style=\"margin: 2px;\">\n    <img alt=\"WeChat\" src=\"https://img.shields.io/badge/_WeChat-MiniMax-FF4040?style=flat-square&labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/>\n  </a>\n  <a href=\"https://www.modelscope.cn/organization/MiniMax\" target=\"_blank\" style=\"margin: 2px;\">\n    <img alt=\"ModelScope\" src=\"https://img.shields.io/badge/_ModelScope-MiniMax-FF4040?style=flat-square&labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/>\n  </a>\n</div>\n\n<div style=\"line-height: 1.5;\">\n  <a href=\"https://github.com/MiniMax-AI/MiniMax-MCP-JS/blob/main/LICENSE\" style=\"margin: 2px;\">\n    <img alt=\"Code License\" src=\"https://img.shields.io/badge/_Code_License-MIT-FF4040?style=flat-square&labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/>\n  </a>\n  <a href=\"https://smithery.ai/server/@MiniMax-AI/MiniMax-MCP-JS\"><img alt=\"Smithery Badge\" src=\"https://smithery.ai/badge/@MiniMax-AI/MiniMax-MCP-JS\"></a>\n</div>\n\n</div>\n\n## Documentation\n\n- [ä¸­æ–‡æ–‡æ¡£](README.zh-CN.md)\n- [Python Version](https://github.com/MiniMax-AI/MiniMax-MCP) - Official Python implementation of MiniMax MCP\n\n## Release Notes\n\n### July 22, 2025\n\n#### ğŸ”§ Fixes & Improvements\n- **TTS Tool Fixes**: Fixed parameter handling for `languageBoost` and `subtitleEnable` in the `text_to_audio` tool\n- **API Response Enhancement**: TTS API can return both audio file and subtitle file, providing a more complete speech-to-text experience\n\n### July 7, 2025\n\n#### ğŸ†• What's New\n- **Voice Design**: New `voice_design` tool - create custom voices from descriptive prompts with preview audio\n- **Video Enhancement**: Added `MiniMax-Hailuo-02` model with ultra-clear quality and duration/resolution controls  \n- **Music Generation**: Enhanced `music_generation` tool powered by `music-1.5` model\n\n#### ğŸ“ˆ Enhanced Tools\n- `voice_design` - Generate personalized voices from text descriptions\n- `generate_video` - Now supports MiniMax-Hailuo-02 with 6s/10s duration and 768P/1080P resolution options\n- `music_generation` - High-quality music creation with music-1.5 model\n\n## Features\n\n- Text-to-Speech (TTS)\n- Image Generation\n- Video Generation\n- Voice Cloning\n- Music Generation\n- Voice Design\n- Dynamic configuration (supports both environment variables and request parameters)\n- Compatible with MCP platform hosting (ModelScope and other MCP platforms)\n\n## Installation\n\n### Installing via Smithery\n\nTo install MiniMax MCP JS for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@MiniMax-AI/MiniMax-MCP-JS):\n\n```bash\nnpx -y @smithery/cli install @MiniMax-AI/MiniMax-MCP-JS --client claude\n```\n\n### Installing manually\n```bash\n# Install with pnpm (recommended)\npnpm add minimax-mcp-js\n```\n\n## Quick Start\n\nMiniMax MCP JS implements the [Model Context Protocol (MCP)](https://github.com/anthropics/model-context-protocol) specification and can be used as a server to interact with MCP-compatible clients (such as Claude AI).\n\n### Quickstart with MCP Client\n\n1. Get your API key from [MiniMax International Platform](https://www.minimax.io/platform/user-center/basic-information/interface-key).\n2. Make sure that you already installed [Node.js and npm](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm)\n3. **Important: API HOST&KEY are different in different region**, they must match, otherwise you will receive an `Invalid API key` error.\n\n|Region| Global  | Mainland  |\n|:--|:-----|:-----|\n|MINIMAX_API_KEY| go get from [MiniMax Global](https://www.minimax.io/platform/user-center/basic-information/interface-key) | go get from [MiniMax](https://platform.minimaxi.com/user-center/basic-information/interface-key) |\n|MINIMAX_API_HOST| â€‹https://api.minimaxi.chat (note the extra **\"i\"**) | â€‹https://api.minimax.chat |\n\n\n### Using with MCP Clients (Recommended)\n\nConfigure your MCP client:\n\n#### Claude Desktop\n\nGo to `Claude > Settings > Developer > Edit Config > claude_desktop_config.json` to include:\n\n```json\n{\n  \"mcpServers\": {\n    \"minimax-mcp-js\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"minimax-mcp-js\"\n      ],\n      \"env\": {\n        \"MINIMAX_API_HOST\": \"<https://api.minimaxi.chat|https://api.minimax.chat>\",\n        \"MINIMAX_API_KEY\": \"<your-api-key-here>\",\n        \"MINIMAX_MCP_BASE_PATH\": \"<local-output-dir-path, such as /User/xxx/Desktop>\",\n        \"MINIMAX_RESOURCE_MODE\": \"<optional, [url|local], url is default, audio/image/video are downloaded locally or provided in URL format>\"\n      }\n    }\n  }\n}\n```\n\n#### Cursor\n\nGo to `Cursor â†’ Preferences â†’ Cursor Settings â†’ MCP â†’ Add new global MCP Server` to add the above config.\n\nâš ï¸ **Note**: If you encounter a \"No tools found\" error when using MiniMax MCP JS with Cursor, please update your Cursor to the latest version. For more information, see this [discussion thread](https://forum.cursor.com/t/mcp-servers-no-tools-found/49094/23).\n\nThat's it. Your MCP client can now interact with MiniMax through these tools.\n\n**For local development**: \nWhen developing locally, you can use `npm link` to test your changes:\n```bash\n# In your project directory\nnpm link\n```\n\nThen configure Claude Desktop or Cursor to use npx as shown above. This will automatically use your linked version.\n\nâš ï¸ **Note**: The API key needs to match the host address. Different hosts are used for global and mainland China versions:\n- Global Host: `https://api.minimaxi.chat` (note the extra \"i\")\n- Mainland China Host: `https://api.minimaxi.chat`\n\n## Transport Modes\n\nMiniMax MCP JS supports three transport modes:\n\n| Feature | stdio (default) | REST | SSE |\n|:-----|:-----|:-----|:-----|\n| Environment | Local only | Local or cloud deployment | Local or cloud deployment |\n| Communication | Via `standard I/O` | Via `HTTP requests` | Via `server-sent events` |\n| Use Cases | Local MCP client integration | API services, cross-language calls | Applications requiring server push |\n| Input Restrictions | Supports `local files` or `URL` resources | When deployed in cloud, `URL` input recommended | When deployed in cloud, `URL` input recommended |\n\n## Configuration\n\nMiniMax-MCP-JS provides multiple flexible configuration methods to adapt to different use cases. The configuration priority from highest to lowest is as follows:\n\n### 1. Request Parameter Configuration (Highest Priority)\n\nIn platform hosting environments (like ModelScope or other MCP platforms), you can provide an independent configuration for each request via the `meta.auth` object in the request parameters:\n\n```json\n{\n  \"params\": {\n    \"meta\": {\n      \"auth\": {\n        \"api_key\": \"your_api_key_here\",\n        \"api_host\": \"<https://api.minimaxi.chat|https://api.minimaxi.chat>\",\n        \"base_path\": \"/path/to/output\",\n        \"resource_mode\": \"url\"\n      }\n    }\n  }\n}\n```\n\nThis method enables multi-tenant usage, where each request can use different API keys and configurations.\n\n### 2. API Configuration\n\nWhen used as a module in other projects, you can pass configuration through the `startMiniMaxMCP` function:\n\n```javascript\nimport { startMiniMaxMCP } from 'minimax-mcp-js';\n\nawait startMiniMaxMCP({\n  apiKey: 'your_api_key_here',\n  apiHost: 'https://api.minimaxi.chat', // Global Host - https://api.minimaxi.chat, Mainland Host - https://api.minimax.chat\n  basePath: '/path/to/output',\n  resourceMode: 'url'\n});\n```\n\n### 3. Command Line Arguments\n\n1. Install the CLI tool globally:\n```bash\n# Install globally\npnpm install -g minimax-mcp-js\n```\n\n2. When used as a CLI tool, you can provide configuration via command line arguments:\n\n```bash\nminimax-mcp-js --api-key your_api_key_here --api-host https://api.minimaxi.chat --base-path /path/to/output --resource-mode url\n```\n\n### 4. Environment Variables (Lowest Priority)\n\nThe most basic configuration method is through environment variables:\n\n```bash\n# MiniMax API Key (required)\nMINIMAX_API_KEY=your_api_key_here\n\n# Base path for output files (optional, defaults to user's desktop)\nMINIMAX_MCP_BASE_PATH=~/Desktop\n\n# MiniMax API Host (optional, defaults to https://api.minimaxi.chat, Global Host - https://api.minimaxi.chat, Mainland Host - https://api.minimax.chat)\nMINIMAX_API_HOST=https://api.minimaxi.chat\n\n# Resource mode (optional, defaults to 'url')\n# Options: 'url' (return URLs), 'local' (save files locally)\nMINIMAX_RESOURCE_MODE=url\n```\n\n### Configuration Priority\n\nWhen multiple configuration methods are used, the following priority order applies (from highest to lowest):\n\n1. **Request-level configuration** (via `meta.auth` in each API request)\n2. **Command line arguments**\n3. **Environment variables**\n4. **Configuration file**\n5. **Default values**\n\nThis prioritization ensures flexibility across different deployment scenarios while maintaining per-request configuration capabilities for multi-tenant environments.\n\n### Configuration Parameters\n\n| Parameter | Description | Default Value |\n|-----------|-------------|---------------|\n| apiKey | MiniMax API Key | None (Required) |\n| apiHost | MiniMax API Host | Global Host - https://api.minimaxi.chat, Mainland Host - https://api.minimax.chat |\n| basePath | Base path for output files | User's desktop |\n| resourceMode | Resource handling mode, 'url' or 'local' | url |\n\nâš ï¸ **Note**: The API key needs to match the host address. Different hosts are used for global and mainland China versions:\n- Global Host: `https://api.minimaxi.chat` (note the extra \"i\")\n- Mainland China Host: `https://api.minimax.chat`\n\n## Example usage\n\nâš ï¸ Warning: Using these tools may incur costs.\n\n### 1. broadcast a segment of the evening news\n<img src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/Snipaste_2025-04-09_20-07-53.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/>\n\n### 2. clone a voice\n<img src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/Snipaste_2025-04-09_19-45-13.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/>\n\n### 3. generate a video\n<img src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/Snipaste_2025-04-09_19-58-52.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/>\n<img src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/Snipaste_2025-04-09_19-59-43.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle; \"/>\n\n### 4. generate images\n<img src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/gen_image.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/>\n<img src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/gen_image1.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle; \"/>\n\n### 5. generate music\n<img src=\"https://filecdn.minimax.chat/public/5675b3dc-6789-4ceb-9505-8ef39ae4224f.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/>\n\n### 6. voice design\n<img src=\"https://filecdn.minimax.chat/public/5654f5df-0642-477f-9c5d-b853d185b8b0.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/>\n\n## Available Tools\n\n### Text to Audio\n\nConvert text to speech audio file.\n\nTool Name: `text_to_audio`\n\nParameters:\n- `text`: Text to convert (required)\n- `model`: Model version, options are 'speech-02-hd', 'speech-02-turbo', 'speech-01-hd', 'speech-01-turbo', 'speech-01-240228', 'speech-01-turbo-240228', default is 'speech-02-hd'\n- `voiceId`: Voice ID, default is 'male-qn-qingse'\n- `speed`: Speech speed, range 0.5-2.0, default is 1.0\n- `vol`: Volume, range 0.1-10.0, default is 1.0\n- `pitch`: Pitch, range -12 to 12, default is 0\n- `emotion`: Emotion, options are 'happy', 'sad', 'angry', 'fearful', 'disgusted', 'surprised', 'neutral', default is 'happy'. Note: This parameter only works with 'speech-02-hd', 'speech-02-turbo', 'speech-01-turbo', 'speech-01-hd' models\n- `format`: Audio format, options are 'mp3', 'pcm', 'flac', 'wav', default is 'mp3'\n- `sampleRate`: Sample rate (Hz), options are 8000, 16000, 22050, 24000, 32000, 44100, default is 32000\n- `bitrate`: Bitrate (bps), options are 64000, 96000, 128000, 160000, 192000, 224000, 256000, 320000, default is 128000\n- `channel`: Audio channels, options are 1 or 2, default is 1\n- `languageBoost`: Enhance the ability to recognize specified languages and dialects.\nSupported values include:\n'Chinese', 'Chinese,Yue', 'English', 'Arabic', 'Russian', 'Spanish', 'French', 'Portuguese', 'German', 'Turkish', 'Dutch', 'Ukrainian', 'Vietnamese', 'Indonesian', 'Japanese', 'Italian', 'Korean', 'Thai', 'Polish', 'Romanian', 'Greek', 'Czech', 'Finnish', 'Hindi', 'auto', default is 'auto'\n- `stream`: Enable streaming output\n- `subtitleEnable`: The parameter controls whether the subtitle service is enabled. The model must be 'speech-01-turbo' or 'speech-01-hd'. If this parameter is not provided, the default value is false\n- `outputDirectory`: Directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n- `outputFile`: Path to save the output file (optional, auto-generated if not provided)\n\n### Play Audio\n\nPlay an audio file. Supports WAV and MP3 formats. Does not support video.\n\nTool Name: `play_audio`\n\nParameters:\n- `inputFilePath`: Path to the audio file to play (required)\n- `isUrl`: Whether the audio file is a URL, default is false\n\n### Voice Clone\n\nClone a voice from an audio file.\n\nTool Name: `voice_clone`\n\nParameters:\n- `audioFile`: Path to audio file (required)\n- `voiceId`: Voice ID (required)\n- `text`: Text for demo audio (optional)\n- `outputDirectory`: Directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n\n### Text to Image\n\nGenerate images based on text prompts.\n\nTool Name: `text_to_image`\n\nParameters:\n- `prompt`: Image description (required)\n- `model`: Model version, default is 'image-01'\n- `aspectRatio`: Aspect ratio, default is '1:1', options are '1:1', '16:9','4:3', '3:2', '2:3', '3:4', '9:16', '21:9'\n- `n`: Number of images to generate, range 1-9, default is 1\n- `promptOptimizer`: Whether to optimize the prompt, default is true\n- `subjectReference`: Path to local image file or public URL for character reference (optional)\n- `outputDirectory`: Directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n- `outputFile`: Path to save the output file (optional, auto-generated if not provided)\n- `asyncMode`: Whether to use async mode. Defaults to False. If True, the video generation task will be submitted asynchronously and the response will return a task_id. Should use `query_video_generation` tool to check the status of the task and get the result. (optional)\n\n### Generate Video\n\nGenerate videos based on text prompts.\n\nTool Name: `generate_video`\n\nParameters:\n- `prompt`: Video description (required)\n- `model`: Model version, options are 'T2V-01', 'T2V-01-Director', 'I2V-01', 'I2V-01-Director', 'I2V-01-live', 'S2V-01', 'MiniMax-Hailuo-02', default is 'MiniMax-Hailuo-02'\n- `firstFrameImage`: Path to first frame image (optional)\n- `duration`: The duration of the video. The model must be \"MiniMax-Hailuo-02\". Values can be 6 and 10. (optional)\n- `resolution`: The resolution of the video. The model must be \"MiniMax-Hailuo-02\". Values range [\"768P\", \"1080P\"]. (optional)\n- `outputDirectory`: Directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n- `outputFile`: Path to save the output file (optional, auto-generated if not provided)\n- `asyncMode`: Whether to use async mode. Defaults to False. If True, the video generation task will be submitted asynchronously and the response will return a task_id. Should use `query_video_generation` tool to check the status of the task and get the result. (optional)\n\n### Query Video Generation Status\n\nQuery the status of a video generation task.\n\nTool Name: `query_video_generation`\n\nParameters:\n- `taskId`: The Task ID to query. Should be the task_id returned by `generate_video` tool if `async_mode` is True. (required)\n- `outputDirectory`: Directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n\n### Generate Music\n\nGenerate music from prompt and lyrics.\n\nTool Name: `music_generation`\n\nParameters:\n- `prompt`: Music creation inspiration describing style, mood, scene, etc. Example: \"Pop music, sad, suitable for rainy nights\". Character range: [10, 300]. (required)\n- `lyrics`: Song lyrics for music generation. Use newline (\\\\n) to separate each line of lyrics. Supports lyric structure tags [Intro] [Verse] [Chorus] [Bridge] [Outro] to enhance musicality. Character range: [10, 600] (each Chinese character, punctuation, and letter counts as 1 character). (required)\n- `sampleRate`: Sample rate of generated music. Values: [16000, 24000, 32000, 44100], default is 32000. (optional)\n- `bitrate`: Bitrate of generated music. Values: [32000, 64000, 128000, 256000], default is 128000. (optional)\n- `format`: Format of generated music. Values: [\"mp3\", \"wav\", \"pcm\"], default is 'mp3'. (optional)\n- `outputDirectory`: The directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n\n\n### Voice Design\n\nGenerate a voice based on description prompts.\n\nTool Name: `voice_design`\n\nParameters:\n- `prompt`: The prompt to generate the voice from. (required)\n- `previewText`: The text to preview the voice. (required)\n- `voiceId`: The id of the voice to use. For example, \"male-qn-qingse\"/\"audiobook_female_1\"/\"cute_boy\"/\"Charming_Lady\"... (optional)\n- `outputDirectory`: The directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n\n## FAQ\n\n### 1. How to use `generate_video` in async-mode\nDefine completion rules before starting:\n<img src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/cursor_rule2.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/>\nAlternatively, these rules can be configured in your IDE settings (e.g., Cursor):\n<img src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/cursor_video_rule.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/>\n\n## Development\n\n### Setup\n\n```bash\n# Clone the repository\ngit clone https://github.com/MiniMax-AI/MiniMax-MCP-JS.git\ncd minimax-mcp-js\n\n# Install dependencies\npnpm install\n```\n\n### Build\n\n```bash\n# Build the project\npnpm run build\n```\n\n### Run\n\n```bash\n# Run the MCP server\npnpm start\n```\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Momo707577045--tinypng-script-with-cache": {
      "owner": "Momo707577045",
      "name": "tinypng-script-with-cache",
      "url": "https://github.com/Momo707577045/tinypng-script-with-cache",
      "imageUrl": "https://github.com/Momo707577045.png",
      "description": "Compress images without dependencies, automatically skip already compressed images, and replace source files, while maintaining quality. The server utilizes multiple API keys for compression and generates compression reports while ensuring no redundant files are created during the process.",
      "stars": 23,
      "forks": 8,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-06-24T13:15:05Z",
      "readme_content": "# æ— ä¾èµ–çš„ tinypng node è„šæœ¬\n## ç‰¹ç‚¹\n- ã€æ— ä¾èµ–ï¼Œçº¯è„šæœ¬ã€‘\n  - ä¸‹è½½è„šæœ¬ä»£ç ï¼Œç›´æ¥ä½¿ç”¨ node å‘½ä»¤å³å¯è¿è¡Œã€‚\n  - å°†ä½¿ç”¨é—¨æ§›é™åˆ°æœ€ä½ã€‚\n- ã€è¿‡æ»¤é‡å¤å‹ç¼©ã€‘\n  - è‡ªåŠ¨è®°å½•å·²è¢«å‹ç¼©è¿‡çš„å›¾ç‰‡ï¼Œè·³è¿‡å‹ç¼©ï¼ŒåŠ å¿«è¿›åº¦ã€‚\n  - è®°å½•å›¾ç‰‡å‹ç¼©åçš„ md5 å€¼ï¼Œå†æ¬¡è¿è¡Œå‹ç¼©è„šæœ¬æ—¶ï¼Œè·³è¿‡å‹ç¼©ã€‚\n  - é€šè¿‡ md5 å€¼æ¯”è¾ƒæ–‡ä»¶å˜æ›´ï¼Œå³ä½¿ã€Œæ–‡ä»¶è¿ç§»ã€ä¹Ÿèƒ½è‡ªåŠ¨è¿‡æ»¤ã€‚\n  - é€šè¿‡ md5 å€¼æ¯”è¾ƒæ–‡ä»¶å˜æ›´ï¼Œå³ä½¿ã€Œä½¿ç”¨åŒåæ–‡ä»¶æ›¿æ¢ã€ä¹Ÿèƒ½è‡ªåŠ¨è¯†åˆ«ï¼Œå¹¶å‹ç¼©ï¼Œæ²¡æœ‰æ¼ç½‘ä¹‹é±¼ã€‚\n- ã€æ›¿æ¢æºæ–‡ä»¶ã€‘\n  - å‹ç¼©æˆåŠŸï¼Œç›´æ¥æ›¿æ¢æºæ–‡ä»¶ï¼Œä¸ç”Ÿæˆå†—ä½™æ–‡ä»¶ï¼Œä¸éœ€è¦å¤åˆ¶ç²˜è´´ï¼Œç§»åŠ¨å›¾ç‰‡ã€‚\n  - é™é»˜å‹ç¼©ï¼Œå¯¹é¡¹ç›®æ— æ„ŸçŸ¥ï¼Œæ— ä»»ä½•å½±å“ã€‚\n- ã€è‡ªåŠ¨åˆ‡æ¢ api keyã€‘\n  - tinypng ç”³è¯·çš„ [api key](https://tinypng.com/developers) æ¯æœˆåªæœ‰ 500 æ¬¡å…è´¹å‹ç¼©é¢åº¦ã€‚\n  - å¯è®¾ç½®å¤šä¸ª api keyï¼Œå½“æŸ key è¶…è¿‡ä½¿ç”¨æ¬¡æ•°æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢ä¸‹ä¸€ä¸ª key è¿›è¡Œå‹ç¼©ã€‚\n- ã€å‹ç¼©æŠ¥å‘Šã€‘\n  - è®°å½•æ¯ä¸ªå›¾ç‰‡çš„å‹ç¼©æ•°æ®ï¼Œå¹¶ç”Ÿæˆæ±‡æ€»ä¿¡æ¯ã€‚\n- ã€å‹ç¼©å®‰å…¨è¾¹ç•Œã€‘\n  - å‹ç¼©å®‰å…¨çº¿ï¼Œå½“å‹ç¼©æ¯”ä¾‹ä½äºè¯¥ç™¾åˆ†æ¯”å€¼æ—¶ï¼Œä¿æŒæºæ–‡ä»¶ï¼Œé¿å…è¿‡åˆ†å‹ç¼©ï¼ŒæŸä¼¤å›¾ç‰‡è´¨é‡ã€‚\n- ã€æºç æºå¸¦è¯¦ç»†å¤‡æ³¨ï¼Œè‡ªå¸¦æµ‹è¯•å›¾ç‰‡ã€‘\n  - é™ä½æºç é˜…è¯»é—¨æ§›ï¼Œé™ä½æµ‹è¯•é—¨æ§›ï¼Œå‡ä½ä½¿ç”¨é—¨æ§›ã€‚\n  - æ¨èé˜…è¯»æºç ï¼Œæ‰“ç ´ææƒ§ï¼Œä¾¿äºå®šåˆ¶ä¸ªæ€§åŒ–éœ€æ±‚ã€‚\n\n\n## ä¸“ä¸ºå°å‹é¡¹ç›®å®šåˆ¶\n- çº¯è„šæœ¬ï¼Œä¸ä¾èµ– gulpï¼Œä¸ä¾èµ– webpackï¼Œæ— éœ€æ­å»ºè„šæ‰‹æ¶ç¯å¢ƒ\n- å°å‹é¡¹ç›®ï¼Œæˆ–è€…åªæœ‰å‡ ä¸ªé™æ€é¡µé¢ï¼Œæ­å»ºè„šæ‰‹æ¶çš„æˆæœ¬è¿‡é«˜ã€‚æœ¬è„šè§£å†³çš„å³æ˜¯è„šæ‰‹æ¶ä¾èµ–çš„é—®é¢˜ã€‚\n- å½“ç„¶ï¼Œä¸­å¤§å‹é¡¹ç›®ä¹Ÿå¯ä»¥ç”¨ï¼Œåªæ˜¯å…¶ã€Œæ— ä¾èµ–ã€çš„ç‰¹ç‚¹åœ¨é‡Œé¢æ²¡é‚£ä¹ˆçªå‡ºã€‚ä¸­å¤§å‹é¡¹ç›®æ¨èä½¿ç”¨å…¶ [gulp ç‰ˆæœ¬](https://segmentfault.com/a/1190000023895556)ï¼Œå®ç°æ›´çµæ´»çš„é…ç½®ã€‚\n\n\n## å•æ–‡ä»¶ä½¿ç”¨æ–¹å¼\n- ç¬¬ä¸€æ­¥ï¼Œç‚¹å‡»[ä¸‹è½½æºç ](http://upyun.luckly-mjw.cn/lib/mtp.js)\n- ç¬¬äºŒæ­¥ï¼Œåœ¨è„šæœ¬æ–‡ä»¶å¤´éƒ¨æ·»åŠ  tinypng çš„ [api key](https://tinypng.com/developers)\n  ```\n  global.tinypngConf = {\n    apiKeyList: [\n      // 'XgNgkoyWbdIZd8OizINMjX2TpxAd_Gp3', // æ— æ•ˆ key\n      // 'IAl6s3ekmONUVMEqWZdIp1nV2ItJL1PC', // æ— æ•ˆ key\n      'IAl6s3ekmONUVMEqWZdIp1nV2ItJLyPC', // æœ‰æ•ˆ key\n    ]\n  }\n  ```\n  ![é…ç½®å›¾](http://upyun.luckly-mjw.cn/Assets/tinypng/004.png)\n- ç¬¬ä¸‰æ­¥ï¼Œèµ‹äºˆè„šæœ¬æ–‡ä»¶ã€Œå¯æ‰§è¡Œã€æƒé™ï¼Œ```chmod +x ./mtp.js```\n- ç¬¬å››æ­¥ï¼Œå°†è„šæœ¬æ–‡ä»¶æ”¾ç½®åˆ°é¡¹ç›®æ‰€åœ¨ç›®å½•\n  ![è¿è¡Œæ•ˆæœ](http://upyun.luckly-mjw.cn/Assets/tinypng/007.jpeg)\n- ç¬¬äº”æ­¥ï¼Œåœ¨é¡¹ç›®æ‰€åœ¨ç›®å½•è¿è¡Œè„šæœ¬```node ./mtp.js```\n  ![è¿è¡Œæ•ˆæœ](http://upyun.luckly-mjw.cn/Assets/tinypng/006.jpeg)\n- åç»­ä½¿ç”¨ï¼Œä»…éœ€æœ€åä¸¤æ­¥ã€Œç¬¬å››æ­¥ã€ã€Œç¬¬äº”æ­¥ã€\n\n\n## å…¨å±€é…ç½®ä½¿ç”¨æ–¹å¼\n- ç¬¬ä¸€æ­¥ï¼Œå…¨å±€å®‰è£…```npm install -g tinypng-script-with-cache```\n- ç¬¬äºŒæ­¥ï¼Œå…¨å±€é…ç½® api key\n  ```mtp setKey XgNgkoyWbdIZd8OizINMjX2TpxAd_Gp3,IAl6s3ekmONUVMEqWZdIp1nV2ItJLyPC```\n- ç¬¬ä¸‰æ­¥ï¼Œåœ¨é¡¹ç›®æ‰€åœ¨ç›®å½•è¿è¡Œè„šæœ¬```mtp```\n- åç»­ä½¿ç”¨ï¼Œæ— éœ€é…ç½®ï¼Œç›´æ¥åœ¨ç›®æ ‡ç›®å½•è¿è¡Œ```mtp```\n\n  ![è¿è¡Œæ•ˆæœ](http://upyun.luckly-mjw.cn/Assets/tinypng/008.png)\n\n## å‚æ•°ä¼ é€’æ–¹å¼\n#### é»˜è®¤é…ç½®\n- é»˜è®¤å‹ç¼©ã€Œè¿è¡Œå‘½ä»¤æ‰€åœ¨æ–‡ä»¶å¤¹ã€ä¸‹çš„å›¾ç‰‡\n- ã€Œå‘½ä»¤ä¼ å‚ã€ä¼˜å…ˆçº§é«˜äºã€Œä¿®æ”¹æºæ–‡ä»¶è®¾ç½®ã€\n\n\n#### ä¿®æ”¹æºæ–‡ä»¶è®¾ç½®\n- åœ¨æºæ–‡ä»¶å¤´éƒ¨ï¼Œå†™å…¥å…¨å±€å‚æ•°ï¼Œç¨‹åºè¿è¡Œæ—¶è‡ªåŠ¨è·å–\n- å…¨éƒ¨å‚è€ƒé…ç½®å¦‚ä¸‹\n  ```\n  global.tinypngConf = {\n     basePath: '/Users/mjw/Desktop/git/tinypng-script-with-cache/test-img', // å‹ç¼©è·¯å¾„\n     createMd5FormOrigin: false, // ä¸è¿›è¡Œå‹ç¼©æ“ä½œï¼Œåªç”Ÿæˆç°æœ‰å›¾ç‰‡çš„ md5 ä¿¡æ¯ï¼Œå¹¶ä½œä¸ºç¼“å­˜ã€‚ç”¨äºã€Œåˆæ¬¡é¡¹ç›®æ¥å…¥ã€åŠæ‰‹åŠ¨æ¸…ç†å†—ä½™çš„ã€Œå›¾ç‰‡md5ä¿¡æ¯ã€\n     apiKeyList: [ // tiny png çš„ api key æ•°ç»„ï¼Œå½“å…¶ä¸­ä¸€ä¸ªä¸å¯ç”¨æˆ–è¶…è¿‡ä½¿ç”¨æ¬¡æ•°æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢ä¸‹ä¸€ä¸ª key è°ƒç”¨\n       'IAl6s3ekmONUVMEqWZdIp1nV2ItJLyPC', // æœ‰æ•ˆ key\n     ]\n   }\n  ```\n  ![é…ç½®å›¾](http://upyun.luckly-mjw.cn/Assets/tinypng/004.png)\n\n#### å‘½ä»¤ä¼ å‚\n- å‚æ•°é€šè¿‡ç©ºæ ¼åŒºåˆ†\n- å‚æ•°ä¸€ï¼šå‹ç¼©è·¯å¾„\n- å‚æ•°äºŒï¼šæ˜¯å¦ä¸è¿›è¡Œå‹ç¼©æ“ä½œï¼Œåªç”Ÿæˆç°æœ‰å›¾ç‰‡çš„ md5 ä¿¡æ¯ã€‚é™¤ç©ºå­—ç¬¦ä¸²```''```å¤–ï¼Œå…¶ä½™å€¼å‡ä¸º true\n- å‚æ•°ä¸‰ï¼šapiKeyListï¼Œä»¥é€—å·åŒºåˆ†```,```\n- ä¼ å‚å‚è€ƒ\n  ```\n  node ./mtp.js /Users/mjw/Desktop/git/tinypng-script-with-cache/test-img '' IAl6s3ekmONUVMEqWZdIp1nV2ItJLyPC\n  ```\n  ![è¿è¡Œæ•ˆæœ](http://upyun.luckly-mjw.cn/Assets/tinypng/005.jpeg)\n\n#### é…ç½®åˆå¹¶ä¼˜å…ˆçº§æºç \n```\nconst vfs = require('vinyl-fs');\nlet tinypng = require('./tinypng-with-cache')\n\nlet apiKeyList = [] // æ¥å£ key é»˜è®¤ä¸ºç©º\nlet basePath = process.cwd() // é»˜è®¤è¿è¡Œè„šæœ¬æ‰€åœ¨ç›®å½•\nlet createMd5FormOrigin = false // ä¸è¿›è¡Œå‹ç¼©æ“ä½œï¼Œåªç”Ÿæˆç°æœ‰å›¾ç‰‡çš„ md5 ä¿¡æ¯ï¼Œå¹¶ä½œä¸ºç¼“å­˜ã€‚ç”¨äºã€Œåˆæ¬¡é¡¹ç›®æ¥å…¥ã€åŠæ‰‹åŠ¨æ¸…ç†å†—ä½™çš„ã€Œå›¾ç‰‡md5ä¿¡æ¯ã€\n\n// å¦‚æœæœ‰å…¨å±€ä¼ å€¼\nif (global.tinypngConf) {\n  basePath = tinypngConf.basePath || basePath\n  apiKeyList = tinypngConf.apiKeyList || apiKeyList\n  createMd5FormOrigin = tinypngConf.createMd5FormOrigin || createMd5FormOrigin\n}\n\n// åŠ¨æ€å‚æ•°ä¼ å€¼\nbasePath = process.argv[2] || basePath\ncreateMd5FormOrigin = process.argv[3] || createMd5FormOrigin\napiKeyList = process.argv[4] ? process.argv[4].split(',') : apiKeyList\n\nlet fileFilter = tinypngConf.fileFilter || [\n  basePath + '/**/*.png',\n  basePath + '/**/*.jpg',\n  basePath + '/**/*.jpeg',\n  `!${basePath}/**/node_modules/**`, // å¿½ç•¥æ— éœ€éå†çš„æ–‡ä»¶ï¼Œè·¯å¾„åŒ¹é…è¯­æ³•å‚è€ƒï¼šhttps://www.gulpjs.com.cn/docs/getting-started/explaining-globs/\n  `!${basePath}/**/dist/**`,\n]\n\nconsole.log({\n  basePath,\n  apiKeyList,\n  fileFilter,\n  createMd5FormOrigin,\n})\n\nif (!apiKeyList.length) {\n  return console.error('tinypng-script-with-cache', 'tinypny key åˆ—è¡¨ä¸èƒ½ä¸ºç©º!')\n}\n\nvfs.src(fileFilter, {\n  base: './', // å¯¹æ–‡ä»¶ä½¿ç”¨ç›¸è·¯å¾„ï¼Œä¸ºäº†åé¢è¦†ç›–æºæ–‡ä»¶\n  nodir: true, // å¿½ç•¥æ–‡ä»¶å¤¹\n})\n.pipe(tinypng({\n  apiKeyList,\n  reportFilePath: basePath + '/tinypngReport.json', // ä¸è®¾ç½®ï¼Œåˆ™ä¸è¿›è¡Œæ—¥å¿—è®°å½•\n  md5RecordFilePath: basePath + '/tinypngMd5Record.json', // ä¸è®¾ç½®ï¼Œåˆ™ä¸è¿›è¡Œç¼“å­˜è¿‡æ»¤\n  minCompressPercentLimit: 10, // é»˜è®¤å€¼ä¸ºé›¶ï¼Œæœ€å°å‹ç¼©ç™¾åˆ†æ¯”é™åˆ¶ï¼Œä¸ºä¿è¯å›¾ç‰‡è´¨é‡ï¼Œå½“å‹ç¼©æ¯”ä¾‹ä½äºè¯¥å€¼æ—¶ï¼Œä¿æŒæºæ–‡ä»¶ï¼Œé¿å…è¿‡åˆ†å‹ç¼©ï¼ŒæŸä¼¤å›¾ç‰‡è´¨é‡\n  createMd5FormOrigin, // ä¸è¿›è¡Œå‹ç¼©æ“ä½œï¼Œåªç”Ÿæˆç°æœ‰å›¾ç‰‡çš„ md5 ä¿¡æ¯ï¼Œå¹¶ä½œä¸ºç¼“å­˜ã€‚ç”¨äºã€Œåˆæ¬¡é¡¹ç›®æ¥å…¥ã€åŠæ‰‹åŠ¨æ¸…ç†å†—ä½™çš„ã€Œå›¾ç‰‡md5ä¿¡æ¯ã€\n}))\n.pipe(vfs.dest('./', { overwrite: true })) // è¦†å†™åŸæ–‡ä»¶\n```\n\n## [é¡¹ç›®åœ°å€](https://github.com/Momo707577045/tinypng-script-with-cache)\n\n## äºŒæ¬¡å¼€å‘ï¼Œç”Ÿæˆè‡ªå®šä¹‰è„šæœ¬\n- git clone ä¸‹è½½é¡¹ç›®\n- npm install å®‰è£…ä¾èµ–\n- ä¿®æ”¹ã€Œtinypng-mjw.jsã€ä¸ã€Œtinypng-with-cache.jsã€æºæ–‡ä»¶\n- æ‰§è¡Œ```npx webpack --config webpack.config.js```å‘½ä»¤ï¼Œè¿›è¡Œæ‰“åŒ…\n- ç”Ÿæˆç›®æ ‡æ–‡ä»¶```dist/mtp.js```\n\n\n## æµ‹è¯•èµ„æº\n- test-imgï¼šå›¾ç‰‡å‹ç¼©æµ‹è¯•ç›®å½•\n- test-img-originï¼šæµ‹è¯•å›¾ç‰‡å¤‡ä»½ç›®å½•ï¼Œç”¨äºæ¢å¤æµ‹è¯•\n\n\n## è¿è¡Œæ•ˆæœ\n![è¿è¡Œæ•ˆæœ](http://upyun.luckly-mjw.cn/Assets/tinypng/006.jpeg)\n\n## å‹ç¼©æŠ¥å‘Š\n![å‹ç¼©æŠ¥å‘Š](http://upyun.luckly-mjw.cn/Assets/tinypng/002.png)\n\n## md5 è®°å½•\n![md5 è®°å½•](http://upyun.luckly-mjw.cn/Assets/tinypng/003.png)\n\n## gulp ç‰ˆæœ¬è¯·å‚è€ƒ[è¿™é‡Œ](https://segmentfault.com/a/1190000023895556)",
      "npm_url": "",
      "npm_downloads": 0
    },
    "MubarakHAlketbi--game-asset-mcp": {
      "owner": "MubarakHAlketbi",
      "name": "game-asset-mcp",
      "url": "https://github.com/MubarakHAlketbi/game-asset-mcp",
      "imageUrl": "https://github.com/MubarakHAlketbi.png",
      "description": "Generates 2D and 3D game assets from text prompts using AI models. Integrates with Hugging Face Spaces for asset generation, facilitating rapid prototyping for game developers.",
      "stars": 85,
      "forks": 20,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-21T17:45:58Z",
      "readme_content": "# Game Asset Generator using MCP and Hugging Face Spaces\n\nThis project is an innovative tool that simplifies game asset creation by leveraging AI-powered generation. Whether you're a game developer seeking rapid prototypes or an AI enthusiast exploring generative models, this tool enables you to create **2D** and **3D game assets** from text prompts effortlessly. It integrates AI models from **Hugging Face Spaces**â€”powered by `\"gokaygokay/Flux-2D-Game-Assets-LoRA\"`, `\"gokaygokay/Flux-Game-Assets-LoRA-v2\"`, and one of three 3D model generation spaces (`InstantMesh`, `Hunyuan3D-2`, or `Hunyuan3D-2mini-Turbo`, which you must duplicate to your account)â€”and uses the **Model Context Protocol (MCP)** for seamless interaction with AI assistants like **Claude Desktop**.\n\n<p align=\"center\">\n  <a href=\"https://pay.ziina.com/MubarakHAlketbi\">\n    <img src=\"https://img.shields.io/badge/Support_Me-Donate-9626ff?style=for-the-badge&logo=https%3A%2F%2Fimgur.com%2FvwC39JY\" alt=\"Support Me - Donate\">\n  </a>\n  <a href=\"https://github.com/RooVetGit/Roo-Code\">\n    <img src=\"https://img.shields.io/badge/Built_With-Roo_Code-412894?style=for-the-badge\" alt=\"Built With - Roo Code\">\n  </a>\n  <br>\n  <a href=\"https://glama.ai/mcp/servers/@MubarakHAlketbi/game-asset-mcp\">\n    <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@MubarakHAlketbi/game-asset-mcp/badge\" />\n  </a>\n</p>\n\n---\n\n## Table of Contents\n\n1. [Project Overview](#project-overview)\n2. [Features](#features)\n3. [How It Works](#how-it-works)\n4. [Prerequisites](#prerequisites)\n5. [Installation](#installation)\n6. [Usage](#usage)\n7. [Configuration](#configuration)\n8. [File Management](#file-management)\n9. [MCP Integration](#mcp-integration)\n10. [Troubleshooting](#troubleshooting)\n11. [Advanced](#advanced)\n12. [Contributing](#contributing)\n13. [License](#license)\n\n---\n\n## Project Overview\n\nThe **Game Asset Generator** (version **0.3.0**) harnesses AI to streamline the creation of game assets. It supports generating **2D assets** (e.g., pixel art sprites) and **3D assets** (e.g., OBJ and GLB models) from text prompts, integrating with **Hugging Face Spaces** and the **Model Context Protocol (MCP)**. This release introduces support for multiple 3D model generation spacesâ€”`InstantMesh`, `Hunyuan3D-2`, and `Hunyuan3D-2mini-Turbo`â€”offering flexibility and enhanced performance. Built with **Node.js** and the **MCP TypeScript SDK (v1.7.0)**, it provides a robust, cross-platform solution for asset generation.\n\n---\n\n## Features\n\n- **2D Asset Generation**: Create pixel art, sprites, or other 2D assets from text prompts (e.g., \"pixel art sword\").\n- **3D Asset Generation**: Generate 3D models (OBJ and GLB formats) from text descriptions, with automatic image-to-model conversion.\n- **Multiple 3D Model Spaces**: Supports `InstantMesh`, `Hunyuan3D-2`, and `Hunyuan3D-2mini-Turbo` for varied 3D generation workflows.\n- **MCP Integration**: Seamlessly interact with the tool via MCP-compatible clients like **Claude Desktop**.\n- **File Management**: Automatically saves and organizes assets in a local `assets` directory with resource URIs (e.g., `asset://{type}/{id}`).\n- **Robust Input Validation**: Uses **Zod** for secure and reliable input processing.\n- **Multi-Client Support**: Handles multiple simultaneous connections via **SSE transport**.\n- **Secure Remote Access**: Optional **HTTPS** support for safe remote communication.\n- **Extensible Backend**: Modular design for easy integration of new models or features.\n- **Cross-Platform**: Compatible with Windows, macOS, and Linux using **Node.js**.\n- **Configurable 3D Generation**: Customize parameters like inference steps, guidance scale, and turbo mode via environment variables.\n\n---\n\n## How It Works\n\nThe Game Asset Generator transforms text prompts into game-ready assets through an automated pipeline:\n\n1. **User Input**: Submit a text prompt (e.g., \"pixel art sword\" or \"isometric 3D castle\").\n2. **MCP Server**: Routes the prompt to the appropriate tool (`generate_2d_asset` or `generate_3d_asset`).\n3. **AI Model Interaction**:\n   - **2D Assets**: Utilizes the **Hugging Face Inference API** with `\"gokaygokay/Flux-2D-Game-Assets-LoRA\"` (50 steps).\n   - **3D Assets**:\n     - Generates an initial image using `\"gokaygokay/Flux-Game-Assets-LoRA-v2\"` (30 steps).\n     - Converts the image to a 3D model using one of:\n       - **InstantMesh**: Multi-step process (`/preprocess`, `/generate_mvs`, `/make3d`).\n       - **Hunyuan3D-2**: Single-step process (`/generation_all`).\n       - **Hunyuan3D-2mini-Turbo**: Single-step process (`/generation_all`) with configurable turbo modes.\n4. **File Output**: Saves assets (PNG for 2D, OBJ/GLB for 3D) in the `assets` directory.\n5. **Response**: Returns resource URIs (e.g., `asset://3d_model/filename.glb`) for immediate use.\n\n### Workflow Diagram\n```\nUser Prompt â†’ MCP Server â†’ AI Model(s) â†’ Local File â†’ Resource URI Response\n```\n\nPrompts are automatically enhanced with \"high detailed, complete object, not cut off, white solid background\" for optimal quality.\n\n---\n\n## Prerequisites\n\n- **Node.js**: Version 16+ (includes `npm`).\n- **Git**: For cloning the repository.\n- **Internet Access**: Required for Hugging Face API connectivity.\n- **Hugging Face Account**: Needed for API access; obtain your token from [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens).\n- **NPM Packages**:\n  - `@gradio/client`: Interacts with Hugging Face Spaces.\n  - `@huggingface/inference`: For direct model inference.\n  - `@modelcontextprotocol/sdk`: Implements the MCP server.\n  - `dotenv`: Loads environment variables.\n  - `express`: Enables SSE transport.\n  - `zod`: Ensures input validation.\n  - `sharp`: Handles image processing.\n- **Optional**: **Claude Desktop** (or another MCP client) for enhanced interaction.\n\n---\n\n## Installation\n\n1. **Clone the Repository**:\n   ```bash\n   git clone https://github.com/yourusername/game-asset-mcp.git\n   cd game-asset-mcp\n   ```\n\n2. **Install Dependencies**:\n   ```bash\n   npm install\n   ```\n\n3. **Configure Environment**:\n   - Copy the example `.env` file:\n     ```bash\n     cp .env.example .env\n     ```\n   - Edit `.env` with your **Hugging Face API token** and duplicated **MODEL_SPACE**. See [Configuration](#configuration) for details.\n\n4. **Run the Server**:\n   - **Local (stdio transport)**:\n     ```bash\n     npm start\n     ```\n   - **Custom Working Directory**:\n     ```bash\n     node src/index.js /path/to/directory\n     ```\n   - **Remote (SSE transport)**:\n     ```bash\n     node src/index.js --sse\n     ```\n   - **Remote with HTTPS**:\n     ```bash\n     node src/index.js --sse --https\n     ```\n     Requires `ssl/key.pem` and `ssl/cert.pem` (see [ssl/README.md](ssl/README.md)).\n\n> **Note**: Uses ES modules (`\"type\": \"module\"` in `package.json`). Ensure Node.js 16+ is installed (`node --version`).\n\n---\n\n## Usage\n\nInteract with the server via an **MCP client** (e.g., Claude Desktop) or programmatically:\n\n- **Generate a 2D Asset**:\n  - **Command**: `generate_2d_asset prompt:\"pixel art sword\"`\n  - **Output**: Saves a PNG file (e.g., `2d_asset_generate_2d_asset_1698765432.png`) and returns its URI.\n\n- **Generate a 3D Asset**:\n  - **Command**: `generate_3d_asset prompt:\"isometric 3D castle\"`\n  - **Output**: Saves OBJ/GLB files and intermediate images, returning their URIs. Provides an operation ID for long-running tasks.\n\n### Prompt Examples\n- **Natural Interaction**:\n  - `generate_2d_sprite prompt:\"pixel art sword\"`\n  - `generate_3d_model prompt:\"isometric 3D castle\"`\n\n### With Claude Desktop\nAfter configuring (see [Configuration](#configuration)), type commands directly in the interface.\n\n---\n\n## Configuration\n\nCustomize the server via the `.env` file:\n\n### Required Settings\n- **HF_TOKEN**: Hugging Face API token.\n  ```plaintext\n  HF_TOKEN=your_hf_token\n  ```\n- **MODEL_SPACE**: Your duplicated 3D model space (e.g., `your-username/InstantMesh`).\n  - Duplicate one of:\n    - [InstantMesh](https://huggingface.co/spaces/tencentARC/InstantMesh)\n    - [Hunyuan3D-2](https://huggingface.co/spaces/tencent/Hunyuan3D-2)\n    - [Hunyuan3D-2mini-Turbo](https://huggingface.co/spaces/tencent/Hunyuan3D-2mini-Turbo)\n  ```plaintext\n  MODEL_SPACE=your-username/InstantMesh\n  ```\n\n### Optional 3D Model Settings\n| Variable                  | Description                                   | Valid Range/Default       |\n|---------------------------|-----------------------------------------------|---------------------------|\n| `MODEL_3D_STEPS`         | Inference steps                              | Varies by space (see below) |\n| `MODEL_3D_GUIDANCE_SCALE`| How closely the model follows the prompt     | 0.0-100.0 (default: 5.0-5.5) |\n| `MODEL_3D_OCTREE_RESOLUTION` | Detail level of the 3D model            | Varies by space (see below) |\n| `MODEL_3D_SEED`          | Randomness control                          | 0-10000000 (default: varies) |\n| `MODEL_3D_REMOVE_BACKGROUND` | Remove image background                | `true`/`false` (default: `true`) |\n| `MODEL_3D_TURBO_MODE`    | Generation mode (Hunyuan3D-2mini-Turbo only) | `Turbo`, `Fast`, `Standard` (default: `Turbo`) |\n| `MODEL_SPACE_TYPE`       | Override space type detection               | `instantmesh`, `hunyuan3d`, `hunyuan3d_mini_turbo` |\n\n#### Space-Specific Defaults\n- **InstantMesh**:\n  - Steps: 30-75 (default: 75)\n  - Seed: Default 42\n- **Hunyuan3D-2**:\n  - Steps: 20-50 (default: 20)\n  - Guidance Scale: Default 5.5\n  - Octree Resolution: `256`, `384`, `512` (default: `256`)\n  - Seed: Default 1234\n- **Hunyuan3D-2mini-Turbo**:\n  - Steps: 1-100 (default: 5 for `Turbo`, 10 for `Fast`, 20 for `Standard`)\n  - Guidance Scale: Default 5.0\n  - Octree Resolution: 16-512 (default: 256)\n  - Seed: Default 1234\n\n### Transport Settings\n- **PORT**: SSE transport port (default: 3000).\n  ```plaintext\n  PORT=3000\n  ```\n\n### Claude Desktop Setup\nEdit the config file:\n- **MacOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n```json\n{\n  \"mcpServers\": {\n    \"game-asset-generator\": {\n      \"command\": \"node\",\n      \"args\": [\"/full/path/to/game-asset-mcp/src/index.js\"]\n    }\n  }\n}\n```\nRestart Claude Desktop after editing.\n\n---\n\n## File Management\n\n- **Storage Location**: Assets are saved in `./assets` within the working directory.\n- **Naming Convention**: Files use a prefix, tool name, timestamp, and unique ID (e.g., `2d_asset_generate_2d_asset_1698765432_abcd1234.png`).\n- **Customization**: Set a custom directory:\n  ```bash\n  node src/index.js /path/to/custom/directory\n  ```\n- **Resource Access**: Use MCP URIs (e.g., `asset://2d_asset/filename.png`) to list or read assets.\n\n---\n\n## MCP Integration\n\nThe **Model Context Protocol (MCP)** enables this tool to serve AI clients securely:\n- **Tools**: `generate_2d_asset`, `generate_3d_asset`.\n- **Resources**: Managed via `asset://` URIs.\n- **Prompts**: `generate_2d_sprite`, `generate_3d_model`.\n- **Compatibility**: Works with **Claude Desktop** and other MCP clients.\n\n---\n\n## Troubleshooting\n\n- **API Errors**: Check network connectivity or rate limits; review `./logs/server.log`.\n- **Authentication Issues**: Verify `HF_TOKEN` and `MODEL_SPACE` in `.env`.\n- **ES Modules Error**: Ensure Node.js 16+ (`node --version`).\n- **Logs**: Inspect detailed logs:\n  ```bash\n  tail -f ./logs/server.log\n  ```\n\n---\n\n## Advanced\n\n### API Endpoints and Integration\n- **2D Asset Generation**: Uses `\"gokaygokay/Flux-2D-Game-Assets-LoRA\"` (50 steps).\n- **3D Asset Image Generation**: Uses `\"gokaygokay/Flux-Game-Assets-LoRA-v2\"` (30 steps).\n- **3D Model Conversion**:\n  - **InstantMesh**: Multi-step (`/check_input_image`, `/preprocess`, `/generate_mvs`, `/make3d`).\n  - **Hunyuan3D-2**: Single-step (`/generation_all`).\n  - **Hunyuan3D-2mini-Turbo**: Single-step (`/generation_all`) with turbo modes.\n\n### Versioning\n- **Current Version**: 0.3.0 (Added Hunyuan3D-2mini-Turbo support).\n- **MCP SDK Version**: 1.7.0.\n- **Format**: MAJOR.MINOR.PATCH (SemVer).\n\n### Backend Architecture\n- **Core File**: `src/index.js`.\n- **Dependencies**: See `package.json`.\n- **Security**: Zod validation, path traversal prevention, HTTPS support, rate limiting.\n- **Performance**: Async processing, retry with backoff, GPU quota handling.\n\n---\n\n## Contributing\n\nWe welcome contributions! To participate:\n1. **Fork the Repository**: Create your copy on GitHub.\n2. **Make Changes**: Add features, fix bugs, or enhance docs.\n3. **Submit a Pull Request**: Detail your changes.\n4. **Open Issues**: Report bugs or suggest improvements.\n\nFollow standard coding conventions and include tests where applicable.\n\n---\n\n## License\n\nLicensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.",
      "npm_url": "",
      "npm_downloads": 0
    },
    "murataskin--image-mcp-server-gemini": {
      "owner": "murataskin",
      "name": "image-mcp-server-gemini",
      "url": "https://github.com/murataskin/image-mcp-server-gemini",
      "imageUrl": "https://github.com/murataskin.png",
      "description": "Analyzes images and videos by providing URLs or local file paths, allowing for detailed insights and descriptions of the content. Uses the Gemini 2.0 Flash model for high-precision recognition and can evaluate relationships between multiple visual inputs.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-04-10T03:32:38Z",
      "readme_content": "\n# image-mcp-server-gemini\n\n\n\n\n[![smithery badge](https://smithery.ai/badge/@Rentapad/image-mcp-server-gemini)](https://smithery.ai/server/@Rentapad/image-mcp-server-gemini)\nAn MCP server that receives image/video URLs or local file paths and analyzes their content using the Gemini 2.0 Flash model.(forked from github.com/champierre/image-mcp-server)\n\n## Features\n\n- Analyzes content from one or more image/video URLs or local file paths.\n- Analyzes videos directly from YouTube URLs.\n- Can analyze relationships between multiple images or videos provided together.\n- Supports optional text prompts to guide the analysis.\n- High-precision recognition and description using the Gemini 2.0 Flash model.\n- URL validity checking and local file loading with Base64 encoding.\n- Basic security checks for local file paths.\n- Handles various image and video MIME types (see Usage section for details).\n\n## Installation\n\n### Installing via Smithery\n\nTo install Image Analysis Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@Rentapad/image-mcp-server-gemini):\n\n```bash\nnpx -y @smithery/cli install @Rentapad/image-mcp-server --client claude\n```\n\n### Manual Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/Rentapad/image-mcp-server-gemini.git \ncd image-mcp-server-gemini\n\n# Install dependencies\nnpm install\n\n# Compile TypeScript\nnpm run build\n```\n\n## Configuration\n\nTo use this server, you need a Gemini API key. Set the following environment variable:\n\n```\nGEMINI_API_KEY=your_gemini_api_key\n```\n\n## MCP Server Configuration\n\nTo use with tools like Cline, add the following settings to your MCP server configuration file:\n\n### For Cline\n\nAdd the following to `cline_mcp_settings.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-video-analysis\": { // Consider renaming for clarity\n      \"command\": \"node\",\n      \"args\": [\"/path/to/image-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"GEMINI_API_KEY\": \"your_gemini_api_key\"\n      }\n    }\n  }\n}\n```\n\n### For Claude Desktop App\n\nAdd the following to `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-video-analysis\": { // Consider renaming for clarity\n      \"command\": \"node\",\n      \"args\": [\"/path/to/image-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"GEMINI_API_KEY\": \"your_gemini_api_key\"\n      }\n    }\n  }\n}\n```\n\n## Usage\n\nOnce the MCP server is configured, the following tools become available:\n\n- `analyze_image`: Receives one or more image URLs and analyzes their content.\n  - Arguments: `imageUrls` (array of strings, required), `prompt` (string, optional).\n- `analyze_image_from_path`: Receives one or more local image file paths and analyzes their content.\n  - Arguments: `imagePaths` (array of strings, required), `prompt` (string, optional).\n- `analyze_video`: Receives one or more video URLs and analyzes their content. Best for smaller videos (see Video Notes).\n  - Arguments: `videoUrls` (array of strings, required), `prompt` (string, optional).\n- `analyze_video_from_path`: Receives one or more local video file paths and analyzes their content. Best for smaller videos (see Video Notes).\n  - Arguments: `videoPaths` (array of strings, required), `prompt` (string, optional).\n- `analyze_youtube_video`: Receives a single YouTube video URL and analyzes its content.\n  - Arguments: `youtubeUrl` (string, required), `prompt` (string, optional).\n\n### Usage Examples\n\n**Analyzing a single image from URL:**\n```\nPlease analyze this image: https://example.com/image.jpg\n```\n\n**Analyzing multiple images from local paths and comparing them:**\n```\nAnalyze these images: /path/to/your/image1.png, /path/to/your/image2.jpeg. Which one contains a cat?\n```\n*(The client would call `analyze_image_from_path` with `imagePaths: [\"/path/to/your/image1.png\", \"/path/to/your/image2.jpeg\"]` and `prompt: \"Which one contains a cat?\"`)*\n\n**Analyzing a video from URL with a specific prompt:**\n```\nSummarize the content of this video: https://example.com/video.mp4\n```\n*(The client would call `analyze_video` with `videoUrls: [\"https://example.com/video.mp4\"]` and `prompt: \"Summarize the content of this video\"`)*\n\n**Analyzing a YouTube video:**\n```\nWhat is the main topic of this YouTube video? https://www.youtube.com/watch?v=dQw4w9WgXcQ\n```\n*(The client would call `analyze_youtube_video` with `youtubeUrl: \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\"` and `prompt: \"What is the main topic of this YouTube video?\"`)*\n\n### Video Notes\n\n- **Size Limit:** For videos provided via URL (`analyze_video`) or path (`analyze_video_from_path`), Gemini currently has limitations on the size of video data that can be processed directly (typically around 20MB after Base64 encoding). Larger videos may fail. YouTube analysis does not have this same client-side download limit.\n- **Supported MIME Types:** The server attempts to map and use MIME types supported by Gemini for video. Officially supported types include: `video/mp4`, `video/mpeg`, `video/mov`, `video/avi`, `video/x-flv`, `video/mpg`, `video/webm`, `video/wmv`, `video/3gpp`. Files with other MIME types might be skipped. YouTube videos are handled separately.\n\n### Note: Specifying Local File Paths\n\nWhen using the `..._from_path` tools, the AI assistant (client) must specify **valid file paths in the environment where this server is running**.\n\n- **If the server is running on WSL:**\n  - If the AI assistant has a Windows path (e.g., `C:\\...`), it needs to convert it to a WSL path (e.g., `/mnt/c/...`) before passing it to the tool.\n  - If the AI assistant has a WSL path, it can pass it as is.\n- **If the server is running on Windows:**\n  - If the AI assistant has a WSL path (e.g., `/home/user/...`), it needs to convert it to a UNC path (e.g., `\\\\wsl$\\Distro\\...`) before passing it to the tool.\n  - If the AI assistant has a Windows path, it can pass it as is.\n\n**Path conversion is the responsibility of the AI assistant (or its execution environment).** The server will try to interpret the received path as is, applying basic security checks.\n\n### Note: Type Errors During Build\n\nWhen running `npm run build`, you may see an error (TS7016) about missing TypeScript type definitions for the `mime-types` module.\n\n```\nsrc/index.ts:16:23 - error TS7016: Could not find a declaration file for module 'mime-types'. ...\n```\n\nThis is a type checking error, and since the JavaScript compilation itself succeeds, it **does not affect the server's execution**. If you want to resolve this error, install the type definition file as a development dependency.\n\n```bash\nnpm install --save-dev @types/mime-types\n# or\nyarn add --dev @types/mime-types\n```\n\n## Development\n\n```bash\n# Run in development mode\nnpm run dev\n```\n\n## License\n\nMIT\n```\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "nansasuke--GarbageSorting": {
      "owner": "nansasuke",
      "name": "GarbageSorting",
      "url": "https://github.com/nansasuke/GarbageSorting",
      "imageUrl": "https://github.com/nansasuke.png",
      "description": "Identify and classify waste using image and voice recognition techniques to streamline the recycling process and enhance environmental awareness.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "",
      "updated_at": "2025-03-11T13:08:27Z",
      "readme_content": "# GarbageSorting\nå›¾ç‰‡è¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ã€åƒåœ¾åˆ†ç±»\n\nä¸€ä¸ªå®Œæ•´çš„åƒåœ¾åˆ†ç±»çš„app\n \n\n![image](https://github.com/hyyz3293/GarbageSorting/blob/master/Images/a.png) ![image](https://github.com/hyyz3293/GarbageSorting/blob/master/Images/b.png)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "nickbaumann98--everart-forge-mcp": {
      "owner": "nickbaumann98",
      "name": "everart-forge-mcp",
      "url": "https://github.com/nickbaumann98/everart-forge-mcp",
      "imageUrl": "https://github.com/nickbaumann98.png",
      "description": "Generates and converts vector and raster images using advanced AI models with support for multiple formats. Provides flexible storage options and automatic formatting for efficient image processing.",
      "stars": 10,
      "forks": 7,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-07-10T04:55:11Z",
      "readme_content": "# EverArt Forge MCP for Cline\n\n![EverArt Forge MCP](icon.svg)\n\nAn advanced Model Context Protocol (MCP) server for [Cline](https://github.com/cline/cline) that integrates with EverArt's AI models to generate both vector and raster images. This server provides powerful image generation capabilities with flexible storage options and format conversion.\n\n## Features\n\n- **Vector Graphics Generation**\n  - Create SVG vector graphics using Recraft-Vector model\n  - Automatic SVG optimization\n  - Perfect for logos, icons, and scalable graphics\n\n- **Raster Image Generation**\n  - Support for PNG, JPEG, and WebP formats\n  - Multiple AI models for different styles\n  - High-quality image processing\n\n- **Flexible Storage**\n  - Custom output paths and filenames\n  - Automatic directory creation\n  - Format validation and extension handling\n  - Web project integration\n\n## Available Models\n\n- **5000:FLUX1.1**: Standard quality, general-purpose image generation\n- **9000:FLUX1.1-ultra**: Ultra high quality for detailed images\n- **6000:SD3.5**: Stable Diffusion 3.5 for diverse styles\n- **7000:Recraft-Real**: Photorealistic style\n- **8000:Recraft-Vector**: Vector art style (SVG output)\n\n## Installation\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/nickbaumann98/everart-forge-mcp.git\n   cd everart-forge-mcp\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n   ```bash\n   npm run build\n   ```\n\n4. Get your EverArt API key:\n   - Sign up at [EverArt](https://everart.ai/) \n   - Navigate to your account settings\n   - Create or copy your API key\n\n5. Add the server to your Cline MCP settings file:\n\n   **For VS Code Extension**:  \n   Edit `~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json`:\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"everart-forge\": {\n         \"command\": \"node\",\n         \"args\": [\"/absolute/path/to/everart-forge-mcp/build/index.js\"],\n         \"env\": {\n           \"EVERART_API_KEY\": \"your_api_key_here\"\n         },\n         \"disabled\": false,\n         \"autoApprove\": []\n       }\n     }\n   }\n   ```\n\n   **For Claude Desktop App**:  \n   Edit `~/Library/Application Support/Claude/claude_desktop_config.json` (macOS) or appropriate location for your OS\n\n6. Restart Cline to load the new MCP server\n\n## Usage Examples\n\nOnce configured, you can use Cline to generate images with prompts like:\n\n- \"Generate a minimalist tech logo in SVG format using the Recraft-Vector model\"\n- \"Create a photorealistic landscape image with the FLUX1.1-ultra model\"\n- \"Make me a vector icon for my project that represents artificial intelligence\"\n- \"Generate a professional company logo as an SVG file and save it to my desktop\"\n\n### Tool Capabilities\n\nThe server provides these tools:\n\n#### generate_image\n\nGenerate images with extensive customization options:\n\n```\nParameters:\n- prompt (required): Text description of desired image\n- model: Model ID (5000:FLUX1.1, 9000:FLUX1.1-ultra, 6000:SD3.5, 7000:Recraft-Real, 8000:Recraft-Vector)\n- format: Output format (svg, png, jpg, webp)\n- output_path: Custom output path for the image\n- web_project_path: Path to web project root for proper asset organization\n- project_type: Web project type (react, vue, html, next, etc.)\n- asset_path: Subdirectory within the web project assets\n- image_count: Number of images to generate (1-10)\n```\n\nNotes:\n- SVG format is only available with Recraft-Vector (8000) model\n- Default format is \"svg\" for model 8000, \"png\" for others\n- You can specify combined model IDs (e.g., \"8000:Recraft-Vector\")\n\n#### list_images\n\nList all previously generated images stored by the server.\n\n#### view_image\n\nOpen a specific image in the default image viewer:\n\n```\nParameters:\n- filename: Name of the image file to view\n```\n\n## Troubleshooting\n\n- **Error: Invalid model ID**: Make sure you're using one of the supported model IDs (5000, 6000, 7000, 8000, 9000)\n- **Format not compatible with model**: SVG format is only available with Recraft-Vector (8000) model\n- **Image not found**: Use the list_images tool to see available images\n- **API authentication failed**: Check your EverArt API key\n- **Images not appearing**: Check file permissions and paths\n\n## License\n\nMIT License - see LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "NightTrek--moondream-mcp": {
      "owner": "NightTrek",
      "name": "moondream-mcp",
      "url": "https://github.com/NightTrek/moondream-mcp",
      "imageUrl": "https://github.com/NightTrek.png",
      "description": "Advanced image analysis capabilities including captioning, object detection, and visual question answering for applications requiring sophisticated computer vision tasks.",
      "stars": 18,
      "forks": 9,
      "license": "Apache License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-08-09T18:23:23Z",
      "readme_content": "# ğŸŒ™ Moondream MCP Server\n\nA powerful Model Context Protocol (MCP) server that brings advanced image analysis capabilities to your applications using the Moondream vision model. This server seamlessly integrates with Claude and Cline, providing a bridge between AI assistants and sophisticated computer vision tasks.\n\nThis IS NOT an offical Moondream package. All credit to [moondream.ai](https://github.com/vikhyat/moondream) for making the best open source vision model that you can run on consumer hardware.\n\n<div align=\"center\" style=\"height: 150px; overflow: hidden; display: flex; align-items: center; margin: 20px 0;\">\n  <img src=\"https://github.com/user-attachments/assets/e999ada0-9dfa-4f3d-a489-e4ce58434ecb\" alt=\"Moondream MCP Banner\" style=\"width: 100%; object-fit: cover;\">\n</div>\n\n\n## âœ¨ Features\n\n- ğŸ–¼ï¸ **Image Captioning**: Generate natural language descriptions of images\n- ğŸ” **Object Detection**: Identify and locate specific objects within images\n- ğŸ’­ **Visual Question Answering**: Ask questions about image content and receive intelligent responses\n- ğŸš€ **High Performance**: Uses quantized 8-bit models for efficient inference\n- ğŸ”„ **Automatic Setup**: Handles model downloading and environment setup\n- ğŸ› ï¸ **MCP Integration**: Standardized protocol for seamless tool usage\n\n## ğŸ¯ Use Cases\n\n- **Content Analysis**: Automatically generate descriptions for image content\n- **Accessibility**: Create alt text for visually impaired users\n- **Data Extraction**: Extract specific information from images through targeted questions\n- **Object Verification**: Confirm the presence of specific objects in images\n- **Scene Understanding**: Analyze complex scenes and their components\n\n## ğŸš€ Quick Start\n\n### Prerequisites\n\n- Node.js v18 or higher\n- Python 3.8+\n- UV package manager (automatically installed if not present)\n\n### Installation\n\n1. **Clone and Setup**\n```bash\ngit clone <repository-url>\ncd moondream-server\npnpm install\n```\n\n2. **Build the Server**\n```bash\npnpm run build\n```\n\nThe server handles the rest automatically:\n- Creates Python virtual environment\n- Installs UV if not present\n- Downloads and sets up the Moondream model\n- Manages the model server process\n\n### Integration with Claude/Cline\n\nAdd to your MCP settings file (`claude_desktop_config.json` or `cline_mcp_settings.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"moondream\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/moondream-server/build/index.js\"]\n    }\n  }\n}\n```\n\n## ğŸ› ï¸ Available Tools\n\n### analyze_image\n\nPowerful image analysis tool with multiple modes:\n\n```typescript\n{\n  \"name\": \"analyze_image\",\n  \"arguments\": {\n    \"image_path\": string,  // Path to image file\n    \"prompt\": string       // Analysis command\n  }\n}\n```\n\n**Prompt Types:**\n- `\"generate caption\"` - Creates natural language description\n- `\"detect: [object]\"` - Finds specific objects (e.g., \"detect: car\")\n- `\"[question]\"` - Answers questions about the image\n\n**Examples:**\n\n```javascript\n// Image Captioning\n{\n  \"image_path\": \"photo.jpg\",\n  \"prompt\": \"generate caption\"\n}\n\n// Object Detection\n{\n  \"image_path\": \"scene.jpg\",\n  \"prompt\": \"detect: person\"\n}\n\n// Visual Q&A\n{\n  \"image_path\": \"painting.jpg\",\n  \"prompt\": \"What colors are used in this painting?\"\n}\n```\n\n## ğŸ”§ Technical Details\n\n### Architecture\n\nThe server operates as a dual-component system:\n\n1. **MCP Interface Layer**\n   - Handles protocol communication\n   - Manages tool interfaces\n   - Processes requests/responses\n\n2. **Moondream Model Server**\n   - Runs the vision model\n   - Processes image analysis\n   - Provides HTTP API endpoints\n\n### Model Information\n\nUses the Moondream quantized model:\n- Default: `moondream-2b-int8.mf.gz`\n- Efficient 8-bit quantization\n- Automatic download from Hugging Face\n- ~500MB model size\n\n### Performance\n\n- Fast startup with automatic caching\n- Efficient memory usage through quantization\n- Responsive API endpoints\n- Concurrent request handling\n\n## ğŸ” Debugging\n\nCommon issues and solutions:\n\n1. **Model Download Issues**\n   ```bash\n   # Manual model download\n   wget https://huggingface.co/vikhyatk/moondream2/resolve/main/moondream-0_5b-int4.mf.gz\n   ```\n\n2. **Server Port Conflicts**\n   - Default port: 3475\n   - Check for process using: `lsof -i :3475`\n\n3. **Python Environment**\n   - UV manages dependencies\n   - Check logs in temp directory\n   - Virtual env in system temp folder\n\n## ğŸ¤ Contributing\n\nContributions welcome! Areas of interest:\n\n- Additional model support\n- Performance optimizations\n- New analysis capabilities\n- Documentation improvements\n\n## ğŸ“„ License\n\n[Add your license information here]\n\n## ğŸ™ Acknowledgments\n\n- [Moondream Model Team](https://github.com/vikhyat/moondream)\n- Model Context Protocol (MCP) Community\n- Contributors and maintainers\n\n---\n\n<p align=\"center\">\nMade with â¤ï¸ by Nighttrek\n</p>\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "noeltg77--Replicate-Designer": {
      "owner": "noeltg77",
      "name": "Replicate-Designer",
      "url": "https://github.com/noeltg77/Replicate-Designer",
      "imageUrl": "https://github.com/noeltg77.png",
      "description": "Generate images from text descriptions using Replicate's Flux 1.1 Pro model. Designed for seamless integration in projects requiring high-quality image generation capabilities.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-03-31T20:07:00Z",
      "readme_content": "# Replicate Designer MCP\n\nAn MCP server for generating images using Replicate's Flux 1.1 Pro model.\n\n## Installation\n\n### Using Directly from GitHub\n\nYou can use the MCP server directly from GitHub in several ways:\n\n#### Option 1: Install directly with pip\n\n```bash\npip install git+https://github.com/yourusername/replicate-designer.git\n```\n\nThen run it with:\n```bash\nmcp-replicate-designer\n```\n\n#### Option 2: Use npx with GitHub repository\n\nCreate a configuration file (e.g., `mcps.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"replicateDesigner\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\", \n        \"github:yourusername/replicate-designer\"\n      ],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your_replicate_api_token_here\"\n      }\n    }\n  }\n}\n```\n\nThen use it with Claude or another assistant:\n```bash\nnpx @anthropic-ai/assistant --mcps-json mcps.json\n```\n\nThis method allows you to include your Replicate API token directly in the configuration file, which is more convenient than setting environment variables separately.\n\n#### Option 3: Local Installation\n\nClone the repository and install from the local directory:\n\n```bash\ngit clone https://github.com/yourusername/replicate-designer.git\ncd replicate-designer\npip install -e .\n```\n\n### Publishing and Using via npm\n\nTo make your MCP available via npm (for easier distribution):\n\n1. Package and publish your MCP:\n```bash\n# Build a wheel\npip install build\npython -m build\n\n# Publish to npm (after setting up an npm account)\nnpm init\nnpm publish\n```\n\n2. Then users can install and use it directly:\n```bash\nnpx -y mcp-replicate-designer\n```\n\n## Usage\n\n### Setting the API Token\n\nThere are several ways to provide your Replicate API token:\n\n1. **Environment variable** (for command line usage):\n   ```bash\n   export REPLICATE_API_TOKEN=your_api_token_here\n   ```\n\n2. **In the MCP configuration file** (as shown in Option 2 above):\n   ```json\n   {\n     \"mcpServers\": {\n       \"replicateDesigner\": {\n         \"command\": \"...\",\n         \"args\": [\"...\"],\n         \"env\": {\n           \"REPLICATE_API_TOKEN\": \"your_replicate_api_token_here\"\n         }\n       }\n     }\n   }\n   ```\n\n3. **Using a .env file** in your project directory:\n   ```\n   REPLICATE_API_TOKEN=your_api_token_here\n   ```\n   \n   Then, install the python-dotenv package:\n   ```bash\n   pip install python-dotenv\n   ```\n\n> **Security Note**: Be careful with your API tokens. Never commit them to public repositories, and use environment variables or secure secret management when possible.\n\n### Running the MCP server\n\n```bash\nmcp-replicate-designer\n```\n\nBy default, it runs in stdio mode which is compatible with npx use. You can also run it in SSE mode:\n\n```bash\nmcp-replicate-designer --transport sse --port 8000\n```\n\n## Using with npx\n\nThis MCP can be used with an AI agent using npx in two ways:\n\n### Direct command line\n\n```bash\nnpx @anthropic-ai/assistant --mcp mcp-replicate-designer\n```\n\n### As a configuration object\n\nIn your configuration JSON:\n\n```json\n{\n  \"mcpServers\": {\n    \"replicateDesigner\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-replicate-designer\"\n      ]\n    }\n  }\n}\n```\n\nThen use it with:\n\n```bash\nnpx @anthropic-ai/assistant --mcps-json /path/to/your/config.json\n```\n\n## Tool\n\nThis MCP exposes a single tool:\n\n### generate_image\n\nGenerates an image using Replicate's Flux 1.1 Pro model.\n\n**Parameters:**\n\n- `prompt` (string, required): Text description of the image to generate\n- `aspect_ratio` (string, optional, default: \"1:1\"): Aspect ratio for the generated image\n- `output_format` (string, optional, default: \"webp\"): Format of the output image\n- `output_quality` (integer, optional, default: 80): Quality of the output image (1-100)\n- `safety_tolerance` (integer, optional, default: 2): Safety tolerance level (0-3)\n- `prompt_upsampling` (boolean, optional, default: true): Whether to use prompt upsampling\n\n**Example:**\n\n```json\n{\n  \"prompt\": \"A photograph of an humanoid AI agent looking sad and in disrepair, the agent is sat at a workbench getting fixed by a human male\",\n  \"aspect_ratio\": \"1:1\",\n  \"output_format\": \"webp\"\n}\n```",
      "npm_url": "",
      "npm_downloads": 0
    },
    "NON906--omniparser-autogui-mcp": {
      "owner": "NON906",
      "name": "omniparser-autogui-mcp",
      "url": "https://github.com/NON906/omniparser-autogui-mcp",
      "imageUrl": "https://github.com/NON906.png",
      "description": "Analyzes the screen using OmniParser to automatically operate graphical user interfaces. It provides capabilities for interpreting visual content and executing GUI actions based on analysis.",
      "stars": 55,
      "forks": 10,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-02T00:52:32Z",
      "readme_content": "# omniparser-autogui-mcp\n\nï¼ˆ[æ—¥æœ¬èªç‰ˆã¯ã“ã¡ã‚‰](README_ja.md)ï¼‰\n\nThis is an [MCP server](https://modelcontextprotocol.io/introduction) that analyzes the screen with [OmniParser](https://github.com/microsoft/OmniParser) and automatically operates the GUI.  \nConfirmed on Windows.\n\n## License notes\n\nThis is MIT license, but Excluding submodules and sub packages.  \nOmniParser's repository is CC-BY-4.0.  \nEach OmniParser model has a different license ([reference](https://github.com/microsoft/OmniParser?tab=readme-ov-file#model-weights-license)).\n\n## Installation\n\n1. Please do the following:\n\n```\ngit clone --recursive https://github.com/NON906/omniparser-autogui-mcp.git\ncd omniparser-autogui-mcp\nuv sync\nset OCR_LANG=en\nuv run download_models.py\n```\n\n(Other than Windows, use ``export`` instead of ``set``.)  \n(If you want ``langchain_example.py`` to work, ``uv sync --extra langchain`` instead.)\n\n2. Add this to your ``claude_desktop_config.json``:\n\n```claude_desktop_config.json\n{\n  \"mcpServers\": {\n    \"omniparser_autogui_mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"D:\\\\CLONED_PATH\\\\omniparser-autogui-mcp\",\n        \"run\",\n        \"omniparser-autogui-mcp\"\n      ],\n      \"env\": {\n        \"PYTHONIOENCODING\": \"utf-8\",\n        \"OCR_LANG\": \"en\"\n      }\n    }\n  }\n}\n```\n\n(Replace ``D:\\\\CLONED_PATH\\\\omniparser-autogui-mcp`` with the directory you cloned.)\n\n``env`` allows for the following additional configurations:\n\n- ``OMNI_PARSER_BACKEND_LOAD``  \nIf it does not work with other clients (such as [LibreChat](https://github.com/danny-avila/LibreChat)), specify ``1``.\n\n- ``TARGET_WINDOW_NAME``  \nIf you want to specify the window to operate, please specify the window name.  \nIf not specified, operates on the entire screen.\n\n- ``OMNI_PARSER_SERVER``  \nIf you want OmniParser processing to be done on another device, specify the server's address and port, such as ``127.0.0.1:8000``.  \nThe server can be started with ``uv run omniparserserver``.\n\n- ``SSE_HOST``, ``SSE_PORT``  \nIf specified, communication will be done via SSE instead of stdio.\n\n- ``SOM_MODEL_PATH``, ``CAPTION_MODEL_NAME``, ``CAPTION_MODEL_PATH``, ``OMNI_PARSER_DEVICE``, ``BOX_TRESHOLD``  \nThese are for OmniParser configuration.  \nUsually, they are not necessary.\n\n## Usage Examples\n\n- Search for \"MCP server\" in the on-screen browser.\n\netc.",
      "npm_url": "",
      "npm_downloads": 0
    },
    "nota--gyazo-mcp-server": {
      "owner": "nota",
      "name": "gyazo-mcp-server",
      "url": "https://github.com/nota/gyazo-mcp-server",
      "imageUrl": "https://github.com/nota.png",
      "description": "Access and manage Gyazo images and their associated metadata, including OCR data, through a standardized protocol. Enables full-text search and retrieval of images using URIs.",
      "stars": 24,
      "forks": 8,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T07:37:31Z",
      "readme_content": "# gyazo-mcp-server\n\nA Model Context Protocol server for Gyazo image integration\n\nThis is a TypeScript-based MCP server that provides access to Gyazo images. It allows AI assistants to access and interact with Gyazo images through the Model Context Protocol, providing:\n\n- Resources representing Gyazo images with URIs and metadata\n- Tools for searching, fetching, and uploading images\n- Image content and metadata access via the Gyazo API\n\n## Features\n\n### Resources\n\n- List and access Gyazo images via `gyazo-mcp://` URIs\n- Each image includes:\n  - Original image content\n  - Metadata (title, description, app, URL)\n  - OCR data (if available)\n- Supports various image formats (JPEG, PNG, etc.)\n\n### Tools\n\n- `gyazo_search` - Full-text search for captures uploaded by users on Gyazo\n\n  - Search by keyword, title, app, URL, or date range\n  - Supports pagination for browsing multiple results\n  - Returns matching image URIs and metadata\n\n- `gyazo_image` - Fetch image content and metadata from Gyazo\n\n  - Retrieve specific images by ID or URL\n  - Returns both image content and detailed metadata\n\n- `gyazo_latest_image` - Fetch the most recent image from Gyazo\n\n  - Returns both image content and metadata\n  - Includes OCR text if available\n\n- `gyazo_upload` - Upload an image to Gyazo\n  - Upload images with base64 encoded image data\n  - Add optional metadata like title, description, referer URL, and app name\n  - Returns the uploaded image's permalink URL and ID\n\n## Installation\n\n### NPM Package\n\nThe easiest way to install the Gyazo MCP server is via npm:\n\n```bash\nnpm install -g @notainc/gyazo-mcp-server\n```\n\n### Prerequisites\n\n- Create a Gyazo account if you don't have one: https://gyazo.com\n- Get your Gyazo API access token from: https://gyazo.com/api\n  - Click \"Register applications\" button\n  - Click \"New Application\" button\n  - Fill in the form with your app name and description\n    - Name and Callback URL are required\n    - You can use `http://localhost` for the Callback URL\n  - Click \"Submit\" button\n  - Click application name to view details\n  - Scroll down to \"Your Access Token\"\n  - Click \"Generate\" button\n  - Copy \"Your access token\" value\n- Set the `GYAZO_ACCESS_TOKEN` environment variable with your token\n\n### Claude Desktop Integration\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n#### Using NPM package (recommended)\n\n```json\n{\n  \"mcpServers\": {\n    \"gyazo-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"@notainc/gyazo-mcp-server\"],\n      \"env\": {\n        \"GYAZO_ACCESS_TOKEN\": \"your-access-token-here\"\n      }\n    }\n  }\n}\n```\n\n#### Using Docker (optional)\n\n```json\n{\n  \"mcpServers\": {\n    \"gyazo-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"GYAZO_ACCESS_TOKEN\",\n        \"gyazo-mcp-server\"\n      ],\n      \"env\": {\n        \"GYAZO_ACCESS_TOKEN\": \"your-access-token-here\"\n      }\n    }\n  }\n}\n```\n\n## Development\n\nInstall dependencies:\n\n```bash\nnpm ci\n```\n\nBuild the server:\n\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n\n```bash\nnpm run watch\n```\n\n### Docker Build (optional)\n\n```bash\nnpm run image:build\n```\n\n---\n\n<a href=\"https://glama.ai/mcp/servers/bhrk879agk\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/bhrk879agk/badge\" />\n</a>\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "PawNzZi--image-server": {
      "owner": "PawNzZi",
      "name": "image-server",
      "url": "https://github.com/PawNzZi/image-server",
      "imageUrl": "https://github.com/PawNzZi.png",
      "description": "Transform text prompts into images using advanced AI techniques, creating unique visuals tailored to user descriptions.",
      "stars": 1,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-04-17T12:56:27Z",
      "readme_content": "[![smithery badge](https://smithery.ai/badge/@PawNzZi/image-server)](https://smithery.ai/server/@PawNzZi/image-server)\n\n### Installing via Smithery\n\nTo install text2image for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@PawNzZi/image-server):\n\n```bash\nnpx -y @smithery/cli install @PawNzZi/image-server --client claude\n```\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "peng-shawn--mermaid-mcp-server": {
      "owner": "peng-shawn",
      "name": "mermaid-mcp-server",
      "url": "https://github.com/peng-shawn/mermaid-mcp-server",
      "imageUrl": "https://github.com/peng-shawn.png",
      "description": "Converts Mermaid diagram descriptions into high-quality PNG images using the Mermaid markdown syntax. Supports customizable themes and backgrounds for visual representations of data and processes.",
      "stars": 185,
      "forks": 21,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:32:19Z",
      "readme_content": "# Mermaid MCP Server\n\nA Model Context Protocol (MCP) server that converts Mermaid diagrams to PNG images or SVG files. This server allows AI assistants and other applications to generate visual diagrams from textual descriptions using the Mermaid markdown syntax.\n\n## Features\n\n- Converts Mermaid diagram code to PNG images or SVG files\n- Supports multiple diagram themes (default, forest, dark, neutral)\n- Customizable background colors\n- Uses Puppeteer for high-quality headless browser rendering\n- Implements the MCP protocol for seamless integration with AI assistants\n- Flexible output options: return images/SVG directly or save to disk\n- Error handling with detailed error messages\n\n## How It Works\n\nThe server uses Puppeteer to launch a headless browser, render the Mermaid diagram to SVG, and optionally capture a screenshot of the rendered diagram. The process involves:\n\n1. Launching a headless browser instance\n2. Creating an HTML template with the Mermaid code\n3. Loading the Mermaid.js library\n4. Rendering the diagram to SVG\n5. Either saving the SVG directly or taking a screenshot as PNG\n6. Either returning the image/SVG directly or saving it to disk\n\n## Build\n\n```bash\nnpx tsc\n```\n\n## Usage\n\n### Use with Claude desktop\n\n```json\n{\n  \"mcpServers\": {\n    \"mermaid\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@peng-shawn/mermaid-mcp-server\"]\n    }\n  }\n}\n```\n\n### Use with Cursor and Cline\n\n```bash\nenv CONTENT_IMAGE_SUPPORTED=false npx -y @peng-shawn/mermaid-mcp-server\n```\n\nYou can find a list of mermaid diagrams under `./diagrams`, they are created using Cursor agent with prompt: \"generate mermaid diagrams and save them in a separate diagrams folder explaining how renderMermaidPng work\"\n\n### Run with inspector\n\nRun the server with inspector for testing and debugging:\n\n```bash\nnpx @modelcontextprotocol/inspector node dist/index.js\n```\n\nThe server will start and listen on stdio for MCP protocol messages.\n\nLearn more about inspector [here](https://modelcontextprotocol.io/docs/tools/inspector).\n\n### Installing via Smithery\n\nTo install Mermaid Diagram Generator for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@peng-shawn/mermaid-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @peng-shawn/mermaid-mcp-server --client claude\n```\n\n### Docker and Smithery Environments\n\nWhen running in Docker containers (including via Smithery), you may need to handle Chrome dependencies:\n\n1. The server now attempts to use Puppeteer's bundled browser by default\n2. If you encounter browser-related errors, you have two options:\n\n   **Option 1: During Docker image build:**\n\n   - Set `PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true` when installing Puppeteer\n   - Install Chrome/Chromium in your Docker container\n   - Set `PUPPETEER_EXECUTABLE_PATH` at runtime to point to the Chrome installation\n\n   **Option 2: Use Puppeteer's bundled Chrome:**\n\n   - Ensure your Docker container has the necessary dependencies for Chrome\n   - No need to set `PUPPETEER_SKIP_CHROMIUM_DOWNLOAD`\n   - The code will use the bundled browser automatically\n\nFor Smithery users, the latest version should work without additional configuration.\n\n## API\n\nThe server exposes a single tool:\n\n- `generate`: Converts Mermaid diagram code to a PNG image or SVG file\n  - Parameters:\n    - `code`: The Mermaid diagram code to render\n    - `theme`: (optional) Theme for the diagram. Options: \"default\", \"forest\", \"dark\", \"neutral\"\n    - `backgroundColor`: (optional) Background color for the diagram, e.g. 'white', 'transparent', '#F0F0F0'\n    - `outputFormat`: (optional) Output format for the diagram. Options: \"png\", \"svg\" (defaults to \"png\")\n    - `name`: Name for the generated file (required when CONTENT_IMAGE_SUPPORTED=false)\n    - `folder`: Absolute path to save the image/SVG to (required when CONTENT_IMAGE_SUPPORTED=false)\n\nThe behavior of the `generate` tool depends on the `CONTENT_IMAGE_SUPPORTED` environment variable:\n\n- When `CONTENT_IMAGE_SUPPORTED=true` (default): The tool returns the image/SVG directly in the response\n- When `CONTENT_IMAGE_SUPPORTED=false`: The tool saves the image/SVG to the specified folder and returns the file path\n\n## Environment Variables\n\n- `CONTENT_IMAGE_SUPPORTED`: Controls whether images are returned directly in the response or saved to disk\n  - `true` (default): Images are returned directly in the response\n  - `false`: Images are saved to disk, requiring `name` and `folder` parameters\n\n## Examples\n\n### Basic Usage\n\n```javascript\n// Generate a flowchart with default settings\n{\n  \"code\": \"flowchart TD\\n    A[Start] --> B{Is it?}\\n    B -->|Yes| C[OK]\\n    B -->|No| D[End]\"\n}\n```\n\n### With Theme and Background Color\n\n```javascript\n// Generate a sequence diagram with forest theme and light gray background\n{\n  \"code\": \"sequenceDiagram\\n    Alice->>John: Hello John, how are you?\\n    John-->>Alice: Great!\",\n  \"theme\": \"forest\",\n  \"backgroundColor\": \"#F0F0F0\"\n}\n```\n\n### Saving to Disk (when CONTENT_IMAGE_SUPPORTED=false)\n\n```javascript\n// Generate a class diagram and save it to disk as PNG\n{\n  \"code\": \"classDiagram\\n    Class01 <|-- AveryLongClass\\n    Class03 *-- Class04\\n    Class05 o-- Class06\",\n  \"theme\": \"dark\",\n  \"name\": \"class_diagram\",\n  \"folder\": \"/path/to/diagrams\"\n}\n```\n\n### Generating SVG Output\n\n```javascript\n// Generate a state diagram as SVG\n{\n  \"code\": \"stateDiagram-v2\\n    [*] --> Still\\n    Still --> [*]\\n    Still --> Moving\\n    Moving --> Still\\n    Moving --> Crash\\n    Crash --> [*]\",\n  \"outputFormat\": \"svg\",\n  \"name\": \"state_diagram\",\n  \"folder\": \"/path/to/diagrams\"\n}\n```\n\n## FAQ\n\n### Doesn't Claude desktop already support mermaid via canvas?\n\nYes, but it doesn't support the `theme` and `backgroundColor` options. Plus, having a dedicated server makes it easier to create mermaid diagrams with different MCP clients.\n\n### Why do I need to specify CONTENT_IMAGE_SUPPORTED=false when using with Cursor?\n\nCursor doesn't support inline images in responses yet.\n\n## Publishing\n\nThis project uses GitHub Actions to automate the publishing process to npm.\n\n### Method 1: Using the Release Script (Recommended)\n\n1. Make sure all your changes are committed and pushed\n2. Run the release script with either a specific version number or a semantic version increment:\n\n   ```bash\n   # Using a specific version number\n   npm run release 0.1.4\n\n   # Using semantic version increments\n   npm run release patch  # Increments the patch version (e.g., 0.1.3 â†’ 0.1.4)\n   npm run release minor  # Increments the minor version (e.g., 0.1.3 â†’ 0.2.0)\n   npm run release major  # Increments the major version (e.g., 0.1.3 â†’ 1.0.0)\n   ```\n\n3. The script will:\n   - Validate the version format or semantic increment\n   - Check if you're on the main branch\n   - Detect and warn about version mismatches between files\n   - Update all version references consistently (package.json, package-lock.json, and index.ts)\n   - Create a single commit with all version changes\n   - Create and push a git tag\n   - The GitHub workflow will then automatically build and publish to npm\n\n### Method 2: Manual Process\n\n1. Update your code and commit the changes\n2. Create and push a new tag with the version number:\n   ```bash\n   git tag v0.1.4  # Use the appropriate version number\n   git push origin v0.1.4\n   ```\n3. The GitHub workflow will automatically:\n   - Build the project\n   - Publish to npm with the version from the tag\n\nNote: You need to set up the `NPM_TOKEN` secret in your GitHub repository settings. To do this:\n\n1. Generate an npm access token with publish permissions\n2. Go to your GitHub repository â†’ Settings â†’ Secrets and variables â†’ Actions\n3. Create a new repository secret named `NPM_TOKEN` with your npm token as the value\n\n## Badges\n\n[![smithery badge](https://smithery.ai/badge/@peng-shawn/mermaid-mcp-server)](https://smithery.ai/server/@peng-shawn/mermaid-mcp-server)\n\n<a href=\"https://glama.ai/mcp/servers/lzjlbitkzr\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/lzjlbitkzr/badge\" alt=\"mermaid-mcp-server MCP server\" />\n</a>\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "philipp-eisen--modal-mcp-toolbox": {
      "owner": "philipp-eisen",
      "name": "modal-mcp-toolbox",
      "url": "https://github.com/philipp-eisen/modal-mcp-toolbox",
      "imageUrl": "https://github.com/philipp-eisen.png",
      "description": "A collection of tools that provides a sandboxed environment for executing Python code and generating images using the FLUX model.",
      "stars": 22,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-12T21:44:25Z",
      "readme_content": "# Modal MCP Toolbox ğŸ› ï¸\n\n[![smithery badge](https://smithery.ai/badge/@philipp-eisen/modal-mcp-toolbox)](https://smithery.ai/server/@philipp-eisen/modal-mcp-toolbox)\n\nA collection of Model Context Protocol (MCP) tools that run on Modal.\nThis let's you extend the capabilities of your LLM in tools such as [Goose](https://block.github.io/goose/) or the [Claude Desktop App](https://claude.ai/download).\n\n<a href=\"https://glama.ai/mcp/servers/ai78w0p5mc\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/ai78w0p5mc/badge\" alt=\"Modal Toolbox MCP server\" /></a>\n\n## Tools\n\n- `run_python_code_in_sandbox`: Let's you run python code in a sandboxed environment.\n- `generate_flux_image`: Generate an image using the FLUX model.\n\n## Demo\n\n### Flux Image Generation\n\n![ğŸ¬Flux Image Generation](./assets/flux.gif)\n\n### Python Code Execution\n\n![ğŸ¬Python Code Execution](./assets/python-sandbox.gif)\n\n## Prerequisites\n\n- A [modal account](https://modal.com/signup) and a configured modal CLI.\n- [UV](https://github.com/astral-sh/uv?tab=readme-ov-file#installation)\n- A client that supports MCP. Such as the [Claude Desktop App](https://claude.ai/download) or [Goose](https://block.github.io/goose/)\n\nThis runs against your modal account, so you will need to have a modal account and be logged in.\n\n## Installation\n\nInstallation depends on the client that uses the MCP. Here is instructions for Claude and Goose.\n\n### Claude\n\nGot to `Settings > Developer` in the Claude Desktop App. And click on Edit Config.\n![ğŸ–¼ï¸Claude Settings](./assets/claude-settings.png)\n\nAdd the config for the mcp server. My config looks like this:\n\n```json\n{\n  \"mcpServers\": {\n    \"modal-toolbox\": {\n      \"command\": \"uvx\",\n      \"args\": [\"modal-mcp-toolbox\"]\n    }\n  }\n}\n```\n\n### Goose\n\nGo to `Settings` and Click on Add.\n\n![ğŸ–¼ï¸Goose Settings](./assets/goose-settings-1.png)\n\nThen add an extension like in the screenshot below.\nThe important part is to set command to:\n\n```\nuvx modal-mcp-toolbox\n```\n\nThe rest you can fill in as you like.\n\n![ğŸ–¼ï¸Goose MCP Settings](./assets/goose-settings-2.png)\n\n### Installing via Smithery (not working currently)\n\nTo install Modal MCP Toolbox for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@philipp-eisen/modal-mcp-toolbox):\n\n```bash\nnpx -y @smithery/cli install @philipp-eisen/modal-mcp-toolbox --client claude\n```\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "pinkpixel-dev--MCPollinations": {
      "owner": "pinkpixel-dev",
      "name": "MCPollinations",
      "url": "https://github.com/pinkpixel-dev/MCPollinations",
      "imageUrl": "https://github.com/pinkpixel-dev.png",
      "description": "Generates images, text, and audio from prompts using the Pollinations APIs. It supports returning images as base64-encoded data and allows listing available models for image and text generation.",
      "stars": 34,
      "forks": 10,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-26T03:37:33Z",
      "readme_content": "# MCPollinations Multimodal MCP Server\nA Model Context Protocol (MCP) server that enables AI assistants to generate images, text, and audio through the Pollinations APIs\n\n[![smithery badge](https://smithery.ai/badge/@pinkpixel-dev/mcpollinations)](https://smithery.ai/server/@pinkpixel-dev/mcpollinations) [![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/8448e4ec-c863-476a-8adb-aed3cf16ea2b)\n\n## Features\n\n- Generate image URLs from text prompts\n- Generate images and return them as base64-encoded data AND save as png, jpeg, jpg, or webp (default: png)\n- Generate text responses from text prompts\n- Generate audio responses from text prompts\n- List available image and text generation models\n- No authentication required\n- Simple and lightweight\n- Compatible with the Model Context Protocol (MCP)\n\n## System Requirements\n\n- **Node.js**: Version 14.0.0 or higher\n  - For best performance, we recommend Node.js 16.0.0 or higher\n  - Node.js versions below 16 use an AbortController polyfill\n\n## Quick Start\n\n### Installing via Smithery\n\nTo install mcpollinations for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@pinkpixel-dev/mcpollinations):\n\n```bash\nnpx -y @smithery/cli install @pinkpixel-dev/mcpollinations --client claude\n```\n\nThe easiest way to use the MCP server:\n\n```bash\n# Run directly with npx (no installation required)\nnpx @pinkpixel/mcpollinations\n```\n\nIf you prefer to install it globally:\n\n```bash\n# Install globally\nnpm install -g @pinkpixel/mcpollinations\n\n# Run the server\nmcpollinations\n# or\nnpx @pinkpixel/mcpollinations\n\n```\n\nOr clone the repository:\n\n```bash\n# Clone the git repository\ngit clone https://github.com/pinkpixel-dev/mcpollinations.git\n# Run the server\nmcpollinations\n# or\nnpx @pinkpixel/mcpollinations\n# or run directly\nnode /path/to/MCPollinations/pollinations-mcp-server.js\n\n```\n\n## MCP Integration\n\nTo integrate the server with applications that support the Model Context Protocol (MCP):\n\n1. Generate an MCP configuration file:\n\n```bash\n# If installed globally\nnpx @pinkpixel/mcpollinations generate-config\n\n# Or run directly\nnode /path/to/MCPollinations/generate-mcp-config.js\n```\n\n### Quick MCP Config (env)\nIf you prefer to skip the generator, copy this into your MCP client config:\n\n```json\n{\n  \"mcpollinations\": {\n    \"command\": \"npx\",\n    \"args\": [\"-y\", \"@pinkpixel/mcpollinations\"],\n    \"env\": {\n      \"token\": \"YOUR_TOKEN_OPTIONAL\",\n      \"referrer\": \"your-app-or-domain-optional\",\n      \"IMAGE_MODEL\": \"flux\",\n      \"IMAGE_WIDTH\": \"1024\",\n      \"IMAGE_HEIGHT\": \"1024\",\n      \"IMAGE_ENHANCE\": \"true\",\n      \"IMAGE_SAFE\": \"false\",\n      \"TEXT_MODEL\": \"openai\",\n      \"TEXT_TEMPERATURE\": \"0.7\",\n      \"TEXT_TOP_P\": \"0.9\",\n      \"TEXT_SYSTEM\": \"\",\n      \"AUDIO_VOICE\": \"alloy\",\n      \"OUTPUT_DIR\": \"./mcpollinations-output\"\n    }\n  }\n}\n```\n\n2. Follow the prompts to customize your configuration or use the defaults.\n   - Set an output directory (relative paths recommended for portability)\n     - **Windows users**: Consider using absolute paths (e.g., `C:\\Users\\YourName\\Pictures\\MCPollinations`) for more reliable file saving\n   - Configure optional authentication (token, referrer) under `env`\n   - Configure default parameters for image generation (with a list of available models, dimensions, etc.)\n   - Configure default parameters for text generation (with a list of available models)\n   - Configure default parameters for audio generation (voice)\n\n\n3. Copy the generated `mcp.json` file to your application's MCP settings .json file.\n4. Restart your application.\n\nAfter integration, you can use commands like:\n\n\"Generate an image of a sunset over the ocean using MCPollinations\"\n\n## Authentication (Optional)\n\nMCPollinations supports optional authentication to provide access to more models and better rate limits. The server works perfectly without authentication (free tier), but users with API tokens can get enhanced access.\n\n### Configuration Methods\n\n**Method 1: Environment Variables (Recommended for security)**\n```bash\n# Set environment variables before running the server\nexport POLLINATIONS_TOKEN=\"your-api-token\"\nexport POLLINATIONS_REFERRER=\"https://your-domain.com\"\n\n# Then run the server\nnpx @pinkpixel/mcpollinations\n```\n\n**Method 2: MCP Configuration File (env)**\nWhen generating your MCP configuration, place auth inside `env` so your MCP client passes them as environment variables to the server process:\n```json\n{\n  \"mcpollinations\": {\n    \"command\": \"npx\",\n    \"args\": [\"-y\", \"@pinkpixel/mcpollinations\"],\n    \"env\": {\n      \"token\": \"your-api-token\",\n      \"referrer\": \"your-app-or-domain\"\n    }\n  }\n}\n```\n\nYou can also provide `POLLINATIONS_TOKEN` and `POLLINATIONS_REFERRER` instead; the server recognizes both forms. Using `token` and `referrer` inside `env` is recommended for MCP configs.\n\n### Authentication Parameters\n\n- **`token`** (optional): Your Pollinations API token for enhanced access\n- **`referrer`** (optional): Your domain/application referrer URL\n\nBoth parameters are completely optional. Leave them empty or unset to use the free tier.\n\n## Using Your Configuration Settings\n\nMCPollinations respects your MCP configuration settings placed in `env` as defaults. When you ask an AI assistant to generate content:\n\n- **Your configured models, output directories, and parameters are used automatically**\n- **To override**: Specifically instruct the AI to use different settings\n  - \"Generate an image using the kontext model\"\n  - \"Save this image to my Desktop folder\"\n  - \"Use a temperature of 1.2 for this text generation\"\n\n**Example Instructions:**\n- âœ… \"Generate a sunset image\" â†’ Uses your configured model and output directory\n- âœ… \"Generate a sunset image with the flux model\" â†’ Overrides model only\n- âœ… \"Generate a sunset image and save it to C:\\Pictures\" â†’ Overrides output path only\n\nThis ensures your preferences are always respected unless you specifically want different settings for a particular request.\n\n## Troubleshooting\n\n### \"AbortController is not defined\" Error\n\nIf you encounter this error when running the MCP server:\n\n```\nReferenceError: AbortController is not defined\n```\n\nThis is usually caused by running on an older version of Node.js (below version 16.0.0). Try one of these solutions:\n\n1. **Update Node.js** (recommended):\n   - Update to Node.js 16.0.0 or newer\n\n2. **Use Global Installation**\n   - Update to the latest version of the package:\n   ```bash\n   npm install -g @pinkpixel/mcpollinations\n   # Run with npx\n   npx @pinkpixel/mcpollinations\n   ```\n\n3. **Install AbortController manually**:\n   - If for some reason the polyfill doesn't work:\n   ```bash\n   npm install node-abort-controller\n   ```\n\n### Check Your Node.js Version\n\nTo check your current Node.js version:\n\n```bash\nnode --version\n```\n\nIf it shows a version lower than 16.0.0, consider upgrading for best compatibility.\n\n## Available Tools\n\nThe MCP server provides the following tools:\n\n### **Image Generation Tools**\n1. `generateImageUrl` - Generates an image URL from a text prompt\n2. `generateImage` - Generates an image, returns it as base64-encoded data, and saves it to a file by default (PNG format)\n3. `editImage` - **NEW!** Edit or modify existing images based on text prompts\n4. `generateImageFromReference` - **NEW!** Generate new images using existing images as reference\n5. `listImageModels` - Lists available models for image generation\n\n### **Text & Audio Tools**\n6. `respondText` - Responds with text to a prompt using text models (customizable parameters)\n7. `respondAudio` - Generates an audio response to a text prompt (customizable voice parameter)\n8. `listTextModels` - Lists available models for text generation\n9. `listAudioVoices` - Lists all available voices for audio generation\n\n## Text Generation Details\n\n### Available Parameters\n\nThe `respondText` tool supports several parameters for fine-tuning text generation:\n\n- **`model`**: Choose from available text models (use `listTextModels` to see current options)\n- **`temperature`** (0.0-2.0): Controls randomness in the output\n  - Lower values (0.1-0.7) = more focused and deterministic\n  - Higher values (0.8-2.0) = more creative and random\n- **`top_p`** (0.0-1.0): Controls diversity via nucleus sampling\n  - Lower values = more focused on likely tokens\n  - Higher values = considers more token possibilities\n- **`system`**: System prompt to guide the model's behavior and personality\n\n### Customizing Text Generation\n\n```javascript\n// Example options for respondText\nconst options = {\n  model: \"openai\",           // Model selection\n  temperature: 0.7,          // Balanced creativity\n  top_p: 0.9,               // High diversity\n  system: \"You are a helpful assistant that explains things clearly and concisely.\"\n};\n```\n\n### Configuration Examples\n\nIn your MCP configuration, set defaults under `env` so the server uses them automatically:\n\n```json\n{\n  \"mcpollinations\": {\n    \"env\": {\n      \"TEXT_MODEL\": \"openai\",\n      \"TEXT_TEMPERATURE\": \"0.7\",\n      \"TEXT_TOP_P\": \"0.9\",\n      \"TEXT_SYSTEM\": \"You are a helpful coding assistant.\"\n    }\n  }\n}\n```\n\n## Image-to-Image Generation (NEW!)\n\nMCPollinations now supports powerful image-to-image generation with two specialized tools:\n\n### **editImage Tool**\nPerfect for modifying existing images:\n- **Remove objects**: \"remove the cat from this image\"\n- **Add elements**: \"add a dog to this scene\"\n- **Change backgrounds**: \"replace the background with mountains\"\n- **Style modifications**: \"make the lighting more dramatic\"\n\n### **generateImageFromReference Tool**\nPerfect for creating variations and new styles:\n- **Style transfer**: \"make this photo look like a painting\"\n- **Format changes**: \"convert this to a cartoon style\"\n- **Creative variations**: \"create a futuristic version of this\"\n- **Artistic interpretations**: \"make this look like a sketch\"\n\n### **Supported Models**\n- **`kontext`**: Specialized model optimized for image-to-image tasks\n- **`nanobanana`**: New Google model supporting both text-to-image and image-to-image generation\n- **`seedream`**: New ByteDance model supporting both text-to-image and image-to-image generation\n\nMulti-reference images: `editImage` and `generateImageFromReference` accept `imageUrl` as a single URL or an array of URLs. The server encodes arrays as the comma-separated `image` parameter used by the API. Ordering matters; kontext uses only the first image, nanobanana is safe up to ~4 refs, and seedream supports up to 10.\n\nImportant: URLs only. The image-to-image tools require publicly accessible HTTP(S) URLs. Local file paths, file uploads, and base64/data URLs are not supported by this MCP server (it does not upload files). If you need to work from a local image, host it somewhere accessible (e.g., a temporary file host, object storage, or a raw link in a repo) and pass the URL.\n\n### **Example Usage**\n```javascript\n// Edit an existing image\nconst editResult = await editImage(\n  \"change the background to a sunset beach\",\n  \"https://example.com/photo.jpg\",\n  \"nanobanana\"  // or \"kontext\", \"seedream\"\n);\n\n// Generate from reference\nconst referenceResult = await generateImageFromReference(\n  \"make this into a watercolor painting\",\n  \"https://example.com/photo.jpg\",\n  \"seedream\"  // or \"kontext\", \"nanobanana\"\n);\n```\n\n## Image Generation Details\n\n### Default Behavior\n\nWhen using the `generateImage` tool:\n\n- Images are saved to disk by default as PNG files\n- The default save location is the current working directory where the MCP server is running\n- The 'flux' model is used by default\n- A random seed is generated by default for each image (ensuring variety)\n- Base64-encoded image data is always returned, regardless of whether the image is saved to a file\n\n### Customizing Image Generation\n\n```javascript\n// Example options for generateImage\nconst options = {\n  // Model selection (defaults to 'flux')\n  // Available models: \"flux\", \"turbo\", \"kontext\", \"nanobanana\", \"seedream\"\n  model: \"flux\",\n\n  // Image dimensions\n  width: 1024,\n  height: 1024,\n\n  // Generation options\n  seed: 12345,  // Specific seed for reproducibility (defaults to random)\n  enhance: true,  // Enhance the prompt using an LLM before generating (defaults to true)\n  safe: false,  // Content filtering (defaults to false)\n\n  // File saving options\n  saveToFile: true,  // Set to false to skip saving to disk\n  outputPath: \"/path/to/save/directory\",  // Custom save location\n  fileName: \"my_custom_name\",  // Without extension\n  format: \"png\"  // png, jpeg, jpg, or webp\n};\n```\n\n### Where Images Are Saved\n\nWhen using Claude or another application with the MCP server:\n\n1. **Images are saved in the current working directory of where the MCP server is running**, not where Claude or the client application is installed.\n\n2. If you start the MCP server manually from a specific directory, images will be saved there by default.\n\n3. If Claude Desktop launches the MCP server automatically, images will be saved in Claude Desktop's working directory (typically in an application data folder).\n\n**ğŸ’¡ Windows Users**: For reliable file saving on Windows, use absolute paths in your MCP configuration instead of relative paths (e.g., `C:\\Users\\YourName\\Pictures\\MCPollinations` instead of `./mcpollinations-output`). Relative paths may not resolve as expected depending on the working directory context.\n\n### Finding Your Generated Images\n\n- The response from Claude after generating an image includes the full file path where the image was saved\n- You can specify a familiar location using the `outputPath` parameter\n- Best practice: Ask Claude to save images to an easily accessible folder like your Pictures or Downloads directory\n\n### Unique Filenames\n\nThe MCP server ensures that generated images always have unique filenames and will never overwrite existing files:\n\n1. **Default filenames** include:\n   - A sanitized version of the prompt (first 20 characters)\n   - A timestamp\n   - A random suffix\n\n2. **Custom filenames** are also protected:\n   - If you specify a filename and a file with that name already exists, a numeric suffix will be added automatically\n   - For example: `sunset.png`, `sunset_1.png`, `sunset_2.png`, etc.\n\nThis means you can safely generate multiple images with the same prompt or filename without worrying about overwriting previous images.\n\n### Accessing Base64 Data\n\nEven when saving to a file, the base64-encoded image data is always returned and can be used for:\n\n- Embedding in web pages (`<img src=\"data:image/png;base64,...\" />`)\n- Passing to other services or APIs\n- Processing in memory without filesystem operations\n- Displaying in applications that support data URIs\n\n## For Developers\n\nIf you want to use the package in your own projects:\n\n```bash\n# Install as a dependency\nnpm install @pinkpixel/mcpollinations\n\n# Import in your code\nimport { generateImageUrl, generateImage, repsondText, respondAudio, listTextModels, listImageModels, listAudioVoices } from '@pinkpixel/mcpollinations';\n```\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "qhdrl12--mcp-server-gemini-image-generator": {
      "owner": "qhdrl12",
      "name": "mcp-server-gemini-image-generator",
      "url": "https://github.com/qhdrl12/mcp-server-gemini-image-generator",
      "imageUrl": "https://github.com/qhdrl12.png",
      "description": "Generate high-quality images from text prompts using the Gemini AI model, manage local image storage, and facilitate creative modifications of existing images.",
      "stars": 23,
      "forks": 17,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-25T16:39:30Z",
      "readme_content": "[![MseeP Badge](https://mseep.net/pr/qhdrl12-mcp-server-gemini-image-generator-badge.jpg)](https://mseep.ai/app/qhdrl12-mcp-server-gemini-image-generator)\n[![smithery badge](https://smithery.ai/badge/@qhdrl12/mcp-server-gemini-image-gen)](https://smithery.ai/server/@qhdrl12/mcp-server-gemini-image-gen)\n\n<a href=\"https://glama.ai/mcp/servers/@qhdrl12/mcp-server-gemini-image-generator\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@qhdrl12/mcp-server-gemini-image-generator/badge\" alt=\"Gemini Image Generator Server MCP server\" />\n</a>\n\n# Gemini Image Generator MCP Server\n\nGenerate high-quality images from text prompts using Google's Gemini model through the MCP protocol.\n\n## Overview\n\nThis MCP server allows any AI assistant to generate images using Google's Gemini AI model. The server handles prompt engineering, text-to-image conversion, filename generation, and local image storage, making it easy to create and manage AI-generated images through any MCP client.\n\n## Features\n\n- Text-to-image generation using Gemini 2.0 Flash\n- Image-to-image transformation based on text prompts\n- Support for both file-based and base64-encoded images\n- Automatic intelligent filename generation based on prompts\n- Automatic translation of non-English prompts\n- Local image storage with configurable output path\n- Strict text exclusion from generated images\n- High-resolution image output\n- Direct access to both image data and file path\n\n## Available MCP Tools\n\nThe server provides the following MCP tools for AI assistants:\n\n### 1. `generate_image_from_text`\n\nCreates a new image from a text prompt description.\n\n```\ngenerate_image_from_text(prompt: str) -> Tuple[bytes, str]\n```\n\n**Parameters:**\n- `prompt`: Text description of the image you want to generate\n\n**Returns:**\n- A tuple containing:\n  - Raw image data (bytes)\n  - Path to the saved image file (str)\n\nThis dual return format allows AI assistants to either work with the image data directly or reference the saved file path.\n\n**Examples:**\n- \"Generate an image of a sunset over mountains\"\n- \"Create a photorealistic flying pig in a sci-fi city\"\n\n#### Example Output\n\nThis image was generated using the prompt:\n\n```\n\"Hi, can you create a 3d rendered image of a pig with wings and a top hat flying over a happy futuristic scifi city with lots of greenery?\"\n```\n\n![Flying pig over sci-fi city](examples/flying_pig_scifi_city.png)\n\n*A 3D rendered pig with wings and a top hat flying over a futuristic sci-fi city filled with greenery*\n\n### Known Issues\n\nWhen using this MCP server with Claude Desktop Host:\n\n1. **Performance Issues**: Using `transform_image_from_encoded` may take significantly longer to process compared to other methods. This is due to the overhead of transferring large base64-encoded image data through the MCP protocol.\n\n2. **Path Resolution Problems**: There may be issues with correctly resolving image paths when using Claude Desktop Host. The host application might not properly interpret the returned file paths, making it difficult to access the generated images.\n\nFor the best experience, consider using alternative MCP clients or the `transform_image_from_file` method when possible. \n\n### 2. `transform_image_from_encoded`\n\nTransforms an existing image based on a text prompt using base64-encoded image data.\n\n```\ntransform_image_from_encoded(encoded_image: str, prompt: str) -> Tuple[bytes, str]\n```\n\n**Parameters:**\n- `encoded_image`: Base64 encoded image data with format header (must be in format: \"data:image/[format];base64,[data]\")\n- `prompt`: Text description of how you want to transform the image\n\n**Returns:**\n- A tuple containing:\n  - Raw transformed image data (bytes)\n  - Path to the saved transformed image file (str)\n\n**Example:**\n- \"Add snow to this landscape\"\n- \"Change the background to a beach\"\n\n### 3. `transform_image_from_file`\n\nTransforms an existing image file based on a text prompt.\n\n```\ntransform_image_from_file(image_file_path: str, prompt: str) -> Tuple[bytes, str]\n```\n\n**Parameters:**\n- `image_file_path`: Path to the image file to be transformed\n- `prompt`: Text description of how you want to transform the image\n\n**Returns:**\n- A tuple containing:\n  - Raw transformed image data (bytes)\n  - Path to the saved transformed image file (str)\n\n**Examples:**\n- \"Add a llama next to the person in this image\"\n- \"Make this daytime scene look like night time\"\n\n#### Example Transformation\n\nUsing the flying pig image created above, we applied a transformation with the following prompt:\n\n```\n\"Add a cute baby whale flying alongside the pig\"\n```\n\n**Before:**\n![Flying pig over sci-fi city](examples/flying_pig_scifi_city.png)\n\n**After:**\n![Flying pig with baby whale](examples/pig_cute_baby_whale.png)\n\n*The original flying pig image with a cute baby whale added flying alongside it*\n\n## Setup\n\n### Prerequisites\n\n- Python 3.11+\n- Google AI API key (Gemini)\n- MCP host application (Claude Desktop App, Cursor, or other MCP-compatible clients)\n\n### Getting a Gemini API Key\n\n1. Visit [Google AI Studio API Keys page](https://aistudio.google.com/apikey)\n2. Sign in with your Google account\n3. Click \"Create API Key\"\n4. Copy your new API key for use in the configuration\n5. Note: The API key provides a certain quota of free usage per month. You can check your usage in the Google AI Studio\n\n### Installation\n\n### Installing via Smithery\n\nTo install Gemini Image Generator MCP for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@qhdrl12/mcp-server-gemini-image-gen):\n\n```bash\nnpx -y @smithery/cli install @qhdrl12/mcp-server-gemini-image-gen --client claude\n```\n\n### Manual Installation\n1. Clone the repository:\n```bash\ngit clone https://github.com/your-username/mcp-server-gemini-image-generator.git\ncd mcp-server-gemini-image-generator\n```\n\n2. Create a virtual environment and install dependencies:\n```bash\n# Using uv (recommended)\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv pip install -e .\n\n# Or using regular venv\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\npip install -e .\n```\n\n3. Set up environment variables (choose one method):\n\n**Method A: Using .env file (optional)**\n```bash\n# Create .env file in the project root\ncat > .env << 'EOF'\nGEMINI_API_KEY=your-gemini-api-key-here\nOUTPUT_IMAGE_PATH=/path/to/save/images\nEOF\n```\n\n**Method B: Set directly in Claude Desktop config (recommended)**\n- Set environment variables directly in the `claude_desktop_config.json` (shown in configuration section below)\n\n### Configure Claude Desktop\n\nAdd the following to your `claude_desktop_config.json`:\n\n- **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n```json\n{\n    \"mcpServers\": {\n        \"gemini-image-generator\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/absolute/path/to/mcp-server-gemini-image-generator\",\n                \"run\",\n                \"mcp-server-gemini-image-generator\"\n            ],\n            \"env\": {\n                \"GEMINI_API_KEY\": \"your-actual-gemini-api-key-here\",\n                \"OUTPUT_IMAGE_PATH\": \"/absolute/path/to/your/images/directory\"\n            }\n        }\n    }\n}\n```\n\n**Important Configuration Notes:**\n\n1. **Replace paths with your actual paths:**\n   - Change `/absolute/path/to/mcp-server-gemini-image-generator` to the actual location where you cloned this repository\n   - Change `/absolute/path/to/your/images/directory` to where you want generated images to be saved\n\n2. **Environment Variables:**\n   - Replace `your-actual-gemini-api-key-here` with your real Gemini API key from Google AI Studio\n   - Use absolute paths for `OUTPUT_IMAGE_PATH` to ensure images are saved correctly\n\n3. **Example with real paths:**\n```json\n{\n    \"mcpServers\": {\n        \"gemini-image-generator\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/Users/username/Projects/mcp-server-gemini-image-generator\",\n                \"run\",\n                \"mcp-server-gemini-image-generator\"\n            ],\n            \"env\": {\n                \"GEMINI_API_KEY\": \"GEMINI_API_KEY\",\n                \"OUTPUT_IMAGE_PATH\": \"OUTPUT_IMAGE_PATH\"\n            }\n        }\n    }\n}\n```\n\n## Usage\n\nOnce installed and configured, you can ask Claude to generate or transform images using prompts like:\n\n### Generating New Images\n- \"Generate an image of a sunset over mountains\"\n- \"Create an illustration of a futuristic cityscape\"\n- \"Make a picture of a cat wearing sunglasses\"\n\n### Transforming Existing Images\n- \"Transform this image by adding snow to the scene\"\n- \"Edit this photo to make it look like it was taken at night\"\n- \"Add a dragon flying in the background of this picture\"\n\nThe generated/transformed images will be saved to your configured output path and displayed in Claude. With the updated return types, AI assistants can also work directly with the image data without needing to access the saved files.\n\n## Testing\n\nYou can test the application by running the FastMCP development server:\n\n```\nfastmcp dev server.py\n```\n\nThis command starts a local development server and makes the MCP Inspector available at http://localhost:5173/. \nThe MCP Inspector provides a convenient web interface where you can directly test the image generation tool without needing to use Claude or another MCP client. \nYou can enter text prompts, execute the tool, and see the results immediately, which is helpful for development and debugging.\n\n## License\n\nMIT License",
      "npm_url": "",
      "npm_downloads": 0
    },
    "qpd-v--mcp-image-downloader": {
      "owner": "qpd-v",
      "name": "mcp-image-downloader",
      "url": "https://github.com/qpd-v/mcp-image-downloader",
      "imageUrl": "https://github.com/qpd-v.png",
      "description": "Provides tools for downloading images from URLs and performing basic image optimization tasks such as resizing, quality adjustment, and format conversion.",
      "stars": 11,
      "forks": 5,
      "license": "Apache License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:32:03Z",
      "readme_content": "# MCP Image Downloader\n\nAn MCP server that provides tools for downloading and optimizing images. Built using the Model Context Protocol (MCP), this server enables AI assistants to download images from URLs and perform basic image optimization tasks.\n\n## Features\n\n- Download images from URLs with proper error handling\n- Optimize images with options for:\n  - Resizing (maintaining aspect ratio)\n  - Quality adjustment (JPEG/WebP)\n  - Format conversion\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/qpd-v/mcp-image-downloader.git\ncd mcp-image-downloader\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Usage\n\n### As an MCP Server\n\nAdd the server to your MCP configuration (e.g., in Claude Desktop's config):\n\n```json\n{\n  \"mcpServers\": {\n    \"image-downloader\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-image-downloader/build/index.js\"]\n    }\n  }\n}\n```\n\n### Available Tools\n\n#### download_image\nDownloads an image from a URL to a specified path.\n\nParameters:\n- `url`: URL of the image to download\n- `outputPath`: Path where to save the image\n\n#### optimize_image\nCreates an optimized version of an image.\n\nParameters:\n- `inputPath`: Path to the input image\n- `outputPath`: Path where to save the optimized image\n- `width` (optional): Target width (maintains aspect ratio if only width is specified)\n- `height` (optional): Target height (maintains aspect ratio if only height is specified)\n- `quality` (optional): JPEG/WebP quality (1-100)\n\n## Development\n\n```bash\n# Run in development mode\nnpm run start\n\n# Build the project\nnpm run build\n```\n\n## Requirements\n\n- Node.js 16 or higher\n- NPM or compatible package manager\n\n## License\n\nMIT License - see the [LICENSE](LICENSE) file for details.\n\n## Author\n\nqpd-v\n\n## Version\n\n0.1.0 - Initial release",
      "npm_url": "",
      "npm_downloads": 0
    },
    "rmcendarfer2017--MCP-image-gen": {
      "owner": "rmcendarfer2017",
      "name": "MCP-image-gen",
      "url": "https://github.com/rmcendarfer2017/MCP-image-gen",
      "imageUrl": "https://github.com/rmcendarfer2017.png",
      "description": "Generate stunning images using advanced AI models with a built-in storage system for managing and accessing creations. Users can customize image styles and utilize a prompt-based interface for generating images.",
      "stars": 0,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-03-08T16:13:41Z",
      "readme_content": "# Image Generator MCP Server\n\nAn MCP server that uses Replicate to generate images and allows users to save them.\n\n## Components\n\n### Resources\n\nThe server implements an image storage system with:\n- Custom image:// URI scheme for accessing individual generated images\n- Each image resource has a name based on its prompt, description with creation date, and image/png mimetype\n\n### Prompts\n\nThe server provides a single prompt:\n- generate-image: Creates prompts for generating images using Stable Diffusion\n  - Optional \"style\" argument to control the image style (realistic/artistic/abstract)\n  - Generates a prompt template with style-specific guidance\n\n### Tools\n\nThe server implements three tools:\n- generate-image: Generates an image using Replicate's Stable Diffusion model\n  - Takes \"prompt\" as a required string argument\n  - Optional parameters include \"negative_prompt\", \"width\", \"height\", \"num_inference_steps\", and \"guidance_scale\"\n  - Returns the generated image and its URL\n- save-image: Saves a generated image to the local filesystem\n  - Takes \"image_url\" and \"prompt\" as required string arguments\n  - Generates a unique ID for the image and saves it to the \"generated_images\" directory\n- list-saved-images: Lists all saved images\n  - Returns a list of all saved images with their metadata and thumbnails\n\n## Configuration\n\n### Replicate API Token\n\nTo use this image generator, you need a Replicate API token:\n\n1. Create an account at [Replicate](https://replicate.com/)\n2. Get your API token from [https://replicate.com/account](https://replicate.com/account)\n3. Create a `.env` file based on the provided `.env.example` template:\n\n```\nREPLICATE_API_TOKEN=your_replicate_api_token_here\n```\n\n> **Important:** The `.env` file is excluded from version control via `.gitignore` to prevent accidentally exposing your API token. Never commit sensitive information to your repository.\n\n### Environment Setup\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/yourusername/image-generator.git\ncd image-generator\n```\n\n2. Create and activate a virtual environment:\n```bash\n# Using venv\npython -m venv .venv\n# On Windows\n.venv\\Scripts\\activate\n# On macOS/Linux\nsource .venv/bin/activate\n```\n\n3. Install dependencies:\n```bash\npip install -r requirements.txt\n```\n\n4. Set up your `.env` file as described above\n\n## Quickstart\n\n### Install\n\n#### Claude Desktop\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n<details>\n  <summary>Development/Unpublished Servers Configuration</summary>\n  ```\n  \"mcpServers\": {\n    \"image-generator\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"B:\\NEWTEST\\image-generator\",\n        \"run\",\n        \"image-generator\"\n      ]\n    }\n  }\n  ```\n</details>\n\n<details>\n  <summary>Published Servers Configuration</summary>\n  ```\n  \"mcpServers\": {\n    \"image-generator\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"image-generator\"\n      ]\n    }\n  }\n  ```\n</details>\n\n### Usage\n\nOnce the server is running, you can:\n\n1. Generate an image by using the \"generate-image\" tool with a descriptive prompt\n2. Save the generated image using the \"save-image\" tool with the image URL and prompt\n3. View all saved images using the \"list-saved-images\" tool\n4. Access saved images through the resource list\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory B:\\NEWTEST\\image-generator run image-generator\n```\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.",
      "npm_url": "",
      "npm_downloads": 0
    },
    "rsagacom--chatgpt-on-wechat": {
      "owner": "rsagacom",
      "name": "chatgpt-on-wechat",
      "url": "https://github.com/rsagacom/chatgpt-on-wechat",
      "imageUrl": "https://github.com/rsagacom.png",
      "description": "A multi-platform intelligent dialogue service that supports text, voice, and image interactions. It can connect to various AI models and allows for custom enterprise AI applications through plugin extensions.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2024-01-28T14:00:49Z",
      "readme_content": "# ç®€ä»‹\n\n> æœ¬é¡¹ç›®æ˜¯åŸºäºå¤§æ¨¡å‹çš„æ™ºèƒ½å¯¹è¯æœºå™¨äººï¼Œæ”¯æŒå¾®ä¿¡ã€ä¼ä¸šå¾®ä¿¡ã€å…¬ä¼—å·ã€é£ä¹¦ã€é’‰é’‰æ¥å…¥ï¼Œå¯é€‰æ‹©GPT3.5/GPT4.0/Claude/æ–‡å¿ƒä¸€è¨€/è®¯é£æ˜Ÿç«/é€šä¹‰åƒé—®/Gemini/LinkAIï¼Œèƒ½å¤„ç†æ–‡æœ¬ã€è¯­éŸ³å’Œå›¾ç‰‡ï¼Œé€šè¿‡æ’ä»¶è®¿é—®æ“ä½œç³»ç»Ÿå’Œäº’è”ç½‘ç­‰å¤–éƒ¨èµ„æºï¼Œæ”¯æŒåŸºäºè‡ªæœ‰çŸ¥è¯†åº“å®šåˆ¶ä¼ä¸šAIåº”ç”¨ã€‚\n\næœ€æ–°ç‰ˆæœ¬æ”¯æŒçš„åŠŸèƒ½å¦‚ä¸‹ï¼š\n\n- [x] **å¤šç«¯éƒ¨ç½²ï¼š** æœ‰å¤šç§éƒ¨ç½²æ–¹å¼å¯é€‰æ‹©ä¸”åŠŸèƒ½å®Œå¤‡ï¼Œç›®å‰å·²æ”¯æŒä¸ªäººå¾®ä¿¡ã€å¾®ä¿¡å…¬ä¼—å·å’Œã€ä¼ä¸šå¾®ä¿¡ã€é£ä¹¦ã€é’‰é’‰ç­‰éƒ¨ç½²æ–¹å¼\n- [x] **åŸºç¡€å¯¹è¯ï¼š** ç§èŠåŠç¾¤èŠçš„æ¶ˆæ¯æ™ºèƒ½å›å¤ï¼Œæ”¯æŒå¤šè½®ä¼šè¯ä¸Šä¸‹æ–‡è®°å¿†ï¼Œæ”¯æŒ GPT-3.5, GPT-4, claude, Gemini, æ–‡å¿ƒä¸€è¨€, è®¯é£æ˜Ÿç«, é€šä¹‰åƒé—®\n- [x] **è¯­éŸ³èƒ½åŠ›ï¼š** å¯è¯†åˆ«è¯­éŸ³æ¶ˆæ¯ï¼Œé€šè¿‡æ–‡å­—æˆ–è¯­éŸ³å›å¤ï¼Œæ”¯æŒ azure, baidu, google, openai(whisper/tts) ç­‰å¤šç§è¯­éŸ³æ¨¡å‹\n- [x] **å›¾åƒèƒ½åŠ›ï¼š** æ”¯æŒå›¾ç‰‡ç”Ÿæˆã€å›¾ç‰‡è¯†åˆ«ã€å›¾ç”Ÿå›¾ï¼ˆå¦‚ç…§ç‰‡ä¿®å¤ï¼‰ï¼Œå¯é€‰æ‹© Dall-E-3, stable diffusion, replicate, midjourney, visionæ¨¡å‹\n- [x] **ä¸°å¯Œæ’ä»¶ï¼š** æ”¯æŒä¸ªæ€§åŒ–æ’ä»¶æ‰©å±•ï¼Œå·²å®ç°å¤šè§’è‰²åˆ‡æ¢ã€æ–‡å­—å†’é™©ã€æ•æ„Ÿè¯è¿‡æ»¤ã€èŠå¤©è®°å½•æ€»ç»“ã€æ–‡æ¡£æ€»ç»“å’Œå¯¹è¯ã€è”ç½‘æœç´¢ç­‰æ’ä»¶\n- [x] **çŸ¥è¯†åº“ï¼š** é€šè¿‡ä¸Šä¼ çŸ¥è¯†åº“æ–‡ä»¶è‡ªå®šä¹‰ä¸“å±æœºå™¨äººï¼Œå¯ä½œä¸ºæ•°å­—åˆ†èº«ã€æ™ºèƒ½å®¢æœã€ç§åŸŸåŠ©æ‰‹ä½¿ç”¨ï¼ŒåŸºäº [LinkAI](https://link-ai.tech) å®ç°\n\n# æ¼”ç¤º\n\nhttps://github.com/zhayujie/chatgpt-on-wechat/assets/26161723/d5154020-36e3-41db-8706-40ce9f3f1b1e\n\nDemo made by [Visionn](https://www.wangpc.cc/)\n\n# å•†ä¸šæ”¯æŒ\n\n> æˆ‘ä»¬è¿˜æä¾›ä¼ä¸šçº§çš„ **AIåº”ç”¨å¹³å°**ï¼ŒåŒ…å«çŸ¥è¯†åº“ã€Agentæ’ä»¶ã€åº”ç”¨ç®¡ç†ç­‰èƒ½åŠ›ï¼Œæ”¯æŒå¤šå¹³å°èšåˆçš„åº”ç”¨æ¥å…¥ã€å®¢æˆ·ç«¯ç®¡ç†ã€å¯¹è¯ç®¡ç†ï¼Œä»¥åŠæä¾›\nSaaSæœåŠ¡ã€ç§æœ‰åŒ–éƒ¨ç½²ã€ç¨³å®šæ‰˜ç®¡æ¥å…¥ ç­‰å¤šç§æ¨¡å¼ã€‚\n>\n> ç›®å‰å·²åœ¨ç§åŸŸè¿è¥ã€æ™ºèƒ½å®¢æœã€ä¼ä¸šæ•ˆç‡åŠ©æ‰‹ç­‰åœºæ™¯ç§¯ç´¯äº†ä¸°å¯Œçš„ AI è§£å†³æ–¹æ¡ˆï¼Œ åœ¨ç”µå•†ã€æ–‡æ•™ã€å¥åº·ã€æ–°æ¶ˆè´¹ç­‰å„è¡Œä¸šæ²‰æ·€äº† AI è½åœ°çš„æœ€ä½³å®è·µï¼Œè‡´åŠ›äºæ‰“é€ åŠ©åŠ›ä¸­å°ä¼ä¸šæ‹¥æŠ± AI çš„ä¸€ç«™å¼å¹³å°ã€‚\n\nä¼ä¸šæœåŠ¡å’Œå•†ç”¨å’¨è¯¢å¯è”ç³»äº§å“é¡¾é—®ï¼š\n\n<img width=\"240\" src=\"https://img-1317903499.cos.ap-guangzhou.myqcloud.com/docs/product-manager-qrcode.jpg\">\n\n# å¼€æºç¤¾åŒº\n\næ·»åŠ å°åŠ©æ‰‹å¾®ä¿¡åŠ å…¥å¼€æºé¡¹ç›®äº¤æµç¾¤ï¼š\n\n<img width=\"240\" src=\"./docs/images/contact.jpg\">\n\n# æ›´æ–°æ—¥å¿—\n\n>**2023.11.11ï¼š** [1.5.3ç‰ˆæœ¬](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.3) å’Œ [1.5.4ç‰ˆæœ¬](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.4)ï¼Œæ–°å¢Google Geminiã€é€šä¹‰åƒé—®æ¨¡å‹\n\n>**2023.11.10ï¼š** [1.5.2ç‰ˆæœ¬](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.2)ï¼Œæ–°å¢é£ä¹¦é€šé“ã€å›¾åƒè¯†åˆ«å¯¹è¯ã€é»‘åå•é…ç½®\n\n>**2023.11.10ï¼š** [1.5.0ç‰ˆæœ¬](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.0)ï¼Œæ–°å¢ `gpt-4-turbo`, `dall-e-3`, `tts` æ¨¡å‹æ¥å…¥ï¼Œå®Œå–„å›¾åƒç†è§£&ç”Ÿæˆã€è¯­éŸ³è¯†åˆ«&ç”Ÿæˆçš„å¤šæ¨¡æ€èƒ½åŠ›\n\n>**2023.10.16ï¼š** æ”¯æŒé€šè¿‡æ„å›¾è¯†åˆ«ä½¿ç”¨LinkAIè”ç½‘æœç´¢ã€æ•°å­¦è®¡ç®—ã€ç½‘é¡µè®¿é—®ç­‰æ’ä»¶ï¼Œå‚è€ƒ[æ’ä»¶æ–‡æ¡£](https://docs.link-ai.tech/platform/plugins)\n\n>**2023.09.26ï¼š** æ’ä»¶å¢åŠ  æ–‡ä»¶/æ–‡ç« é“¾æ¥ ä¸€é”®æ€»ç»“å’Œå¯¹è¯çš„åŠŸèƒ½ï¼Œä½¿ç”¨å‚è€ƒï¼š[æ’ä»¶è¯´æ˜](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins/linkai#3%E6%96%87%E6%A1%A3%E6%80%BB%E7%BB%93%E5%AF%B9%E8%AF%9D%E5%8A%9F%E8%83%BD)\n\n>**2023.08.08ï¼š** æ¥å…¥ç™¾åº¦æ–‡å¿ƒä¸€è¨€æ¨¡å‹ï¼Œé€šè¿‡ [æ’ä»¶](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins/linkai) æ”¯æŒ Midjourney ç»˜å›¾\n\n>**2023.06.12ï¼š** æ¥å…¥ [LinkAI](https://link-ai.tech/console) å¹³å°ï¼Œå¯åœ¨çº¿åˆ›å»ºé¢†åŸŸçŸ¥è¯†åº“ï¼Œå¹¶æ¥å…¥å¾®ä¿¡ã€å…¬ä¼—å·åŠä¼ä¸šå¾®ä¿¡ä¸­ï¼Œæ‰“é€ ä¸“å±å®¢æœæœºå™¨äººã€‚ä½¿ç”¨å‚è€ƒ [æ¥å…¥æ–‡æ¡£](https://link-ai.tech/platform/link-app/wechat)ã€‚\n\n>**2023.04.26ï¼š** æ”¯æŒä¼ä¸šå¾®ä¿¡åº”ç”¨å·éƒ¨ç½²ï¼Œå…¼å®¹æ’ä»¶ï¼Œå¹¶æ”¯æŒè¯­éŸ³å›¾ç‰‡äº¤äº’ï¼Œç§äººåŠ©ç†ç†æƒ³é€‰æ‹©ï¼Œ[ä½¿ç”¨æ–‡æ¡£](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/wechatcom/README.md)ã€‚(contributed by [@lanvent](https://github.com/lanvent) in [#944](https://github.com/zhayujie/chatgpt-on-wechat/pull/944))\n\n>**2023.04.05ï¼š** æ”¯æŒå¾®ä¿¡å…¬ä¼—å·éƒ¨ç½²ï¼Œå…¼å®¹æ’ä»¶ï¼Œå¹¶æ”¯æŒè¯­éŸ³å›¾ç‰‡äº¤äº’ï¼Œ[ä½¿ç”¨æ–‡æ¡£](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/wechatmp/README.md)ã€‚(contributed by [@JS00000](https://github.com/JS00000) in [#686](https://github.com/zhayujie/chatgpt-on-wechat/pull/686))\n\n>**2023.04.05ï¼š** å¢åŠ èƒ½è®©ChatGPTä½¿ç”¨å·¥å…·çš„`tool`æ’ä»¶ï¼Œ[ä½¿ç”¨æ–‡æ¡£](https://github.com/goldfishh/chatgpt-on-wechat/blob/master/plugins/tool/README.md)ã€‚å·¥å…·ç›¸å…³issueå¯åé¦ˆè‡³[chatgpt-tool-hub](https://github.com/goldfishh/chatgpt-tool-hub)ã€‚(contributed by [@goldfishh](https://github.com/goldfishh) in [#663](https://github.com/zhayujie/chatgpt-on-wechat/pull/663))\n\n>**2023.03.25ï¼š** æ”¯æŒæ’ä»¶åŒ–å¼€å‘ï¼Œç›®å‰å·²å®ç° å¤šè§’è‰²åˆ‡æ¢ã€æ–‡å­—å†’é™©æ¸¸æˆã€ç®¡ç†å‘˜æŒ‡ä»¤ã€Stable Diffusionç­‰æ’ä»¶ï¼Œä½¿ç”¨å‚è€ƒ [#578](https://github.com/zhayujie/chatgpt-on-wechat/issues/578)ã€‚(contributed by [@lanvent](https://github.com/lanvent) in [#565](https://github.com/zhayujie/chatgpt-on-wechat/pull/565))\n\n>**2023.03.09ï¼š** åŸºäº `whisper API`(åç»­å·²æ¥å…¥æ›´å¤šçš„è¯­éŸ³`API`æœåŠ¡) å®ç°å¯¹å¾®ä¿¡è¯­éŸ³æ¶ˆæ¯çš„è§£æå’Œå›å¤ï¼Œæ·»åŠ é…ç½®é¡¹ `\"speech_recognition\":true` å³å¯å¯ç”¨ï¼Œä½¿ç”¨å‚è€ƒ [#415](https://github.com/zhayujie/chatgpt-on-wechat/issues/415)ã€‚(contributed by [wanggang1987](https://github.com/wanggang1987) in [#385](https://github.com/zhayujie/chatgpt-on-wechat/pull/385))\n\n>**2023.02.09ï¼š** æ‰«ç ç™»å½•å­˜åœ¨è´¦å·é™åˆ¶é£é™©ï¼Œè¯·è°¨æ…ä½¿ç”¨ï¼Œå‚è€ƒ[#58](https://github.com/AutumnWhj/ChatGPT-wechat-bot/issues/158)\n\n# å¿«é€Ÿå¼€å§‹\n\nå¿«é€Ÿå¼€å§‹æ–‡æ¡£ï¼š[é¡¹ç›®æ­å»ºæ–‡æ¡£](https://docs.link-ai.tech/cow/quick-start)\n\n## å‡†å¤‡\n\n### 1. è´¦å·æ³¨å†Œ\n\né¡¹ç›®é»˜è®¤ä½¿ç”¨OpenAIæ¥å£ï¼Œéœ€å‰å¾€ [OpenAIæ³¨å†Œé¡µé¢](https://beta.openai.com/signup) åˆ›å»ºè´¦å·ï¼Œåˆ›å»ºå®Œè´¦å·åˆ™å‰å¾€ [APIç®¡ç†é¡µé¢](https://beta.openai.com/account/api-keys) åˆ›å»ºä¸€ä¸ª API Key å¹¶ä¿å­˜ä¸‹æ¥ï¼Œåé¢éœ€è¦åœ¨é¡¹ç›®ä¸­é…ç½®è¿™ä¸ªkeyã€‚æ¥å£éœ€è¦æµ·å¤–ç½‘ç»œè®¿é—®åŠç»‘å®šä¿¡ç”¨å¡æ”¯ä»˜ã€‚\n\n> é»˜è®¤å¯¹è¯æ¨¡å‹æ˜¯ openai çš„ gpt-3.5-turboï¼Œè®¡è´¹æ–¹å¼æ˜¯çº¦æ¯ 1000tokens (çº¦750ä¸ªè‹±æ–‡å•è¯ æˆ– 500æ±‰å­—ï¼ŒåŒ…å«è¯·æ±‚å’Œå›å¤) æ¶ˆè€— $0.002ï¼Œå›¾ç‰‡ç”Ÿæˆæ˜¯Dell Eæ¨¡å‹ï¼Œæ¯å¼ æ¶ˆè€— $0.016ã€‚\n\né¡¹ç›®åŒæ—¶ä¹Ÿæ”¯æŒä½¿ç”¨ LinkAI æ¥å£ï¼Œæ— éœ€ä»£ç†ï¼Œå¯ä½¿ç”¨ æ–‡å¿ƒã€è®¯é£ã€GPT-3ã€GPT-4 ç­‰æ¨¡å‹ï¼Œæ”¯æŒ å®šåˆ¶åŒ–çŸ¥è¯†åº“ã€è”ç½‘æœç´¢ã€MJç»˜å›¾ã€æ–‡æ¡£æ€»ç»“å’Œå¯¹è¯ç­‰èƒ½åŠ›ã€‚ä¿®æ”¹é…ç½®å³å¯ä¸€é”®åˆ‡æ¢ï¼Œå‚è€ƒ [æ¥å…¥æ–‡æ¡£](https://link-ai.tech/platform/link-app/wechat)ã€‚\n\n### 2.è¿è¡Œç¯å¢ƒ\n\næ”¯æŒ Linuxã€MacOSã€Windows ç³»ç»Ÿï¼ˆå¯åœ¨LinuxæœåŠ¡å™¨ä¸Šé•¿æœŸè¿è¡Œ)ï¼ŒåŒæ—¶éœ€å®‰è£… `Python`ã€‚\n> å»ºè®®Pythonç‰ˆæœ¬åœ¨ 3.7.1~3.9.X ä¹‹é—´ï¼Œæ¨è3.8ç‰ˆæœ¬ï¼Œ3.10åŠä»¥ä¸Šç‰ˆæœ¬åœ¨ MacOS å¯ç”¨ï¼Œå…¶ä»–ç³»ç»Ÿä¸Šä¸ç¡®å®šèƒ½å¦æ­£å¸¸è¿è¡Œã€‚\n\n> æ³¨æ„ï¼šDocker æˆ– Railway éƒ¨ç½²æ— éœ€å®‰è£…pythonç¯å¢ƒå’Œä¸‹è½½æºç ï¼Œå¯ç›´æ¥å¿«è¿›åˆ°ä¸‹ä¸€èŠ‚ã€‚\n\n**(1) å…‹éš†é¡¹ç›®ä»£ç ï¼š**\n\n```bash\ngit clone https://github.com/zhayujie/chatgpt-on-wechat\ncd chatgpt-on-wechat/\n```\n\næ³¨: å¦‚é‡åˆ°ç½‘ç»œé—®é¢˜å¯é€‰æ‹©å›½å†…é•œåƒ https://gitee.com/zhayujie/chatgpt-on-wechat\n\n**(2) å®‰è£…æ ¸å¿ƒä¾èµ– (å¿…é€‰)ï¼š**\n> èƒ½å¤Ÿä½¿ç”¨`itchat`åˆ›å»ºæœºå™¨äººï¼Œå¹¶å…·æœ‰æ–‡å­—äº¤æµåŠŸèƒ½æ‰€éœ€çš„æœ€å°ä¾èµ–é›†åˆã€‚\n```bash\npip3 install -r requirements.txt\n```\n\n**(3) æ‹“å±•ä¾èµ– (å¯é€‰ï¼Œå»ºè®®å®‰è£…)ï¼š**\n\n```bash\npip3 install -r requirements-optional.txt\n```\n> å¦‚æœæŸé¡¹ä¾èµ–å®‰è£…å¤±è´¥å¯æ³¨é‡Šæ‰å¯¹åº”çš„è¡Œå†ç»§ç»­\n\n## é…ç½®\n\né…ç½®æ–‡ä»¶çš„æ¨¡æ¿åœ¨æ ¹ç›®å½•çš„`config-template.json`ä¸­ï¼Œéœ€å¤åˆ¶è¯¥æ¨¡æ¿åˆ›å»ºæœ€ç»ˆç”Ÿæ•ˆçš„ `config.json` æ–‡ä»¶ï¼š\n\n```bash\n  cp config-template.json config.json\n```\n\nç„¶ååœ¨`config.json`ä¸­å¡«å…¥é…ç½®ï¼Œä»¥ä¸‹æ˜¯å¯¹é»˜è®¤é…ç½®çš„è¯´æ˜ï¼Œå¯æ ¹æ®éœ€è¦è¿›è¡Œè‡ªå®šä¹‰ä¿®æ”¹ï¼ˆè¯·å»æ‰æ³¨é‡Šï¼‰ï¼š\n\n```bash\n# config.jsonæ–‡ä»¶å†…å®¹ç¤ºä¾‹\n{\n  \"open_ai_api_key\": \"YOUR API KEY\",                          # å¡«å…¥ä¸Šé¢åˆ›å»ºçš„ OpenAI API KEY\n  \"model\": \"gpt-3.5-turbo\",                                   # æ¨¡å‹åç§°, æ”¯æŒ gpt-3.5-turbo, gpt-3.5-turbo-16k, gpt-4, wenxin, xunfei\n  \"proxy\": \"\",                                                # ä»£ç†å®¢æˆ·ç«¯çš„ipå’Œç«¯å£ï¼Œå›½å†…ç¯å¢ƒå¼€å¯ä»£ç†çš„éœ€è¦å¡«å†™è¯¥é¡¹ï¼Œå¦‚ \"127.0.0.1:7890\"\n  \"single_chat_prefix\": [\"bot\", \"@bot\"],                      # ç§èŠæ—¶æ–‡æœ¬éœ€è¦åŒ…å«è¯¥å‰ç¼€æ‰èƒ½è§¦å‘æœºå™¨äººå›å¤\n  \"single_chat_reply_prefix\": \"[bot] \",                       # ç§èŠæ—¶è‡ªåŠ¨å›å¤çš„å‰ç¼€ï¼Œç”¨äºåŒºåˆ†çœŸäºº\n  \"group_chat_prefix\": [\"@bot\"],                              # ç¾¤èŠæ—¶åŒ…å«è¯¥å‰ç¼€åˆ™ä¼šè§¦å‘æœºå™¨äººå›å¤\n  \"group_name_white_list\": [\"ChatGPTæµ‹è¯•ç¾¤\", \"ChatGPTæµ‹è¯•ç¾¤2\"], # å¼€å¯è‡ªåŠ¨å›å¤çš„ç¾¤åç§°åˆ—è¡¨\n  \"group_chat_in_one_session\": [\"ChatGPTæµ‹è¯•ç¾¤\"],              # æ”¯æŒä¼šè¯ä¸Šä¸‹æ–‡å…±äº«çš„ç¾¤åç§°  \n  \"image_create_prefix\": [\"ç”»\", \"çœ‹\", \"æ‰¾\"],                   # å¼€å¯å›¾ç‰‡å›å¤çš„å‰ç¼€\n  \"conversation_max_tokens\": 1000,                            # æ”¯æŒä¸Šä¸‹æ–‡è®°å¿†çš„æœ€å¤šå­—ç¬¦æ•°\n  \"speech_recognition\": false,                                # æ˜¯å¦å¼€å¯è¯­éŸ³è¯†åˆ«\n  \"group_speech_recognition\": false,                          # æ˜¯å¦å¼€å¯ç¾¤ç»„è¯­éŸ³è¯†åˆ«\n  \"use_azure_chatgpt\": false,                                 # æ˜¯å¦ä½¿ç”¨Azure ChatGPT serviceä»£æ›¿openai ChatGPT service. å½“è®¾ç½®ä¸ºtrueæ—¶éœ€è¦è®¾ç½® open_ai_api_baseï¼Œå¦‚ https://xxx.openai.azure.com/\n  \"azure_deployment_id\": \"\",                                  # é‡‡ç”¨Azure ChatGPTæ—¶ï¼Œæ¨¡å‹éƒ¨ç½²åç§°\n  \"azure_api_version\": \"\",                                    # é‡‡ç”¨Azure ChatGPTæ—¶ï¼ŒAPIç‰ˆæœ¬\n  \"character_desc\": \"ä½ æ˜¯ChatGPT, ä¸€ä¸ªç”±OpenAIè®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹, ä½ æ—¨åœ¨å›ç­”å¹¶è§£å†³äººä»¬çš„ä»»ä½•é—®é¢˜ï¼Œå¹¶ä¸”å¯ä»¥ä½¿ç”¨å¤šç§è¯­è¨€ä¸äººäº¤æµã€‚\",  # äººæ ¼æè¿°\n  # è®¢é˜…æ¶ˆæ¯ï¼Œå…¬ä¼—å·å’Œä¼ä¸šå¾®ä¿¡channelä¸­è¯·å¡«å†™ï¼Œå½“è¢«è®¢é˜…æ—¶ä¼šè‡ªåŠ¨å›å¤ï¼Œå¯ä½¿ç”¨ç‰¹æ®Šå ä½ç¬¦ã€‚ç›®å‰æ”¯æŒçš„å ä½ç¬¦æœ‰{trigger_prefix}ï¼Œåœ¨ç¨‹åºä¸­å®ƒä¼šè‡ªåŠ¨æ›¿æ¢æˆbotçš„è§¦å‘è¯ã€‚\n  \"subscribe_msg\": \"æ„Ÿè°¢æ‚¨çš„å…³æ³¨ï¼\\nè¿™é‡Œæ˜¯ChatGPTï¼Œå¯ä»¥è‡ªç”±å¯¹è¯ã€‚\\næ”¯æŒè¯­éŸ³å¯¹è¯ã€‚\\næ”¯æŒå›¾ç‰‡è¾“å‡ºï¼Œç”»å­—å¼€å¤´çš„æ¶ˆæ¯å°†æŒ‰è¦æ±‚åˆ›ä½œå›¾ç‰‡ã€‚\\næ”¯æŒè§’è‰²æ‰®æ¼”å’Œæ–‡å­—å†’é™©ç­‰ä¸°å¯Œæ’ä»¶ã€‚\\nè¾“å…¥{trigger_prefix}#help æŸ¥çœ‹è¯¦ç»†æŒ‡ä»¤ã€‚\",\n  \"use_linkai\": false,                                        # æ˜¯å¦ä½¿ç”¨LinkAIæ¥å£ï¼Œé»˜è®¤å…³é—­ï¼Œå¼€å¯åå¯å›½å†…è®¿é—®ï¼Œä½¿ç”¨çŸ¥è¯†åº“å’ŒMJ\n  \"linkai_api_key\": \"\",                                       # LinkAI Api Key\n  \"linkai_app_code\": \"\"                                       # LinkAI åº”ç”¨code\n}\n```\n**é…ç½®è¯´æ˜ï¼š**\n\n**1.ä¸ªäººèŠå¤©**\n\n+ ä¸ªäººèŠå¤©ä¸­ï¼Œéœ€è¦ä»¥ \"bot\"æˆ–\"@bot\" ä¸ºå¼€å¤´çš„å†…å®¹è§¦å‘æœºå™¨äººï¼Œå¯¹åº”é…ç½®é¡¹ `single_chat_prefix` (å¦‚æœä¸éœ€è¦ä»¥å‰ç¼€è§¦å‘å¯ä»¥å¡«å†™  `\"single_chat_prefix\": [\"\"]`)\n+ æœºå™¨äººå›å¤çš„å†…å®¹ä¼šä»¥ \"[bot] \" ä½œä¸ºå‰ç¼€ï¼Œ ä»¥åŒºåˆ†çœŸäººï¼Œå¯¹åº”çš„é…ç½®é¡¹ä¸º `single_chat_reply_prefix` (å¦‚æœä¸éœ€è¦å‰ç¼€å¯ä»¥å¡«å†™ `\"single_chat_reply_prefix\": \"\"`)\n\n**2.ç¾¤ç»„èŠå¤©**\n\n+ ç¾¤ç»„èŠå¤©ä¸­ï¼Œç¾¤åç§°éœ€é…ç½®åœ¨ `group_name_white_list ` ä¸­æ‰èƒ½å¼€å¯ç¾¤èŠè‡ªåŠ¨å›å¤ã€‚å¦‚æœæƒ³å¯¹æ‰€æœ‰ç¾¤èŠç”Ÿæ•ˆï¼Œå¯ä»¥ç›´æ¥å¡«å†™ `\"group_name_white_list\": [\"ALL_GROUP\"]`\n+ é»˜è®¤åªè¦è¢«äºº @ å°±ä¼šè§¦å‘æœºå™¨äººè‡ªåŠ¨å›å¤ï¼›å¦å¤–ç¾¤èŠå¤©ä¸­åªè¦æ£€æµ‹åˆ°ä»¥ \"@bot\" å¼€å¤´çš„å†…å®¹ï¼ŒåŒæ ·ä¼šè‡ªåŠ¨å›å¤ï¼ˆæ–¹ä¾¿è‡ªå·±è§¦å‘ï¼‰ï¼Œè¿™å¯¹åº”é…ç½®é¡¹ `group_chat_prefix`\n+ å¯é€‰é…ç½®: `group_name_keyword_white_list`é…ç½®é¡¹æ”¯æŒæ¨¡ç³ŠåŒ¹é…ç¾¤åç§°ï¼Œ`group_chat_keyword`é…ç½®é¡¹åˆ™æ”¯æŒæ¨¡ç³ŠåŒ¹é…ç¾¤æ¶ˆæ¯å†…å®¹ï¼Œç”¨æ³•ä¸ä¸Šè¿°ä¸¤ä¸ªé…ç½®é¡¹ç›¸åŒã€‚ï¼ˆContributed by [evolay](https://github.com/evolay))\n+ `group_chat_in_one_session`ï¼šä½¿ç¾¤èŠå…±äº«ä¸€ä¸ªä¼šè¯ä¸Šä¸‹æ–‡ï¼Œé…ç½® `[\"ALL_GROUP\"]` åˆ™ä½œç”¨äºæ‰€æœ‰ç¾¤èŠ\n\n**3.è¯­éŸ³è¯†åˆ«**\n\n+ æ·»åŠ  `\"speech_recognition\": true` å°†å¼€å¯è¯­éŸ³è¯†åˆ«ï¼Œé»˜è®¤ä½¿ç”¨openaiçš„whisperæ¨¡å‹è¯†åˆ«ä¸ºæ–‡å­—ï¼ŒåŒæ—¶ä»¥æ–‡å­—å›å¤ï¼Œè¯¥å‚æ•°ä»…æ”¯æŒç§èŠ (æ³¨æ„ç”±äºè¯­éŸ³æ¶ˆæ¯æ— æ³•åŒ¹é…å‰ç¼€ï¼Œä¸€æ—¦å¼€å¯å°†å¯¹æ‰€æœ‰è¯­éŸ³è‡ªåŠ¨å›å¤ï¼Œæ”¯æŒè¯­éŸ³è§¦å‘ç”»å›¾)ï¼›\n+ æ·»åŠ  `\"group_speech_recognition\": true` å°†å¼€å¯ç¾¤ç»„è¯­éŸ³è¯†åˆ«ï¼Œé»˜è®¤ä½¿ç”¨openaiçš„whisperæ¨¡å‹è¯†åˆ«ä¸ºæ–‡å­—ï¼ŒåŒæ—¶ä»¥æ–‡å­—å›å¤ï¼Œå‚æ•°ä»…æ”¯æŒç¾¤èŠ (ä¼šåŒ¹é…group_chat_prefixå’Œgroup_chat_keyword, æ”¯æŒè¯­éŸ³è§¦å‘ç”»å›¾)ï¼›\n+ æ·»åŠ  `\"voice_reply_voice\": true` å°†å¼€å¯è¯­éŸ³å›å¤è¯­éŸ³ï¼ˆåŒæ—¶ä½œç”¨äºç§èŠå’Œç¾¤èŠï¼‰ï¼Œä½†æ˜¯éœ€è¦é…ç½®å¯¹åº”è¯­éŸ³åˆæˆå¹³å°çš„keyï¼Œç”±äºitchatåè®®çš„é™åˆ¶ï¼Œåªèƒ½å‘é€è¯­éŸ³mp3æ–‡ä»¶ï¼Œè‹¥ä½¿ç”¨wechatyåˆ™å›å¤çš„æ˜¯å¾®ä¿¡è¯­éŸ³ã€‚\n\n**4.å…¶ä»–é…ç½®**\n\n+ `model`: æ¨¡å‹åç§°ï¼Œç›®å‰æ”¯æŒ `gpt-3.5-turbo`, `text-davinci-003`, `gpt-4`, `gpt-4-32k`, `wenxin` , `claude` ,  `xunfei`(å…¶ä¸­gpt-4 apiæš‚æœªå®Œå…¨å¼€æ”¾ï¼Œç”³è¯·é€šè¿‡åå¯ä½¿ç”¨)\n+ `temperature`,`frequency_penalty`,`presence_penalty`: Chat APIæ¥å£å‚æ•°ï¼Œè¯¦æƒ…å‚è€ƒ[OpenAIå®˜æ–¹æ–‡æ¡£ã€‚](https://platform.openai.com/docs/api-reference/chat)\n+ `proxy`ï¼šç”±äºç›®å‰ `openai` æ¥å£å›½å†…æ— æ³•è®¿é—®ï¼Œéœ€é…ç½®ä»£ç†å®¢æˆ·ç«¯çš„åœ°å€ï¼Œè¯¦æƒ…å‚è€ƒ  [#351](https://github.com/zhayujie/chatgpt-on-wechat/issues/351)\n+ å¯¹äºå›¾åƒç”Ÿæˆï¼Œåœ¨æ»¡è¶³ä¸ªäººæˆ–ç¾¤ç»„è§¦å‘æ¡ä»¶å¤–ï¼Œè¿˜éœ€è¦é¢å¤–çš„å…³é”®è¯å‰ç¼€æ¥è§¦å‘ï¼Œå¯¹åº”é…ç½® `image_create_prefix `\n+ å…³äºOpenAIå¯¹è¯åŠå›¾ç‰‡æ¥å£çš„å‚æ•°é…ç½®ï¼ˆå†…å®¹è‡ªç”±åº¦ã€å›å¤å­—æ•°é™åˆ¶ã€å›¾ç‰‡å¤§å°ç­‰ï¼‰ï¼Œå¯ä»¥å‚è€ƒ [å¯¹è¯æ¥å£](https://beta.openai.com/docs/api-reference/completions) å’Œ [å›¾åƒæ¥å£](https://beta.openai.com/docs/api-reference/completions)  æ–‡æ¡£ï¼Œåœ¨[`config.py`](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/config.py)ä¸­æ£€æŸ¥å“ªäº›å‚æ•°åœ¨æœ¬é¡¹ç›®ä¸­æ˜¯å¯é…ç½®çš„ã€‚\n+ `conversation_max_tokens`ï¼šè¡¨ç¤ºèƒ½å¤Ÿè®°å¿†çš„ä¸Šä¸‹æ–‡æœ€å¤§å­—æ•°ï¼ˆä¸€é—®ä¸€ç­”ä¸ºä¸€ç»„å¯¹è¯ï¼Œå¦‚æœç´¯ç§¯çš„å¯¹è¯å­—æ•°è¶…å‡ºé™åˆ¶ï¼Œå°±ä¼šä¼˜å…ˆç§»é™¤æœ€æ—©çš„ä¸€ç»„å¯¹è¯ï¼‰\n+ `rate_limit_chatgpt`ï¼Œ`rate_limit_dalle`ï¼šæ¯åˆ†é’Ÿæœ€é«˜é—®ç­”é€Ÿç‡ã€ç”»å›¾é€Ÿç‡ï¼Œè¶…é€Ÿåæ’é˜ŸæŒ‰åºå¤„ç†ã€‚\n+ `clear_memory_commands`: å¯¹è¯å†…æŒ‡ä»¤ï¼Œä¸»åŠ¨æ¸…ç©ºå‰æ–‡è®°å¿†ï¼Œå­—ç¬¦ä¸²æ•°ç»„å¯è‡ªå®šä¹‰æŒ‡ä»¤åˆ«åã€‚\n+ `hot_reload`: ç¨‹åºé€€å‡ºåï¼Œæš‚å­˜å¾®ä¿¡æ‰«ç çŠ¶æ€ï¼Œé»˜è®¤å…³é—­ã€‚\n+ `character_desc` é…ç½®ä¸­ä¿å­˜ç€ä½ å¯¹æœºå™¨äººè¯´çš„ä¸€æ®µè¯ï¼Œä»–ä¼šè®°ä½è¿™æ®µè¯å¹¶ä½œä¸ºä»–çš„è®¾å®šï¼Œä½ å¯ä»¥ä¸ºä»–å®šåˆ¶ä»»ä½•äººæ ¼      (å…³äºä¼šè¯ä¸Šä¸‹æ–‡çš„æ›´å¤šå†…å®¹å‚è€ƒè¯¥ [issue](https://github.com/zhayujie/chatgpt-on-wechat/issues/43))\n+ `subscribe_msg`ï¼šè®¢é˜…æ¶ˆæ¯ï¼Œå…¬ä¼—å·å’Œä¼ä¸šå¾®ä¿¡channelä¸­è¯·å¡«å†™ï¼Œå½“è¢«è®¢é˜…æ—¶ä¼šè‡ªåŠ¨å›å¤ï¼Œ å¯ä½¿ç”¨ç‰¹æ®Šå ä½ç¬¦ã€‚ç›®å‰æ”¯æŒçš„å ä½ç¬¦æœ‰{trigger_prefix}ï¼Œåœ¨ç¨‹åºä¸­å®ƒä¼šè‡ªåŠ¨æ›¿æ¢æˆbotçš„è§¦å‘è¯ã€‚\n\n**5.LinkAIé…ç½® (å¯é€‰)**\n\n+ `use_linkai`: æ˜¯å¦ä½¿ç”¨LinkAIæ¥å£ï¼Œå¼€å¯åå¯å›½å†…è®¿é—®ï¼Œä½¿ç”¨çŸ¥è¯†åº“å’Œ `Midjourney` ç»˜ç”», å‚è€ƒ [æ–‡æ¡£](https://link-ai.tech/platform/link-app/wechat)\n+ `linkai_api_key`: LinkAI Api Keyï¼Œå¯åœ¨ [æ§åˆ¶å°](https://link-ai.tech/console/interface) åˆ›å»º\n+ `linkai_app_code`: LinkAI åº”ç”¨codeï¼Œé€‰å¡«\n\n**æœ¬è¯´æ˜æ–‡æ¡£å¯èƒ½ä¼šæœªåŠæ—¶æ›´æ–°ï¼Œå½“å‰æ‰€æœ‰å¯é€‰çš„é…ç½®é¡¹å‡åœ¨è¯¥[`config.py`](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/config.py)ä¸­åˆ—å‡ºã€‚**\n\n## è¿è¡Œ\n\n### 1.æœ¬åœ°è¿è¡Œ\n\nå¦‚æœæ˜¯å¼€å‘æœº **æœ¬åœ°è¿è¡Œ**ï¼Œç›´æ¥åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹æ‰§è¡Œï¼š\n\n```bash\npython3 app.py                                    # windowsç¯å¢ƒä¸‹è¯¥å‘½ä»¤é€šå¸¸ä¸º python app.py\n```\n\nç»ˆç«¯è¾“å‡ºäºŒç»´ç åï¼Œä½¿ç”¨å¾®ä¿¡è¿›è¡Œæ‰«ç ï¼Œå½“è¾“å‡º \"Start auto replying\" æ—¶è¡¨ç¤ºè‡ªåŠ¨å›å¤ç¨‹åºå·²ç»æˆåŠŸè¿è¡Œäº†ï¼ˆæ³¨æ„ï¼šç”¨äºç™»å½•çš„å¾®ä¿¡éœ€è¦åœ¨æ”¯ä»˜å¤„å·²å®Œæˆå®åè®¤è¯ï¼‰ã€‚æ‰«ç ç™»å½•åä½ çš„è´¦å·å°±æˆä¸ºæœºå™¨äººäº†ï¼Œå¯ä»¥åœ¨å¾®ä¿¡æ‰‹æœºç«¯é€šè¿‡é…ç½®çš„å…³é”®è¯è§¦å‘è‡ªåŠ¨å›å¤ (ä»»æ„å¥½å‹å‘é€æ¶ˆæ¯ç»™ä½ ï¼Œæˆ–æ˜¯è‡ªå·±å‘æ¶ˆæ¯ç»™å¥½å‹)ï¼Œå‚è€ƒ[#142](https://github.com/zhayujie/chatgpt-on-wechat/issues/142)ã€‚\n\n### 2.æœåŠ¡å™¨éƒ¨ç½²\n\nä½¿ç”¨nohupå‘½ä»¤åœ¨åå°è¿è¡Œç¨‹åºï¼š\n\n```bash\nnohup python3 app.py & tail -f nohup.out          # åœ¨åå°è¿è¡Œç¨‹åºå¹¶é€šè¿‡æ—¥å¿—è¾“å‡ºäºŒç»´ç \n```\næ‰«ç ç™»å½•åç¨‹åºå³å¯è¿è¡ŒäºæœåŠ¡å™¨åå°ï¼Œæ­¤æ—¶å¯é€šè¿‡ `ctrl+c` å…³é—­æ—¥å¿—ï¼Œä¸ä¼šå½±å“åå°ç¨‹åºçš„è¿è¡Œã€‚ä½¿ç”¨ `ps -ef | grep app.py | grep -v grep` å‘½ä»¤å¯æŸ¥çœ‹è¿è¡Œäºåå°çš„è¿›ç¨‹ï¼Œå¦‚æœæƒ³è¦é‡æ–°å¯åŠ¨ç¨‹åºå¯ä»¥å…ˆ `kill` æ‰å¯¹åº”çš„è¿›ç¨‹ã€‚æ—¥å¿—å…³é—­åå¦‚æœæƒ³è¦å†æ¬¡æ‰“å¼€åªéœ€è¾“å…¥Â `tail -f nohup.out`ã€‚æ­¤å¤–ï¼Œ`scripts` ç›®å½•ä¸‹æœ‰ä¸€é”®è¿è¡Œã€å…³é—­ç¨‹åºçš„è„šæœ¬ä¾›ä½¿ç”¨ã€‚\n\n> **å¤šè´¦å·æ”¯æŒï¼š** å°†é¡¹ç›®å¤åˆ¶å¤šä»½ï¼Œåˆ†åˆ«å¯åŠ¨ç¨‹åºï¼Œç”¨ä¸åŒè´¦å·æ‰«ç ç™»å½•å³å¯å®ç°åŒæ—¶è¿è¡Œã€‚\n\n> **ç‰¹æ®ŠæŒ‡ä»¤ï¼š** ç”¨æˆ·å‘æœºå™¨äººå‘é€ **#reset** å³å¯æ¸…ç©ºè¯¥ç”¨æˆ·çš„ä¸Šä¸‹æ–‡è®°å¿†ã€‚\n\n\n### 3.Dockeréƒ¨ç½²\n\n> ä½¿ç”¨dockeréƒ¨ç½²æ— éœ€ä¸‹è½½æºç å’Œå®‰è£…ä¾èµ–ï¼Œåªéœ€è¦è·å– docker-compose.yml é…ç½®æ–‡ä»¶å¹¶å¯åŠ¨å®¹å™¨å³å¯ã€‚\n\n> å‰ææ˜¯éœ€è¦å®‰è£…å¥½ `docker` åŠ `docker-compose`ï¼Œå®‰è£…æˆåŠŸçš„è¡¨ç°æ˜¯æ‰§è¡Œ `docker -v` å’Œ `docker-compose version` (æˆ– docker compose version) å¯ä»¥æŸ¥çœ‹åˆ°ç‰ˆæœ¬å·ï¼Œå¯å‰å¾€ [dockerå®˜ç½‘](https://docs.docker.com/engine/install/) è¿›è¡Œä¸‹è½½ã€‚\n\n#### (1) ä¸‹è½½ docker-compose.yml æ–‡ä»¶\n\n```bash\nwget https://open-1317903499.cos.ap-guangzhou.myqcloud.com/docker-compose.yml\n```\n\nä¸‹è½½å®Œæˆåæ‰“å¼€ `docker-compose.yml` ä¿®æ”¹æ‰€éœ€é…ç½®ï¼Œå¦‚ `OPEN_AI_API_KEY` å’Œ `GROUP_NAME_WHITE_LIST` ç­‰ã€‚\n\n#### (2) å¯åŠ¨å®¹å™¨\n\nåœ¨ `docker-compose.yml` æ‰€åœ¨ç›®å½•ä¸‹æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨å®¹å™¨ï¼š\n\n```bash\nsudo docker compose up -d\n```\n\nè¿è¡Œ `sudo docker ps` èƒ½æŸ¥çœ‹åˆ° NAMES ä¸º chatgpt-on-wechat çš„å®¹å™¨å³è¡¨ç¤ºè¿è¡ŒæˆåŠŸã€‚\n\næ³¨æ„ï¼š\n\n - å¦‚æœ `docker-compose` æ˜¯ 1.X ç‰ˆæœ¬ åˆ™éœ€è¦æ‰§è¡Œ `sudo  docker-compose up -d` æ¥å¯åŠ¨å®¹å™¨\n - è¯¥å‘½ä»¤ä¼šè‡ªåŠ¨å» [docker hub](https://hub.docker.com/r/zhayujie/chatgpt-on-wechat) æ‹‰å– latest ç‰ˆæœ¬çš„é•œåƒï¼Œlatest é•œåƒä¼šåœ¨æ¯æ¬¡é¡¹ç›® release æ–°çš„ç‰ˆæœ¬æ—¶ç”Ÿæˆ\n\næœ€åè¿è¡Œä»¥ä¸‹å‘½ä»¤å¯æŸ¥çœ‹å®¹å™¨è¿è¡Œæ—¥å¿—ï¼Œæ‰«ææ—¥å¿—ä¸­çš„äºŒç»´ç å³å¯å®Œæˆç™»å½•ï¼š\n\n```bash\nsudo docker logs -f chatgpt-on-wechat\n```\n\n#### (3) æ’ä»¶ä½¿ç”¨\n\nå¦‚æœéœ€è¦åœ¨dockerå®¹å™¨ä¸­ä¿®æ”¹æ’ä»¶é…ç½®ï¼Œå¯é€šè¿‡æŒ‚è½½çš„æ–¹å¼å®Œæˆï¼Œå°† [æ’ä»¶é…ç½®æ–‡ä»¶](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/plugins/config.json.template)\né‡å‘½åä¸º `config.json`ï¼Œæ”¾ç½®äº `docker-compose.yml` ç›¸åŒç›®å½•ä¸‹ï¼Œå¹¶åœ¨ `docker-compose.yml` ä¸­çš„ `chatgpt-on-wechat` éƒ¨åˆ†ä¸‹æ·»åŠ  `volumes` æ˜ å°„:\n\n```\nvolumes:\n  - ./config.json:/app/plugins/config.json\n```\n\n### 4. Railwayéƒ¨ç½²\n\n> Railway æ¯æœˆæä¾›5åˆ€å’Œæœ€å¤š500å°æ—¶çš„å…è´¹é¢åº¦ã€‚ (07.11æ›´æ–°: ç›®å‰å¤§éƒ¨åˆ†è´¦å·å·²æ— æ³•å…è´¹éƒ¨ç½²)\n\n1. è¿›å…¥ [Railway](https://railway.app/template/qApznZ?referralCode=RC3znh)\n2. ç‚¹å‡» `Deploy Now` æŒ‰é’®ã€‚\n3. è®¾ç½®ç¯å¢ƒå˜é‡æ¥é‡è½½ç¨‹åºè¿è¡Œçš„å‚æ•°ï¼Œä¾‹å¦‚`open_ai_api_key`, `character_desc`ã€‚\n\n**ä¸€é”®éƒ¨ç½²:**\n  \n  [![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/template/qApznZ?referralCode=RC3znh)\n\n## å¸¸è§é—®é¢˜\n\nFAQsï¼š <https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs>\n\næˆ–ç›´æ¥åœ¨çº¿å’¨è¯¢ [é¡¹ç›®å°åŠ©æ‰‹](https://link-ai.tech/app/Kv2fXJcH)  (betaç‰ˆæœ¬ï¼Œè¯­æ–™å®Œå–„ä¸­ï¼Œå›å¤ä»…ä¾›å‚è€ƒ)\n\n## å¼€å‘\n\næ¬¢è¿æ¥å…¥æ›´å¤šåº”ç”¨ï¼Œå‚è€ƒ [Terminalä»£ç ](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/terminal/terminal_channel.py) å®ç°æ¥æ”¶å’Œå‘é€æ¶ˆæ¯é€»è¾‘å³å¯æ¥å…¥ã€‚ åŒæ—¶æ¬¢è¿å¢åŠ æ–°çš„æ’ä»¶ï¼Œå‚è€ƒ [æ’ä»¶è¯´æ˜æ–‡æ¡£](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins)ã€‚\n\n## è”ç³»\n\næ¬¢è¿æäº¤PRã€Issuesï¼Œä»¥åŠStaræ”¯æŒä¸€ä¸‹ã€‚ç¨‹åºè¿è¡Œé‡åˆ°é—®é¢˜å¯ä»¥æŸ¥çœ‹ [å¸¸è§é—®é¢˜åˆ—è¡¨](https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs) ï¼Œå…¶æ¬¡å‰å¾€ [Issues](https://github.com/zhayujie/chatgpt-on-wechat/issues) ä¸­æœç´¢ã€‚ä¸ªäººå¼€å‘è€…å¯åŠ å…¥å¼€æºäº¤æµç¾¤å‚ä¸æ›´å¤šè®¨è®ºï¼Œä¼ä¸šç”¨æˆ·å¯è”ç³»[äº§å“é¡¾é—®](https://img-1317903499.cos.ap-guangzhou.myqcloud.com/docs/product-manager-qrcode.jpg)å’¨è¯¢ã€‚\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "sammyl720--image-generator-mcp-server": {
      "owner": "sammyl720",
      "name": "image-generator-mcp-server",
      "url": "https://github.com/sammyl720/image-generator-mcp-server",
      "imageUrl": "https://github.com/sammyl720.png",
      "description": "Connects to OpenAI's DALL-E 3 model to generate images based on user prompts, saving the results to a specified directory on the user's desktop.",
      "stars": 10,
      "forks": 7,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-05-24T09:22:57Z",
      "readme_content": "# image-generator MCP Server\n\nAn mcp server that generates images based on image prompts\n\nThis is a TypeScript-based MCP server that implements image generation using **OPENAI**'s `dall-e-3` image generation model.\n\n## Features\n\n### Tools\n- `generate_image` - Generate an image for given prompt\n  - Takes `prompt` as a required parameter\n  - Takes `imageName` as a required parameter to save the generated image in a `generated-images` directory on your desktop\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"command\": \"image-generator\",\n      \"env\": {\n        \"OPENAI_API_KEY\": \"<your-openai-api-key>\"\n    }\n  }\n}\n```\nMake sure to replace `<your-openai-api-key>` with your actual **OPENAI** Api Key.\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "sarthakkimtani--mcp-image-gen": {
      "owner": "sarthakkimtani",
      "name": "mcp-image-gen",
      "url": "https://github.com/sarthakkimtani/mcp-image-gen",
      "imageUrl": "https://github.com/sarthakkimtani.png",
      "description": "Generates high-quality images from textual prompts with customizable dimensions using the Flux.1 Schnell model. Provides standardized interfaces for specifying image generation parameters and includes error handling features.",
      "stars": 15,
      "forks": 6,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-05T13:37:04Z",
      "readme_content": "# Image Generation MCP Server\n\nA Model Context Protocol (MCP) server that enables seamless generation of high-quality images via Together AI. This server provides a standardized interface to specify image generation parameters.\n\n<a href=\"https://glama.ai/mcp/servers/o0137xiz62\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/o0137xiz62/badge\" alt=\"Image Generation Server MCP server\" />\n</a>\n\n## Features\n\n- High-quality image generation powered by the Flux.1 Schnell model\n- Support for customizable dimensions (width and height)\n- Clear error handling for prompt validation and API issues\n- Easy integration with MCP-compatible clients\n\n## Installation\n\n#### Claude Desktop\n\n- On MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n- On Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n<summary>Development/Unpublished Servers Configuration</summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"image-gen\": {\n      \"command\": \"uv\",\n      \"args\": [\"--directory\", \"/ABSOLUTE/PATH/TO/image-gen/\", \"run\", \"image-gen\"],\n      \"env\": {\n        \"TOGETHER_AI_API_KEY\": \"<API KEY>\"\n      }\n    }\n  }\n}\n```\n\n## Available Tools\n\nThe server implements one tool:\n\n### generate_image\n\nGenerates an image based on the given textual prompt and optional dimensions.\n\n**Input Schema:**\n\n```json\n{\n  \"prompt\": {\n    \"type\": \"string\",\n    \"description\": \"A descriptive prompt for generating the image (e.g., 'a futuristic cityscape at sunset')\"\n  },\n  \"width\": {\n    \"type\": \"integer\",\n    \"description\": \"Width of the generated image in pixels (optional)\"\n  },\n  \"height\": {\n    \"type\": \"integer\",\n    \"description\": \"Height of the generated image in pixels (optional)\"\n  },\n  \"model\": {\n    \"type\": \"string\",\n    \"description\": \"The exact model name as it appears in Together AI. If incorrect, it will fallback to the default model (black-forest-labs/FLUX.1-schnell).\"\n  }\n}\n```\n\n## Prerequisites\n\n- Python 3.12 or higher\n- httpx\n- mcp\n\n## Contributing\n\nContributions are welcome! Please follow these steps to contribute:\n\n1. Fork the repository\n2. Create a new branch (`feature/my-new-feature`)\n3. Commit your changes\n4. Push the branch to your fork\n5. Open a Pull Request\n\nFor significant changes, please open an issue first to discuss your proposed changes.\n\n## License\n\nThis project is licensed under the MIT License. See the LICENSE file for details.",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Sheshiyer--jina-ai-mcp-multimodal-search": {
      "owner": "Sheshiyer",
      "name": "jina-ai-mcp-multimodal-search",
      "url": "https://github.com/Sheshiyer/jina-ai-mcp-multimodal-search",
      "imageUrl": "https://github.com/Sheshiyer.png",
      "description": "Seamless integration with Jina AI's neural search capabilities enables semantic, image, and cross-modal searches through a simple interface. Perform searches based on natural language queries, visual similarities, and text-to-image or image-to-text conversions.",
      "stars": 4,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-08-19T08:35:51Z",
      "readme_content": "# Jina AI MCP Server\n\nA Model Context Protocol (MCP) server that provides seamless integration with Jina AI's neural search capabilities. This server enables semantic search, image search, and cross-modal search functionalities through a simple interface.\n\n## ğŸš€ Features\n\n- **Semantic Search**: Find semantically similar documents using natural language queries\n- **Image Search**: Search for visually similar images using image URLs\n- **Cross-Modal Search**: Perform text-to-image or image-to-text searches\n\n## ğŸ“‹ Prerequisites\n\n- Node.js 16 or higher\n- A Jina AI account and API key ([Get one here](https://cloud.jina.ai/))\n- MCP-compatible environment (e.g., Cline)\n\n## ğŸ› ï¸ Installation\n\n1. Clone the repository:\n```bash\ngit clone <repository-url>\ncd jina-ai-mcp\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Create a `.env` file with your Jina AI API key:\n```bash\nJINA_API_KEY=your_api_key_here\n```\n\n4. Build the server:\n```bash\nnpm run build\n```\n\n## âš™ï¸ Configuration\n\nAdd the following configuration to your MCP settings file:\n\n```json\n{\n  \"mcpServers\": {\n    \"jina-ai\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/jina-ai-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"JINA_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n## ğŸ” Available Tools\n\n### 1. Semantic Search\nPerform semantic/neural search on text documents.\n\n```typescript\nuse_mcp_tool({\n  server_name: \"jina-ai\",\n  tool_name: \"semantic_search\",\n  arguments: {\n    query: \"search query text\",\n    collection: \"your-collection-name\",\n    limit: 10 // optional, defaults to 10\n  }\n})\n```\n\n### 2. Image Search\nSearch for similar images using an image URL.\n\n```typescript\nuse_mcp_tool({\n  server_name: \"jina-ai\",\n  tool_name: \"image_search\",\n  arguments: {\n    imageUrl: \"https://example.com/image.jpg\",\n    collection: \"your-collection-name\",\n    limit: 10 // optional, defaults to 10\n  }\n})\n```\n\n### 3. Cross-Modal Search\nPerform text-to-image or image-to-text search.\n\n```typescript\nuse_mcp_tool({\n  server_name: \"jina-ai\",\n  tool_name: \"cross_modal_search\",\n  arguments: {\n    query: \"a beautiful sunset\", // or image URL for image2text\n    mode: \"text2image\", // or \"image2text\"\n    collection: \"your-collection-name\",\n    limit: 10 // optional, defaults to 10\n  }\n})\n```\n\n## ğŸ“ Response Format\n\nAll search tools return results in the following format:\n\n```typescript\n{\n  content: [\n    {\n      type: \"text\",\n      text: JSON.stringify({\n        results: [\n          {\n            id: string,\n            score: number,\n            data: Record<string, any>\n          }\n        ]\n      }, null, 2)\n    }\n  ]\n}\n```\n\n## ğŸ” Error Handling\n\nThe server handles various error cases:\n- Invalid API key\n- Missing or invalid parameters\n- API rate limits\n- Network errors\n- Invalid collection names\n\nAll errors are properly formatted and returned with appropriate error codes and messages.\n\n## ğŸ¤ Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## ğŸ“„ License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## ğŸ™ Acknowledgments\n\n- [Jina AI](https://jina.ai/) for their excellent neural search platform\n- [Model Context Protocol](https://github.com/modelcontextprotocol/protocol) for the MCP specification\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Siddhant-K-code--memory-journal-mcp-server": {
      "owner": "Siddhant-K-code",
      "name": "memory-journal-mcp-server",
      "url": "https://github.com/Siddhant-K-code/memory-journal-mcp-server",
      "imageUrl": "https://github.com/Siddhant-K-code.png",
      "description": "Search and analyze photos in a library using various intuitive tools, including location-based searches to easily find images taken in specific places.",
      "stars": 21,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-07-28T18:59:40Z",
      "readme_content": "# ğŸ“¸ Smart Photo Journal MCP Server\n\n**Smart Photo Journal** is an MCP server designed to help you search and analyze your photo library with powerful, intuitive tools. Whether you're reminiscing about family moments or looking for a specific photo with friends, this server has got you covered! ğŸ‰\n\n> **Inspired by:** [burningion/video-editing-mcp](https://github.com/burningion/video-editing-mcp)\n> A huge shoutout to [@burningion](https://x.com/burningion) for the innovative idea of using MCP for creative media management!\n\n<a href=\"https://glama.ai/mcp/servers/51jiworg5k\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/51jiworg5k/badge\" alt=\"Smart Photo Journal Server MCP server\" /></a>\n\n## ğŸ¯ Features\n\n- **Location Search:** Find photos from specific places with ease. ğŸŒ\n- **Label Search:** Search photos by keywords or labels like \"Birthday,\" \"Beach,\" or \"Vacation.\" ğŸ‰\n- **People Search:** Quickly locate photos featuring specific people. ğŸ‘¥\n- **Photo Analysis:** Discover fun insights like the most popular times and days for your photo shoots. ğŸ•°ï¸\n- **Fuzzy Matching:** Not sure of the exact name? Don't worry! The server supports fuzzy matching for flexibility. ğŸ”\n\n## ğŸš€ Getting started\n\n### Prerequisites\n\n1. Ensure you have macOS with a Photos library.\n2. Install [uv](https://docs.astral.sh/uv/) to manage dependencies and run the server.\n\n### Installation\n\n1. Clone the repository:\n\n   ```bash\n   git clone https://github.com/Siddhant-K-code/memory-journal-mcp-server.git\n   cd memory-journal-mcp-server\n   ```\n\n2. Install dependencies using `uv`:\n\n   ```bash\n   uv sync\n   ```\n\n3. Configure the MCP server. Update your `claude_desktop_config.json` with the following configuration:\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"smart-photo-journal\": {\n         \"command\": \"/Users/<YOUR_DEVICE_USERNAME>/.local/bin/uv\",\n         \"args\": [\n           \"--directory\",\n           \"/Users/<PATH_TO_CLONED_DIR>/memory-journal-mcp-server\",\n           \"run\",\n           \"server.py\"\n         ]\n       }\n     }\n   }\n   ```\n\n4. Start the server with following command or just open Claude Desktop:\n   ```bash\n   uv run server.py\n   ```\n\n> **Note:** Replace `<YOUR_DEVICE_USERNAME>` and `<PATH_TO_CLONED_DIR>` with your actual device username and the path to the cloned directory.\n> You will get a popup to authorize the server to access your photos. It will be in local only, and no data will be shared with anyone except Claude services.\n\n### MCP Server Initialization\n\nWhen the server starts, you'll see:\n\n```\nStarting Smart Photo Journal MCP server.\n```\n\nIt's now ready to process your photo queries! ğŸ‰\n\n---\n\n## ğŸ› ï¸ Usage\n\n### Available Tools\n\n1. **Location Search**\n\n   - Description: Find photos taken in a specific location.\n   - Input Example:\n     ```json\n     {\n       \"location\": \"Udaipur\"\n     }\n     ```\n   - Expected Output:\n     ```\n     Found 5 photos from Udaipur:\n     ğŸ“· IMG_1234.jpg\n     ...\n     ```\n\n2. **Label Search**\n\n   - Description: Search for photos by labels or keywords.\n   - Input Example:\n     ```json\n     {\n       \"label\": \"Birthday\"\n     }\n     ```\n   - Expected Output:\n     ```\n     Photos labeled as 'Birthday' (3 found):\n     ğŸ“· IMG_5678.jpg\n     ...\n     ```\n\n3. **People Search**\n\n   - Description: Find photos containing specific people.\n   - Input Example:\n     ```json\n     {\n       \"person\": \"Maa\"\n     }\n     ```\n   - Expected Output:\n     ```\n     Photos with Maa (10 found):\n     ğŸ“· IMG_9101.jpg\n     ...\n     ```\n\n4. **Photo Analysis**\n   - Description: Analyze patterns in your photo library, such as the most common times or days for photo shoots.\n   - Input Example:\n     ```json\n     {}\n     ```\n   - Expected Output:\n     ```\n     ğŸ“¸ Photo Taking Patterns:\n     Total Photos: 200\n     ...\n     ```\n\n---\n\n## ğŸ“š Example Use-Cases\n\n### 1. **Family & Friends Album Organizer**\n\nWant to gather all your family moments in one place? Use the `people-search` tool with names like \"Papa\" or \"Mom\" or \"Any Friend\" to find photos with specific people.\n\n### 2. **Vacation Highlights**\n\nSearch for photos from your vacation destination using the `location-search` tool.\n\n### 3. **Throwback Fun**\n\nCurious about your past birthday photos? Use `label-search` with \"Birthday\" and relive the fun!\n\n### 4. **Understand Your Photography Habits**\n\nUse the `photo-analysis` tool to understand when and where you take most of your photos. Plan your next shoot accordingly!\n\n---\n\n## âš¡ Tips for Best Results\n\n- Ensure your Photos library is loaded in macOS.\n- Be as specific as possible with search queries for more accurate results.\n- Use fuzzy matching for flexibility when you're unsure of the exact name.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "sshtunnelvision--MCP-LOGO-GEN": {
      "owner": "sshtunnelvision",
      "name": "MCP-LOGO-GEN",
      "url": "https://github.com/sshtunnelvision/MCP-LOGO-GEN",
      "imageUrl": "https://github.com/sshtunnelvision.png",
      "description": "Logo generation using AI tools, including features for image creation, background removal, and automatic scaling for high-quality outputs in various sizes.",
      "stars": 171,
      "forks": 17,
      "license": "GNU General Public License v3.0",
      "language": "Python",
      "updated_at": "2025-08-18T06:34:36Z",
      "readme_content": "# MCP Tool Server for Logo Generation\n\nThis server provides logo generation capabilities using FAL AI, with tools for image generation, background removal, and automatic scaling.\n\n## Demo\n\n[![MCP Tool Server Demo](https://img.youtube.com/vi/Miemu1xEZng/0.jpg)](https://www.youtube.com/watch?v=Miemu1xEZng)\n\n## Installation\n\n1. Install `uv` (Universal Virtualenv):\n\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n2. Create and activate a virtual environment:\n\n```bash\nuv venv\nsource .venv/bin/activate  # On Unix/macOS\n# or\n.venv\\Scripts\\activate     # On Windows\n```\n\n3. Install dependencies:\n\n```bash\nuv pip install -r requirements.txt\n```\n\n4. Set up your environment variables:\n   - Create a `.env` file in the root directory\n   - Add your FAL AI API key:\n\n```bash\nFAL_KEY=your_fal_ai_key_here\n```\n\n## Running the Server\n\nStart the server with:\n\n```bash\npython run_server.py\n```\n\nThe server will be available at `http://127.0.0.1:7777`\n\n### Troubleshooting\n\nIf you encounter a `FileNotFoundError` on Windows when running the server, make sure you're running the command from the root directory of the project. If the issue persists, try updating to the latest version of the repository which includes fixes for Windows compatibility.\n\nFor Windows users specifically:\n\n1. Make sure you've activated your virtual environment with `.venv\\Scripts\\activate`\n2. Run the server from the root directory of the project with `python run_server.py`\n3. If you see any path-related errors, please report them in the issues section of the repository\n\n## Cursor IDE Configuration\n\n1. Open Cursor Settings\n2. Navigate to the MCP section\n3. Add the following configuration:\n   - URL: `http://127.0.0.1:7777/sse`\n   - Connection Type: `SSE`\n   - Enable the connection\n\n## Notes\n\n- Always reference `@logo-creation.mdc` in your Cursor Composer for consistent results\n- Steps are defined in `@logo-creation.mdc` but tools can be used independently\n- All generated logos will be saved in the `downloads` directory\n- Each logo is automatically generated in three sizes:\n  - Original size\n  - 32x32 pixels\n  - 128x128 pixels\n- All logos maintain transparency in their final PNG format\n- Prompts created by agent are informed by examples and prompt structure seen in server.py. You can customize the prompt structure by editing the server.py file.\n- You can use the generate_image tool to generate any image you want, not just logos\n\n## Requirements\n\n- Python 3.8+\n- FAL AI API key (required for image generation)\n- Active internet connection\n\n## References\n\n- [Cursor MCP Documentation](https://docs.cursor.com/context/model-context-protocol)\n- [Model Context Protocol Introduction](https://modelcontextprotocol.io/introduction)\n- [FAL AI Dashboard](https://fal.ai/dashboard)\n\n---\n\nIf you find this tool helpful, you can [buy me a coffee](https://buymeacoffee.com/sshtunnelvision) â˜•ï¸ to support development!\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "stabgan--openrouter-mcp-multimodal": {
      "owner": "stabgan",
      "name": "openrouter-mcp-multimodal",
      "url": "https://github.com/stabgan/openrouter-mcp-multimodal",
      "imageUrl": "https://github.com/stabgan.png",
      "description": "Combines text chat and image analysis capabilities to conduct multimodal conversations and handle custom queries seamlessly. Optimizes workflows with intelligent model selection and performance improvements.",
      "stars": 10,
      "forks": 4,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-05T07:28:32Z",
      "readme_content": "# OpenRouter MCP Multimodal Server\n\n[![Build Status](https://github.com/stabgan/openrouter-mcp-multimodal/actions/workflows/publish.yml/badge.svg)](https://github.com/stabgan/openrouter-mcp-multimodal/actions/workflows/publish.yml)\n[![npm version](https://img.shields.io/npm/v/@stabgan/openrouter-mcp-multimodal.svg)](https://www.npmjs.com/package/@stabgan/openrouter-mcp-multimodal)\n[![Docker Pulls](https://img.shields.io/docker/pulls/stabgandocker/openrouter-mcp-multimodal.svg)](https://hub.docker.com/r/stabgandocker/openrouter-mcp-multimodal)\n\nAn MCP (Model Context Protocol) server that provides chat and image analysis capabilities through OpenRouter.ai's diverse model ecosystem. This server combines text chat functionality with powerful image analysis capabilities.\n\n## Features\n\n- **Text Chat:**\n  - Direct access to all OpenRouter.ai chat models\n  - Support for simple text and multimodal conversations\n  - Configurable temperature and other parameters\n\n- **Image Analysis:**\n  - Analyze single images with custom questions\n  - Process multiple images simultaneously \n  - Automatic image resizing and optimization\n  - Support for various image sources (local files, URLs, data URLs)\n\n- **Model Selection:**\n  - Search and filter available models\n  - Validate model IDs\n  - Get detailed model information\n  - Support for default model configuration\n\n- **Performance Optimization:**\n  - Smart model information caching\n  - Exponential backoff for retries\n  - Automatic rate limit handling\n\n## What's New in 1.5.0\n\n- **Improved OS Compatibility:**\n  - Enhanced path handling for Windows, macOS, and Linux\n  - Better support for Windows-style paths with drive letters\n  - Normalized path processing for consistent behavior across platforms\n\n- **MCP Configuration Support:**\n  - Cursor MCP integration without requiring environment variables\n  - Direct configuration via MCP parameters\n  - Flexible API key and model specification options\n\n- **Robust Error Handling:**\n  - Improved fallback mechanisms for image processing\n  - Better error reporting with specific diagnostics\n  - Multiple backup strategies for file reading\n\n- **Image Processing Enhancements:**\n  - More reliable base64 encoding for all image types\n  - Fallback options when Sharp module is unavailable\n  - Better handling of large images with automatic optimization\n\n## Installation\n\n### Option 1: Install via npm\n\n```bash\nnpm install -g @stabgan/openrouter-mcp-multimodal\n```\n\n### Option 2: Run via Docker\n\n```bash\ndocker run -i -e OPENROUTER_API_KEY=your-api-key-here stabgandocker/openrouter-mcp-multimodal:latest\n```\n\n## Quick Start Configuration\n\n### Prerequisites\n\n1. Get your OpenRouter API key from [OpenRouter Keys](https://openrouter.ai/keys)\n2. Choose a default model (optional)\n\n### MCP Configuration Options\n\nAdd one of the following configurations to your MCP settings file (e.g., `cline_mcp_settings.json` or `claude_desktop_config.json`):\n\n#### Option 1: Using npx (Node.js)\n\n```json\n{\n  \"mcpServers\": {\n    \"openrouter\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@stabgan/openrouter-mcp-multimodal\"\n      ],\n      \"env\": {\n        \"OPENROUTER_API_KEY\": \"your-api-key-here\",\n        \"DEFAULT_MODEL\": \"qwen/qwen2.5-vl-32b-instruct:free\"\n      }\n    }\n  }\n}\n```\n\n#### Option 2: Using uv (Python Package Manager)\n\n```json\n{\n  \"mcpServers\": {\n    \"openrouter\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"-m\",\n        \"openrouter_mcp_multimodal\"\n      ],\n      \"env\": {\n        \"OPENROUTER_API_KEY\": \"your-api-key-here\",\n        \"DEFAULT_MODEL\": \"qwen/qwen2.5-vl-32b-instruct:free\"\n      }\n    }\n  }\n}\n```\n\n#### Option 3: Using Docker\n\n```json\n{\n  \"mcpServers\": {\n    \"openrouter\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\", \"OPENROUTER_API_KEY=your-api-key-here\",\n        \"-e\", \"DEFAULT_MODEL=qwen/qwen2.5-vl-32b-instruct:free\",\n        \"stabgandocker/openrouter-mcp-multimodal:latest\"\n      ]\n    }\n  }\n}\n```\n\n#### Option 4: Using Smithery (recommended)\n\n```json\n{\n  \"mcpServers\": {\n    \"openrouter\": {\n      \"command\": \"smithery\",\n      \"args\": [\n        \"run\",\n        \"stabgan/openrouter-mcp-multimodal\"\n      ],\n      \"env\": {\n        \"OPENROUTER_API_KEY\": \"your-api-key-here\",\n        \"DEFAULT_MODEL\": \"qwen/qwen2.5-vl-32b-instruct:free\"\n      }\n    }\n  }\n}\n```\n\n## Examples\n\nFor comprehensive examples of how to use this MCP server, check out the [examples directory](./examples/). We provide:\n\n- JavaScript examples for Node.js applications\n- Python examples with interactive chat capabilities\n- Code snippets for integrating with various applications\n\nEach example comes with clear documentation and step-by-step instructions.\n\n## Dependencies\n\nThis project uses the following key dependencies:\n\n- `@modelcontextprotocol/sdk`: ^1.8.0 - Latest MCP SDK for tool implementation\n- `openai`: ^4.89.1 - OpenAI-compatible API client for OpenRouter\n- `sharp`: ^0.33.5 - Fast image processing library\n- `axios`: ^1.8.4 - HTTP client for API requests\n- `node-fetch`: ^3.3.2 - Modern fetch implementation\n\nNode.js 18 or later is required. All dependencies are regularly updated to ensure compatibility and security.\n\n## Available Tools\n\n### mcp_openrouter_chat_completion\n\nSend text or multimodal messages to OpenRouter models:\n\n```javascript\nuse_mcp_tool({\n  server_name: \"openrouter\",\n  tool_name: \"mcp_openrouter_chat_completion\",\n  arguments: {\n    model: \"google/gemini-2.5-pro-exp-03-25:free\", // Optional if default is set\n    messages: [\n      {\n        role: \"system\",\n        content: \"You are a helpful assistant.\"\n      },\n      {\n        role: \"user\",\n        content: \"What is the capital of France?\"\n      }\n    ],\n    temperature: 0.7 // Optional, defaults to 1.0\n  }\n});\n```\n\nFor multimodal messages with images:\n\n```javascript\nuse_mcp_tool({\n  server_name: \"openrouter\",\n  tool_name: \"mcp_openrouter_chat_completion\",\n  arguments: {\n    model: \"anthropic/claude-3.5-sonnet\",\n    messages: [\n      {\n        role: \"user\",\n        content: [\n          {\n            type: \"text\",\n            text: \"What's in this image?\"\n          },\n          {\n            type: \"image_url\",\n            image_url: {\n              url: \"https://example.com/image.jpg\"\n            }\n          }\n        ]\n      }\n    ]\n  }\n});\n```",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Sunwood-ai-labs--ideagram-mcp-server": {
      "owner": "Sunwood-ai-labs",
      "name": "ideagram-mcp-server",
      "url": "https://github.com/Sunwood-ai-labs/ideagram-mcp-server",
      "imageUrl": "https://github.com/Sunwood-ai-labs.png",
      "description": "Generate images based on prompts with customizable parameters like aspect ratio and style using the Ideogram API.",
      "stars": 5,
      "forks": 7,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-08-20T21:40:42Z",
      "readme_content": "<div align=\"center\">\n\n![](docs/ideogram-image_2025-05-18T06-31-45-777Z.png)\n\n  <h1>ğŸ¨ Ideogram MCP Server</h1>\n\n  <p>\n    <img alt=\"GitHub\" src=\"https://img.shields.io/github/license/sunwood-ai-labs/ideagram-mcp-server\">\n    <img alt=\"GitHub package.json version\" src=\"https://img.shields.io/github/package-json/v/sunwood-ai-labs/ideagram-mcp-server\">\n    <img alt=\"GitHub issues\" src=\"https://img.shields.io/github/issues/sunwood-ai-labs/ideagram-mcp-server\">\n    <img alt=\"GitHub pull requests\" src=\"https://img.shields.io/github/issues-pr/sunwood-ai-labs/ideagram-mcp-server\">\n    <img alt=\"npm\" src=\"https://img.shields.io/npm/v/@sunwood-ai-labs/ideagram-mcp-server\">\n    <img alt=\"npm\" src=\"https://img.shields.io/npm/dt/@sunwood-ai-labs/ideagram-mcp-server\">\n  </p>\n\n  <p>\n    Ideogram APIã‚’ä½¿ã£ã¦ç”»åƒç”Ÿæˆã‚’æä¾›ã™ã‚‹Model Context Protocol (MCP) ã‚µãƒ¼ãƒãƒ¼ã ã‚ˆï¼<br>\n    <b>Ideogram 3.0</b>å¯¾å¿œã§ã€Claude Desktopã‚„MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰çˆ†é€Ÿé€£æºã§ãã‚‹ã®ãŒç¥âœ¨\n  </p>\n</div>\n\n---\n\n## ğŸ“¦ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦\n\n- Ideogram API (v3.0) ã‚’MCPã‚µãƒ¼ãƒãƒ¼çµŒç”±ã§ä½¿ãˆã‚‹TypeScriptè£½ãƒ„ãƒ¼ãƒ«\n- ç”»åƒç”Ÿæˆãƒ»ã‚¹ã‚¿ã‚¤ãƒ«å‚ç…§ãƒ»ãƒã‚¸ãƒƒã‚¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ãƒ»ãƒ¢ãƒ‡ãƒ«é¸æŠãªã©å¤šæ©Ÿèƒ½\n- Claude Desktopã‚„ä»–MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰å³åˆ©ç”¨OK\n\n---\n\n\n## âš¡ï¸ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ\n\nClaude Desktopã‚„ä»–MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§çˆ†é€Ÿé€£æºã—ãŸã„ãªã‚‰ã€  \nä¸‹è¨˜JSONã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚³ãƒ”ãƒšã§OKï¼âœ¨\n\n```json\n{\n  \"mcpServers\": {\n    \"ideogram\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"@sunwood-ai-labs/ideagram-mcp-server\"\n      ],\n      \"env\": {\n        \"IDEOGRAM_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n\n---\n\n## ğŸ› ï¸ MCPãƒ„ãƒ¼ãƒ«ä»•æ§˜\n\n### generate_image\n\n#### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸€è¦§ï¼ˆæœ€æ–°ç‰ˆï¼‰\n\n| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿         | å‹         | èª¬æ˜                                                                                 | å¿…é ˆ/ä»»æ„ | å‚™è€ƒ                      |\n|--------------------|------------|--------------------------------------------------------------------------------------|-----------|---------------------------|\n| prompt             | string     | ç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆè‹±èªæ¨å¥¨ï¼‰                                                        | å¿…é ˆ      |                           |\n| aspect_ratio       | string     | ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ï¼ˆä¾‹: \"1x1\", \"16x9\", \"4x3\" ãªã©ï¼‰                                        | ä»»æ„      | 15ç¨®é¡                    |\n| resolution         | string     | è§£åƒåº¦ï¼ˆå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‚ç…§ã€å…¨69ç¨®ï¼‰                                               | ä»»æ„      |                           |\n| seed               | integer    | ä¹±æ•°ã‚·ãƒ¼ãƒ‰ï¼ˆå†ç¾æ€§æ‹…ä¿ç”¨ï¼‰                                                            | ä»»æ„      | 0ï½2147483647             |\n| magic_prompt       | string     | ãƒã‚¸ãƒƒã‚¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆ\"AUTO\"|\"ON\"|\"OFF\"ï¼‰                                               | ä»»æ„      | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ\"AUTO\"          |\n| rendering_speed    | string     | v3ç”¨ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°é€Ÿåº¦ï¼ˆ\"TURBO\"|\"DEFAULT\"|\"QUALITY\"ï¼‰                                  | ä»»æ„      |                           |\n| style_codes        | string[]   | 8æ–‡å­—ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚³ãƒ¼ãƒ‰é…åˆ—                                                             | ä»»æ„      |                           |\n| style_type         | string     | ã‚¹ã‚¿ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ï¼ˆ\"AUTO\"|\"GENERAL\"|\"REALISTIC\"|\"DESIGN\"ï¼‰                              | ä»»æ„      |                           |\n| negative_prompt    | string     | é™¤å¤–è¦ç´ ï¼ˆè‹±èªæ¨å¥¨ï¼‰                                                                  | ä»»æ„      |                           |\n| num_images         | number     | ç”Ÿæˆç”»åƒæ•°ï¼ˆ1ï½8ï¼‰                                                                    | ä»»æ„      |                           |\n| style_reference    | object     | ã‚¹ã‚¿ã‚¤ãƒ«å‚ç…§ï¼ˆIdeogram 3.0æ–°æ©Ÿèƒ½ï¼‰                                                   | ä»»æ„      | ä¸‹è¨˜è©³ç´°                   |\n| â”” urls             | string[]   | å‚ç…§ç”»åƒURLé…åˆ—ï¼ˆæœ€å¤§3ã¤ï¼‰                                                            | ä»»æ„      |                           |\n| â”” style_code       | string     | ã‚¹ã‚¿ã‚¤ãƒ«ã‚³ãƒ¼ãƒ‰                                                                        | ä»»æ„      |                           |\n| â”” random_style     | boolean    | ãƒ©ãƒ³ãƒ€ãƒ ã‚¹ã‚¿ã‚¤ãƒ«ä½¿ç”¨                                                                  | ä»»æ„      |                           |\n| output_dir         | string     | ç”»åƒä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: \"docs\"ï¼‰                                            | ä»»æ„      |                           |\n| base_filename      | string     | ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒ™ãƒ¼ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: \"ideogram-image\"ï¼‰                                | ä»»æ„      | ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ»IDä»˜ä¸     |\n| blur_mask          | boolean    | ç”»åƒã®ç¸ã‚’ã¼ã‹ã™ï¼ˆtrueã§ãƒã‚¹ã‚¯åˆæˆï¼‰                                                  | ä»»æ„      | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: false          |\n\n#### ğŸ“ ä½¿ç”¨ä¾‹\n\n```typescript\nconst result = await use_mcp_tool({\n  server_name: \"ideagram-mcp-server\",\n  tool_name: \"generate_image\",\n  arguments: {\n    prompt: \"A beautiful sunset over mountains\",\n    aspect_ratio: \"16x9\",\n    rendering_speed: \"QUALITY\",\n    num_images: 2,\n    style_reference: {\n      urls: [\n        \"https://example.com/ref1.jpg\",\n        \"https://example.com/ref2.jpg\"\n      ],\n      random_style: false\n    },\n    blur_mask: true\n  }\n});\n```\n\n---\n\n## ğŸ§‘â€ğŸ’» é–‹ç™ºãƒ»ãƒ“ãƒ«ãƒ‰ãƒ»ãƒ†ã‚¹ãƒˆ\n\n- `npm run build` ... TypeScriptãƒ“ãƒ«ãƒ‰\n- `npm run watch` ... é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ï¼ˆè‡ªå‹•ãƒ“ãƒ«ãƒ‰ï¼‰\n- `npm run lint` ... ã‚³ãƒ¼ãƒ‰ãƒªãƒ³ãƒˆ\n- `npm test` ... ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ\n\n---\n\n## ğŸ—‚ï¸ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ\n\n```bash\nideagram-mcp-server/\nâ”œâ”€â”€ assets/\nâ”œâ”€â”€ docs/\nâ”‚   â””â”€â”€ ideogram-image_2025-05-18T06-31-45-777Z.png\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ tools/\nâ”‚   â”œâ”€â”€ types/\nâ”‚   â”œâ”€â”€ utils/\nâ”‚   â”œâ”€â”€ ideogram-client.ts\nâ”‚   â”œâ”€â”€ index.ts\nâ”‚   â”œâ”€â”€ server.ts\nâ”‚   â””â”€â”€ test.ts\nâ”œâ”€â”€ .env.example\nâ”œâ”€â”€ package.json\nâ”œâ”€â”€ tsconfig.json\nâ”œâ”€â”€ README.md\nâ””â”€â”€ ...ï¼ˆçœç•¥ï¼‰\n```\n\n---\n\n## ğŸ“ ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³\n\n1. ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ãƒ•ã‚©ãƒ¼ã‚¯\n2. æ–°ãƒ–ãƒ©ãƒ³ãƒä½œæˆ (`git checkout -b feature/awesome`)\n3. å¤‰æ›´ã‚³ãƒŸãƒƒãƒˆï¼ˆã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯æ—¥æœ¬èªï¼‹çµµæ–‡å­—æ¨å¥¨ï¼ï¼‰\n4. ãƒ—ãƒƒã‚·ãƒ¥ï¼†ãƒ—ãƒ«ãƒªã‚¯ä½œæˆ\n\n---\n\n## ğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤ & ãƒªãƒªãƒ¼ã‚¹\n\n- GitHub Actionsã§è‡ªå‹•npmå…¬é–‹\n- ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ›´æ–°â†’ã‚¿ã‚°pushã§è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤\n\n```bash\nnpm version patch|minor|major\ngit push --follow-tags\n```\n\nè©³ç´°ã¯ [docs/npm-deploy.md](docs/npm-deploy.md) ã‚’å‚ç…§ï¼\n\n---\n\n## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹\n\nMIT\n\n---\n\n<div align=\"center\">\n\n![](assets/header-animation.svg)\n\n</div>\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "surferdot--mcp-svg-converter": {
      "owner": "surferdot",
      "name": "mcp-svg-converter",
      "url": "https://github.com/surferdot/mcp-svg-converter",
      "imageUrl": "https://github.com/surferdot.png",
      "description": "Converts SVG code to high-quality PNG and JPG images while providing options for transparency and image quality customization. Enhances image processing by allowing transformation of vector graphics into raster formats with detailed settings.",
      "stars": 3,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-17T13:58:17Z",
      "readme_content": "# MCP SVG Converter\n\n[![npm version](https://img.shields.io/npm/v/mcp-svg-converter.svg)](https://www.npmjs.com/package/mcp-svg-converter)\n[![Downloads](https://img.shields.io/npm/dt/mcp-svg-converter.svg)](https://www.npmjs.com/package/mcp-svg-converter)\n[![License](https://img.shields.io/npm/l/mcp-svg-converter.svg)](https://github.com/surferdot/mcp-svg-converter/blob/main/LICENSE)\n\n[English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)\n\n<a name=\"english\"></a>\n## English\n\nA Model Context Protocol (MCP) server that provides tools for converting SVG code to high-quality PNG and JPG images with detailed customization options.\n\n### Features\n\n- Convert SVG code to high-quality PNG images with transparency support\n- Convert SVG code to high-quality JPG images with customizable quality settings\n- Automatic dimension detection and preservation from original SVG\n- Support for scaling to higher resolutions\n- Background color customization\n- Intelligent path handling with automatic redirection to allowed directories\n- Secure file system access with configurable permissions\n\n### Installation\n\n#### Quick Install with npx\n\n```bash\nnpx mcp-svg-converter /path/to/allowed/directory\n```\n\n#### Global Installation\n\n```bash\nnpm install -g mcp-svg-converter\nmcp-svg-converter /path/to/allowed/directory\n```\n\n#### From Source\n\n##### Prerequisites\n\n- Node.js 16 or higher\n- npm or yarn\n\n##### Installation Steps\n\n1. Clone this repository\n   ```bash\n   git clone https://github.com/surferdot/mcp-svg-converter.git\n   cd mcp-svg-converter\n   ```\n\n2. Install dependencies\n   ```bash\n   npm install\n   ```\n\n3. Build the project\n   ```bash\n   npm run build\n   ```\n\n### Usage\n\n#### As a standalone server\n\nRun the server by specifying one or more allowed directories where the converted images can be saved:\n\n```bash\nnode build/index.js /path/to/allowed/directory1 /path/to/allowed/directory2\n```\n\n#### With Claude Desktop\n\n1. Download and install [Claude Desktop](https://claude.ai/download)\n2. Create or confirm you have access to an output directory:\n   ```bash\n   # macOS/Linux\n   mkdir -p ~/Desktop/svg-output\n   \n   # Windows\n   mkdir \"%USERPROFILE%\\Desktop\\svg-output\"\n   ```\n\n3. Configure Claude Desktop by editing the configuration file:\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n4. Open the Claude app, click on the Claude menu in your system menu bar and select \"Settings...\"\n5. Click on \"Developer\" in the left sidebar\n6. Click \"Edit Config\" to open the configuration file\n\n7. Add this server configuration:\n\n##### Using npm package with npx (recommended)\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-svg-converter\",\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n##### Using global installation\n\nIf you've installed the package globally:\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"mcp-svg-converter\",\n      \"args\": [\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n##### Using local build\n\nIf you've built from source:\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/to/mcp-svg-converter/build/index.js\",\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n8. Save the file and restart Claude Desktop\n\n#### Verifying the Setup\n\nWhen Claude Desktop restarts, if configured correctly:\n\n1. You should see a hammer icon <img src=\"https://mintlify.s3.us-west-1.amazonaws.com/mcp/images/claude-desktop-mcp-hammer-icon.svg\" style=\"display: inline; height: 1.3em; vertical-align: middle\"> at the bottom right of the input box indicating MCP tools are available.\n2. Clicking the hammer icon should show the `svg-to-png` and `svg-to-jpg` tools.\n\n### Examples in Claude Desktop\n\n#### Example 1: Converting a Simple SVG to PNG\n\nIn Claude Desktop, send a message like:\n\n```\nPlease convert this SVG to PNG and save it to my output directory:\n\n<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 200 100\" width=\"200\" height=\"100\">\n  <rect x=\"10\" y=\"10\" width=\"80\" height=\"80\" fill=\"#4285f4\" />\n  <circle cx=\"140\" cy=\"50\" r=\"40\" fill=\"#ea4335\" />\n  <path d=\"M10 50 L90 50 L50 90 Z\" fill=\"#fbbc05\" />\n  <text x=\"100\" y=\"20\" font-family=\"Arial\" font-size=\"12\" text-anchor=\"middle\" fill=\"#34a853\">SVG Example</text>\n</svg>\n```\n\n#### Example 2: High-Quality JPG Conversion\n\n```\nPlease convert this SVG to a JPG with 95% quality and 2x scaling:\n\n<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 200 200\">\n  <rect width=\"200\" height=\"200\" fill=\"#f0f0f0\" />\n  <circle cx=\"100\" cy=\"100\" r=\"80\" fill=\"#ff6b6b\" />\n  <path d=\"M100 50 L130 150 L70 150 Z\" fill=\"white\" />\n</svg>\n```\n\n### Tools\n\n#### svg-to-png\n\nConverts SVG code to a high-quality PNG image with transparency support.\n\n**Parameters:**\n- `svgCode` (string, required): The SVG code to convert\n- `outputPath` (string, required): Path where the PNG file should be saved\n- `backgroundColor` (string, optional): Background color (default: transparent)\n- `scale` (number, optional): Scale factor for higher resolution (default: 1)\n\n#### svg-to-jpg\n\nConverts SVG code to a high-quality JPG image.\n\n**Parameters:**\n- `svgCode` (string, required): The SVG code to convert\n- `outputPath` (string, required): Path where the JPG file should be saved\n- `backgroundColor` (string, optional): Background color (default: white)\n- `quality` (number, optional): JPEG quality from 1-100 (default: 90)\n- `scale` (number, optional): Scale factor for higher resolution (default: 1)\n\n### Advanced Usage Tips\n\n#### Specifying Multiple Output Directories\n\nYou can specify multiple allowed output directories for more flexible file saving:\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-svg-converter\",\n        \"/Users/yourusername/Desktop/svg-output\",\n        \"/Users/yourusername/Documents/svg-images\",\n        \"/Users/yourusername/Downloads\"\n      ]\n    }\n  }\n}\n```\n\n#### Using Custom Output Filenames\n\nSpecify detailed file paths in your request:\n\n```\nPlease convert this SVG to PNG, and save it as \"colorful_shapes.png\" in my output directory.\n\n<svg>...</svg>\n```\n\n#### Automatic Path Redirection\n\nIf you request saving to a non-allowed directory, the converter automatically redirects to an allowed directory and informs you of the actual save location.\n\n### Troubleshooting\n\n#### Claude Doesn't Show MCP Tools Icon\n1. Verify the configuration file has correct JSON syntax\n2. Ensure all paths are absolute paths\n3. Make sure output directories exist and are writable\n4. Completely exit and restart Claude Desktop\n5. Check Claude logs:\n   - macOS: `~/Library/Logs/Claude/mcp*.log`\n   - Windows: `%APPDATA%\\Claude\\logs\\mcp*.log`\n\n#### Tool Execution Fails\n1. Ensure `mcp-svg-converter` is correctly installed\n2. Check output directory permissions\n3. Verify the SVG code is valid\n4. Check Claude logs for detailed error messages\n\n#### \"Command Not Found\" Error\n1. Ensure `mcp-svg-converter` is globally installed or correctly reference `npx`\n2. Confirm npm's global bin directory is in your PATH\n3. Try using full paths in configuration\n\n### Debugging\n\nYou can use the MCP Inspector to debug and test the server directly:\n\n```bash\nnpx @modelcontextprotocol/inspector npx mcp-svg-converter /path/to/allowed/directory\n```\n\nThis opens an interactive interface where you can test all available tools without going through Claude Desktop.\n\n### Security Considerations\n\n- The server will only write files to the directories specified when starting the server\n- If a user attempts to save to a non-allowed directory, the file will be automatically redirected to an allowed directory\n- Path traversal attacks are prevented by proper path validation\n\n### License\n\nMIT\n\n---\n\n<a name=\"ä¸­æ–‡\"></a>\n## ä¸­æ–‡\n\nMCP SVG è½¬æ¢å™¨æ˜¯ä¸€ä¸ªåŸºäºæ¨¡å‹ä¸Šä¸‹æ–‡åè®® (MCP) çš„æœåŠ¡å™¨ï¼Œæä¾›å°† SVG ä»£ç è½¬æ¢ä¸ºé«˜è´¨é‡ PNG å’Œ JPG å›¾åƒçš„å·¥å…·ï¼Œæ”¯æŒè¯¦ç»†çš„è‡ªå®šä¹‰é€‰é¡¹ã€‚\n\n### ç‰¹ç‚¹\n\n- å°† SVG ä»£ç è½¬æ¢ä¸ºæ”¯æŒé€æ˜åº¦çš„é«˜è´¨é‡ PNG å›¾åƒ\n- å°† SVG ä»£ç è½¬æ¢ä¸ºå¯å®šåˆ¶è´¨é‡è®¾ç½®çš„é«˜è´¨é‡ JPG å›¾åƒ\n- è‡ªåŠ¨æ£€æµ‹å¹¶ä¿ç•™åŸå§‹ SVG çš„å°ºå¯¸\n- æ”¯æŒç¼©æ”¾åˆ°æ›´é«˜åˆ†è¾¨ç‡\n- å¯è‡ªå®šä¹‰èƒŒæ™¯é¢œè‰²\n- æ™ºèƒ½è·¯å¾„å¤„ç†ï¼Œè‡ªåŠ¨é‡å®šå‘åˆ°å…è®¸çš„ç›®å½•\n- å¯é…ç½®æƒé™çš„å®‰å…¨æ–‡ä»¶ç³»ç»Ÿè®¿é—®\n\n### å®‰è£…\n\n#### ä½¿ç”¨ npx å¿«é€Ÿå®‰è£…\n\n```bash\nnpx mcp-svg-converter /path/to/allowed/directory\n```\n\n#### å…¨å±€å®‰è£…\n\n```bash\nnpm install -g mcp-svg-converter\nmcp-svg-converter /path/to/allowed/directory\n```\n\n#### ä»æºä»£ç å®‰è£…\n\n##### å‰ææ¡ä»¶\n\n- Node.js 16 æˆ–æ›´é«˜ç‰ˆæœ¬\n- npm æˆ– yarn\n\n##### å®‰è£…æ­¥éª¤\n\n1. å…‹éš†æ­¤ä»“åº“\n   ```bash\n   git clone https://github.com/surferdot/mcp-svg-converter.git\n   cd mcp-svg-converter\n   ```\n\n2. å®‰è£…ä¾èµ–\n   ```bash\n   npm install\n   ```\n\n3. æ„å»ºé¡¹ç›®\n   ```bash\n   npm run build\n   ```\n\n### ä½¿ç”¨æ–¹æ³•\n\n#### ä½œä¸ºç‹¬ç«‹æœåŠ¡å™¨è¿è¡Œ\n\né€šè¿‡æŒ‡å®šä¸€ä¸ªæˆ–å¤šä¸ªå…è®¸å­˜å‚¨è½¬æ¢åå›¾åƒçš„ç›®å½•æ¥è¿è¡ŒæœåŠ¡å™¨ï¼š\n\n```bash\nnode build/index.js /path/to/allowed/directory1 /path/to/allowed/directory2\n```\n\n#### ä¸ Claude Desktop ä¸€èµ·ä½¿ç”¨\n\n1. ä¸‹è½½å¹¶å®‰è£… [Claude Desktop](https://claude.ai/download)\n2. åˆ›å»ºæˆ–ç¡®è®¤ä½ æœ‰æƒé™è®¿é—®çš„è¾“å‡ºç›®å½•ï¼š\n   ```bash\n   # macOS/Linux\n   mkdir -p ~/Desktop/svg-output\n   \n   # Windows\n   mkdir \"%USERPROFILE%\\Desktop\\svg-output\"\n   ```\n\n3. é…ç½® Claude Desktopï¼š\n   - æ‰“å¼€ Claude åº”ç”¨ç¨‹åº\n   - ç‚¹å‡»ç³»ç»Ÿèœå•æ ä¸­çš„ Claude å›¾æ ‡\n   - é€‰æ‹©\"Settings...\"ï¼ˆè®¾ç½®ï¼‰\n   - åœ¨å·¦ä¾§èœå•ä¸­é€‰æ‹©\"Developer\"ï¼ˆå¼€å‘è€…ï¼‰\n   - ç‚¹å‡»\"Edit Config\"ï¼ˆç¼–è¾‘é…ç½®ï¼‰æŒ‰é’®\n\n4. ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼š\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n5. æ·»åŠ æœåŠ¡å™¨é…ç½®ï¼š\n\n##### ä½¿ç”¨ npm åŒ…ä¸ npxï¼ˆæ¨èï¼‰\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-svg-converter\",\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n##### ä½¿ç”¨å…¨å±€å®‰è£…\n\nå¦‚æœä½ å·²å…¨å±€å®‰è£…äº†æ­¤åŒ…ï¼š\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"mcp-svg-converter\",\n      \"args\": [\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n##### ä½¿ç”¨æœ¬åœ°æ„å»º\n\nå¦‚æœä½ ä»æºä»£ç æ„å»ºï¼š\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/to/mcp-svg-converter/build/index.js\",\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n6. ä¿å­˜æ–‡ä»¶å¹¶é‡å¯ Claude Desktop\n\n#### éªŒè¯è®¾ç½®\n\nå½“ Claude Desktop é‡å¯åï¼Œå¦‚æœé…ç½®æ­£ç¡®ï¼š\n\n1. ä½ åº”è¯¥åœ¨è¾“å…¥æ¡†å³ä¸‹è§’çœ‹åˆ°ä¸€ä¸ªé”¤å­å›¾æ ‡ <img src=\"https://mintlify.s3.us-west-1.amazonaws.com/mcp/images/claude-desktop-mcp-hammer-icon.svg\" style=\"display: inline; height: 1.3em; vertical-align: middle\">ï¼Œè¡¨ç¤º MCP å·¥å…·å¯ç”¨ã€‚\n2. ç‚¹å‡»é”¤å­å›¾æ ‡åº”æ˜¾ç¤º `svg-to-png` å’Œ `svg-to-jpg` å·¥å…·ã€‚\n\n### Claude Desktop ä¸­çš„ä½¿ç”¨ç¤ºä¾‹\n\n#### ç¤ºä¾‹ 1ï¼šå°†ç®€å• SVG è½¬æ¢ä¸º PNG\n\nåœ¨ Claude Desktop ä¸­å‘é€ä»¥ä¸‹æ¶ˆæ¯ï¼š\n\n```\nè¯·å°†è¿™ä¸ª SVG è½¬æ¢ä¸º PNG å¹¶ä¿å­˜åˆ°æˆ‘çš„è¾“å‡ºç›®å½•ï¼š\n\n<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 200 100\" width=\"200\" height=\"100\">\n  <rect x=\"10\" y=\"10\" width=\"80\" height=\"80\" fill=\"#4285f4\" />\n  <circle cx=\"140\" cy=\"50\" r=\"40\" fill=\"#ea4335\" />\n  <path d=\"M10 50 L90 50 L50 90 Z\" fill=\"#fbbc05\" />\n  <text x=\"100\" y=\"20\" font-family=\"Arial\" font-size=\"12\" text-anchor=\"middle\" fill=\"#34a853\">SVG ç¤ºä¾‹</text>\n</svg>\n```\n\n#### ç¤ºä¾‹ 2ï¼šé«˜è´¨é‡ JPG è½¬æ¢\n\n```\nè¯·å°†è¿™ä¸ª SVG è½¬æ¢ä¸º 95% è´¨é‡å’Œ 2 å€ç¼©æ”¾çš„ JPG å›¾åƒï¼š\n\n<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 200 200\">\n  <rect width=\"200\" height=\"200\" fill=\"#f0f0f0\" />\n  <circle cx=\"100\" cy=\"100\" r=\"80\" fill=\"#ff6b6b\" />\n  <path d=\"M100 50 L130 150 L70 150 Z\" fill=\"white\" />\n</svg>\n```\n\n### å·¥å…·\n\n#### svg-to-png\n\nå°† SVG ä»£ç è½¬æ¢ä¸ºæ”¯æŒé€æ˜åº¦çš„é«˜è´¨é‡ PNG å›¾åƒã€‚\n\n**å‚æ•°ï¼š**\n- `svgCode` (å­—ç¬¦ä¸²ï¼Œå¿…éœ€)ï¼šè¦è½¬æ¢çš„ SVG ä»£ç \n- `outputPath` (å­—ç¬¦ä¸²ï¼Œå¿…éœ€)ï¼šPNG æ–‡ä»¶çš„ä¿å­˜è·¯å¾„\n- `backgroundColor` (å­—ç¬¦ä¸²ï¼Œå¯é€‰)ï¼šèƒŒæ™¯é¢œè‰² (é»˜è®¤ï¼šé€æ˜)\n- `scale` (æ•°å­—ï¼Œå¯é€‰)ï¼šæ›´é«˜åˆ†è¾¨ç‡çš„ç¼©æ”¾å› å­ (é»˜è®¤ï¼š1)\n\n#### svg-to-jpg\n\nå°† SVG ä»£ç è½¬æ¢ä¸ºé«˜è´¨é‡ JPG å›¾åƒã€‚\n\n**å‚æ•°ï¼š**\n- `svgCode` (å­—ç¬¦ä¸²ï¼Œå¿…éœ€)ï¼šè¦è½¬æ¢çš„ SVG ä»£ç \n- `outputPath` (å­—ç¬¦ä¸²ï¼Œå¿…éœ€)ï¼šJPG æ–‡ä»¶çš„ä¿å­˜è·¯å¾„\n- `backgroundColor` (å­—ç¬¦ä¸²ï¼Œå¯é€‰)ï¼šèƒŒæ™¯é¢œè‰² (é»˜è®¤ï¼šç™½è‰²)\n- `quality` (æ•°å­—ï¼Œå¯é€‰)ï¼šJPEG è´¨é‡ï¼ŒèŒƒå›´ä» 1 åˆ° 100 (é»˜è®¤ï¼š90)\n- `scale` (æ•°å­—ï¼Œå¯é€‰)ï¼šæ›´é«˜åˆ†è¾¨ç‡çš„ç¼©æ”¾å› å­ (é»˜è®¤ï¼š1)\n\n### é«˜çº§ä½¿ç”¨æŠ€å·§\n\n#### æŒ‡å®šå¤šä¸ªè¾“å‡ºç›®å½•\n\nä½ å¯ä»¥æŒ‡å®šå¤šä¸ªå…è®¸çš„è¾“å‡ºç›®å½•ï¼Œä»¥æä¾›æ›´çµæ´»çš„æ–‡ä»¶ä¿å­˜é€‰é¡¹ï¼š\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-svg-converter\",\n        \"/Users/yourusername/Desktop/svg-output\",\n        \"/Users/yourusername/Documents/svg-images\",\n        \"/Users/yourusername/Downloads\"\n      ]\n    }\n  }\n}\n```\n\n#### ä½¿ç”¨è‡ªå®šä¹‰è¾“å‡ºæ–‡ä»¶å\n\nåœ¨è¯·æ±‚ä¸­æŒ‡å®šè¯¦ç»†çš„æ–‡ä»¶è·¯å¾„ï¼š\n\n```\nè¯·å°†è¿™ä¸ª SVG è½¬æ¢ä¸º PNGï¼Œå¹¶ä»¥æ–‡ä»¶å \"colorful_shapes.png\" ä¿å­˜åˆ°è¾“å‡ºç›®å½•ã€‚\n\n<svg>...</svg>\n```\n\n#### è‡ªåŠ¨è·¯å¾„é‡å®šå‘\n\nå¦‚æœä½ è¯·æ±‚ä¿å­˜åˆ°ä¸€ä¸ªä¸å…è®¸çš„ç›®å½•ï¼Œè½¬æ¢å™¨ä¼šè‡ªåŠ¨å°†æ–‡ä»¶é‡å®šå‘åˆ°å…è®¸çš„ç›®å½•ï¼Œå¹¶åœ¨å“åº”ä¸­å‘ŠçŸ¥ä½ å®é™…çš„ä¿å­˜ä½ç½®ã€‚\n\n### æ•…éšœæ’é™¤\n\n#### Claude æ²¡æœ‰æ˜¾ç¤º MCP å·¥å…·å›¾æ ‡\n1. ç¡®è®¤é…ç½®æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼ˆJSON è¯­æ³•ï¼‰\n2. æ£€æŸ¥æ‰€æœ‰è·¯å¾„æ˜¯å¦ä¸ºç»å¯¹è·¯å¾„\n3. ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ä¸”å¯å†™\n4. å®Œå…¨é€€å‡ºå¹¶é‡å¯ Claude Desktop\n5. æ£€æŸ¥ Claude æ—¥å¿—ï¼š\n   - macOS: `~/Library/Logs/Claude/mcp*.log`\n   - Windows: `%APPDATA%\\Claude\\logs\\mcp*.log`\n\n#### å·¥å…·æ‰§è¡Œå¤±è´¥\n1. ç¡®ä¿å·²æ­£ç¡®å®‰è£… `mcp-svg-converter`\n2. æ£€æŸ¥è¾“å‡ºç›®å½•çš„æƒé™\n3. éªŒè¯ SVG ä»£ç æ˜¯å¦æœ‰æ•ˆ\n4. æ£€æŸ¥ Claude æ—¥å¿—äº†è§£è¯¦ç»†é”™è¯¯ä¿¡æ¯\n\n#### \"command not found\" é”™è¯¯\n1. ç¡®ä¿å·²å…¨å±€å®‰è£… `mcp-svg-converter` æˆ–æ­£ç¡®å¼•ç”¨ `npx`\n2. ç¡®è®¤ npm çš„å…¨å±€ bin ç›®å½•åœ¨ç³»ç»Ÿ PATH ä¸­\n3. å°è¯•åœ¨é…ç½®ä¸­ä½¿ç”¨å®Œæ•´è·¯å¾„\n\n### è°ƒè¯•\n\næ‚¨å¯ä»¥ä½¿ç”¨ MCP Inspector ç›´æ¥è°ƒè¯•å’Œæµ‹è¯•æœåŠ¡å™¨ï¼š\n\n```bash\nnpx @modelcontextprotocol/inspector npx mcp-svg-converter /path/to/allowed/directory\n```\n\nè¿™å°†æ‰“å¼€ä¸€ä¸ªäº¤äº’å¼ç•Œé¢ï¼Œä½ å¯ä»¥åœ¨å…¶ä¸­æµ‹è¯•æ‰€æœ‰å¯ç”¨å·¥å…·ï¼Œè€Œæ— éœ€é€šè¿‡ Claude Desktopã€‚\n\n### å®‰å…¨è€ƒè™‘\n\n- æœåŠ¡å™¨åªä¼šå°†æ–‡ä»¶å†™å…¥å¯åŠ¨æœåŠ¡å™¨æ—¶æŒ‡å®šçš„ç›®å½•\n- å¦‚æœç”¨æˆ·å°è¯•ä¿å­˜åˆ°éå…è®¸ç›®å½•ï¼Œæ–‡ä»¶å°†è‡ªåŠ¨é‡å®šå‘åˆ°å…è®¸çš„ç›®å½•\n- é€šè¿‡é€‚å½“çš„è·¯å¾„éªŒè¯é˜²æ­¢è·¯å¾„éå†æ”»å‡»\n\n### è®¸å¯è¯\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "SureScaleAI--openai-gpt-image-mcp": {
      "owner": "SureScaleAI",
      "name": "openai-gpt-image-mcp",
      "url": "https://github.com/SureScaleAI/openai-gpt-image-mcp",
      "imageUrl": "https://github.com/SureScaleAI.png",
      "description": "Generate and edit images using the latest OpenAI GPT-4o and gpt-image-1 models with advanced prompt control. Outputs can be saved to disk or received in base64 format for integration with MCP-compatible clients.",
      "stars": 74,
      "forks": 23,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T22:32:34Z",
      "readme_content": "# openai-gpt-image-mcp\n\n<p align=\"center\">\n  <a href=\"https://www.npmjs.com/package/@modelcontextprotocol/sdk\"><img src=\"https://img.shields.io/npm/v/@modelcontextprotocol/sdk?label=MCP%20SDK&color=blue\" alt=\"MCP SDK\"></a>\n  <a href=\"https://www.npmjs.com/package/openai\"><img src=\"https://img.shields.io/npm/v/openai?label=OpenAI%20SDK&color=blueviolet\" alt=\"OpenAI SDK\"></a>\n  <a href=\"https://github.com/SureScaleAI/openai-gpt-image-mcp/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/SureScaleAI/openai-gpt-image-mcp?color=brightgreen\" alt=\"License\"></a>\n  <a href=\"https://github.com/SureScaleAI/openai-gpt-image-mcp/stargazers\"><img src=\"https://img.shields.io/github/stars/SureScaleAI/openai-gpt-image-mcp?style=social\" alt=\"GitHub stars\"></a>\n  <a href=\"https://github.com/SureScaleAI/openai-gpt-image-mcp/actions\"><img src=\"https://img.shields.io/github/actions/workflow/status/SureScaleAI/openai-gpt-image-mcp/main.yml?label=build&logo=github\" alt=\"Build Status\"></a>\n</p>\n\n---\n\nA Model Context Protocol (MCP) tool server for OpenAI's GPT-4o/gpt-image-1 image generation and editing APIs.\n\n- **Generate images** from text prompts using OpenAI's latest models.\n- **Edit images** (inpainting, outpainting, compositing) with advanced prompt control.\n- **Supports**: Claude Desktop, Cursor, VSCode, Windsurf, and any MCP-compatible client.\n\n---\n\n## âœ¨ Features\n\n- **create-image**: Generate images from a prompt, with advanced options (size, quality, background, etc).\n- **edit-image**: Edit or extend images using a prompt and optional mask, supporting both file paths and base64 input.\n- **File output**: Save generated images directly to disk, or receive as base64.\n\n---\n\n## ğŸš€ Installation\n\n```sh\ngit clone https://github.com/SureScaleAI/openai-gpt-image-mcp.git\ncd openai-gpt-image-mcp\nyarn install\nyarn build\n```\n\n---\n\n## ğŸ”‘ Configuration\n\nAdd to Claude Desktop or VSCode (including Cursor/Windsurf) config:\n\n```json\n{\n  \"mcpServers\": {\n    \"openai-gpt-image-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/dist/index.js\"],\n      \"env\": { \"OPENAI_API_KEY\": \"sk-...\" }\n    }\n  }\n}\n```\n\nAlso supports Azure deployments:\n\n```json\n{\n  \"mcpServers\": {\n    \"openai-gpt-image-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/dist/index.js\"],\n      \"env\": { \n        \"AZURE_OPENAI_API_KEY\": \"sk-...\",\n        \"AZURE_OPENAI_ENDPOINT\": \"my.endpoint.com\",\n        \"OPENAI_API_VERSION\": \"2024-12-01-preview\"\n      }\n    }\n  }\n}\n```\n\nAlso supports supplying an environment files:\n\n```json\n{\n  \"mcpServers\": {\n    \"openai-gpt-image-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/dist/index.js\", \"--env-file\", \"./deployment/.env\"]\n    }\n  }\n}\n```\n\n---\n\n## âš¡ Advanced\n\n- For `create-image`, set `n` to generate up to 10 images at once.\n- For `edit-image`, provide a mask image (file path or base64) to control where edits are applied.\n- Provide an environment file with `--env-file path/to/file/.env`\n- See `src/index.ts` for all options.\n\n---\n\n## ğŸ§‘â€ğŸ’» Development\n\n- TypeScript source: `src/index.ts`\n- Build: `yarn build`\n- Run: `node dist/index.js`\n\n---\n\n## ğŸ“ License\n\nMIT\n\n---\n\n## ğŸ©º Troubleshooting\n\n- Make sure your `OPENAI_API_KEY` is valid and has image API access.\n- You must have a [verified OpenAI organization](https://platform.openai.com/account/organization). After verifying, it can take 15â€“20 minutes for image API access to activate.\n- File paths must be absolute.\n  - **Unix/macOS/Linux**: Starting with `/` (e.g., `/path/to/image.png`)\n  - **Windows**: Drive letter followed by `:` (e.g., `C:/path/to/image.png` or `C:\\path\\to\\image.png`)\n- For file output, ensure the directory is writable.\n- If you see errors about file types, check your image file extensions and formats.\n\n---\n\n## âš ï¸ Limitations & Large File Handling\n\n- **1MB Payload Limit:** MCP clients (including Claude Desktop) have a hard 1MB limit for tool responses. Large images (especially high-res or multiple images) can easily exceed this limit if returned as base64.\n- **Auto-Switch to File Output:** If the total image size exceeds 1MB, the tool will automatically save images to disk and return the file path(s) instead of base64. This ensures compatibility and prevents errors like `result exceeds maximum length of 1048576`.\n- **Default File Location:** If you do not specify a `file_output` path, images will be saved to `/tmp` (or the directory set by the `MCP_HF_WORK_DIR` environment variable) with a unique filename.\n- **Environment Variable:**\n  - `MCP_HF_WORK_DIR`: Set this to control where large images and file outputs are saved. Example: `export MCP_HF_WORK_DIR=/your/desired/dir`\n- **Best Practice:** For large or production images, always use file output and ensure your client is configured to handle file paths.\n\n---\n\n## ğŸ“š References\n\n- [OpenAI Images API Documentation](https://platform.openai.com/docs/api-reference/images)\n\n---\n\n## ğŸ™ Credits\n\n- Built with [@modelcontextprotocol/sdk](https://www.npmjs.com/package/@modelcontextprotocol/sdk)\n- Uses [openai](https://www.npmjs.com/package/openai) Node.js SDK \n- Built by [SureScale.ai](https://surescale.ai)\n- Contributions from [Axle Research and Technology](https://axleinfo.com/)",
      "npm_url": "",
      "npm_downloads": 0
    },
    "techkwon--mcp-gemini": {
      "owner": "techkwon",
      "name": "mcp-gemini",
      "url": "https://github.com/techkwon/mcp-gemini",
      "imageUrl": "https://github.com/techkwon.png",
      "description": "Leverages Google's Gemini API to generate text, create and analyze images, perform video analysis on YouTube content, and conduct web searches. Provides a range of advanced AI functionalities for various applications.",
      "stars": 4,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-07-23T14:36:23Z",
      "readme_content": "# MCP Gemini API ì„œë²„\n\nCursorì™€ Claudeë¥¼ ìœ„í•œ Google Gemini API ì„œë²„ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ ìƒì„±, ì´ë¯¸ì§€ ë¶„ì„, ë¹„ë””ì˜¤ ë¶„ì„ ë“± Geminiì˜ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n\n## ì£¼ìš” ê¸°ëŠ¥\n\n- í…ìŠ¤íŠ¸ ìƒì„± (gemini-2.0-flash ëª¨ë¸ ì‚¬ìš©)\n- ì´ë¯¸ì§€ ìƒì„± ë° ë¶„ì„\n- YouTube ë¹„ë””ì˜¤ ë¶„ì„\n- ì›¹ ê²€ìƒ‰\n\n## ì‹œì‘í•˜ê¸°\n\n### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­\n\n- Node.js 18.0.0 ì´ìƒ\n- npm ë˜ëŠ” yarn\n- Google API í‚¤ (Gemini API ì ‘ê·¼ìš©)\n\n### ì„¤ì¹˜\n\n```bash\n# ì €ì¥ì†Œ í´ë¡ \ngit clone https://github.com/techkwon/mcp-gemini.git\ncd mcp-gemini\n\n# ì˜ì¡´ì„± ì„¤ì¹˜\nnpm install\n```\n\n### í™˜ê²½ ì„¤ì •\n\n1. `config.ts` íŒŒì¼ì— Google API í‚¤ ì„¤ì •:\n\n```typescript\nexport default {\n  googleApiKey: \"your_api_key_here\",\n  // ê¸°íƒ€ ì„¤ì •...\n};\n```\n\n### ë¹Œë“œ ë° ì‹¤í–‰\n\n```bash\n# TypeScript ë¹Œë“œ\nnpm run build\n\n# ì„œë²„ ì‹œì‘ (PM2 ì‚¬ìš©)\nnpm start\n\n# ê°œë°œ ëª¨ë“œë¡œ ì‹¤í–‰\nnpm run dev\n```\n\n### PM2 ì„œë²„ ê´€ë¦¬\n\nì„œë²„ëŠ” PM2ë¥¼ í†µí•´ ìë™ìœ¼ë¡œ ê´€ë¦¬ë©ë‹ˆë‹¤. ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„œë²„ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n\n```bash\n# ì„œë²„ ìƒíƒœ í™•ì¸\nnpm run status\n\n# ì„œë²„ ë¡œê·¸ í™•ì¸\nnpm run logs\n\n# ì„œë²„ ì¤‘ì§€\nnpm run stop\n\n# ì„œë²„ ì¬ì‹œì‘\nnpm run restart\n\n# ì‹œìŠ¤í…œ ì¬ì‹œì‘ ì‹œ ìë™ ì‹¤í–‰ ì„¤ì •\npm2 startup\npm2 save\n```\n\n## Cursor/Claude ì—°ë™\n\n### MCP ì„¤ì •\n\n`~/.cursor/mcp.json` íŒŒì¼ì— ë‹¤ìŒ ì„¤ì •ì„ ì¶”ê°€í•˜ì„¸ìš”:\n\n```json\n{\n  \"github.com/techkwon/mcp-gemini\": {\n    \"command\": \"npm\",\n    \"args\": [\"start\"],\n    \"cwd\": \"<í”„ë¡œì íŠ¸_ê²½ë¡œ>\",\n    \"env\": {\n      \"NODE_ENV\": \"production\"\n    },\n    \"disabled\": false,\n    \"autoStart\": true,\n    \"autoApprove\": [\n      \"gem-generate\",\n      \"gem-generate-image\",\n      \"gem-analyze-video\",\n      \"gem-search\"\n    ]\n  }\n}\n```\n\n### API ì—”ë“œí¬ì¸íŠ¸\n\n- `/gem-generate`: í…ìŠ¤íŠ¸ ìƒì„±\n- `/gem-generate-image`: ì´ë¯¸ì§€ ìƒì„±/ë¶„ì„\n- `/gem-analyze-video`: YouTube ë¹„ë””ì˜¤ ë¶„ì„\n- `/gem-search`: ì›¹ ê²€ìƒ‰\n\n## ì£¼ìš” ì—…ë°ì´íŠ¸\n\n### ìµœì‹  ë²„ì „ (2024-03)\n- PM2ë¥¼ í†µí•œ ì„œë²„ ìë™í™” êµ¬í˜„\n- gemini-2.0-flash ëª¨ë¸ë¡œ í†µì¼\n- ìë™ ì¬ì‹œì‘ ë° ì˜¤ë¥˜ ë³µêµ¬ ê¸°ëŠ¥ ì¶”ê°€\n- í™˜ê²½ ì„¤ì • ê°œì„ \n\n### ì´ì „ ë²„ì „\n- YouTube ë¹„ë””ì˜¤ ë¶„ì„ ê¸°ëŠ¥ ì¶”ê°€\n- ì´ë¯¸ì§€ ìƒì„±/ë¶„ì„ ê¸°ëŠ¥ ê°œì„ \n- ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€\n\n## ë¬¸ì œ í•´ê²°\n\n### ì¼ë°˜ì ì¸ ë¬¸ì œ\n\n1. **ì„œë²„ê°€ ì‹œì‘ë˜ì§€ ì•ŠëŠ” ê²½ìš°**\n   ```bash\n   # PM2 ë¡œê·¸ í™•ì¸\n   npm run logs\n   \n   # PM2 í”„ë¡œì„¸ìŠ¤ ìƒíƒœ í™•ì¸\n   npm run status\n   ```\n\n2. **API í‚¤ ì˜¤ë¥˜**\n   - `config.ts` íŒŒì¼ì—ì„œ API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸\n   - Gemini API í• ë‹¹ëŸ‰ ë° ê¶Œí•œ í™•ì¸\n\n3. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¬¸ì œ**\n   - `ecosystem.config.js`ì—ì„œ ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì • í™•ì¸\n   - PM2 ëª¨ë‹ˆí„°ë§ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì \n\n## ê¸°ì—¬í•˜ê¸°\n\n1. Fork the Project\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\n3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\n5. Open a Pull Request\n\n## ë¼ì´ì„ ìŠ¤\n\nì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.\n\n## ì—°ë½ì²˜\n\ní”„ë¡œì íŠ¸ ê´€ë¦¬ì: techkwon\nì´ë©”ì¼: techkwon@example.com\ní”„ë¡œì íŠ¸ ë§í¬: [https://github.com/techkwon/mcp-gemini](https://github.com/techkwon/mcp-gemini)\n\n## ì£¼ìš” ì˜ì¡´ì„±\n\n- @google/generative-ai: ^0.1.3 (Gemini API SDK)\n- @fastify/cors: ^8.5.0 (CORS ì§€ì›)\n- fastify: ^4.29.0 (ì›¹ ì„œë²„ í”„ë ˆì„ì›Œí¬)\n- googleapis: ^148.0.0 (Google API ì§€ì›)\n- typescript: ^5.0.0\n- zod: ^3.24.2 (ë°ì´í„° ê²€ì¦)\n- pino: ^8.21.0 (ë¡œê¹…)\n\n## Claude ë°ìŠ¤í¬í†± ì•± í†µí•© ê°€ì´ë“œ\n\n### ì„¤ì • íŒŒì¼ ìœ„ì¹˜\nClaude ë°ìŠ¤í¬í†± ì•±ì˜ ì„¤ì • íŒŒì¼ì€ ë‹¤ìŒ ê²½ë¡œì— ìœ„ì¹˜í•©ë‹ˆë‹¤:\n- Windows: `%APPDATA%/Claude/config.json`\n- macOS: `~/Library/Application Support/Claude/config.json`\n\n### JSON ì„¤ì • ì˜ˆì‹œ\n\n```json\n{\n  \"apis\": [\n    {\n      \"name\": \"MCP Gemini\",\n      \"url\": \"http://localhost:8000\",\n      \"methods\": [\n        {\n          \"name\": \"í…ìŠ¤íŠ¸ ìƒì„±\",\n          \"method\": \"gem-generate\",\n          \"template\": {\n            \"jsonrpc\": \"2.0\",\n            \"id\": \"{uuid}\",\n            \"method\": \"gem-generate\",\n            \"params\": {\n              \"prompt\": \"{input}\"\n            }\n          }\n        },\n        {\n          \"name\": \"ì´ë¯¸ì§€ ìƒì„±\",\n          \"method\": \"gem-generate-image\",\n          \"template\": {\n            \"jsonrpc\": \"2.0\",\n            \"id\": \"{uuid}\",\n            \"method\": \"gem-generate-image\",\n            \"params\": {\n              \"prompt\": \"{input}\"\n            }\n          }\n        },\n        {\n          \"name\": \"ë¹„ë””ì˜¤ ë¶„ì„\",\n          \"method\": \"gem-analyze-video\",\n          \"template\": {\n            \"jsonrpc\": \"2.0\",\n            \"id\": \"{uuid}\",\n            \"method\": \"gem-analyze-video\",\n            \"params\": {\n              \"videoUrl\": \"{input}\",\n              \"query\": \"ì´ ì˜ìƒì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”\"\n            }\n          }\n        },\n        {\n          \"name\": \"ì›¹ ê²€ìƒ‰\",\n          \"method\": \"gem-search\",\n          \"template\": {\n            \"jsonrpc\": \"2.0\",\n            \"id\": \"{uuid}\",\n            \"method\": \"gem-search\",\n            \"params\": {\n              \"query\": \"{input}\"\n            }\n          }\n        }\n      ]\n    }\n  ]\n}\n```\n\n### ë³€ìˆ˜ ì„¤ëª…\n\n- `{uuid}`: ìë™ìœ¼ë¡œ ìƒì„±ë˜ëŠ” ê³ ìœ  ìš”ì²­ ID\n- `{input}`: Claude ì±„íŒ…ì°½ì— ì…ë ¥í•œ í…ìŠ¤íŠ¸\n\n### ì‚¬ìš© ë°©ë²•\n\n1. Claude ë°ìŠ¤í¬í†± ì•±ì˜ ì„¤ì • íŒŒì¼ì„ ì—½ë‹ˆë‹¤.\n2. ìœ„ì˜ JSON ì„¤ì •ì„ ê¸°ì¡´ ì„¤ì •ì— ì¶”ê°€í•©ë‹ˆë‹¤.\n3. Claude ë°ìŠ¤í¬í†± ì•±ì„ ì¬ì‹œì‘í•©ë‹ˆë‹¤.\n4. ì±„íŒ…ì°½ì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n\n```\n@MCP Gemini.í…ìŠ¤íŠ¸ ìƒì„± í•œêµ­ì˜ ì „í†µ ìŒì‹ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”\n@MCP Gemini.ì´ë¯¸ì§€ ìƒì„± í•œì˜¥ë§ˆì„ì˜ ì•„ë¦„ë‹¤ìš´ í’ê²½\n@MCP Gemini.ë¹„ë””ì˜¤ ë¶„ì„ https://youtube.com/watch?v=VIDEO_ID\n@MCP Gemini.ì›¹ ê²€ìƒ‰ ìµœì‹  ì¸ê³µì§€ëŠ¥ ê¸°ìˆ  ë™í–¥\n```\n\n### ì‘ë‹µ í˜•ì‹\n\nëª¨ë“  API ì‘ë‹µì€ ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¦…ë‹ˆë‹¤:\n\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"ìš”ì²­ì—ì„œ ë³´ë‚¸ ID\",\n  \"result\": {\n    \"content\": \"ì‘ë‹µ ë‚´ìš©\"\n  }\n}\n```\n\n### ì˜¤ë¥˜ ì‘ë‹µ\n\nì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš° ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•©ë‹ˆë‹¤:\n\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"ìš”ì²­ì—ì„œ ë³´ë‚¸ ID\",\n  \"error\": {\n    \"code\": ì˜¤ë¥˜ì½”ë“œ,\n    \"message\": \"ì˜¤ë¥˜ ë©”ì‹œì§€\",\n    \"data\": {\n      \"details\": \"ìƒì„¸ ì˜¤ë¥˜ ì •ë³´\"\n    }\n  }\n}\n```\n\n## ì˜¤ë¥˜ ì²˜ë¦¬\n\nì„œë²„ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ìƒí™©ì—ì„œ ì ì ˆí•œ ì˜¤ë¥˜ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤:\n\n- 400: ì˜ëª»ëœ ìš”ì²­ í˜•ì‹\n- 401: ì¸ì¦ ì˜¤ë¥˜ (API í‚¤ ê´€ë ¨)\n- 500: ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜\n\n## ë³´ì•ˆ ê³ ë ¤ì‚¬í•­\n\n- API í‚¤ëŠ” ë°˜ë“œì‹œ í™˜ê²½ ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ì„¸ìš”\n- í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ì ì ˆí•œ ë³´ì•ˆ ì„¤ì •ì„ ì¶”ê°€í•˜ì„¸ìš”\n- ë¯¼ê°í•œ ì •ë³´ëŠ” ë¡œê·¸ì— ê¸°ë¡í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”\n\n## ë¬¸ì œ í•´ê²°\n\n### í¬íŠ¸ ì¶©ëŒ\nì´ë¯¸ 8000ë²ˆ í¬íŠ¸ê°€ ì‚¬ìš© ì¤‘ì¸ ê²½ìš°:\n```bash\n# ê¸°ì¡´ Node.js í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ\npkill -f \"node\"\n```\n\n### ì„œë²„ ì•ˆì •ì„±\nì„œë²„ê°€ ì˜ˆê¸°ì¹˜ ì•Šê²Œ ì¢…ë£Œë˜ëŠ” ê²½ìš°:\n- PM2ë‚˜ ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬ì ì‚¬ìš©ì„ ê³ ë ¤í•˜ì„¸ìš”\n- ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ì¢…ë£Œ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”\n\n## ê°œë°œ ê°€ì´ë“œ\n\n### ë¡œê¹…\n- Pino ë¡œê±°ë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ ë¡œê¹…ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤\n- ê°œë°œ í™˜ê²½ì—ì„œëŠ” pino-prettyë¥¼ í†µí•´ ê°€ë…ì„± ìˆëŠ” ë¡œê·¸ê°€ ì¶œë ¥ë©ë‹ˆë‹¤\n\n### íƒ€ì… ì•ˆì •ì„±\n- TypeScriptì™€ Zodë¥¼ ì‚¬ìš©í•˜ì—¬ ëŸ°íƒ€ì„ íƒ€ì… ì•ˆì •ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤\n- API ìš”ì²­/ì‘ë‹µì— ëŒ€í•œ ìŠ¤í‚¤ë§ˆ ê²€ì¦ì´ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤\n\n## CLINE MCP ë§ˆì¼“í”Œë ˆì´ìŠ¤ ë“±ë¡ ê°€ì´ë“œ\n\n### ì‚¬ì „ ì¤€ë¹„ì‚¬í•­\n\n1. GitHub ì €ì¥ì†Œê°€ ê³µê°œë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤\n2. README.md íŒŒì¼ì— ëª…í™•í•œ ì„¤ì¹˜ ë° ì„¤ì • ë°©ë²•ì´ í¬í•¨ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤\n3. (ì„ íƒì‚¬í•­) `llms-install.md` íŒŒì¼ì„ í†µí•´ AI ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ ì¶”ê°€ ì„¤ì¹˜ ê°€ì´ë“œë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n\n### ë“±ë¡ ì ˆì°¨\n\n1. [CLINE MCP ë§ˆì¼“í”Œë ˆì´ìŠ¤ ì €ì¥ì†Œ](https://github.com/cline/mcp-marketplace)ì— ìƒˆë¡œìš´ ì´ìŠˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤\n\n2. ì´ìŠˆì— ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤:\n   - **GitHub ì €ì¥ì†Œ URL:** https://github.com/techkwon/mcp-gemini\n   - **ë¡œê³  ì´ë¯¸ì§€:** 400Ã—400 í¬ê¸°ì˜ PNG íŒŒì¼\n   - **ì¶”ê°€ ì´ìœ :** ì´ MCP ì„œë²„ê°€ CLINE ì‚¬ìš©ìë“¤ì—ê²Œ ì œê³µí•  ìˆ˜ ìˆëŠ” ê°€ì¹˜\n   ì˜ˆì‹œ:\n   ```markdown\n   ## MCP Gemini ì„œë²„ ë“±ë¡ ìš”ì²­\n   \n   ### GitHub ì €ì¥ì†Œ\n   https://github.com/techkwon/mcp-gemini\n   \n   ### ì£¼ìš” ê¸°ëŠ¥\n   - Gemini APIë¥¼ í™œìš©í•œ í…ìŠ¤íŠ¸ ìƒì„±\n   - ì´ë¯¸ì§€ ìƒì„± ë° í¸ì§‘ (gemini-2.0-flash-exp ëª¨ë¸ ì‚¬ìš©)\n   - YouTube ë¹„ë””ì˜¤ ì½˜í…ì¸  ë¶„ì„\n   - ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥\n   \n   ### ì‚¬ìš©ì ì´ì \n   - ìµœì‹  Gemini ëª¨ë¸ì„ MCP í”„ë¡œí† ì½œì„ í†µí•´ ì‰½ê²Œ í™œìš©\n   - ë‹¤ì–‘í•œ ë¯¸ë””ì–´ í˜•ì‹(í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ë¹„ë””ì˜¤) ì²˜ë¦¬ ê°€ëŠ¥\n   - ëª…í™•í•œ JSON-RPC ì¸í„°í˜ì´ìŠ¤ë¡œ ì‰¬ìš´ í†µí•©\n   - ìƒì„¸í•œ ë¬¸ì„œí™”ì™€ ì˜ˆì œ ì œê³µ\n   ```\n\n3. CLINEì´ README.mdë§Œìœ¼ë¡œ ì„œë²„ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì„¤ì¹˜í•  ìˆ˜ ìˆëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤\n\n### ìŠ¹ì¸ ì ˆì°¨\n\n1. CLINE íŒ€ì´ ì œì¶œëœ MCP ì„œë²„ë¥¼ ê²€í† í•©ë‹ˆë‹¤\n2. ë³´ì•ˆ ë° ì•ˆì •ì„± ê²€ì¦ì„ ì§„í–‰í•©ë‹ˆë‹¤\n3. ìŠ¹ì¸ë˜ë©´ ë§ˆì¼“í”Œë ˆì´ìŠ¤ì— ë“±ë¡ë˜ì–´ ëª¨ë“  CLINE ì‚¬ìš©ìê°€ ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤\n\n### ì„¤ì¹˜ ê°€ì´ë“œ ìµœì í™”\n\n`llms-install.md` íŒŒì¼ì„ ìƒì„±í•˜ì—¬ AI ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ ì¶”ê°€ ì„¤ì¹˜ ê°€ì´ë“œë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n\n```markdown\n# MCP Gemini ì„œë²„ ì„¤ì¹˜ ê°€ì´ë“œ (AI ì—ì´ì „íŠ¸ìš©)\n\n## í™˜ê²½ ìš”êµ¬ì‚¬í•­\n- Node.js 18.0.0 ì´ìƒ\n- npm ë˜ëŠ” yarn\n- Google AI Studio API í‚¤\n\n## ì„¤ì¹˜ ë‹¨ê³„\n1. ì €ì¥ì†Œ í´ë¡ \n2. ì˜ì¡´ì„± ì„¤ì¹˜: `npm install`\n3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •: GOOGLE_API_KEY ì¶”ê°€\n4. ë¹Œë“œ: `npm run build`\n5. ì„œë²„ ì‹¤í–‰: `npm run start`\n\n## ì„¤ì • ê²€ì¦\n- 8000ë²ˆ í¬íŠ¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n- API í‚¤ ìœ íš¨ì„± ê²€ì¦\n- CORS ì„¤ì • í™•ì¸\n\n## ë¬¸ì œ í•´ê²°\n- í¬íŠ¸ ì¶©ëŒ ì‹œ í•´ê²° ë°©ë²•\n- API í‚¤ ì˜¤ë¥˜ í•´ê²° ë°©ë²•\n- ì¼ë°˜ì ì¸ ì„¤ì¹˜ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ\n``` ",
      "npm_url": "",
      "npm_downloads": 0
    },
    "Tencent--cos-mcp": {
      "owner": "Tencent",
      "name": "cos-mcp",
      "url": "https://github.com/Tencent/cos-mcp",
      "imageUrl": "https://github.com/Tencent.png",
      "description": "Integrate large language models with Tencent Cloud Object Storage (COS) and Data Insight (CI), enabling file management, automated cloud data handling, and various image and video processing tasks. Supports natural language-based metadata search and efficient backup workflows.",
      "stars": 15,
      "forks": 6,
      "license": "Other",
      "language": "TypeScript",
      "updated_at": "2025-10-02T12:48:08Z",
      "readme_content": "ä¸­æ–‡ | [English](README.en.md)\n\n# è…¾è®¯äº‘ COS MCP Server ğŸš€ğŸš€ğŸš€\n ![](https://badge.mcpx.dev?type=server 'MCP Server') [![npm Version](https://img.shields.io/npm/v/cos-mcp)](https://www.npmjs.com/package/cos-mcp) [![license](http://img.shields.io/badge/license-BSD3-brightgreen.svg?style=flat)](License.txt)\n\n<p align=\"center\">\n  <img alt=\"logo\" src=\"https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/logo.png\"/>\n</p>\n\nåŸºäº MCP åè®®çš„è…¾è®¯äº‘ COS MCP Serverï¼Œæ— éœ€ç¼–ç å³å¯è®©å¤§æ¨¡å‹å¿«é€Ÿæ¥å…¥è…¾è®¯äº‘å­˜å‚¨ (COS) å’Œæ•°æ®ä¸‡è±¡ (CI) èƒ½åŠ›ã€‚\n\n---\n\n## âœ¨ æ ¸å¿ƒåŠŸèƒ½\n\n### äº‘ç«¯å­˜å‚¨èƒ½åŠ›\n- â¬†ï¸ æ–‡ä»¶ä¸Šä¼ åˆ°äº‘ç«¯\n- â¬‡ï¸ æ–‡ä»¶ä»äº‘ç«¯ä¸‹è½½\n- ğŸ“‹ è·å–äº‘ç«¯æ–‡ä»¶åˆ—è¡¨\n\n### äº‘ç«¯å¤„ç†èƒ½åŠ›\n- ğŸ–¼ï¸ è·å–å›¾ç‰‡ä¿¡æ¯\n- ğŸ” å›¾ç‰‡è¶…åˆ†è¾¨ç‡\n- âœ‚ï¸ å›¾ç‰‡è£å‰ª\n- ğŸ“² äºŒç»´ç è¯†åˆ«\n- ğŸ† å›¾ç‰‡è´¨é‡è¯„ä¼°\n- ğŸ…°ï¸ æ–‡å­—æ°´å°\n- ğŸ¬ å…ƒæ•°æ®/è‡ªç„¶è¯­è¨€æ£€ç´¢ (MateInsight)\n- ğŸ“„ æ–‡æ¡£è½¬ PDF\n- ğŸ¥ è§†é¢‘å°é¢\n\n---\n\n## ğŸ’¡ å…¸å‹åº”ç”¨åœºæ™¯\n\n- ä½¿ç”¨å…¶ä»– MCP èƒ½åŠ›è·å–çš„æ–‡æœ¬/å›¾ç‰‡/è§†é¢‘/éŸ³é¢‘ç­‰æ•°æ®ï¼Œå¯ç›´æ¥ä¸Šä¼ åˆ° COS äº‘ç«¯å­˜å‚¨ã€‚\n- æœ¬åœ°æ•°æ®å¿«é€Ÿé€šè¿‡å¤§æ¨¡å‹è½¬å­˜åˆ° COS äº‘ç«¯å­˜å‚¨/å¤‡ä»½ã€‚\n- é€šè¿‡å¤§æ¨¡å‹å®ç°è‡ªåŠ¨åŒ–ï¼šå°†ç½‘é¡µé‡Œçš„è§†é¢‘/å›¾ç‰‡/éŸ³é¢‘/æ–‡æœ¬ç­‰æ•°æ®æ‰¹é‡è½¬å­˜åˆ° COS äº‘ç«¯å­˜å‚¨ã€‚\n- è‡ªåŠ¨åŒ–å°†è§†é¢‘/å›¾ç‰‡/éŸ³é¢‘/æ–‡æœ¬ç­‰æ•°æ®åœ¨äº‘ç«¯å¤„ç†ï¼Œå¹¶è½¬å­˜åˆ° COS äº‘ç«¯å­˜å‚¨ã€‚\n\n---\n\n## ğŸŒŸ åŠŸèƒ½ç¤ºä¾‹\n\n1. ä¸Šä¼ æ–‡ä»¶åˆ° COS  \n   ![eg1](https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/eg1.png)\n2. å›¾ç‰‡è´¨é‡è¯„ä¼°  \n   ![eg3](https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/eg3.png)\n3. è‡ªç„¶è¯­è¨€æ£€ç´¢å›¾ç‰‡  \n   ![eg2](https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/eg2.png)\n4. è§†é¢‘æˆªå¸§  \n   ![eg15](https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/eg15.png)\n\n---\n\n# ğŸ”§ å®‰è£…ä½¿ç”¨\n\n## å‚æ•°è¯´æ˜\n\nä¸ºäº†ä¿æŠ¤æ‚¨çš„æ•°æ®ç§å¯†æ€§ï¼Œè¯·å‡†å¤‡ä»¥ä¸‹å‚æ•°ï¼š\n\n### 1. **SecretId / SecretKey**\n- **è¯´æ˜**: è…¾è®¯äº‘ COS çš„å¯†é’¥ï¼Œç”¨äºèº«ä»½è®¤è¯ï¼Œè¯·å¦¥å–„ä¿ç®¡ï¼Œåˆ‡å‹¿æ³„éœ²ã€‚\n- **è·å–æ–¹å¼**: \n  1. è®¿é—® [è…¾è®¯äº‘å¯†é’¥ç®¡ç†](https://console.cloud.tencent.com/cam/capi)ã€‚\n  2. æ–°å»ºå¯†é’¥å¹¶å¤åˆ¶ç”Ÿæˆçš„ **SecretId** å’Œ **SecretKey**ã€‚\n\n### 2. **Bucket**\n- **ç¤ºä¾‹**: `mybucket-123456`\n- **è¯´æ˜**: å­˜å‚¨æ¡¶åç§°ï¼Œç”¨äºå­˜æ”¾æ•°æ®ï¼Œç›¸å½“äºæ‚¨çš„ä¸ªäººå­˜å‚¨ç©ºé—´ã€‚\n- **è·å–æ–¹å¼**: \n  1. è®¿é—® [å­˜å‚¨æ¡¶åˆ—è¡¨](https://console.cloud.tencent.com/cos/bucket)ã€‚\n  2. å¤åˆ¶å­˜å‚¨æ¡¶åç§°ã€‚å¦‚æœæ²¡æœ‰å­˜å‚¨æ¡¶ï¼Œå¯ç‚¹å‡»â€œåˆ›å»ºå­˜å‚¨æ¡¶â€ï¼Œä¸€èˆ¬é€‰æ‹©é»˜è®¤é…ç½®å³å¯å¿«é€Ÿå®Œæˆåˆ›å»ºã€‚\n\n### 3. **Region**\n- **ç¤ºä¾‹**: `ap-beijing`\n- **è¯´æ˜**: å­˜å‚¨æ¡¶æ‰€åœ¨çš„åœ°åŸŸã€‚\n- **è·å–æ–¹å¼**: \n  1. åœ¨ [å­˜å‚¨æ¡¶åˆ—è¡¨](https://console.cloud.tencent.com/cos/bucket) ä¸­æ‰¾åˆ°å­˜å‚¨æ¡¶ã€‚\n  2. åœ¨å­˜å‚¨æ¡¶åç§°ä¸€è¡ŒæŸ¥çœ‹æ‰€å±åœ°åŸŸå¹¶å¤åˆ¶ï¼Œä¾‹å¦‚ï¼š`ap-beijing`ã€‚\n\n### 4. **DatasetName**\n- **è¯´æ˜**: éå¿…å¡«å‚æ•°ï¼Œæ•°æ®æ™ºèƒ½æ£€ç´¢æ“ä½œéœ€è¦æ­¤å‚æ•°ã€‚\n- **è·å–æ–¹å¼**: \n  1. è®¿é—® [æ•°æ®é›†ç®¡ç†](https://console.cloud.tencent.com/cos/metaInsight/dataManage)ã€‚\n  2. åˆ›å»ºæ•°æ®é›†å¹¶ç­‰å¾…ç´¢å¼•å»ºç«‹å®Œæˆåï¼Œå¤åˆ¶æ•°æ®é›†åç§°ã€‚\n\n### 5. **connectType**\n- **è¯´æ˜**: éå¿…å¡«å‚æ•°ï¼ŒæŒ‡å®šè¿æ¥æ–¹å¼ï¼Œå¯é€‰å€¼ä¸º `stdio`ï¼ˆæœ¬åœ°ï¼‰æˆ– `sse`ï¼ˆè¿œç¨‹ï¼‰ã€‚\n- **é»˜è®¤å€¼**: `stdio`\n\n### 6. **port**\n- **è¯´æ˜**: éå¿…å¡«å‚æ•°ï¼Œå½“è¿æ¥æ–¹å¼ä¸º `sse` æ—¶ï¼Œå¯è‡ªç”±è®¾ç½®ç«¯å£ã€‚\n- **é»˜è®¤å€¼**: `3001`\n\n---\n\n## ä» npx å¯åŠ¨\n\nåœ¨å¤§æ¨¡å‹å†…ä½¿ç”¨æ—¶ï¼ˆä¾‹å¦‚: cursorï¼‰ï¼Œéœ€è¦åœ¨ `mcp.json` ä¸­é…ç½®ï¼š\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"cos-mcp\",\n        \"--Region=yourRegion\",\n        \"--Bucket=yourBucket\",\n        \"--SecretId=yourSecretId\",\n        \"--SecretKey=yourSecretKey\",\n        \"--DatasetName=yourDatasetname\"\n      ]\n    }\n  }\n}\n```\n\nä¹Ÿå¯ä»¥é€šè¿‡ JSON é…ç½®ï¼š\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"cos-mcp\",\n        \"--cos-config='{\\\"Region\\\":\\\"yourRegion\\\",\\\"Bucket\\\":\\\"yourBucket\\\",\\\"SecretId\\\":\\\"yourSecretId\\\",\\\"SecretKey\\\":\\\"yourSecretKey\\\",\\\"DatasetName\\\":\\\"yourDatasetname\\\"}'\"\n      ]\n    }\n  }\n}\n```\n\n---\n\n## ä½¿ç”¨ npm å®‰è£…\n\n```bash\n# å®‰è£…\nnpm install -g cos-mcp@latest\n\n# è¿è¡Œå¼€å¯ SSE æ¨¡å¼\ncos-mcp --Region=yourRegion --Bucket=yourBucket --SecretId=yourSecretId --SecretKey=yourSecretKey --DatasetName=yourDatasetname --port=3001 --connectType=sse\n\n# æˆ–é€šè¿‡ JSON é…ç½®\ncos-mcp --cos-config='{\"Region\":\"yourRegion\",\"Bucket\":\"BucketName-APPID\",\"SecretId\":\"yourSecretId\",\"SecretKey\":\"yourSecretKey\",\"DatasetName\":\"datasetName\"}' --port=3001 --connectType=sse\n```\n\nåœ¨å¤§æ¨¡å‹å†…ä½¿ç”¨ SSE æ¨¡å¼æ—¶ï¼ˆä¾‹å¦‚: cursorï¼‰ï¼Œéœ€è¦åœ¨ `mcp.json` ä¸­é…ç½®ï¼š\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"url\": \"http://localhost:3001/sse\"\n    }\n  }\n}\n```\n\n---\n\n## ä½¿ç”¨æºç å®‰è£…\n\n### æ­¥éª¤ 1: å…‹éš†é¡¹ç›®ä»£ç \n\n```bash\ngit clone https://github.com/Tencent/cos-mcp.git\ncd cos-mcp\n```\n\n### æ­¥éª¤ 2: å®‰è£…ä¾èµ–\n\n```bash\nnpm install\n```\n\n### æ­¥éª¤ 3: å¯åŠ¨æœåŠ¡\n\n#### 3.1 é…ç½®æœ¬åœ°ç¯å¢ƒå˜é‡\n\nåˆ›å»º `.env` æ–‡ä»¶ï¼Œå¹¶é…ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š\n\n```env\nRegion='yourRegion'\nBucket='yourBucket'\nSecretId='yourSecretId'\nSecretKey='yourSecretKey'\nDatasetName=\"yourDatasetName\"\n```\n\n#### 3.2 æœ¬åœ° SSE æ¨¡å¼å¯åŠ¨ï¼ˆæ–¹å¼ä¸€ï¼‰\n\n```bash\nnpm run start:sse\n```\n\n#### 3.3 æœ¬åœ°æ„å»ºåä½¿ç”¨ STDIO æ¨¡å¼ï¼ˆæ–¹å¼äºŒï¼‰\n\n```bash\nnpm run build\n```\n\næ„å»ºäº§ç‰©ä½äº `dist/index.js`ã€‚\n\n---\n\n### æ­¥éª¤ 4: åœ¨å¤§æ¨¡å‹å†…ä½¿ç”¨\n\n#### SSE æ¨¡å¼é…ç½®\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"url\": \"http://localhost:3001/sse\"\n    }\n  }\n}\n```\n\n#### STDIO æ¨¡å¼é…ç½®\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"${your work space}/dist/index.js\"\n      ]\n    }\n  }\n}\n```\n\nå®Œæˆä»¥ä¸Šæ­¥éª¤åï¼Œå³å¯é€šè¿‡æºç è¿è¡Œ COS MCP Serverã€‚\n\n---\n\n## âš ï¸ æ³¨æ„äº‹é¡¹\n\n1. å¦‚æœå®‰è£…äº†æ—§ç‰ˆæœ¬çš„åŒ…ï¼Œå¯ä»¥å°†ä¸Šè¿°å†…å®¹å†… `cos-mcp` æ”¹ä¸º `cos-mcp@latest` å®‰è£…æœ€æ–°ç‰ˆåŒ…ã€‚\n2. å¦‚æœå…¨å±€å®‰è£…åç›´æ¥ä½¿ç”¨ `cos-mcp` ä¸è¡Œï¼Œå¯èƒ½æ˜¯å…¨å±€å˜é‡æœ‰é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨æ‹†åˆ†å˜é‡æˆ– `npx` çš„æ–¹å¼å¯åŠ¨ï¼š\n   ```bash\n   npm install -g cos-mcp@latest\n   cos-mcp --cos-config=xxx --port=3001 --connectType=sse\n   ```\n   ä¸Šè¿°å‘½ä»¤æ•ˆæœç­‰åŒäºï¼š\n   ```bash\n   npx cos-mcp@latest --cos-config=xxx --port=3001 --connectType=sse\n   ```\n3. å¦‚æœå‡ºç°è§£æé—®é¢˜ï¼Œå¯èƒ½æ˜¯ç»ˆç«¯å¯¹åŒå¼•å·æ•æ„Ÿï¼Œå¯ä»¥å°†é…ç½®å‚æ•°æ”¹ä¸ºä»¥ä¸‹æ ¼å¼å†å°è¯•ï¼š\n   ```bash\n   --cos-config='{\\\"Region\\\":\\\"yourRegion\\\",\\\"Bucket\\\":\\\"BucketName-APPID\\\",\\\"SecretId\\\":\\\"yourSecretId\\\",\\\"SecretKey\\\":\\\"yourSecretKey\\\",\\\"DatasetName\\\":\\\"datasetName\\\"}' --port=3001 --connectType=sse\n   ```\n\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "tuki0918--eagle-mcp-server": {
      "owner": "tuki0918",
      "name": "eagle-mcp-server",
      "url": "https://github.com/tuki0918/eagle-mcp-server",
      "imageUrl": "https://github.com/tuki0918.png",
      "description": "Integrates with the Eagle app to manage and interact with digital assets through a standardized MCP interface, enabling operations such as folder and item management, metadata retrieval, and media handling.",
      "stars": 3,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-22T11:24:54Z",
      "readme_content": "# Eagle MCP Server (Unofficial)\n\n> [!NOTE]\n> [Official MCP support is planned for Eagle v5 (public beta in Q1 2026)](https://eagle.cool/blog/post/eagle5-teaser)\n\n![](.github/docs/cover.png)\n\nA Model Context Protocol (MCP) server for Eagle.\n\n<details>\n\n<summary>Supported file formats:</summary>\n\n- `JPG` / `JPEG`\n- `PNG`\n- `PDF`\n- `SVG`\n- `MP4`\n- `MP3`\n- `FBX`\n- `OBJ`\n- `EPS`\n- `TIF` / `TIFF`\n- `WebP`\n- `BMP`\n- `ICO`\n- `RAW`\n- etc\n\n</details>\n\n- Eagle: https://eagle.cool/<br />\n- Eagle API docs: https://api.eagle.cool/<br />\n\n## Requirements\n\n- Python 3.13\n- [uv](https://docs.astral.sh/uv/)\n\n## Prerequisites\n\nInstall the required dependencies:\n\n```bash\nuv sync\n```\n\n## Usage\n\n1. Launch the [Eagle](https://eagle.cool/) app.\n2. Launch this MCP server by running the following command:\n\n```bash\nuv run main.py\n```\n\n\n## Connecting to the MCP Server using Streamable HTTP\n\nExample config (Cursor editor recommended):\n\n```\n{\n  \"mcpServers\": {\n    \"eagle-mcp-server\": {\n      \"url\": \"http://localhost:8000/mcp\"\n    }\n  }\n}\n```\n\n## Tools\n\n| Supported | Eagle API endpoint | Operation ID | Enabled (default) | Category |\n|:----:|:---------------------------|:-------------------------|:----:|:------------|\n| âœ… | -               | `connect`                |  | MCP         |\n| âœ… | /api/application/info      | `get_application_info`   | âš«ï¸ | Application |\n| âœ… | /api/folder/create         | `create_folder`          | âš«ï¸ | Folder      |\n| âœ… | /api/folder/rename         | `rename_folder`          |  | Folder      |\n| âœ… | /api/folder/update         | `update_folder`          | âš«ï¸ | Folder      |\n| âœ… | /api/folder/list           | `get_folder_list`        | âš«ï¸ | Folder      |\n| âœ… | /api/folder/listRecent     | `get_folder_list_recent` |  | Folder      |\n| âœ… | /api/item/addFromURL       | `add_item_from_url`      |  | Item        |\n| âœ… | /api/item/addFromURLs      | `add_items_from_urls`    |  | Item        |\n| âœ… | /api/item/addFromPath      | `add_item_from_path`     | âš«ï¸ | Item        |\n| âœ… | /api/item/addFromPaths     | `add_items_from_paths`   |  | Item        |\n| âœ… | /api/item/addBookmark      | `add_bookmark`           |  | Item        |\n| âœ… | /api/item/info             | `get_item_info`          | âš«ï¸ | Item        |\n| âœ… | -           | `get_item_source`        | âš«ï¸ | Item        |\n| âœ… | /api/item/thumbnail        | `get_item_thumbnail`     |  | Item        |\n| âœ… | /api/item/list             | `get_item_list`          | âš«ï¸ | Item        |\n| âœ… | /api/item/moveToTrash      | `move_item_to_trash`     | âš«ï¸ | Item        |\n| âœ… | /api/item/refreshPalette   | `refresh_item_palette`   |  | Item        |\n| âœ… | /api/item/refreshThumbnail | `refresh_item_thumbnail` |  | Item        |\n| âœ… | /api/item/update           | `update_item`            | âš«ï¸ | Item        |\n| âœ… | /api/library/info          | `get_library_info`       | âš«ï¸ | Library     |\n| âœ… | /api/library/history       | `get_library_history`    |  | Library     |\n| âœ… | /api/library/switch        | `switch_library`         |  | Library     |\n| âœ… | /api/library/icon          | `get_library_icon`       |  | Library     |\n\nMCP Server API docs: \n- https://tuki0918.github.io/eagle-mcp-server/\n- http://localhost:8000/redoc\n\n## Enabling Disabled Tools\n\nSome tools are disabled by default (shown as empty cells in the \"Enabled (default)\" column above). To enable these disabled tools:\n\n1. Locate the tool definition in the source code\n2. Remove the `tags=[\"Disabled\"]` line from the tool configuration\n3. Restart the MCP server\n\nThis will make the previously disabled tools available for use.\n\n## Use Cases\n\n### 1) Same Host (Recommended)\n\n```mermaid\nflowchart LR\n\n    subgraph 192.168.1.100\n        direction LR\n        \n        subgraph FileSystem [File System]\n        end\n        subgraph EagleApp [Eagle App<br/>localhost:41595]\n        end\n        subgraph MCPServer [MCP Server<br/>localhost:8000]\n        end\n        subgraph MCPClient [MCP Client]\n        end\n    end\n\n    EagleApp ==> MCPServer e1@==> MCPClient\n    MCPClient e2@==> MCPServer ==> EagleApp\n    EagleApp ==> FileSystem\n    FileSystem ==> EagleApp\n\n    e1@{ animate: true }\n    e2@{ animate: true }\n```\n\n> [!TIP]\n> You have direct access to the filesystem.\n\n### 2) Other Host (MCP Client) + Same Host (MCP Server, Eagle App)\n\n```mermaid\nflowchart LR\n  \n    subgraph 192.168.1.100\n        subgraph FileSystem [File System]\n        end\n        subgraph EagleApp [Eagle App<br/>localhost:41595]\n        end\n        subgraph MCPServer [MCP Server<br/>localhost:8000]\n        end\n    end\n\n    subgraph 192.168.1.xxx\n        subgraph MCPClient [MCP Client]\n        end\n    end\n\n    EagleApp ==> MCPServer e1@==> MCPClient\n    MCPClient e2@==> MCPServer ==> EagleApp\n    EagleApp ==> FileSystem\n    FileSystem ==> EagleApp\n\n    e1@{ animate: true }\n    e2@{ animate: true }\n```\n\n> [!WARNING]\n> You don't have access to the filesystem.\n\n### 3) Other Host\n\n```mermaid\nflowchart LR\n\n    subgraph 192.168.1.100\n        subgraph FileSystem [File System]\n        end\n        subgraph EagleApp [Eagle App<br/>localhost:41595]\n        end\n    end\n\n    subgraph 192.168.1.101\n        subgraph MCPServer [MCP Server<br/>localhost:8000]\n        end\n    end\n\n    subgraph 192.168.1.xxx\n        subgraph MCPClient [MCP Client]\n        end\n    end\n\n    EagleApp ==> MCPServer e1@==> MCPClient\n    MCPClient e2@==> MCPServer ==> EagleApp\n    EagleApp ==> FileSystem\n    FileSystem ==> EagleApp\n\n    e1@{ animate: true }\n    e2@{ animate: true }\n```\n\n> [!WARNING]\n> You don't have access to the filesystem.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "tzafrir--mcp-server-replicate": {
      "owner": "tzafrir",
      "name": "mcp-server-replicate",
      "url": "https://github.com/tzafrir/mcp-server-replicate",
      "imageUrl": "https://github.com/tzafrir.png",
      "description": "Access various AI models hosted on Replicate through a standardized interface for image generation with customizable parameters, enabling output resizing and optimization. Future enhancements will include text and video generation features.",
      "stars": 3,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-05-05T06:38:38Z",
      "readme_content": "# MCP Server for Replicate\n\nA FastMCP server implementation for interfacing with Replicate's API. This server provides tools for accessing various AI models hosted on Replicate through a standardized interface.\n\n## Current Status: Early Alpha\n\nThis project is in early alpha development. Features and APIs may change significantly.\n\n### Currently Supported\n- Image generation models with:\n  - Model schema inspection\n  - Image generation with customizable parameters\n  - Output resizing and optimization\n\n## Roadmap\n\n### Planned Features\n1. Text Generation\n   - Support for text completion models\n   - Chat model integration\n   - Streaming support for real-time responses\n\n2. Video Generation\n   - Support for video generation models\n   - Video output handling and optimization\n   - Progress tracking for long-running generations\n\n3. Additional Features\n   - Model version management\n   - Better error handling and retries\n   - Caching for frequently used models\n   - Rate limiting and queue management\n\n## Setup\n\n1. Install dependencies:\n```bash\npip install -r requirements.txt\n```\n\n2. Set up your Replicate API token in `.env`:\n```\nREPLICATE_API_TOKEN=your_token_here\n```\n\n3. Run the server:\n```bash\nfastmcp dev server.py\n```\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "video-creator--ffmpeg-mcp": {
      "owner": "video-creator",
      "name": "ffmpeg-mcp",
      "url": "https://github.com/video-creator/ffmpeg-mcp",
      "imageUrl": "https://github.com/video-creator.png",
      "description": "Enables local video search, trimming, stitching, and playback through conversational commands using ffmpeg. Provides tools for finding, clipping, concatenating, and playing video files on macOS platforms.",
      "stars": 84,
      "forks": 14,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-04T04:24:05Z",
      "readme_content": "# FFmpeg-MCP\nUsing ffmpeg command line to achieve an mcp server, can be very convenient, through the dialogue to achieve the local video search, tailoring, stitching, playback and other functions\n\n<a href=\"https://glama.ai/mcp/servers/@video-creator/ffmpeg-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@video-creator/ffmpeg-mcp/badge\" alt=\"FFmpeg-Server MCP server\" />\n</a>\n\n## Support Tools\nThe server implements the following tools: <br/>\n- `find_video_path`\n  The parameters are directory and file name, file name can be complete, or is not suffixed, recursive search in the directory, return the full path\n- `get_video_info`\n  The parameters are video path, return the video info, linkes duration/fps/codec/width/height.\n- `clip_video`\n  The parameter is the file path, start time, end time or duration, and returns the trimmed file path\n- `concat_videos`\n  The parameters are the list of files, the output path, and if the video elements in the list of files, such as width, height, frame rate, etc., are consistent, quick mode synthesis is automatically used\n- `play_video`\n  Play video/audio with ffplay, support many format, like mov/mp4/avi/mkv/3gp, video_path: video path speed: play rate loop: play count\n- `overlay_video`\n  Two video overlay. <br/>\n  background_video: backgroud video path <br/>\n  overlay_video: front video path <br/>\n  output_path: output video path<br/>\n  position: relative location<br/>\n  dx: x offset<br/>\n  dy: y offset<br/>\n- `scale_video`\n  Video scale. <br/>\n  video_path: in video path <br/>\n  width: out video width, -2 keep aspect <br/>\n  height: out video height, -2 keep aspect <br/>\n  output_path: output video path <br/>\n- `extract_frames_from_video`\n  Extract images from a video.<br/>\n  Parameters: <br/>\n  video_path (str): The path to the video.<br/>\n  fps (int): Extract one frame every specified number of seconds. If set to 0, extract all frames; if set to 1, extract one frame per second.<br/>\n  output_folder (str): The directory where the images will be saved.<br/>\n  format (int): The format of the extracted images; 0: PNG, 1: JPG, 2: WEBP.<br/>\n  total_frames (int): The maximum number of frames to extract. If set to 0, there is no limit<br/>\n<br/>\nMore features are coming\n\n## Installation procedure\n1. Download project\n```\ngit clone  https://github.com/video-creator/ffmpeg-mcp.git\ncd ffmpeg-mcp\nuv sync\n```\n\n2. Configuration in Cline\n```\n{\n  \"mcpServers\": {\n    \"ffmpeg-mcp\": {\n      \"autoApprove\": [],\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/xxx/Downloads/ffmpeg-mcp\",\n        \"run\",\n        \"ffmpeg-mcp\"\n      ],\n      \"transportType\": \"stdio\"\n    }\n  }\n}\n```\nNote: the value:`/Users/XXX/Downloads/ffmpeg` in args  need to replace the actual download ffmpeg-mcp directory\n\n## Supported platforms\nCurrently, only macos platforms are supported, including ARM64 or x86_64",
      "npm_url": "",
      "npm_downloads": 0
    },
    "vishwa684--unet": {
      "owner": "vishwa684",
      "name": "unet",
      "url": "https://github.com/vishwa684/unet",
      "imageUrl": "https://github.com/vishwa684.png",
      "description": "Train and deploy U-Net models for biomedical image segmentation using the Medical Decathlon dataset, with support for both 2D and 3D U-Net scripts. Visualize predictions and assess model performance through comprehensive demos and visual outputs.",
      "stars": 0,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "",
      "updated_at": "2024-05-11T00:13:12Z",
      "readme_content": "# Deep Learning Medical Decathlon Demos for Python*\n### U-Net Biomedical Image Segmentation with Medical Decathlon Dataset.\n\nThis repository contains [2D](https://github.com/IntelAI/unet/tree/master/2D) and [3D](https://github.com/IntelAI/unet/tree/master/3D) U-Net scripts for training models using the [Medical Decathlon](http://medicaldecathlon.com/) dataset (http://medicaldecathlon.com/).\n\n![pred152_3D](https://github.com/IntelAI/unet/blob/master/3D/images/BRATS_152_img3D.gif\n\"BRATS image #152:  Purple voxels indicate a perfect prediction by the model. Red are false positives. Blue are false negatives\").  ![pred195](https://github.com/IntelAI/unet/blob/master/3D/images/BRATS_195_img.gif \"BRATS image #195:  Purple voxels indicate a perfect prediction by the model. Red are false positives. Blue are false negatives\")\n\n\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "wheattoast11--mcp-video-gen": {
      "owner": "wheattoast11",
      "name": "mcp-video-gen",
      "url": "https://github.com/wheattoast11/mcp-video-gen",
      "imageUrl": "https://github.com/wheattoast11.png",
      "description": "Generate videos and images from text prompts or existing images using advanced AI models, with capabilities for audio addition, content upscaling, and prompt enhancement. Manage and refine AI-generated content through API interactions with RunwayML and Luma AI.",
      "stars": 11,
      "forks": 2,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-09-24T02:58:53Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/wheattoast11-mcp-video-gen-badge.png)](https://mseep.ai/app/wheattoast11-mcp-video-gen)\n\n# RunwayML + Luma AI MCP Server\n\nThis MCP server provides tools to interact with the RunwayML and Luma AI APIs for video and image generation tasks.\n\n## Features\n\n*   Generate videos from text prompts (RunwayML or Luma AI).\n*   Generate videos from images (RunwayML or Luma AI).\n*   Generate images from text prompts (Luma AI).\n*   Manage Luma AI generations (list, get, delete).\n*   Add audio to Luma AI generations.\n*   Upscale Luma AI generations.\n*   Enhance prompts using OpenRouter LLMs before generation.\n\n## Prerequisites\n\n*   Node.js (v18 LTS or later recommended)\n*   npm (usually included with Node.js)\n*   API Keys:\n    *   RunwayML API Secret\n    *   Luma AI API Key\n    *   OpenRouter API Key (for the `enhance_prompt` tool)\n\n## Installation\n\n1.  **Clone or Download:** Obtain the server code.\n2.  **Navigate to Directory:** Open a terminal in the server's root directory (`runwayml-mcp-server`).\n3.  **Install Dependencies:**\n    ```bash\n    npm install\n    ```\n\n## Configuration\n\n1.  **Create `.env` file:** In the server's root directory, create a file named `.env`.\n2.  **Add API Keys:** Add your API keys to the `.env` file:\n    ```dotenv\n    RUNWAYML_API_SECRET=your_runwayml_api_secret_here\n    LUMAAI_API_KEY=your_luma_api_key_here\n    OPENROUTER_API_KEY=your_openrouter_api_key_here\n    ```\n    Replace the placeholder values with your actual keys.\n\n## Running the Server\n\n1.  **Build the Server:** Compile the TypeScript code:\n    ```bash\n    npm run build\n    ```\n2.  **Start the Server:**\n    ```bash\n    npm start\n    ```\n    You should see a message like `RunwayML MCP server running on stdio` in your terminal's error output (stderr).\n\n## MCP Client Setup (e.g., Claude Desktop App, Cline)\n\nConfigure your MCP client to connect to this server. The exact steps depend on the client, but you'll typically need to provide:\n\n*   **Name:** A descriptive name (e.g., `runway-luma-server`)\n*   **Command:** `node`\n*   **Arguments:** The full path to the compiled server index file (e.g., `/path/to/your/runwayml-mcp-server/build/server-index.js`)\n*   **Environment Variables:**\n    *   `RUNWAYML_API_SECRET`: Your RunwayML API Secret\n    *   `LUMAAI_API_KEY`: Your Luma AI API Key\n    *   `OPENROUTER_API_KEY`: Your OpenRouter API Key\n\n**Example Configuration (Conceptual):**\n\n```json\n{\n  \"mcpServers\": {\n    \"runway-luma-server\": {\n      \"command\": \"node\",\n      \"args\": [\"/full/path/to/runwayml-mcp-server/build/server-index.js\"],\n      \"env\": {\n        \"RUNWAYML_API_SECRET\": \"your_runwayml_api_secret_here\",\n        \"LUMAAI_API_KEY\": \"your_luma_api_key_here\",\n        \"OPENROUTER_API_KEY\": \"your_openrouter_api_key_here\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n*(Remember to replace `/full/path/to/` with the actual path on your system)*\n\n## Available Tools\n\n*   **`generate_text_to_video`**: Generates video from text.\n    *   `provider`: (Optional) `runwayml` (default) or `lumaai`.\n    *   `promptText`: (Required) The text prompt.\n    *   `runway_model`: (Optional) Runway model (e.g., \"gen-2\").\n    *   `runway_resolution`: (Optional) Runway resolution (`1280:768` or `768:1280`).\n    *   `runway_watermark`: (Optional) Boolean, default `false`.\n    *   `luma_model`: (Optional) Luma model (`ray-flash-2`, `ray-2` (default), `ray-1-6`).\n    *   `luma_aspect_ratio`: (Optional) Luma aspect ratio (e.g., `16:9` (default), `1:1`).\n    *   `luma_loop`: (Optional) Boolean.\n    *   `duration`: (Optional) Video duration in seconds (number).\n    *   `seed`: (Optional) Generation seed (number).\n*   **`generate_image_to_video`**: Generates video from an image.\n    *   `provider`: (Optional) `runwayml` (default) or `lumaai`.\n    *   `promptImage`: (Required) URL of the input image, or for Runway, an array `[{uri: \"url\", position: \"first\" | \"last\"}]`.\n    *   `promptText`: (Optional) Text prompt to accompany the image.\n    *   `runway_model`: (Optional) Runway model (`gen3a_turbo` (default)).\n    *   `runway_duration`: (Optional) Runway duration (`5` (default) or `10`).\n    *   `runway_ratio`: (Optional) Runway resolution (`1280:768` or `768:1280`).\n    *   `runway_watermark`: (Optional) Boolean, default `false`.\n    *   `luma_model`: (Optional) Luma model (`ray-flash-2`, `ray-2` (default), `ray-1-6`).\n    *   `luma_aspect_ratio`: (Optional) Luma aspect ratio (e.g., `16:9` (default)).\n    *   `luma_loop`: (Optional) Boolean.\n    *   `seed`: (Optional) Generation seed (number).\n*   **`enhance_prompt`**: Refines a prompt using OpenRouter.\n    *   `original_prompt`: (Required) The prompt to enhance.\n    *   `model`: (Optional) OpenRouter model name (defaults to a capable model like `anthropic/claude-3.5-sonnet`).\n    *   `instructions`: (Optional) Specific instructions for the enhancement.\n*   **`luma_generate_image`**: Generates an image using Luma AI.\n    *   `prompt`: (Required) Text prompt.\n    *   `aspect_ratio`: (Optional) Luma aspect ratio (`16:9` (default)).\n    *   `model`: (Optional) Luma image model (`photon-1` (default), `photon-flash-1`).\n    *   `image_ref`: (Optional) Array of image reference objects (`{url: string, weight?: number}`). Max 4.\n    *   `style_ref`: (Optional) Array of style reference objects (`{url: string, weight?: number}`). Max 1.\n    *   `character_ref`: (Optional) Character reference object (`{ identity0: { images: [url1, ...] } }`).\n    *   `modify_image_ref`: (Optional) Modify image reference object (`{url: string, weight?: number}`).\n*   **`luma_list_generations`**: Lists previous Luma AI generations.\n    *   `limit`: (Optional) Number of results (default 10).\n    *   `offset`: (Optional) Offset for pagination (default 0).\n*   **`luma_get_generation`**: Gets details for a specific Luma AI generation.\n    *   `generation_id`: (Required) UUID of the generation.\n*   **`luma_delete_generation`**: Deletes a specific Luma AI generation.\n    *   `generation_id`: (Required) UUID of the generation.\n*   **`luma_get_camera_motions`**: Lists supported camera motions for Luma AI prompts. (No parameters).\n*   **`luma_add_audio`**: Adds audio to a Luma generation.\n    *   `generation_id`: (Required) UUID of the generation.\n    *   `prompt`: (Required) Prompt for the audio.\n    *   `negative_prompt`: (Optional) Negative prompt for audio.\n*   **`luma_upscale`**: Upscales a Luma generation.\n    *   `generation_id`: (Required) UUID of the generation.\n    *   `resolution`: (Optional) Target resolution (`1080p` (default) or `4k`).\n\n*(Note: For tools involving generation (`generate_*`, `luma_upscale`), the server initiates the task and returns immediately. Progress updates and the final result URL will be sent via MCP progress notifications.)*\n\n## Example Workflows\n\nHere are examples of how to combine the server's tools for common use cases:\n\n### 1. Music Video Snippet (Cyberpunk Noir)\n\n**Goal:** Create a 5-second cyberpunk noir video clip for the lyric \"Neon rivers flowing through a city of chrome\".\n\n**Steps:**\n\n1.  **Generate Base Image (Luma):**\n    ```json\n    {\n      \"tool_name\": \"luma_generate_image\",\n      \"arguments\": {\n        \"prompt\": \"Overhead shot of a dark, rainy cyberpunk city street at night. Bright neon signs reflect on wet pavement, resembling rivers of light flowing between towering chrome skyscrapers. Film noir aesthetic, photorealistic.\",\n        \"aspect_ratio\": \"16:9\"\n      }\n    }\n    ```\n    *(Wait for image generation to complete and get the image URL)*\n\n2.  **Animate Image (Luma):**\n    ```json\n    {\n      \"tool_name\": \"generate_image_to_video\",\n      \"arguments\": {\n        \"provider\": \"lumaai\",\n        \"promptImage\": \"{IMAGE_URL_FROM_STEP_1}\",\n        \"promptText\": \"Slow pan left across the rainy cyberpunk cityscape, neon lights flickering subtly.\",\n        \"luma_aspect_ratio\": \"16:9\",\n        \"duration\": 5\n      }\n    }\n    ```\n    *(Wait for video generation to complete)*\n\n### 2. Product Ad Concept (Floating Earbud)\n\n**Goal:** Create a 5-second video showing a futuristic earbud floating in a minimalist environment.\n\n**Steps:**\n\n1.  **Generate Scene with Product Reference (Luma):**\n    ```json\n    {\n      \"tool_name\": \"luma_generate_image\",\n      \"arguments\": {\n        \"prompt\": \"A single, sleek futuristic wireless earbud floats weightlessly in the center of a bright, minimalist white room with soft, diffused ambient light. Zero gravity effect.\",\n        \"aspect_ratio\": \"1:1\",\n        \"image_ref\": [{ \"url\": \"{PRODUCT_IMAGE_URL}\", \"weight\": 0.8 }]\n      }\n    }\n    ```\n    *(Wait for image generation to complete and get the image URL)*\n\n2.  **Animate Scene (Luma):**\n    ```json\n    {\n      \"tool_name\": \"generate_image_to_video\",\n      \"arguments\": {\n        \"provider\": \"lumaai\",\n        \"promptImage\": \"{IMAGE_URL_FROM_STEP_1}\",\n        \"promptText\": \"The earbud slowly rotates and drifts gently in zero gravity.\",\n        \"luma_aspect_ratio\": \"1:1\",\n        \"duration\": 5\n      }\n    }\n    ```\n    *(Wait for video generation to complete)*\n\n### 3. Image Animation (RunwayML Gen3a)\n\n**Goal:** Animate an existing image using RunwayML's Gen3a model.\n\n**Steps:**\n\n1.  **(Optional) Generate Base Image (Luma):** Use `luma_generate_image` if you don't have an image.\n2.  **Animate Image (RunwayML):**\n    ```json\n    {\n      \"tool_name\": \"generate_image_to_video\",\n      \"arguments\": {\n        \"provider\": \"runwayml\",\n        \"promptImage\": \"{YOUR_IMAGE_URL}\",\n        \"promptText\": \"Subtle zoom in, cinematic lighting.\",\n        \"runway_model\": \"gen3a_turbo\",\n        \"runway_duration\": \"5\",\n        \"runway_ratio\": \"1280:768\" // Or \"768:1280\"\n      }\n    }\n    ```\n    *(Wait for video generation to complete)*\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "whiteking64--macos-ocr-mcp": {
      "owner": "whiteking64",
      "name": "macos-ocr-mcp",
      "url": "https://github.com/whiteking64/macos-ocr-mcp",
      "imageUrl": "https://github.com/whiteking64.png",
      "description": "Perform Optical Character Recognition (OCR) on images with the help of macOS's Vision framework, extracting recognized text segments, confidence scores, and bounding box coordinates. Suitable for applications that require text extraction from image files.",
      "stars": 1,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-06-07T18:16:13Z",
      "readme_content": "# macOS OCR MCP Tool\n\nThis project provides a MetaCall Protocol (MCP) tool to perform Optical Character Recognition (OCR) on images using macOS's built-in Vision framework. It exposes an `ocr_image` tool that takes an image file path and returns the recognized text along with confidence scores and bounding boxes.\n\n## Project Setup\n\n### Dependencies\nThis project relies on Python 3.13+ and the following main dependencies:\n- `ocrmac`: For accessing macOS OCR capabilities. See [ocrmac](https://github.com/straussmaximilian/ocrmac).\n- `Pillow`: For image manipulation.\n- `mcp[cli]>=1.7.1`: For the MetaCall Protocol server and client.\n\n### Installation\nIt is recommended to use a virtual environment.\n\n1.  **Create and activate a virtual environment:**\n    ```bash\n    python -m venv .venv\n    source .venv/bin/activate\n    ```\n\n2.  **Install dependencies using `uv`:**\n    ```bash\n    uv sync\n    ```\n\n## Running the MCP Server\n\nTo start the MCP server, run `main.py`:\n```bash\nuv run main.py\n```\nThis will start the MCP server, making the `ocr_image` tool available.\n\n## Available MCP Tools\n\n### `ocr_image`\n-   **Description:** Conducts OCR on the provided image file using macOS's built-in capabilities. Returns recognized text segments, their confidence scores, and bounding box coordinates.\n-   **Input:** `file_path: str` - The absolute or relative path to the image file.\n-   **Output (Example Success):**\n    ```json\n    {\n      \"filename\": \"path/to/your/image.png\",\n      \"annotations\": [\n        {\n          \"text\": \"Hello World\",\n          \"confidence\": 0.95,\n          \"bounding_box\": [0.1, 0.1, 0.5, 0.05] \n        },\n        // ... more annotations\n      ]\n    }\n    ```\n-   **Output (Example Error):**\n    ```json\n    {\n      \"error\": \"OCR functionality is only available on macOS.\"\n    }\n    ```\n    or\n    ```json\n    {\n      \"error\": \"File not found: path/to/nonexistent/image.png\"\n    }\n    ```\n\n**Note:** This tool will only function correctly on a macOS system due to its reliance on the Vision framework.\n\n## Testing with MCP Inspector\n\nYou can use the [MCP Inspector](https://github.com/modelcontextprotocol/inspector) to connect to the running MCP server and test the tool.\n\n## Cursor MCP Configuration\n\nTo configure this MCP server in Cursor, you can add the following to your MCP JSON configuration file (e.g., `~/.cursor/mcp.json` or project-specific `.cursor/mcp.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"ocrmac\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/macos-ocr-mcp\",\n        \"run\",\n        \"main.py\"\n      ]\n    }\n  }\n}\n```\n\nThis configuration tells Cursor how to start your MCP server. You can then call the `ocrmac.ocr_image` tool from within Cursor.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "xenoailimited--mcp-mavae": {
      "owner": "xenoailimited",
      "name": "mcp-mavae",
      "url": "https://github.com/xenoailimited/mcp-mavae",
      "imageUrl": "https://github.com/xenoailimited.png",
      "description": "A Model Context Protocol (MCP) server for interacting with image media tools, providing capabilities for image generation, editing, and management of collections and models.",
      "stars": 0,
      "forks": 1,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-04-24T16:15:59Z",
      "readme_content": "# MAVAE - IMAGE TOOLBOX\nA powerful creative and editing toolkit designed for AI Agents.\n\n[![smithery badge](https://smithery.ai/badge/@xenoailimited/mavae-image-toolbox)](https://smithery.ai/server/@xenoailimited/mavae-image-toolbox)\n[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)\n[![Node.js](https://img.shields.io/badge/Node.js-339933?style=for-the-badge&logo=nodedotjs&logoColor=white)](https://nodejs.org/)\n[![MCP](https://img.shields.io/badge/MCP-Model_Context_Protocol-blue?style=for-the-badge)](https://github.com/anthropics/model-context-protocol)\n[![Docker](https://img.shields.io/badge/Docker-2CA5E0?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)\n\nMAVAE is a Model Context Protocol (MCP) server for interacting with image media tools. It provides a standardized interface for AI Agents to generate and manipulate images.\n\n## ğŸš€ Features\n\n- **Image Generation**: Generate images using both raw configurations and predefined collections\n- **Image Editing**: Compress, crop, and resize images with proportional or fixed dimensions\n- **Collection Management**: Create, manage, and share configurations for consistent image generation\n- **Model & Lora Management**: List and utilize available models and Loras\n- **API Token Management**: Handle authentication for secure interaction with Mavae services\n\n## ğŸ“‹ Prerequisites\n\n- Node.js (v16 or higher)\n- MAVAE API Key (set as environment variable, [Apply here](https://mcp.mavae.ai/))\n\n## ğŸ› ï¸ Installation\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n\n# Start the server\nnpm start\n```\n\n## MCP Json\n```json\n{\n  \"mcpServers\": {\n      \"mavae\": {\n          \"command\": \"node\",\n          \"args\": [\n              \"***/dist/index.js\"\n          ],\n          \"env\": {\n              \"MAVAE_API_KEY\": MAVAE_API_KEY\n          }\n      }\n  }\n}\n```\nWhen using MAVAE MCP locally, this path is an absolute path ğŸ‘‰ğŸ» \"***/dist/index.js\"\n\n## ğŸ³ Docker Support\n\n```bash\n# Build Docker image\ndocker build -t mavae-mcp-server .\n\n# Run Docker container\ndocker run -e MAVAE_API_KEY=your_api_key mavae-mcp-server\n```\n\n## ğŸ“ Project Structure\n\n```\nmavae/\nâ”œâ”€â”€ src/                  # Source code\nâ”‚   â”œâ”€â”€ actions/          # API endpoint implementation handlers\nâ”‚   â”‚   â”œâ”€â”€ aigc.ts       # Image generation operations\nâ”‚   â”‚   â”œâ”€â”€ collection.ts # Collection management operations\nâ”‚   â”‚   â”œâ”€â”€ edit.ts       # Image editing operations\nâ”‚   â”‚   â””â”€â”€ token.ts      # API token operations\nâ”‚   â”œâ”€â”€ tools/            # MCP tool definitions\nâ”‚   â”‚   â”œâ”€â”€ aigc.ts       # Image generation tool definitions\nâ”‚   â”‚   â”œâ”€â”€ collection.ts # Collection management tool definitions\nâ”‚   â”‚   â””â”€â”€ edit.ts       # Image editing tool definitions\nâ”‚   â”œâ”€â”€ types/            # TypeScript type definitions\nâ”‚   â”‚   â”œâ”€â”€ aigc.ts       # Image generation types\nâ”‚   â”‚   â”œâ”€â”€ collection.ts # Collection types\nâ”‚   â”‚   â”œâ”€â”€ edit.ts       # Image editing types\nâ”‚   â”‚   â””â”€â”€ response.ts   # API response types\nâ”‚   â”œâ”€â”€ utils/            # Utility functions\nâ”‚   â”‚   â””â”€â”€ constants.ts  # Constant values\nâ”‚   â””â”€â”€ index.ts          # Server entry point\nâ”œâ”€â”€ dist/                 # Compiled JavaScript files\nâ”œâ”€â”€ package.json          # Project dependencies and scripts\nâ””â”€â”€ tsconfig.json         # TypeScript configuration\n```\n\n## ğŸ›ï¸ Available Tools\n\n### Image Generation\n- `image_raw_generate` - Generate an image using raw AIGC configuration\n- `image_collection_generate` - Generate an image using a collection's AIGC configuration\n- `image_retry_generate` - Retry a failed image generation\n- `image_state` - Get the details of an owned image\n- `generate_task_state` - Get the generation state of an image by task id\n\n### Collection Management\n- `collection_create` - Create a new collection\n- `collection_delete` - Delete a collection\n- `collection_toggle_public` - Toggle the public status of a collection\n- `collection_list` - Get the list of owned collections\n- `collection_state` - Get the details of an owned collection\n\n### Image Editing\n- `compress_image` - Lossless compression of images\n- `crop_image` - Crop images with local path and URL support\n- `resize_image` - Resize images with proportional or fixed dimensions\n\n### Model & Resources\n- `list_images` - Get the list of owned images\n- `list_loras` - Get the list of available loras\n- `list_models` - Get the list of available models\n\n### Authentication\n- `token_state` - Get the x-api-token state\n\n\n\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "xixilidao--osgearth": {
      "owner": "xixilidao",
      "name": "osgearth",
      "url": "https://github.com/xixilidao/osgearth",
      "imageUrl": "https://github.com/xixilidao.png",
      "description": "Add geospatially accurate 3D maps to C++ applications, enabling developers to integrate and display complex geographical data visually.",
      "stars": 0,
      "forks": 0,
      "license": "Other",
      "language": "",
      "updated_at": "2024-10-07T03:14:53Z",
      "readme_content": "![Windows](https://github.com/gwaldron/osgearth/actions/workflows/windows.yml/badge.svg)\n![Linux](https://github.com/gwaldron/osgearth/actions/workflows/linux.yml/badge.svg)\n![OSX](https://github.com/gwaldron/osgearth/actions/workflows/macos.yml/badge.svg)\n\n\n## Welcome to osgEarth!\n\nosgEarth adds geospatially accurate 3D maps to your C++ application.\n\n<img src=\"https://github.com/user-attachments/assets/a0b1c650-442a-4e6d-88e6-42a5c92083b8\" width=\"200\" height=\"140\"/>\n<img src=\"https://github.com/user-attachments/assets/08d0f8c0-49e1-41a8-8b97-d663337f1cbb\" width=\"200\" height=\"140\"/>\n<img src=\"https://github.com/user-attachments/assets/575315e1-e2ae-43ec-8a97-83bafcfa9131\" width=\"200\" height=\"140\"/>\n<img src=\"https://github.com/user-attachments/assets/24971c79-f93c-48eb-ab79-161bb35beae4\" width=\"200\" height=\"140\"/>\n<img src=\"https://github.com/user-attachments/assets/cf40e4a9-429d-4cac-9464-f9825149e7f2\" width=\"200\" height=\"140\"/>\n<img src=\"https://github.com/user-attachments/assets/1cd49290-9b2d-42ec-a8c3-9c1c38eb673c\" width=\"200\" height=\"140\"/>\n<img src=\"https://github.com/user-attachments/assets/bfd869fd-32b5-48b5-a037-4951f812b757\" width=\"200\" height=\"140\"/>\n<img src=\"https://github.com/user-attachments/assets/1876fffb-e683-4fa9-9521-cdd9795dea85\" width=\"200\" height=\"140\"/>\n\nosgEarth builds on trusted open source technologies like OpenSceneGraph and GDAL to give you high-performance, accurate terrain and map rendering. It supports a myriad of geospatial data formats and map projections.\n\n## Install the SDK\n\nWindows users can install the latest version of osgEarth through `vcpkg`:\n```bat\ngit clone https://github.com/microsoft/vcpkg.git\ncd vcpkg && bootstrap-vcpkg.bat\nvcpkg install osgearth:x64-windows\n```\nThis will take a while the first time as vcpkg builds osgEarth and its dependencies.\n\n## Check out some examples\n\n`osgearth_imgui` is the main command-line viewer. `osgearth_viewer` is a stripped-down viewer without any GUI.\nBoth of these read \"earth files\", XML files that describe the contents of a map.\n\nYou can find example earth files in the `tests` folder of the repo.\n\n```bat\n:: Online imagery and elevation:\nosgearth_imgui tests\\readymap.earth\n\n:: OpenStreetMap:\nosgearth_imgui tests\\osm.earth\n\n:: Local GeoTIFFs:\nosgearth_imgui tests\\simple.earth \n```\n\n## Integrate it into your project\n\nCMakeLists.txt\n```cmake\ncmake_minimum_required(VERSION 3.20)\nproject(myApp)\nfind_package(osgEarth CONFIG REQUIRED)\nadd_executable(myApp main.cpp)\ntarget_link_libraries(myApp PRIVATE osgEarth::osgEarth)\ninstall(TARGETS myApp RUNTIME DESTINATION bin)\n```\nmain.cpp\n```c++\n#include <osgEarth/MapNode>\n#include <osgEarth/TMS>\n#include <osgEarth/EarthManipulator>\n#include <osg/ArgumentParser>\n#include <osgViewer/Viewer>\n\nint main(int argc, char** argv)\n{\n    osgEarth::initialize();\n    \n    osg::ArgumentParser args(&argc, argv);\n    osgViewer::Viewer viewer(args);\n    \n    auto imagery = new osgEarth::TMSImageLayer();\n    imagery->setURL(\"https://readymap.org/readymap/tiles/1.0.0/7/\");\n    \n    auto mapNode = new osgEarth::MapNode();\n    mapNode->getMap()->addLayer(imagery);\n    \n    viewer.setSceneData(mapNode);\n    viewer.setCameraManipulator(new osgEarth::EarthManipulator(args));\n    \n    return viewer.run();\n}\n```\n\n## Resources\n\n* [Documentation](http://docs.osgearth.org/en/latest/)\n* [Gallery](https://www.pelicanmapping.com/home-1/opensource)\n* [Custom Software Development](https://www.pelicanmapping.com/software)\n\n---\nÂ© Copyright [Pelican Mapping](http://pelicanmapping.com)\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "xoy8n--webp-converter": {
      "owner": "xoy8n",
      "name": "webp-converter",
      "url": "https://github.com/xoy8n/webp-converter",
      "imageUrl": "https://github.com/xoy8n.png",
      "description": "A server that converts image files such as PNG, JPG, and JPEG to WebP format, supporting both single and batch conversions. It allows configuration of quality settings and provides detailed conversion reports.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-06-19T01:34:07Z",
      "readme_content": "# WebP Conversion MCP Server\n\nThis project is a Model Context Protocol (MCP) server that converts image files to WebP format.\n\n## Features\n\n- Convert PNG, JPG, and JPEG files to WebP\n- Support for single image or batch image conversion\n- Option to configure quality and lossless compression\n- Option to keep original files\n- Provides a detailed report of the conversion result\n\n### Installation & Execution\n\n```bash\nnpx -y @xoy8n/webp-converter@latest\n```\n\n### Cursor mcp.json Configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"webp-converter\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@xoy8n/webp-converter@latest\"]\n    }\n  }\n}\n```\n\n## MCP Tool List\n\n### 1. convert_to_webp\n\nConverts a single image file to WebP format.\n\n**Parameters:**\n\n- `image_path`: Path to the image file to convert\n- `base_path`: Base directory path\n- `quality`: WebP quality setting (default: 95)\n- `lossless`: Whether to use lossless compression (default: false)\n- `keep_original`: Whether to retain the original file (default: false)\n\n**Returns:**\n\n- Conversion success status\n- Input/output file paths\n- File size before/after conversion\n- Applied quality and compression settings\n\n### 2. batch_convert_to_webp\n\nConverts multiple image files to WebP format in one go.\n\n**Parameters:**\n\n- `image_paths`: Array of paths to image files to convert\n- `base_path`: Base directory path (optional)\n- `quality`: WebP quality setting (default: 95)\n- `lossless`: Whether to use lossless compression (default: false)\n- `keep_original`: Whether to retain the original files (default: false)\n\n**Returns:**\n\n- Array of conversion results for each image file\n\n## How to Use\n\n1. Select the image files you want to convert.\n2. Run the `convert_to_webp` or `batch_convert_to_webp` command via the MCP tools.\n3. Check the conversion results.\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "xiyuefox--mcp-hfspace": {
      "owner": "xiyuefox",
      "name": "mcp-hfspace",
      "url": "https://github.com/xiyuefox/mcp-hfspace",
      "imageUrl": "https://github.com/xiyuefox.png",
      "description": "Connect to Hugging Face Spaces to access various AI models for tasks like image generation and text-to-speech with minimal setup. Leverage the default model for seamless integration into applications.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-03-10T03:52:55Z",
      "readme_content": "# mcp-hfspace MCP Server ğŸ¤—\n\nRead the introduction here [llmindset.co.uk/resources/mcp-hfspace/](https://llmindset.co.uk/resources/mcp-hfspace/)\n\nConnect to [Hugging Face Spaces](https://huggingface.co/spaces)  with minimal setup needed - simply add your spaces and go!\n\nBy default, it connects to `evalstate/FLUX.1-schnell` providing Image Generation capabilities to Claude Desktop.\n\n![Default Setup](./images/2024-12-09-flower.png)\n\n## Installation\n\nNPM Package is `@llmindset/mcp-hfspsace`.\n\nInstall a recent version of [NodeJS](https://nodejs.org/en/download) for your platform, then add the following to the `mcpServers` section of your `claude_desktop_config.json` file:\n\n```json\n    \"mcp=hfspace\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\"\n      ]\n    }\n```\n\nPlease make sure you are using Claude Desktop 0.78 or greater.\n\nThis will get you started with an Image Generator.\n\n### Basic setup\n\nSupply a list of HuggingFace spaces in the arguments. mcp-hfspace will find the most appropriate endpoint and automatically configure it for usage. An example `claude_desktop_config.json` is supplied [below](#installation).\n\nBy default the current working directory is used for file upload/download. On Windows this is a read/write folder at `\\users\\<username>\\AppData\\Roaming\\Claude\\<version.number\\`, and on MacOS it is the is the read-only root: `/`.\n\nIt is recommended to override this and set a Working Directory for handling the upload and download of images and other file-based content. Specify either the `--work-dir=/your_directory` argument or `MCP_HF_WORK_DIR` environment variable.\n\nAn example configuration for using a modern image generator, vision model and text to speech is below with a working directory set is below:\n\n```json\n    \"mcp-hfspace\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\",\n        \"--work-dir=/Users/evalstate/mcp-store\",\n        \"shuttleai/shuttle-jaguar\",\n        \"styletts2/styletts2\",\n        \"Qwen/QVQ-72B-preview\"\n      ]\n    }\n```\n\n\nTo use private spaces, supply your Hugging Face Token with either the  `--hf-token=hf_...` argument or `HF_TOKEN` environment variable.\n\nIt's possible to run multiple server instances to use different working directories and tokens if needed.\n\n## File Handling and Claude Desktop Mode\n\nBy default, the Server operates in _Claude Desktop Mode_. In this mode, Images are returned in the tool responses, while other files are saved in the working folder, their file path is returned as a message. This will usually give the best experience if using Claude Desktop as the client.\n\nURLs can also be supplied as inputs: the content gets passed to the Space.\n\nThere is an \"Available Resources\" prompt that gives Claude the available files and mime types from your working directory. This is currently the best way to manage files.\n\n### Example 1 - Image Generation (Download Image / Claude Vision)\n\nWe'll use Claude to compare images created by `shuttleai/shuttle-3.1-aesthetic` and `FLUX.1-schnell`. The images gets saved to the Work Directory, as well as included in Claude's context window - so Claude can use its vision capabilities.\n\n![Image Generation Comparison](./images/2024-12-05-flux-shuttle.png)\n\n### Example 2 - Vision Model (Upload Image)\n\nWe'll use `merve/paligemma2-vqav2` [space link](https://huggingface.co/spaces/merve/paligemma2-vqav2) to query an image. In this case, we specify the filename which is available in the Working Directory: we  don't want to upload the Image directly to Claude's context window. So, we can prompt Claude:\n\n`use paligemma to find out who is in \"test_gemma.jpg\"` -> `Text Output: david bowie`\n![Vision - File Upload](./images/2024-12-09-bowie.png)\n\n_If you are uploading something to Claude's context use the Paperclip Attachment button, otherwise specify the filename for the Server to send directly._\n\nWe can also supply a URL. For example : `use paligemma to detect humans in https://e3.365dm.com/24/12/1600x900/skynews-taylor-swift-eras-tour_6771083.jpg?20241209000914` -> `One person is detected in the image - Taylor Swift on stage.`\n\n### Example 3 - Text-to-Speech (Download Audio)\n\nIn _Claude Desktop Mode_, the audio file is saved in the WORK_DIR, and Claude is notified of the creation. If not in desktop mode, the file is returned as a base64 encoded resource to the Client (useful if it supports embedded Audio attachments).\n\n![Voice Production](./images/2024-12-08-mcp-parler.png)\n\n### Example 4 - Speech-to-Text (Upload Audio)\n\nHere, we use `hf-audio/whisper-large-v3-turbo` to transcribe some audio, and make it available to Claude.\n\n![Audio Transcribe](./images/2024-12-09-transcribe.png)\n\n### Example 5 - Image-to-Image\n\nIn this example, we specify the filename for `microsoft/OmniParser` to use, and get returned an annotated Image and 2 separate pieces of text: descriptions and coordinates. The prompt used was `use omniparser to analyse ./screenshot.png` and `use the analysis to produce an artifact that reproduces that screen`. `DawnC/Pawmatch` is also good at this.\n\n![Omniparser and Artifact](./images/2024-12-08-mcp-omni-artifact.png)\n\n### Example 6 - Chat\n\nIn this example, Claude sets a number of reasoning puzzles for Qwen, and asks follow-up questions for clarification.\n\n![Qwen Reasoning Test](./images/2024-12-09-qwen-reason.png)\n\n### Specifying API Endpoint\n\nIf you need, you can specify a specific API Endpoint by adding it to the spacename. So rather than passing in `Qwen/Qwen2.5-72B-Instruct` you would use `Qwen/Qwen2.5-72B-Instruct/model_chat`.\n\n### Claude Desktop Mode\n\nThis can be disabled with the option --desktop-mode=false or the environment variable CLAUDE_DESKTOP_MODE=false. In this case, content as returned as an embedded Base64 encoded Resource.\n\n## Recommended Spaces\n\nSome recommended spaces to try:\n\n### Image Generation\n\n- shuttleai/shuttle-3.1-aesthetic\n- black-forest-labs/FLUX.1-schnell\n- yanze/PuLID-FLUX\n- Inspyrenet-Rembg (Background Removal)\n- diyism/Datou1111-shou_xin - [Beautiful Pencil Drawings](https://x.com/ClementDelangue/status/1867318931502895358) \n\n### Chat\n\n- Qwen/Qwen2.5-72B-Instruct\n- prithivMLmods/Mistral-7B-Instruct-v0.3\n\n### Text-to-speech / Audio Generation\n\n- fantaxy/Sound-AI-SFX\n- parler-tts/parler_tts\n\n### Speech-to-text\n\n- hf-audio/whisper-large-v3-turbo\n- (the openai models use unnamed parameters so will not work)\n\n### Text-to-music\n\n- haoheliu/audioldm2-text2audio-text2music\n\n### Vision Tasks\n\n- microsoft/OmniParser\n- merve/paligemma2-vqav2\n- merve/paligemma-doc\n- DawnC/PawMatchAI \n- DawnC/PawMatchAI/on_find_match_click - for interactive dog recommendations\n\n## Other Features\n\n### Prompts\n\nPrompts for each Space are generated, and provide an opportunity to input. Bear in mind that often Spaces aren't configured with particularly helpful labels etc. Claude is actually very good at figuring this out, and the Tool description is quite rich (but not visible in Claude Desktop).\n\n### Resources\n\nA list of files in the WORK_DIR is returned, and as a convenience returns the name as \"Use the file...\" text. If you want to add something to Claude's context, use the paperclip - otherwise specify the filename for the MCP Server. Claude does not support transmitting resources from within Context.\n\n### Private Spaces\n\nPrivate Spaces are supported with a HuggingFace token. The Token is used to download and save generated content.\n\n### Using Claude Desktop\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-hfspace\": {\n      \"command\": \"npx\"\n      \"args:\" [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\",\n        \"--work-dir=~/mcp-files/ or x:/temp/mcp-files/\",\n        \"--HF_TOKEN=HF_{optional token}\"\n        \"Qwen/Qwen2-72B-Instruct\",\n        \"black-forest-labs/FLUX.1-schnell\",\n        \"space/example/specific-endpint\"\n        (... and so on)\n        ]\n    }\n  }\n}\n```\n\n## Known Issues and Limitations\n\n### mcp-hfspace\n\n- Endpoints with unnamed parameters are unsupported for the moment.\n- Full translation from some complex Python types to suitable MCP formats.\n\n### Claude Desktop\n\n- Claude Desktop 0.75 doesn't seem to respond to errors from the MCP Server, timing out instead. For persistent issues, use the MCP Inspector to get a better look at diagnosing what's going wrong. If something suddenly stops working, it's probably due to exhausting your HuggingFace ZeroGPU quota - try again after a short period, or set up your own Space for hosting.\n- Claude Desktop seems to use a hard timeout value of 60s, and doesn't appear  to use Progress Notifications to manage UX or keep-alive. If you are using ZeroGPU spaces, large/heavy jobs may timeout. Check the WORK_DIR for results though; the MCP Server will still capture and save the result if it was produced.\n- Claude Desktops reporting of Server Status, logging etc. isn't great - use [@modelcontextprotocol/inspector](https://github.com/modelcontextprotocol/inspector) to help diagnose issues.\n\n### HuggingFace Spaces\n\n- If ZeroGPU quotas or queues are too long, try duplicating the space. If your job takes less than sixty seconds, you can usually change the function decorator `@spaces.GPU(duration=20)` in `app.py` to request less quota when running the job.\n- If you have a HuggingFace Pro account, please note that The Gradio API does not your additional quote for ZeroGPU jobs - you will need to set an `X-IP-Token` header to achieve that.\n- If you have a private space, and dedicated hardware your HF_TOKEN will give you direct access to that - no quota's apply. I recommend this if you are using for any kind of Production task.\n\n## Third Party MCP Services\n\n<a href=\"https://glama.ai/mcp/servers/s57c80wvgq\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/s57c80wvgq/badge\" alt=\"mcp-hfspace MCP server\" /></a>\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "yanjunz--mcp_search_images": {
      "owner": "yanjunz",
      "name": "mcp_search_images",
      "url": "https://github.com/yanjunz/mcp_search_images",
      "imageUrl": "https://github.com/yanjunz.png",
      "description": "Search for high-quality images from sources like Unsplash, Pexels, and Pixabay, and generate custom icons based on text descriptions, facilitating visual enhancements for projects.",
      "stars": 10,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-15T13:46:13Z",
      "readme_content": "# MCP å›¾åƒæœç´¢ä¸å›¾æ ‡ç”ŸæˆæœåŠ¡\n\nåŸºäºå¤šä¸ªå›¾ç‰‡APIçš„æœç´¢æœåŠ¡å’Œå›¾æ ‡ç”ŸæˆåŠŸèƒ½ï¼Œä¸“é—¨è®¾è®¡ç”¨äºä¸ Cursor MCP æœåŠ¡é›†æˆã€‚æ”¯æŒå›¾ç‰‡æœç´¢ã€ä¸‹è½½å’ŒAIç”Ÿæˆå›¾æ ‡ã€‚\n\n![MCPå›¾åƒæœç´¢å·¥å…·ç¤ºä¾‹](examples/mcp_search_example.png)\n\n## å·¥ä½œåŸç†\n\næœ¬å·¥å…·é€šè¿‡MCP (Model Control Protocol) ä¸ºCursor IDEæä¾›å›¾åƒæœç´¢å’Œå›¾æ ‡ç”ŸæˆåŠŸèƒ½ï¼š\n\n1. **æœç´¢å›¾ç‰‡**: è¿æ¥Unsplashã€Pexelså’ŒPixabayç­‰å›¾ç‰‡æºï¼Œæ ¹æ®å…³é”®è¯æœç´¢é«˜è´¨é‡å›¾ç‰‡\n2. **ä¸‹è½½å›¾ç‰‡**: å°†æœç´¢åˆ°çš„å›¾ç‰‡ä¸‹è½½åˆ°æŒ‡å®šä½ç½®ï¼Œæ–¹ä¾¿ç›´æ¥åœ¨é¡¹ç›®ä¸­ä½¿ç”¨\n3. **ç”Ÿæˆå›¾æ ‡**: åŸºäºæ–‡æœ¬æè¿°ç”Ÿæˆè‡ªå®šä¹‰å›¾æ ‡ï¼Œæ»¡è¶³é¡¹ç›®UIéœ€æ±‚\n\n### ç³»ç»Ÿå·¥ä½œæµç¨‹\n\n```\nç”¨æˆ· (åœ¨Cursorä¸­) â†’ å‘Claude/å¤§æ¨¡å‹æé—® â†’ å¤§æ¨¡å‹è°ƒç”¨MCPå·¥å…· â†’ å·¥å…·å¤„ç†è¯·æ±‚ â†’ è¿”å›ç»“æœ â†’ å¤§æ¨¡å‹å±•ç¤ºç»“æœ\n```\n\næ¯”å¦‚ï¼Œä½ å¯ä»¥åœ¨Cursorä¸­å‘Claudeè¯¢é—®\"å¸®æˆ‘æ‰¾5å¼ å…³äºå¤ªç©ºçš„å›¾ç‰‡\"ï¼ŒClaudeä¼šé€šè¿‡MCPå·¥å…·æœç´¢å¹¶å±•ç¤ºå›¾ç‰‡ï¼Œç„¶åä½ å¯ä»¥è¿›ä¸€æ­¥è¦æ±‚ä¸‹è½½æˆ–ç”Ÿæˆç‰¹å®šå›¾æ ‡ã€‚\n\n## åŠŸèƒ½ç‰¹ç‚¹\n\n* æ”¯æŒå¤šä¸ªå›¾ç‰‡æºæœç´¢ (Unsplash, Pexels, Pixabay)\n* é«˜è´¨é‡å›¾æ ‡ç”Ÿæˆ (åŸºäºTogether AI)\n* ç®€å•æ˜“ç”¨çš„API\n* å®Œæ•´çš„é”™è¯¯å¤„ç†\n* è‡ªå®šä¹‰ä¿å­˜è·¯å¾„å’Œæ–‡ä»¶å\n* å¯è°ƒæ•´å›¾ç‰‡å°ºå¯¸\n\n## ç¯å¢ƒå‡†å¤‡\n\n### 1. Python ç¯å¢ƒ\n\n* Python 3.10+\n* ä¸‹è½½åœ°å€ï¼š https://www.python.org/downloads/\n* æ¨èä½¿ç”¨ pyenv ç®¡ç† Python ç‰ˆæœ¬ï¼š\n\n```bash\n# macOS å®‰è£… pyenv\nbrew install pyenv\n\n# å®‰è£… Python\npyenv install 3.13.2\npyenv global 3.13.2\n```\n\n### 2. uv åŒ…ç®¡ç†å·¥å…·\n\nuv æ˜¯ä¸€ä¸ªå¿«é€Ÿçš„ Python åŒ…ç®¡ç†å™¨ï¼Œéœ€è¦å…ˆå®‰è£…ï¼š\n\n```bash\n# macOS å®‰è£… uv\nbrew install uv\n\n# æˆ–è€…ä½¿ç”¨ pip å®‰è£…\npip install uv\n```\n\n### 3. å›¾ç‰‡APIå¯†é’¥\n\n#### Unsplash API å¯†é’¥\n1. è®¿é—® [Unsplash Developers](https://unsplash.com/developers)\n2. æ³¨å†Œ/ç™»å½•è´¦å·\n3. åˆ›å»ºæ–°çš„åº”ç”¨ç¨‹åº\n4. è·å– Access Key\n\n#### Pexels API å¯†é’¥\n1. è®¿é—® [Pexels API](https://www.pexels.com/api/)\n2. æ³¨å†Œ/ç™»å½•è´¦å·\n3. è¯·æ±‚APIå¯†é’¥\n\n#### Pixabay API å¯†é’¥\n1. è®¿é—® [Pixabay API](https://pixabay.com/api/docs/)\n2. æ³¨å†Œ/ç™»å½•è´¦å·\n3. è·å–APIå¯†é’¥\n\n#### Together AI API å¯†é’¥\n1. è®¿é—® [Together AI API Keys](https://api.together.xyz/keys)\n2. æ³¨å†Œ/ç™»å½•è´¦å·\n3. åˆ›å»ºæ–°çš„ API å¯†é’¥\n\n### 4. Cursor\n\n* ä¸‹è½½å¹¶å®‰è£… [Cursor IDE](https://cursor.sh/)\n* ç¡®ä¿ Cursor å·²æ­£ç¡®é…ç½® Python ç¯å¢ƒ\n\n## å®‰è£…é…ç½®\n\n1. å…‹éš†é¡¹ç›®ï¼š\n\n```bash\ngit clone https://github.com/yanjunz/mcp_search_images.git\n```\n\n2. å®‰è£…ä¾èµ–ï¼š\n\n```bash\npython3 -m pip install fastmcp requests\n```\n\nå‡ºç°è¯ä¹¦é—®é¢˜å¯ä»¥ä½¿ç”¨ï¼š\n\n```bash\npython3 -m pip install fastmcp requests --trusted-host pypi.org --trusted-host files.pythonhosted.org --upgrade --force-reinstall --no-cache-dir\n```\n\n3. é…ç½® API å¯†é’¥ï¼š\n\nä»æ¨¡æ¿åˆ›å»ºé…ç½®æ–‡ä»¶ï¼š\n\n```bash\n# å¤åˆ¶æ¨¡æ¿æ–‡ä»¶ä½œä¸ºé…ç½®æ–‡ä»¶\ncp config.json.template config.json\n\n# ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼Œè®¾ç½®APIå¯†é’¥\nnano config.json  # æˆ–ä½¿ç”¨å…¶ä»–ç¼–è¾‘å™¨\n```\n\nåœ¨ `config.json` ä¸­ä¿®æ”¹ä»¥ä¸‹é…ç½®ï¼š\n\n```json\n{\n    \"api\": {\n        \"unsplash_access_key\": \"ä½ çš„Unsplashè®¿é—®å¯†é’¥\",\n        \"pexels_api_key\": \"ä½ çš„Pexels APIå¯†é’¥\",\n        \"pixabay_api_key\": \"ä½ çš„Pixabay APIå¯†é’¥\",\n        \"together_api_key\": \"ä½ çš„Together APIå¯†é’¥\",\n        \"timeout\": 30,\n        \"max_retries\": 3,\n        \"retry_delay\": 5\n    },\n    // ...å…¶ä»–é…ç½®...\n}\n```\n\n> **æ³¨æ„**ï¼šè¯·ç¡®ä¿ä¸è¦å°†åŒ…å«APIå¯†é’¥çš„é…ç½®æ–‡ä»¶æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿä¸­ã€‚\n> é¡¹ç›®ä¸­çš„ `.gitignore` æ–‡ä»¶å·²é…ç½®ä¸ºå¿½ç•¥ `config.json`ï¼Œä½†ä¿ç•™ `config.json.template`ã€‚\n\n## è¿è¡ŒæœåŠ¡\n\n### æ–¹æ³•ä¸€ï¼šç›´æ¥ä½¿ç”¨Pythonè¿è¡Œ\n\nè¿™æ˜¯æœ€ç®€å•çš„æ–¹å¼ï¼Œç›´æ¥ä½¿ç”¨Pythonè¿è¡ŒæœåŠ¡ï¼š\n\n```bash\npython3.11 main.py\n```\n\næœåŠ¡å¯åŠ¨åä¼šæ˜¾ç¤ºä»¥ä¸‹ä¿¡æ¯:\n```\nå¯åŠ¨å›¾ç‰‡æœç´¢æœåŠ¡ - ç«¯å£: 5173\næä¾›çš„å·¥å…·: search_images, download_image, generate_icon\nINFO:     Started server process [xxxxx]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:5173 (Press CTRL+C to quit)\n```\n\n### æ–¹æ³•äºŒï¼šä½¿ç”¨fastmcpå‘½ä»¤è¿è¡Œ\n\nå¦‚æœæ‚¨å®‰è£…äº†fastmcpåŒ…ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨fastmcpå‘½ä»¤è¿è¡Œï¼š\n\n1. å¼€å‘æ¨¡å¼è¿è¡Œï¼ˆå¸¦è°ƒè¯•ç•Œé¢ï¼‰ï¼š\n\n```bash\nfastmcp dev main.py\n```\n\n2. ç”Ÿäº§æ¨¡å¼è¿è¡Œï¼š\n\n```bash\nfastmcp run main.py\n```\n\n3. å¦‚æœç«¯å£è¢«å ç”¨ï¼Œå¯ä»¥æŒ‡å®šå…¶ä»–ç«¯å£ï¼š\n\n```bash\nPORT=5174 fastmcp dev main.py\n```\n\n### æ–¹æ³•ä¸‰ï¼šä½¿ç”¨uvè¿è¡Œ\n\nå¦‚æœæ‚¨ä½¿ç”¨uvä½œä¸ºåŒ…ç®¡ç†å™¨ï¼š\n\n```bash\nuv run --with fastmcp fastmcp run main.py\n```\n\næˆ–è€…åœ¨å¼€å‘æ¨¡å¼ä¸‹ï¼š\n\n```bash\nuv run --with fastmcp fastmcp dev main.py\n```\n\n### Cursorä¸MCPçš„å·¥ä½œåŸç†\n\nä¸ºäº†æ›´å¥½åœ°ç†è§£å’Œè§£å†³è¿æ¥é—®é¢˜ï¼Œä»¥ä¸‹æ˜¯Cursorä¸MCPæœåŠ¡äº¤äº’çš„åŸºæœ¬å·¥ä½œåŸç†ï¼š\n\n1. **MCPæœåŠ¡å¯åŠ¨æµç¨‹**ï¼š\n   * å½“è¿è¡Œ`python3.11 main.py`æ—¶ï¼ŒæœåŠ¡åˆå§‹åŒ–å¹¶åˆ›å»ºSSEï¼ˆServer-Sent Eventsï¼‰åº”ç”¨\n   * æœåŠ¡åœ¨æŒ‡å®šç«¯å£ï¼ˆé»˜è®¤5173ï¼‰å¼€å§‹ç›‘å¬è¯·æ±‚\n   * æœåŠ¡æ³¨å†Œå·¥å…·å‡½æ•°ï¼ˆsearch_images, download_image, generate_iconï¼‰\n   * å¯¹äºä½¿ç”¨ServerLinkæ–¹å¼çš„è¿æ¥ï¼ŒæœåŠ¡éœ€è¦åœ¨`/sse`è·¯å¾„ä¸Šæ­£ç¡®å¤„ç†SSEè¯·æ±‚\n\n2. **Cursorè¿æ¥æµç¨‹**ï¼š\n   * å½“åœ¨Cursorè®¾ç½®ä¸­æ·»åŠ MCPå·¥å…·æ—¶ï¼ŒCursorå°è¯•ä¸æä¾›çš„URLå»ºç«‹è¿æ¥\n   * Cursorå‘é€åˆå§‹åŒ–è¯·æ±‚ï¼Œæ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£å¸¸å“åº”\n   * æœåŠ¡éœ€è¦è¿”å›æ­£ç¡®çš„MCPåè®®å“åº”ï¼ŒåŒ…æ‹¬å¯ç”¨å·¥å…·åˆ—è¡¨\n   * è¿æ¥æˆåŠŸåï¼ŒCursorä¼šå°†è¯¥å·¥å…·æ·»åŠ åˆ°å¯ç”¨å·¥å…·åˆ—è¡¨\n   \n3. **è¯Šæ–­è¿æ¥é—®é¢˜**ï¼š\n   * æ£€æŸ¥æœåŠ¡æ˜¯å¦åœ¨è¿è¡Œï¼š`lsof -i :5173`\n   * æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼š`curl http://localhost:5173`\n   * æ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£ç¡®å®ç°MCPåè®®ï¼šæœåŠ¡å¯åŠ¨æ—¥å¿—åº”æ˜¾ç¤ºæ³¨å†Œçš„å·¥å…·\n   * æ£€æŸ¥é˜²ç«å¢™å’Œç½‘ç»œæƒé™ï¼šæœ¬åœ°æœåŠ¡æœ‰æ—¶å¯èƒ½è¢«é˜²ç«å¢™é˜»æ­¢\n   \n4. **å®Œæ•´çš„æµ‹è¯•æµç¨‹**ï¼š\n   ```bash\n   # 1. åœæ­¢ä»»ä½•å¯èƒ½æ­£åœ¨è¿è¡Œçš„æœåŠ¡\n   pkill -f \"python.*main.py\"\n   \n   # 2. å¯åŠ¨æœåŠ¡ï¼ˆåœ¨å‰å°è¿è¡Œä»¥æŸ¥çœ‹æ—¥å¿—ï¼‰\n   python3.11 main.py\n   \n   # 3. åœ¨æ–°çš„ç»ˆç«¯çª—å£ä¸­ï¼Œæµ‹è¯•è¿æ¥\n   curl http://localhost:5173\n   \n   # 4. æµ‹è¯•SSEç«¯ç‚¹ï¼ˆç”¨äºServerLinkæ–¹å¼ï¼‰\n   curl http://localhost:5173/sse\n   \n   # 5. åœ¨Cursorä¸­æ·»åŠ MCPå·¥å…·å¹¶æµ‹è¯•\n   ```\n\nå¦‚æœæŒ‰ç…§ä»¥ä¸Šæ­¥éª¤æ“ä½œåä»ç„¶æ— æ³•è¿æ¥ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥Pythonç‰ˆæœ¬å…¼å®¹æ€§æˆ–ä¾èµ–åŒ…æ˜¯å¦æ­£ç¡®å®‰è£…ã€‚æœ‰æ—¶é‡æ–°å®‰è£…ä¾èµ–åŒ…ä¹Ÿæœ‰å¸®åŠ©ï¼š\n\n```bash\npython3.11 -m pip uninstall fastmcp mcp uvicorn starlette -y\npython3.11 -m pip install fastmcp mcp uvicorn starlette\n```\n\n## ä½¿ç”¨è¯´æ˜\n\n### åœ¨ Cursor IDE ä¸­ä½¿ç”¨\n\n1. ç¡®ä¿æœåŠ¡æ­£åœ¨è¿è¡Œ\n   ```bash\n   # ç›´æ¥è¿è¡ŒPythonè„šæœ¬\n   python3.11 main.py\n   ```\n   æœåŠ¡å¯åŠ¨åä¼šæ˜¾ç¤ºä»¥ä¸‹ä¿¡æ¯:\n   ```\n   å¯åŠ¨å›¾ç‰‡æœç´¢æœåŠ¡ - ç«¯å£: 5173\n   æä¾›çš„å·¥å…·: search_images, download_image, generate_icon\n   INFO:     Started server process [xxxxx]\n   INFO:     Waiting for application startup.\n   INFO:     Application startup complete.\n   INFO:     Uvicorn running on http://0.0.0.0:5173 (Press CTRL+C to quit)\n   ```\n\n2. åœ¨Cursorä¸­æ·»åŠ MCPæœåŠ¡:\n   * æ‰“å¼€Cursor IDE\n   * ç‚¹å‡»å·¦ä¸‹è§’çš„é½¿è½®å›¾æ ‡ï¼Œæ‰“å¼€è®¾ç½®\n   * é€‰æ‹©\"AI & Copilot\"è®¾ç½®\n   * åœ¨\"MCPå·¥å…·\"éƒ¨åˆ†ç‚¹å‡»\"æ·»åŠ MCPå·¥å…·\"\n   * å¡«å†™ä»¥ä¸‹ä¿¡æ¯:\n     - åç§°: å›¾ç‰‡æœç´¢æœåŠ¡\n     - ç±»å‹: SSE (Server-Sent Events)\n     - URL: http://localhost:5173\n     - ç‚¹å‡»\"ä¿å­˜\"\n     \n   **å¤‡é€‰é…ç½®æ–¹æ³•**:\n   * æŸäº›ç‰ˆæœ¬çš„Cursorå¯èƒ½éœ€è¦ä½¿ç”¨ServerLinké…ç½®:\n     - åç§°: å›¾ç‰‡æœç´¢æœåŠ¡\n     - ç±»å‹: sse\n     - ServerLink: http://localhost:5173/sse\n     - ç‚¹å‡»\"ä¿å­˜\"\n\n   > **æ³¨æ„**: å¦‚æœå‡ºç°\"Fail to create client\"é”™è¯¯ï¼Œè¯·æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹:\n   > 1. ç¡®è®¤æœåŠ¡æ­£åœ¨è¿è¡Œ (é€šè¿‡`lsof -i :5173`æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«ç›‘å¬)\n   > 2. å°è¯•åœ¨æµè§ˆå™¨ä¸­è®¿é—®`http://localhost:5173`æµ‹è¯•è¿æ¥æ€§\n   > 3. ç¡®ä¿URLæ²¡æœ‰å¤šä½™çš„æ–œæ æˆ–ç©ºæ ¼\n   > 4. å¯¹äºServerLinkæ–¹å¼ï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ç«¯ç‚¹è·¯å¾„`/sse`\n   > 5. é‡å¯æœåŠ¡åå†æ¬¡å°è¯•æ·»åŠ \n   > 6. æœ‰æ—¶éœ€è¦é‡å¯Cursor IDEä»¥æ¸…é™¤ä¹‹å‰çš„è¿æ¥ç¼“å­˜\n\n3. å¼€å§‹ä½¿ç”¨MCPå·¥å…·:\n   * åœ¨Cursorä¸­æ‰“å¼€åŒ…å«Claudeæˆ–å…¶ä»–æ”¯æŒå·¥å…·è°ƒç”¨çš„å¤§æ¨¡å‹å¯¹è¯çª—å£\n   * å½“æœåŠ¡æ­£åœ¨è¿è¡Œæ—¶ï¼Œå¤§æ¨¡å‹å¯ä»¥è‡ªåŠ¨å‘ç°å¹¶ä½¿ç”¨è¯¥å·¥å…·\n   * å¦‚æœå¤§æ¨¡å‹æœªè‡ªåŠ¨å‘ç°å·¥å…·ï¼Œå¯ä»¥æç¤ºå®ƒ:\"è¯·ä½¿ç”¨å›¾ç‰‡æœç´¢æœåŠ¡æ¥æŸ¥æ‰¾å›¾ç‰‡\"\n\n4. åœ¨å¼€å‘è¿‡ç¨‹ä¸­éšæ—¶ä½¿ç”¨:\n   * ç¼–å†™ä»£ç æ—¶éœ€è¦å›¾æ ‡ç´ æï¼Œå¯ä»¥ç›´æ¥å‘å¤§æ¨¡å‹æè¿°éœ€æ±‚\n   * ä¾‹å¦‚:\"å¸®æˆ‘æ‰¾ä¸€äº›é€‚åˆä½œä¸ºç™»å½•æŒ‰é’®çš„å›¾æ ‡\"\n   * å¤§æ¨¡å‹ä¼šè°ƒç”¨MCPå·¥å…·æœç´¢å›¾ç‰‡å¹¶å±•ç¤ºç»“æœ\n   * ä½ å¯ä»¥è¿›ä¸€æ­¥è¦æ±‚ä¸‹è½½æˆ–ç”Ÿæˆè‡ªå®šä¹‰å›¾æ ‡\n\n5. æŸ¥çœ‹å›¾æ ‡ä¿å­˜ä½ç½®:\n   * é»˜è®¤æƒ…å†µä¸‹ï¼Œå›¾æ ‡ä¼šä¿å­˜åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„`icons`æ–‡ä»¶å¤¹ä¸­\n   * å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹å·²ä¿å­˜çš„å›¾æ ‡:\n     ```bash\n     ls -la icons\n     ```\n\n### åŠŸèƒ½ä½¿ç”¨ç¤ºä¾‹\n\n#### æœç´¢å›¾ç‰‡\n\nå¯ä»¥ç›´æ¥å‘å¤§æ¨¡å‹æè¿°éœ€æ±‚:\n```\næœç´¢å…³é”®è¯ä¸º\"technology\"çš„å›¾ç‰‡\n```\næˆ–æ›´å…·ä½“çš„æè¿°:\n```\nè¯·åœ¨Unsplashä¸Šæœç´¢5å¼ å…³äº\"artificial intelligence\"çš„å›¾ç‰‡\n```\n\n#### ä¸‹è½½å›¾ç‰‡\n\nå½“å¤§æ¨¡å‹æ˜¾ç¤ºæœç´¢ç»“æœåï¼Œä½ å¯ä»¥è¦æ±‚ä¸‹è½½ç‰¹å®šå›¾ç‰‡:\n```\nä¸‹è½½ç¬¬2å¼ å›¾ç‰‡å¹¶ä¿å­˜ä¸ºtech-icon.png\n```\næˆ–è€…æŒ‡å®šä¿å­˜è·¯å¾„:\n```\nå°†ç¬¬3å¼ å›¾ç‰‡ä¸‹è½½åˆ°/Users/username/Desktop/ï¼Œæ–‡ä»¶åä¸ºai-image.jpg\n```\n\n#### ç”Ÿæˆå›¾æ ‡\n\nå¯ä»¥æä¾›è¯¦ç»†çš„æè¿°æ¥ç”Ÿæˆç¬¦åˆéœ€æ±‚çš„å›¾æ ‡:\n```\nç”Ÿæˆä¸€ä¸ªè“è‰²ç§‘æŠ€é£æ ¼çš„å›¾æ ‡ï¼Œä¿å­˜ä¸ºblue-tech.png\n```\næˆ–è€…æ›´è¯¦ç»†çš„æè¿°:\n```\nè¯·åˆ›å»ºä¸€ä¸ªæ‰å¹³åŒ–è®¾è®¡çš„é‚®ä»¶å›¾æ ‡ï¼Œçº¢è‰²è½®å»“ï¼Œç™½è‰²èƒŒæ™¯ï¼Œå›¾æ ‡å°ºå¯¸ä¸º256x256ï¼Œä¿å­˜ä¸ºemail-icon.png\n```\n\n### å®é™…å¯¹è¯ç¤ºä¾‹\n\næŸ¥çœ‹[ç¤ºä¾‹å¯¹è¯](examples/dialog_example.md)äº†è§£å¦‚ä½•åœ¨å®é™…ä½¿ç”¨ä¸­ä¸Claude/å¤§æ¨¡å‹äº¤äº’æ¥æœç´¢å’Œç”Ÿæˆå›¾æ ‡ã€‚\n\n### é›†æˆåˆ°é¡¹ç›®å·¥ä½œæµ\n\n1. åœ¨é¡¹ç›®åˆå§‹é˜¶æ®µæ‰¹é‡ç”Ÿæˆå›¾æ ‡:\n   * åˆ›å»ºè®¾è®¡ç³»ç»Ÿæ—¶ï¼Œå¯ä»¥ä¸€æ¬¡æ€§ç”Ÿæˆå¤šä¸ªç›¸å…³å›¾æ ‡\n   * ä¾‹å¦‚:\"å¸®æˆ‘ç”Ÿæˆä¸€å¥—åŒ…å«ä¸»é¡µã€è®¾ç½®ã€ç”¨æˆ·ã€æ¶ˆæ¯é€šçŸ¥çš„åº”ç”¨å›¾æ ‡\"\n\n2. å¼€å‘è¿‡ç¨‹ä¸­æŒ‰éœ€æœç´¢:\n   * åœ¨ç¼–å†™ä»£ç æ—¶éšæ—¶æŸ¥æ‰¾æ‰€éœ€å›¾ç‰‡èµ„æº\n   * ä¾‹å¦‚:\"æˆ‘æ­£åœ¨å¼€å‘ä¸€ä¸ªå¤©æ°”åº”ç”¨ï¼Œéœ€è¦å‡ ä¸ªå¤©æ°”ç›¸å…³çš„å›¾æ ‡\"\n\n3. é¡¹ç›®å®Œå–„é˜¶æ®µå®šåˆ¶å›¾æ ‡:\n   * æ ¹æ®åº”ç”¨é£æ ¼ç»Ÿä¸€ä¼˜åŒ–å›¾æ ‡\n   * ä¾‹å¦‚:\"ç”Ÿæˆä¸€ç»„ä¸æˆ‘å½“å‰åº”ç”¨é£æ ¼ä¸€è‡´çš„ç¤¾äº¤åª’ä½“åˆ†äº«å›¾æ ‡\"\n\n### æœ€ä½³å®è·µ\n\n1. **ä½¿ç”¨æ˜ç¡®çš„å…³é”®è¯**: æœç´¢æ—¶ä½¿ç”¨å…·ä½“ã€æ˜ç¡®çš„å…³é”®è¯è·å¾—æ›´ç²¾ç¡®çš„ç»“æœ\n2. **æŒ‡å®šå›¾ç‰‡æº**: æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„å›¾ç‰‡æºï¼ˆUnsplashé€‚åˆè‡ªç„¶é£å…‰ï¼ŒPixabayé€‚åˆå•†ä¸šå›¾ç‰‡ç­‰ï¼‰\n3. **ä¿å­˜ç»“æ„åŒ–å‘½å**: ä¸ºå›¾æ ‡ä½¿ç”¨ç»“æ„åŒ–å‘½åï¼Œå¦‚`category-name-size.png`\n4. **æ‰¹é‡æ“ä½œ**: ä¸€æ¬¡æ€§è¯·æ±‚å¤šä¸ªç›¸å…³å›¾æ ‡è€Œä¸æ˜¯é€ä¸ªè¯·æ±‚\n5. **ä¸ä»£ç ç»“åˆ**: åœ¨å®é™…å¼€å‘ä¸­æåŠä»£ç ä¸Šä¸‹æ–‡ï¼Œå¤§æ¨¡å‹å¯ä»¥æ›´å‡†ç¡®åœ°ç†è§£ä½ çš„éœ€æ±‚\n\n## é”™è¯¯æ’æŸ¥\n\n### Cursor MCPè¿æ¥é”™è¯¯\n\nå¦‚æœåœ¨Cursorä¸­æ·»åŠ MCPæœåŠ¡æ—¶é‡åˆ°\"Fail to create client\"é”™è¯¯ï¼Œè¯·å°è¯•ä»¥ä¸‹è§£å†³æ–¹æ³•ï¼š\n\n1. **æ£€æŸ¥æœåŠ¡çŠ¶æ€**ï¼š\n   ```bash\n   # æ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ\n   lsof -i :5173\n   # å¦‚æœæ²¡æœ‰è¾“å‡ºï¼Œè¡¨ç¤ºæœåŠ¡æœªè¿è¡Œï¼Œè¯·å¯åŠ¨æœåŠ¡\n   python3.11 main.py\n   ```\n\n2. **æµ‹è¯•è¿æ¥**ï¼š\n   ```bash\n   # ä½¿ç”¨curlæµ‹è¯•APIè¿æ¥\n   curl -v http://localhost:5173\n   ```\n\n3. **ä¿®æ”¹è¿æ¥è®¾ç½®**ï¼š\n   * ç¡®ä¿é€‰æ‹©äº†æ­£ç¡®çš„è¿æ¥ç±»å‹ï¼šSSE\n   * å°è¯•ä½¿ç”¨IPåœ°å€ä»£æ›¿localhostï¼š`http://127.0.0.1:5173`\n   * ç¡®ä¿URLä¸å«é¢å¤–æ–œæ ï¼šä½¿ç”¨`http://localhost:5173`è€Œé`http://localhost:5173/`\n   * å°è¯•ä½¿ç”¨ServerLinkæ–¹å¼é…ç½®ï¼š\n     - ç±»å‹: sse\n     - ServerLink: http://localhost:5173/sse\n   * æœ‰äº›ç‰ˆæœ¬çš„Cursorå¯èƒ½å¯¹URLæ ¼å¼æœ‰ç‰¹å®šè¦æ±‚ï¼Œä¸¤ç§æ–¹å¼éƒ½å€¼å¾—å°è¯•\n\n4. **é‡å¯ç»„ä»¶**ï¼š\n   * åœæ­¢å¹¶é‡å¯MCPæœåŠ¡\n   * é‡å¯Cursor IDE\n   * å¦‚æœä½¿ç”¨macOSï¼Œæ£€æŸ¥é˜²ç«å¢™è®¾ç½®æ˜¯å¦é˜»æ­¢äº†è¿æ¥\n\n5. **æ£€æŸ¥æ—¥å¿—**ï¼š\n   * è§‚å¯ŸæœåŠ¡å¯åŠ¨æ—¶çš„æ—¥å¿—è¾“å‡º\n   * å½“å°è¯•ä»Cursorè¿æ¥æ—¶ï¼ŒæŸ¥çœ‹æœåŠ¡ç«¯æœ‰æ— æ–°çš„æ—¥å¿—è¾“å‡º\n\n6. **å°è¯•å…¶ä»–ç«¯å£**ï¼š\n   * ä¿®æ”¹ä»£ç ä¸­çš„ç«¯å£ï¼ˆå¦‚æ”¹ä¸º5174ï¼‰å¹¶é‡å¯æœåŠ¡ï¼š\n   ```python\n   uvicorn.run(sse_app, host=\"0.0.0.0\", port=5174)\n   ```\n\n### å…¶ä»–å¸¸è§é—®é¢˜\n\nå¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š\n\n1. æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ\n2. ä¿å­˜è·¯å¾„æ˜¯å¦æ­£ç¡®\n3. ç›®å½•æƒé™æ˜¯å¦æ­£ç¡®\n4. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n5. API å¯†é’¥æ˜¯å¦æœ‰æ•ˆ\n6. Python ç¯å¢ƒæ˜¯å¦æ­£ç¡®é…ç½®\n7. uv æ˜¯å¦æ­£ç¡®å®‰è£…\n8. ä¾èµ–åŒ…æ˜¯å¦å®Œæ•´å®‰è£…\n\n## è´¡çŒ®\n\næ¬¢è¿æäº¤é—®é¢˜å’Œæ‹‰å–è¯·æ±‚æ¥æ”¹è¿›é¡¹ç›®ã€‚\n\n## è®¸å¯\n\n[MIT License](LICENSE) ",
      "npm_url": "",
      "npm_downloads": 0
    },
    "yunwoong7--aws-nova-canvas-mcp": {
      "owner": "yunwoong7",
      "name": "aws-nova-canvas-mcp",
      "url": "https://github.com/yunwoong7/aws-nova-canvas-mcp",
      "imageUrl": "https://github.com/yunwoong7.png",
      "description": "Generate and edit images with advanced features such as text-to-image generation, image inpainting, and background removal, using the Nova Canvas model from Amazon Bedrock.",
      "stars": 4,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-06-22T12:28:20Z",
      "readme_content": "<h2 align=\"center\">\nAWS Nova Canvas MCP Server\n</h2>\n\n<div align=\"center\">\n  <img src=\"https://img.shields.io/badge/Python-3.12-3776AB?logo=python\"/>\n  <img src=\"https://img.shields.io/badge/Amazon-Bedrock-FF9900?logo=amazon&logoColor=white\"/>\n</div>\n\nAn MCP server that allows you to generate and edit images using the Nova Canvas model of Amazon Bedrock.\n\n## Features\n\n- Text to Image\n- Image Inpainting\n- Image Outpainting\n- Image Variation\n- Image Conditioning\n- Color Guided Generation\n- Background Removal\n- Show Image Thumbnails\n\n## Installation\n\n### Claude Desktop Setup\n\n1. Configure Claude Desktop\n   * Click on **Claude > Settings** from the Claude Desktop menu.\n   * When the popup appears, select **Developer** from the left menu, and click the **Edit Settings** button.\n   * This will open a folder containing the settings file. The name of this settings file is:\n   * `claude_desktop_config.json`\n\n<div align=\"center\">\n<img src=\"https://blog.kakaocdn.net/dn/bIl5q9/btsM3U5Vjw5/aGruWqP3wNmWZ1sKrnhbPk/img.png\" width=\"70%\">\n</div>\n\n3. Add the following content to the settings file (Python version):\n\n   - python version\n\n     ```json\n     \"nova-canvas\": {\n       \"command\": \"uvx\",\n       \"args\": [\n         \"aws-nova-canvas-mcp\"\n       ],\n       \"env\": {\n         \"AWS_PROFILE\": \"YOUR_AWS_PROFILE\"\n       }\n     }\n     ```\n\n     > âœ… Only AWS_PROFILE is required. Other variables like AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION, and PORT are optional and not necessary if your AWS profile is set correctly.\n     >\n     > â€‹\tâš™ï¸ If the setup is completed successfully, you can see that the \"nova-canvas\" item has been added in **Claude > Settings > Developer tab**.\n     > âš ï¸ **Important:** MCP settings only work on the **Claude desktop app, not the Claude web browser version**\n\n## Image Save Location\n\nBy default, all generated or edited images will be saved in the following directory:\n\n* **macOS / Linux**:  `~/Desktop/aws-nova-canvas`\n* **Windows**:  `C:\\Users\\YourUsername\\Desktop\\aws-nova-canvas`\n\n> ğŸ“ If no image save path is specified, the application will automatically create and use the folder above.\n\n<div align=\"center\">\n<img src=\"https://blog.kakaocdn.net/dn/bpUWLj/btsM4kJZC6v/HHQfQctKsevWnK6LCKEkv0/img.png\" width=\"70%\">\n</div>\n\n## Usage Example\n\n<div align=\"center\">\n<img src=\"https://blog.kakaocdn.net/dn/uNi8L/btsM4pEjswV/hSfxo1gHzPvpXPsEEyuijk/img.gif\" width=\"70%\">\n</div>\n\n## Limitations\n\n- Prompt text supports up to 1024 characters\n- Image generation allows up to 3 images at a time\n- Image variation requires 1-5 reference images\n- Color guide supports 1-10 color codes\n\n## License\n\nMIT License\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "zjf2671--hh-mcp-comfyui": {
      "owner": "zjf2671",
      "name": "hh-mcp-comfyui",
      "url": "https://github.com/zjf2671/hh-mcp-comfyui",
      "imageUrl": "https://github.com/zjf2671.png",
      "description": "Integrates with local ComfyUI instances via API calls to enable natural language-driven image generation. Supports dynamic parameter replacement in workflows and automatic loading of workflow files as resources.",
      "stars": 16,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-18T16:25:43Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/zjf2671-hh-mcp-comfyui-badge.png)](https://mseep.ai/app/zjf2671-hh-mcp-comfyui)\n\n# ComfyUI MCP æœåŠ¡\n\n[![English](https://img.shields.io/badge/English-Click-yellow)](docs/README.EN.md)\n[![ç®€ä½“ä¸­æ–‡](https://img.shields.io/badge/ç®€ä½“ä¸­æ–‡-ç‚¹å‡»æŸ¥çœ‹-orange)](README.md)\n![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)\n[![License](https://img.shields.io/badge/license-MIT-green.svg)](LiCENSE)\n[![smithery badge](https://smithery.ai/badge/@zjf2671/hh-mcp-comfyui)](https://smithery.ai/server/@zjf2671/hh-mcp-comfyui)\n\nè¿™æ˜¯ä¸€ä¸ªåŸºäºModel Context Protocol (MCP)çš„ComfyUIå›¾åƒç”ŸæˆæœåŠ¡ï¼Œé€šè¿‡APIè°ƒç”¨æœ¬åœ°ComfyUIå®ä¾‹ç”Ÿæˆå›¾ç‰‡ã€‚\n\n## åŠŸèƒ½ç‰¹æ€§\n\n- é€šè¿‡MCPåè®®æä¾›å›¾åƒç”ŸæˆæœåŠ¡ï¼Œå®ç°è‡ªç„¶è¯­è¨€ç”Ÿå›¾è‡ªç”±\n- æ”¯æŒåŠ¨æ€æ›¿æ¢å·¥ä½œæµä¸­çš„æç¤ºè¯å’Œå°ºå¯¸ç­‰å‚æ•°\n- è‡ªåŠ¨åŠ è½½workflowsç›®å½•ä¸‹çš„å·¥ä½œæµæ–‡ä»¶ä½œä¸ºèµ„æº\n\n## æ–°å¢åŠŸèƒ½è®°å½•\n- [2025-06-29] æ”¯æŒkontextå›¾ç‰‡ç¼–è¾‘å·¥ä½œæµ\n![edit-image-85457440acc11a9f386f8ef284fd62f2.jpg](https://image.harryzhang.site/2025/07/edit-image-85457440acc11a9f386f8ef284fd62f2.jpg)\n- [2025-05-11] æ”¯æŒå·¥ä½œæµæ–‡ä»¶ç›®å½•åŠ¨æ€é…ç½®\n- [2025-05-09] å¢åŠ dockeræ„å»ºæ–¹å¼,æ”¯æŒPython 3.12+\n- [2025-05-07] å¢åŠ pipæ„å»ºæ–¹å¼\n- [2025-05-06] æŠŠé¡¹ç›®ç›®å½•src/hhä¿®æ”¹æˆsrc/hh_mcp_comfyui,å¢åŠ uvxæ„å»ºæ–¹å¼\n- [2025-04-26] å¢åŠ å›¾ç”Ÿå›¾å’Œç§»é™¤èƒŒæ™¯æ ·ä¾‹å·¥ä½œæµåŠæ”¯æŒå›¾ç”Ÿå›¾å·¥å…·\n- [2025-04-20] åŠ å…¥æ–‡ç”Ÿå›¾ç”Ÿæˆå·¥å…·\n \n## æ•ˆæœ\n\n- **Cherry Studioä¸­ä½¿ç”¨æ•ˆæœ**\n![image-b8f946109d63fe1ccb5e2d63933e3f9e.png](https://image.harryzhang.site/2025/07/image-b8f946109d63fe1ccb5e2d63933e3f9e.png)\n\n- **Clineä¸­ä½¿ç”¨æ•ˆæœ**\n![cline_gen_image-48d8515e0b59cd313879c62a1546162d.png](https://image.harryzhang.site/2025/07/cline_gen_image-48d8515e0b59cd313879c62a1546162d.png)\n![ComfyUI_00020_-d9171f87fc9e67fcc1966cdbfb952a0c.png](https://image.harryzhang.site/2025/07/ComfyUI_00020_-d9171f87fc9e67fcc1966cdbfb952a0c.png)\n\n## å®‰è£…ä¾èµ–\n\n**1. ç¡®ä¿å·²å®‰è£…Python 3.12+**\n\n**2. ä½¿ç”¨uvç®¡ç†Pythonç¯å¢ƒï¼š**\n- å®‰è£…uv:\n  ```bash\n  # On macOS and Linux.\n  $ curl -LsSf https://astral.sh/uv/install.sh | sh\n\n  # On Windows.\n  $ powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n  # æ›´æ–°uv(éå¿…è¦æ“ä½œ):\n  $ uv self update\n  ```\n\n## æµ‹è¯•è¿è¡ŒæœåŠ¡\n\n- **uvxæ–¹å¼**\n  ```bash\n  $ uvx hh-mcp-comfyui\n\n  INFO:hh_mcp_comfyui.server:Scanning for workflows in: C:\\Users\\tianw\\AppData\\Local\\uv\\cache\\archive-v0\\dp4MTo0f1qL0DdYF_BYCL\\Lib\\site-packages\\hh_mcp_comfyui\\workflows\n  INFO:hh_mcp_comfyui.server:Starting ComfyUI MCP Server...\n  ```\n- **pipæ–¹å¼**\n  ```bash\n  $ pip install hh_mcp_comfyui\n  \n  $ python -m hh_mcp_comfyui\n\n  INFO:hh_mcp_comfyui.server:Scanning for workflows in: F:\\Python\\Python313\\Lib\\site-packages\\hh_mcp_comfyui\\workflows\n  INFO:hh_mcp_comfyui.server:Starting ComfyUI MCP Server...\n  ```\n**å‡ºç°ä¸Šé¢çš„ä¿¡æ¯è¡¨ç¤ºæœåŠ¡å¯åŠ¨æˆåŠŸ**\n\n## ä½¿ç”¨æ–¹æ³•\n> **å¿…é¡»ç¡®ä¿æœ¬åœ°ComfyUIå®ä¾‹æ­£åœ¨è¿è¡Œ(é»˜è®¤åœ°å€: http://127.0.0.1:8188) [ComfyUIå®‰è£…åœ°å€](https://github.com/comfyanonymous/ComfyUI.git)**\n\n### Cherry Studioã€Clineã€Cursorç­‰å®¢æˆ·ç«¯çš„ä½¿ç”¨æ–¹å¼\n\n<details>\n  <summary>uvx MCPæœåŠ¡é…ç½®</summary>\n\n  ```bash\n  {\n    \"mcpServers\": {\n      \"hh-mcp-comfyui\": {\n        \"command\": \"uvx\",\n        \"args\": [\n          \"hh-mcp-comfyui@latest\"\n        ],\n        \"env\": {\n          \"COMFYUI_API_BASE\": \"http://127.0.0.1:8188\",\n          \"COMFYUI_WORKFLOWS_DIR\": \"/path/hh-mcp-comfyui/workflows\"\n        }\n      }\n    }\n  }\n  ```\n  </details>\n\n<details>\n  <summary>pip MCPæœåŠ¡é…ç½®</summary>\n\n  **éœ€è¦å…ˆæ‰§è¡Œå‘½ä»¤çª—å£å…ˆæ‰§è¡Œï¼špip install hh_mcp_comfyui**\n\n  ```bash\n  {\n    \"mcpServers\": {\n      \"hh-mcp-comfyui\": {\n        \"command\": \"python\",\n        \"args\": [\n          \"-m\",\n          \"hh_mcp_comfyui\"\n        ],\n        \"env\": {\n          \"COMFYUI_API_BASE\": \"http://127.0.0.1:8188\",\n          \"COMFYUI_WORKFLOWS_DIR\": \"/path/hh-mcp-comfyui/workflows\"\n        }\n      }\n    }\n  }\n  ```\n</details>\n\n<details>\n  <summary>docker MCPæœåŠ¡é…ç½®</summary>\n\n  **å‰ææ˜¯å·²å®‰è£…docker**\n\n  ```bash\n  {\n    \"mcpServers\": {\n      \"hh-mcp-comfyui\": {\n        \"command\": \"docker\",\n        \"args\": [\n            \"run\",\n            \"--net=host\",\n            \"-v\",\n            \"/path/hh-mcp-comfyui/workflows:/app/workflows\",\n            \"-i\",\n            \"--rm\",\n            \"zjf2671/hh-mcp-comfyui:latest\"\n        ],\n        \"env\": {\n          \"COMFYUI_API_BASE\": \"http://127.0.0.1:8188\"\n        }\n      }\n    }\n  }\n  ```\n</details>\n\n## æ ·ä¾‹å·¥ä½œæµcopyåˆ°æŒ‡å®šå·¥ä½œæµç›®å½•ï¼š\n\n  ï¼ˆ**æ³¨æ„**ï¼šä½¿ç”¨ä¸‹é¢uvxæˆ–pipæ–¹å¼æ‰¾åˆ°ä½ çš„å®‰è£…å·¥ä½œæµç›®å½•çš„ä½ç½®æŠŠæ ·ä¾‹å·¥ä½œæµæ·»åŠ è¿›å»ï¼Œç„¶åé‡å¯ä½ çš„MCPæœåŠ¡ï¼‰\n- **uvx**\n  ```bash\n  $ uvx hh-mcp-comfyui\n  ```\n  ![image-2-f89caf964efbccdad7b6fa2672d1cac0.png](https://image.harryzhang.site/2025/07/image-2-f89caf964efbccdad7b6fa2672d1cac0.png)\n- **pip**\n  \n   ```bash\n  #é¦–å…ˆå®‰è£…ä¾èµ–\n  $ pip install hh_mcp_comfyui\n  $ python -m hh_mcp_comfyui\n  ```\n  ![image-3-03a069f40492fea9947a351b8707aa3f.png](https://image.harryzhang.site/2025/07/image-3-03a069f40492fea9947a351b8707aa3f.png)\n\n## æµ‹è¯•\n\n> **ä½¿ç”¨MCP Inspectoræµ‹è¯•æœåŠ¡ç«¯å·¥å…·**\n\n- **uvxæ–¹å¼**\n  ```bash\n  $ npx @modelcontextprotocol/inspector uvx hh-mcp-comfyui\n  ``` \n- **pipæ–¹å¼**\n  ```bash\n  $ pip install hh_mcp_comfyui\n  $ npx @modelcontextprotocol/inspector python -m hh_mcp_comfyui\n  ``` \n - **dockeræ–¹å¼**\n    ```bash\n    $ npx @modelcontextprotocol/inspector docker run --net=host -i --rm zjf2671/hh-mcp-comfyui\n    ``` \nç„¶åç‚¹å‡»è¿æ¥å¦‚å›¾å³å¯è°ƒè¯•ï¼š\n![image-1-44c6a003ee317093afe5a61cfe028720.png](https://image.harryzhang.site/2025/07/image-1-44c6a003ee317093afe5a61cfe028720.png)\n\n## ä½¿ç”¨æ³¨æ„äº‹é¡¹ï¼ˆé’ˆå¯¹æ²¡æœ‰ç”¨è¿‡comfyuiçš„ç‰¹åˆ«æ³¨æ„ï¼‰\n\n- é»˜è®¤å·¥ä½œæµä¸º`t2image_bizyair_flux`\n- å›¾ç‰‡å°ºå¯¸é»˜è®¤ä¸º1024x1024\n- æœåŠ¡å¯åŠ¨æ—¶ä¼šè‡ªåŠ¨åŠ è½½workflowsç›®å½•ä¸‹çš„æ‰€æœ‰JSONå·¥ä½œæµæ–‡ä»¶\n- å¦‚æœä½ ä½¿ç”¨çš„æ˜¯æœ¬é¡¹ç›®ä¸­çš„**æ ·ä¾‹å·¥ä½œæµ**éœ€è¦åœ¨comfyuiä¸­ä¸‹è½½ä¸ªæ’ä»¶ï¼Œè¯¦ç»†æ“ä½œè¯·æŸ¥çœ‹ï¼š[æ ·ä¾‹å·¥ä½œæµæ’ä»¶å®‰è£…æ•™ç¨‹](https://ziitefe2yxn.feishu.cn/wiki/PlSmwBbBWiA0iDkc07scb4EEnHc)\n- å¦‚æœä½¿ç”¨ä½ æœ¬åœ°çš„comfyuiå·¥ä½œæµçš„è¯ï¼Œå…ˆè¦ä¿è¯ä½ çš„å·¥ä½œæµèƒ½åœ¨comfyuiæ­£å¸¸è¿è¡Œï¼Œç„¶åéœ€è¦å¯¼å‡º(API)çš„JSONæ ¼å¼ï¼Œå¹¶æ”¾å…¥åˆ°ä½ æœ¬åœ°çš„`/path/hh_mcp_comfyui/workflows`ç›®å½•ä¸­\n\n## æ·»åŠ æ–°å·¥ä½œæµ\n\n1. å°†å·¥ä½œæµJSONæ–‡ä»¶æ”¾å…¥`/path/hh_mcp_comfyui/workflows`ç›®å½•ä¸­\n  \n    å¦‚æœæ˜¯uvxå’Œpipå¯åŠ¨æ–¹å¼è¯·çœ‹ä¸Šé¢ ã€Š**æ ·ä¾‹å·¥ä½œæµcopyåˆ°æŒ‡å®šå·¥ä½œæµç›®å½•**ã€‹ çš„ä½¿ç”¨æ–¹å¼\n\n2. é‡å¯æœåŠ¡è‡ªåŠ¨åŠ è½½æ–°å·¥ä½œæµ\n\n## å¼€å‘\n\n\n### é¡¹ç›®ç»“æ„\n\n```\n.\nâ”œâ”€â”€ .gitignore\nâ”œâ”€â”€ .python-version\nâ”œâ”€â”€ pyproject.toml\nâ”œâ”€â”€ README.md\nâ”œâ”€â”€ uv.lock\nâ”œâ”€â”€ example/              # ç¤ºä¾‹å·¥ä½œæµç›®å½•\nâ”‚   â””â”€â”€ workflows/\nâ”‚       â”œâ”€â”€ i2image_bizyair_sdxl.json\nâ”‚       â”œâ”€â”€ t2image_bizyair_flux.json\nâ”‚       â”œâ”€â”€ i2image_cogview4.json\nâ”‚       â””â”€â”€ t2image_sd1.5.json\nâ”œâ”€â”€ src/                  # æºä»£ç ç›®å½•\nâ”‚   â””â”€â”€ hh_mcp_comfyui/\nâ”‚       â”œâ”€â”€ comfyui_client.py    # ComfyUIå®¢æˆ·ç«¯å®ç°\nâ”‚       â”œâ”€â”€ server.py            # MCPæœåŠ¡ä¸»æ–‡ä»¶\nâ”‚       â””â”€â”€ workflows/           # å·¥ä½œæµæ–‡ä»¶ç›®å½•\n```\n\n\n ### åˆå§‹åŒ–é¡¹ç›®å¼€å‘ç¯å¢ƒï¼š  \n\n  ```bash\n  # Clone the repository.\n  $ git clone https://github.com/zjf2671/hh-mcp-comfyui.git\n\n  $ cd hh-mcp-comfyui\n\n  # Initialized venv\n  $ uv venv\n\n  # Activate the virtual environment.\n  $ .venv\\Scripts\\activate\n\n  # Install dependencies.\n  $ uv lock\n  Resolved 30 packages in 1ms\n\n  # sync dependencies.\n  $ uv sync\n  Resolved 30 packages in 2.54s\n  Audited 29 package in 0.02ms\n  ```\n\n### æ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£å¸¸\n\n  ```bash\n  $ uv --directory ä½ æœ¬åœ°å®‰è£…ç›®å½•/hh-mcp-comfyui run hh-mcp-comfyui\n\n  INFO:__main__:Scanning for workflows in: D:\\cygitproject\\hh-mcp-comfyui\\src\\hh_mcp_comfyui\\workflows\n  INFO:__main__:Registered resource: workflow://t2image_bizyair_flux -> t2image_bizyair_flux.json\n  INFO:__main__:Starting ComfyUI MCP Server...\n  ```\n### ä½¿ç”¨MCP Inspectoræµ‹è¯•æœåŠ¡ç«¯å·¥å…·\n  \n  ```bash\n  $ npx @modelcontextprotocol/inspector uv --directory ä½ æœ¬åœ°å®‰è£…ç›®å½•/hh-mcp-comfyui run hh-mcp-comfyui\n  ```\n\n### MCPé…ç½®\n\n  ```bash\n  {\n    \"mcpServers\": {\n      \"hh-mcp-comfyui\": {\n        \"command\": \"uv\",\n        \"args\": [\n          \"--directory\",\n          \"é¡¹ç›®ç»å¯¹è·¯å¾„ï¼ˆä¾‹å¦‚ï¼šD:/hh-mcp-comfyuiï¼‰\",\n          \"run\",\n          \"hh-mcp-comfyui\"\n        ],\n        \"env\": {\n          \"COMFYUI_API_BASE\": \"http://127.0.0.1:8188\",\n          \"COMFYUI_WORKFLOWS_DIR\": \"/path/hh-mcp-comfyui/workflows\"\n        }\n      }\n    }\n  }\n  ```\n\n## è´¡çŒ®\n\n1. Forké¡¹ç›®\n2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)\n3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)\n4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)\n5. æ‰“å¼€Pull Request\n\n---\n## å¦‚æœ‰é—®é¢˜å¯ä»¥åˆ°å…¬ä¼—å·ä¸­è”ç³»æˆ‘ï¼š\n\n*<center>![å…¬ä¼—å·äºŒç»´ç ](https://image.harryzhang.site/2025/04/image-1-5ac2e62b072e6f1d6eb4e3638634094c.png)</center>*\n\n<center><u>ğŸ‘† æ‰«ç å…³æ³¨ï¼Œå‘ç°æ›´å¤šå¥½ç©çš„ï¼</u></center>\n\n---\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "zxkane--mcp-server-amazon-bedrock": {
      "owner": "zxkane",
      "name": "mcp-server-amazon-bedrock",
      "url": "https://github.com/zxkane/mcp-server-amazon-bedrock",
      "imageUrl": "https://github.com/zxkane.png",
      "description": "Integrates with Amazon Bedrock's Nova Canvas model to generate high-quality images based on text descriptions. Provides advanced features for refining image composition through negative prompts and allows control over image dimensions and quality.",
      "stars": 21,
      "forks": 11,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-25T09:31:13Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/zxkane-mcp-server-amazon-bedrock-badge.png)](https://mseep.ai/app/zxkane-mcp-server-amazon-bedrock)\n\n# Amazon Bedrock MCP Server\n\nA Model Control Protocol (MCP) server that integrates with Amazon Bedrock's Nova Canvas model for AI image generation.\n\n<a href=\"https://glama.ai/mcp/servers/9qw7dwpvj9\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/9qw7dwpvj9/badge\" alt=\"Amazon Bedrock Server MCP server\" /></a>\n\n## Features\n\n- High-quality image generation from text descriptions using Amazon's Nova Canvas model\n- Advanced control through negative prompts to refine image composition\n- Flexible configuration options for image dimensions and quality\n- Deterministic image generation with seed control\n- Robust input validation and error handling\n\n## Prerequisites\n\n1. Active AWS account with Amazon Bedrock and Nova Canvas model access\n2. Properly configured AWS credentials with required permissions\n3. Node.js version 18 or later\n\n## Installation\n\n### AWS Credentials Configuration\n\nThe server requires AWS credentials with appropriate Amazon Bedrock permissions. Configure these using one of the following methods:\n\n1. Environment variables:\n   ```bash\n   export AWS_ACCESS_KEY_ID=your_access_key\n   export AWS_SECRET_ACCESS_KEY=your_secret_key\n   export AWS_REGION=us-east-1  # or your preferred region\n   ```\n\n2. AWS credentials file (`~/.aws/credentials`):\n   ```ini\n   [the_profile_name]\n   aws_access_key_id = your_access_key\n   aws_secret_access_key = your_secret_key\n   ```\n   Environment variable for active profile:\n   ```bash\n   export AWS_PROFILE=the_profile_name\n   ```\n\n3. IAM role (when deployed on AWS infrastructure)\n\n### Claude Desktop Integration\n\nTo integrate with Claude Desktop, add the following configuration to your settings file:\n\nMacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nWindows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"amazon-bedrock\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@zxkane/mcp-server-amazon-bedrock\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your_profile_name\",         // Optional, only if you want to use a specific profile\n        \"AWS_ACCESS_KEY_ID\": \"your_access_key\",     // Optional if using AWS credentials file or IAM role\n        \"AWS_SECRET_ACCESS_KEY\": \"your_secret_key\", // Optional if using AWS credentials file or IAM role\n        \"AWS_REGION\": \"us-east-1\"                   // Optional, defaults to 'us-east-1'\n      }\n    }\n  }\n}\n```\n\n## Available Tools\n\n### generate_image\n\nCreates images from text descriptions using Amazon Bedrock's Nova Canvas model.\n\n#### Parameters\n\n- `prompt` (required): Descriptive text for the desired image (1-1024 characters)\n- `negativePrompt` (optional): Elements to exclude from the image (1-1024 characters)\n- `width` (optional): Image width in pixels (default: 1024)\n- `height` (optional): Image height in pixels (default: 1024)\n- `quality` (optional): Image quality level - \"standard\" or \"premium\" (default: \"standard\")\n- `cfg_scale` (optional): Prompt adherence strength (1.1-10, default: 6.5)\n- `seed` (optional): Generation seed for reproducibility (0-858993459, default: 12)\n- `numberOfImages` (optional): Batch size for generation (1-5, default: 1)\n\n#### Example Implementation\n\n```typescript\nconst result = await callTool('generate_image', {\n  prompt: \"A serene mountain landscape at sunset\",\n  negativePrompt: \"people, buildings, vehicles\",\n  quality: \"premium\",\n  cfg_scale: 8,\n  numberOfImages: 2\n});\n```\n\n#### Prompt Guidelines\n\nFor optimal results, avoid negative phrasing (\"no\", \"not\", \"without\") in the main prompt. Instead, move these elements to the `negativePrompt` parameter. For example, rather than using \"a landscape without buildings\" in the prompt, use \"buildings\" in the `negativePrompt`.\n\nFor detailed usage guidelines, refer to the [Nova Canvas documentation][nova-canvas-doc].\n\n## Development\n\nTo set up and run the server in a local environment:\n\n```bash\ngit clone https://github.com/zxkane/mcp-server-amazon-bedrock.git\ncd mcp-server-amazon-bedrock\nnpm install\nnpm run build\n```\n\n### Performance Considerations\n\nGeneration time is influenced by resolution (`width` and `height`), `numberOfImages`, and `quality` settings. When using higher values, be mindful of potential timeout implications in your implementation.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n[nova-canvas-doc]: https://docs.aws.amazon.com/nova/latest/userguide/image-gen-access.html\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "zym9863--pixabay-mcp": {
      "owner": "zym9863",
      "name": "pixabay-mcp",
      "url": "https://github.com/zym9863/pixabay-mcp",
      "imageUrl": "https://github.com/zym9863.png",
      "description": "Connect to the Pixabay API to search for images and retrieve formatted results that include image URLs and metadata. Handle errors seamlessly during API interactions for reliable performance.",
      "stars": 4,
      "forks": 1,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-29T07:41:49Z",
      "readme_content": "# pixabay-mcp MCP Server\n\n[ä¸­æ–‡ç‰ˆ](README_zh.md)\n\nA Model Context Protocol (MCP) server for Pixabay image and video search with structured results & runtime validation.\n\n<a href=\"https://glama.ai/mcp/servers/@zym9863/pixabay-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@zym9863/pixabay-mcp/badge\" alt=\"Pixabay Server MCP server\" />\n</a>\n\nThis TypeScript MCP server exposes Pixabay search tools over stdio so AI assistants / agents can retrieve media safely and reliably.\n\nHighlights:\n- Image & video search tools (Pixabay official API)\n- Runtime argument validation (enums, ranges, semantic checks)\n- Consistent error logging without leaking sensitive keys\n- Planned structured JSON payloads for easier downstream automation (see Roadmap)\n\n## Features\n\n### Tools\n`search_pixabay_images`\n  - Required: `query` (string)\n  - Optional: `image_type` (all|photo|illustration|vector), `orientation` (all|horizontal|vertical), `per_page` (3-200)\n  - Returns: human-readable text block (current) + (planned) structured JSON array of hits\n\n`search_pixabay_videos`\n  - Required: `query`\n  - Optional: `video_type` (all|film|animation), `orientation`, `per_page` (3-200), `min_duration`, `max_duration`\n  - Returns: human-readable text block + (planned) structured JSON with duration & URLs\n\n### Configuration\nEnvironment variables:\n| Name | Required | Default | Description |\n| ---- | -------- | ------- | ----------- |\n| `PIXABAY_API_KEY` | Yes | - | Your Pixabay API key (images & videos) |\n| `PIXABAY_TIMEOUT_MS` | No | 10000 (planned) | Request timeout once feature lands |\n| `PIXABAY_RETRY` | No | 0 (planned) | Number of retry attempts for transient network errors |\n\nNotes:\n- Safe search is enabled by default.\n- Keys are never echoed back in structured errors or logs.\n\n## Usage Examples\n\nCurrent (text only response excerpt):\n```\nFound 120 images for \"cat\":\n- cat, pet, animal (User: Alice): https://.../medium1.jpg\n- kitten, cute (User: Bob): https://.../medium2.jpg\n```\n\nPlanned structured result (Roadmap v0.4+):\n```jsonc\n{\n  \"content\": [\n    { \"type\": \"text\", \"text\": \"Found 120 images for \\\"cat\\\":\\n- ...\" },\n    {\n      \"type\": \"json\",\n      \"data\": {\n        \"query\": \"cat\",\n        \"totalHits\": 120,\n        \"page\": 1,\n        \"perPage\": 20,\n        \"hits\": [\n          { \"id\": 123, \"tags\": [\"cat\",\"animal\"], \"user\": \"Alice\", \"previewURL\": \"...\", \"webformatURL\": \"...\", \"largeImageURL\": \"...\" }\n        ]\n      }\n    }\n  ]\n}\n```\n\nError response (planned shape):\n```json\n{\n  \"content\": [{ \"type\": \"text\", \"text\": \"Pixabay API error: 400 ...\" }],\n  \"isError\": true,\n  \"metadata\": { \"status\": 400, \"code\": \"UPSTREAM_BAD_REQUEST\", \"hint\": \"Check API key or parameters\" }\n}\n```\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nWatch mode:\n```bash\nnpm run watch\n```\n\n## Installation\n\n### Option 1: Using npx (Recommended)\n\nAdd this to your Claude Desktop configuration:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"pixabay-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"pixabay-mcp@latest\"],\n      \"env\": {\n        \"PIXABAY_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n### Option 2: Local Installation\n\n1. Clone and build the project:\n\n```bash\ngit clone https://github.com/zym9863/pixabay-mcp.git\ncd pixabay-mcp\nnpm install\nnpm run build\n```\n\n2. Add the server config:\n\n```json\n{\n  \"mcpServers\": {\n    \"pixabay-mcp\": {\n      \"command\": \"/path/to/pixabay-mcp/build/index.js\",\n      \"env\": {\n        \"PIXABAY_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n### API Key Setup\n\nGet your Pixabay API key from [https://pixabay.com/api/docs/](https://pixabay.com/api/docs/) and set it in the configuration above. The same key grants access to both image and video endpoints.\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## Roadmap (Condensed)\n| Version | Focus | Key Items |\n| ------- | ----- | --------- |\n| v0.4 | Structured & Reliability | JSON payload, timeout, structured errors |\n| v0.5 | UX & Pagination | page/order params, limited retry, modular refactor, tests |\n| v0.6 | Multi-source Exploration | Evaluate integrating Unsplash/Pexels abstraction |\n\nSee `product.md` for full backlog & prioritization.\n\n## Contributing\nPlanned contributions welcome once tests & module split land (v0.5 target). Feel free to open issues for API shape / schema suggestions.\n\n## License\nMIT\n\n## Disclaimer\nThis project is not affiliated with Pixabay. Respect Pixabay's Terms of Service and rate limits.\n",
      "npm_url": "",
      "npm_downloads": 0
    },
    "zym9863--together-ai-image-server": {
      "owner": "zym9863",
      "name": "together-ai-image-server",
      "url": "https://github.com/zym9863/together-ai-image-server",
      "imageUrl": "https://github.com/zym9863.png",
      "description": "Generates images from text prompts using Together AI's image generation models via the MCP protocol. It supports optional parameters for fine-tuning the image generation process.",
      "stars": 4,
      "forks": 4,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-04-21T08:41:48Z",
      "readme_content": "# Together AI Image Server\n\nEnglish | [ç®€ä½“ä¸­æ–‡](README_zh.md)\n\nA TypeScript-based MCP (Model Context Protocol) server for generating images using Together AI API.\n\n<a href=\"https://glama.ai/mcp/servers/p1ctvg1l87\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/p1ctvg1l87/badge\" alt=\"Together AI Image Server MCP server\" />\n</a>\n\n## Overview\n\nThis server provides a simple interface to generate images using Together AI's image generation models through the MCP protocol. It allows Claude and other MCP-compatible assistants to generate images based on text prompts.\n\n## Features\n\n### Tools\n\n- `generate_image` - Generate images from text prompts\n  - Takes a text prompt as required parameter\n  - Optional parameters for controlling generation steps and number of images\n  - Returns URLs and local paths to generated images\n\n## Prerequisites\n\n- Node.js (v14 or later recommended)\n- Together AI API key\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/zym9863/together-ai-image-server.git\ncd together-ai-image-server\n\n# Install dependencies\nnpm install\n```\n\n## Configuration\n\nSet your Together AI API key as an environment variable:\n\n```bash\n# On Linux/macOS\nexport TOGETHER_API_KEY=\"your-api-key-here\"\n\n# On Windows (Command Prompt)\nset TOGETHER_API_KEY=your-api-key-here\n\n# On Windows (PowerShell)\n$env:TOGETHER_API_KEY=\"your-api-key-here\"\n```\n\nAlternatively, you can create a `.env` file in the project root:\n\n```\nTOGETHER_API_KEY=your-api-key-here\n```\n\n## Development\n\nBuild the server:\n\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n\n```bash\nnpm run watch\n```\n\n## Usage with Claude Desktop\n\nTo use with Claude Desktop, add the server config:\n\nOn macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`  \nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"Together AI Image Server\": {\n      \"command\": \"/path/to/together-ai-image-server/build/index.js\"\n    }\n  }\n}\n```\n\nReplace `/path/to/together-ai-image-server` with the actual path to your installation.\n\n## Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## API Reference\n\n### generate_image\n\nGenerates images based on a text prompt using Together AI's image generation API.\n\n**Parameters:**\n\n- `prompt` (string, required): Text prompt for image generation\n- `steps` (number, optional, default: 4): Number of diffusion steps (1-4)\n- `n` (number, optional, default: 1): Number of images to generate (1-4)\n\n**Returns:**\n\nJSON object containing:\n- `image_urls`: Array of URLs to the generated images\n- `local_paths`: Array of paths to locally cached images\n\n## License\n\nMIT\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.",
      "npm_url": "",
      "npm_downloads": 0
    }
  }
}